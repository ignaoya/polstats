,Texto,Clase
0,"
",1
1,"Medicine is the art,[1] science,[2] and practice[3] of caring for a patient and managing the diagnosis, prognosis, prevention, treatment or  palliation of their injury or disease. Medicine encompasses a variety of health care practices evolved to maintain and restore health by the prevention and treatment of illness. Contemporary medicine applies biomedical sciences, biomedical research, genetics, and medical technology to diagnose, treat, and prevent injury and disease, typically through pharmaceuticals or surgery, but also through therapies as diverse as psychotherapy, external splints and traction, medical devices, biologics, and ionizing radiation, amongst others.[4]
",1
2,"Medicine has been practiced since prehistoric times, during most of which it was an art (an area of skill and knowledge) frequently having connections to the religious and philosophical beliefs of local culture. For example, a medicine man would apply herbs and say prayers for healing, or an ancient philosopher and physician would apply bloodletting according to the theories of humorism. In recent centuries, since the advent of modern science, most medicine has become a combination of art and science (both basic and applied, under the umbrella of medical science). While stitching technique for sutures is an art learned through practice, the knowledge of what happens at the cellular and molecular level in the tissues being stitched arises through science.
",1
3,"Prescientific forms of medicine are now known as traditional medicine and folk medicine. They remain commonly used with, or instead of, scientific medicine and are thus called alternative medicine. As an example, evidence on the effectiveness of acupuncture is ""variable and inconsistent"" for any condition,[5] but is generally safe when done by an appropriately trained practitioner.[6] In contrast, alternative treatments outside the bounds not just of scientific medicine, but also that of safety and efficacy are termed quackery. This can encompass an array of practices and practitioners, irrespective of whether they are prescientific (traditional medicine and folk medicine) or modern pseudo-scientific, including chiropractic which rejects modern scientific germ theory of disease (instead believing without evidence that human diseases are caused by invisible subluxation of the bones, predominantly of the spine and less so of other bones), with just over half of chiropractors also rejecting the science of immunization.
",1
4,"Medicine (UK: /ˈmɛdsɪn/ (listen), US: /ˈmɛdɪsɪn/ (listen)) is the science and practice of the diagnosis, prognosis, treatment, and prevention of disease.[7][8] The word ""medicine"" is derived from Latin medicus, meaning ""a physician"".[9][10]
",1
5,"Medical availability and clinical practice varies across the world due to regional differences in culture and technology. Modern scientific medicine is highly developed in the Western world, while in developing countries such as parts of Africa or Asia, the population may rely more heavily on traditional medicine with limited evidence and efficacy and no required formal training for practitioners.[11]
",1
6,"In the developed world, evidence-based medicine is not universally used in clinical practice; for example, a 2007 survey of literature reviews found that about 49% of the interventions lacked sufficient evidence to support either benefit or harm.[12]
",1
7,"In modern clinical practice, physicians and physician assistants personally assess patients in order to diagnose, prognose, treat, and prevent disease using clinical judgment. The doctor-patient relationship typically begins an interaction with an examination of the patient's medical history and medical record, followed by a medical interview[13] and a physical examination. Basic diagnostic medical devices (e.g. stethoscope, tongue depressor) are typically used. After examination for signs and interviewing for symptoms, the doctor may order medical tests (e.g. blood tests), take a biopsy, or prescribe pharmaceutical drugs or other therapies. Differential diagnosis methods help to rule out conditions based on the information provided. During the encounter, properly informing the patient of all relevant facts is an important part of the relationship and the development of trust. The medical encounter is then documented in the medical record, which is a legal document in many jurisdictions.[14] Follow-ups may be shorter but follow the same general procedure, and specialists follow a similar process. The diagnosis and treatment may take only a few minutes or a few weeks depending upon the complexity of the issue.
",1
8,"The components of the medical interview[13] and encounter are:
",1
9,"The physical examination is the examination of the patient for medical signs of disease, which are objective and observable, in contrast to symptoms that are volunteered by the patient and not necessarily objectively observable.[15] The healthcare provider uses sight, hearing, touch, and sometimes smell (e.g., in infection, uremia, diabetic ketoacidosis). Four actions are the basis of physical examination: inspection, palpation (feel), percussion (tap to determine resonance characteristics), and auscultation (listen), generally in that order although auscultation occurs prior to percussion and palpation for abdominal assessments.[16]
",1
10,"The clinical examination involves the study of:[17]
",1
11,"It is to likely focus on areas of interest highlighted in the medical history and may not include everything listed above.
",1
12,"The treatment plan may include ordering additional medical laboratory tests and medical imaging studies, starting therapy, referral to a specialist, or watchful observation. Follow-up may be advised. Depending upon the health insurance plan and the managed care system, various forms of ""utilization review"", such as prior authorization of tests, may place barriers on accessing expensive services.[21]
",1
13,"The medical decision-making (MDM) process involves analysis and synthesis of all the above data to come up with a list of possible diagnoses (the differential diagnoses), along with an idea of what needs to be done to obtain a definitive diagnosis that would explain the patient's problem.
",1
14,"On subsequent visits, the process may be repeated in an abbreviated manner to obtain any new history, symptoms, physical findings, and lab or imaging results or specialist consultations.
",1
15,"Contemporary medicine is in general conducted within health care systems. Legal, credentialing and financing frameworks are established by individual governments, augmented on occasion by international organizations, such as churches. The characteristics of any given health care system have significant impact on the way medical care is provided.
",1
16,"From ancient times, Christian emphasis on practical charity gave rise to the development of systematic nursing and hospitals and the Catholic Church today remains the largest non-government provider of medical services in the world.[22] Advanced industrial countries (with the exception of the United States)[23][24] and many developing countries provide medical services through a system of universal health care that aims to guarantee care for all through a single-payer health care system, or compulsory private or co-operative health insurance. This is intended to ensure that the entire population has access to medical care on the basis of need rather than ability to pay. Delivery may be via private medical practices or by state-owned hospitals and clinics, or by charities, most commonly by a combination of all three.
",1
17,"Most tribal societies provide no guarantee of healthcare for the population as a whole. In such societies, healthcare is available to those that can afford to pay for it or have self-insured it (either directly or as part of an employment contract) or who may be covered by care financed by the government or tribe directly.
",1
18,"Transparency of information is another factor defining a delivery system. Access to information on conditions, treatments, quality, and pricing greatly affects the choice by patients/consumers and, therefore, the incentives of medical professionals. While the US healthcare system has come under fire for lack of openness,[25] new legislation may encourage greater openness. There is a perceived tension between the need for transparency on the one hand and such issues as patient confidentiality and the possible exploitation of information for commercial gain on the other.
",1
19,"Provision of medical care is classified into primary, secondary, and tertiary care categories.[26]
",1
20,"Primary care medical services are provided by physicians, physician assistants, nurse practitioners, or other health professionals who have first contact with a patient seeking medical treatment or care.[27] These occur in physician offices, clinics, nursing homes, schools, home visits, and other places close to patients. About 90% of medical visits can be treated by the primary care provider. These include treatment of acute and chronic illnesses, preventive care and health education for all ages and both sexes.
",1
21,"Secondary care medical services are provided by medical specialists in their offices or clinics or at local community hospitals for a patient referred by a primary care provider who first diagnosed or treated the patient.[28] Referrals are made for those patients who required the expertise or procedures performed by specialists. These include both ambulatory care and inpatient services, Emergency departments, intensive care medicine, surgery services, physical therapy, labor and delivery, endoscopy units, diagnostic laboratory and medical imaging services, hospice centers, etc. Some primary care providers may also take care of hospitalized patients and deliver babies in a secondary care setting.
",1
22,"Tertiary care medical services are provided by specialist hospitals or regional centers equipped with diagnostic and treatment facilities not generally available at local hospitals. These include trauma centers, burn treatment centers, advanced neonatology unit services, organ transplants, high-risk pregnancy, radiation oncology, etc.
",1
23,"Modern medical care also depends on information – still delivered in many health care settings on paper records, but increasingly nowadays by electronic means.
",1
24,"In low-income countries, modern healthcare is often too expensive for the average person. International healthcare policy researchers have advocated that ""user fees"" be removed in these areas to ensure access, although even after removal, significant costs and barriers remain.[29]
",1
25,"Separation of prescribing and dispensing is a practice in medicine and pharmacy in which the physician who provides a medical prescription is independent from the  pharmacist who provides the prescription drug. In the Western world there are centuries of tradition for separating pharmacists from physicians. In Asian countries, it is traditional for physicians to also provide drugs.[30]
",1
26,"Working together as an interdisciplinary team, many highly trained health professionals besides medical practitioners are involved in the delivery of modern health care. Examples include: nurses, emergency medical technicians and paramedics, laboratory scientists, pharmacists, podiatrists, physiotherapists, respiratory therapists, speech therapists, occupational therapists, radiographers, dietitians, and bioengineers, medical physics, surgeons, surgeon's assistant, surgical technologist.
",1
27,"The scope and sciences underpinning human medicine overlap many other fields. Dentistry, while considered by some a separate discipline from medicine, is a medical field.
",1
28,"A patient admitted to the hospital is usually under the care of a specific team based on their main presenting problem, e.g., the cardiology team, who then may interact with other specialties, e.g., surgical, radiology, to help diagnose or treat the main problem or any subsequent complications/developments.
",1
29,"Physicians have many specializations and subspecializations into certain branches of medicine, which are listed below. There are variations from country to country regarding which specialties certain subspecialties are in.
",1
30,"The main branches of medicine are:
",1
31,"In the broadest meaning of ""medicine"", there are many different specialties. In the UK, most specialities have their own body or college, which has its own entrance examination. These are collectively known as the Royal Colleges, although not all currently use the term ""Royal"". The development of a speciality is often driven by new technology (such as the development of effective anaesthetics) or ways of working (such as emergency departments); the new specialty leads to the formation of a unifying body of doctors and the prestige of administering their own examination.
",1
32,"Within medical circles, specialities usually fit into one of two broad categories: ""Medicine"" and ""Surgery."" ""Medicine"" refers to the practice of non-operative medicine, and most of its subspecialties require preliminary training in Internal Medicine. In the UK, this was traditionally evidenced by passing the examination for the Membership of the Royal College of Physicians (MRCP) or the equivalent college in Scotland or Ireland. ""Surgery"" refers to the practice of operative medicine, and most subspecialties in this area require preliminary training in General Surgery, which in the UK leads to membership of the Royal College of Surgeons of England (MRCS). At present, some specialties of medicine do not fit easily into either of these categories, such as radiology, pathology, or anesthesia. Most of these have branched from one or other of the two camps above; for example anaesthesia developed first as a faculty of the Royal College of Surgeons (for which MRCS/FRCS would have been required) before becoming the Royal College of Anaesthetists and membership of the college is attained by sitting for the examination of the Fellowship of the Royal College of Anesthetists (FRCA).
",1
33,"Surgery is an ancient medical specialty that uses operative manual and instrumental techniques on a patient to investigate or treat a pathological condition such as disease or injury, to help improve bodily function or appearance or to repair unwanted ruptured areas (for example, a perforated ear drum). Surgeons must also manage pre-operative, post-operative, and potential surgical candidates on the hospital wards. Surgery has many sub-specialties, including general surgery,[31] ophthalmic surgery,[32] cardiovascular surgery, colorectal surgery,[33] neurosurgery,[34] oral and maxillofacial surgery,[35] oncologic surgery,[36] orthopedic surgery,[37] otolaryngology,[38] plastic surgery,[39] podiatric surgery, transplant surgery, trauma surgery,[40] urology,[41] vascular surgery,[42] and pediatric surgery[43]. In some centers, anesthesiology is part of the division of surgery (for historical and logistical reasons), although it is not a surgical discipline. Other medical specialties may employ surgical procedures, such as ophthalmology and dermatology, but are not considered surgical sub-specialties per se.
",1
34,"Surgical training in the U.S. requires a minimum of five years of residency after medical school. Sub-specialties of surgery often require seven or more years. In addition, fellowships can last an additional one to three years. Because post-residency fellowships can be competitive, many trainees devote two additional years to research. Thus in some cases surgical training will not finish until more than a decade after medical school. Furthermore, surgical training can be very difficult and time-consuming.
",1
35,"Internal medicine is the medical specialty dealing with the prevention, diagnosis, and treatment of adult diseases.[44] According to some sources, an emphasis on internal structures is implied.[45] In North America, specialists in internal medicine are commonly called ""internists."" Elsewhere, especially in Commonwealth nations, such specialists are often called physicians.[46] These terms, internist or physician (in the narrow sense, common outside North America), generally exclude practitioners of gynecology and obstetrics, pathology, psychiatry, and especially surgery and its subspecialities.
",1
36,"Because their patients are often seriously ill or require complex investigations, internists do much of their work in hospitals. Formerly, many internists were not subspecialized; such general physicians would see any complex nonsurgical problem; this style of practice has become much less common. In modern urban practice, most internists are subspecialists: that is, they generally limit their medical practice to problems of one organ system or to one particular area of medical knowledge. For example, gastroenterologists and nephrologists specialize respectively in diseases of the gut and the kidneys.[47]
",1
37,"In the Commonwealth of Nations and some other countries, specialist pediatricians and geriatricians are also described as specialist physicians (or internists) who have subspecialized by age of patient rather than by organ system. Elsewhere, especially in North America, general pediatrics is often a form of primary care.
",1
38,"There are many subspecialities (or subdisciplines) of internal medicine:
",1
39,"Training in internal medicine (as opposed to surgical training), varies considerably across the world: see the articles on medical education and physician for more details. In North America, it requires at least three years of residency training after medical school, which can then be followed by a one- to three-year fellowship in the subspecialties listed above. In general, resident work hours in medicine are less than those in surgery, averaging about 60 hours per week in the US. This difference does not apply in the UK where all doctors are now required by law to work less than 48 hours per week on average.
",1
40,"The following are some major medical specialties that do not directly fit into any of the above-mentioned groups:
",1
41,"Some interdisciplinary sub-specialties of medicine include:
",1
42,"Medical education and training varies around the world. It typically involves entry level education at a university medical school, followed by a period of supervised practice or internship, or residency. This can be followed by postgraduate vocational training. A variety of teaching methods have been employed in medical education, still itself a focus of active research. In Canada and the United States of America, a Doctor of Medicine degree, often abbreviated M.D., or a Doctor of Osteopathic Medicine degree, often abbreviated as D.O. and unique to the United States, must be completed in and delivered from a recognized university.
",1
43,"Since knowledge, techniques, and medical technology continue to evolve at a rapid rate, many regulatory authorities require continuing medical education. Medical practitioners upgrade their knowledge in various ways, including medical journals, seminars, conferences, and online programs.  A database of objectives covering medical knowledge, as suggested by national societies across the United States, can be searched at http://data.medobjectives.marian.edu/.[49]
",1
44,"In most countries, it is a legal requirement for a medical doctor to be licensed or registered. In general, this entails a medical degree from a university and accreditation by a medical board or an equivalent national organization, which may ask the applicant to pass exams. This restricts the considerable legal authority of the medical profession to physicians that are trained and qualified by national standards. It is also intended as an assurance to patients and as a safeguard against charlatans that practice inadequate medicine for personal gain. While the laws generally require medical doctors to be trained in ""evidence based"", Western, or Hippocratic Medicine, they are not intended to discourage different paradigms of health.
",1
45,"In the European Union, the profession of doctor of medicine is regulated. A profession is said to be regulated when access and exercise is subject to the possession of a specific professional qualification.
The regulated professions database contains a list of regulated professions for doctor of medicine in the EU member states, EEA countries and Switzerland. This list is covered by the Directive 2005/36/EC.
",1
46,"Doctors who are negligent or intentionally harmful in their care of patients can face charges of medical malpractice and be subject to civil, criminal, or professional sanctions.
",1
47,"Medical ethics is a system of moral principles that apply values and judgments to the practice of medicine. As a scholarly discipline, medical ethics encompasses its practical application in clinical settings as well as work on its history, philosophy, theology, and sociology. Six of the values that commonly apply to medical ethics discussions are:
",1
48,"Values such as these do not give answers as to how to handle a particular situation, but provide a useful framework for understanding conflicts. When moral values are in conflict, the result may be an ethical dilemma or crisis. Sometimes, no good solution to a dilemma in medical ethics exists, and occasionally, the values of the medical community (i.e., the hospital and its staff) conflict with the values of the individual patient, family, or larger non-medical community. Conflicts can also arise between health care providers, or among family members. For example, some argue that the principles of autonomy and beneficence clash when patients refuse blood transfusions, considering them life-saving; and truth-telling was not emphasized to a large extent before the HIV era.
",1
49,"Prehistoric medicine incorporated plants (herbalism), animal parts, and minerals. In many cases these materials were used ritually as magical substances by priests, shamans, or medicine men. Well-known spiritual systems include animism (the notion of inanimate objects having spirits), spiritualism (an appeal to gods or communion with ancestor spirits); shamanism (the vesting of an individual with mystic powers); and divination (magically obtaining the truth). The field of medical anthropology examines the ways in which culture and society are organized around or impacted by issues of health, health care and related issues.
",1
50,"Early records on medicine have been discovered from ancient Egyptian medicine, Babylonian Medicine, Ayurvedic medicine (in the Indian subcontinent), classical Chinese medicine (predecessor to the modern traditional Chinese medicine), and ancient Greek medicine and Roman medicine.
",1
51,"In Egypt, Imhotep (3rd millennium BCE) is the first physician in history known by name. The oldest Egyptian medical text is the Kahun Gynaecological Papyrus from around 2000 BCE, which describes gynaecological diseases. The Edwin Smith Papyrus dating back to 1600 BCE is an early work on surgery, while the Ebers Papyrus dating back to 1500 BCE is akin to a textbook on medicine.[50]
",1
52,"In China, archaeological evidence of medicine in Chinese dates back to the Bronze Age Shang Dynasty, based on seeds for herbalism and tools presumed to have been used for surgery.[51] The Huangdi Neijing, the progenitor of Chinese medicine, is a medical text written beginning in the 2nd century BCE and compiled in the 3rd century.[52]
",1
53,"In India, the surgeon Sushruta described numerous surgical operations, including the earliest forms of plastic surgery.[53][dubious  – discuss][54] Earliest records of dedicated hospitals come from Mihintale in Sri Lanka where evidence of dedicated medicinal treatment facilities for patients are found.[55][56]
",1
54,"In Greece, the Greek physician Hippocrates, the ""father of modern medicine"",[57][58] laid the foundation for a rational approach to medicine. Hippocrates introduced the Hippocratic Oath for physicians, which is still relevant and in use today, and was the first to categorize illnesses as acute, chronic, endemic and epidemic, and use terms such as, ""exacerbation, relapse, resolution, crisis, paroxysm, peak, and convalescence"".[59][60] The Greek physician Galen was also one of the greatest surgeons of the ancient world and performed many audacious operations, including brain and eye surgeries. After the fall of the Western Roman Empire and the onset of the Early Middle Ages, the Greek tradition of medicine went into decline in Western Europe, although it continued uninterrupted in the Eastern Roman (Byzantine) Empire.
",1
55,"Most of our knowledge of ancient Hebrew medicine during the 1st millennium BC comes from the Torah, i.e. the Five Books of Moses, which contain various health related laws and rituals. The Hebrew contribution to the development of modern medicine started in the Byzantine Era, with the physician Asaph the Jew.[61]
",1
56,"The concept of hospital as institution to offer medical care and possibility of a cure for the patients due to the ideals of Christian charity, rather than just merely a place to die, appeared in the Byzantine Empire.[62]
",1
57,"Although the concept of uroscopy was known to Galen, he did not see the importance of using it to localize the disease. It was under the Byzantines with physicians such of Theophilus Protospatharius that they realized the potential in uroscopy to determine disease in a time when no microscope or stethoscope existed. That practice eventually spread to the rest of Europe.[63]
",1
58,"After 750 CE, the Muslim world had the works of Hippocrates, Galen and Sushruta translated into Arabic, and Islamic physicians engaged in some significant medical research. Notable Islamic medical pioneers include the Persian polymath, Avicenna, who, along with Imhotep and Hippocrates, has also been called the ""father of medicine"".[64] He wrote The Canon of Medicine which became a standard medical text at many medieval European universities,[65] considered one of the most famous books in the history of medicine.[66] Others include Abulcasis,[67] Avenzoar,[68] Ibn al-Nafis,[69] and Averroes.[70] Persian  physician Rhazes[71] was one of the first to question the Greek theory of humorism, which nevertheless remained influential in both medieval Western and medieval Islamic medicine.[72] Some volumes of Rhazes's work Al-Mansuri, namely ""On Surgery"" and ""A General Book on Therapy"", became part of the medical curriculum in European universities.[73] Additionally, he has been described as a doctor's doctor,[74] the father of pediatrics,[75][76] and a pioneer of ophthalmology. For example, he was the first to recognize the reaction of the eye's pupil to light.[76] The Persian Bimaristan hospitals were an early example of public hospitals.[77][78]
",1
59,"In Europe, Charlemagne decreed that a hospital should be attached to each cathedral and monastery and the historian Geoffrey Blainey likened the activities of the Catholic Church in health care during the Middle Ages to an early version of a welfare state: ""It conducted hospitals for the old and orphanages for the young; hospices for the sick of all ages; places for the lepers; and hostels or inns where pilgrims could buy a cheap bed and meal"". It supplied food to the population during famine and distributed food to the poor. This welfare system the church funded through collecting taxes on a large scale and possessing large farmlands and estates. The Benedictine order was noted for setting up hospitals and infirmaries in their monasteries, growing medical herbs and becoming the chief medical care givers of their districts, as at the great Abbey of Cluny. The Church also established a network of cathedral schools and universities where medicine was studied. The Schola Medica Salernitana in Salerno, looking to the learning of Greek and Arab physicians, grew to be the finest medical school in Medieval Europe.[79]
",1
60,"However, the fourteenth and fifteenth century Black Death devastated both the Middle East and Europe, and it has even been argued that Western Europe was generally more effective in recovering from the pandemic than the Middle East.[80] In the early modern period, important early figures in medicine and anatomy emerged in Europe, including Gabriele Falloppio and William Harvey.
",1
61,"The major shift in medical thinking was the gradual rejection, especially during the Black Death in the 14th and 15th centuries, of what may be called the 'traditional authority' approach to science and medicine. This was the notion that because some prominent person in the past said something must be so, then that was the way it was, and anything one observed to the contrary was an anomaly (which was paralleled by a similar shift in European society in general – see Copernicus's rejection of Ptolemy's theories on astronomy). Physicians like Vesalius improved upon or disproved some of the theories from the past. The main tomes used both by medicine students and expert physicians were Materia Medica and Pharmacopoeia.
",1
62,"Andreas Vesalius was the author of De humani corporis fabrica, an important book on human anatomy.[81] Bacteria and microorganisms were first observed with a microscope by Antonie van Leeuwenhoek in 1676, initiating the scientific field microbiology.[82] Independently from Ibn al-Nafis, Michael Servetus rediscovered the pulmonary circulation, but this discovery did not reach the public because it was written down for the first time in the ""Manuscript of Paris""[83] in 1546, and later published in the theological work for which he paid with his life in 1553. Later this was described by Renaldus Columbus and Andrea Cesalpino. Herman Boerhaave is sometimes referred to as a ""father of physiology"" due to his exemplary teaching in Leiden and textbook 'Institutiones medicae' (1708). Pierre Fauchard has been called ""the father of modern dentistry"".[84]
",1
63,"Veterinary medicine was, for the first time, truly separated from human medicine in 1761, when the French veterinarian Claude Bourgelat founded the world's first veterinary school in Lyon, France. Before this, medical doctors treated both humans and other animals.
",1
64,"Modern scientific biomedical research (where results are testable and reproducible) began to replace early Western traditions based on herbalism, the Greek ""four humours"" and other such pre-modern notions. The modern era really began with Edward Jenner's discovery of the smallpox vaccine at the end of the 18th century (inspired by the method of inoculation earlier practiced in Asia), Robert Koch's discoveries around 1880 of the transmission of disease by bacteria, and then the discovery of antibiotics around 1900.
",1
65,"The post-18th century modernity period brought more groundbreaking researchers from Europe. From Germany and Austria, doctors Rudolf Virchow, Wilhelm Conrad Röntgen, Karl Landsteiner and Otto Loewi made notable contributions. In the United Kingdom, Alexander Fleming, Joseph Lister, Francis Crick and Florence Nightingale are considered important. Spanish doctor Santiago Ramón y Cajal is considered the father of modern neuroscience.
",1
66,"From New Zealand and Australia came Maurice Wilkins, Howard Florey, and Frank Macfarlane Burnet.
",1
67,"Others that did significant work include William Williams Keen, William Coley, James D. Watson (United States); Salvador Luria (Italy); Alexandre Yersin (Switzerland); Kitasato Shibasaburō (Japan); Jean-Martin Charcot, Claude Bernard, Paul Broca (France); Adolfo Lutz (Brazil); Nikolai Korotkov (Russia); Sir William Osler (Canada); and Harvey Cushing (United States).
",1
68,"As science and technology developed, medicine became more reliant upon medications. Throughout history and in Europe right until the late 18th century, not only animal and plant products were used as medicine, but also human body parts and fluids.[85] Pharmacology developed in part from herbalism and some drugs are still derived from plants (atropine, ephedrine, warfarin, aspirin, digoxin, vinca alkaloids,[86] taxol, hyoscine, etc.).[87] Vaccines were discovered by Edward Jenner and Louis Pasteur.
",1
69,"The first antibiotic was arsphenamine (Salvarsan) discovered by Paul Ehrlich in 1908 after he observed that bacteria took up toxic dyes that human cells did not. The first major class of antibiotics was the sulfa drugs, derived by German chemists originally from azo dyes.
",1
70,"Pharmacology has become increasingly sophisticated; modern biotechnology allows drugs targeted towards specific physiological processes to be developed, sometimes designed for compatibility with the body to reduce side-effects. Genomics and knowledge of human genetics and human evolution is having increasingly significant influence on medicine, as the causative genes of most monogenic genetic disorders have now been identified, and the development of techniques in molecular biology, evolution, and genetics are influencing medical technology, practice and decision-making.
",1
71,"Evidence-based medicine is a contemporary movement to establish the most effective algorithms of practice (ways of doing things) through the use of systematic reviews and meta-analysis. The movement is facilitated by modern global information science, which allows as much of the available evidence as possible to be collected and analyzed according to standard protocols that are then disseminated to healthcare providers. The Cochrane Collaboration leads this movement. A 2001 review of 160 Cochrane systematic reviews revealed that, according to two readers, 21.3% of the reviews concluded insufficient evidence, 20% concluded evidence of no effect, and 22.5% concluded positive effect.[88]
",1
72,"Evidence-based medicine, prevention of medical error (and other ""iatrogenesis""), and avoidance of unnecessary health care are a priority in modern medical systems. These topics generate significant political and public policy attention, particularly in the United States where healthcare is regarded as excessively costly but population health metrics lag similar nations.[89]
",1
73,"Globally, many developing countries lack access to care and access to medicines.[90] As of 2015, most wealthy developed countries provide health care to all citizens, with a few exceptions such as the United States where lack of health insurance coverage may limit access.[91]
",1
74,"The World Health Organization (WHO) defines traditional medicine as ""the sum total of the knowledge, skills, and practices based on the theories, beliefs, and experiences indigenous to different cultures, whether explicable or not, used in the maintenance of health as well as in the prevention, diagnosis, improvement or treatment of physical and mental illness.""[92] Practices known as traditional medicines include Ayurveda, Siddha medicine, Unani, ancient Iranian medicine, Irani, Islamic medicine, traditional Chinese medicine, traditional Korean medicine, acupuncture, Muti, Ifá, and traditional African medicine.[93]
",1
75,"The WHO stated that ""inappropriate use of traditional medicines or practices can have negative or dangerous effects"" and that ""further research is needed to ascertain the efficacy and safety"" of several of the practices and medicinal plants used by traditional medicine systems.[92] As example, Indian Medical Association regard traditional medicine practices, such as Ayurveda and Siddha medicine, as quackery.[94][95][96] Practitioners of traditional medicine are not authorized to practice medicine in India unless trained at a qualified medical institution, registered with the government, and listed as registered physicians annually in The Gazette of India.[94][95] Identifying practitioners of traditional medicine, the Supreme Court of India stated in 2018 that ""unqualified, untrained quacks are posing a great risk to the entire society and playing with the lives of people without having the requisite training and education in the science from approved institutions"".[94]
",1
76,"
",1
77,"Prognosis (Greek: πρόγνωσις ""fore-knowing, foreseeing"") is a medical term for predicting the likely or expected development of a disease, including whether the signs and symptoms will improve or worsen (and how quickly) or remain stable over time; expectations of quality of life, such as the ability to carry out daily activities; the potential for complications and associated health issues; and the likelihood of survival (including life expectancy).[1][2] A prognosis is made on the basis of the normal course of the diagnosed disease, the individual's physical and mental condition, the available treatments, and additional factors.[2] A complete prognosis includes the expected duration, function, and description of the course of the disease, such as progressive decline, intermittent crisis, or sudden, unpredictable crisis.
",1
78,"When applied to large statistical populations, prognostic estimates can be very accurate: for example the statement ""45% of patients with severe septic shock will die within 28 days"" can be made with some confidence, because previous research found that this proportion of patients died. This statistical information does not apply to the prognosis for each individual patient, because patient-specific factors can substantially change the expected course of the disease: additional information is needed to determine whether a patient belongs to the 45% who will die, or to the 55% who survive.[3]
",1
79,"Prognostic scoring is also used for cancer outcome predictions. A Manchester score is an indicator of prognosis for small-cell lung cancer. For Non-Hodgkin lymphoma, physicians have developed the International Prognostic Index to predict patient outcome.
",1
80,"Other medical areas where prognostic indicators are used is in Drug-Induced Liver Injury (DILI) (Hy's law) and use of an exercise stress test as a prognostic indicator after myocardial infarction, also use to indicator multiple myeloma survive rate.[4]
",1
81,"Studies have found that most doctors are overly optimistic when making a prognosis; they tend to overstate how long a patient might live. For patients who are critically ill, particularly those in an intensive care unit, there are numerical prognostic scoring systems that are more accurate. The most famous of these is the APACHE II scale, which is most accurate when applied in the seven days prior to a patient's predicted death.
",1
82,"Knowing the prognosis helps determine whether it makes more sense to attempt certain treatments or to withhold them, and thus plays an important role in end-of-life decisions.
",1
83,"Estimators that are commonly used to describe prognoses include:
",1
84,"One of the earliest written works of medicine is the Book of Prognostics of Hippocrates, written around 400 BC. This work opens with the following statement: ""It appears to me a most excellent thing for the physician to cultivate Prognosis; for by foreseeing and foretelling, in the presence of the sick, the present, the past, and the future, and explaining the omissions which patients have been guilty of, he will be the more readily believed to be acquainted with the circumstances of the sick; so that men will have confidence to intrust themselves to such a physician.""[5]
",1
85,"For 19th century physicians, particularly those following the French school of medicine, the main aim of medicine was not to cure disease, but rather to give a medical diagnosis and achieve a satisfying prognosis of the patient's chances. Only several decades later did the focus of efforts in Western medicine shift to curing disease.[citation needed]
",1
86,"Signs and symptomsSymptomSyndrome
",1
87,"Medical diagnosisDifferential diagnosisPrognosis
",1
88,"AcuteChronicCure/Remission
",1
89,"DiseaseEponymous diseaseAcronym or abbreviation
",1
90,"A therapy or medical treatment (often abbreviated tx, Tx, or Tx) is the attempted remediation of a health problem, usually following a medical diagnosis.  
",1
91,"As a rule, each therapy has indications and contraindications.  There are many different types of therapy.  Not all therapies are effective.  Many therapies can produce unwanted adverse effects.
",1
92,"Treatment and therapy are generally considered synonyms.  However,  in the context of mental health, the term therapy may refer specifically to psychotherapy. 
",1
93,"The words care, therapy, treatment, and intervention overlap in a semantic field, and thus they can be synonymous depending on context. Moving rightward through that order, the connotative level of holism decreases and the level of specificity (to concrete instances) increases. Thus, in health care contexts (where its senses are always noncount), the word care tends to imply a broad idea of everything done to protect or improve someone's health (for example, as in the terms preventive care and primary care, which connote ongoing action), although it sometimes implies a narrower idea (for example, in the simplest cases of wound care or postanesthesia care, a few particular steps are sufficient, and the patient's interaction with that provider is soon finished). In contrast, the word intervention tends to be specific and concrete, and thus the word is often countable; for example, one instance of cardiac catheterization is one intervention performed, and coronary care (noncount) can require a series of interventions (count). At the extreme, the piling on of such countable interventions amounts to interventionism, a flawed model of care lacking holistic circumspection—merely treating discrete problems (in billable increments) rather than maintaining health. Therapy and treatment, in the middle of the semantic field, can connote either the holism of care or the discreteness of intervention, with context conveying the intent in each use. Accordingly, they can be used in both noncount and count senses (for example, therapy for chronic kidney disease can involve several dialysis treatments per week).
",1
94,"The words aceology and iamatology are obscure and obsolete synonyms referring to the study of therapies.
",1
95,"The English word therapy comes via Latin therapīa from Greek: θεραπεία and literally means ""curing"" or ""healing"".[1]
",1
96,"Levels of care classify health care into categories of chronology, priority, or intensity, as follows:
",1
97,"Treatment decisions often follow formal or informal algorithmic guidelines. Treatment options can often be ranked or prioritized into lines of therapy: first-line therapy, second-line therapy, third-line therapy, and so on. First-line therapy (sometimes called induction therapy, primary therapy, or front-line therapy)[2] is the first therapy that will be tried. Its priority over other options is usually either: (1) formally recommended on the basis of clinical trial evidence for its best-available combination of efficacy, safety, and tolerability or (2) chosen based on the clinical experience of the physician. If a first-line therapy either fails to resolve the issue or produces intolerable side effects, additional (second-line) therapies may be substituted or added to the treatment regimen, followed by third-line therapies, and so on.
",1
98,"An example of a context in which the formalization of treatment algorithms and the ranking of lines of therapy is very extensive is chemotherapy regimens. Because of the great difficulty in successfully treating some forms of cancer, one line after another may be tried. In oncology the count of therapy lines may reach 10 or even 20.
",1
99,"Often multiple therapies may be tried simultaneously (combination therapy or polytherapy). Thus combination chemotherapy is also called polychemotherapy, whereas chemotherapy with one agent at a time is called single-agent therapy or monotherapy.
",1
100,"Adjuvant therapy is therapy given in addition to the primary, main, or initial treatment, but simultaneously (as opposed to second-line therapy). Neoadjuvant therapy is therapy that is begun before the main therapy. Thus one can consider surgical excision of a tumor as the first-line therapy for a certain type and stage of cancer even though radiotherapy is used before it; the radiotherapy is neoadjuvant (chronologically first but not primary in the sense of the main event). Premedication is conceptually not far from this, but the words are not interchangeable; cytotoxic drugs to put a tumor ""on the ropes"" before surgery delivers the ""knockout punch""  are called neoadjuvant chemotherapy, not premedication, whereas things like anesthetics or prophylactic antibiotics before dental surgery are called premedication.
",1
101,"Step therapy or stepladder therapy is a specific type of prioritization by lines of therapy. It is controversial in American health care because unlike conventional decision-making about what constitutes first-line, second-line, and third-line therapy, which in the U.S. reflects safety and efficacy first and cost only according to the patient's wishes, step therapy attempts to mix cost containment by someone other than the patient (third-party payers) into the algorithm. Therapy freedom and the negotiation between individual and group rights are involved.
",1
102,"Treatments can be classified according to the method of treatment:
",1
103,"
",1
104,"Acupuncture[b] is a form of alternative medicine[2] and a key component of traditional Chinese medicine (TCM) in which thin needles are inserted into the body.[3] Acupuncture is a pseudoscience,[4][5] the theories and practices of TCM are not based on scientific knowledge, and it has been characterized as quackery.[6] There is a range of acupuncture variants which originated in different philosophies,[7] and techniques vary depending on the country in which it is performed, but can be divided into two main foundational philosophical applications and approaches, the first being the modern standardized form called eight principal TCM and the second an older system that is based on the ancient Taoist Wuxing or better known as the five elements or phases in the West.[8][9][10] Acupunture is most often used to attempt pain relief,[11][12] though acupuncturists say that it can also be used for a wide range of other conditions. Acupuncture is generally used only in combination with other forms of treatment.[13]
",1
105,"The conclusions of trials and systematic reviews of acupuncture are inconsistent, which suggests that it is not effective.[11][14][15] An overview of Cochrane reviews found that acupuncture is not effective for a wide range of conditions.[14] A systematic review conducted by medical scientists at the universities of Exeter and Plymouth found little evidence of acupuncture's effectiveness in treating pain.[11] Overall, the evidence suggests that short-term treatment with acupuncture does not produce long-term benefits.[16] Some research results suggest that acupuncture can alleviate some forms of pain, though the majority of research suggests that acupuncture's apparent effects are not caused by the treatment itself.[8] A systematic review concluded that the analgesic effect of acupuncture seemed to lack clinical relevance and could not be clearly distinguished from bias.[17] One meta-analysis found that acupuncture for chronic low back pain was cost-effective as an adjunct to standard care,[18] while a separate systematic review found insufficient evidence for the cost-effectiveness of acupuncture in the treatment of chronic low back pain.[19]
",1
106,"Acupuncture is generally safe when done by appropriately trained practitioners using clean needle technique and single-use needles.[20][21] When properly delivered, it has a low rate of mostly minor adverse effects.[3][20] Accidents and infections do occur, though, and are associated with neglect on the part of the practitioner, particularly in the application of sterile techniques.[11][21] A review conducted in 2013 stated that reports of infection transmission increased significantly in the preceding decade.[22] The most frequently reported adverse events were pneumothorax and infections.[11] Since serious adverse events continue to be reported, it is recommended that acupuncturists be trained sufficiently to reduce the risk.[11]
",1
107,"Scientific investigation has not found any histological or physiological evidence for traditional Chinese concepts such as qi, meridians, and acupuncture points,[c][26] and many modern practitioners no longer support the existence of life force energy (qi) or meridians, which was a major part of early belief systems.[7][27][28] Acupuncture is believed to have originated around 100 BC in China, around the time The Yellow Emperor's Classic of Internal Medicine (Huangdi Neijing) was published,[29] though some experts suggest it could have been practiced earlier.[8] Over time, conflicting claims and belief systems emerged about the effect of lunar, celestial and earthly cycles, yin and yang energies, and a body's ""rhythm"" on the effectiveness of treatment.[30] Acupuncture fluctuated in popularity in China due to changes in the country's political leadership and the preferential use of rationalism or Western medicine.[29] Acupuncture spread first to Korea in the 6th century AD, then to Japan through medical missionaries,[31] and then to Europe, beginning with France.[29] In the 20th century, as it spread to the United States and Western countries, spiritual elements of acupuncture that conflicted with Western beliefs were sometimes abandoned in favor of simply tapping needles into acupuncture points.[29][32][33]
",1
108,"Acupuncture is a form of alternative medicine.[2] It is used most commonly for pain relief,[11][12] though it is also used to treat a wide range of conditions. Acupuncture is generally only used in combination with other forms of treatment.[13] For example, the American Society of Anesthesiologists states it may be considered in the treatment for nonspecific, noninflammatory low back pain only in conjunction with conventional therapy.[34]
",1
109,"Acupuncture is the insertion of thin needles into the skin.[3] According to the Mayo Foundation for Medical Education and Research (Mayo Clinic), a typical session entails lying still while approximately five to twenty needles are inserted; for the majority of cases, the needles will be left in place for ten to twenty minutes.[35] It can be associated with the application of heat, pressure, or laser light.[3] Classically, acupuncture is individualized and based on philosophy and intuition, and not on scientific research.[36] There is also a non-invasive therapy developed in early 20th century Japan using an elaborate set of instruments other than needles for the treatment of children (shōnishin or shōnihari).[37][38]
",1
110,"Clinical practice varies depending on the country.[8][39] A comparison of the average number of patients treated per hour found significant differences between China (10) and the United States (1.2).[40] Chinese herbs are often used.[41] There is a diverse range of acupuncture approaches, involving different philosophies.[7] Although various different techniques of acupuncture practice have emerged, the method used in traditional Chinese medicine (TCM) seems to be the most widely adopted in the US.[2] Traditional acupuncture involves needle insertion, moxibustion, and cupping therapy,[20] and may be accompanied by other procedures such as feeling the pulse and other parts of the body and examining the tongue.[2] Traditional acupuncture involves the belief that a ""life force"" (qi) circulates within the body in lines called meridians.[42] The main methods practiced in the UK are TCM and Western medical acupuncture.[43] The term Western medical acupuncture is used to indicate an adaptation of TCM-based acupuncture which focuses less on TCM.[42][44] The Western medical acupuncture approach involves using acupuncture after a medical diagnosis.[42] Limited research has compared the contrasting acupuncture systems used in various countries for determining different acupuncture points and thus there is no defined standard for acupuncture points.[45]
",1
111,"In traditional acupuncture, the acupuncturist decides which points to treat by observing and questioning the patient to make a diagnosis according to the tradition used. In TCM, the four diagnostic methods are: inspection, auscultation and olfaction, inquiring, and palpation. Inspection focuses on the face and particularly on the tongue, including analysis of the tongue size, shape, tension, color and coating, and the absence or presence of teeth marks around the edge.[46] Auscultation and olfaction involve listening for particular sounds such as wheezing, and observing body odor.[46] Inquiring involves focusing on the ""seven inquiries"": chills and fever; perspiration; appetite, thirst and taste; defecation and urination; pain; sleep; and menses and leukorrhea.[46] Palpation is focusing on feeling the body for tender ""A-shi"" points and feeling the pulse.[46]
",1
112,"The most common mechanism of stimulation of acupuncture points employs penetration of the skin by thin metal needles, which are manipulated manually or the needle may be further stimulated by electrical stimulation (electroacupuncture).[2] Acupuncture needles are typically made of stainless steel, making them flexible and preventing them from rusting or breaking.[47] Needles are usually disposed of after each use to prevent contamination.[47] Reusable needles when used should be sterilized between applications.[47][48] In many areas, only sterile, single-use acupuncture needles are allowed, including the State of California, USA.[49] Needles vary in length between 13 to 130 millimetres (0.51 to 5.12 in), with shorter needles used near the face and eyes, and longer needles in areas with thicker tissues; needle diameters vary from 0.16 mm (0.006 in) to 0.46 mm (0.018 in),[50] with thicker needles used on more robust patients. Thinner needles may be flexible and require tubes for insertion. The tip of the needle should not be made too sharp to prevent breakage, although blunt needles cause more pain.[51]
",1
113,"Apart from the usual filiform needle, other needle types include three-edged needles and the Nine Ancient Needles.[50] Japanese acupuncturists use extremely thin needles that are used superficially, sometimes without penetrating the skin, and surrounded by a guide tube (a 17th-century invention adopted in China and the West). Korean acupuncture uses copper needles and has a greater focus on the hand.[39]
",1
114,"The skin is sterilized and needles are inserted, frequently with a plastic guide tube. Needles may be manipulated in various ways, including spinning, flicking, or moving up and down relative to the skin. Since most pain is felt in the superficial layers of the skin, a quick insertion of the needle is recommended.[52] Often the needles are stimulated by hand in order to cause a dull, localized, aching sensation that is called de qi, as well as ""needle grasp,"" a tugging feeling felt by the acupuncturist and generated by a mechanical interaction between the needle and skin.[2] Acupuncture can be painful.[53] The skill level of the acupuncturist may influence how painful the needle insertion is, and a sufficiently skilled practitioner may be able to insert the needles without causing any pain.[52]
",1
115,"De-qi (Chinese: 得气; pinyin: dé qì; ""arrival of qi"") refers to a claimed sensation of numbness, distension, or electrical tingling at the needling site. If these sensations are not observed then inaccurate location of the acupoint, improper depth of needle insertion, inadequate manual manipulation, are blamed. If de-qi is not immediately observed upon needle insertion, various manual manipulation techniques are often applied to promote it (such as ""plucking"", ""shaking"" or ""trembling"").[54]
",1
116,"Once de-qi is observed, techniques might be used which attempt to ""influence"" the de-qi; for example, by certain manipulation the de-qi can allegedly be conducted from the needling site towards more distant sites of the body. Other techniques aim at ""tonifying"" (Chinese: 补; pinyin: bǔ) or ""sedating"" (Chinese: 泄; pinyin: xiè) qi.[54] The former techniques are used in deficiency patterns, the latter in excess patterns.[54] De qi is more important in Chinese acupuncture, while Western and Japanese patients may not consider it a necessary part of the treatment.[39]
",1
117,"Acupressure being applied to a hand.
",1
118,"Sujichim, hand acupuncture
",1
119,"Japanese moxibustion
",1
120,"A woman receiving fire cupping in China.
",1
121,"Acupuncture has been researched extensively; as of 2013, there were almost 1,500 randomized controlled trials on PubMed with ""acupuncture"" in the title. The results of reviews of acupuncture's efficacy, however, have been inconclusive.[71]
",1
122,"In January 2020, David Gorski analyzed a 2020 review of systematic reviews (""Acupuncture for the Relief of Chronic Pain: A Synthesis of Systematic Reviews"") concerning the use of acupuncture to treat chronic pain. Writing in Science-Based Medicine, Gorski said that its findings highlight the conclusion that acupuncture is ""a theatrical placebo whose real history has been retconned beyond recognition."" He also said this review ""reveals the many weaknesses in the design of acupuncture clinical trials"".[72]
",1
123,"It is difficult but not impossible to design rigorous research trials for acupuncture.[73][74] Due to acupuncture's invasive nature, one of the major challenges in efficacy research is in the design of an appropriate placebo control group.[75][76] For efficacy studies to determine whether acupuncture has specific effects, ""sham"" forms of acupuncture where the patient, practitioner, and analyst are blinded seem the most acceptable approach.[73] Sham acupuncture uses non-penetrating needles or needling at non-acupuncture points,[77] e.g. inserting needles on meridians not related to the specific condition being studied, or in places not associated with meridians.[78] The under-performance of acupuncture in such trials may indicate that therapeutic effects are due entirely to non-specific effects, or that the sham treatments are not inert, or that systematic protocols yield less than optimal treatment.[79][80]
",1
124,"A 2014 review in Nature Reviews Cancer found that ""contrary to the claimed mechanism of redirecting the flow of qi through meridians, researchers usually find that it generally does not matter where the needles are inserted, how often (that is, no dose-response effect is observed), or even if needles are actually inserted. In other words, 'sham' or 'placebo' acupuncture generally produces the same effects as 'real' acupuncture and, in some cases, does better.""[81] A 2013 meta-analysis found little evidence that the effectiveness of acupuncture on pain (compared to sham) was modified by the location of the needles, the number of needles used, the experience or technique of the practitioner, or by the circumstances of the sessions.[82] The same analysis also suggested that the number of needles and sessions is important, as greater numbers improved the outcomes of acupuncture compared to non-acupuncture controls.[82] There has been little systematic investigation of which components of an acupuncture session may be important for any therapeutic effect, including needle placement and depth, type and intensity of stimulation, and number of needles used.[79] The research seems to suggest that needles do not need to stimulate the traditionally specified acupuncture points or penetrate the skin to attain an anticipated effect (e.g. psychosocial factors).[2]
",1
125,"A response to ""sham"" acupuncture in osteoarthritis may be used in the elderly, but placebos have usually been regarded as deception and thus unethical.[83] However, some physicians and ethicists have suggested circumstances for applicable uses for placebos such as it might present a theoretical advantage of an inexpensive treatment without adverse reactions or interactions with drugs or other medications.[83] As the evidence for most types of alternative medicine such as acupuncture is far from strong, the use of alternative medicine in regular healthcare can present an ethical question.[84]
",1
126,"Using the principles of evidence-based medicine to research acupuncture is controversial, and has produced different results.[75] Some research suggests acupuncture can alleviate pain but the majority of research suggests that acupuncture's effects are mainly due to placebo.[8] Evidence suggests that any benefits of acupuncture are short-lasting.[16] There is insufficient evidence to support use of acupuncture compared to mainstream medical treatments.[85] Acupuncture is not better than mainstream treatment in the long term.[78]
",1
127,"The use of acupuncture has been criticized owing to there being little scientific evidence for explicit effects, or the mechanisms for its supposed effectiveness, for any condition that is discernible from placebo.[81] Acupuncture has been called 'theatrical placebo',[15] and David Gorski argues that when acupuncture proponents advocate 'harnessing of placebo effects' or work on developing 'meaningful placebos', they essentially concede it is little more than that.[81]
",1
128,"Publication bias is cited as a concern in the reviews of randomized controlled trials of acupuncture.[15][86][87] A 1998 review of studies on acupuncture found that trials originating in China, Japan, Hong Kong, and Taiwan were uniformly favourable to acupuncture, as were ten out of eleven studies conducted in Russia.[88] A 2011 assessment of the quality of randomized controlled trials on traditional chinese medicine, including acupuncture, concluded that the methodological quality of most such trials (including randomization, experimental control, and blinding) was generally poor, particularly for trials published in Chinese journals (though the quality of acupuncture trials was better than the trials testing traditional chinese medicine remedies).[89] The study also found that trials published in non-Chinese journals tended to be of higher quality.[89] Chinese authors use more Chinese studies, which have been demonstrated to be uniformly positive.[90] A 2012 review of 88 systematic reviews of acupuncture published in Chinese journals found that less than half of these reviews reported testing for publication bias, and that the majority of these reviews were published in journals with impact factors of zero.[91] A 2015 study comparing pre-registered records of acupuncture trials with their published results found that it was uncommon for such trials to be registered before the trial began. This study also found that selective reporting of results and changing outcome measures to obtain statistically significant results was common in this literature.[92]
",1
129,"Scientist and journalist Steven Salzberg identifies acupuncture and Chinese medicine generally as a focus for ""fake medical journals"" such as the Journal of Acupuncture and Meridian Studies and Acupuncture in Medicine.[93]
",1
130,"The conclusions of many trials and numerous systematic reviews of acupuncture are largely inconsistent with each other.[14] A 2011 systematic review of systematic reviews found that for reducing pain, real acupuncture was no better than sham acupuncture, and concluded that numerous reviews have shown little convincing evidence that acupuncture is an effective treatment for reducing pain.[11] The same review found that neck pain was one of only four types of pain for which a positive effect was suggested, but cautioned that the primary studies used carried a considerable risk of bias.[11] A 2009 overview of Cochrane reviews found acupuncture is not effective for a wide range of conditions.[14]
",1
131,"A 2014 systematic review suggests that the nocebo effect of acupuncture is clinically relevant and that the rate of adverse events may be a gauge of the nocebo effect.[94] A 2012 meta-analysis conducted by the Acupuncture Trialists' Collaboration found ""relatively modest"" efficacy of acupuncture (in comparison to sham) for the treatment of four different types of chronic pain (back and neck pain, knee osteoarthritis, chronic headache, and shoulder pain) and on that basis concluded that it ""is more than a placebo"" and a reasonable referral option.[95] Commenting on this meta-analysis, both Edzard Ernst and David Colquhoun said the results were of negligible clinical significance.[96][97] Edzard Ernst later stated that ""I fear that, once we manage to eliminate this bias [that operators are not blind] … we might find that the effects of acupuncture exclusively are a placebo response.""[98] In 2017, the same research group updated their previous meta-analysis and again found acupuncture to be superior to sham acupuncture for non-specific musculoskeletal pain, osteoarthritis, chronic headache, and shoulder pain. They also found that the effects of acupuncture decreased by about 15% after one year.[99]
",1
132,"A 2010 systematic review suggested that acupuncture is more than a placebo for commonly occurring chronic pain conditions, but the authors acknowledged that it is still unknown if the overall benefit is clinically meaningful or cost-effective.[100] A 2010 review found real acupuncture and sham acupuncture produce similar improvements, which can only be accepted as evidence against the efficacy of acupuncture.[101] The same review found limited evidence that real acupuncture and sham acupuncture appear to produce biological differences despite similar effects.[101] A 2009 systematic review and meta-analysis found that acupuncture had a small analgesic effect, which appeared to lack any clinical importance and could not be discerned from bias.[17] The same review found that it remains unclear whether acupuncture reduces pain independent of a psychological impact of the needling ritual.[17] A 2017 systematic review and meta-analysis found that ear acupuncture may be effective at reducing pain within 48 hours of its use, but the mean difference between the acupuncture and control groups was small.[102]
",1
133,"A 2013 systematic review found that acupuncture may be effective for nonspecific lower back pain, but the authors noted there were limitations in the studies examined, such as heterogeneity in study characteristics and low methodological quality in many studies.[103] A 2012 systematic review found some supporting evidence that acupuncture was more effective than no treatment for chronic non-specific low back pain; the evidence was conflicting comparing the effectiveness over other treatment approaches.[13] A 2011 systematic review of systematic reviews found that ""for chronic low back pain, individualized acupuncture is not better in reducing symptoms than formula acupuncture or sham acupuncture with a toothpick that does not penetrate the skin.""[11] A 2010 review found that sham acupuncture was as effective as real acupuncture for chronic low back pain.[2] The specific therapeutic effects of acupuncture were small, whereas its clinically relevant benefits were mostly due to contextual and psychosocial circumstances.[2] Brain imaging studies have shown that traditional acupuncture and sham acupuncture differ in their effect on limbic structures, while at the same time showed equivalent analgesic effects.[2] A 2005 Cochrane review found insufficient evidence to recommend for or against either acupuncture or dry needling for acute low back pain.[104] The same review found low quality evidence for pain relief and improvement compared to no treatment or sham therapy for chronic low back pain only in the short term immediately after treatment.[104] The same review also found that acupuncture is not more effective than conventional therapy and other alternative medicine treatments.[104] A 2017 systematic review and meta-analysis concluded that, for neck pain, acupuncture was comparable in effectiveness to conventional treatment, while electroacupuncture was even more effective in reducing pain than was conventional acupuncture. The same review noted that ""It is difficult to draw conclusion [sic] because the included studies have a high risk of bias and imprecision.""[105] A 2015 overview of systematic reviews of variable quality showed that acupuncture can provide short-term improvements to people with chronic Low Back Pain.[106] The overview said this was true when acupuncture was used either in isolation or in addition to conventional therapy.[106] A 2017 systematic review for an American College of Physicians clinical practice guideline found low to moderate evidence that acupuncture was effective for chronic low back pain, and limited evidence that it was effective for acute low back pain. The same review found that the strength of the evidence for both conditions was low to moderate.[107] Another 2017 clinical practice guideline, this one produced by the Danish Health Authority, recommended against acupuncture for both recent-onset low back pain and lumbar radiculopathy.[108]
",1
134,"Two separate 2016 Cochrane reviews found that acupuncture could be useful in the prevention of tension-type headaches and episodic migraines.[109][110] The 2016 Cochrane review evaluating acupuncture for episodic migraine prevention concluded that true acupuncture had a small effect beyond sham acupuncture and found moderate-quality evidence to suggest that acupuncture is at least similarly effective to prophylactic medications for this purpose.[110] A 2012 review found that acupuncture has demonstrated benefit for the treatment of headaches, but that safety needed to be more fully documented in order to make any strong recommendations in support of its use.[111]
",1
135,"A 2014 review concluded that ""current evidence supports the use of acupuncture as an alternative to traditional analgesics in osteoarthritis patients.""[112] As of 2014[update], a meta-analysis showed that acupuncture may help osteoarthritis pain but it was noted that the effects were insignificant in comparison to sham needles.[113] A 2012 review found ""the potential beneficial action of acupuncture on osteoarthritis pain does not appear to be clinically relevant.""[78] A 2010 Cochrane review found that acupuncture shows statistically significant benefit over sham acupuncture in the treatment of peripheral joint osteoarthritis; however, these benefits were found to be so small that their clinical significance was doubtful, and ""probably due at least partially to placebo effects from incomplete blinding"".[114]
",1
136,"A 2013 Cochrane review found low to moderate evidence that acupuncture improves pain and stiffness in treating people with fibromyalgia compared with no treatment and standard care.[115] A 2012 review found ""there is insufficient evidence to recommend acupuncture for the treatment of fibromyalgia.""[78] A 2010 systematic review found a small pain relief effect that was not apparently discernible from bias; acupuncture is not a recommendable treatment for the management of fibromyalgia on the basis of this review.[116]
",1
137,"A 2012 review found that the effectiveness of acupuncture to treat rheumatoid arthritis is ""sparse and inconclusive.""[78] A 2005 Cochrane review concluded that acupuncture use to treat rheumatoid arthritis ""has no effect on ESR, CRP, pain, patient's global assessment, number of swollen joints, number of tender joints, general health, disease activity and reduction of analgesics.""[117] A 2010 overview of systematic reviews found insufficient evidence to recommend acupuncture in the treatment of most rheumatic conditions, with the exceptions of osteoarthritis, low back pain, and lateral elbow pain.[118] A 2018 systematic review found some evidence that acupuncture could be effective for the treatment of rheumatoid arthritis, but that the evidence was limited because of heterogeneity and methodological flaws in the included studies.[119]
",1
138,"A 2014 systematic review found that although manual acupuncture was effective at relieving short-term pain when used to treat tennis elbow, its long-term effect in relieving pain was ""unremarkable"".[120] A 2007 review found that acupuncture was significantly better than sham acupuncture at treating chronic knee pain; the evidence was not conclusive due to the lack of large, high-quality trials.[121]
",1
139,"A 2014 overview of systematic reviews found insufficient evidence to suggest that acupuncture is an effective treatment for postoperative nausea and vomiting (PONV) in a clinical setting.[122] A 2013 systematic review concluded that acupuncture might be beneficial in prevention and treatment of PONV.[123] A 2015 Cochrane review found moderate-quality evidence of no difference between stimulation of the P6 acupoint on the wrist and antiemetic drugs for preventing PONV.[124] A new finding of the review was that further comparative trials are futile, based on the conclusions of a trial sequential analysis.[125] Whether combining PC6 acupoint stimulation with antiemetics is effective was inconclusive.
",1
140,"A 2014 overview of systematic reviews found insufficient evidence to suggest that acupuncture is effective for surgical or post-operative pain.[122] For the use of acupuncture for post-operative pain, there was contradictory evidence.[122] A 2014 systematic review found supportive but limited evidence for use of acupuncture for acute post-operative pain after back surgery.[126] A 2014 systematic review found that while the evidence suggested acupuncture could be an effective treatment for postoperative gastroparesis, a firm conclusion could not be reached because the trials examined were of low quality.[127]
",1
141,"A 2015 Cochrane review found that there is insufficient evidence to determine whether acupuncture is an effective treatment for cancer pain in adults.[128] A 2014 systematic review published in the Chinese Journal of Integrative Medicine found that acupuncture may be effective as an adjunctive treatment to palliative care for cancer patients.[129] A 2013 overview of reviews published in the Journal of Multinational Association for Supportive Care in Cancer found evidence that acupuncture could be beneficial for people with cancer-related symptoms, but also identified few rigorous trials and high heterogeneity between trials.[130] A 2012 systematic review of randomised clinical trials published in the same journal found that the number and quality of RCTs for using acupuncture in the treatment of cancer pain was too low to draw definite conclusions.[131]
",1
142,"A 2014 systematic review reached inconclusive results with regard to the effectiveness of acupuncture for treating cancer-related fatigue.[132] A 2013 systematic review found that acupuncture is an acceptable adjunctive treatment for chemotherapy-induced nausea and vomiting, but that further research with a low risk of bias is needed.[133] A 2013 systematic review found that the quantity and quality of available RCTs for analysis were too low to draw valid conclusions for the effectiveness of acupuncture for cancer-related fatigue.[134]
",1
143,"Several meta-analytic and systematic reviews suggest that acupuncture alleviates sleep disturbance, particularly insomnia. However, reviewers caution that this evidence should be considered preliminary due to publication bias, problems with research methodology, small sample sizes, and heterogeneity.[135][136][137][138][139][140][141][142][143][144]
",1
144,"For the following conditions, the Cochrane Collaboration or other reviews have concluded there is no strong evidence of benefit:
",1
145,"A 2010 overview of systematic reviews found that moxibustion was effective for several conditions but the primary studies were of poor quality, so there persists ample uncertainty, which limits the conclusiveness of their findings.[236]
",1
146,"Acupuncture is generally safe when administered by an experienced, appropriately trained practitioner using clean-needle technique and sterile single-use needles.[21] When improperly delivered it can cause adverse effects.[20] Accidents and infections are associated with infractions of sterile technique or neglect on the part of the practitioner.[21] To reduce the risk of serious adverse events after acupuncture, acupuncturists should be trained sufficiently.[11] People with serious spinal disease, such as cancer or infection, are not good candidates for acupuncture.[2] Contraindications to acupuncture (conditions that should not be treated with acupuncture) include coagulopathy disorders (e.g. hemophilia and advanced liver disease), warfarin use, severe psychiatric disorders (e.g. psychosis), and skin infections or skin trauma (e.g. burns).[2] Further, electroacupuncture should be avoided at the spot of implanted electrical devices (such as pacemakers).[2]
",1
147,"A 2011 systematic review of systematic reviews (internationally and without language restrictions) found that serious complications following acupuncture continue to be reported.[11] Between 2000 and 2009, ninety-five cases of serious adverse events, including five deaths, were reported.[11] Many such events are not inherent to acupuncture but are due to malpractice of acupuncturists.[11] This might be why such complications have not been reported in surveys of adequately trained acupuncturists.[11] Most such reports originate from Asia, which may reflect the large number of treatments performed there or a relatively higher number of poorly trained Asian acupuncturists.[11] Many serious adverse events were reported from developed countries.[11] These included Australia, Austria, Canada, Croatia, France, Germany, Ireland, the Netherlands, New Zealand, Spain, Sweden, Switzerland, the UK, and the US.[11] The number of adverse effects reported from the UK appears particularly unusual, which may indicate less under-reporting in the UK than other countries.[11] Reports included 38 cases of infections and 42 cases of organ trauma.[11] The most frequent adverse events included pneumothorax, and bacterial and viral infections.[11]
",1
148,"A 2013 review found (without restrictions regarding publication date, study type or language) 295 cases of infections; mycobacterium was the pathogen in at least 96%.[22] Likely sources of infection include towels, hot packs or boiling tank water, and reusing reprocessed needles.[22] Possible sources of infection include contaminated needles, reusing personal needles, a person's skin containing mycobacterium, and reusing needles at various sites in the same person.[22] Although acupuncture is generally considered a safe procedure, a 2013 review stated that the reports of infection transmission increased significantly in the prior decade, including those of mycobacterium.[22] Although it is recommended that practitioners of acupuncture use disposable needles, the reuse of sterilized needles is still permitted.[22] It is also recommended that thorough control practices for preventing infection be implemented and adapted.[22]
",1
149,"A 2013 systematic review of the English-language case reports found that serious adverse events associated with acupuncture are rare, but that acupuncture is not without risk.[20] Between 2000 and 2011 the English-language literature from 25 countries and regions reported 294 adverse events.[20] The majority of the reported adverse events were relatively minor, and the incidences were low.[20] For example, a prospective survey of 34,000 acupuncture treatments found no serious adverse events and 43 minor ones, a rate of 1.3 per 1000 interventions.[20] Another survey found there were 7.1% minor adverse events, of which 5 were serious, amid 97,733 acupuncture patients.[20] The most common adverse effect observed was infection (e.g. mycobacterium), and the majority of infections were bacterial in nature, caused by skin contact at the needling site.[20] Infection has also resulted from skin contact with unsterilized equipment or with dirty towels in an unhygienic clinical setting.[20] Other adverse complications included five reported cases of spinal cord injuries (e.g. migrating broken needles or needling too deeply), four brain injuries, four peripheral nerve injuries, five heart injuries, seven other organ and tissue injuries, bilateral hand edema, epithelioid granuloma, pseudolymphoma, argyria, pustules, pancytopenia, and scarring due to hot-needle technique.[20] Adverse reactions from acupuncture, which are unusual and uncommon in typical acupuncture practice, included syncope, galactorrhoea, bilateral nystagmus, pyoderma gangrenosum, hepatotoxicity, eruptive lichen planus, and spontaneous needle migration.[20]
",1
150,"A 2013 systematic review found 31 cases of vascular injuries caused by acupuncture, three resulting in death.[237] Two died from pericardial tamponade and one was from an aortoduodenal fistula.[237] The same review found vascular injuries were rare, bleeding and pseudoaneurysm were most prevalent.[237] A 2011 systematic review (without restriction in time or language), aiming to summarize all reported case of cardiac tamponade after acupuncture, found 26 cases resulting in 14 deaths, with little doubt about causality in most fatal instances.[238] The same review concluded cardiac tamponade was a serious, usually fatal, though theoretically avoidable complication following acupuncture, and urged training to minimize risk.[238]
",1
151,"A 2012 review found a number of adverse events were reported after acupuncture in the UK's National Health Service (NHS) but most (95%) were not severe,[43] though miscategorization and under-reporting may alter the total figures.[43] From January 2009 to December 2011, 468 safety incidents were recognized within the NHS organizations.[43] The adverse events recorded included retained needles (31%), dizziness (30%), loss of consciousness/unresponsive (19%), falls (4%), bruising or soreness at needle site (2%), pneumothorax (1%) and other adverse side effects (12%).[43] Acupuncture practitioners should know, and be prepared to be responsible for, any substantial harm from treatments.[43] Some acupuncture proponents argue that the long history of acupuncture suggests it is safe.[43] However, there is an increasing literature on adverse events (e.g. spinal-cord injury).[43]
",1
152,"Acupuncture seems to be safe in people getting anticoagulants, assuming needles are used at the correct location and depth.[239] Studies are required to verify these findings.[239] The evidence suggests that acupuncture might be a safe option for people with allergic rhinitis.[146]
",1
153,"A 2010 systematic review of the Chinese-language literature found numerous acupuncture-related adverse events, including pneumothorax, fainting, subarachnoid hemorrhage, and infection as the most frequent, and cardiovascular injuries, subarachnoid hemorrhage, pneumothorax, and recurrent cerebral hemorrhage as the most serious, most of which were due to improper technique.[240] Between 1980 and 2009, the Chinese-language literature reported 479 adverse events.[240] Prospective surveys show that mild, transient acupuncture-associated adverse events ranged from 6.71% to 15%.[240] In a study with 190,924 patients, the prevalence of serious adverse events was roughly 0.024%.[240] Another study showed a rate of adverse events requiring specific treatment of 2.2%, 4,963 incidences among 229,230 patients.[240] Infections, mainly hepatitis, after acupuncture are reported often in English-language research, though are rarely reported in Chinese-language research, making it plausible that acupuncture-associated infections have been underreported in China.[240] Infections were mostly caused by poor sterilization of acupuncture needles.[240] Other adverse events included spinal epidural hematoma (in the cervical, thoracic and lumbar spine), chylothorax, injuries of abdominal organs and tissues, injuries in the neck region, injuries to the eyes, including orbital hemorrhage, traumatic cataract, injury of the oculomotor nerve and retinal puncture, hemorrhage to the cheeks and the hypoglottis, peripheral motor-nerve injuries and subsequent motor dysfunction, local allergic reactions to metal needles, stroke, and cerebral hemorrhage after acupuncture.[240]
",1
154,"A causal link between acupuncture and the adverse events cardiac arrest, pyknolepsy, shock, fever, cough, thirst, aphonia, leg numbness, and sexual dysfunction remains uncertain.[240] The same review concluded that acupuncture can be considered inherently safe when practiced by properly trained practitioners, but the review also stated there is a need to find effective strategies to minimize the health risks.[240] Between 1999 and 2010, the Korean-language literature contained reports of 1104 adverse events.[241] Between the 1980s and 2002, the Japanese-language literature contained reports of 150 adverse events.[242]
",1
155,"Although acupuncture has been practiced for thousands of years in China, its use in pediatrics in the United States did not become common until the early 2000s. In 2007, the National Health Interview Survey (NHIS) conducted by the National Center For Health Statistics (NCHS) estimated that approximately 150,000 children had received acupuncture treatment for a variety of conditions.[243]
",1
156,"In 2008 a study determined that the use of acupuncture-needle treatment on children was ""questionable"" due to the possibility of adverse side-effects and the pain manifestation differences in children versus adults. The study also includes warnings against practicing acupuncture on infants, as well as on children who are over-fatigued, very weak, or have over-eaten.[244]
",1
157,"When used on children, acupuncture is considered safe when administered by well-trained, licensed practitioners using sterile needles; however, a 2011 review found there was limited research to draw definite conclusions about the overall safety of pediatric acupuncture.[3] The same review found 279 adverse events, 25 of them serious.[3] The adverse events were mostly mild in nature (e.g. bruising or bleeding).[3] The prevalence of mild adverse events ranged from 10.1% to 13.5%, an estimated 168 incidences among 1,422 patients.[3] On rare occasions adverse events were serious (e.g. cardiac rupture or hemoptysis); many might have been a result of substandard practice.[3] The incidence of serious adverse events was 5 per one million, which included children and adults.[3]
",1
158,"When used during pregnancy, the majority of adverse events caused by acupuncture were mild and transient, with few serious adverse events.[245] The most frequent mild adverse event was needling or unspecified pain, followed by bleeding.[245] Although two deaths (one stillbirth and one neonatal death) were reported, there was a lack of acupuncture-associated maternal mortality.[245] Limiting the evidence as certain, probable or possible in the causality evaluation, the estimated incidence of adverse events following acupuncture in pregnant women was 131 per 10,000.[245]
Although acupuncture is not contraindicated in pregnant women, some specific acupuncture points are particularly sensitive to needle insertion; these spots, as well as the abdominal region, should be avoided during pregnancy.[2]
",1
159,"Four adverse events associated with moxibustion were bruising, burns and cellulitis, spinal epidural abscess, and large superficial basal cell carcinoma.[20] Ten adverse events were associated with cupping.[20] The minor ones were keloid scarring, burns, and bullae;[20] the serious ones were acquired hemophilia A, stroke following cupping on the back and neck, factitious panniculitis, reversible cardiac hypertrophy, and iron deficiency anemia.[20]
",1
160,"A 2013 meta-analysis found that acupuncture for chronic low back pain was cost-effective as a complement to standard care, but not as a substitute for standard care except in cases where comorbid depression presented.[18] The same meta-analysis found there was no difference between sham and non-sham acupuncture.[18] A 2011 systematic review found insufficient evidence for the cost-effectiveness of acupuncture in the treatment of chronic low back pain.[19] A 2010 systematic review found that the cost-effectiveness of acupuncture could not be concluded.[100] A 2012 review found that acupuncture seems to be cost-effective for some pain conditions.[246]
",1
161,"As with other alternative medicines, unethical or naïve practitioners may induce patients to exhaust financial resources by pursuing ineffective treatment.[6][247] Professional ethics codes set by accrediting organizations such as the National Certification Commission for Acupuncture and Oriental Medicine require practitioners to make ""timely referrals to other health care professionals as may be appropriate.""[248] Stephen Barrett states that there is a ""risk that an acupuncturist whose approach to diagnosis is not based on scientific concepts will fail to diagnose a dangerous condition"".[249]
",1
162,"Acupuncture is a substantial part of traditional Chinese medicine (TCM). Early acupuncture beliefs relied on concepts that are common in TCM, such as a life force energy called qi.[250] Qi was believed to flow from the body's primary organs (zang-fu organs) to the ""superficial"" body tissues of the skin, muscles, tendons, bones, and joints, through channels called meridians.[251] Acupuncture points where needles are inserted are mainly (but not always) found at locations along the meridians.[252] Acupuncture points not found along a meridian are called extraordinary points and those with no designated site are called ""A-shi"" points.[252]
",1
163,"In TCM, disease is generally perceived as a disharmony or imbalance in energies such as yin, yang, qi, xuĕ, zàng-fǔ, meridians, and of the interaction between the body and the environment.[253] Therapy is based on which ""pattern of disharmony"" can be identified.[254][255] For example, some diseases are believed to be caused by meridians being invaded with an excess of wind, cold, and damp.[256] In order to determine which pattern is at hand, practitioners examine things like the color and shape of the tongue, the relative strength of pulse-points, the smell of the breath, the quality of breathing, or the sound of the voice.[257][258] TCM and its concept of disease does not strongly differentiate between the cause and effect of symptoms.[259]
",1
164,"Scientific research has not supported the existence of qi, meridians, or yin and yang.[c][26][27] A Nature editorial described TCM as ""fraught with pseudoscience"", with the majority of its treatments having no logical mechanism of action.[260] Quackwatch states that ""TCM theory and practice are not based upon the body of knowledge related to health, disease, and health care that has been widely accepted by the scientific community. TCM practitioners disagree among themselves about how to diagnose patients and which treatments should go with which diagnoses. Even if they could agree, the TCM theories are so nebulous that no amount of scientific study will enable TCM to offer rational care.""[6]
",1
165,"Some modern practitioners support the use of acupuncture to treat pain, but have abandoned the use of qi, meridians, yin, yang and other mystical energies as an explanatory frameworks.[7][27][28] The use of qi as an explanatory framework has been decreasing in China, even as it becomes more prominent during discussions of acupuncture in the US.[261] Academic discussions of acupuncture still make reference to pseudoscientific concepts such as qi and meridians despite the lack of scientific evidence.[261] Many within the scientific community consider attempts to rationalize acupuncture in science to be quackery and pseudoscience.[262][263] Academics Massimo Pigliucci and Maarten Boudry describe it as a ""borderlands science"" lying between science and pseudoscience.[264]
",1
166,"Many acupuncturists attribute pain relief to the release of endorphins when needles penetrate, but no longer support the idea that acupuncture can affect a disease.[28][261] It is a generally held belief within the acupuncture community that acupuncture points and meridians structures are special conduits for electrical signals, but no research has established any consistent anatomical structure or function for either acupuncture points or meridians.[c][26] Human tests to determine whether electrical continuity was significantly different near meridians than other places in the body have been inconclusive.[26]
",1
167,"Some studies suggest acupuncture causes a series of events within the central nervous system,[265] and that it is possible to inhibit acupuncture's analgesic effects with the opioid antagonist naloxone.[266] Mechanical deformation of the skin by acupuncture needles appears to result in the release of adenosine.[2] The anti-nociceptive effect of acupuncture may be mediated by the adenosine A1 receptor.[267] A 2014 review in Nature Reviews Cancer found that since the key mouse studies that suggested acupuncture relieves pain via the local release of adenosine, which then triggered nearby A1 receptors ""caused more tissue damage and inflammation relative to the size of the animal in mice than in humans, such studies unnecessarily muddled a finding that local inflammation can result in the local release of adenosine with analgesic effect.""[81]
",1
168,"It has been proposed that acupuncture's effects in gastrointestinal disorders may relate to its effects on the parasympathetic and sympathetic nervous system, which have been said to be the ""Western medicine"" equivalent of ""yin and yang"".[268] Another mechanism whereby acupuncture may be effective for gastrointestinal dysfunction involves the promotion of gastric peristalsis in subjects with low initial gastric motility, and suppressing peristalsis in subjects with active initial motility.[269] Acupuncture has also been found to exert anti-inflammatory effects, which may be mediated by the activation of the vagus nerve and deactivation of inflammatory macrophages.[270] Neuroimaging studies suggest that acupuncture stimulation results in deactivation of the limbic brain areas and the default mode network.[271]
",1
169,"Acupuncture, along with moxibustion, is one of the oldest practices of traditional Chinese medicine.[31] Most historians believe the practice began in China, though there are some conflicting narratives on when it originated.[29][32] Academics David Ramey and Paul Buell said the exact date acupuncture was founded depends on the extent to which dating of ancient texts can be trusted and the interpretation of what constitutes acupuncture.[272]
",1
170,"According to an article in Rheumatology, the first documentation of an ""organized system of diagnosis and treatment"" for acupuncture was in The Yellow Emperor's Classic of Internal Medicine (Huangdi Neijing) from about 100 BC.[29] Gold and silver needles found in the tomb of Liu Sheng from around 100 BC are believed to be the earliest archaeological evidence of acupuncture, though it is unclear if that was their purpose.[272] According to Plinio Prioreschi, the earliest known historical record of acupuncture is the Shiji (""Records of the Grand Historian""), written by a historian around 100 BC.[30] It is believed that this text was documenting what was established practice at that time.[29]
",1
171,"The 5,000-year-old mummified body of Ötzi the Iceman was found with 15 groups of tattoos,[273] many of which were located at points on the body where acupuncture needles are used for abdominal or lower back problems. Evidence from the body suggests Otzi suffered from these conditions.[32] This has been cited as evidence that practices similar to acupuncture may have been practised elsewhere in Eurasia during the early Bronze Age;[273] however, The Oxford Handbook of the History of Medicine calls this theory ""speculative"".[33] It is considered unlikely that acupuncture was practised before 2000 BC.[272] The Ötzi the Iceman's tattoo marks suggest to some experts that an acupuncture-like treatment was previously used in Europe 5 millennia ago.[8]
",1
172,"Acupuncture may have been practised during the Neolithic era, near the end of the Stone Age, using sharpened stones called Bian shi.[31]:70 Many Chinese texts from later eras refer to sharp stones called ""plen"", which means ""stone probe"", that may have been used for acupuncture purposes.[31]:70 The ancient Chinese medical text, Huangdi Neijing, indicates that sharp stones were believed at-the-time to cure illnesses at or near the body's surface, perhaps because of the short depth a stone could penetrate.[31]:71 However, it is more likely that stones were used for other medical purposes, such as puncturing a growth to drain its pus.[29][32] The Mawangdui texts, which are believed to be from the 2nd century BC, mention the use of pointed stones to open abscesses, and moxibustion, but not for acupuncture.[30] It is also speculated that these stones may have been used for bloodletting, due to the ancient Chinese belief that illnesses were caused by demons within the body that could be killed or released.[274] It is likely bloodletting was an antecedent to acupuncture.[32]
",1
173,"According to historians Lu Gwei-djen and Joseph Needham, there is substantial evidence that acupuncture may have begun around 600 BC.[31] Some hieroglyphs and pictographs from that era suggests acupuncture and moxibustion were practised.[275] However, historians Lu and Needham said it was unlikely a needle could be made out of the materials available in China during this time period.[31]:71–72 It is possible that bronze was used for early acupuncture needles. Tin, copper, gold and silver are also possibilities, though they are considered less likely, or to have been used in fewer cases.[31]:69 If acupuncture was practised during the Shang dynasty (1766 to 1122 BC), organic materials like thorns, sharpened bones, or bamboo may have been used.[31]:70 Once methods for producing steel were discovered, it would replace all other materials, since it could be used to create a very fine, but sturdy needles.[31]:74 Lu and Needham noted that all the ancient materials that could have been used for acupuncture and which often produce archaeological evidence, such as sharpened bones, bamboo or stones, were also used for other purposes.[31] An article in Rheumatology said that the absence of any mention of acupuncture in documents found in the tomb of Mawangdui from 198 BC suggest that acupuncture was not practised by that time.[29]
",1
174,"Several different and sometimes conflicting belief systems emerged regarding acupuncture. This may have been the result of competing schools of thought.[29] Some ancient texts referred to using acupuncture to cause bleeding, while others mixed the ideas of blood-letting and spiritual ch'i energy. Over time, the focus shifted from blood to the concept of puncturing specific points on the body, and eventually to balancing Yin and Yang energies as well.[30] According to David Ramey, no single ""method or theory"" was ever predominantly adopted as the standard.[276] At the time, scientific knowledge of medicine was not yet developed, especially because in China dissection of the deceased was forbidden, preventing the development of basic anatomical knowledge.[29]
",1
175,"It is not certain when specific acupuncture points were introduced, but the autobiography of Bian Que from around 400–500 BC references inserting needles at designated areas.[31] Bian Que believed there was a single acupuncture point at the top of one's skull that he called the point ""of the hundred meetings.""[31]:83 Texts dated to be from 156–186 BC document early beliefs in channels of life force energy called meridians that would later be an element in early acupuncture beliefs.[272]
",1
176,"Ramey and Buell said the ""practice and theoretical underpinnings"" of modern acupuncture were introduced in The Yellow Emperor's Classic (Huangdi Neijing) around 100 BC.[30][272] It introduced the concept of using acupuncture to manipulate the flow of life energy (qi) in a network of meridian (channels) in the body.[272][277] The network concept was made up of acu-tracts, such as a line down the arms, where it said acupoints were located. Some of the sites acupuncturists use needles at today still have the same names as those given to them by the Yellow Emperor's Classic.[31]:93 Numerous additional documents were published over the centuries introducing new acupoints.[31]:101 By the 4th century AD, most of the acupuncture sites in use today had been named and identified.[31]:101
",1
177,"In the first half of the 1st century AD, acupuncturists began promoting the belief that acupuncture's effectiveness was influenced by the time of day or night, the lunar cycle, and the season.[31]:140–41 The Science of the Yin-Yang Cycles (Yün Chhi Hsüeh) was a set of beliefs that curing diseases relied on the alignment of both heavenly (tian) and earthly (di) forces that were attuned to cycles like that of the sun and moon.[31]:140–41 There were several different belief systems that relied on a number of celestial and earthly bodies or elements that rotated and only became aligned at certain times.[31]:140–41 According to Needham and Lu, these ""arbitrary predictions"" were depicted by acupuncturists in complex charts and through a set of special terminology.[31]
",1
178,"Acupuncture needles during this period were much thicker than most modern ones and often resulted in infection. Infection is caused by a lack of sterilization, but at that time it was believed to be caused by use of the wrong needle, or needling in the wrong place, or at the wrong time.[31]:102–03 Later, many needles were heated in boiling water, or in a flame. Sometimes needles were used while they were still hot, creating a cauterizing effect at the injection site.[31]:104 Nine needles were recommended in the Chen Chiu Ta Chheng from 1601, which may have been because of an ancient Chinese belief that nine was a magic number.[31]:102–03
",1
179,"Other belief systems were based on the idea that the human body operated on a rhythm and acupuncture had to be applied at the right point in the rhythm to be effective.[31]:140–41 In some cases a lack of balance between Yin and Yang were believed to be the cause of disease.[31]:140–41
",1
180,"In the 1st century AD, many of the first books about acupuncture were published and recognized acupuncturist experts began to emerge. The Zhen Jiu Jia Yi Jing, which was published in the mid-3rd century, became the oldest acupuncture book that is still in existence in the modern era.[31] Other books like the Yu Kuei Chen Ching, written by the Director of Medical Services for China, were also influential during this period, but were not preserved.[31] In the mid 7th century, Sun Simiao published acupuncture-related diagrams and charts that established standardized methods for finding acupuncture sites on people of different sizes and categorized acupuncture sites in a set of modules.[31]
",1
181,"Acupuncture became more established in China as improvements in paper led to the publication of more acupuncture books. The Imperial Medical Service and the Imperial Medical College, which both supported acupuncture, became more established and created medical colleges in every province.[31]:129 The public was also exposed to stories about royal figures being cured of their diseases by prominent acupuncturists.[31]:129–35 By time The Great Compendium of Acupuncture and Moxibustion was published during the Ming dynasty (1368–1644 AD), most of the acupuncture practices used in the modern era had been established.[29]
",1
182,"By the end of the Song dynasty (1279 AD), acupuncture had lost much of its status in China.[278] It became rarer in the following centuries, and was associated with less prestigious professions like alchemy, shamanism, midwifery and moxibustion.[279] Additionally, by the 18th century, scientific rationality was becoming more popular than traditional superstitious beliefs.[29] By 1757 a book documenting the history of Chinese medicine called acupuncture a ""lost art"".[31]:160 Its decline was attributed in part to the popularity of prescriptions and medications, as well as its association with the lower classes.[280]
",1
183,"In 1822, the Chinese Emperor signed a decree excluding the practice of acupuncture from the Imperial Medical Institute.[29] He said it was unfit for practice by gentlemen-scholars.[281] In China acupuncture was increasingly associated with lower-class, illiterate practitioners.[282] It was restored for a time, but banned again in 1929 in favor of science-based Western medicine. Although acupuncture declined in China during this time period, it was also growing in popularity in other countries.[32]
",1
184,"Korea is believed to be the first country in Asia that acupuncture spread to outside of China.[31] Within Korea there is a legend that acupuncture was developed by emperor Dangun, though it is more likely to have been brought into Korea from a Chinese colonial prefecture in 514 AD.[31]:262–63 Acupuncture use was commonplace in Korea by the 6th century. It spread to Vietnam in the 8th and 9th centuries.[32] As Vietnam began trading with Japan and China around the 9th century, it was influenced by their acupuncture practices as well.[29] China and Korea sent ""medical missionaries"" that spread traditional Chinese medicine to Japan, starting around 219 AD. In 553, several Korean and Chinese citizens were appointed to re-organize medical education in Japan and they incorporated acupuncture as part of that system.[31]:264 Japan later sent students back to China and established acupuncture as one of five divisions of the Chinese State Medical Administration System.[31]:264–65
",1
185,"Acupuncture began to spread to Europe in the second half of the 17th century. Around this time the surgeon-general of the Dutch East India Company met Japanese and Chinese acupuncture practitioners and later encouraged Europeans to further investigate it.[31]:264–65 He published the first in-depth description of acupuncture for the European audience and created the term ""acupuncture"" in his 1683 work De Acupunctura.[274] France was an early adopter among the West due to the influence of Jesuit missionaries, who brought the practice to French clinics in the 16th century.[29] The French doctor Louis Berlioz (the father of the composer Hector Berlioz) is usually credited with being the first to experiment with the procedure in Europe in 1810, before publishing his findings in 1816.[281]
",1
186,"By the 19th century, acupuncture had become commonplace in many areas of the world.[31]:295 Americans and Britons began showing interest in acupuncture in the early 19th century, although interest waned by mid-century.[29] Western practitioners abandoned acupuncture's traditional beliefs in spiritual energy, pulse diagnosis, and the cycles of the moon, sun or the body's rhythm. Diagrams of the flow of spiritual energy, for example, conflicted with the West's own anatomical diagrams. It adopted a new set of ideas for acupuncture based on tapping needles into nerves.[29][32][33] In Europe it was speculated that acupuncture may allow or prevent the flow of electricity in the body, as electrical pulses were found to make a frog's leg twitch after death.[274]
",1
187,"The West eventually created a belief system based on Travell trigger points that were believed to inhibit pain. They were in the same locations as China's spiritually identified acupuncture points, but under a different nomenclature.[29] The first elaborate Western treatise on acupuncture was published in 1683 by Willem ten Rhijne.[283]
",1
188,"In China, the popularity of acupuncture rebounded in 1949 when Mao Zedong took power and sought to unite China behind traditional cultural values. It was also during this time that many Eastern medical practices were consolidated under the name traditional Chinese medicine (TCM).[32]
",1
189,"New practices were adopted in the 20th century, such as using a cluster of needles,[31]:164 electrified needles, or leaving needles inserted for up to a week.[31]:164 A lot of emphasis developed on using acupuncture on the ear.[31]:164 Acupuncture research organizations such as the International Society of Acupuncture were founded in the 1940s and 1950s and acupuncture services became available in modern hospitals.[29][284] China, where acupuncture was believed to have originated, was increasingly influenced by Western medicine.[29] Meanwhile, acupuncture grew in popularity in the US. The US Congress created the Office of Alternative Medicine in 1992 and the National Institutes of Health (NIH) declared support for acupuncture for some conditions in November 1997. In 1999, the National Center for Complementary and Alternative Medicine was created within the NIH. Acupuncture became the most popular alternative medicine in the US.[265]
",1
190,"Politicians from the Chinese Communist Party said acupuncture was superstitious and conflicted with the party's commitment to science.[285] Communist Party Chairman Mao Zedong later reversed this position,[285] arguing that the practice was based on scientific principles.[286]
",1
191,"In 1971, a New York Times reporter published an article on his acupuncture experiences in China, which led to more investigation of and support for acupuncture.[29] The US President Richard Nixon visited China in 1972.[287] During one part of the visit, the delegation was shown a patient undergoing major surgery while fully awake, ostensibly receiving acupuncture rather than anesthesia.[287] Later it was found that the patients selected for the surgery had both a high pain tolerance and received heavy indoctrination before the operation; these demonstration cases were also frequently receiving morphine surreptitiously through an intravenous drip that observers were told contained only fluids and nutrients.[287] One patient receiving open heart surgery while awake was ultimately found to have received a combination of three powerful sedatives as well as large injections of a local anesthetic into the wound.[15] After the National Institute of Health expressed support for acupuncture for a limited number of conditions, adoption in the US grew further.[29] In 1972 the first legal acupuncture center in the US was established in Washington DC[288] and in 1973 the American Internal Revenue Service allowed acupuncture to be deducted as a medical expense.[289]
",1
192,"In 2006, a BBC documentary Alternative Medicine filmed a patient undergoing open heart surgery allegedly under acupuncture-induced anesthesia. It was later revealed that the patient had been given a cocktail of anesthetics.[290][291]
",1
193,"In 2010, UNESCO inscribed ""acupuncture and moxibustion of traditional Chinese medicine"" on the UNESCO Intangible Cultural Heritage List following China's nomination.[292]
",1
194,"Acupuncture is most heavily practiced in China[240] and is popular in[240] the US,[20] Australia,[293] and Europe.[294] In Switzerland, acupuncture has become the most frequently used alternative medicine since 2004.[295] In the United Kingdom, a total of 4 million acupuncture treatments were administered in 2009.[296] Acupuncture is used in most pain clinics and hospices in the UK.[42] An estimated 1 in 10 adults in Australia used acupuncture in 2004.[293] In Japan, it is estimated that 25 percent of the population will try acupuncture at some point,[297] though in most cases it is not covered by public health insurance.[297] Users of acupuncture in Japan are more likely to be elderly and to have a limited education.[297] Approximately half of users surveyed indicated a likelihood to seek such remedies in the future, while 37% did not.[297] Less than one percent of the US population reported having used acupuncture in the early 1990s.[298] By the early 2010s, more than 14 million Americans reported having used acupuncture as part of their health care.[298]
",1
195,"In the US, acupuncture is increasingly (as of 2014[update]) used at academic medical centers,[81] and is usually offered through CAM centers or anesthesia and pain management services. Examples include those at Harvard University, Stanford University, Johns Hopkins University, and UCLA.[299]
",1
196,"The use of acupuncture in Germany increased by 20% in 2007, after the German acupuncture trials supported its efficacy for certain uses.[300] In 2011, there were more than one million users,[300] and insurance companies have estimated that two-thirds of German users are women.[300] As a result of the trials, German public health insurers began to cover acupuncture for chronic low back pain and osteoarthritis of the knee, but not tension headache or migraine.[301] This decision was based in part on socio-political reasons.[301] Some insurers in Germany chose to stop reimbursement of acupuncture because of the trials.[302] For other conditions, insurers in Germany were not convinced that acupuncture had adequate benefits over usual care or sham treatments.[303] Highlighting the results of the placebo group, researchers refused to accept a placebo therapy as efficient.[304]
",1
197,"There are various government and trade association regulatory bodies for acupuncture in the United Kingdom, the United States, Saudi Arabia, Australia, New Zealand, Japan, Canada, and in European countries and elsewhere. The World Health Organization recommends that before being licensed or certified, an acupuncturist receive 200 hours of specialized training if they are a physician and 2,500 hours for non-physicians; many governments have adopted similar standards.
",1
198,"In China, the practice of acupuncture is regulated by the Chinese Medicine Council that was formed in 1999 by the Legislative Council. It includes a licensing exam and registration, as well as degree courses approved by the board.[305] Canada has acupuncture licensing programs in the provinces of British Columbia, Ontario, Alberta and Quebec; standards set by the Chinese Medicine and Acupuncture Association of Canada are used in provinces without government regulation.[294] Regulation in the US began in the 1970s in California, which was eventually followed by every state but Wyoming and Idaho. Licensing requirements vary greatly from state to state. The needles used in acupuncture are regulated in the US by the Food and Drug Administration.[306] In some states acupuncture is regulated by a board of medical examiners, while in others by the board of licensing, health or education.
",1
199,"In Japan, acupuncturists are licensed by the Minister of Health, Labour and Welfare after passing an examination and graduating from a technical school or university.[307] In Australia, the Chinese Medicine Board of Australia regulates acupuncture, among other Chinese medical traditions, and restricts the use of titles like 'acupuncturist' to registered practitioners only.[308]  The practice of Acupuncture in New Zealand  in 1990 acupuncture was included into the Governmental Accident Compensation Corporation (ACC) Act. This inclusion granted qualified and professionally registered acupuncturists to provide subsidised care and treatment to citizens, residents, and temporary visitors for work or sports related injuries that occurred within the country of New Zealand.The two bodies for the regulation of acupuncture and attainment of ACC treatment provider status in New Zealand are Acupuncture NZ,[309] and The New Zealand Acupuncture Standards Authority.[310][311] At least 28 countries in Europe have professional associations for acupuncturists.[307] In France, the Académie Nationale de Médecine (National Academy of Medicine) has regulated acupuncture since 1955.[312]
",1
200,"
",1
201,"A medication (also referred to as medicine, pharmaceutical drug, medicinal drug or simply drug) is a drug used to diagnose, cure, treat, or prevent disease.[1][2][3] Drug therapy (pharmacotherapy) is an important part of the medical field and relies on the science of pharmacology for continual advancement and on pharmacy for appropriate management.
",1
202,"Drugs are classified in multiple ways. One of the key divisions is by level of control, which distinguishes prescription drugs (those that a pharmacist dispenses only on the order of a physician, physician assistant, or qualified nurse) from over-the-counter drugs (those that consumers can order for themselves). Another key distinction is between traditional small-molecule drugs, usually derived from chemical synthesis, and biopharmaceuticals, which include recombinant proteins, vaccines, blood products used therapeutically (such as IVIG), gene therapy, monoclonal antibodies and cell therapy (for instance, stem-cell therapies). Other ways to classify medicines are by mode of action, route of administration, biological system affected, or therapeutic effects. An elaborate and widely used classification system is the Anatomical Therapeutic Chemical Classification System (ATC system). The World Health Organization keeps a list of essential medicines.
",1
203,"Drug discovery and drug development are complex and expensive endeavors undertaken by pharmaceutical companies, academic scientists, and governments. As a result of this complex path from discovery to commercialization, partnering has become a standard practice for advancing drug candidates through development pipelines.  Governments generally regulate what drugs can be marketed, how drugs are marketed, and in some jurisdictions, drug pricing. Controversies have arisen over drug pricing and disposal of used drugs.
",1
204,"In Europe, the term is ""medicinal product"", and it is defined by EU law as:
",1
205,"In the US, a ""drug"" is:
",1
206,"Drug use among elderly Americans has been studied; in a group of 2377 people with average age of 71 surveyed between 2005 and 2006, 84% took at least one prescription drug, 44% took at least one over-the-counter (OTC) drug, and 52% took at least one dietary supplement; in a group of 2245 elderly Americans (average age of 71) surveyed over the period 2010 – 2011, those percentages were 88%, 38%, and 64%.[6]
",1
207,"One of the key classifications is between traditional small molecule drugs; usually derived from chemical synthesis, and biologic medical products; which include recombinant proteins, vaccines, blood products used therapeutically (such as IVIG), gene therapy, and cell therapy (for instance, stem cell therapies).
",1
208,"Pharmaceuticals or drugs or medicines are classified in various other groups besides their origin on the basis of pharmacological properties like mode of action and their pharmacological action or activity,[7] such as by chemical properties, mode or route of administration, biological system affected, or therapeutic effects. An elaborate and widely used classification system is the Anatomical Therapeutic Chemical Classification System (ATC system). The World Health Organization keeps a list of essential medicines.
",1
209,"A sampling of classes of medicine includes:
",1
210,"Pharmaceuticals may also be described as ""specialty"", independent of other classifications, which is an ill-defined class of drugs that might be difficult to administer, require special handling during administration, require patient monitoring during and immediately after administration, have particular regulatory requirements restricting their use, and are generally expensive relative to other drugs.[8]
",1
211,"Drugs affecting the central nervous system include: psychedelics, hypnotics, anaesthetics, antipsychotics, eugeroics, antidepressants (including tricyclic antidepressants, monoamine oxidase inhibitors, lithium salts, and selective serotonin reuptake inhibitors (SSRIs)), antiemetics, Anticonvulsants/antiepileptics, anxiolytics, barbiturates, movement disorder (e.g., Parkinson's disease) drugs, stimulants (including amphetamines), benzodiazepines, cyclopyrrolones, dopamine antagonists, antihistamines, cholinergics, anticholinergics, emetics, cannabinoids, and 5-HT (serotonin) antagonists.
",1
212,"The main classes of painkillers are NSAIDs, opioids and local anesthetics.
",1
213,"For consciousness (anesthetic drugs)
",1
214,"Some anesthetics include benzodiazepines and barbiturates.
",1
215,"The main categories of drugs for musculoskeletal disorders are: NSAIDs (including COX-2 selective inhibitors), muscle relaxants, neuromuscular drugs, and anticholinesterases.
",1
216,"Antibiotics, sympathomimetics, antihistamines, anticholinergics, NSAIDs, corticosteroids, antiseptics, local anesthetics, antifungals, cerumenolytic.
",1
217,"Bronchodilators, antitussives, mucolytics, decongestants, inhaled and systemic corticosteroids, beta2-adrenergic agonists, anticholinergics, mast cell stabilizers, leukotriene antagonists.
",1
218,"Androgens, antiandrogens, estrogens, gonadotropin, corticosteroids, human growth hormone, insulin, antidiabetics (sulfonylureas, biguanides/metformin, thiazolidinediones, insulin), thyroid hormones, antithyroid drugs, calcitonin, diphosphonate, vasopressin analogues.
",1
219,"Antifungal, alkalinizing agents, quinolones, antibiotics, cholinergics, anticholinergics, antispasmodics, 5-alpha reductase inhibitor, selective alpha-1 blockers, sildenafils, fertility medications.
",1
220,"NSAIDs, anticholinergics, haemostatic drugs, antifibrinolytics, Hormone Replacement Therapy (HRT), bone regulators, beta-receptor agonists, follicle stimulating hormone, luteinising hormone, LHRH, gamolenic acid, gonadotropin release inhibitor, progestogen, dopamine agonists, oestrogen, prostaglandins, gonadorelin, clomiphene, tamoxifen, diethylstilbestrol.
",1
221,"Emollients, anti-pruritics, antifungals, antiseptics, scabicides, pediculicides, tar products, vitamin A derivatives, vitamin D analogues, keratolytics, abrasives, systemic antibiotics, topical antibiotics, hormones, desloughing agents, exudate absorbents, fibrinolytics, proteolytics, sunscreens, antiperspirants, corticosteroids, immune modulators.
",1
222,"Antibiotics, antifungals, antileprotics, antituberculous drugs, antimalarials, anthelmintics, amoebicides, antivirals, antiprotozoals, probiotics, prebiotics, antitoxins and antivenoms.
",1
223,"Vaccines, immunoglobulins, immunosuppressants, interferons, monoclonal antibodies.
",1
224,"Anti-allergics, antihistamines, NSAIDs, corticosteroids.
",1
225,"Tonics, electrolytes and mineral preparations (including iron preparations and magnesium preparations), parenteral nutritions, vitamins, anti-obesity drugs, anabolic drugs, haematopoietic drugs, food product drugs.
",1
226,"Cytotoxic drugs, therapeutic antibodies, sex hormones, aromatase inhibitors, somatostatin inhibitors, recombinant interleukins, G-CSF, erythropoietin.
",1
227,"Contrast media.
",1
228,"A euthanaticum is used for euthanasia and physician-assisted suicide. Euthanasia is not permitted by law in many countries, and consequently, medicines will not be licensed for this use in those countries.
",1
229,"Administration is the process by which a patient takes a medicine. There are three major categories of drug administration; enteral (via the human gastrointestinal tract), injection, and other (dermal, nasal, ophthalmic, otologic, and urogenital).[9]
",1
230,"Oral administration, the most common form of enteral administration, can be performed in various dosage forms including pills, tablets, or capsules, and other routes likewise have various forms.
",1
231,"The drug may contain a single or multiple active ingredients.
",1
232,"They can be administered all at once as a bolus, at frequent intervals or continuously. Frequencies are often abbreviated from Latin, such as every 8 hours reading Q8H from Quaque VIII Hora.
",1
233,"In the fields of medicine, biotechnology and pharmacology, drug discovery is the process by which new drugs are discovered.
",1
234,"Historically, drugs were discovered through identifying the active ingredient from traditional remedies or by serendipitous discovery.  Later chemical libraries of synthetic small molecules, natural products or extracts were screened in intact cells or whole organisms to identify substances that have a desirable therapeutic effect in a process known as
classical pharmacology.  Since sequencing of the human genome which allowed rapid cloning and synthesis of large quantities of purified proteins, it has become common practice to use high throughput screening of large compounds libraries against isolated biological targets which are hypothesized to be disease-modifying in a process known as reverse pharmacology.  Hits from these screens are then tested in cells and then in animals for efficacy.  Even more recently, scientists have been able to understand the shape of biological molecules at the atomic level, and to use that knowledge to design (see drug design) drug candidates.
",1
235,"Modern drug discovery involves the identification of screening hits, medicinal chemistry and optimization of those hits to increase the affinity, selectivity (to reduce the potential of side effects), efficacy/potency, metabolic stability (to increase the half-life), and oral bioavailability. Once a compound that fulfills all of these requirements has been identified, it will begin the process of drug development prior to clinical trials. One or more of these steps may, but not necessarily, involve computer-aided drug design.
",1
236,"Despite advances in technology and understanding of biological systems, drug discovery is still a lengthy, ""expensive, difficult, and inefficient process"" with low rate of new therapeutic discovery.[10] In 2010, the research and development cost of each new molecular entity (NME) was approximately US$1.8 billion.[11] Drug discovery is done by pharmaceutical companies, sometimes with research assistance from universities. The ""final product"" of drug discovery is a patent on the potential drug. The drug requires very expensive Phase I, II and III clinical trials, and most of them fail. Small companies have a critical role, often then selling the rights to larger companies that have the resources to run the clinical trials.
",1
237,"Drug development is the process of bringing a new drug to the market once a lead compound has been identified through the process of drug discovery. It includes pre-clinical research (microorganisms/animals) and clinical trials (on humans) and may include the step of obtaining regulatory approval to market the drug.[12][13]
",1
238,"The regulation of drugs varies by jurisdiction. In some countries, such as the United States, they are regulated at the national level by a single agency. In other jurisdictions, they are regulated at the state level, or at both state and national levels by various bodies, as is the case in Australia.  The role of therapeutic goods regulation is designed mainly to protect the health and safety of the population. Regulation is aimed at ensuring the safety, quality, and efficacy of the therapeutic goods which are covered under the scope of the regulation. In most jurisdictions, therapeutic goods must be registered before they are allowed to be marketed. There is usually some degree of restriction of the availability of certain therapeutic goods depending on their risk to consumers.
",1
239,"Depending upon the jurisdiction, drugs may be divided into over-the-counter drugs (OTC) which may be available without special restrictions, and prescription drugs, which must be prescribed by a licensed medical practitioner in accordance with medical guidelines due to the risk of adverse effects and contraindications. The precise distinction between OTC and prescription depends on the legal jurisdiction. A third category, ""behind-the-counter"" drugs, is implemented in some jurisdictions. These do not require a prescription, but must be kept in the dispensary, not visible to the public, and only be sold by a pharmacist or pharmacy technician. Doctors may also prescribe prescription drugs for off-label use – purposes which the drugs were not originally approved for by the regulatory agency. The Classification of Pharmaco-Therapeutic Referrals helps guide the referral process between pharmacists and doctors.
",1
240,"The International Narcotics Control Board of the United Nations imposes a world law of prohibition of certain drugs. They publish a lengthy list of chemicals and plants whose trade and consumption (where applicable) is forbidden. OTC drugs are sold without restriction as they are considered safe enough that most people will not hurt themselves accidentally by taking it as instructed.[14] Many countries, such as the United Kingdom have a third category of ""pharmacy medicines"", which can only be sold in registered pharmacies by or under the supervision of a pharmacist.
",1
241,"Medical errors include overprescription and polypharmacy, misprescription, contraindication and lack of detail in dosage and administrations instructions. In 2000 the definition of a prescription error was studied using a Delphi method conference; the conference was motivated by ambiguity in the what a prescription error and a need to use a uniform definition in studies.[15]
",1
242,"In many jurisdictions drug prices are regulated.
",1
243,"In the UK, the Pharmaceutical Price Regulation Scheme is intended to ensure that the National Health Service is able to purchase drugs at reasonable prices. The prices are negotiated between the Department of Health, acting with the authority of Northern Ireland and the UK Government, and the representatives of the Pharmaceutical industry brands, the Association of the British Pharmaceutical Industry (ABPI). For 2017 this payment percentage set by the PPRS will be 4,75%.[16]
",1
244,"In Canada, the Patented Medicine Prices Review Board examines drug pricing and determines if a price is excessive or not. In these circumstances, drug manufacturers must submit a proposed price to the appropriate regulatory agency. Furthermore, ""the International Therapeutic Class Comparison Test is responsible for comparing the National Average Transaction Price of the patented drug product under review""[17] different countries that the prices are being compared to are the following: France, Germany, Italy, Sweden, Switzerland, the United Kingdom, and the United States[17]
",1
245,"In Brazil, the prices are regulated through a legislation under the name of Medicamento Genérico (generic drugs) since 1999.[18]
",1
246,"In India, drug prices are regulated by the National Pharmaceutical Pricing Authority.
",1
247,"In the United States, drug costs are unregulated, but instead are the result of negotiations between drug companies and insurance companies.[19]
",1
248,"High prices have been attributed to monopolies given to manufacturers by the government and a lack of ability for organizations to negotiate prices.[20] New drug development costs continue to rise as well. Despite the enormous advances in science and technology, the number of new blockbuster drugs approved per billion dollars spent has halved every 9 years since 1950.[21]
",1
249,"A blockbuster drug is a drug that generates more than $1 billion in revenue for a pharmaceutical company in a single year.[22] Cimetidine was the first drug ever to reach more than $1 billion a year in sales, thus making it the first blockbuster drug.[23]
",1
250,"Antibiotics first arrived on the medical scene in 1932 thanks to Gerhard Domagk;[25] and were coined the ""wonder drugs"". The introduction of the sulfa drugs led to the mortality rate from pneumonia in the U.S. to drop from 0.2% each year to 0.05% by 1939.[26] Antibiotics inhibit the growth or the metabolic activities of bacteria and other microorganisms by a chemical substance of microbial origin. Penicillin, introduced a few years later, provided a broader spectrum of activity compared to sulfa drugs and reduced side effects. Streptomycin, found in 1942, proved to be the first drug effective against the cause of tuberculosis and also came to be the best known of a long series of important antibiotics. A second generation of antibiotics was introduced in the 1940s: aureomycin and chloramphenicol. Aureomycin was the best known of the second generation.
",1
251,"Lithium was discovered in the 19th century for nervous disorders and its possible mood-stabilizing or prophylactic effect; it was cheap and easily produced. As lithium fell out of favor in France, valpromide came into play. This antibiotic was the origin of the drug that eventually created the mood stabilizer category. Valpromide had distinct psychotrophic effects that were of benefit in both the treatment of acute manic states and in the maintenance treatment of manic depression illness. Psychotropics can either be sedative or stimulant; sedatives aim at damping down the extremes of behavior. Stimulants aim at restoring normality by increasing tone. Soon arose the notion of a tranquilizer which was quite different from any sedative or stimulant. The term tranquilizer took over the notions of sedatives and became the dominant term in the West through the 1980s. In Japan, during this time, the term tranquilizer produced the notion of a psyche-stabilizer and the term mood stabilizer vanished.[27]
",1
252,"Premarin (conjugated estrogens, introduced in 1942) and Prempro (a combination estrogen-progestin pill, introduced in 1995) dominated the hormone replacement therapy (HRT) during the 1990s. HRT is not a life-saving drug, nor does it cure any disease. HRT has been prescribed to improve one's quality of life. Doctors prescribe estrogen for their older female patients both to treat short-term menopausal symptoms and to prevent long-term diseases. In the 1960s and early 1970s, more and more physicians began to prescribe estrogen for their female patients. between 1991 and 1999, Premarin was listed as the most popular prescription and best-selling drug in America.[27]
",1
253,"The first oral contraceptive, Enovid, was approved by FDA in 1960. Oral contraceptives inhibit ovulation and so prevent conception. Enovid was known to be much more effective than alternatives including the condom and the diaphragm. As early as 1960, oral contraceptives were available in several different strengths by every manufacturer. In the 1980s and 1990s, an increasing number of options arose including, most recently, a new delivery system for the oral contraceptive via a transdermal patch. In 1982, a new version of the Pill was introduced, known as the ""biphasic"" pill. By 1985, a new triphasic pill was approved. Physicians began to think of the Pill as an excellent means of birth control for young women.[27]
",1
254,"Stimulants such as Ritalin (methylphenidate) came to be pervasive tools for behavior management and modification in young children. Ritalin was first marketed in 1955 for narcolepsy; its potential users were middle-aged and the elderly. It wasn't until some time in the 1980s along with hyperactivity in children that Ritalin came onto the market. Medical use of methlyphenidate is predominantly for symptoms of attention deficit/hyperactivity disorder (ADHD). Consumption of methylphenidate in the U.S. out-paced all other countries between 1991 and 1999. Significant growth in consumption was also evident in Canada, New Zealand, Australia, and Norway. Currently, 85% of the world's methylphenidate is consumed in America.[27]
",1
255,"The first minor tranquilizer was Meprobamate. Only fourteen months after it was made available, meprobamate had become the country's largest-selling prescription drug. By 1957, meprobamate had become the fastest-growing drug in history. The popularity of meprobamate paved the way for Librium and Valium, two minor tranquilizers that belonged to a new chemical class of drugs called the benzodiazepines. These were drugs that worked chiefly as anti-anxiety agents and muscle relaxants. The first benzodiazepine was Librium. Three months after it was approved, Librium had become the most prescribed tranquilizer in the nation. Three years later, Valium hit the shelves and was ten times more effective as a muscle relaxant and anti-convulsant. Valium was the most versatile of the minor tranquilizers. Later came the widespread adoption of major tranquilizers such as chlorpromazine and the drug reserpine. In 1970, sales began to decline for Valium and Librium, but sales of new and improved tranquilizers, such as Xanax, introduced in 1981 for the newly created diagnosis of panic disorder, soared.[27]
",1
256,"Mevacor (lovastatin) is the first and most influential statin in the American market. The 1991 launch of Pravachol (pravastatin), the second available in the United States, and the release of Zocor (simvastatin) made Mevacor no longer the only statin on the market.
In 1998, Viagra was released as a treatment for erectile dysfunction.[27]
",1
257,"Using plants and plant substances to treat all kinds of diseases and medical conditions is believed to date back to prehistoric medicine.
",1
258,"The Kahun Gynaecological Papyrus, the oldest known medical text of any kind, dates to about 1800 BC and represents the first documented use of any kind of drug.[28][29] It and other medical papyri describe Ancient Egyptian medical practices, such as using honey to treat infections and the legs of bee-eaters to treat neck pains.
",1
259,"Ancient Babylonian medicine demonstrate the use of prescriptions in the first half of the 2nd millennium BC. Medicinal creams and pills were employed as treatments.[30]
",1
260,"On the Indian subcontinent, the Atharvaveda, a sacred text of Hinduism whose core dates from the 2nd millennium BC, although the hymns recorded in it are believed to be older, is the first Indic text dealing with medicine. It describes plant-based drugs to counter diseases.[31] The earliest foundations of ayurveda were built on a synthesis of selected ancient herbal practices, together with a massive addition of theoretical conceptualizations, new nosologies and new therapies dating from about 400 BC onwards.[32] The student of Āyurveda was expected to know ten arts that were indispensable in the preparation and application of his medicines: distillation, operative skills, cooking, horticulture, metallurgy, sugar manufacture, pharmacy, analysis and separation of minerals, compounding of metals, and preparation of alkalis.
",1
261,"The Hippocratic Oath for physicians, attributed to 5th century BC Greece, refers to the existence of ""deadly drugs"", and ancient Greek physicians imported drugs from Egypt and elsewhere.[33] The pharmacopoeia De materia medica, written between 50 and 70 CE by the Greek physician Pedanius Dioscorides, was widely read for more than 1,500 years.[34]
",1
262,"Al-Kindi's 9th century AD book, De Gradibus and Ibn Sina (Avicenna)'s The Canon of Medicine cover a range of drugs known to Medicine in the medieval Islamic world.
",1
263,"Medieval medicine saw advances in surgery, but few truly effective drugs existed, beyond opium (found in such extremely popular drugs as the ""Great Rest"" of the Antidotarium Nicolai at the time)[35] and quinine. Folklore cures and potentially poisonous metal-based compounds were popular treatments. Theodoric Borgognoni, (1205–1296), one of the most significant surgeons of the medieval period, responsible for introducing and promoting important surgical advances including basic antiseptic practice and the use of anaesthetics. Garcia de Orta described some herbal treatments that were used.
",1
264,"For most of the 19th century, drugs were not highly effective, leading Oliver Wendell Holmes, Sr. to famously comment in 1842 that ""if all medicines in the world were thrown into the sea, it would be all the better for mankind and all the worse for the fishes"".[24]:21
",1
265,"During the First World War, Alexis Carrel and Henry Dakin developed the Carrel-Dakin method of treating wounds with an irrigation, Dakin's solution, a germicide which helped prevent gangrene.
",1
266,"In the inter-war period, the first anti-bacterial agents such as the sulpha antibiotics were developed. The Second World War saw the introduction of widespread and effective antimicrobial therapy with the development and mass production of penicillin antibiotics, made possible by the pressures of the war and the collaboration of British scientists with the American pharmaceutical industry.
",1
267,"Medicines commonly used by the late 1920s included aspirin, codeine, and morphine for pain; digitalis, nitroglycerin, and quinine for heart disorders, and insulin for diabetes. Other drugs included antitoxins, a few biological vaccines, and a few synthetic drugs. In the 1930s, antibiotics emerged: first sulfa drugs, then penicillin and other antibiotics. Drugs increasingly became ""the center of medical practice"".[24]:22 In the 1950s, other drugs emerged including corticosteroids for inflammation, rauvolfia alkaloids as tranqulizers and antihypertensives, antihistamines for nasal allergies, xanthines for asthma, and typical antipsychotics for psychosis.[24]:23–24 As of 2007, thousands of approved drugs have been developed. Increasingly, biotechnology is used to discover biopharmaceuticals.[24] Recently, multi-disciplinary approaches have yielded a wealth of new data on the development of novel antibiotics and antibacterials and on the use of biological agents for antibacterial therapy.[36]
",1
268,"In the 1950s, new psychiatric drugs, notably the antipsychotic chlorpromazine, were designed in laboratories and slowly came into preferred use. Although often accepted as an advance in some ways, there was some opposition, due to serious adverse effects such as tardive dyskinesia. Patients often opposed psychiatry and refused or stopped taking the drugs when not subject to psychiatric control.
",1
269,"Governments have been heavily involved in the regulation of drug development and drug sales. In the U.S., the Elixir Sulfanilamide disaster led to the establishment of the Food and Drug Administration, and the 1938 Federal Food, Drug, and Cosmetic Act required manufacturers to file new drugs with the FDA. The 1951 Humphrey-Durham Amendment required certain drugs to be sold by prescription. In 1962, a subsequent amendment required new drugs to be tested for efficacy and safety in clinical trials.[24]:24–26
",1
270,"Until the 1970s, drug prices were not a major concern for doctors and patients. As more drugs became prescribed for chronic illnesses, however, costs became burdensome, and by the 1970s nearly every U.S. state required or encouraged the substitution of generic drugs for higher-priced brand names. This also led to the 2006 U.S. law, Medicare Part D, which offers Medicare coverage for drugs.[24]:28–29
",1
271,"As of 2008, the United States is the leader in medical research, including pharmaceutical development. U.S. drug prices are among the highest in the world, and drug innovation is correspondingly high. In 2000, U.S.-based firms developed 29 of the 75 top-selling drugs; firms from the second-largest market, Japan, developed eight, and the United Kingdom contributed 10. France, which imposes price controls, developed three. Throughout the 1990s, outcomes were similar.[24]:30–31
",1
272,"Controversies concerning pharmaceutical drugs include patient access to drugs under development and not yet approved, pricing, and environmental issues.
",1
273,"Governments worldwide have created provisions for granting access to drugs prior to approval for patients who have exhausted all alternative treatment options and do not match clinical trial entry criteria. Often grouped under the labels of compassionate use, expanded access, or named patient supply, these programs are governed by rules which vary by country defining access criteria, data collection, promotion, and control of drug distribution.[37]
",1
274,"Within the United States, pre-approval demand is generally met through treatment IND (investigational new drug) applications (INDs), or single-patient INDs. These mechanisms, which fall under the label of expanded access programs, provide access to drugs for groups of patients or individuals residing in the US. Outside the US, Named Patient Programs provide controlled, pre-approval access to drugs in response to requests by physicians on behalf of specific, or ""named"", patients before those medicines are licensed in the patient's home country.  Through these programs, patients are able to access drugs in late-stage clinical trials or approved in other countries for a genuine, unmet medical need, before those drugs have been licensed in the patient's home country.
",1
275,"Patients who have not been able to get access to drugs in development have organized and advocated for greater access.  In the United States, ACT UP formed in the 1980s, and eventually formed its Treatment Action Group in part to pressure the US government to put more resources into discovering treatments for AIDS and then to speed release of drugs that were under development.[38]
",1
276,"The Abigail Alliance was established in November 2001 by Frank Burroughs in memory of his daughter, Abigail.[39] The Alliance seeks broader availability of investigational drugs on behalf of terminally ill patients.
",1
277,"In 2013, BioMarin Pharmaceutical was at the center of a high-profile debate regarding expanded access of cancer patients to experimental drugs.[40][41]
",1
278,"Essential medicines as defined by the World Health Organization (WHO) are ""those drugs that satisfy the health care needs of the majority of the population; they should therefore be available at all times in adequate amounts and in appropriate dosage forms, at a price the community can afford.""[42]  Recent studies have found that most of the medicines on the WHO essential medicines list, outside of the field of HIV drugs, are not patented in the developing world, and that lack of widespread access to these medicines arise from issues fundamental to economic development – lack of infrastructure and poverty.[43] Médecins Sans Frontières also runs a Campaign for Access to Essential Medicines campaign, which includes advocacy for greater resources to be devoted to currently untreatable diseases that primarily occur in the developing world. The Access to Medicine Index tracks how well pharmaceutical companies make their products available in the developing world.
",1
279,"World Trade Organization negotiations in the 1990s, including the TRIPS Agreement and the Doha Declaration, have centered on issues at the intersection of international trade in pharmaceuticals and intellectual property rights, with developed world nations seeking strong intellectual property rights to protect investments made to develop new drugs, and developing world nations seeking to promote their generic pharmaceuticals industries and their ability to make medicine available to their people via compulsory licenses.
",1
280,"Some have raised ethical objections specifically with respect to pharmaceutical patents and the high prices for drugs that they enable their proprietors to charge, which poor people in the developed world, and developing world, cannot afford.[44][45] Critics also question the rationale that exclusive patent rights and the resulting high prices are required for pharmaceutical companies to recoup the large investments needed for research and development.[44] One study concluded that marketing expenditures for new drugs often doubled the amount that was allocated for research and development.[46] Other critics claim that patent settlements would be costly for consumers, the health care system, and state and federal governments because it would result in delaying access to lower cost generic medicines.[47]
",1
281,"Novartis fought a protracted battle with the government of India over the patenting of its drug, Gleevec, in India, which ended up in India's Supreme Court in a case known as Novartis v. Union of India & Others.  The Supreme Court ruled narrowly against Novartis, but opponents of patenting drugs claimed it as a major victory.[48]
",1
282,"The environmental impact of pharmaceuticals and personal care products is controversial. PPCPs are substances used by individuals for personal health or cosmetic reasons and the products used by agribusiness to boost growth or health of livestock.  PPCPs comprise a diverse collection of thousands of chemical substances, including prescription and over-the-counter therapeutic drugs, veterinary drugs, fragrances, and cosmetics. PPCPs have been detected in water bodies throughout the world and ones that persist in the environment are called Environmental Persistent Pharmaceutical Pollutants.  The effects of these chemicals on humans and the environment are not yet known, but to date there is no scientific evidence that they affect human health.[49]
",1
283,"
",1
284,"Surgery[a] is a medical or dental specialty that uses operative manual and instrumental techniques on a person to investigate or treat a pathological condition such as a disease or injury, to help improve bodily function, appearance, or to repair unwanted ruptured areas.
",1
285,"The act of performing surgery may be called a surgical procedure, operation, or simply ""surgery"". In this context, the verb ""operate"" means to perform surgery. The adjective surgical means pertaining to surgery; e.g. surgical instruments or surgical nurse. The person or subject on which the surgery is performed can be a person or an animal. A surgeon is a person who practices surgery and a surgeon's assistant is a person who practices surgical assistance. A surgical team is made up of the surgeon, the surgeon's assistant, an anaesthetist, a circulating nurse and a surgical technologist. Surgery usually spans from minutes to hours, but it is typically not an ongoing or periodic type of treatment. The term ""surgery"" can also refer to the place where surgery is performed, or, in British English, simply the office of a physician,[1] dentist, or veterinarian.
",1
286,"Surgery is an invasive technique with the fundamental principle of physical intervention on organs/organ systems/tissues for diagnostic or therapeutic reasons.
",1
287,"As a general rule, a procedure is considered surgical when it involves cutting of a person's tissues or closure of a previously sustained wound.  Other procedures that do not necessarily fall under this rubric, such as angioplasty or endoscopy, may be considered surgery if they involve ""common"" surgical procedure or settings, such as use of a sterile environment, anesthesia, antiseptic conditions, typical surgical instruments, and suturing or stapling.  All forms of surgery are considered invasive procedures; so-called ""noninvasive surgery"" usually refers to an excision that does not penetrate the structure being excised (e.g. laser ablation of the cornea) or to a radiosurgical procedure (e.g. irradiation of a tumor).
",1
288,"Surgical procedures are commonly categorized by urgency, type of procedure, body system involved, the degree of invasiveness, and special instrumentation.
",1
289,"Inpatient surgery is performed in a hospital, and the person undergoing surgery stays at least one night in the hospital after the surgery. Outpatient surgery occurs in a hospital outpatient department or freestanding ambulatory surgery center, and the person who had surgery is discharged the same working day.[4] Office surgery occurs in a physician's office, and the person is discharged the same working day.[5]
",1
290,"At a hospital, modern surgery is often performed in an operating theater using surgical instruments, an operating table, and other equipment. Among United States hospitalizations for nonmaternal and nonneonatal conditions in 2012, more than one-fourth of stays and half of hospital costs involved stays that included operating room (OR) procedures.[6] The environment and procedures used in surgery are governed by the principles of aseptic technique: the strict separation of ""sterile"" (free of microorganisms) things from ""unsterile"" or ""contaminated"" things.  All surgical instruments must be sterilized, and an instrument must be replaced or re-sterilized if, it becomes contaminated (i.e. handled in an unsterile manner, or allowed to touch an unsterile surface). Operating room staff must wear sterile attire (scrubs, a scrub cap, a sterile surgical gown, sterile latex or non-latex polymer gloves and a surgical mask), and they must scrub hands and arms with an approved disinfectant agent before each procedure.
",1
291,"Prior to surgery, the person is given a medical examination, receives certain pre-operative tests, and their physical status is rated according to the ASA physical status classification system. If these results are satisfactory, the person requiring surgery signs a consent form and is given a surgical clearance. If the procedure is expected to result in significant blood loss, an autologous blood donation may be made some weeks prior to surgery. If the surgery involves the digestive system, the person requiring surgery may be instructed to perform a bowel prep by drinking a solution of polyethylene glycol the night before the procedure. People preparing for surgery are also instructed to abstain from food or drink (an NPO order after midnight on the night before the procedure), to minimize the effect of stomach contents on pre-operative medications and reduce the risk of aspiration if the person vomits during or after the procedure.
",1
292,"Some medical systems have a practice of routinely performing chest x-rays before surgery. The premise behind this practice is that the physician might discover some unknown medical condition which would complicate the surgery, and that upon discovering this with the chest x-ray, the physician would adapt the surgery practice accordingly.[7] However, medical specialty professional organizations recommend against routine pre-operative chest x-rays for people who have an unremarkable medical history and presented with a physical exam which did not indicate a chest x-ray.[7] Routine x-ray examination is more likely to result in problems like misdiagnosis, overtreatment, or other negative outcomes than it is to result in a benefit to the person.[7] Likewise, other tests including complete blood count, prothrombin time, partial thromboplastin time, basic metabolic panel, and urinalysis should not be done unless the results of these tests can help evaluate surgical risk.[8]
",1
293,"The pre-operative holding area[9] is so important in the surgical phase since here is where most of the family members can see who the staff of the surgery will be, also this area is where the nurses in charge to give information to the family members of the patient. In the pre-operative holding area, the person preparing for surgery changes out of his or her street clothes and is asked to confirm the details of his or her surgery. A set of vital signs are recorded, a peripheral IV line is placed, and pre-operative medications (antibiotics, sedatives, etc.) are given.[10] When the person enters the operating room, the skin surface to be operated on, called the operating field, is cleaned and prepared by applying an antiseptic (ideally chlorhexidine gluconate in alcoholic, as this is twice as effective as povidone-iodine for reduce the risk of infection.[11] If hair is present at the surgical site, it is clipped off prior to prep application. The person is assisted by an anesthesiologist or resident to make a specific surgical position, then sterile drapes are used to cover the surgical site or at least a wide area surrounding the operating field; the drapes are clipped to a pair of poles near the head of the bed to form an ""ether screen"", which separates the anesthetist/anesthesiologist's working area (unsterile) from the surgical site (sterile).[12]
",1
294,"Anesthesia is administered to prevent pain from an incision, tissue manipulation and suturing.  Depending on the kind of operation, anesthesia may be provided locally or as general anesthesia.  Spinal anesthesia may be used when the surgical site is too large or deep for a local block, but general anesthesia may not be desirable.  With local and spinal anesthesia, the surgical site is anesthetized, but the person can remain conscious or minimally sedated.  In contrast, general anesthesia renders the person unconscious and paralyzed during surgery.  The person is intubated and is placed on a mechanical ventilator, and anesthesia is produced by a combination of injected and inhaled agents.
Choice of surgical method and anesthetic technique aims to reduce the risk of complications, shorten the time needed for recovery and minimise the surgical stress response.
",1
295,"The intraoperative phase begins when the surgery subject is received in the surgical area (such as the operating theater or surgical department), and lasts until the subject is transferred to a recovery area (such as a post-anesthesia care unit).[13]
",1
296,"An incision is made to access the surgical site.  Blood vessels may be clamped or cauterized to prevent bleeding, and retractors may be used to expose the site or keep the incision open.  The approach to the surgical site may involve several layers of incision and dissection, as in abdominal surgery, where the incision must traverse skin, subcutaneous tissue, three layers of muscle and then the peritoneum.  In certain cases, bone may be cut to further access the interior of the body; for example, cutting the skull for brain surgery or cutting the sternum for thoracic (chest) surgery to open up the rib cage. Whilst in surgery aseptic technique is used to prevent infection or further spreading of the disease. The surgeons' and assistants' hands, wrists and forearms are washed thoroughly for at least 4 minutes to prevent germs getting into the operative field, then sterile gloves are placed onto their hands. An antiseptic solution is applied to the area of the person's body that will be operated on. Sterile drapes are placed around the operative site. Surgical masks are worn by the surgical team to avoid germs on droplets of liquid from their mouths and noses from contaminating the operative site.
",1
297,"Work to correct the problem in body then proceeds.  This work may involve:

",1
298,"Blood or blood expanders may be administered to compensate for blood lost during surgery.  Once the procedure is complete, sutures or staples are used to close the incision.  Once the incision is closed, the anesthetic agents are stopped or reversed, and the person is taken off ventilation and extubated (if general anesthesia was administered).[15]
",1
299,"After completion of surgery, the person is transferred to the post anesthesia care unit and closely monitored.  When the person is judged to have recovered from the anesthesia, he/she is either transferred to a surgical ward elsewhere in the hospital or discharged home.  During the post-operative period, the person's general function is assessed, the outcome of the procedure is assessed, and the surgical site is checked for signs of infection. There are several risk factors associated with postoperative complications, such as immune deficiency and obesity. Obesity has long been considered a risk factor for adverse post-surgical outcomes. It has been linked to many disorders such as obesity hypoventilation syndrome, atelectasis and pulmonary embolism, adverse cardiovascular effects, and wound healing complications.[16] If removable skin closures are used, they are removed after 7 to 10 days post-operatively, or after healing of the incision is well under way.
",1
300,"It is not uncommon for surgical drains (see Drain (surgery)) to be required to remove blood or fluid from the surgical wound during recovery. Mostly these drains stay in until the volume tapers off, then they are removed.  These drains can become clogged, leading to abscess.
",1
301,"Postoperative therapy may include adjuvant treatment such as chemotherapy, radiation therapy, or administration of medication such as anti-rejection medication for transplants.  Other follow-up studies or rehabilitation may be prescribed during and after the recovery period.
",1
302,"The use of topical antibiotics on surgical wounds to reduce infection rates has been questioned.[17] Antibiotic ointments are likely to irritate the skin, slow healing, and could increase risk of developing contact dermatitis and antibiotic resistance.[17] It has also been suggested that topical antibiotics should only be used when a person shows signs of infection and not as a preventative.[17] A systematic review published by Cochrane (organisation) in 2016, though, concluded that topical antibiotics applied over certain types of surgical wounds reduce the risk of surgical site infections, when compared to no treatment or use of antiseptics.[18] The review also did not find conclusive evidence to suggest that topical antibiotics increased the risk of local skin reactions or antibiotic resistance.
",1
303,"Through a retrospective analysis of national administrative data, the association between mortality and day of elective surgical procedure suggests a higher risk in procedures carried out later in the working week and on weekends. The odds of death were 44% and 82% higher respectively when comparing procedures on a Friday to a weekend procedure. This ""weekday effect"" has been postulated to be from several factors including poorer availability of services on a weekend, and also, decrease number and level of experience over a weekend.[19]
",1
304,"While pain is universal and expected after surgery, there is growing evidence that pain may be inadequately treated in many people in the acute period immediately after surgery. It has been reported that incidence of inadequately controlled pain after surgery ranged from 25.1% to 78.4% across all surgical disciplines.[20]
",1
305,"Postoperative recovery has been defined as an energy‐requiring process to decrease physical symptoms, reach a level of emotional well‐being, regain functions, and re‐establish activities.[21] Moreover, it has been identified that patients who have undergone surgery are often not fully recovered on discharge.
",1
306,"In 2011, of the 38.6 million hospital stays in U.S. hospitals, 29% included at least one operating room procedure. These stays accounted for 48% of the total $387 billion in hospital costs.[22]
",1
307,"The overall number of procedures remained stable from 2001 to 2011. In 2011, over 15 million operating room procedures were performed in U.S. hospitals.[23]
",1
308,"Data from 2003 to 2011 showed that U.S. hospital costs were highest for the surgical service line; the surgical service line costs were $17,600 in 2003 and projected to be $22,500 in 2013.[24] For hospital stays in 2012 in the United States, private insurance had the highest percentage of surgical expenditure.[25] in 2012, mean hospital costs in the United States were highest for surgical stays.[25]
",1
309,"Older adults have widely varying physical health.  Frail elderly people are at significant risk of post-surgical complications and the need for extended care.  Assessment of older people before elective surgery can accurately predict the person's recovery trajectories.[26] One frailty scale uses five items:  unintentional weight loss, muscle weakness, exhaustion, low physical activity, and slowed walking speed.  A healthy person scores 0; a very frail person scores 5.  Compared to non-frail elderly people, people with intermediate frailty scores (2 or 3) are twice as likely to have post-surgical complications, spend 50% more time in the hospital, and are three times as likely to be discharged to a skilled nursing facility instead of to their own homes.[26] People who are frail and elderly (score of 4 or 5) have even worse outcomes, with the risk of being discharged to a nursing home rising to twenty times the rate for non-frail elderly people.
",1
310,"Surgery on children requires considerations that are not common in adult surgery. Children and adolescents are still developing physically and mentally making it difficult for them to make informed decisions and give consent for surgical treatments. Bariatric surgery in youth is among the controversial topics related to surgery in children.
",1
311,"Doctors perform surgery with the consent of the person undergoing surgery. Some people are able to give better informed consent than others. Populations such as incarcerated persons, people living with dementia, the mentally incompetent, persons subject to coercion, and other people who are not able to make decisions with the same authority as others, have special needs when making decisions about their personal healthcare, including surgery.
",1
312,"Surgery remains grossly neglected in global health, famously described by Halfdan T. Mahler as the 'neglected stepchild of global health'. This particularly affects low-resource settings with weak surgical health systems. 'Global surgery' is the term now adopted to describe the rapidly developing field seeking to address this, and has been defined as 'the multidisciplinary enterprise of providing improved and equitable surgical care to the world's population, with its core tenets as the issues of need, access and quality'.[27]
",1
313,"In 2014, The Lancet Commission on Global Surgery was launched to examine the case for surgery as an integral component of global health care and to provide recommendations regarding the delivery of surgical and anesthesia services in low and middle income countries.[28] In this study, two primary conclusions were reached:
",1
314,"Globally, 4.2 million people are estimated to die within 30 days of surgery each year, with half of these occurring in low- and middle-income countries.[29] A prospective study of 10,745 adults undergoing emergency abdominal surgery from 357 centres across 58 countries found that mortality is three times higher in low- compared with high-human development index (HDI) countries even when adjusted for prognostic factors.[30] In this study the overall global mortality rate was 1·6 per cent at 24 hours (high HDI 1·1 per cent, middle HDI 1·9 per cent, low HDI 3·4 per cent), increasing to 5·4 per cent by 30 days (high HDI 4·5 per cent, middle HDI 6·0 per cent, low HDI 8·6 per cent; P < 0·001). A sub-study of 1,409 children undergoing emergency abdominal surgery from 253 centres across 43 countries found that adjusted mortality in children following surgery may be as high as 7 times greater in low-HDI and middle-HDI countries compared with high-HDI countries. This translates to 40 excess deaths per 1000 procedures performed in these settings.[31] Patient safety factors were suggested to play an important role, with use of the WHO Surgical Safety Checklist associated with reduced mortality at 30 days.[32]
",1
315,"Introducing novel or new surgical techniques in low- and middle-income countries is a challenge.[33] Challenges include knowledge (awareness), fear, costs, and cultural beliefs.[34]
",1
316,"Access to surgical care is increasingly recognized as an integral aspect of healthcare, and therefore is evolving into a normative derivation of human right to health.[35] The ICESCR Article 12.1 and 12.2 define the human right to health as ""the right of everyone to the enjoyment of the highest attainable standard of physical and mental health""[36] In the August 2000, the UN Committee on Economic, Social and Cultural Rights (CESCR) interpreted this to mean ""right to the enjoyment of a variety of facilities, goods, services, and conditions necessary for the realization of the highest attainable health"".[37] Surgical care can be thereby viewed as a positive right – an entitlement to protective healthcare.[37]
",1
317,"Woven through the International Human and Health Rights literature is the right to be free from surgical disease. The 1966 ICESCR Article 12.2a described the need for ""provision for the reduction of the stillbirth-rate and of infant mortality and for the healthy development of the child""[38] which was subsequently interpreted to mean ""requiring measures to improve… emergency obstetric services"".[37] Article 12.2d of the ICESCR stipulates the need for ""the creation of conditions which would assure to all medical service and medical attention in the event of sickness"",[39] and is interpreted in the 2000 comment to include timely access to ""basic preventative, curative services… for appropriate treatment of injury and disability."".[40] Obstetric care shares close ties with reproductive rights, which includes access to reproductive health.[40]
",1
318,"Surgeons and public health advocates, such as Kelly McQueen, have described surgery as ""Integral to the right to health"".[41] This is reflected in the establishment of the WHO Global Initiative for Emergency and Essential Surgical Care in 2005,[42] the 2013 formation of the Lancet Commission for Global Surgery,[43] the 2015 World Bank Publication of Volume 1 of its Disease Control Priorities ""Essential Surgery"",[44] and the 2015 World Health Assembly 68.15 passing of the Resolution for Strengthening Emergency and Essential Surgical Care and Anesthesia as a Component of Universal Health Coverage.[45] The Lancet Commission for Global Surgery outlined the need for access to ""available, affordable, timely and safe"" surgical and anesthesia care;[46] dimensions paralleled in ICESCR General Comment No. 14, which similarly outlines need for available, accessible, affordable and timely healthcare.[37]
",1
319,"Surgical treatments date back to the prehistoric era. The oldest for which there is evidence is trepanation,[47] in which a hole is drilled or scraped into the skull, thus exposing the dura mater in order to treat health problems related to intracranial pressure and other diseases.
",1
320,"Prehistoric surgical techniques are seen in Ancient Egypt, where a mandible dated to approximately 2650 BC shows two perforations just below the root of the first molar, indicating the draining of an abscessed tooth. Surgical texts from ancient Egypt date back about 3500 years ago. Surgical operations were performed by priests, specialized in medical treatments similar to today,[48] and used sutures to close wounds.[49] Infections were treated with honey.[50]
",1
321,"Remains from the early Harappan periods of the Indus Valley Civilization (c. 3300 BC) show evidence of teeth having been drilled dating back 9,000 years.[51] Susruta[52] was an ancient Indian surgeon commonly credited as the author of the treatise Sushruta Samhita. He is well known  as the ""father of surgery"", and his period is usually placed around 1200–600 BC.[53] One of the earliest known mentions of the name is from the Bower Manuscript, in which Sushruta is listed as one of the ten sages residing in the Himalayas.[54] Texts suggest that he learned surgery at Kasi from Lord Dhanvantari, the god of medicine in Hindu mythology.[55] It is one of the oldest known surgical texts and it describes in detail the examination, diagnosis, treatment, and prognosis of numerous ailments, as well as procedures for various forms of cosmetic surgery, plastic surgery and rhinoplasty.[56]
",1
322,"In ancient Greece, temples dedicated to the healer-god Asclepius, known as Asclepieia (Greek: Ασκληπιεία, sing. Asclepieion Ασκληπιείον), functioned as centers of medical advice, prognosis, and healing.[57] In the Asclepieion of Epidaurus, some of the surgical cures listed, such as the opening of an abdominal abscess or the removal of traumatic foreign material, are realistic enough to have taken place.[15] The Greek Galen was one of the greatest surgeons of the ancient world and performed many audacious operations – including brain and eye surgery – that were not tried again for almost two millennia.
",1
323,"Researchers from the Adelphi University discovered in the Paliokastro on Thasos ten skeletal remains, four women and six men, who were buried between the fourth and seventh centuries A.D. Their bones illuminated their physical activities, traumas, and even a complex form of brain surgery. According to the researchers: ""The very serious trauma cases sustained by both males and females had been treated surgically or orthopedically by a very experienced physician/surgeon with great training in trauma care. We believe it to have been a military physician"". The researchers were impressed by the complexity of the brain surgical operation.[58]
",1
324,"During the Islamic Golden Age, largely based upon Paul of Aegina's Pragmateia, the writings of Abulcasis (Abu al-Qasim Khalaf ibn al-Abbas Al-Zahrawi), an Andalusian-Arab physician and scientist who practiced in the Zahra suburb of Córdoba, were influential.[59][60] Al-Zahrawi specialized in curing disease by cauterization. He invented several surgical instruments for purposes such as inspection of the interior of the urethra and for removing foreign bodies from the throat, the ear, and other body organs. He was also the first to illustrate the various cannulae and to treat warts with an iron tube and caustic metal[clarification needed] as a boring instrument. He describes what is thought to be the first attempt at reduction mammaplasty for the management of gynaecomastia[61] and the first mastectomy to treat breast cancer.[62] He is credited with the performance of the first thyroidectomy.[63] Al-Zahrawi pioneered techniques of neurosurgery and neurological diagnosis, treating head injuries, skull fractures, spinal injuries, hydrocephalus, subdural effusions and headache. The first clinical description of an operative procedure for hydrocephalus was given by Al-Zahrawi, who clearly describes the evacuation of superficial intracranial fluid in hydrocephalic children.[64]
",1
325,"In Europe, the demand grew for surgeons to formally study for many years before practicing; universities such as Montpellier, Padua and Bologna were particularly renowned. In the 12th century, Rogerius Salernitanus composed his Chirurgia, laying the foundation for modern Western surgical manuals. Barber-surgeons generally had a bad reputation that was not to improve until the development of academic surgery as a specialty of medicine, rather than an accessory field.[65] Basic surgical principles for asepsis etc., are known as Halsteads principles.
",1
326,"There were some important advances to the art of surgery during this period. The professor of anatomy at the University of Padua, Andreas Vesalius, was a pivotal figure in the Renaissance transition from classical medicine and anatomy based on the works of Galen, to an empirical approach of 'hands-on' dissection. In his anatomic treaties De humani corporis fabrica, he exposed the many anatomical errors in Galen and advocated that all surgeons should train by engaging in practical dissections themselves.
",1
327,"The second figure of importance in this era was Ambroise Paré (sometimes spelled ""Ambrose""[66]), a French army surgeon from the 1530s until his death in 1590. The practice for cauterizing gunshot wounds on the battlefield had been to use boiling oil; an extremely dangerous and painful procedure. Paré began to employ a less irritating emollient, made of egg yolk, rose oil and turpentine. He also described more efficient techniques for the effective ligation of the blood vessels during an amputation.
",1
328,"The discipline of surgery was put on a sound, scientific footing during the Age of Enlightenment in Europe. An important figure in this regard was the Scottish surgical scientist, John Hunter, generally regarded as the father of modern scientific surgery.[67] He brought an empirical and experimental approach to the science and was renowned around Europe for the quality of his research and his written works. Hunter reconstructed surgical knowledge from scratch; refusing to rely on the testimonies of others, he conducted his own surgical experiments to determine the truth of the matter. To aid comparative analysis, he built up a collection of over 13,000 specimens of separate organ systems, from the simplest plants and animals to humans.
",1
329,"He greatly advanced knowledge of venereal disease and introduced many new techniques of surgery, including new methods for repairing damage to the Achilles tendon and a more effective method for applying ligature of the arteries in case of an aneurysm.[68] He was also one of the first to understand the importance of pathology, the danger of the spread of infection and how the problem of inflammation of the wound, bone lesions and even tuberculosis often undid any benefit that was gained from the intervention. He consequently adopted the position that all surgical procedures should be used only as a last resort.[69]
",1
330,"Other important 18th- and early 19th-century surgeons included Percival Pott (1713–1788) who described tuberculosis on the spine and first demonstrated that a cancer may be caused by an environmental carcinogen (he noticed a connection between chimney sweep's exposure to soot and their high incidence of scrotal cancer). Astley Paston Cooper (1768–1841) first performed a successful ligation of the abdominal aorta, and James Syme (1799–1870) pioneered the Symes Amputation for the ankle joint and successfully carried out the first hip disarticulation.
",1
331,"Modern pain control through anesthesia was discovered in the mid-19th century. Before the advent of anesthesia, surgery was a traumatically painful procedure and surgeons were encouraged to be as swift as possible to minimize patient suffering.  This also meant that operations were largely restricted to amputations and external growth removals. Beginning in the 1840s, surgery began to change dramatically in character with the discovery of effective and practical anaesthetic chemicals such as ether, first used by the American surgeon Crawford Long, and chloroform, discovered by Scottish obstetrician James Young Simpson and later pioneered by John Snow, physician to Queen Victoria.[70] In addition to relieving patient suffering, anaesthesia allowed more intricate operations in the internal regions of the human body.  In addition, the discovery of muscle relaxants such as curare allowed for safer applications.
",1
332,"Unfortunately, the introduction of anesthetics encouraged more surgery, which inadvertently caused more dangerous patient post-operative infections.  The concept of infection was unknown until relatively modern times. The first progress in combating infection was made in 1847 by the Hungarian doctor Ignaz Semmelweis who noticed that medical students fresh from the dissecting room were causing excess maternal death compared to midwives. Semmelweis, despite ridicule and opposition, introduced compulsory handwashing for everyone entering the maternal wards and was rewarded with a plunge in maternal and fetal deaths; however, the Royal Society dismissed his advice.
",1
333,"Until the pioneering work of British surgeon Joseph Lister in the 1860s, most medical men believed that chemical damage from exposures to bad air (see ""miasma"") was responsible for infections in wounds, and facilities for washing hands or a patient's wounds were not available.[71] Lister became aware of the work of French chemist Louis Pasteur, who showed that rotting and fermentation could occur under anaerobic conditions if micro-organisms were present.  Pasteur suggested three methods to eliminate the micro-organisms responsible for gangrene: filtration, exposure to heat, or exposure to chemical solutions. Lister confirmed Pasteur's conclusions with his own experiments and decided to use his findings to develop antiseptic techniques for wounds.  As the first two methods suggested by Pasteur were inappropriate for the treatment of human tissue, Lister experimented with the third, spraying carbolic acid on his instruments. He found that this remarkably reduced the incidence of gangrene and he published his results in The Lancet.[72] Later, on 9 August 1867, he read a paper before the British Medical Association in Dublin, on the Antiseptic Principle of the Practice of Surgery, which was reprinted in the British Medical Journal.[73][74][75] His work was groundbreaking and laid the foundations for a rapid advance in infection control that saw modern antiseptic operating theatres widely used within 50 years.
",1
334,"Lister continued to develop improved methods of antisepsis and asepsis when he realised that infection could be better avoided by preventing bacteria from getting into wounds in the first place. This led to the rise of sterile surgery. Lister introduced the Steam Steriliser to sterilize equipment, instituted rigorous hand washing and later implemented the wearing of rubber gloves. These three crucial advances – the adoption of a scientific methodology toward surgical operations, the use of anaesthetic and the introduction of sterilised equipment – laid the groundwork for the modern invasive surgical techniques of today.
",1
335,"The use of X-rays as an important medical diagnostic tool began with their discovery in 1895 by German physicist Wilhelm Röntgen. He noticed that these rays could penetrate the skin, allowing the skeletal structure to be captured on a specially treated photographic plate.
",1
336,"Hieronymus Fabricius, Operationes chirurgicae, 1685
",1
337,"John Syng Dorsey wrote the first American textbook on surgery
",1
338,"An operation in 1753, painted by Gaspare Traversi.
",1
339,"
",1
340,"Psychiatry is the medical specialty devoted to the diagnosis, prevention, and treatment of mental disorders.[1][2] These include various maladaptations related to mood, behaviour, cognition, and perceptions. See glossary of psychiatry.
",1
341,"Initial psychiatric assessment of a person typically begins with a case history and mental status examination. Physical examinations and psychological tests may be conducted. On occasion, neuroimaging or other neurophysiological techniques are used.[3] Mental disorders are often diagnosed in accordance with clinical concepts listed in diagnostic manuals such as the International Classification of Diseases (ICD), edited and used by the World Health Organization (WHO) and the widely used Diagnostic and Statistical Manual of Mental Disorders (DSM), published by the American Psychiatric Association (APA). The fifth edition of the DSM (DSM-5) was published in 2013 which re-organized the larger categories of various diseases and expanded upon the previous edition to include information/insights that are consistent with current research.[4]
",1
342,"The combined treatment of psychiatric medication and psychotherapy has become the most common mode of psychiatric treatment in current practice,[5][6] but contemporary practice also includes a wide variety of other modalities, e.g., assertive community treatment, community reinforcement, and supported employment. Treatment may be delivered on an inpatient or outpatient basis, depending on the severity of functional impairment or on other aspects of the disorder in question. An inpatient may be treated in a psychiatric hospital. Research and treatment within psychiatry as a whole are conducted on an interdisciplinary basis with other professionals, such as epidemiologists, nurses, social workers, occupational therapists or psychologists.
",1
343,"The term psychiatry was first coined by the German physician Johann Christian Reil in 1808 and literally means the 'medical treatment of the soul' (psych- 'soul' from Ancient Greek psykhē 'soul'; -iatry 'medical treatment' from Gk. iātrikos 'medical' from iāsthai 'to heal'). A medical doctor specializing in psychiatry is a psychiatrist. (For a historical overview, see Timeline of psychiatry.)
",1
344,"Psychiatry refers to a field of medicine focused specifically on the mind, aiming to study, prevent, and treat mental disorders in humans.[9][10][11] It has been described as an intermediary between the world from a social context and the world from the perspective of those who are mentally ill.[12]
",1
345,"People who specialize in psychiatry often differ from most other mental health professionals and physicians in that they must be familiar with both the social and biological sciences.[10] The discipline studies the operations of different organs and body systems as classified by the patient's subjective experiences and the objective physiology of the patient. [13] Psychiatry treats mental disorders, which are conventionally divided into three very general categories: mental illnesses, severe learning disabilities, and personality disorders.[14] While the focus of psychiatry has changed little over time, the diagnostic and treatment processes have evolved dramatically and continue to do so. Since the late 20th century, the field of psychiatry has continued to become more biological and less conceptually isolated from other medical fields.[15]
",1
346,"Though the medical specialty of psychiatry uses research in the field of neuroscience, psychology, medicine, biology, biochemistry, and pharmacology,[16] it has generally been considered a middle ground between neurology and psychology.[17] Because psychiatry and neurology are deeply intertwined medical specialties, all certification for both specialties and for their subspecialties is offered by a single board, the American Board of Psychiatry and Neurology, one of the member boards of the American Board of Medical Specialties.[18] Unlike other physicians and neurologists, psychiatrists specialize in the doctor–patient relationship and are trained to varying extents in the use of psychotherapy and other therapeutic communication techniques.[17] Psychiatrists also differ from psychologists in that they are physicians and have post-graduate training called residency (usually 4 to 5 years) in psychiatry; the quality and thoroughness of their graduate medical training is identical to that of all other physicians.[19] Psychiatrists can therefore counsel patients, prescribe medication, order laboratory tests, order neuroimaging, and conduct physical examinations.[3]
",1
347,"The World Psychiatric Association issues an ethical code to govern the conduct of psychiatrists (like other purveyors of professional ethics). The psychiatric code of ethics, first set forth through the Declaration of Hawaii in 1977 has been expanded through a 1983 Vienna update and in the broader Madrid Declaration in 1996. The code was further revised during the organization's general assemblies in 1999, 2002, 2005, and 2011.[20]
",1
348,"The World Psychiatric Association code covers such matters as confidentiality, the death penalty, ethnic or cultural discrimination,[20] euthanasia, genetics, the human dignity of incapacitated patients, media relations, organ transplantation, patient assessment, research ethics, sex selection,[21] torture,[22][23] and up-to-date knowledge.
",1
349,"In establishing such ethical codes, the profession has responded to a number of controversies about the practice of psychiatry, for example, surrounding the use of lobotomy and electroconvulsive therapy.
",1
350,"Discredited psychiatrists who operated outside the norms of medical ethics include Harry Bailey, Donald Ewen Cameron, Samuel A. Cartwright, Henry Cotton, and Andrei Snezhnevsky.[24][page needed]
",1
351,"Psychiatric illnesses can be conceptualised in a number of different ways. The biomedical approach examines signs and symptoms and compares them with diagnostic criteria. Mental illness can be assessed, conversely, through a narrative which tries to incorporate symptoms into a meaningful life history and to frame them as responses to external conditions. Both approaches are important in the field of psychiatry[25] but have not sufficiently reconciled to settle controversy over either the selection of a psychiatric paradigm or the specification of psychopathology. The notion of a ""biopsychosocial model"" is often used to underline the multifactorial nature of clinical impairment.[26][27][28] In this notion the word model is not used in a strictly scientific way though.[26] Alternatively, a ""biocognitive model"" acknowledges the physiological basis for the mind's existence but identifies cognition as an irreducible and independent realm in which disorder may occur.[26][27][28] The biocognitive approach includes a mentalist etiology and provides a natural dualist (i.e., non-spiritual) revision of the biopsychosocial view, reflecting the efforts of Australian psychiatrist Niall McLaren to bring the discipline into scientific maturity in accordance with the paradigmatic standards of philosopher Thomas Kuhn.[26][27][28]
",1
352,"Once a medical professional diagnoses a patient there are numerous ways that they could choose to treat the patient. Often psychiatrists will develop a treatment strategy that incorporates different facets of different approaches into one. Drug prescriptions are very commonly written to be regimented to patients along with any therapy they receive. There are three major pillars of psychotherapy that treatment strategies are most regularly drawn from. Humanistic psychology attempts to put the ""whole"" of the patient in perspective; it also focuses on self exploration.[29] Behaviorism is a therapeutic school of thought that elects to focus solely on real and observable events, rather than mining the unconscious or subconscious. Psychoanalysis, on the other hand, concentrates its dealings on early childhood, irrational drives, the unconscious, and conflict between conscious and unconscious streams.[30]
",1
353,"All physicians can diagnose mental disorders and prescribe treatments utilizing principles of psychiatry. Psychiatrists are trained physicians who specialize in psychiatry and are certified to treat mental illness. They may treat outpatients, inpatients, or both; they may practice as solo practitioners or as members of groups; they may be self-employed, be members of partnerships, or be employees of governmental, academic, nonprofit, or for-profit entities; employees of hospitals; they may treat military personnel as civilians or as members of the military; and in any of these settings they may function as clinicians, researchers, teachers, or some combination of these. Although psychiatrists may also go through significant training to conduct psychotherapy, psychoanalysis or cognitive behavioral therapy, it is their training as physicians that differentiates them from other mental health professionals.
",1
354,"Psychiatry was not a popular career choice among medical students, even though medical school placements are rated favorably.[31] This has resulted in a significant shortage of psychiatrists in the United States and elsewhere.[32] Strategies to address this shortfall have included the use of short 'taster' placements early in the medical school curriculum [31] and attempts to extend psychiatry services further using telemedicine technologies and other methods.[33] Recently, however, there has been an increase in the number of medical students entering into a psychiatry residency. There are several reasons for this surge including the interesting nature of the field, growing interest in genetic biomarkers involved in psychiatric diagnoses, and newer pharmaceuticals on the drug market to treat psychiatric illnesses.[34]
",1
355,"The field of psychiatry has many subspecialties that require additional training and certification by the American Board of Psychiatry and Neurology (ABPN). Such subspecialties include:[35]
",1
356,"Additional psychiatry subspecialties, for which ABPN does not provide formal certification, include:[43]
",1
357,"Addiction psychiatry focuses on evaluation and treatment of individuals with alcohol, drug, or other substance-related disorders, and of individuals with dual diagnosis of substance-related and other psychiatric disorders. Biological psychiatry is an approach to psychiatry that aims to understand mental disorders in terms of the biological function of the nervous system. Child and adolescent psychiatry is the branch of psychiatry that specializes in work with children, teenagers, and their families. Community psychiatry is an approach that reflects an inclusive public health perspective and is practiced in community mental health services.[44] Cross-cultural psychiatry is a branch of psychiatry concerned with the cultural and ethnic context of mental disorder and psychiatric services. Emergency psychiatry is the clinical application of psychiatry in emergency settings. Forensic psychiatry utilizes medical science generally, and psychiatric knowledge and assessment methods in particular, to help answer legal questions. Geriatric psychiatry is a branch of psychiatry dealing with the study, prevention, and treatment of mental disorders in the elderly. Global Mental Health is an area of study, research and practice that places a priority on improving mental health and achieving equity in mental health for all people worldwide,[45] although some scholars consider it to be a neo-colonial, culturally insensitive project.[46][47][48][49] Liaison psychiatry is the branch of psychiatry that specializes in the interface between other medical specialties and psychiatry. Military psychiatry covers special aspects of psychiatry and mental disorders within the military context. Neuropsychiatry is a branch of medicine dealing with mental disorders attributable to diseases of the nervous system. Social psychiatry is a branch of psychiatry that focuses on the interpersonal and cultural context of mental disorder and mental well-being.
",1
358,"In larger healthcare organizations, psychiatrists often serve in senior management roles, where they are responsible for the efficient and effective delivery of mental health services for the organization's constituents. For example, the Chief of Mental Health Services at most VA medical centers is usually a psychiatrist, although psychologists occasionally are selected for the position as well.[citation needed]
",1
359,"In the United States, psychiatry is one of the few specialties which qualify for further education and board-certification in pain medicine, palliative medicine, and sleep medicine.
",1
360,"Psychiatric research is, by its very nature, interdisciplinary; combining social, biological and psychological perspectives in attempt to understand the nature and treatment of mental disorders.[50] Clinical and research psychiatrists study basic and clinical psychiatric topics at research institutions and publish articles in journals.[16][51][52][53] Under the supervision of institutional review boards, psychiatric clinical researchers look at topics such as neuroimaging, genetics, and psychopharmacology in order to enhance diagnostic validity and reliability, to discover new treatment methods, and to classify new mental disorders.[54][page needed]
",1
361,"Psychiatric diagnoses take place in a wide variety of settings and are performed by many different health professionals. Therefore, the diagnostic procedure may vary greatly based upon these factors. Typically, though, a psychiatric diagnosis utilizes a differential diagnosis procedure where a mental status examination and physical examination is conducted, with pathological, psychopathological or psychosocial histories obtained, and sometimes neuroimages or other neurophysiological measurements are taken, or personality tests or cognitive tests administered.[55][56][57][58][59] In some cases, a brain scan might be used to rule out other medical illnesses, but at this time relying on brain scans alone cannot accurately diagnose a mental illness or tell the risk of getting a mental illness in the future.[60] Some clinicians are beginning to utilize genetics[61][62][63] and speech[64] during the diagnostic process but on the whole these remain research topics.
",1
362,"Three main diagnostic manuals used to classify mental health conditions are in use today. The ICD-10 is produced and published by the World Health Organization, includes a section on psychiatric conditions, and is used worldwide.[65] The Diagnostic and Statistical Manual of Mental Disorders, produced and published by the American Psychiatric Association, is primarily focused on mental health conditions and is the main classification tool in the United States.[66] It is currently in its fifth revised edition and is also used worldwide.[66] The Chinese Society of Psychiatry has also produced a diagnostic manual, the Chinese Classification of Mental Disorders.[67]
",1
363,"The stated intention of diagnostic manuals is typically to develop replicable and clinically useful categories and criteria, to facilitate consensus and agreed upon standards, whilst being atheoretical as regards etiology.[66][68] However, the categories are nevertheless based on particular psychiatric theories and data; they are broad and often specified by numerous possible combinations of symptoms, and many of the categories overlap in symptomology or typically occur together.[69] While originally intended only as a guide for experienced clinicians trained in its use, the nomenclature is now widely used by clinicians, administrators and insurance companies in many countries.[70]
",1
364,"The DSM has attracted praise for standardizing psychiatric diagnostic categories and criteria. It has also attracted controversy and criticism. Some critics argue that the DSM represents an unscientific system that enshrines the opinions of a few powerful psychiatrists. There are ongoing issues concerning the validity and reliability of the diagnostic categories; the reliance on superficial symptoms; the use of artificial dividing lines between categories and from 'normality'; possible cultural bias; medicalization of human distress and financial conflicts of interest, including with the practice of psychiatrists and with the pharmaceutical industry; political controversies about the inclusion or exclusion of diagnoses from the manual, in general or in regard to specific issues; and the experience of those who are most directly affected by the manual by being diagnosed, including the consumer/survivor movement.[71][72][73][74] The publication of the DSM, with tightly guarded copyrights, now makes APA over $5 million a year, historically adding up to over $100 million.[75]
",1
365,"Individuals with mental health conditions are commonly referred to as patients but may also be called clients, consumers, or service recipients. They may come under the care of a psychiatric physician or other psychiatric practitioners by various paths, the two most common being self-referral or referral by a primary care physician. Alternatively, a person may be referred by hospital medical staff, by court order, involuntary commitment, or, in the UK and Australia, by sectioning under a mental health law.
",1
366,"Persons who undergo a psychiatric assessment are evaluated by a psychiatrist for their mental and physical condition. This usually involves interviewing the person and often obtaining information from other sources such as other health and social care professionals, relatives, associates, law enforcement personnel, emergency medical personnel, and psychiatric rating scales. A mental status examination is carried out, and a physical examination is usually performed to establish or exclude other illnesses that may be contributing to the alleged psychiatric problems. A physical examination may also serve to identify any signs of self-harm; this examination is often performed by someone other than the psychiatrist, especially if blood tests and medical imaging are performed.
",1
367,"Like most medications, psychiatric medications can cause adverse effects in patients, and some require ongoing therapeutic drug monitoring, for instance full blood counts serum drug levels, renal function, liver function or thyroid function. Electroconvulsive therapy (ECT) is sometimes administered for serious and disabling conditions, such as those unresponsive to medication. The efficacy[76][77] and adverse effects of psychiatric drugs may vary from patient to patient.
",1
368,"For many years, controversy has surrounded the use of involuntary treatment and use of the term ""lack of insight"" in describing patients. Mental health laws vary significantly among jurisdictions, but in many cases, involuntary psychiatric treatment is permitted when there is deemed to be a risk to the patient or others due to the patient's illness. Involuntary treatment refers to treatment that occurs based on the treating physician's recommendations without requiring consent from the patient.[78]
",1
369,"Mental health issues such as mood disorders and schizophrenia and other psychotic disorders were the most common principle diagnoses for Medicaid super-utilizers in the United States in 2012.[79]
",1
370,"Psychiatric treatments have changed over the past several decades. In the past, psychiatric patients were often hospitalized for six months or more, with some cases involving hospitalization for many years.
",1
371,"Average inpatient psychiatric treatment stay has decreased significantly since the 1960s, a trend known as deinstitutionalization.[80][81][82][83] Today in most countries, people receiving psychiatric treatment are more likely to be seen as outpatients. If hospitalization is required, the average hospital stay is around one to two weeks, with only a small number receiving long-term hospitalization.[citation needed]. However, in Japan psychiatric hospitals continue to keep patients for long periods, sometimes even keeping them in physical restraints, strapped to their beds for periods of weeks or months.[84][85]
",1
372,"Psychiatric inpatients are people admitted to a hospital or clinic to receive psychiatric care. Some are admitted involuntarily, perhaps committed to a secure hospital, or in some jurisdictions to a facility within the prison system. In many countries including the United States and Canada, the criteria for involuntary admission vary with local jurisdiction. They may be as broad as having a mental health condition, or as narrow as being an immediate danger to themselves or others. Bed availability is often the real determinant of admission decisions to hard pressed public facilities. European Human Rights legislation restricts detention to medically certified cases of mental disorder, and adds a right to timely judicial review of detention.[citation needed]
",1
373,"People may be admitted voluntarily if the treating doctor considers that safety isn't compromised by this less restrictive option. Inpatient psychiatric wards may be secure (for those thought to have a particular risk of violence or self-harm) or unlocked/open. Some wards are mixed-sex whilst same-sex wards are increasingly favored to protect women inpatients. Once in the care of a hospital, people are assessed, monitored, and often given medication and care from a multidisciplinary team, which may include physicians, pharmacists, psychiatric nurse practitioners, psychiatric nurses, clinical psychologists, psychotherapists, psychiatric social workers, occupational therapists and social workers. If a person receiving treatment in a psychiatric hospital is assessed as at particular risk of harming themselves or others, they may be put on constant or intermittent one-to-one supervision and may be put in physical restraints or medicated. People on inpatient wards may be allowed leave for periods of time, either accompanied or on their own.[86]
",1
374,"In many developed countries there has been a massive reduction in psychiatric beds since the mid 20th century, with the growth of community care. Standards of inpatient care remain a challenge in some public and private facilities, due to levels of funding, and facilities in developing countries are typically grossly inadequate for the same reason. Even in developed countries, programs in public hospitals vary widely. Some may offer structured activities and therapies offered from many perspectives while others may only have the funding for medicating and monitoring patients. This may be problematic in that the maximum amount of therapeutic work might not actually take place in the hospital setting. This is why hospitals are increasingly used in limited situations and moments of crisis where patients are a direct threat to themselves or others. Alternatives to psychiatric hospitals that may actively offer more therapeutic approaches include rehabilitation centers or ""rehab"" as popularly termed.[citation needed]
",1
375,"Outpatient treatment involves periodic visits to a psychiatrist for consultation in his or her office, or at a community-based outpatient clinic. Initial appointments, at which the psychiatrist conducts a psychiatric assessment or evaluation of the patient, are typically 45 to 75 minutes in length. Follow-up appointments are generally shorter in duration, i.e., 15 to 30 minutes, with a focus on making medication adjustments, reviewing potential medication interactions, considering the impact of other medical disorders on the patient's mental and emotional functioning, and counseling patients regarding changes they might make to facilitate healing and remission of symptoms (e.g., exercise, cognitive therapy techniques, sleep hygiene—to name just a few). The frequency with which a psychiatrist sees people in treatment varies widely, from once a week to twice a year, depending on the type, severity and stability of each person's condition, and depending on what the clinician and patient decide would be best.
",1
376,"Increasingly, psychiatrists are limiting their practices to psychopharmacology (prescribing medications), as opposed to previous practice in which a psychiatrist would provide traditional 50-minute psychotherapy sessions, of which psychopharmacology would be a part, but most of the consultation sessions consisted of ""talk therapy."" This shift began in the early 1980s and accelerated in the 1990s and 2000s.[87] A major reason for this change was the advent of managed care insurance plans, which began to limit reimbursement for psychotherapy sessions provided by psychiatrists. The underlying assumption was that psychopharmacology was at least as effective as psychotherapy, and it could be delivered more efficiently because less time is required for the appointment.[88][89][90][91][92][93] For example, most psychiatrists schedule three or four follow-up appointments per hour, as opposed to seeing one patient per hour in the traditional psychotherapy model.[a] Because of this shift in practice patterns, psychiatrists often refer patients whom they think would benefit from psychotherapy to other mental health professionals, e.g., clinical social workers and psychologists.[94]
",1
377,"The earliest known texts on mental disorders are from ancient India and include the Ayurvedic text, Charaka Samhita.[95][96] The first hospitals for curing mental illness were established in India during the 3rd century BCE.[97]
",1
378,"The Greeks also created early manuscripts about mental disorders.[98] In the 4th century BCE, Hippocrates theorized that physiological abnormalities may be the root of mental disorders.[99] In 4th to 5th Century B.C. Greece, Hippocrates wrote that he visited Democritus and found him in his garden cutting open animals. Democritus explained that he was attempting to discover the cause of madness and melancholy. Hippocrates praised his work. Democritus had with him a book on madness and melancholy.[100] During the 5th century BCE, mental disorders, especially those with psychotic traits, were considered supernatural in origin,[99] a view which existed throughout ancient Greece and Rome,[99] as well as Egyptian regions.[101][page needed] Religious leaders often turned to versions of exorcism to treat mental disorders often utilizing methods that many consider to be cruel or barbaric methods. Trepanning was one of these methods used throughout history.[99]
",1
379,"The Islamic Golden Age fostered early studies in Islamic psychology and psychiatry, with many scholars writing about mental disorders. The Persian physician Muhammad ibn Zakariya al-Razi, also known as ""Rhazes"", wrote texts about psychiatric conditions in the 9th century.[102] As chief physician of a hospital in Baghdad, he was also the director of one of the first psychiatric wards in the world. Two of his works in particular, El-Mansuri and Al-Hawi, provide descriptions and treatments for mental illnesses.[102]
",1
380,"Abu Zayd al-Balkhi, was a Persian polymath during the 9th and 10th centuries and one of the first to classify neurotic disorders. He pioneered cognitive therapy in order to treat each of these classified neurotic disorders. He classified neurosis into four emotional disorders: fear and anxiety, anger and aggression, sadness and depression, and obsession. Al-Balkhi further classified three types of depression: normal depression or sadness (huzn), endogenous depression originating from within the body, and reactive clinical depression originating from outside the body.[103]
",1
381,"The first bimaristan was founded in Baghdad in the 9th century, and several others of increasing complexity were created throughout the Arab world in the following centuries. Some of the bimaristans contained wards dedicated to the care of mentally ill patients,[104] most of whom suffered from debilitating illnesses or exhibited violence.[105] Specialist hospitals such as Bethlem Royal Hospital in London were built in medieval Europe from the 13th century to treat mental disorders, but were used only as custodial institutions and did not provide any type of treatment.[106]
",1
382,"The beginning of psychiatry as a medical specialty is dated to the middle of the nineteenth century,[98] although its germination can be traced to the late eighteenth century. In the late 17th century, privately run asylums for the insane began to proliferate and expand in size. In 1713 the Bethel Hospital Norwich was opened, the first purpose-built asylum in England.[107] In 1656, Louis XIV of France created a public system of hospitals for those suffering from mental disorders, but as in England, no real treatment was applied.[108]
",1
383,"During the Enlightenment attitudes towards the mentally ill began to change. It came to be viewed as a disorder that required compassionate treatment. In 1758 English physician William Battie wrote his Treatise on Madness on the management of mental disorder. It was a critique aimed particularly at the Bethlem Hospital, where a conservative regime continued to use barbaric custodial treatment. Battie argued for a tailored management of patients entailing cleanliness, good food, fresh air, and distraction from friends and family. He argued that mental disorder originated from dysfunction of the material brain and body rather than the internal workings of the mind.[109][110]
",1
384,"The introduction of moral treatment was initiated independently by the French doctor Philippe Pinel and the English Quaker William Tuke.[99] In 1792 Pinel became the chief physician at the Bicêtre Hospital. Patients were allowed to move freely about the hospital grounds, and eventually dark dungeons were replaced with sunny, well-ventilated rooms. Pinel's student and successor, Jean Esquirol (1772–1840), went on to help establish 10 new mental hospitals that operated on the same principles.[111]
",1
385,"Although Tuke, Pinel and others had tried to do away with physical restraint, it remained widespread into the 19th century. At the Lincoln Asylum in England, Robert Gardiner Hill, with the support of Edward Parker Charlesworth, pioneered a mode of treatment that suited ""all types"" of patients, so that mechanical restraints and coercion could be dispensed with — a situation he finally achieved in 1838. In 1839 Sergeant John Adams and Dr. John Conolly were impressed by the work of Hill, and introduced the method into their Hanwell Asylum, by then the largest in the country.[112][113][page needed]
",1
386,"The modern era of institutionalized provision for the care of the mentally ill, began in the early 19th century with a large state-led effort. In England, the Lunacy Act 1845 was an important landmark in the treatment of the mentally ill, as it explicitly changed the status of mentally ill people to patients who required treatment. All asylums were required to have written regulations and to have a resident qualified physician.[114][full citation needed] In 1838, France enacted a law to regulate both the admissions into asylums and asylum services across the country.
In the United States, the erection of state asylums began with the first law for the creation of one in New York, passed in 1842. The Utica State Hospital was opened around 1850. Many state hospitals in the United States were built in the 1850s and 1860s on the Kirkbride Plan, an architectural style meant to have curative effect.[115][page needed]
",1
387,"At the turn of the century, England and France combined had only a few hundred individuals in asylums.[116] By the late 1890s and early 1900s, this number had risen to the hundreds of thousands. However, the idea that mental illness could be ameliorated through institutionalization ran into difficulties.[117] Psychiatrists were pressured by an ever-increasing patient population,[117] and asylums again became almost indistinguishable from custodial institutions.[118]
",1
388,"In the early 1800s, psychiatry made advances in the diagnosis of mental illness by broadening the category of mental disease to include mood disorders, in addition to disease level delusion or irrationality.[119] The 20th century introduced a new psychiatry into the world, with different perspectives of looking at mental disorders. For Emil Kraepelin, the initial ideas behind biological psychiatry, stating that the different mental disorders are all biological in nature, evolved into a new concept of ""nerves"", and psychiatry became a rough approximation of neurology and neuropsychiatry.[120] Following Sigmund Freud's pioneering work, ideas stemming from psychoanalytic theory also began to take root in psychiatry.[121] The psychoanalytic theory became popular among psychiatrists because it allowed the patients to be treated in private practices instead of warehoused in asylums.[121]
",1
389,"By the 1970s, however, the psychoanalytic school of thought became marginalized within the field.[121] Biological psychiatry reemerged during this time. Psychopharmacology became an integral part of psychiatry starting with Otto Loewi's discovery of the neuromodulatory properties of acetylcholine; thus identifying it as the first-known neurotransmitter.[122] Neuroimaging was first utilized as a tool for psychiatry in the 1980s.[123] The discovery of chlorpromazine's effectiveness in treating schizophrenia in 1952 revolutionized treatment of the disorder,[124] as did lithium carbonate's ability to stabilize mood highs and lows in bipolar disorder in 1948.[125] Psychotherapy was still utilized, but as a treatment for psychosocial issues.[126]
",1
390,"In 1963, US president John F. Kennedy introduced legislation delegating the National Institute of Mental Health to administer Community Mental Health Centers for those being discharged from state psychiatric hospitals.[127] Later, though, the Community Mental Health Centers focus shifted to providing psychotherapy for those suffering from acute but less serious mental disorders.[127] Ultimately there were no arrangements made for actively following and treating severely mentally ill patients who were being discharged from hospitals, resulting in a large population of chronically homeless people suffering from mental illness.[127]
",1
391,"Controversy has surrounded psychiatry, with scholars producing critiques. It has been argued that psychiatry: is too influenced by ideas from medicine, causing it to misunderstand the nature of mental distress; that its use of drugs is in part due to lobbying by drug companies resulting in distortion of research; that the concept of ""mental illness"" is often used to label and control those with beliefs and behaviours that the majority of people disagree with; and that it confuses disorders of the mind with disorders of the brain that can be treated with drugs.[128] Critique of psychiatry from within the field comes from the critical psychiatry group in the UK.
",1
392,"The term ""anti-psychiatry"" was coined by psychiatrist David Cooper in 1967 and was later made popular by Thomas Szasz. The word ""Antipsychiatrie"" was already used in Germany in 1904.[129] The basic premise of the anti-psychiatry movement is that psychiatrists attempt to classify ""normal"" people as ""deviant;"" psychiatric treatments are ultimately more damaging than helpful to patients; and psychiatry's history involves (what may now be seen as) dangerous treatments, such as the frontal lobectomy (commonly called a lobotomy).[130] Several former patient groups have been formed often referring to themselves as ""survivors.""[131] In 1973, the Rosenhan experiment was conducted to determine the validity of psychiatric diagnosis. Volunteers feigned hallucinations to enter psychiatric hospitals, and acted normally afterwards. They were diagnosed with psychiatric disorders and were given antipsychotic drugs. The study was conducted by psychologist David Rosenhan, a Stanford University professor, and published by the journal Science under the title ""On being sane in insane places"".[132] However, the neutrality of the project is nowadays often questioned and the project itself is seen by many experts as manipulated.[133][134]
",1
393,"The Church of Scientology is critical of psychiatry, whereas others have questioned the veracity of information the Church of Scientology provides to the public.[135]
",1
394,"
",1
395,"Neurology (from Greek: νεῦρον (neûron), ""string, nerve"" and the suffix -logia, ""study of"") is a branch of medicine dealing with disorders of the nervous system. Neurology deals with the diagnosis and treatment of all categories of conditions and disease involving the central and peripheral nervous systems (and their subdivisions, the autonomic and  somatic nervous systems), including their coverings, blood vessels, and all effector tissue, such as muscle.[1] Neurological practice relies heavily on the field of neuroscience, the scientific study of the nervous system. 
",1
396,"A neurologist is a physician specializing in neurology and trained to investigate, or diagnose and treat neurological disorders.[2] Neurologists may also be involved in clinical research, clinical trials, and basic or translational research. While neurology is a nonsurgical specialty, its corresponding surgical specialty is neurosurgery.[2]
",1
397,"Significant overlap occurs between the fields of neurology and psychiatry, with the boundary between the two disciplines and the conditions they treat being somewhat nebulous.
",1
398,"Many neurological disorders have been described as listed. These can affect the central nervous system (brain and spinal cord), the peripheral nervous system, the autonomic nervous system, and the muscular system.
",1
399,"The academic discipline began between the 15th and 16th centuries with the work and research of many neurologists such as Thomas Willis, Robert Whytt, Matthew Baillie, Charles Bell, Moritz Heinrich Romberg, Duchenne de Boulogne, William A. Hammond, Jean-Martin Charcot, and John Hughlings Jackson.
",1
400," Many neurologists also have additional training or interest in one area of neurology, such as stroke, epilepsy, neuromuscular, sleep medicine, pain management, or movement disorders.
",1
401,"In the United States and Canada, neurologists are physicians having completed postgraduate training in neurology after graduation from medical school. Neurologists complete, on average, about 8 years of medical college education and clinical training, which includes obtaining a four-year undergraduate degree, a medical degree (DO or MD), which comprises an additional four years of study, then completing one year of basic clinical training and four years of residency.[6] The four-year residency consists of one year of internal medicine internship training followed by three years of training in neurology.
",1
402,"Some neurologists receive additional subspecialty training focusing on a particular area of the fields.  These training programs are called fellowships, and are one to two years in duration.  Subspecialties include brain injury medicine, clinical neurophysiology, epilepsy, hospice and palliative medicine, neurodevelopmental disabilities, neuromuscular medicine, pain medicine, sleep medicine, neurocritical care, vascular neurology (stroke),[7] behavioral neurology, child neurology, headache, multiple sclerosis, neuroimaging, neurorehabilitation.
",1
403,"In Germany, a compulsory year of psychiatry must be done to complete a residency of neurology.[citation needed]
",1
404,"In the United Kingdom and Ireland, neurology is a subspecialty of general (internal) medicine. After five years of medical school and two years as a Foundation Trainee, an aspiring neurologist must pass the examination for Membership of the Royal College of Physicians (or the Irish equivalent) and complete two years of core medical training before entering specialist training in neurology. Up to the 1960s, some intending to become neurologists would also spend two years working in psychiatric units before obtaining a diploma in psychological medicine.  However, that was uncommon and, now that the MRCPsych takes three years to obtain, would no longer be practical. A period of research is essential, and obtaining a higher degree aids career progression. Many found it was eased after an attachment to the Institute of Neurology at Queen Square, London. Some neurologists enter the field of rehabilitation medicine (known as physiatry in the US) to specialise in neurological rehabilitation, which may include stroke medicine, as well as brain injuries.[citation needed]
",1
405,"During a neurological examination, the neurologist reviews the patient's health history with special attention to the current condition. The patient then takes a neurological exam. Typically, the exam tests mental status, function of the cranial nerves (including vision), strength, coordination, reflexes, and sensation. This information helps the neurologist determine whether the problem exists in the nervous system and the clinical localization. Localization of the pathology is the key process by which neurologists develop their differential diagnosis. Further tests may be needed to confirm a diagnosis and ultimately guide therapy and appropriate management.
",1
406,"Neurologists examine patients who are referred to them by other physicians in both the inpatient and outpatient settings. Neurologists begin their interactions with patients by taking a comprehensive medical history, and then performing a physical examination focusing on evaluating the nervous system. Components of the neurological examination include assessment of the patient's cognitive function, cranial nerves, motor strength, sensation, reflexes, coordination, and gait.
",1
407,"In some instances, neurologists may order additional diagnostic tests as part of the evaluation. Commonly employed tests in neurology include imaging studies such as computed axial tomography (CAT) scans, magnetic resonance imaging (MRI), and ultrasound of major blood vessels of the head and neck. Neurophysiologic studies, including electroencephalography (EEG), needle electromyography (EMG), nerve conduction studies (NCSs) and evoked potentials are also commonly ordered. Neurologists frequently perform lumbar punctures to assess characteristics of a patient's cerebrospinal fluid.  Advances in genetic testing have made genetic testing an important tool in the classification of inherited neuromuscular disease and diagnosis of many other neurogenetic diseases.  The role of genetic influences on the development of acquired neurologic diseases is an active area of research.
",1
408,"Some of the commonly encountered conditions treated by neurologists include headaches, radiculopathy, neuropathy, stroke, dementia, seizures and epilepsy, Alzheimer's disease, attention deficit/hyperactivity disorder,[8] Parkinson's disease, Tourette's syndrome, multiple sclerosis, head trauma, sleep disorders, neuromuscular diseases, and various infections and tumors of the nervous system.  Neurologists are also asked to evaluate unresponsive patients on life support to confirm brain death.
",1
409,"Treatment options vary depending on the neurological problem. They can include referring the patient to a physiotherapist, prescribing medications, or recommending a surgical procedure.
",1
410,"Some neurologists specialize in certain parts of the nervous system or in specific procedures. For example, clinical neurophysiologists specialize in the use of EEG and intraoperative monitoring to diagnose certain neurological disorders.[9] Other neurologists specialize in the use of electrodiagnostic medicine studies – needle EMG and NCSs.  In the US, physicians do not typically specialize in all the aspects of clinical neurophysiology – i.e. sleep, EEG, EMG, and NCSs.  The American Board of Clinical Neurophysiology certifies US physicians in general clinical neurophysiology, epilepsy, and intraoperative monitoring.[10] The American Board of Electrodiagnostic Medicine certifies US physicians in electrodiagnostic medicine and certifies technologists in nerve-conduction studies.[11] Sleep medicine is a subspecialty field in the US under several medical specialties including anesthesiology, internal medicine, family medicine, and neurology.[12] Neurosurgery is a distinct specialty that involves a different training path, and emphasizes the surgical treatment of neurological disorders.
",1
411,"Also, many nonmedical doctors, those with doctoral degrees (usually PhDs) in subjects such as biology and chemistry, study and research the nervous system. Working in laboratories in universities, hospitals, and private companies, these neuroscientists perform clinical and laboratory experiments and tests to learn more about the nervous system and find cures or new treatments for diseases and disorders.
",1
412,"A great deal of overlap occurs between neuroscience and neurology. Many neurologists work in academic training hospitals, where they conduct research as neuroscientists in addition to treating patients and teaching neurology to medical students.
",1
413,"Neurologists are responsible for the diagnosis, treatment, and management of all the conditions mentioned above. When surgical or endovascular intervention is required, the neurologist may refer the patient to a neurosurgeon or an interventional neuroradiologist. In some countries, additional legal responsibilities of a neurologist may include making a finding of brain death when it is suspected that a patient has died. Neurologists frequently care for people with hereditary (genetic) diseases when the major manifestations are neurological, as is frequently the case. Lumbar punctures are frequently performed by neurologists. Some neurologists may develop an interest in particular subfields, such as stroke, dementia, movement disorders, neurointensive care, headaches, epilepsy, sleep disorders, chronic pain management, multiple sclerosis, or neuromuscular diseases.
",1
414,"Some overlap also occurs with other specialties, varying from country to country and even within a local geographic area. Acute head trauma is most often treated by neurosurgeons, whereas sequelae of head trauma may be treated by neurologists or specialists in rehabilitation medicine. Although stroke cases have been traditionally managed by internal medicine or hospitalists, the emergence of vascular neurology and interventional neuroradiology has created a demand for stroke specialists. The establishment of Joint Commission-certified stroke centers has increased the role of neurologists in stroke care in many primary, as well as tertiary, hospitals. Some cases of nervous system infectious diseases are treated by infectious disease specialists. Most cases of headache are diagnosed and treated primarily by general practitioners, at least the less severe cases. Likewise, most cases of sciatica are treated by general practitioners, though they may be referred to neurologists or  surgeons (neurosurgeons or orthopedic surgeons). Sleep disorders are also treated by pulmonologists and psychiatrists. Cerebral palsy is initially treated by pediatricians, but care may be transferred to an adult neurologist after the patient reaches a certain age. Physical medicine and rehabilitation physicians may treat patients with neuromuscular diseases with electrodiagnostic studies (needle EMG and nerve-conduction studies) and other diagnostic tools. In the United Kingdom and other countries, many of the conditions encountered by older patients such as movement disorders, including Parkinson's disease, stroke, dementia, or gait disorders, are managed predominantly by specialists in geriatric medicine.
",1
415,"Clinical neuropsychologists are often called upon to evaluate brain-behavior relationships for the purpose of assisting with differential diagnosis, planning rehabilitation strategies, documenting cognitive strengths and weaknesses, and measuring change over time (e.g., for identifying abnormal aging or tracking the progression of a dementia)
",1
416,"In some countries such as the United States and Germany, neurologists may subspecialize in clinical neurophysiology, the field responsible for EEG and intraoperative monitoring, or in electrodiagnostic medicine nerve conduction studies, EMG, and evoked potentials. In other countries, this is an autonomous specialty (e.g., United Kingdom, Sweden, Spain).
",1
417,"Although mental illnesses are believed by many to be neurological disorders affecting the central nervous system, traditionally they are classified separately, and treated by psychiatrists. In a 2002 review article in the American Journal of Psychiatry, Professor Joseph B. Martin, Dean of Harvard Medical School and a neurologist by training, wrote, ""the separation of the two categories is arbitrary, often influenced by beliefs rather than proven scientific observations. And the fact that the brain and mind are one makes the separation artificial anyway"".[13]
",1
418,"Neurological disorders often have psychiatric manifestations, such as poststroke depression, depression and dementia associated with Parkinson's disease, mood and cognitive dysfunctions in Alzheimer's disease, and Huntington disease, to name a few. Hence, the sharp distinction between neurology and psychiatry is not always on a biological basis. The dominance of psychoanalytic theory in the first three-quarters of the 20th century has since then been largely replaced by a focus on pharmacology.[citation needed] Despite the shift to a medical model, brain science has not advanced to a point where scientists or clinicians can point to readily discernible pathological lesions or genetic abnormalities that in and of themselves serve as reliable or predictive biomarkers of a given mental disorder.
",1
419,"The emerging field of neurological enhancement highlights the potential of therapies to improve such things as workplace efficacy, attention in school, and overall happiness in personal lives.[14] However, this field has also given rise to questions about neuroethics and the psychopharmacology of lifestyle drugs can have negative and positive effects on neurology because different types 
of drugs can depend on people and their lives [Cheyanne l.dorsey]
",1
420,"
",1
421,"The human musculoskeletal system (also known as the human locomotor system, and previously the activity system[1]) is an organ system that gives humans the ability to move using their muscular and skeletal systems. The musculoskeletal system provides form, support, stability, and movement to the body.
",1
422,"It is made up of the bones of the skeleton, muscles, cartilage,[2] tendons, ligaments, joints, and other connective tissue that supports and binds tissues and organs together. The musculoskeletal system's primary functions include supporting the body, allowing motion, and protecting vital organs.[3] The skeletal portion of the system serves as the main storage system for calcium and phosphorus and contains critical components of the hematopoietic system.[4]
",1
423,"This system describes how bones are connected to other bones and muscle fibers via connective tissue such as tendons and ligaments. The bones provide stability to the body. Muscles keep bones in place and also play a role in the movement of bones. To allow motion, different bones are connected by joints.  Cartilage prevents the bone ends from rubbing directly onto each other. Muscles contract to move the bone attached at the joint.
",1
424,"There are, however, diseases and disorders that may adversely affect the function and overall effectiveness of the system. These diseases can be difficult to diagnose due to the close relation of the musculoskeletal system to other internal systems. The musculoskeletal system refers to the system having its muscles attached to an internal skeletal system and is necessary for humans to move to a more favorable position. Complex issues and injuries involving the musculoskeletal system are usually handled by a physiatrist (specialist in physical medicine and rehabilitation) or an orthopaedic surgeon.
",1
425,"The skeletal system serves many important functions; it provides the shape and form for the body, support and protection, allows bodily movement, produces blood for the body, and stores minerals.[5] The number of bones in the human skeletal system is a controversial topic. Humans are born with over 300 bones; however, many bones fuse together between birth and maturity. As a result, an average adult skeleton consists of 206 bones. The number of bones varies according to the method used to derive the count. While some consider certain structures to be a single bone with multiple parts, others may see it as a single part with multiple bones.[6] There are five general classifications of bones. These are long bones, short bones, flat bones, irregular bones, and sesamoid bones. The human skeleton is composed of both fused and individual bones supported by ligaments, tendons, muscles and cartilage. It is a complex structure with two distinct divisions; the axial skeleton, which includes the vertebral column, and the appendicular skeleton.[7]
",1
426,"The skeletal system serves as a framework for tissues and organs to attach themselves to. This system acts as a protective structure for vital organs. Major examples of this are the brain being protected by the skull and the lungs being protected by the rib cage.
",1
427,"Located in long bones are two distinctions of bone marrow (yellow and red). The yellow marrow has fatty connective tissue and is found in the marrow cavity. During starvation, the body uses the fat in yellow marrow for energy.[8] The red marrow of some bones is an important site for blood cell production, approximately 2.6 million red blood cells per second in order to replace existing cells that have been destroyed by the liver.[5] Here all erythrocytes, platelets, and most leukocytes form in adults. From the red marrow, erythrocytes, platelets, and leukocytes migrate to the blood to do their special tasks.
",1
428,"Another function of bones is the storage of certain minerals. Calcium and phosphorus are among the main minerals being stored. The importance of this storage ""device"" helps to regulate mineral balance in the bloodstream. When the fluctuation of minerals is high, these minerals are stored in bone; when it is low it will be withdrawn from the bone.
",1
429,"There are three types of muscles—cardiac, skeletal, and smooth. Smooth muscles are used to control the flow of substances within the lumens of hollow organs, and are not consciously controlled. Skeletal and cardiac muscles have striations that are visible under a microscope due to the components within their cells. Only skeletal and smooth muscles are part of the musculoskeletal system and only the skeletal muscles can move the body. Cardiac muscles are found in the heart and are used only to circulate blood; like the smooth muscles, these muscles are not under conscious control. Skeletal muscles are attached to bones and arranged in opposing groups around joints.[9]  Muscles are innervated, to communicate nervous energy to,[10] by nerves, which conduct electrical currents from the central nervous system and cause the muscles to contract.[11]
",1
430,"In mammals, when a muscle contracts, a series of reactions occur. Muscle contraction is stimulated by the motor neuron sending a message to the muscles from the somatic nervous system. Depolarization of the motor neuron results in neurotransmitters being released from the nerve terminal. The space between the nerve terminal and the muscle cell is called the neuromuscular junction. These neurotransmitters diffuse across the synapse and bind to specific receptor sites on the cell membrane of the muscle fiber. When enough receptors are stimulated, an  action potential is generated and the permeability of the sarcolemma is altered. This process is known as initiation.[12]
",1
431,"A tendon is a tough, flexible band of fibrous connective tissue that connects muscles to bones.[13]  The extra-cellular connective tissue between muscle fibers binds to tendons at the distal and proximal ends, and the tendon binds to the periosteum of individual bones at the muscle's origin and insertion. As muscles contract, tendons transmit the forces to the relatively rigid bones, pulling on them and causing movement.  Tendons can stretch substantially, allowing them to function as springs during locomotion, thereby saving energy.
",1
432,"Joints are structures that connect individual bones and may allow bones to move against each other to cause movement. There are three divisions of joints, diarthroses which allow extensive mobility between two or more articular heads; amphiarthrosis, which is a joint that allows some movement, and false joints or synarthroses, joints that are immovable, that allow little or no movement and are predominantly fibrous. Synovial joints, joints that are not directly joined, are lubricated by a solution called synovial fluid that is produced by the synovial membranes. This fluid lowers the friction between the articular surfaces and is kept within an articular capsule, binding the joint with its taut tissue.[7]
",1
433,"A ligament is a small band of dense, white, fibrous elastic tissue.[7]  Ligaments connect the ends of bones together in order to form a joint. Most ligaments limit dislocation, or prevent certain movements that may cause breaks. Since they are only elastic they increasingly lengthen when under pressure. When this occurs the ligament may be susceptible to break resulting in an unstable joint.
",1
434,"Ligaments may also restrict some actions: movements such as hyper extension and hyper flexion are restricted by ligaments to an extent. Also ligaments prevent certain directional movement.[14]
",1
435,"A bursa is a small fluid-filled sac made of white fibrous tissue and lined with synovial membrane. Bursa may also be formed by a synovial membrane that extends outside of the joint capsule.[8] It provides a cushion between bones and tendons or muscles around a joint; bursa are filled with synovial fluid and are found around almost every major joint of the body.
",1
436,"Because many other body systems, including the vascular, nervous, and integumentary systems, are interrelated, disorders of one of these systems may also affect the musculoskeletal system and complicate the diagnosis of the disorder's origin. Diseases of the musculoskeletal system mostly encompass functional disorders or motion discrepancies; the level of impairment depends specifically on the problem and its severity. In a study of hospitalizations in the United States, the most common inpatient OR procedures in 2012 involved the musculoskeletal system: knee arthroplasty, laminectomy, hip replacement, and spinal fusion.[16]
",1
437,"Articular (of or pertaining to the joints)[17] disorders are the most common. However, also among the diagnoses are: primary muscular diseases, neurologic (related to the medical science that deals with the nervous system and disorders affecting it)[18] deficits, toxins, endocrine abnormalities, metabolic disorders, infectious diseases, blood and vascular disorders, and nutritional imbalances.
",1
438,"Disorders of muscles from another body system can bring about irregularities such as: impairment of ocular motion and control, respiratory dysfunction, and bladder malfunction. Complete paralysis, paresis, or ataxia may be caused by primary muscular dysfunctions of infectious or toxic origin; however, the primary disorder is usually related to the nervous system, with the muscular system acting as the effector organ, an organ capable of responding to a stimulus, especially a nerve impulse.[4]
",1
439,"One understated disorder that begins during pregnancy is pelvic girdle pain. It is complex, multi-factorial, and likely to be also represented by a series of sub-groups driven by pain varying from peripheral or central nervous system,[19] altered laxity/stiffness of muscles,[20] laxity to injury of tendinous/ligamentous structures[21]
to maladaptive body mechanics.[19]
",1
440,"
",1
441,"The circulatory system, also called the cardiovascular system or the vascular system, is an organ system that permits blood to circulate and transport nutrients (such as amino acids and electrolytes), oxygen, carbon dioxide, hormones, and blood cells to and from the cells in the body to provide nourishment and help in fighting diseases, stabilize temperature and pH, and maintain homeostasis.
",1
442,"The circulatory system includes the lymphatic system, which circulates lymph.[1] The passage of lymph takes much longer than that of blood.[2] Blood is a fluid consisting of plasma, red blood cells, white blood cells, and platelets that is circulated by the heart through the vertebrate vascular system, carrying oxygen and nutrients to and waste materials away from all body tissues. Lymph is essentially recycled excess blood plasma after it has been filtered from the interstitial fluid (between cells) and returned to the lymphatic system. The cardiovascular (from Latin words meaning ""heart"" and ""vessel"") system comprises the blood, heart, and blood vessels.[3] The lymph, lymph nodes, and lymph vessels form the lymphatic system, which returns filtered blood plasma from the interstitial fluid (between cells) as lymph.
",1
443,"The circulatory system of the blood is seen as having two components, a systemic circulation and a pulmonary circulation.[4]
",1
444,"While humans, as well as other vertebrates, have a closed cardiovascular system (meaning that the blood never leaves the network of arteries, veins and capillaries), some invertebrate groups have an open cardiovascular system. The lymphatic system, on the other hand, is an open system providing an accessory route for excess interstitial fluid to be returned to the blood.[5] The more primitive, diploblastic animal phyla lack circulatory systems.
",1
445,"Many diseases affect the circulatory system. This includes cardiovascular disease, affecting the cardiovascular system, and lymphatic disease affecting the lymphatic system. Cardiologists are medical professionals which specialise in the heart, and cardiothoracic surgeons specialise in operating on the heart and its surrounding areas. Vascular surgeons focus on other parts of the circulatory system.
",1
446,"
",1
447,"The essential components of the human cardiovascular system are the heart, blood and blood vessels.[6] It includes the pulmonary circulation, a ""loop"" through the lungs where blood is oxygenated; and the systemic circulation, a ""loop"" through the rest of the body to provide oxygenated blood. The systemic circulation can also be seen to function in two parts – a macrocirculation and a microcirculation. An average adult contains five to six quarts (roughly 4.7 to 5.7 liters) of blood, accounting for approximately 7% of their total body weight.[7] Blood consists of plasma, red blood cells, white blood cells, and platelets. Also, the digestive system works with the circulatory system to provide the nutrients the system needs to keep the heart pumping.[8]
",1
448,"The cardiovascular systems of humans are closed, meaning that the blood never leaves the network of blood vessels. In contrast, oxygen and nutrients diffuse across the blood vessel layers and enter interstitial fluid, which carries oxygen and nutrients to the target cells, and carbon dioxide and wastes in the opposite direction. The other component of the circulatory system, the lymphatic system, is open.
",1
449,"Oxygenated blood enters the systemic circulation when leaving the left ventricle, through the aortic semilunar valve. The first part of the systemic circulation is the aorta, a massive and thick-walled artery. The aorta arches and gives branches supplying the upper part of the body after passing through the aortic opening of the diaphragm at the level of thoracic ten vertebra, it enters the abdomen. Later it descends down and supplies branches to abdomen, pelvis, perineum and the lower limbs. The walls of aorta are elastic. This elasticity helps to maintain the blood pressure throughout the body. When the aorta receives almost five litres of blood from the heart, it recoils and is responsible for pulsating blood pressure. Moreover, as aorta branches into smaller arteries, their elasticity goes on decreasing and their compliance goes on increasing.
",1
450,"Arteries branch into small passages called arterioles and then into the capillaries.[9] The capillaries merge to bring blood into the venous system.[10]
",1
451,"Capillaries merge into venules, which merge into veins. The venous system feeds into the two major veins: the superior vena cava – which mainly drains tissues above the heart – and the inferior vena cava – which mainly drains tissues below the heart. These two large veins empty into the right atrium of the heart.
",1
452,"The general rule is that arteries from the heart branch out into capillaries, which collect into veins leading back to the heart. Portal veins are a slight exception to this. In humans the only significant example is the hepatic portal vein which combines from capillaries around the gastrointestinal tract where the blood absorbs the various products of digestion; rather than leading directly back to the heart, the hepatic portal vein branches into a second capillary system in the liver.
",1
453,"The heart pumps oxygenated blood to the body and deoxygenated blood to the lungs. In the human heart there is one atrium and one ventricle for each circulation, and with both a systemic and a pulmonary circulation there are four chambers in total: left atrium, left ventricle, right atrium and right ventricle. The right atrium is the upper chamber of the right side of the heart. The blood that is returned to the right atrium is deoxygenated (poor in oxygen) and passed into the right ventricle to be pumped through the pulmonary artery to the lungs for re-oxygenation and removal of carbon dioxide. The left atrium receives newly oxygenated blood from the lungs as well as the pulmonary vein which is passed into the strong left ventricle to be pumped through the aorta to the different organs of the body.
",1
454,"The heart itself is supplied with oxygen and nutrients through a small ""loop"" of the systemic circulation and derives very little from the blood contained within the four chambers.
The coronary circulation system provides a blood supply to the heart muscle itself. The coronary circulation begins near the origin of the aorta by two coronary arteries: the right coronary artery and the left coronary artery. After nourishing the heart muscle, blood returns through the coronary veins into the coronary sinus and from this one into the right atrium. Back flow of blood through its opening during atrial systole is prevented by Thebesian valve. The smallest cardiac veins drain directly into the heart chambers.[8]
",1
455,"The circulatory system of the lungs is the portion of the cardiovascular system in which oxygen-depleted blood is pumped away from the heart, via the pulmonary artery, to the lungs and returned, oxygenated, to the heart via the pulmonary vein.
",1
456,"Oxygen deprived blood from the superior and inferior vena cava enters the right atrium of the heart and flows through the tricuspid valve (right atrioventricular valve) into the right ventricle, from which it is then pumped through the pulmonary semilunar valve into the pulmonary artery to the lungs. Gas exchange occurs in the lungs, whereby CO2 is released from the blood, and oxygen is absorbed. The pulmonary vein returns the now oxygen-rich blood to the left atrium.[8]
",1
457,"A separate system known as the bronchial circulation supplies blood to the tissue of the larger airways of the lung.
",1
458,"Systemic circulation is the portion of the cardiovascular system which transports oxygenated blood away from the heart through the aorta from the left ventricle where the blood has been previously deposited from pulmonary circulation, to the rest of the body, and returns oxygen-depleted blood back to the heart.[8]
",1
459,"The brain has a dual blood supply that comes from arteries at its front and back. These are called the ""anterior"" and ""posterior"" circulation respectively. The anterior circulation arises from the internal carotid arteries and supplies the front of the brain. The posterior circulation arises from the vertebral arteries, and supplies the back of the brain and brainstem. The circulation from the front and the back join together (anastomise) at the Circle of Willis.
",1
460,"The renal circulation receives around 20% of the cardiac output. It branches from the abdominal aorta and returns blood to the ascending vena cava. It is the blood supply to the kidneys, and contains many specialized blood vessels.
",1
461,"The lymphatic system is part of the circulatory system in many complex animals such as mammals and birds. It is a network of lymphatic vessels and lymph capillaries, lymph nodes and organs, and lymphatic tissues and circulating lymph. One of its major functions is to carry the lymph, draining and returning interstitial fluid back towards the heart for return to the cardiovascular system, by emptying into the lymphatic ducts. Its other main function is in the adaptive immune system.[11]
",1
462,"The development of the circulatory system starts with vasculogenesis in the embryo. The human arterial and venous systems develop from different areas in the embryo. The arterial system develops mainly from the aortic arches, six pairs of arches which develop on the upper part of the embryo. The venous system arises from three bilateral veins during weeks 4 – 8 of embryogenesis. Fetal circulation begins within the 8th week of development. Fetal circulation does not include the lungs, which are bypassed via the truncus arteriosus. Before birth the fetus obtains oxygen (and nutrients) from the mother through the placenta and the umbilical cord.[12]
",1
463,"The human arterial system originates from the aortic arches and from the dorsal aortae starting from week 4 of embryonic life. The first and second aortic arches regress and forms only the maxillary arteries and stapedial arteries respectively. The arterial system itself arises from aortic arches 3, 4 and 6 (aortic arch 5 completely regresses).
",1
464,"The dorsal aortae, present on the dorsal side of the embryo, are initially present on both sides of the embryo. They later fuse to form the basis for the aorta itself. Approximately thirty smaller arteries branch from this at the back and sides. These branches form the intercostal arteries, arteries of the arms and legs, lumbar arteries and the lateral sacral arteries. Branches to the sides of the aorta will form the definitive renal, suprarenal and gonadal arteries. Finally, branches at the front of the aorta consist of the vitelline arteries and umbilical arteries. The vitelline arteries form the celiac, superior and inferior mesenteric arteries of the gastrointestinal tract. After birth, the umbilical arteries will form the internal iliac arteries.
",1
465,"The human venous system develops mainly from the vitelline veins, the umbilical veins and the cardinal veins, all of which empty into the sinus venosus.
",1
466,"About 98.5% of the oxygen in a sample of arterial blood in a healthy human, breathing air at sea-level pressure, is chemically combined with hemoglobin molecules. About 1.5% is physically dissolved in the other blood liquids and not connected to hemoglobin. The hemoglobin molecule is the primary transporter of oxygen in mammals and many other species.
",1
467,"
Many diseases affect the circulatory system. These include a number of cardiovascular diseases, affecting the cardiovascular system, and lymphatic diseases affecting the lymphatic system. Cardiologists are medical professionals which specialise in the heart, and cardiothoracic surgeons specialise in operating on the heart and its surrounding areas. Vascular surgeons focus on other parts of the circulatory system.
",1
468,"Diseases affecting the cardiovascular system are called cardiovascular disease.
",1
469,"Many of these diseases are called ""lifestyle diseases"" because they develop over time and are related to a person's exercise habits, diet, whether they smoke, and other lifestyle choices a person makes. Atherosclerosis is the precursor to many of these diseases. It is where small atheromatous plaques build up in the walls of medium and large arteries. This may eventually grow or rupture to occlude the arteries. It is also a risk factor for acute coronary syndromes, which are diseases that are characterised by a sudden deficit of oxygenated blood to the heart tissue. Atherosclerosis is also associated with problems such as aneurysm formation or splitting (""dissection"") of arteries.
",1
470,"Another major cardiovascular disease involves the creation of a clot, called a ""thrombus"". These can originate in veins or arteries. Deep venous thrombosis, which mostly occurs in the legs, is one cause of clots in the veins of the legs, particularly when a person has been stationary for a long time. These clots may embolise, meaning travel to another location in the body. The results of this may include pulmonary embolus, transient ischaemic attacks, or stroke.
",1
471,"Cardiovascular diseases may also be congenital in nature, such as heart defects or persistent fetal circulation, where the circulatory changes that are supposed to happen after birth do not. Not all congenital changes to the circulatory system are associated with diseases, a large number are anatomical variations.
",1
472,"The function and health of the circulatory system and its parts are measured in a variety of manual and automated ways. These include simple methods such as those that are part of the cardiovascular examination, including the taking of a person's pulse as an indicator of a person's heart rate, the taking of blood pressure through a sphygmomanometer or the use of a stethoscope to listen to the heart for murmurs which may indicate problems with the heart's valves. An electrocardiogram can also be used to evaluate the way in which electricity is conducted through the heart.
",1
473,"Other more invasive means can also be used. A cannula or catheter inserted into an artery may be used to measure pulse pressure or pulmonary wedge pressures. Angiography, which involves injecting a dye into an artery to visualise an arterial tree, can be used in the heart (coronary angiography) or brain. At the same time as the arteries are visualised, blockages or narrowings may be fixed through the insertion of stents, and active bleeds may be managed by the insertion of coils. An MRI may be used to image arteries, called an MRI angiogram. For evaluation of the blood supply to the lungs a CT pulmonary angiogram may be used.
",1
474,"Vascular ultrasonography include for example:
",1
475,"There are a number of surgical procedures performed on the circulatory system:
",1
476,"Cardiovascular procedures are more likely to be performed in an inpatient setting than in an ambulatory care setting; in the United States, only 28% of cardiovascular surgeries were performed in the ambulatory care setting.[13]
",1
477,"In Ancient Greece, the heart was thought to be the source of innate heat for the body.
The circulatory system as we know it was discovered by William Harvey.
",1
478,"While humans, as well as other vertebrates, have a closed blood circulatory system (meaning that the blood never leaves the network of arteries, veins and capillaries), some invertebrate groups have an open circulatory system containing a heart but limited blood vessels. The most primitive, diploblastic animal phyla lack circulatory systems.
",1
479,"An additional transport system, the lymphatic system, which is only found in animals with a closed blood circulation,  is an open system providing an accessory route for excess interstitial fluid to be returned to the blood.[5]
",1
480,"The blood vascular system first appeared probably in an ancestor of the triploblasts over 600 million years ago, overcoming the time-distance constraints of diffusion, while endothelium evolved in an ancestral vertebrate some 540–510 million years ago.[14]
",1
481,"In arthropods, the open circulatory system is a system in which a fluid in a cavity called the hemocoel bathes the organs directly with oxygen and nutrients, with there being no distinction between blood and interstitial fluid; this combined fluid is called hemolymph or haemolymph.[15] Muscular movements by the animal during locomotion can facilitate hemolymph movement, but diverting flow from one area to another is limited. When the heart relaxes, blood is drawn back toward the heart through open-ended pores (ostia).
",1
482,"Hemolymph fills all of the interior hemocoel of the body and surrounds all cells. Hemolymph is composed of water, inorganic salts (mostly sodium, chloride, potassium, magnesium, and calcium), and organic compounds (mostly carbohydrates, proteins, and lipids). The primary oxygen transporter molecule is hemocyanin.
",1
483,"There are free-floating cells, the hemocytes, within the hemolymph. They play a role in the arthropod immune system.
",1
484,"The circulatory systems of all vertebrates, as well as of annelids (for example, earthworms) and cephalopods (squids, octopuses and relatives) always keep their circulating blood enclosed within heart chambers or blood vessels and are classified as closed, just as in humans. Still, the systems of fish, amphibians, reptiles, and birds show various stages of the evolution of the circulatory system.[16] Closed systems permit blood to be directed to the organs that require it.
",1
485,"In fish, the system has only one circuit, with the blood being pumped through the capillaries of the gills and on to the capillaries of the body tissues. This is known as single cycle circulation. The heart of fish is, therefore, only a single pump (consisting of two chambers).
",1
486,"In amphibians and most reptiles, a double circulatory system is used, but the heart is not always completely separated into two pumps. Amphibians have a three-chambered heart.
",1
487,"In reptiles, the ventricular septum of the heart is incomplete and the pulmonary artery is equipped with a sphincter muscle. This allows a second possible route of blood flow. Instead of blood flowing through the pulmonary artery to the lungs, the sphincter may be contracted to divert this blood flow through the incomplete ventricular septum into the left ventricle and out through the aorta. This means the blood flows from the capillaries to the heart and back to the capillaries instead of to the lungs. This process is useful to ectothermic (cold-blooded) animals in the regulation of their body temperature.
",1
488,"Birds, mammals, and crocodilians show complete separation of the heart into two pumps, for a total of four heart chambers; it is thought that the four-chambered heart of birds and crocodilians evolved independently from that of mammals.[17] Double circulatory systems permit blood to be repressurized after returning from the lungs, speeding up delivery of oxygen to tissues.
",1
489,"Circulatory systems are absent in some animals, including flatworms. Their body cavity has no lining or enclosed fluid. Instead a muscular pharynx leads to an extensively branched digestive system that facilitates direct diffusion of nutrients to all cells. The flatworm's dorso-ventrally flattened body shape also restricts the distance of any cell from the digestive system or the exterior of the organism. Oxygen can diffuse from the surrounding water into the cells, and carbon dioxide can diffuse out. Consequently, every cell is able to obtain nutrients, water and oxygen without the need of a transport system.
",1
490,"Some animals, such as jellyfish, have more extensive branching from their gastrovascular cavity (which functions as both a place of digestion and a form of circulation), this branching allows for bodily fluids to reach the outer layers, since the digestion begins in the inner layers.
",1
491,"The earliest known writings on the circulatory system are found in the Ebers Papyrus (16th century BCE), an ancient Egyptian medical papyrus containing over 700 prescriptions and remedies, both physical and spiritual. In the papyrus, it acknowledges the connection of the heart to the arteries. The Egyptians thought air came in through the mouth and into the lungs and heart. From the heart, the air travelled to every member through the arteries. Although this concept of the circulatory system is only partially correct, it represents one of the earliest accounts of scientific thought.
",1
492,"In the 6th century BCE, the knowledge of circulation of vital fluids through the body was known to the Ayurvedic physician Sushruta in ancient India.[18] He also seems to have possessed knowledge of the arteries, described as 'channels' by Dwivedi & Dwivedi (2007).[18] The valves of the heart were discovered by a physician of the Hippocratean school around the 4th century BCE. However their function was not properly understood then. Because blood pools in the veins after death, arteries look empty. Ancient anatomists assumed they were filled with air and that they were for transport of air.
",1
493,"The Greek physician, Herophilus, distinguished veins from arteries but thought that the pulse was a property of arteries themselves. Greek anatomist Erasistratus observed that arteries that were cut during life bleed. He ascribed the fact to the phenomenon that air escaping from an artery is replaced with blood that entered by very small vessels between veins and arteries. Thus he apparently postulated capillaries but with reversed flow of blood.[19]
",1
494,"In 2nd century AD Rome, the Greek physician Galen knew that blood vessels carried blood and identified venous (dark red) and arterial (brighter and thinner) blood, each with distinct and separate functions. Growth and energy were derived from venous blood created in the liver from chyle, while arterial blood gave vitality by containing pneuma (air) and originated in the heart. Blood flowed from both creating organs to all parts of the body where it was consumed and there was no return of blood to the heart or liver. The heart did not pump blood around, the heart's motion sucked blood in during diastole and the blood moved by the pulsation of the arteries themselves.
",1
495,"Galen believed that the arterial blood was created by venous blood passing from the left ventricle to the right by passing through 'pores' in the interventricular septum, air passed from the lungs via the pulmonary artery to the left side of the heart. As the arterial blood was created 'sooty' vapors were created and passed to the lungs also via the pulmonary artery to be exhaled.
",1
496,"In 1025, The Canon of Medicine by the Persian physician, Avicenna, ""erroneously accepted the Greek notion regarding the existence of a hole in the ventricular septum by which the blood traveled between the ventricles."" Despite this, Avicenna ""correctly wrote on the cardiac cycles and valvular function"", and ""had a vision of blood circulation"" in his Treatise on Pulse.[20][verification needed] While also refining Galen's erroneous theory of the pulse, Avicenna provided the first correct explanation of pulsation: ""Every beat of the pulse comprises two movements and two pauses. Thus, expansion : pause : contraction : pause. [...] The pulse is a movement in the heart and arteries ... which takes the form of alternate expansion and contraction.""[21]
",1
497,"In 1242, the Arabian physician, Ibn al-Nafis, became the first person to accurately describe the process of pulmonary circulation, for which he is sometimes considered the father of circulatory physiology.[22][failed verification] Ibn al-Nafis stated in his Commentary on Anatomy in Avicenna's Canon:
",1
498,"""...the blood from the right chamber of the heart must arrive at the left chamber but there is no direct pathway between them. The thick septum of the heart is not perforated and does not have visible pores as some people thought or invisible pores as Galen thought. The blood from the right chamber must flow through the vena arteriosa (pulmonary artery) to the lungs, spread through its substances, be mingled there with air, pass through the arteria venosa (pulmonary vein) to reach the left chamber of the heart and there form the vital spirit...""",1
499,"In addition, Ibn al-Nafis had an insight into what would become a larger theory of the capillary circulation. He stated that ""there must be small communications or pores (manafidh in Arabic) between the pulmonary artery and vein,"" a prediction that preceded the discovery of the capillary system by more than 400 years.[23] Ibn al-Nafis' theory, however, was confined to blood transit in the lungs and did not extend to the entire body.
",1
500,"Michael Servetus was the first European to describe the function of pulmonary circulation, although his achievement was not widely recognized at the time, for a few reasons. He firstly described it in the ""Manuscript of Paris""[24][25] (near 1546), but this work was never published. And later he published this description, but in a theological treatise, Christianismi Restitutio, not in a book on medicine. Only three copies of the book survived but these remained hidden for decades, the rest were burned shortly after its publication in 1553 because of persecution of Servetus by religious authorities.
",1
501,"Better known discovery of pulmonary circulation was by Vesalius's successor at Padua, Realdo Colombo, in 1559.
",1
502,"Finally, the English physician William Harvey, a pupil of Hieronymus Fabricius (who had earlier described the valves of the veins without recognizing their function), performed a sequence of experiments and published his Exercitatio Anatomica de Motu Cordis et Sanguinis in Animalibus in 1628, which ""demonstrated that there had to be a direct connection between the venous and arterial systems throughout the body, and not just the lungs. Most importantly, he argued that the beat of the heart produced a continuous circulation of blood through minute connections at the extremities of the body. This is a conceptual leap that was quite different from Ibn al-Nafis' refinement of the anatomy and bloodflow in the heart and lungs.""[26] This work, with its essentially correct exposition, slowly convinced the medical world. However, Harvey was not able to identify the capillary system connecting arteries and veins; these were later discovered by Marcello Malpighi in 1661.
",1
503,"In 1956, André Frédéric Cournand, Werner Forssmann and Dickinson W. Richards were awarded the Nobel Prize in Medicine ""for their discoveries concerning heart catheterization and pathological changes in the circulatory system.""[27]
In his Nobel lecture, Forssmann credits Harvey as birthing cardiology with the publication of his book in 1628.[28]
",1
504,"In the 1970s, Diana McSherry developed computer-based systems to create images of the circulatory system and heart without the need for surgery.[29]
",1
505,"
",1
506,"A physician (American English), medical practitioner (Commonwealth English), medical doctor, or simply doctor, is a professional who practices medicine, which is concerned with promoting, maintaining, or restoring health through the study, diagnosis, prognosis and treatment of disease, injury, and other physical and mental impairments. Physicians may focus their practice on certain disease categories, types of patients, and methods of treatment—known as specialities—or they may assume responsibility for the provision of continuing and comprehensive medical care to individuals, families, and communities—known as general practice.[2] Medical practice properly requires both a detailed knowledge of the academic disciplines, such as anatomy and physiology, underlying diseases and their treatment—the science of medicine—and also a decent competence in its applied practice—the art or craft of medicine.
",1
507,"Both the role of the physician and the meaning of the word itself vary around the world. Degrees and other qualifications vary widely, but there are some common elements, such as medical ethics requiring that physicians show consideration, compassion, and benevolence for their patients.
",1
508,"Around the world the term physician refers to a specialist in internal medicine or one of its many sub-specialties (especially as opposed to a specialist in surgery). This meaning of physician conveys a sense of expertise in treatment by drugs or medications, rather than by the procedures of surgeons.[4]
",1
509,"This term is at least nine hundred years old in English: physicians and surgeons were once members of separate professions, and traditionally were rivals. The Shorter Oxford English Dictionary, third edition, gives a Middle English quotation making this contrast, from as early as 1400: ""O Lord, whi is it so greet difference betwixe a cirugian and a physician.""[5]
",1
510,"Henry VIII granted a charter to the London Royal College of Physicians in 1518. It was not until 1540 that he granted the Company of Barber-Surgeons (ancestor of the Royal College of Surgeons) its separate charter. In the same year, the English monarch established the Regius Professorship of Physic at the University of Cambridge.[6] Newer universities would probably describe such an academic as a professor of internal medicine. Hence, in the 16th century, physic meant roughly what internal medicine does now.
",1
511,"Currently, a specialist physician in the United States may be described as an internist. Another term, hospitalist, was introduced in 1996,[7] to describe US specialists in internal medicine who work largely or exclusively in hospitals. Such 'hospitalists' now make up about 19% of all US general internists,[8] who are often called general physicians in Commonwealth countries.
",1
512,"This original use, as distinct from surgeon, is common in most of the world including the United Kingdom and other Commonwealth countries (such as Australia, Bangladesh, India, New Zealand, Pakistan, South Africa, Sri Lanka, and Zimbabwe), as well as in places as diverse as Brazil, Hong Kong, Indonesia, Japan, Ireland, and Taiwan. In such places, the more general English terms doctor or medical practitioner are prevalent, describing any practitioner of medicine (whom an American would likely call a physician, in the broad sense).[9] In Commonwealth countries, specialist pediatricians and geriatricians are also described as specialist physicians who have sub-specialized by age of patient rather than by organ system.
",1
513,"Around the world, the combined term ""physician and surgeon"" is used to describe either a general practitioner or any medical practitioner irrespective of specialty.[4][5] This usage still shows the original meaning of physician and preserves the old difference between a physician, as a practitioner of physic, and a surgeon. The term may be used by state medical boards in the United States, and by equivalent bodies in Canadian provinces, to describe any medical practitioner.
",1
514,"In modern English, the term physician is used in two main ways, with relatively broad and narrow meanings respectively. This is the result of history and is often confusing. These meanings and variations are explained below.
",1
515,"In the United States and Canada, the term physician describes all medical practitioners holding a professional medical degree. The American Medical Association, established in 1847, as well as the American Osteopathic Association, founded in 1897, both currently use the term physician to describe members. However, the American College of Physicians, established in 1915, does not: its title uses physician in its original sense.
",1
516,"The vast majority of physicians trained in the United States have a Doctor of Medicine degree, and use the initials M.D. A smaller number attend Osteopathic schools and have a Doctor of Osteopathic Medicine degree and use the initials D.O.[10] After completion of medical school, physicians complete a residency in the specialty in which they will practice. Subspecialties require the completion of a fellowship after residency.
",1
517,"All boards of certification now require that physicians demonstrate, by examination, continuing mastery of the core knowledge and skills for a chosen specialty. Recertification varies by particular specialty between every seven and every ten years.
",1
518,"Primary care physicians guide patients in preventing disease and detecting health problems early while they're still treatable.[11] They are divided into two types: family medicine doctors and internal medicine doctors.[12] Family doctors, or family physicians, are trained to care for patients of any age, while internists are trained to care for adults.[13] Family doctors receive training in a variety of care and are therefore also referred to as general practitioners.[14] Family medicine grew out of the general practitioner movement of the 1960s in response to the growing specialization in medicine that was seen as threatening to the doctor-patient relationship and continuity of care.[15]
",1
519,"Also in the United States, the American Podiatric Medical Association (APMA) defines podiatrists as physicians and surgeons that fall under the department of surgery in hospitals.[16] They undergo training with the Doctor of Podiatric Medicine (DPM) degree.[17] In the US, podiatrist are required to complete three to four years surgical residency upon graduating from DPM degree. After residency, one to two years of fellowship programs are available in plastic surgery, foot and ankle reconstructive surgery, sports medicine, and wound care.[18] This degree is also available at one Canadian university, namely the Université du Québec à Trois-Rivières. Students are typically required to complete an internship in New York prior to the obtention of their professional degree.
",1
520,"Many countries in the developing world have the problem of too few physicians.[19] In 2015, the Association of American Medical Colleges warned that the US will face a doctor shortage of as many as 90,000 by 2025.[20]
",1
521,"Within Western culture and over recent centuries, medicine has become increasingly based on scientific reductionism and materialism. This style of medicine is now dominant throughout the industrialized world, and is often termed biomedicine by medical anthropologists.[21] Biomedicine ""formulates the human body and disease in a culturally distinctive pattern"",[22] and is a world view learnt by medical students. Within this tradition, the medical model is a term for the complete ""set of procedures in which all doctors are trained"",[23] including mental attitudes. A particularly clear expression of this world view, currently dominant among conventional physicians, is evidence-based medicine. Within conventional medicine, most physicians still pay heed to their ancient traditions:
",1
522," The critical sense and sceptical attitude of the citation of medicine from the shackles of priestcraft and of caste; secondly, the conception of medicine as an art based on accurate observation, and as a science, an integral part of the science of man and of nature; thirdly, the high moral ideals, expressed in that most ""memorable of human documents"" (Gomperz), the Hippocratic oath; and fourthly, the conception and realization of medicine as the profession of a cultivated gentleman.
",1
523,"— Sir William Osler, Chauvanism in Medicine (1902)[24]
",1
524,"In this Western tradition, physicians are considered to be members of a learned profession, and enjoy high social status, often combined with expectations of a high and stable income and job security. However, medical practitioners often work long and inflexible hours, with shifts at unsociable times. Their high status is partly from their extensive training requirements, and also because of their occupation's special ethical and legal duties. The term traditionally used by physicians to describe a person seeking their help is the word patient (although one who visits a physician for a routine check-up may also be so described). This word patient is an ancient reminder of medical duty, as it originally meant 'one who suffers'. The English noun comes from the Latin word patiens, the present participle of the deponent verb, patior, meaning 'I am suffering', and akin to the Greek verb πάσχειν (romanized: paschein, lit. to suffer) and its cognate noun πάθος (pathos, suffering).[5][25]
",1
525,"Physicians in the original, narrow sense (specialist physicians or internists, see above) are commonly members or fellows of professional organizations, such as the American College of Physicians or the Royal College of Physicians in the United Kingdom, and such hard-won membership is itself a mark of status.[citation needed]
",1
526,"While contemporary biomedicine has distanced itself from its ancient roots in religion and magic, many forms of traditional medicine[26] and alternative medicine continue to espouse vitalism in various guises: ""As long as life had its own secret properties, it was possible to have sciences and medicines based on those properties"".[27] The US National Center for Complementary and Alternative Medicine (NCCAM) classifies complementary and alternative medicine therapies into five categories or domains, including:[28] alternative medical systems, or complete systems of therapy and practice; mind-body interventions, or techniques designed to facilitate the mind's effect on bodily functions and symptoms; biologically based systems including herbalism; and manipulative and body-based methods such as chiropractic and massage therapy.
",1
527,"In considering these alternate traditions that differ from biomedicine (see above), medical anthropologists emphasize that all ways of thinking about health and disease have a significant cultural content, including conventional western medicine.[21][22][29][30]
",1
528,"Ayurveda, Unani medicine, and homeopathy are popular types of alternative medicine.
",1
529,"Some commentators have argued that physicians have duties to serve as role models for the general public in matters of health, for example by not smoking cigarettes.[31] Indeed, in most western nations relatively few physicians smoke, and their professional knowledge does appear to have a beneficial effect on their health and lifestyle. According to a study of male physicians,[32] life expectancy is slightly higher for physicians (73 years for white and 69 years for black) than lawyers or many other highly educated professionals. Causes of death which are less likely to occur in physicians than the general population include respiratory disease (including pneumonia, pneumoconioses, COPD, but excluding emphysema and other chronic airway obstruction), alcohol-related deaths, rectosigmoid and anal cancers, and bacterial diseases.[32]
",1
530,"Physicians do experience exposure to occupational hazards, and there is a well-known aphorism that ""doctors make the worst patients"".[33] Causes of death that are shown to be higher in the physician population include suicide among doctors and self-inflicted injury, drug-related causes, traffic accidents, and cerebrovascular and ischaemic heart disease.[32] Physicians are also prone to occupational burnout. This manifests as a long-term stress reaction characterized by poorer quality of care towards patients, emotional exhaustion, a feeling of decreased personal achievement, and others. A study by the Agency for Healthcare Research and Quality reported that time pressure was the greatest cause of burnout; a survey from the American Medical Association reported that more than half of all respondents chose ""too many bureaucratic tasks"" as the leading cause of burnout.[34][35]
",1
531,"Medical education and career pathways for doctors vary considerably across the world.
",1
532,"In all developed countries, entry-level medical education programs are tertiary-level courses, undertaken at a medical school attached to a university. Depending on jurisdiction and university, entry may follow directly from secondary school or require pre-requisite undergraduate education. The former commonly takes five or six years to complete. Programs that require previous undergraduate education (typically a three- or four-year degree, often in science) are usually four or five years in length. Hence, gaining a basic medical degree may typically take from five to eight years, depending on jurisdiction and university.
",1
533,"Following the completion of entry-level training, newly graduated medical practitioners are often required to undertake a period of supervised practice before full registration is granted, typically one or two years. This may be referred to as an ""internship"", as the ""foundation"" years in the UK, or as ""conditional registration"". Some jurisdictions, including the United States, require residencies for practice.
",1
534,"Medical practitioners hold a medical degree specific to the university from which they graduated. This degree qualifies the medical practitioner to become licensed or registered under the laws of that particular country, and sometimes of several countries, subject to requirements for an internship or conditional registration.
",1
535,"Specialty training is begun immediately following completion of entry-level training, or even before. In other jurisdictions, junior medical doctors must undertake generalist (un-streamed) training for one or more years before commencing specialization. Hence, depending on the jurisdiction, a specialist physician (internist) often does not achieve recognition as a specialist until twelve or more years after commencing basic medical training—five to eight years at university to obtain a basic medical qualification, and up to another nine years to become a specialist.
",1
536,"In most jurisdictions, physicians (in either sense of the word) need government permission to practice. Such permission is intended to promote public safety, and often to protect government spending, as medical care is commonly subsidized by national governments.
",1
537,"In some jurisdictions such as in Singapore, it is common for physicians to inflate their qualifications with the title ""Dr"" in correspondence or namecards, even if their qualifications are limited to a basic (e.g., bachelor level) degree. In other countries such as Germany, only physicians holding an academic doctorate may call themselves doctor – on the other hand, the European Research Council has decided that the German medical doctorate does not meet the international standards of a PhD research degree.[dubious  – discuss][36][37]
",1
538,"Among the English-speaking countries, this process is known either as licensure as in the United States, or as registration in the United Kingdom, other Commonwealth countries, and Ireland. Synonyms in use elsewhere include colegiación in Spain, ishi menkyo in Japan, autorisasjon in Norway, Approbation in Germany, and .mw-parser-output .polytonic{font-family:""SBL BibLit"",""SBL Greek"",Athena,""EB Garamond"",""EB Garamond 12"",""Foulis Greek"",""Garamond Libre"",Cardo,""Gentium Plus"",Gentium,Garamond,""Palatino Linotype"",""DejaVu Sans"",""DejaVu Serif"",FreeSerif,FreeSans,""Arial Unicode MS"",""Lucida Sans Unicode"",""Lucida Grande"",Code2000,sans-serif}άδεια εργασίας in Greece. In France, Italy and Portugal, civilian physicians must be members of the Order of Physicians to practice medicine.
",1
539,"In some countries, including the United Kingdom and Ireland, the profession largely regulates itself, with the government affirming the regulating body's authority. The best-known example of this is probably the General Medical Council of Britain. In all countries, the regulating authorities will revoke permission to practice in cases of malpractice or serious misconduct.
",1
540,"In the large English-speaking federations (United States, Canada, Australia), the licensing or registration of medical practitioners is done at a state or provincial level, or nationally as in New Zealand. Australian states usually have a ""Medical Board,"" which has now been replaced by the Australian Health Practitioner Regulatory Authority (AHPRA) in most states, while Canadian provinces usually have a ""College of Physicians and Surgeons"". All American states have an agency that is usually called the ""Medical Board"", although there are alternate names such as ""Board of Medicine,"" ""Board of Medical Examiners"", ""Board of Medical Licensure"", ""Board of Healing Arts"" or some other variation.[38] After graduating from a first-professional school, physicians who wish to practice in the US usually take standardized exams, such as the USMLE for a Doctor in Medicine.
",1
541,"Most countries have some method of officially recognizing specialist qualifications in all branches of medicine, including internal medicine. Sometimes, this aims to promote public safety by restricting the use of hazardous treatments. Other reasons for regulating specialists may include standardization of recognition for hospital employment and restriction on which practitioners are entitled to receive higher insurance payments for specialist services.
",1
542,"The issue of medical errors, drug abuse, and other issues in physician professional behavior received significant attention across the world,[39] in particular following a critical 2000 report[40] which ""arguably launched"" the patient-safety movement.[41] In the US, as of 2006 there were few organizations that systematically monitored performance. In the US, only the Department of Veterans Affairs randomly drug tests physicians, in contrast to drug testing practices for other professions that have a major impact on public welfare. Licensing boards at the US state-level depend upon continuing education to maintain competence.[42] Through the utilization of the National Practitioner Data Bank, Federation of State Medical Boards' disciplinary report, and American Medical Association Physician Profile Service, the 67 State Medical Boards continually self-report any adverse/disciplinary actions taken against a licensed physician in order that the other Medical Boards in which the physician holds or is applying for a medical license will be properly notified so that corrective, reciprocal action can be taken against the offending physician.[43] In Europe, as of 2009 the health systems are governed according to various national laws, and can also vary according to regional differences similar to the United States.[44]
",1
543,"A nurse practitioner (NP) is an advanced practice registered nurse and a type of mid-level practitioner. NPs are trained to assess patient needs, order and interpret diagnostic and laboratory tests, diagnose disease, formulate and prescribe treatment plans. NP training covers basic disease prevention, coordination of care, and health promotion, but does not provide the depth of expertise needed to recognize more complex conditions.[1][2] According to the American Association of Nurse Practitioners, an organization that lobbies for the expansion of the scope of practice of NPs, NPs are educated at the graduate level to provide ""primary, acute, chronic, and specialty care to patients of all ages"", depending on their field of practice.[3]
",1
544,"The scope of practice for a NP is defined by legal jurisdiction.[4][5] In some places, NPs are required to work under the supervision of a physician, and in other places they can practice independently.[6]
",1
545,"The present day concept of advanced practice nursing as a primary care provider was created in the mid-1960s, spurred on by a national shortage of physicians.[7] The first formal graduate certificate program for NPs was created by Henry Silver, a physician, and Loretta Ford, a nurse, in 1965.[7] In 1971, The U.S. Secretary of Health, Education and Welfare, Elliot Richardson, made a formal recommendation in expanding the scope of nursing practice to be able to serve as primary care providers.[8] In 2012, discussions have risen between accreditation agencies, national certifying bodies, and state boards of nursing about the possibility of making the Doctorate of Nursing Practice (DNP) as the new minimum standard of education for NP certification and licensure by 2015.[9]
",1
546,"Advanced practice nursing first appeared in the 1990s in Ontario.[10] These nurses practiced in neonatal intensive care units within tertiary care hospitals in collaboration with pediatricians and neonatologists.[10] Although the role of these nurses initially resembled a blended version of clinical nurse specialists and NPs, today the distinction has been more formally established.[10]
",1
547,"Becoming a Nurse Practitioner (NP) does not always require experience as a registered nurse in addition to a graduate degree.
",1
548,"NP's are required to be licensed Registered Nurses prior to obtaining their APRN certification. To become an NP requires between 1.5 and 3 years of post-baccalaureate training, in addition to prior training and experience as an RN, though there are alternate routes to training.
",1
549,"There are many types of nurse practitioner programs in the United States with the vast majority being in the specialty of a Family Nurse Practitioner (FNP).[11] There are also Psychiatric, Adult Geriatric Acute Care, Adult Geriatric Primary Care, Pediatric, and Neonatal nurse practitioner programs. Many of these programs have their pre-clinical or didactic courses taught online with proctored examinations. Once the students start their clinical courses they have online material, but are required to perform clinical hours at an approved facility under the guidance of an NP or Physician. Each clinical course has specific requirements that vary on their program's degree/ eligibility for certification. For instance FNP's are required to see patients across the lifespan; where as Adult Geriatric NP's do not see anyone below the Age of 13.[12]
",1
550,"The amount and quality of education required to be an NP has been the subject of controversy in the United States. Opponents of independent practice have argued that NP education can consist of online coursework with few hours of actual patient contact.[13] To become an NP requires between 1.5 and 3 years of post-baccalaureate training, in addition to prior training and experience as an RN, though there are alternate routes to training. A new nurse practitioner may have between 500 and 1,000 hours of clinical training.[1] The quality of education and of applicants for NP schools has been cited as a reason to not allow NPs to practice medicine autonomously. Some graduate nursing schools have 100% acceptance rates.[14]
",1
551,"A review of studies comparing outcomes of care by NPs and by physicians in primary care, urgent care, and anesthesia conducted by the Department of Veteran Affairs found that outcomes in the assessed studies were generally comparable; however, the strength of the evidence was generally low.[15] However, it has recently been shown that NPs prescribe opioids at a rate 28 times higher than their physician counterparts in states where they practice autonomously.[16]
",1
552,"One systematic review states that utilization of NPs under physician supervision may improve access to care[further explanation needed] in emergency and critical care settings.[17]
",1
553,"Because the profession is state-regulated, the scope of practice varies by state.  Some states allow NPs to have full practice authority, however, in other states, a written collaborative or supervisory agreement with a physician is legally required for practice.[18] Autonomous practice was introduced in the 1980s, mostly in states facing a physician shortage or that struggled to find enough healthcare providers to work in rural areas.[19]  The extent of this collaborative agreement, and the role, duties, responsibilities, nursing treatments, and pharmacologic recommendations again varies widely between states.[20][21][22]
",1
554,"NPs can legally examine patients, diagnose illness, prescribe some medications, and provide treatments. In 2017, twenty-two states gave full practice authority to NPs and do not require the supervision of a physician. Thirty-eight states require NPs to have a written agreement with a physician in order to provide care. Twelve of those states require NPs to be supervised or delegated by a physician, this physician may not be on site.[23]
",1
555,"In Canada, an NP is a registered nurse (RN) with a graduate degree in nursing. Canada recognizes them in primary care and acute care practice. NPs diagnose illnesses and medical conditions, prescribe Schedule 1 medications, order and interpret diagnostic tests, and perform procedures, within their scope of practice, and may build their own panel of patients at the same level as physicians.[24] Primary care NPs work in places like primary care and community healthcare centers, as well as long-term care institutions. The main focus of primary care NPs includes health promotion, preventative care, diagnosis and treatment of acute and chronic diseases and conditions. Acute care NPs serve a specific population of patients. They generally work in in-patient facilities that include neonatology, nephrology, and cardiology units.[25] There are currently three specialties for Nurse Practitioners in Canada: Family Practice, Pediatrics, and Adult Care. NPs who specialize in Family Practice work at the same level and offer the same services as Family Physicians with the exclusion of Quebec, where only Physicians are allowed to formulate a medical diagnosis.[26]
",1
556,"In the United Kingdom nurse practitioners carry out care at an advanced practice level. They commonly work in primary care (e.g. GP surgeries) or A&E departments, although they are increasingly being seen in other areas of practice.
",1
557,"The path to becoming an NP in the U.S. begins by earning an undergraduate degree in nursing and requires licensure and experience as an RN. One must then complete graduate or doctoral studies with additional medical training before taking national board certification testing in their specialty field.
",1
558,"In Australia, RNs who have the equivalent of three years of full-time experience (5000 hours) and have completed a program of study approved by the Nursing and Midwifery Board of Australia (a postgraduate nursing master's degree including advanced health assessment, pharmacology for prescribing, therapeutics and diagnostics and research), or a program that is substantially equivalent to an approved program of study, may apply to the Nursing and Midwifery Board of Australia for endorsement as a Nurse Practitioner.[27] The Australian professional organisation is the Australian College of Nurse Practitioners (ACNP).[28]
",1
559,"In Canada, the educational standard is a graduate degree in nursing. The Canadian Nursing Association (CNA) notes that advanced practice nurses must have a combination of a graduate level education and the clinical experience that prepare them to practice at an advanced level. Their education alone does not give them the ability to practice at an advanced level. Two national frameworks have been developed in order to provide further guidance for the development of educational courses and requirements, research concepts, and government position statements regarding advanced practice nursing: the CNA's Advanced Nursing Practice: A National Framework and the Canadian Nurse Practitioner Core Competency Framework. All educational programs for NPs must achieve formal approval by provincial and territorial regulating nurse agencies due to the fact that the NP is considered a legislated role in Canada. As such, it is common to see differences among approved educational programs between territories and provinces. Specifically, inconsistencies can be found in core graduate courses, clinical experiences, and length of programs. Canada does not have a national curriculum or consistent standards regarding advanced practice nurses. All advanced practice nurses must meet individual requirements set by their provincial or territorial regulatory nursing body.
",1
560,"As of November 2013, NPs were recognized legally in Israel.[29]
",1
561,"The salary of an NP generally depends on the area of specialization, location, years of experience, and level of education. In 2015, the American Association of Nurse Practitioners (AANP) conducted its 4th annual NP salary survey. The results revealed the salary range to be between $98,760 to $108,643 reported income among full-time NPs. According to the U.S. Bureau of Labor Statistics, NPs in the top 10% earned an average salary of $135,800. The median salary was $98,190. According to a report published by Merritt Hawkins, starting salaries for NPs increased in dramatic fashion between 2015 and 2016.[citation needed] The highest average starting salary reached $197,000 in 2016. The primary factor in the dramatic increase in starting salaries is skyrocketing demand for NPs, recognizing them as the 5th most highly sought after advanced health professional in 2016.[30]
",1
562,"
",1
563,"Anatomy (Greek anatomē, 'dissection') is the branch of biology concerned with the study of the structure of organisms and their parts.[1] Anatomy is a branch of natural science which deals with the structural organization of living things. It is an old science, having its beginnings in prehistoric times.[2] Anatomy is inherently tied to developmental biology, embryology, comparative anatomy, evolutionary biology, and phylogeny,[3] as these are the processes by which anatomy is generated, both over immediate and long-term timescales. Anatomy and physiology, which study the structure and function of organisms and their parts respectively, make a natural pair of related disciplines, and are often studied together. Human anatomy is one of the essential basic sciences that are applied in medicine.[4]
",1
564,"The discipline of anatomy is divided into macroscopic and microscopic. Macroscopic anatomy, or gross anatomy, is the examination of an animal's body parts using unaided eyesight. Gross anatomy also includes the branch of superficial anatomy. Microscopic anatomy involves the use of optical instruments in the study of the tissues of various structures, known as histology, and also in the study of cells.
",1
565,"The history of anatomy is characterized by a progressive understanding of the functions of the organs and structures of the human body. Methods have also improved dramatically, advancing from the examination of animals by dissection of carcasses and cadavers (corpses) to 20th century medical imaging techniques including X-ray, ultrasound, and magnetic resonance imaging.
",1
566,"Derived from the Greek ἀνατομή anatomē ""dissection"" (from ἀνατέμνω anatémnō ""I cut up, cut open"" from ἀνά aná ""up"", and τέμνω témnō ""I cut""),[5] anatomy is the scientific study of the structure of organisms including their systems, organs and tissues. It includes the appearance and position of the various parts, the materials from which they are composed, their locations and their relationships with other parts. Anatomy is quite distinct from physiology and biochemistry, which deal respectively with the functions of those parts and the chemical processes involved. For example, an anatomist is concerned with the shape, size, position, structure, blood supply and innervation of an organ such as the liver; while a physiologist is interested in the production of bile, the role of the liver in nutrition and the regulation of bodily functions.[6]
",1
567,"The discipline of anatomy can be subdivided into a number of branches including gross or macroscopic anatomy and microscopic anatomy.[7] Gross anatomy is the study of structures large enough to be seen with the naked eye, and also includes superficial anatomy or surface anatomy, the study by sight of the external body features. Microscopic anatomy is the study of structures on a microscopic scale, along with histology (the study of tissues), and embryology (the study of an organism in its immature condition).[3]
",1
568,"Anatomy can be studied using both invasive and non-invasive methods with the goal of obtaining information about the structure and organization of organs and systems.[3] Methods used include dissection, in which a body is opened and its organs studied, and endoscopy, in which a video camera-equipped instrument is inserted through a small incision in the body wall and used to explore the internal organs and other structures. Angiography using X-rays or magnetic resonance angiography are methods to visualize blood vessels.[8][9][10][11]
",1
569,"The term ""anatomy"" is commonly taken to refer to human anatomy. However, substantially the same structures and tissues are found throughout the rest of the animal kingdom and the term also includes the anatomy of other animals. The term zootomy is also sometimes used to specifically refer to non-human animals. The structure and tissues of plants are of a dissimilar nature and they are studied in plant anatomy.[6]
",1
570,"The kingdom Animalia contains multicellular organisms that are heterotrophic and motile (although some have secondarily adopted a sessile lifestyle). Most animals have bodies differentiated into separate tissues and these animals are also known as eumetazoans. They have an internal digestive chamber, with one or two openings; the gametes are produced in multicellular sex organs, and the zygotes include a blastula stage in their embryonic development. Metazoans do not include the sponges, which have undifferentiated cells.[12]
",1
571,"Unlike plant cells, animal cells have neither a cell wall nor chloroplasts. Vacuoles, when present, are more in number and much smaller than those in the plant cell. The body tissues are composed of numerous types of cell, including those found in muscles, nerves and skin. Each typically has a cell membrane formed of phospholipids, cytoplasm and a nucleus.  All of the different cells of an animal are derived from the embryonic germ layers. Those simpler invertebrates which are formed from two germ layers of ectoderm and endoderm are called diploblastic and the more developed animals whose structures and organs are formed from three germ layers are called triploblastic.[13] All of a triploblastic animal's tissues and organs are derived from the three germ layers of the embryo, the ectoderm, mesoderm and endoderm.
",1
572,"Animal tissues can be grouped into four basic types: connective, epithelial, muscle and nervous tissue.
",1
573,"Connective tissues are fibrous and made up of cells scattered among inorganic material called the extracellular matrix. Connective tissue gives shape to organs and holds them in place. The main types are loose connective tissue, adipose tissue, fibrous connective tissue, cartilage and bone. The extracellular matrix contains proteins, the chief and most abundant of which is collagen. Collagen plays a major part in organizing and maintaining tissues. The matrix can be modified to form a skeleton to support or protect the body. An exoskeleton is a thickened, rigid cuticle which is stiffened by mineralization, as in crustaceans or by the cross-linking of its proteins as in insects. An endoskeleton is internal and present in all developed animals, as well as in many of those less developed.[13]
",1
574,"Epithelial tissue is composed of closely packed cells, bound to each other by cell adhesion molecules, with little intercellular space. Epithelial cells can be squamous (flat), cuboidal or columnar and rest on a basal lamina, the upper layer of the basement membrane,[14] the lower layer is the reticular lamina lying next to the connective tissue in the extracellular matrix secreted by the epithelial cells.[15] There are many different types of epithelium, modified to suit a particular function. In the respiratory tract there is a type of ciliated epithelial lining; in the small intestine there are microvilli on the epithelial lining and in the large intestine there are intestinal villi. Skin consists of an outer layer of keratinized stratified squamous epithelium that covers the exterior of the vertebrate body. Keratinocytes make up to 95% of the cells in the skin.[16] The epithelial cells on the external surface of the body typically secrete an extracellular matrix in the form of a cuticle. In simple animals this may just be a coat of glycoproteins.[13] In more advanced animals, many glands are formed of epithelial cells.[17]
",1
575,"Muscle cells (myocytes) form the active contractile tissue of the body. Muscle tissue functions to produce force and cause motion, either locomotion or movement within internal organs. Muscle is formed of contractile filaments and is separated into three main types; smooth muscle, skeletal muscle and cardiac muscle. Smooth muscle has no striations when examined microscopically. It contracts slowly but maintains contractibility over a wide range of stretch lengths. It is found in such organs as sea anemone tentacles and the body wall of sea cucumbers. Skeletal muscle contracts rapidly but has a limited range of extension. It is found in the movement of appendages and jaws. Obliquely striated muscle is intermediate between the other two. The filaments are staggered and this is the type of muscle found in earthworms that can extend slowly or make rapid contractions.[18] In higher animals striated muscles occur in bundles attached to bone to provide movement and are often arranged in antagonistic sets. Smooth muscle is found in the walls of the uterus, bladder, intestines, stomach, oesophagus, respiratory airways, and blood vessels. Cardiac muscle is found only in the heart, allowing it to contract and pump blood round the body.
",1
576,"Nervous tissue is composed of many nerve cells known as neurons which transmit information. In some slow-moving radially symmetrical marine animals such as ctenophores and cnidarians (including sea anemones and jellyfish), the nerves form a nerve net, but in most animals they are organized longitudinally into bundles. In simple animals, receptor neurons in the body wall cause a local reaction to a stimulus. In more complex animals, specialized receptor cells such as chemoreceptors and photoreceptors are found in groups and send messages along neural networks to other parts of the organism. Neurons can be connected together in ganglia.[19] In higher animals, specialized receptors are the basis of sense organs and there is a central nervous system (brain and spinal cord) and a peripheral nervous system. The latter consists of sensory nerves that transmit information from sense organs and motor nerves that influence target organs.[20][21] The peripheral nervous system is divided into the somatic nervous system which conveys sensation and controls voluntary muscle, and the autonomic nervous system which involuntarily controls smooth muscle, certain glands and internal organs, including the stomach.[22]
",1
577,"All vertebrates have a similar basic body plan and at some point in their lives, mostly in the embryonic stage, share the major chordate characteristics; a stiffening rod, the notochord; a dorsal hollow tube of nervous material, the neural tube; pharyngeal arches; and a tail posterior to the anus. The spinal cord is protected by the vertebral column and is above the notochord and the gastrointestinal tract is below it.[23] Nervous tissue is derived from the ectoderm, connective tissues are derived from mesoderm, and gut is derived from the endoderm. At the posterior end is a tail which continues the spinal cord and vertebrae but not the gut. The mouth is found at the anterior end of the animal, and the anus at the base of the tail.[24] The defining characteristic of a vertebrate is the vertebral column, formed in the development of the segmented series of vertebrae. In most vertebrates the notochord becomes the nucleus pulposus of the intervertebral discs. However, a few vertebrates, such as the sturgeon and the coelacanth retain the notochord into adulthood.[25] Jawed vertebrates are typified by paired appendages, fins or legs, which may be secondarily lost. The limbs of vertebrates are considered to be homologous because the same underlying skeletal structure was inherited from their last common ancestor. This is one of the arguments put forward by Charles Darwin to support his theory of evolution.[26]
",1
578,"The body of a fish is divided into a head, trunk and tail, although the divisions between the three are not always externally visible. The skeleton, which forms the support structure inside the fish, is either made of cartilage, in cartilaginous fish, or bone in bony fish. The main skeletal element is the vertebral column, composed of articulating vertebrae which are lightweight yet strong. The ribs attach to the spine and there are no limbs or limb girdles. The main external features of the fish, the fins, are composed of either bony or soft spines called rays, which with the exception of the caudal fins, have no direct connection with the spine. They are supported by the muscles which compose the main part of the trunk.[27] The heart has two chambers and pumps the blood through the respiratory surfaces of the gills and on round the body in a single circulatory loop.[28] The eyes are adapted for seeing underwater and have only local vision. There is an inner ear but no external or middle ear. Low frequency vibrations are detected by the lateral line system of sense organs that run along the length of the sides of fish, and these respond to nearby movements and to changes in water pressure.[27]
",1
579,"Sharks and rays are basal fish with numerous primitive anatomical features similar to those of ancient fish, including skeletons composed of cartilage. Their bodies tend to be dorso-ventrally flattened, they usually have five pairs of gill slits and a large mouth set on the underside of the head. The dermis is covered with separate dermal placoid scales. They have a cloaca into which the urinary and genital passages open, but not a swim bladder. Cartilaginous fish produce a small number of large, yolky eggs. Some species are ovoviviparous and the young develop internally but others are oviparous and the larvae develop externally in egg cases.[29]
",1
580,"The bony fish lineage shows more derived anatomical traits, often with major evolutionary changes from the features of ancient fish. They have a bony skeleton, are generally laterally flattened, have five pairs of gills protected by an operculum, and a mouth at or near the tip of the snout. The dermis is covered with overlapping scales. Bony fish have a swim bladder which helps them maintain a constant depth in the water column, but not a cloaca. They mostly spawn a large number of small eggs with little yolk which they broadcast into the water column.[29]
",1
581,"Amphibians are a class of animals comprising frogs, salamanders and caecilians. They are tetrapods, but the caecilians and a few species of salamander have either no limbs or their limbs are much reduced in size. Their main bones are hollow and lightweight and are fully ossified and the vertebrae interlock with each other and have articular processes. Their ribs are usually short and may be fused to the vertebrae. Their skulls are mostly broad and short, and are often incompletely ossified. Their skin contains little keratin and lacks scales, but contains many mucous glands and in some species, poison glands. The hearts of amphibians have three chambers, two atria and one ventricle. They have a urinary bladder and nitrogenous waste products are excreted primarily as urea. Amphibians breathe by means of buccal pumping, a pump action in which air is first drawn into the buccopharyngeal region through the nostrils. These are then closed and the air is forced into the lungs by contraction of the throat.[30] They supplement this with gas exchange through the skin which needs to be kept moist.[31]
",1
582,"In frogs the pelvic girdle is robust and the hind legs are much longer and stronger than the forelimbs. The feet have four or five digits and the toes are often webbed for swimming or have suction pads for climbing. Frogs have large eyes and no tail. Salamanders resemble lizards in appearance; their short legs project sideways, the belly is close to or in contact with the ground and they have a long tail. Caecilians superficially resemble earthworms and are limbless. They burrow by means of zones of muscle contractions which move along the body and they swim by undulating their body from side to side.[32]
",1
583,"Reptiles are a class of animals comprising turtles, tuataras, lizards, snakes and crocodiles. They are tetrapods, but the snakes and a few species of lizard either have no limbs or their limbs are much reduced in size. Their bones are better ossified and their skeletons stronger than those of amphibians. The teeth are conical and mostly uniform in size. The surface cells of the epidermis are modified into horny scales which create a waterproof layer. Reptiles are unable to use their skin for respiration as do amphibians and have a more efficient respiratory system drawing air into their lungs by expanding their chest walls. The heart resembles that of the amphibian but there is a septum which more completely separates the oxygenated and deoxygenated bloodstreams. The reproductive system has evolved for internal fertilization, with a copulatory organ present in most species. The eggs are surrounded by amniotic membranes which prevents them from drying out and are laid on land, or develop internally in some species. The bladder is small as nitrogenous waste is excreted as uric acid.[33]
",1
584,"Turtles are notable for their protective shells. They have an inflexible trunk encased in a horny carapace above and a plastron below. These are formed from bony plates embedded in the dermis which are overlain by horny ones and are partially fused with the ribs and spine. The neck is long and flexible and the head and the legs can be drawn back inside the shell. Turtles are vegetarians and the typical reptile teeth have been replaced by sharp, horny plates. In aquatic species, the front legs are modified into flippers.[34]
",1
585,"Tuataras superficially resemble lizards but the lineages diverged in the Triassic period. There is one living species, Sphenodon punctatus. The skull has two openings (fenestrae) on either side and the jaw is rigidly attached to the skull. There is one row of teeth in the lower jaw and this fits between the two rows in the upper jaw when the animal chews. The teeth are merely projections of bony material from the jaw and eventually wear down. The brain and heart are more primitive than those of other reptiles, and the lungs have a single chamber and lack bronchi. The tuatara has a well-developed parietal eye on its forehead.[34]
",1
586,"Lizards have skulls with only one fenestra on each side, the lower bar of bone below the second fenestra having been lost. This results in the jaws being less rigidly attached which allows the mouth to open wider. Lizards are mostly quadrupeds, with the trunk held off the ground by short, sideways-facing legs, but a few species have no limbs and resemble snakes. Lizards have moveable eyelids, eardrums are present and some species have a central parietal eye.[34]
",1
587,"Snakes are closely related to lizards, having branched off from a common ancestral lineage during the Cretaceous period, and they share many of the same features. The skeleton consists of a skull, a hyoid bone, spine and ribs though a few species retain a vestige of the pelvis and rear limbs in the form of pelvic spurs. The bar under the second fenestra has also been lost and the jaws have extreme flexibility allowing the snake to swallow its prey whole. Snakes lack moveable eyelids, the eyes being covered by transparent ""spectacle"" scales. They do not have eardrums but can detect ground vibrations through the bones of their skull. Their forked tongues are used as organs of taste and smell and some species have sensory pits on their heads enabling them to locate warm-blooded prey.[35]
",1
588,"Crocodilians are large, low-slung aquatic reptiles with long snouts and large numbers of teeth. The head and trunk are dorso-ventrally flattened and the tail is laterally compressed. It undulates from side to side to force the animal through the water when swimming. The tough keratinized scales provide body armour and some are fused to the skull. The nostrils, eyes and ears are elevated above the top of the flat head enabling them to remain above the surface of the water when the animal is floating. Valves seal the nostrils and ears when it is submerged. Unlike other reptiles, crocodilians have hearts with four chambers allowing complete separation of oxygenated and deoxygenated blood.[36]
",1
589,"Birds are tetrapods but though their hind limbs are used for walking or hopping, their front limbs are wings covered with feathers and adapted for flight. Birds are endothermic, have a high metabolic rate, a light skeletal system and powerful muscles. The long bones are thin, hollow and very light. Air sac extensions from the lungs occupy the centre of some bones. The sternum is wide and usually has a keel and the caudal vertebrae are fused. There are no teeth and the narrow jaws are adapted into a horn-covered beak. The eyes are relatively large, particularly in nocturnal species such as owls. They face forwards in predators and sideways in ducks.[37]
",1
590,"The feathers are outgrowths of the epidermis and are found in localized bands from where they fan out over the skin. Large flight feathers are found on the wings and tail, contour feathers cover the bird's surface and fine down occurs on young birds and under the contour feathers of water birds. The only cutaneous gland is the single uropygial gland near the base of the tail. This produces an oily secretion that waterproofs the feathers when the bird preens. There are scales on the legs, feet and claws on the tips of the toes.[37]
",1
591,"Mammals are a diverse class of animals, mostly terrestrial but some are aquatic and others have evolved flapping or gliding flight. They mostly have four limbs but some aquatic mammals have no limbs or limbs modified into fins and the forelimbs of bats are modified into wings. The legs of most mammals are situated below the trunk, which is held well clear of the ground. The bones of mammals are well ossified and their teeth, which are usually differentiated, are coated in a layer of prismatic enamel. The teeth are shed once (milk teeth) during the animal's lifetime or not at all, as is the case in cetaceans. Mammals have three bones in the middle ear and a cochlea in the inner ear. They are clothed in hair and their skin contains glands which secrete sweat. Some of these glands are specialized as mammary glands, producing milk to feed the young. Mammals breathe with lungs and have a muscular diaphragm separating the thorax from the abdomen which helps them draw air into the lungs. The mammalian heart has four chambers and oxygenated and deoxygenated blood are kept entirely separate. Nitrogenous waste is excreted primarily as urea.[38]
",1
592,"Mammals are amniotes, and most are viviparous, giving birth to live young. The exception to this are the egg-laying monotremes, the platypus and the echidnas of Australia. Most other mammals have a placenta through which the developing foetus obtains nourishment, but in marsupials, the foetal stage is very short and the immature young is born and finds its way to its mother's pouch where it latches on to a nipple and completes its development.[38]
",1
593,"Humans have the overall body plan of a mammal. Humans have a head, neck, trunk (which includes the thorax and abdomen), two arms and hands, and two legs and feet.
",1
594,"Generally, students of certain biological sciences, paramedics, prosthetists and orthotists, physiotherapists, occupational therapists, nurses, podiatrists, and medical students learn gross anatomy and microscopic anatomy from anatomical models, skeletons, textbooks, diagrams, photographs, lectures and tutorials and in addition, medical students generally also learn gross anatomy through practical experience of dissection and inspection of cadavers. The study of microscopic anatomy (or histology) can be aided by practical experience examining histological preparations (or slides) under a microscope.
[40]
",1
595,"Human anatomy, physiology and biochemistry are complementary basic medical sciences, which are generally taught to medical students in their first year at medical school. Human anatomy can be taught regionally or systemically; that is, respectively, studying anatomy by bodily regions such as the head and chest, or studying by specific systems, such as the nervous or respiratory systems.[3] The major anatomy textbook, Gray's Anatomy, has been reorganized from a systems format to a regional format, in line with modern teaching methods.[41][42] A thorough working knowledge of anatomy is required by physicians, especially surgeons and doctors working in some diagnostic specialties, such as histopathology and radiology.
[43]
",1
596,"Academic anatomists are usually employed by universities, medical schools or teaching hospitals. They are often involved in teaching anatomy, and research into certain systems, organs, tissues or cells.[43]
",1
597,"Invertebrates constitute a vast array of living organisms ranging from the simplest unicellular eukaryotes such as Paramecium to such complex multicellular animals as the octopus, lobster and dragonfly. They constitute about 95% of the animal species. By definition, none of these creatures has a backbone. The cells of single-cell protozoans have the same basic structure as those of multicellular animals but some parts are specialized into the equivalent of tissues and organs. Locomotion is often provided by cilia or flagella or may proceed via the advance of pseudopodia, food may be gathered by phagocytosis, energy needs may be supplied by photosynthesis and the cell may be supported by an endoskeleton or an exoskeleton. Some protozoans can form multicellular colonies.[44]
",1
598,"Metazoans are a multicellular organism, with different groups of cells serving different functions. The most basic types of metazoan tissues are epithelium and connective tissue, both of which are present in nearly all invertebrates. The outer surface of the epidermis is normally formed of epithelial cells and secretes an extracellular matrix which provides support to the organism. An endoskeleton derived from the mesoderm is present in echinoderms, sponges and some cephalopods. Exoskeletons are derived from the epidermis and is composed of chitin in arthropods (insects, spiders, ticks, shrimps, crabs, lobsters). Calcium carbonate constitutes the shells of molluscs, brachiopods and some tube-building polychaete worms and silica forms the exoskeleton of the microscopic diatoms and radiolaria.[45] Other invertebrates may have no rigid structures but the epidermis may secrete a variety of surface coatings such as the pinacoderm of sponges, the gelatinous cuticle of cnidarians (polyps, sea anemones, jellyfish) and the collagenous cuticle of annelids. The outer epithelial layer may include cells of several types including sensory cells, gland cells and stinging cells. There may also be protrusions such as microvilli, cilia, bristles, spines and tubercles.[46]
",1
599,"Marcello Malpighi, the father of microscopical anatomy, discovered that plants had tubules similar to those he saw in insects like the silk worm. He observed that when a ring-like portion of bark was removed on a trunk a swelling occurred in the tissues above the ring, and he unmistakably interpreted this as growth stimulated by food coming down from the leaves, and being captured above the ring.[47]
",1
600,"Arthropods comprise the largest phylum in the animal kingdom with over a million known invertebrate species.[48]
",1
601,"Insects possess segmented bodies supported by a hard-jointed outer covering, the exoskeleton, made mostly of chitin. The segments of the body are organized into three distinct parts, a head, a thorax and an abdomen.[49] The head typically bears a pair of sensory antennae, a pair of compound eyes, one to three simple eyes (ocelli) and three sets of modified appendages that form the mouthparts. The thorax has three pairs of segmented legs, one pair each for the three segments that compose the thorax and one or two pairs of wings. The abdomen is composed of eleven segments, some of which may be fused and houses the digestive, respiratory, excretory and reproductive systems.[50] There is considerable variation between species and many adaptations to the body parts, especially wings, legs, antennae and mouthparts.[51]
",1
602,"Spiders a class of arachnids have four pairs of legs; a body of two segments—a cephalothorax and an abdomen. Spiders have no wings and no antennae. They have mouthparts called chelicerae which are often connected to venom glands as most spiders are venomous. They have a second pair of appendages called pedipalps attached to the cephalothorax. These have similar segmentation to the legs and function as taste and smell organs. At the end of each male pedipalp is a spoon-shaped cymbium that acts to support the copulatory organ.
",1
603,"In 1600 BCE, the Edwin Smith Papyrus, an Ancient Egyptian medical text, described the heart, its vessels, liver, spleen, kidneys, hypothalamus, uterus and bladder, and showed the blood vessels diverging from the heart. The Ebers Papyrus (c. 1550 BCE) features a ""treatise on the heart"", with vessels carrying all the body's fluids to or from every member of the body.[53]
",1
604,"Ancient Greek anatomy and physiology underwent great changes and advances throughout the early medieval world.  Over time, this medical practice expanded by a continually developing understanding of the functions of organs and structures in the body. Phenomenal anatomical observations of the human body were made, which have contributed towards the understanding of the brain, eye, liver, reproductive organs and the nervous system.
",1
605,"The Hellenistic Egyptian city of Alexandria was the stepping-stone for Greek anatomy and physiology. Alexandria not only housed the biggest library for medical records and books of the liberal arts in the world during the time of the Greeks, but was also home to many medical practitioners and philosophers. Great patronage of the arts and sciences from the Ptolemy rulers helped raise Alexandria up, further rivalling the cultural and scientific achievements of other Greek states.[54]
",1
606,"Some of the most striking advances in early anatomy and physiology took place in Hellenistic Alexandria.[54] Two of the most famous anatomists and physiologists of the third century were Herophilus and Erasistratus. These two physicians helped pioneer human dissection for medical research. They also conducted vivisections on the cadavers of condemned criminals, which was considered taboo until the Renaissance—Herophilus was recognized as the first person to perform systematic dissections.[55] Herophilus became known for his anatomical works making impressing contributions to many branches of anatomy and many other aspects of medicine.[56] Some of the works included classifying the system of the pulse, the discovery that human arteries had thicker walls than veins, and that the atria were parts of the heart. Herophilus's knowledge of the human body has provided vital input towards understanding the brain, eye, liver, reproductive organs and nervous system, and characterizing the course of disease.[57] Erasistratus accurately described the structure of the brain, including the cavities and membranes, and made a distinction between its cerebrum and cerebellum[58] During his study in Alexandria, Erasistratus was particularly concerned with studies of the circulatory and nervous systems. He was able to distinguish the sensory and the motor nerves in the human body and believed that air entered the lungs and heart, which was then carried throughout the body. His distinction between the arteries and veins—the arteries carrying the air through the body, while the veins carried the blood from the heart was a great anatomical discovery. Erasistratus was also responsible for naming and describing the function of the epiglottis and the valves of the heart, including the tricuspid.[59] During the third century, Greek physicians were able to differentiate nerves from blood vessels and tendons[60] and to realize that the nerves convey neural impulses.[54] It was Herophilus who made the point that damage to motor nerves induced paralysis.[61] Herophilus named the meninges and ventricles in the brain, appreciated the division between cerebellum and cerebrum and recognized that the brain was the ""seat of intellect"" and not a ""cooling chamber"" as propounded by Aristotle[62] Herophilus is also credited with describing the optic, oculomotor, motor division of the trigeminal, facial, vestibulocochlear and hypoglossal nerves.[63]
",1
607,"Great feats were made during the third century BCE in both the digestive and reproductive systems. Herophilus was able to discover and describe not only the salivary glands, but the small intestine and liver.[63] He showed that the uterus is a hollow organ and described the ovaries and uterine tubes. He recognized that spermatozoa were produced by the testes and was the first to identify the prostate gland.[63]
",1
608,"The anatomy of the muscles and skeleton is described in the Hippocratic Corpus, an Ancient Greek medical work written by unknown authors.[64] Aristotle described vertebrate anatomy based on animal dissection. Praxagoras identified the difference between arteries and veins. Also in the 4th century BCE, Herophilos and Erasistratus produced more accurate anatomical descriptions based on vivisection of criminals in Alexandria during the Ptolemaic dynasty.[65][66]
",1
609,"In the 2nd century, Galen of Pergamum, an anatomist, clinician, writer and philosopher,[67] wrote the final and highly influential anatomy treatise of ancient times.[68] He compiled existing knowledge and studied anatomy through dissection of animals.[67] He was one of the first experimental physiologists through his vivisection experiments on animals.[69] Galen's drawings, based mostly on dog anatomy, became effectively the only anatomical textbook for the next thousand years.[70] His work was known to Renaissance doctors only through Islamic Golden Age medicine until it was translated from the Greek some time in the 15th century.[70]
",1
610,"Anatomy developed little from classical times until the sixteenth century; as the historian Marie Boas writes, ""Progress in anatomy before the sixteenth century is as mysteriously slow as its development after 1500 is startlingly rapid"".[70]:120–121 Between 1275 and 1326, the anatomists Mondino de Luzzi, Alessandro Achillini and Antonio Benivieni at Bologna carried out the first systematic human dissections since ancient times.[71][72][73] Mondino's Anatomy of 1316 was the first textbook in the medieval rediscovery of human anatomy. It describes the body in the order followed in Mondino's dissections, starting with the abdomen, then the thorax, then the head and limbs. It was the standard anatomy textbook for the next century.[70]
",1
611,"Leonardo da Vinci (1452–1519) was trained in anatomy by Andrea del Verrocchio.[70] He made use of his anatomical knowledge in his artwork, making many sketches of skeletal structures, muscles and organs of humans and other vertebrates that he dissected.[70][74]
",1
612,"Andreas Vesalius (1514–1564) (Latinized from Andries van Wezel), professor of anatomy at the University of Padua, is considered the founder of modern human anatomy.[75] Originally from Brabant, Vesalius published the influential book De humani corporis fabrica (""the structure of the human body""), a large format book in seven volumes, in 1543.[76] The accurate and intricately detailed illustrations, often in allegorical poses against Italianate landscapes, are thought to have been made by the artist Jan van Calcar, a pupil of Titian.[77]
",1
613,"In England, anatomy was the subject of the first public lectures given in any science; these were given by the Company of Barbers and Surgeons in the 16th century, joined in 1583 by the Lumleian lectures in surgery at the Royal College of Physicians.[78]
",1
614,"In the United States, medical schools began to be set up towards the end of the 18th century. Classes in anatomy needed a continual stream of cadavers for dissection and these were difficult to obtain. Philadelphia, Baltimore and New York were all renowned for body snatching activity as criminals raided graveyards at night, removing newly buried corpses from their coffins.[79] A similar problem existed in Britain where demand for bodies became so great that grave-raiding and even anatomy murder were practised to obtain cadavers.[80] Some graveyards were in consequence protected with watchtowers. The practice was halted in Britain by the Anatomy Act of 1832,[81][82] while in the United States, similar legislation was enacted after the physician William S. Forbes of Jefferson Medical College was found guilty in 1882 of ""complicity with resurrectionists in the despoliation of graves in Lebanon Cemetery"".[83]
",1
615,"The teaching of anatomy in Britain was transformed by Sir John Struthers, Regius Professor of Anatomy at the University of Aberdeen from 1863 to 1889. He was responsible for setting up the system of three years of ""pre-clinical"" academic teaching in the sciences underlying medicine, including especially anatomy. This system lasted until the reform of medical training in 1993 and 2003. As well as teaching, he collected many vertebrate skeletons for his museum of comparative anatomy, published over 70 research papers, and became famous for his public dissection of the Tay Whale.[84][85] From 1822 the Royal College of Surgeons regulated the teaching of anatomy in medical schools.[86] Medical museums provided examples in comparative anatomy, and were often used in teaching.[87] Ignaz Semmelweis investigated puerperal fever and he discovered how it was caused. He noticed that the frequently fatal fever occurred more often in mothers examined by medical students than by midwives. The students went from the dissecting room to the hospital ward and examined women in childbirth. Semmelweis showed that when the trainees washed their hands in chlorinated lime before each clinical examination, the incidence of puerperal fever among the mothers could be reduced dramatically.[88]
",1
616,"Before the modern medical era, the main means for studying the internal structures of the body were dissection of the dead and inspection, palpation and auscultation of the living. It was the advent of microscopy that opened up an understanding of the building blocks that constituted living tissues. Technical advances in the development of achromatic lenses increased the resolving power of the microscope and around 1839, Matthias Jakob Schleiden and Theodor Schwann identified that cells were the fundamental unit of organization of all living things. Study of small structures involved passing light through them and the microtome was invented to provide sufficiently thin slices of tissue to examine. Staining techniques using artificial dyes were established to help distinguish between different types of tissue. Advances in the fields of histology and cytology began in the late 19th century[89] along with advances in surgical techniques allowing for the painless and safe removal of biopsy specimens. The invention of the electron microscope brought a great advance in resolution power and allowed research into the ultrastructure of cells and the organelles and other structures within them. About the same time, in the 1950s, the use of X-ray diffraction for studying the crystal structures of proteins, nucleic acids and other biological molecules gave rise to a new field of molecular anatomy.[89]
",1
617,"Equally important advances have occurred in  non-invasive techniques for examining the interior structures of the body. X-rays can be passed through the body and used in medical radiography and fluoroscopy to differentiate interior structures that have varying degrees of opaqueness. Magnetic resonance imaging, computed tomography, and ultrasound imaging have all enabled examination of internal structures in unprecedented detail to a degree far beyond the imagination of earlier generations.[90]
",1
618,"
",1
619,"Embryology (from Greek ἔμβρυον, embryon, ""the unborn, embryo""; and -λογία, -logia) is the branch of biology that studies the prenatal development of gametes (sex cells), fertilization, and development of embryos and fetuses. Additionally, embryology encompasses the study of congenital disorders that occur before birth, known as teratology.
",1
620,"Early embryology was proposed by Marcello Malpighi, and known as preformationism, the theory that organisms develop from pre-existing miniature versions of themselves. Then Aristotle proposed the theory that is now accepted, epigenesis. Epigenesis is the idea that organisms develop from seed or egg in a sequence of steps. Modern embryology developed from the work of Karl Ernst von Baer, though accurate observations had been made in Italy by anatomists such as Aldrovandi and Leonardo da Vinci in the Renaissance.
",1
621,"As recently as the 18th century, the prevailing notion in western human embryology was preformation: the idea that semen contains an embryo – a preformed, miniature infant, or homunculus – that simply becomes larger during development.
",1
622,"The competing explanation of embryonic development was epigenesis, originally proposed 2,000 years earlier by Aristotle. Much early embryology came from the work of the Italian anatomists Aldrovandi, Aranzio, Leonardo da Vinci, Marcello Malpighi, Gabriele Falloppio, Girolamo Cardano, Emilio Parisano, Fortunio Liceti, Stefano Lorenzini, Spallanzani, Enrico Sertoli, and Mauro Ruscóni. According to epigenesis, the form of an animal emerges gradually from a relatively formless egg. As microscopy improved during the 19th century, biologists could see that embryos took shape in a series of progressive steps, and epigenesis displaced preformation as the favored explanation among embryologists.
",1
623,"Cleavage is the very beginning steps of a developing embryo. Cleavage refers to the many mitotic divisions that occur after the egg is fertilized by the sperm. The ways in which the cells divide is specific to certain types of animals and may have many forms.
",1
624,"Holoblastic cleavage is the complete division of cells. Holoblastic cleavage can be radial (see: Radial cleavage), spiral (see: Spiral cleavage), bilateral (see: Bilateral cleavage), or rotational (see: Rotational cleavage). In holoblastic cleavage the entire egg will divide and become the embryo, whereas in meroblastic cleavage some cells will become the embryo and others will be the yolk sac.
",1
625,"Meroblastic cleavage is the incomplete division of cells. The division furrow does not protrude into the yolky region as those cells impede membrane formation and this causes the incomplete separation of cells. Meroblastic cleavage can bilateral (see: Bilateral cleavage), discoidal (see: Discoidal cleavage), or centrolecithal (see: Centrolecithal).
",1
626,"Animals that belong to the basal phyla have holoblastic radial cleavage which results in radial symmetry (see: Symmetry in biology). During cleavage there is a central axis that all divisions rotate about. The basal phyla also has only one to two embryonic cell layers, compared to the three in bilateral animals (endoderm, mesoderm, and ectoderm).
",1
627,"In bilateral animals cleavage can be either holoblastic or meroblastic depending on the species. During gastrulation the blastula develops in one of two ways that divide the whole animal kingdom into two-halves (see: Embryological origins of the mouth and anus). If in the blastula the first pore, or blastopore, becomes the mouth of the animal, it is a protostome; if the blastopore becomes the anus then it is a deuterostome. The protostomes include most invertebrate animals, such as insects, worms and molluscs, while the deuterostomes include the vertebrates. In due course, the blastula changes into a more differentiated structure called the gastrula. Soon after the gastrula is formed, three distinct layers of cells (the germ layers) from which all the bodily organs and tissues then develop.
",1
628,"Drosophila have been used as a developmental model for many years. The studies that have been conducted have discovered many useful aspects of development that not only apply to fruit flies but other species as well.
",1
629,"Outlined below is the process that leads to cell and tissue differentiation.
",1
630,"Humans are bilateral animals that have holoblastic rotational cleavage. Humans are also deuterostomes. In regard to humans, the term embryo refers to the ball of dividing cells from the moment the zygote implants itself in the uterus wall until the end of the eighth week after conception. Beyond the eighth week after conception (tenth week of pregnancy), the developing human is then called a fetus.
",1
631,"Evolutionary embryology is the expansion of comparative embryology by the ideas of Charles Darwin. Similarly to Karl Ernst von Baer's principles that explained why many species often appear similar to one another in early developmental stages, Darwin argued that the relationship between groups can be determined based upon common embryonic and larval structures.
",1
632,"Using Darwin's theory evolutionary embryologists have since been able to distinguish between homologous and analogous structures between varying species. Homologous structures are those that the similarities between them are derived from a common ancestor, such as the human arm and bat wings. Analogous structures are those that appear to be similar but have no common ancestral derivation.[1]
",1
633,"Until the birth of modern embryology through observation of the mammalian ovum by Karl Ernst von Baer in 1827, there was no clear scientific understanding of embryology. Only in the late 1950s when ultrasound was first used for uterine scanning, was the true developmental chronology of human fetus available. Karl Ernst von Baer along with Heinz Christian Pander, also proposed the germ layer theory of development which helped to explain how the embryo developed in progressive steps. Part of this explanation explored why embryos in many species often appear similar to one another in early developmental stages using his four principles.
",1
634,"Embryology is central to evolutionary developmental biology (""evo-devo""), which studies the genetic control of the development process (e.g. morphogens), its link to cell signalling, its roles in certain diseases and mutations, and its links to stem cell research. Embryology is the key to Gestational Surrogacy, which is when the sperm of the intended father and egg of intended mother are fused in a lab forming an embryo. This embryo is then put into the surrogate who carries the child to term.
",1
635,"Medical embryology is used widely to detect abnormalities before birth. 2-5% of babies are born with an observable abnormality and medical embryology explores the different ways and stages that these abnormalities appear in.[1] Genetically derived abnormalities are referred to as malformations. When there are multiple malformations, this is considered a syndrome. When abnormalities appear due to outside contributors, these are disruptions. The outside contributors causing disruptions are known as teratogens. Common teratogens are alcohol, retinoic acid,[2] ionizing radiation or hyperthermic stress.
",1
636,"Many principles of embryology apply to invertebrates as well as to vertebrates. Therefore, the study of invertebrate embryology has advanced the study of vertebrate embryology. However, there are many differences as well. For example, numerous invertebrate species release a larva before development is complete; at the end of the larval period, an animal for the first time comes to resemble an adult similar to its parent or parents. Although invertebrate embryology is similar in some ways for different invertebrate animals, there are also countless variations. For instance, while spiders proceed directly from egg to adult form, many insects develop through at least one larval stage.
For decades, a number of so-called normal staging tables were produced for the embryology of particular species, mainly focussing on external developmental characters. As variation in developmental progress makes comparison among species difficult, a character-based Standard Event System was developed, which documents these differences and allows for phylogenetic comparisons among species.[3]
",1
637,"After the 1950s, with the DNA helical structure being unraveled and the increasing knowledge in the field of molecular biology, developmental biology emerged as a field of study which attempts to correlate the genes with morphological change, and so tries to determine which genes are responsible for each morphological change that takes place in an embryo, and how these genes are regulated.
",1
638,"Human embryos by Leonardo da Vinci
",1
639,"Human embryo at six weeks gestational age
",1
640,"Histological film 10-day mouse embryo
",1
641,"As of today, human embryology is taught as a cornerstone subject in medical schools, as well as in biology and zoology programs at both an undergraduate and graduate level.
",1
642,"Neuroscience (or neurobiology) is the scientific study of the nervous system.[1] It is a multidisciplinary science that combines physiology, anatomy, molecular biology, developmental biology, cytology, computer science and mathematical modeling  to understand the fundamental and emergent properties of neurons and neural circuits.[2][3][4][5][6] The understanding of the biological basis of learning, memory, behavior, perception, and consciousness has been described by Eric Kandel as the ""ultimate challenge"" of the biological sciences.[7]
",1
643,"The scope of neuroscience has broadened over time to include different approaches used to study the nervous system at different scales and the techniques used by neuroscientists have expanded enormously, from molecular and cellular studies of individual neurons to imaging of sensory, motor and cognitive tasks in the brain.
",1
644,"The earliest study of the nervous system dates to ancient Egypt. Trepanation, the surgical practice of either drilling or scraping a hole into the skull for the purpose of curing head injuries or mental disorders, or relieving cranial pressure, was first recorded during the Neolithic period. Manuscripts dating to 1700 BC indicate that the Egyptians had some knowledge about symptoms of brain damage.[8]
",1
645,"Early views on the function of the brain regarded it to be a ""cranial stuffing"" of sorts. In Egypt, from the late Middle Kingdom onwards, the brain was regularly removed in preparation for mummification. It was believed at the time that the heart was the seat of intelligence. According to Herodotus, the first step of mummification was to ""take a crooked piece of iron, and with it draw out the brain through the nostrils, thus getting rid of a portion, while the skull is cleared of the rest by rinsing with drugs.""[9]
",1
646,"The view that the heart was the source of consciousness was not challenged until the time of the Greek physician Hippocrates. He believed that the brain was not only involved with sensation—since most specialized organs (e.g., eyes, ears, tongue) are located in the head near the brain—but was also the seat of intelligence.[10] Plato also speculated that the brain was the seat of the rational part of the soul.[11] Aristotle, however, believed the heart was the center of intelligence and that the brain regulated the amount of heat from the heart.[12] This view was generally accepted until the Roman physician Galen, a follower of Hippocrates and physician to Roman gladiators, observed that his patients lost their mental faculties when they had sustained damage to their brains.[13]
",1
647,"Abulcasis, Averroes, Avicenna, Avenzoar, and Maimonides, active in the Medieval Muslim world, described a number of medical problems related to the brain. In Renaissance Europe, Vesalius (1514–1564), René Descartes (1596–1650), Thomas Willis (1621–1675) and Jan Swammerdam (1637–1680) also made several contributions to neuroscience.
",1
648,"Luigi Galvani's pioneering work in the late 1700s set the stage for studying the electrical excitability of muscles and neurons. In the first half of the 19th century, Jean Pierre Flourens pioneered the experimental method of carrying out localized lesions of the brain in living animals describing their effects on motricity, sensibility and behavior. In 1843 Emil du Bois-Reymond demonstrated the electrical nature of the nerve signal,[14] whose speed Hermann von Helmholtz proceeded to measure,[15] and in 1875 Richard Caton found electrical phenomena in the cerebral hemispheres of rabbits and monkeys.[16] Adolf Beck published in 1890 similar observations of spontaneous electrical activity of the brain of rabbits and dogs.[17] Studies of the brain became more sophisticated after the invention of the microscope and the development of a staining procedure by Camillo Golgi during the late 1890s. The procedure used a silver chromate salt to reveal the intricate structures of individual neurons. His technique was used by Santiago Ramón y Cajal and led to the formation of the neuron doctrine, the hypothesis that the functional unit of the brain is the neuron.[18] Golgi and Ramón y Cajal shared the Nobel Prize in Physiology or Medicine in 1906 for their extensive observations, descriptions, and categorizations of neurons throughout the brain.
",1
649,"In parallel with this research, work with brain-damaged patients by Paul Broca suggested that certain regions of the brain were responsible for certain functions. At the time, Broca's findings were seen as a confirmation of Franz Joseph Gall's theory that language was localized and that certain psychological functions were localized in specific areas of the cerebral cortex.[19][20] The localization of function hypothesis was supported by observations of epileptic patients conducted by John Hughlings Jackson, who correctly inferred the organization of the motor cortex by watching the progression of seizures through the body. Carl Wernicke further developed the theory of the specialization of specific brain structures in language comprehension and production. Modern research through neuroimaging techniques, still uses the Brodmann cerebral cytoarchitectonic map (referring to study of cell structure) anatomical definitions from this era in continuing to show that distinct areas of the cortex are activated in the execution of specific tasks.[21]
",1
650,"During the 20th century, neuroscience began to be recognized as a distinct academic discipline in its own right, rather than as studies of the nervous system within other disciplines. Eric Kandel and collaborators have cited David Rioch, Francis O. Schmitt, and Stephen Kuffler as having played critical roles in establishing the field.[22] Rioch originated the integration of basic anatomical and physiological research with clinical psychiatry at the Walter Reed Army Institute of Research, starting in the 1950s. During the same period, Schmitt established a neuroscience research program within the Biology Department at the Massachusetts Institute of Technology, bringing together biology, chemistry, physics, and mathematics. The first freestanding neuroscience department (then called Psychobiology) was founded in 1964 at the University of California, Irvine by James L. McGaugh.[23] This was followed by the Department of Neurobiology at Harvard Medical School, which was founded in 1966 by Stephen Kuffler.[24]
",1
651,"The understanding of neurons and of nervous system function became increasingly precise and molecular during the 20th century. For example, in 1952, Alan Lloyd Hodgkin and Andrew Huxley presented a mathematical model for transmission of electrical signals in neurons of the giant axon of a squid, which they called ""action potentials"", and how they are initiated and propagated, known as the Hodgkin–Huxley model. In 1961–1962, Richard FitzHugh and J. Nagumo simplified Hodgkin–Huxley, in what is called the FitzHugh–Nagumo model. In 1962, Bernard Katz modeled neurotransmission across the space between neurons known as synapses. Beginning in 1966, Eric Kandel and collaborators examined biochemical changes in neurons associated with learning and memory storage in Aplysia. In 1981 Catherine Morris and Harold Lecar combined these models in the Morris–Lecar model. Such increasingly quantitative work gave rise to numerous biological neuron models and models of neural computation.
",1
652,"As a result of the increasing interest about the nervous system, several prominent neuroscience organizations have been formed to provide a forum to all neuroscientist during the 20th century. For example, the International Brain Research Organization was founded in 1961,[25] the International Society for Neurochemistry in 1963,[26] the European Brain and Behaviour Society in 1968,[27] and the Society for Neuroscience in 1969.[28] Recently, the application of neuroscience research results has also given rise to applied disciplines as neuroeconomics,[29] neuroeducation,[30] neuroethics,[31] and neurolaw.[32]
",1
653,"Over time, brain research has gone through philosophical, experimental, and theoretical phases, with work on brain simulation predicted to be important in the future.[33]
",1
654,"The scientific study of the nervous system increased significantly during the second half of the twentieth century, principally due to advances in molecular biology, electrophysiology, and computational neuroscience. This has allowed neuroscientists to study the nervous system in all its aspects: how it is structured, how it works, how it develops, how it malfunctions, and how it can be changed.
",1
655,"For example, it has become possible to understand, in much detail, the complex processes occurring within a single neuron. Neurons are cells specialized for communication. They are able to communicate with neurons and other cell types through specialized junctions called synapses, at which electrical or electrochemical signals can be transmitted from one cell to another. Many neurons extrude a long thin filament of axoplasm called an axon, which may extend to distant parts of the body and are capable of rapidly carrying electrical signals, influencing the activity of other neurons, muscles, or glands at their termination points. A nervous system emerges from the assemblage of neurons that are connected to each other.
",1
656,"The vertebrate nervous system can be split into two parts: the central nervous system (defined as the brain and spinal cord), and the peripheral nervous system. In many species — including all vertebrates — the nervous system is the most complex organ system in the body, with most of the complexity residing in the brain. The human brain alone contains around one hundred billion neurons and one hundred trillion synapses; it consists of thousands of distinguishable substructures, connected to each other in synaptic networks whose intricacies have only begun to be unraveled. At least one out of three of the approximately 20,000 genes belonging to the human genome is expressed mainly in the brain.[34]
",1
657,"Due to the high degree of plasticity of the human brain, the structure of its synapses and their resulting functions change throughout life.[35]
",1
658,"Making sense of the nervous system's dynamic complexity is a formidable research challenge. Ultimately, neuroscientists would like to understand every aspect of the nervous system, including how it works, how it develops, how it malfunctions, and how it can be altered or repaired. Analysis of the nervous system is therefore performed at multiple levels, ranging from the molecular and cellular levels to the systems and cognitive levels. The specific topics that form the main foci of research change over time, driven by an ever-expanding base of knowledge and the availability of increasingly sophisticated technical methods. Improvements in technology have been the primary drivers of progress. Developments in electron microscopy, computer science, electronics, functional neuroimaging, and genetics and genomics have all been major drivers of progress.
",1
659,"Basic questions addressed in molecular neuroscience include the mechanisms by which neurons express and respond to molecular signals and how axons form complex connectivity patterns. At this level, tools from molecular biology and genetics are used to understand how neurons develop and how genetic changes affect biological functions. The morphology, molecular identity, and physiological characteristics of neurons and how they relate to different types of behavior are also of considerable interest.
",1
660,"Questions addressed in cellular neuroscience include the mechanisms of how neurons process signals physiologically and electrochemically. These questions include how signals are processed by neurites and somas and how neurotransmitters and electrical signals are used to process information in a neuron. Neurites are thin extensions from a neuronal cell body, consisting of dendrites (specialized to receive synaptic inputs from other neurons) and axons (specialized to conduct nerve impulses called action potentials). Somas are the cell bodies of the neurons and contain the nucleus.
",1
661,"Another major area of cellular neuroscience is the investigation of the development of the nervous system. Questions include the patterning and regionalization of the nervous system, neural stem cells, differentiation of neurons and glia (neurogenesis and gliogenesis), neuronal migration, axonal and dendritic development, trophic interactions, and synapse formation.
",1
662,"Computational neurogenetic modeling is concerned with the development of dynamic neuronal models for modeling brain functions with respect to genes and dynamic interactions between genes.
",1
663,"Questions in systems neuroscience include how neural circuits are formed and used anatomically and physiologically to produce functions such as reflexes, multisensory integration, motor coordination, circadian rhythms, emotional responses, learning, and memory. In other words, they address how these neural circuits function in large-scale brain networks, and the mechanisms through which behaviors are generated. For example, systems level analysis addresses questions concerning specific sensory and motor modalities: how does vision work? How do songbirds learn new songs and bats localize with ultrasound? How does the somatosensory system process tactile information? The related fields of neuroethology and neuropsychology address the question of how neural substrates underlie specific animal and human behaviors. Neuroendocrinology and psychoneuroimmunology examine interactions between the nervous system and the endocrine and immune systems, respectively. Despite many advancements, the way that networks of neurons perform complex cognitive processes and behaviors is still poorly understood.
",1
664,"Cognitive neuroscience addresses the questions of how psychological functions are produced by neural circuitry. The emergence of powerful new measurement techniques such as neuroimaging (e.g., fMRI, PET, SPECT), EEG, MEG, electrophysiology, optogenetics and human genetic analysis combined with sophisticated experimental techniques from cognitive psychology allows neuroscientists and psychologists to address abstract questions such as how cognition and emotion are mapped to specific neural substrates. Although many studies still hold a reductionist stance looking for the neurobiological basis of cognitive phenomena, recent research shows that there is an interesting interplay between neuroscientific findings and conceptual research, soliciting and integrating both perspectives. For example, neuroscience research on empathy solicited an interesting interdisciplinary debate involving philosophy, psychology and psychopathology.[36] Moreover, the neuroscientific identification of multiple memory systems related to different brain areas has challenged the idea of memory as a literal reproduction of the past, supporting a view of memory as a generative, constructive and dynamic process.[37]
",1
665,"Neuroscience is also allied with the social and behavioral sciences as well as nascent interdisciplinary fields such as neuroeconomics, decision theory, social neuroscience, and neuromarketing to address complex questions about interactions of the brain with its environment. A study into consumer responses for example uses EEG to investigate neural correlates associated with narrative transportation into stories about energy efficiency.[38]
",1
666,"Questions in computational neuroscience can span a wide range of levels of traditional analysis, such as development, structure, and cognitive functions of the brain. Research in this field utilizes mathematical models, theoretical analysis, and computer simulation to describe and verify biologically plausible neurons and nervous systems. For example, biological neuron models are mathematical descriptions of spiking neurons which can be used to describe both the behavior of single neurons as well as the dynamics of neural networks. Computational neuroscience is often referred to as theoretical neuroscience.
",1
667,"Nanoparticles in medicine are versatile in treating neurological disorders showing promising results in mediating drug transport across the blood brain barrier.[39] Implementing nanoparticles in antiepileptic drugs enhances their medical efficacy by increasing bioavailability in the bloodstream, as well as offering a measure of control in release time concentration.[39] Although nanoparticles can assist therapeutic drugs by adjusting physical properties to achieve desirable effects, inadvertent increases in toxicity often occur in preliminary drug trials.[40] Furthermore, production of nanomedicine for drug trials is economically consuming, hindering progress in their implementation. Computational models in nanoneuroscience provide alternatives to study the efficacy of nanotechnology-based medicines in neurological disorders while mitigating potential side effects and development costs.[39]
",1
668,"Nanomaterials often operate at length scales between classical and quantum regimes.[41] Due to the associated uncertainties at the length scales that nanomaterials operate, it is difficult to predict their behavior prior to in vivo studies.[39] Classically, the physical processes which occur throughout neurons are analogous to electrical circuits. Designers focus on such analogies and model brain activity as a neural circuit.[42] Success in computational modeling of neurons have led to the development of stereochemical models that accurately predict acetylcholine receptor-based synapses operating at microsecond time scales.[42]
",1
669,"Ultrafine nanoneedles for cellular manipulations are thinner than the smallest single walled carbon nanotubes. Computational quantum chemistry[43] is used to design ultrafine nanomaterials with highly symmetrical structures to optimize geometry, reactivity and stability.[41]
",1
670,"Behavior of nanomaterials are dominated by long ranged non-bonding interactions.[44] Electrochemical processes that occur throughout the brain generate an electric field which can inadvertently affect the behavior of some nanomaterials.[41] Molecular dynamics simulations can mitigate the development phase of nanomaterials as well as prevent neural toxicity of nanomaterials following in vivo clinical trials.[40] Testing nanomaterials using molecular dynamics optimizes nano characteristics for therapeutic purposes by testing different environment conditions, nanomaterial shape fabrications, nanomaterial surface properties, etc. without the need for in vivo experimentation.[45] Flexibility in molecular dynamic simulations allows medical practitioners to personalize treatment. Nanoparticle related data from translational nanoinformatics links neurological patient specific data to predict treatment response.[44]
",1
671,"The visualization of neuronal activity is of key importance in the study of neurology. Nano-imaging tools with nanoscale resolution help in these areas. These optical imaging tools are PALM[46] and STORM[47] which helps visualize nanoscale objects within cells. Pampaloni states that, so far, these imaging tools revealed the dynamic behavior and organization of the actin cytoskeleton inside the cells, which will assist in understanding how neurons probe their involvement during neuronal outgrowth and in response to injury, and how they differentiate axonal processes and characterization of receptor clustering and stoichiometry at the plasma inside the synapses, which are critical for understanding how synapses respond to changes in neuronal activity.[48] These past works focused on devices for stimulation or inhibition of neural activity, but the crucial aspect is the ability for the device to simultaneously monitor neural activity. The major aspect that is to be improved in the nano imaging tools is the effective collection of the light as a major problem is that biological tissue are dispersive media that do not allow a straightforward propagation and control of light. These devices use nanoneedle and nanowire (NWs) for probing and stimulation.[46]
",1
672,"NWs are artificial nano- or micro-sized “needles” that can provide high-fidelity electrophysiological recordings if used as microscopic electrodes for neuronal recordings. NWs are an attractive as they are highly functional structures that offer unique electronic properties that are affected by biological/chemical species adsorbed on their surface; mostly the conductivity.[49][50] This conductivity variance depending on chemical species present allows enhanced sensing performances.[51] NWs are also able to act as non-invasive and highly local probes. These versatility of NWs makes it optimal for interfacing with neurons due to the fact that the contact length along the axon (or the dendrite projection crossing a NW) is just about 20 nm.[52]
",1
673,"Neurology, psychiatry, neurosurgery, psychosurgery, anesthesiology and pain medicine, neuropathology, neuroradiology, ophthalmology, otolaryngology, clinical neurophysiology, addiction medicine, and sleep medicine are some medical specialties that specifically address the diseases of the nervous system. These terms also refer to clinical disciplines involving diagnosis and treatment of these diseases.
",1
674,"Neurology works with diseases of the central and peripheral nervous systems, such as amyotrophic lateral sclerosis (ALS) and stroke, and their medical treatment. Psychiatry focuses on affective, behavioral, cognitive, and perceptual disorders. Anesthesiology focuses on perception of pain, and pharmacologic alteration of consciousness. Neuropathology focuses upon the classification and underlying pathogenic mechanisms of central and peripheral nervous system and muscle diseases, with an emphasis on morphologic, microscopic, and chemically observable alterations. Neurosurgery and psychosurgery work primarily with surgical treatment of diseases of the central and peripheral nervous systems.
",1
675,"Recently, the boundaries between various specialties have blurred, as they are all influenced by basic research in neuroscience. For example, brain imaging enables objective biological insight into mental illnesses, which can lead to faster diagnosis, more accurate prognosis, and improved monitoring of patient progress over time.[53]
",1
676,"Integrative neuroscience describes the effort to combine models and information from multiple levels of research to develop a coherent model of the nervous system. For example, brain imaging coupled with physiological numerical models and theories of fundamental mechanisms may shed light on psychiatric disorders.[54]
",1
677,"One of the main goals of nanoneuroscience is to gain a detailed understanding of how the nervous system operates and, thus, how neurons organize themselves in the brain. Consequently, creating drugs and devices that are able to cross the blood brain barrier (BBB) are essential to allow for detailed imaging and diagnoses. The blood brain barrier functions as a highly specialized semipermeable membrane surrounding the brain, preventing harmful molecules that may be dissolved in the circulation blood from entering the central nervous system.
",1
678,"The main two hurdles for drug-delivering molecules to access the brain are size (must have a molecular weight < 400 Da) and lipid solubility.[55] Physicians hope to circumvent difficulties in accessing the central nervous system through viral gene therapy. This often involves direct injection into the patient’s brain or cerebral spinal fluid. The drawback of this therapy is that it is invasive and carries a high risk factor due to the necessity of surgery for the treatment to be administered. Because of this, only 3.6% of clinical trials in this field have progressed to stage III since the concept of gene therapy was developed in the 1980s.[56]
",1
679,"Another proposed way to cross the BBB is through temporary intentional disruption of the barrier. This method was first inspired by certain pathological conditions that were discovered to break down this barrier by themselves, such as Alzheimer’s disease, Parkinson’s disease, stroke, and seizure conditions.[55]
",1
680,"Nanoparticles are unique from macromolecules because their surface properties are dependent on their size, allowing for strategic manipulation of these properties (or, “programming”) by scientists that would not be possible otherwise. Likewise, nanoparticle shape can also be varied to give a different set of characteristics based on the surface area to volume ratio of the particle.[57]
",1
681,"Nanoparticles have promising therapeutic effects when treating neurodegenerative diseases. Oxygen reactive polymer (ORP) is a nano-platform programmed to react with oxygen and has been shown to detect and reduce the presence of reactive oxygen species (ROS) formed immediately after traumatic brain injuries.[58] Nanoparticles have also been employed as a “neuroprotective” measure, as is the case with Alzheimer’s disease and stroke models. Alzheimer’s disease results in toxic aggregates of the amyloid beta protein formed in the brain. In one study, gold nanoparticles were programmed to attach themselves to these aggregates and were successful in breaking them up.[59] Likewise, with ischemic stroke models, cells in the affected region of the brain undergo apoptosis, dramatically reducing blood flow to important parts of the brain and often resulting in death or severe mental and physical changes.[59] Platinum nanoparticles have been shown to act as ROS, serving as “biological antioxidants” and significantly reducing oxidation in the brain as a result of stroke.[59] Nanoparticles can also lead to neurotoxicity and cause permanent BBB damage either from brain oedema or from unrelated molecules crossing the BBB and causing brain damage.[58] This proves further long term in vivo studies are needed to gain enough understanding to allow for successful clinical trials.
",1
682,"One of the most common nano-based drug delivery platforms is liposome-based delivery. They are both lipid-soluble and nano-scale and thus are permitted through a fully functioning BBB. Additionally, lipids themselves are biological molecules, making them highly biocompatible, which in turn lowers the risk of cell toxicity. The bilayer that is formed allows the molecule to fully encapsulate any drug, protecting it while it is travelling through the body. One drawback to shielding the drug from the outside cells is that it no longer has specificity, and requires coupling to extra antibodies to be able to target a biological site. Due to their low stability, liposome-based nanoparticles for drug delivery have a short shelf life.[57]
",1
683,"Targeted therapy using magnetic nanoparticles (MNPs) is also a popular topic of research and has led to several stage III clinical trials.[60] Invasiveness is not an issue here because a magnetic force can be applied from the outside of a patient’s body to interact and direct the MNPs. This strategy has been proven successful in delivering Brain-derived neurotropic factor, a naturally occurring gene thought to promote neurorehabilitation, across the BBB.[58]
",1
684,"Modern neuroscience education and research activities can be very roughly categorized into the following major branches, based on the subject and scale of the system in examination as well as distinct experimental or curricular approaches. Individual neuroscientists, however, often work on questions that span several distinct subfields.
",1
685,"The largest professional neuroscience organization is the Society for Neuroscience (SFN), which is based in the United States but includes many members from other countries. Since its founding in 1969 the SFN has grown steadily: as of 2010 it recorded 40,290 members from 83 different countries.[64] Annual meetings, held each year in a different American city, draw attendance from researchers, postdoctoral fellows, graduate students, and undergraduates, as well as educational institutions, funding agencies, publishers, and hundreds of businesses that supply products used in research.
",1
686,"Other major organizations devoted to neuroscience include the International Brain Research Organization (IBRO), which holds its meetings in a country from a different part of the world each year, and the Federation of European Neuroscience Societies (FENS), which holds a meeting in a different European city every two years. FENS comprises a set of 32 national-level organizations, including the British Neuroscience Association, the German Neuroscience Society (Neurowissenschaftliche Gesellschaft), and the French Société des Neurosciences. The first National Honor Society in Neuroscience, Nu Rho Psi, was founded in 2006. Numerous youth neuroscience societies which support undergraduates, graduates and early career researchers also exist, like Project Encephalon.[65]
",1
687,"In 2013, the BRAIN Initiative was announced in the US. An International Brain Initiative was created in 2017,[66] currently integrated by more than seven national-level brain research initiatives (US, Europe, Allen Institute, Japan, China, Australia, Canada, Korea, Israel)[67] spanning four continents.
",1
688,"In addition to conducting traditional research in laboratory settings, neuroscientists have also been involved in the promotion of awareness and knowledge about the nervous system among the general public and government officials. Such promotions have been done by both individual neuroscientists and large organizations. For example, individual neuroscientists have promoted neuroscience education among young students by organizing the International Brain Bee, which is an academic competition for high school or secondary school students worldwide.[68] In the United States, large organizations such as the Society for Neuroscience have promoted neuroscience education by developing a primer called Brain Facts,[69] collaborating with public school teachers to develop Neuroscience Core Concepts for K-12 teachers and students,[70] and cosponsoring a campaign with the Dana Foundation called Brain Awareness Week to increase public awareness about the progress and benefits of brain research.[71] In Canada, the CIHR Canadian National Brain Bee is held annually at McMaster University.[72]
",1
689,"Neuroscience educators formed Faculty for Undergraduate Neuroscience (FUN) in 1992 to share best practices and provide travel awards for undergraduates presenting at Society for Neuroscience meetings.[73]
",1
690,"Finally, neuroscientists have also collaborated with other education experts to study and refine educational techniques to optimize learning among students, an emerging field called educational neuroscience.[74] Federal agencies in the United States, such as the National Institute of Health (NIH)[75] and National Science Foundation (NSF),[76] have also funded research that pertains to best practices in teaching and learning of neuroscience concepts.
",1
691,"
",2
692,"
",2
693,"Politics (from Greek: Πολιτικά, politiká, 'affairs of the cities') is the set of activities that are associated with making decisions in groups, or other forms of power relations between individuals, such as the distribution of resources or status. The branch of social science that studies politics is referred to as political science.
",2
694,"It may be used positively in the context of a ""political solution"" which is compromising and non-violent,[1] or descriptively as ""the art or science of government"", but also often carries a negative connotation.[2] For example, abolitionist Wendell Phillips declared that ""we do not play politics; anti-slavery is no half-jest with us.""[3] The concept has been defined in various ways, and different approaches have fundamentally differing views on whether it should be used extensively or limitedly, empirically or normatively, and on whether conflict or co-operation is more essential to it.
",2
695,"A variety of methods are deployed in politics, which include promoting one's own political views among people, negotiation with other political subjects, making laws, and exercising force, including warfare against adversaries.[4][5][6][7][8] Politics is exercised on a wide range of social levels, from clans and tribes of traditional societies, through modern local governments, companies and institutions up to sovereign states, to the international level. In modern nation states, people often form political parties to represent their ideas. Members of a party often agree to take the same position on many issues and agree to support the same changes to law and the same leaders. An election is usually a competition between different parties.
",2
696,"A political system is a framework which defines acceptable political methods within a society. The history of political thought can be traced back to early antiquity, with seminal works such as Plato's Republic, Aristotle's Politics, Chanakya's Arthashastra and Chanakya Niti (3rd century BCE), as well as the works of Confucius.[9]
",2
697,"The English politics has its roots in the name of Aristotle's classic work, Politiká, which introduced the Greek term politiká (Πολιτικά, 'affairs of the cities'). In the mid-15th century, Aristotle's composition would be rendered in Early Modern English as Polettiques [sic],[a][10] which would become Politics in Modern English.
",2
698,"The singular politic first attested in English in 1430, coming from Middle French politique—itself taking from politicus,[11] a Latinization of the Greek πολιτικός (politikos) from πολίτης (polites, 'citizen') and πόλις (polis, 'city').[12]
",2
699,"Politics comprises all the activities of co-operation, negotiation and conflict within and between societies, whereby people go about organizing the use, production or distribution of human, natural and other resources in the course of the production and reproduction of their biological and social life.[17]",2
700,"There are several ways in which approaching politics has been conceptualized.
",2
701,"Adrian Leftwich has differentiated views of politics based on how extensive or limited their perception of what accounts as 'political' is.[18] The extensive view sees politics as present across the sphere of human social relations, while the limited view restricts it to certain contexts. For example, in a more restrictive way, politics may be viewed as primarily about governance,[19] while a feminist perspective could argue that sites which have been viewed traditionally as non-political, should indeed be viewed as political as well.[20] This latter position is encapsulated in the slogan the personal is political, which disputes the distinction between private and public issues. Instead, politics may be defined by the use of power, as has been argued by Robert A. Dahl.[21]
",2
702,"Some perspectives on politics view it empirically as an exercise of power, while others see it as a social function with a normative basis.[22] This distinction has been called the difference between political moralism and political realism.[23] For moralists, politics is closely linked to ethics, and is at its extreme in utopian thinking.[23] For example, according to Hannah Arendt, the view of Aristotle was that ""to be political…meant that everything was decided through words and persuasion and not through violence;""[24] while according to Bernard Crick ""[p]olitics is the way in which free societies are governed. Politics is politics and other forms of rule are something else.""[25] In contrast, for realists, represented by those such as Niccolò Machiavelli, Thomas Hobbes, and Harold Lasswell, politics is based on the use of power, irrespective of the ends being pursued.[26][23]
",2
703,"Agonism argues that politics essentially comes down to conflict between conflicting interests. Political scientist Elmer Schattschneider argued that ""at the root of all politics is the universal language of conflict,""[27] while for Carl Schmitt the essence of politics is the distinction of 'friend' from foe'.[28] This is in direct contrast to the more co-operative views of politics by Aristotle and Crick. However, a more mixed view between these extremes is provided by Irish political scientist Michael Laver, who noted that:",2
704,Politics is about the characteristic blend of conflict and co-operation that can be found so often in human interactions. Pure conflict is war. Pure co-operation is true love. Politics is a mixture of both.[29],2
705,"The history of politics spans human history and is not limited to modern institutions of government.
",2
706,"Frans de Waal argued that already chimpanzees engage in politics through ""social manipulation to secure and maintain influential positions.""[30] Early human forms of social organization—bands and tribes—lacked centralized political structures.[31] These are sometimes referred to as stateless societies.
",2
707,"In ancient history, civilizations did not have definite boundaries as states have today, and their borders could be more accurately described as frontiers. Early dynastic Sumer, and early dynastic Egypt were the first civilizations to define their borders. Moreover, up to the 12th century, many people lived in non-state societies. These range from relatively egalitarian bands and tribes to complex and highly stratified chiefdoms.
",2
708,"There are a number of different theories and hypotheses regarding early state formation that seek generalizations to explain why the state developed in some places but not others. Other scholars believe that generalizations are unhelpful and that each case of early state formation should be treated on its own.[32]
",2
709,"Voluntary theories contend that diverse groups of people came together to form states as a result of some shared rational interest.[33] The theories largely focus on the development of agriculture, and the population and organizational pressure that followed and resulted in state formation. One of the most prominent theories of early and primary state formation is the hydraulic hypothesis, which contends that the state was a result of the need to build and maintain large-scale irrigation projects.[34]
",2
710,"Conflict theories of state formation regard conflict and dominance of some population over another population as key to the formation of states.[33] In contrast with voluntary theories, these arguments believe that people do not voluntarily agree to create a state to maximize benefits, but that states form due to some form of oppression by one group over others. Some theories in turn argue that warfare was critical for state formation.[33]
",2
711,"The first states of sorts were those of early dynastic Sumer and early dynastic Egypt, which arose from the Uruk period and Predynastic Egypt respectively around approximately 3000 BCE.[35] Early dynastic Egypt was based around the Nile River in the north-east of Africa, the kingdom's boundaries being based around the Nile and stretching to areas where oases existed.[36] Early dynastic Sumer was located in southern Mesopotamia with its borders extending from the Persian Gulf to parts of the Euphrates and Tigris rivers.[35]
",2
712,"Although state-forms existed before the rise of the Ancient Greek empire, the Greeks were the first people known to have explicitly formulated a political philosophy of the state, and to have rationally analyzed political institutions. Prior to this, states were described and justified in terms of religious myths.[37]
",2
713,"Several important political innovations of classical antiquity came from the Greek city-states (polis) and the Roman Republic. The Greek city-states before the 4th century granted citizenship rights to their free population; in Athens these rights were combined with a directly democratic form of government that was to have a long afterlife in political thought and history.[citation needed]
",2
714,"The Peace of Westphalia (1648) is considered by political scientists to be the beginning of the modern international system,[38][39][40] in which external powers should avoid interfering in another country's domestic affairs.[41] The principle of non-interference in other countries' domestic affairs was laid out in the mid-18th century by Swiss jurist Emer de Vattel.[42] States became the primary institutional agents in an interstate system of relations. The Peace of Westphalia is said to have ended attempts to impose supranational authority on European states. The ""Westphalian"" doctrine of states as independent agents was bolstered by the rise in 19th century thought of nationalism, under which legitimate states were assumed to correspond to nations—groups of people united by language and culture.[43]
",2
715,"In Europe, during the 18th century, the classic non-national states were the multinational empires: the Austrian Empire, Kingdom of France, Kingdom of Hungary,[44] the Russian Empire, the Spanish Empire, the Ottoman Empire, and the British Empire. Such empires also existed in Asia, Africa, and the Americas; in the Muslim world, immediately after the death of Muhammad in 632, Caliphates were established, which developed into multi-ethnic trans-national empires.[45] The multinational empire was an absolute monarchy ruled by a king, emperor or sultan. The population belonged to many ethnic groups, and they spoke many languages. The empire was dominated by one ethnic group, and their language was usually the language of public administration. The ruling dynasty was usually, but not always, from that group. Some of the smaller European states were not so ethnically diverse, but were also dynastic states, ruled by a royal house. A few of the smaller states survived, such as the independent principalities of Liechtenstein, Andorra, Monaco, and the republic of San Marino.
",2
716,"Most theories see the nation state as a 19th-century European phenomenon, facilitated by developments such as state-mandated education, mass literacy, and mass media. However, historians[who?] also note the early emergence of a relatively unified state and identity in Portugal and the Dutch Republic.[46] Scholars such as Steven Weber, David Woodward, Michel Foucault, and Jeremy Black have advanced the hypothesis that the nation state did not arise out of political ingenuity or an unknown undetermined source, nor was it an accident of history or political invention.[47][33][48] Rather, the nation state is an inadvertent byproduct of 15th-century intellectual discoveries in political economy, capitalism, mercantilism, political geography, and geography[49][50] combined together with cartography[51][52] and advances in map-making technologies.[53]
",2
717,"Some nation states, such as Germany and Italy, came into existence at least partly as a result of political campaigns by nationalists, during the 19th century. In both cases, the territory was previously divided among other states, some of them very small. Liberal ideas of free trade played a role in German unification, which was preceded by a customs union, the Zollverein. National self-determination was a key aspect of United States President Woodrow Wilson's Fourteen Points, leading to the dissolution of the Austro-Hungarian Empire and the Ottoman Empire after the First World War, while the Russian Empire became the Soviet Union after the Russian Civil War. Decolonization lead to the creation of new nation states in place of multinational empires in the Third World.
",2
718,"Political globalization began in the 20th century through intergovernmental organizations and supranational unions. The League of Nations was founded after World War I, and after World War II it was replaced by the United Nations. Various international treaties have been signed through it. Regional integration has been pursued by the African Union, ASEAN, the European Union, and Mercosur. International political institutions on the international level include the International Criminal Court, the International Monetary Fund, and the World Trade Organization.
",2
719,"The study of politics is called political science, or politology. It comprises numerous subfields, including comparative politics, political economy, international relations, political philosophy, public administration, public policy, gender and politics, and political methodology. Furthermore, political science is related to, and draws upon, the fields of economics, law, sociology, history, philosophy, geography, psychology/psychiatry, anthropology, and neurosciences.
",2
720,"Comparative politics is the science of comparison and teaching of different types of constitutions, political actors, legislature and associated fields, all of them from an intrastate perspective. International relations deals with the interaction between nation-states as well as intergovernmental and transnational organizations. Political philosophy is more concerned with contributions of various classical and contemporary thinkers and philosophers.
",2
721,"Political science is methodologically diverse and appropriates many methods originating in psychology, social research, and cognitive neuroscience. Approaches include positivism, interpretivism, rational choice theory, behavioralism, structuralism, post-structuralism, realism, institutionalism, and pluralism. Political science, as one of the social sciences, uses methods and techniques that relate to the kinds of inquiries sought: primary sources such as historical documents and official records, secondary sources such as scholarly journal articles, survey research, statistical analysis, case studies, experimental research, and model building.
",2
722,"The political system defines the process for making official government decisions. It is usually compared to the legal system, economic system, cultural system, and other social systems. According to David Easton, ""A political system can be designated as the interactions through which values are authoritatively allocated for a society.""[54] Each political system is embedded in a society with its own political culture, and they in turn shape their societies through public policy. The interactions between different political systems are the basis for global politics.
",2
723,"Forms of government can be classified by several ways. In terms of the structure of power, there are monarchies (including constitutional monarchies) and republics (usually presidential, semi-presidential, or parliamentary).
",2
724,"The separation of powers describes the degree of horizontal integration between the legislature, the executive, the judiciary, and other independent institutions.
",2
725,"The source of power determines the difference between democracies, oligarchies, and autocracies.
",2
726,"In a democracy, political legitimacy is based on popular sovereignty. Forms of democracy include representative democracy, direct democracy, and demarchy. These are separated by the way decisions are made, whether by elected representatives, referendums, or by citizen juries. Democracies can be either republics or constitutional monarchies.
",2
727,"Oligarchy is a power structure where a minority rules. These may be in the form of anocracy, aristocracy, ergatocracy, geniocracy, gerontocracy, kakistocracy, kleptocracy, meritocracy, noocracy, particracy, plutocracy, stratocracy, technocracy, theocracy, or timocracy.
",2
728,"
Autocracies are either dictatorships (including military dictatorships) or absolute monarchies.",2
729,"In terms of level of vertical integration, political systems can be divided into (from least to most integrated) confederations, federations, and unitary states.
",2
730,"A federation (also known as a federal state) is a political entity characterized by a union of partially self-governing provinces, states, or other regions under a central federal government (federalism). In a federation, the self-governing status of the component states, as well as the division of power between them and the central government, is typically constitutionally entrenched and may not be altered by a unilateral decision of either party, the states or the federal political body. Federations were formed first in Switzerland, then in the United States in 1776, in Canada in 1867 and in Germany in 1871 and in 1901, Australia. Compared to a federation, a confederation has less centralized power.
",2
731,"All the above forms of government are variations of the same basic polity, the sovereign state. The state has been defined by Max Weber as a political entity that has monopoly on violence within its territory, while the Montevideo Convention holds that states need to have a defined territory; a permanent population; a government; and a capacity to enter into international relations.
",2
732,"A stateless society is a society that is not governed by a state.[55] In stateless societies, there is little concentration of authority; most positions of authority that do exist are very limited in power and are generally not permanently held positions; and social bodies that resolve disputes through predefined rules tend to be small.[56] Stateless societies are highly variable in economic organization and cultural practices.[57]
",2
733,"While stateless societies were the norm in human prehistory, few stateless societies exist today; almost the entire global population resides within the jurisdiction of a sovereign state. In some regions nominal state authorities may be very weak and wield little or no actual power. Over the course of history most stateless peoples have been integrated into the state-based societies around them.[58]
",2
734,"Some political philosophies consider the state undesirable, and thus consider the formation of a stateless society a goal to be achieved. A central tenet of anarchism is the advocacy of society without states.[55][59] The type of society sought for varies significantly between anarchist schools of thought, ranging from extreme individualism to complete collectivism.[60] In Marxism, Marx's theory of the state considers that in a post-capitalist society the state, an undesirable institution, would be unnecessary and wither away.[61] A related concept is that of stateless communism, a phrase sometimes used to describe Marx's anticipated post-capitalist society.
",2
735,"Constitutions are written documents that specify and limit the powers of the different branches of government. Although a constitution is a written document, there is also an unwritten constitution. The unwritten constitution is continually being written by the legislative and judiciary branch of government; this is just one of those cases in which the nature of the circumstances determines the form of government that is most appropriate.[62] England did set the fashion of written constitutions during the Civil War but after the Restoration abandoned them to be taken up later by the American Colonies after their emancipation and then France after the Revolution and the rest of Europe including the European colonies.
",2
736,"Constitutions often set out separation of powers, dividing the government into the executive, the legislature, and the judiciary (together referred to as the trias politica), in order to achieve checks and balances within the state. Additional independent branches may also be created, including civil service commissions, election commissions, and supreme audit institutions.
",2
737,"Political culture describes how culture impacts politics. Every political system is embedded in a particular political culture.[63] Lucian Pye's definition is that ""Political culture is the set of attitudes, beliefs, and sentiments, which give order and meaning to a political process and which provide the underlying assumptions and rules that govern behavior in the political system"".[63]
",2
738,"Trust is a major factor in political culture, as its level determines the capacity of the state to function.[64] Postmaterialism is the degree to which a political culture is concerned with issues which are not of immediate physical or material concern, such as human rights and environmentalism.[63] Religion has also an impact on political culture.[64]
",2
739,"Political corruption is the use of powers for illegitimate private gain, conducted by government officials or their network contacts. Forms of political corruption include bribery, cronyism, nepotism, and political patronage. Forms of political patronage, in turn, includes clientelism, earmarking, pork barreling, slush funds, and spoils systems; as well as political machines, which is a political system that operates for corrupt ends.
",2
740,"When corruption is embedded in political culture, this may be referred to as patrimonialism or neopatrimonialism. A form of government that is built on corruption is called a kleptocracy ('rule of thieves').
",2
741,"Political conflict entails the use of political violence to achieve political ends. As noted by Carl von Clausewitz, ""War is a mere continuation of politics by other means.""[65] Beyond just inter-state warfare, this may include civil war; wars of national liberation; or asymmetric warfare, such as guerrilla war or terrorism. When a political system is overthrown, the event is called a revolution: it is a political revolution if it does not go further; or a social revolution if the social system is also radically altered. However, these may also be nonviolent revolutions.
",2
742,"Macropolitics can either describe political issues that affect an entire political system (e.g. the nation state), or refer to interactions between political systems (e.g. international relations).[66]
",2
743,"Global politics (or world politics) covers all aspects of politics that affect multiple political systems, in practice meaning any political phenomenon crossing national borders. This can include cities, nation-states, multinational corporations, non-governmental organizations, and/or international organizations. An important element is international relations: the relations between nation-states may be peaceful when they are conducted through diplomacy, or they may be violent, which is described as war. States that are able to exert strong international influence are referred to as superpowers, whereas less-powerful ones may be called regional or middle powers. The international system of power is called the world order, which is affected by the balance of power that defines the degree of polarity in the system. Emerging powers are potentially destabilizing to it, especially if they display revanchism or irredentism.
",2
744,"Politics inside the limits of political systems, which in contemporary context correspond to national borders, are referred to as domestic politics. This includes most forms of public policy, such as social policy, economic policy, or law enforcement, which are executed by the state bureaucracy.
",2
745,"Mesopolitics describes the politics of intermediary structures within a political system, such as national political parties or movements.[66]
",2
746,"A political party is a political organization that typically seeks to attain and maintain political power within government, usually by participating in political campaigns, educational outreach, or protest actions. Parties often espouse an expressed ideology or vision, bolstered by a written platform with specific goals, forming a coalition among disparate interests.[67]
",2
747,"Political parties within a particular political system together form the party system, which can be either multiparty, two-party, dominant-party, or one-party, depending on the level of pluralism. This is affected by characteristics of the political system, including its electoral system. According to Duverger's law, first-past-the-post systems are likely to lead to two-party systems, while proportional representation systems are more likely to create a multiparty system.
",2
748,"Micropolitics describes the actions of individual actors within the political system.[66] This is often described as political participation.[68] Political participation may take many forms, including:
",2
749,"Democracy is a system of processing conflicts in which outcomes depend on what participants do, but no single force controls what occurs and its outcomes. The uncertainty of outcomes is inherent in democracy. Democracy makes all forces struggle repeatedly to realize their interests and devolves power from groups of people to sets of rules.[69]
",2
750,"Among modern political theorists, there are three contending conceptions of democracy: aggregative, deliberative, and radical.[70]
",2
751,"The theory of aggregative democracy claims that the aim of the democratic processes is to solicit the preferences of citizens, and aggregate them together to determine what social policies the society should adopt. Therefore, proponents of this view hold that democratic participation should primarily focus on voting, where the policy with the most votes gets implemented.
",2
752,"Different variants of aggregative democracy exist. Under minimalism, democracy is a system of government in which citizens have given teams of political leaders the right to rule in periodic elections. According to this minimalist conception, citizens cannot and should not ""rule"" because, for example, on most issues, most of the time, they have no clear views or their views are not well-founded. Joseph Schumpeter articulated this view most famously in his book Capitalism, Socialism, and Democracy.[71] Contemporary proponents of minimalism include William H. Riker, Adam Przeworski, Richard Posner.
",2
753,"According to the theory of direct democracy, on the other hand, citizens should vote directly, not through their representatives, on legislative proposals. Proponents of direct democracy offer varied reasons to support this view. Political activity can be valuable in itself, it socializes and educates citizens, and popular participation can check powerful elites. Most importantly, citizens do not rule themselves unless they directly decide laws and policies.
",2
754,"Governments will tend to produce laws and policies that are close to the views of the median voter—with half to their left and the other half to their right. This is not a desirable outcome as it represents the action of self-interested and somewhat unaccountable political elites competing for votes. Anthony Downs suggests that ideological political parties are necessary to act as a mediating broker between individual and governments. Downs laid out this view in his 1957 book An Economic Theory of Democracy.[72]
",2
755,"Robert A. Dahl argues that the fundamental democratic principle is that, when it comes to binding collective decisions, each person in a political community is entitled to have his/her interests be given equal consideration (not necessarily that all people are equally satisfied by the collective decision). He uses the term polyarchy to refer to societies in which there exists a certain set of institutions and procedures which are perceived as leading to such democracy. First and foremost among these institutions is the regular occurrence of free and open elections which are used to select representatives who then manage all or most of the public policy of the society. However, these polyarchic procedures may not create a full democracy if, for example, poverty prevents political participation.[73] Similarly, Ronald Dworkin argues that ""democracy is a substantive, not a merely procedural, ideal.""[74]
",2
756,"Deliberative democracy is based on the notion that democracy is government by deliberation. Unlike aggregative democracy, deliberative democracy holds that, for a democratic decision to be legitimate, it must be preceded by authentic deliberation, not merely the aggregation of preferences that occurs in voting. Authentic deliberation is deliberation among decision-makers that is free from distortions of unequal political power, such as power a decision-maker obtained through economic wealth or the support of interest groups.[75][76][77] If the decision-makers cannot reach consensus after authentically deliberating on a proposal, then they vote on the proposal using a form of majority rule.
",2
757,"Radical democracy is based on the idea that there are hierarchical and oppressive power relations that exist in society. Democracy's role is to make visible and challenge those relations by allowing for difference, dissent and antagonisms in decision-making processes.
",2
758,"Equality is a state of affairs in which all people within a specific society or isolated group have the same social status, especially socioeconomic status, including protection of human rights and dignity, and equal access to certain social goods and social services. Furthermore, it may also include health equality, economic equality and other social securities. Social equality requires the absence of legally enforced social class or caste boundaries and the absence of discrimination motivated by an inalienable part of a person's identity. To this end there must be equal justice under law, and equal opportunity regardless of, for example, sex, gender, ethnicity, age, sexual orientation, origin, caste or class, income or property, language, religion, convictions, opinions, health or disability.
",2
759,"A common way of understanding politics is through the left–right political spectrum, which ranges from left-wing politics via centrism to right-wing politics. This classification is comparatively recent and dates from the French Revolution, when those members of the National Assembly who supported the republic, the common people and a secular society sat on the left and supporters of the monarchy, aristocratic privilege and the Church sat on the right.[86]
",2
760,"Today, the left is generally progressivist, seeking social progress in society. The more extreme elements of the left, named the far-left, tend to support revolutionary means for achieving this. This includes ideologies such as Communism and Marxism. The center-left, on the other hand, advocate for more reformist approaches, for example that of social democracy.
",2
761,"In contrast, the right is generally motivated by conservatism, which seeks to conserve what it sees as the important elements of society. The far-right goes beyond this, and often represents a reactionary turn against progress, seeking to undo it. Examples of such ideologies have included Fascism and Nazism. The center-right may be less clear-cut and more mixed in this regard, with neoconservatives supporting the spread of democracy, and one-nation conservatives more open to social welfare programs.
",2
762,"According to Norberto Bobbio, one of the major exponents of this distinction, the left believes in attempting to eradicate social inequality—believing it to be unethical or unnatural,[87] while the right regards most social inequality as the result of ineradicable natural inequalities, and sees attempts to enforce social equality as utopian or authoritarian.[88]
Some ideologies, notably Christian Democracy, claim to combine left and right-wing politics; according to Geoffrey K. Roberts and Patricia Hogwood, ""In terms of ideology, Christian Democracy has incorporated many of the views held by liberals, conservatives and socialists within a wider framework of moral and Christian principles.""[89] Movements which claim or formerly claimed to be above the left-right divide include Fascist Terza Posizione economic politics in Italy and Peronism in Argentina.[90][91]
",2
763,"Political freedom (also known as political liberty or autonomy) is a central concept in political thought and one of the most important features of democratic societies. Negative liberty has been described as freedom from oppression or coercion and unreasonable external constraints on action, often enacted through civil and political rights, while positive liberty is the absence of disabling conditions for an individual and the fulfillment of enabling conditions, e.g. economic compulsion, in a society. This capability approach to freedom requires economic, social and cultural rights in order to be realized.
",2
764,"Authoritarianism and libertarianism disagree the amount of individual freedom each person possesses in that society relative to the state. One author describes authoritarian political systems as those where ""individual rights and goals are subjugated to group goals, expectations and conformities,""[92] while libertarians generally oppose the state and hold the individual as sovereign. In their purest form, libertarians are anarchists,[93] who argue for the total abolition of the state, of political parties and of other political entities, while the purest authoritarians are, by definition, totalitarians who support state control over all aspects of society.[94]
",2
765,"For instance, classical liberalism (also known as laissez-faire liberalism)[95] is a doctrine stressing individual freedom and limited government. This includes the importance of human rationality, individual property rights, free markets, natural rights, the protection of civil liberties, constitutional limitation of government, and individual freedom from restraint as exemplified in the writings of John Locke, Adam Smith, David Hume, David Ricardo, Voltaire, Montesquieu and others. According to the libertarian Institute for Humane Studies, ""the libertarian, or 'classical liberal,' perspective is that individual well-being, prosperity, and social harmony are fostered by 'as much liberty as possible' and 'as little government as necessary.'""[96] For anarchist political philosopher L. Susan Brown (1993), ""liberalism and anarchism are two political philosophies that are fundamentally concerned with individual freedom yet differ from one another in very distinct ways. Anarchism shares with liberalism a radical commitment to individual freedom while rejecting liberalism's competitive property relations.""[97]
",2
766,"
",2
767,"
",2
768,"Democracy (Greek: δημοκρατία, dēmokratiā, from dēmos 'people' and kratos 'rule')[1] is a form of government in which the people have the authority to choose their governing legislators. The decisions on who is considered part of the people and how authority is shared among or delegated by the people have changed over time and at different speeds in different countries, but they have included more and more of the inhabitants of all countries. Cornerstones include freedom of assembly and speech, inclusiveness and equality, membership, consent, voting, right to life and minority rights.
",2
769,"The notion of democracy has evolved over time considerably,[2]
and, generally, the two current types of democracy are direct and representative. In a direct democracy, the people directly deliberate and decide on legislation. In a representative democracy, the people elect representatives to deliberate and decide on legislation, such as in parliamentary or presidential democracy.[3] Liquid democracy combines elements of these two basic types. 
",2
770,"Prevalent day-to-day decision making of democracies is the majority rule,[4][5] though other decision making approaches like supermajority and consensus have been equally integral to democracies. They serve the crucial purpose of inclusiveness and broader legitimacy on sensitive issues, counterbalancing majoritarianism, and therefore mostly take precedence on a constitutional level.
",2
771,"In the common variant of liberal democracy, the powers of the majority are exercised within the framework of a representative democracy, but the constitution limits the majority and protects the minority, usually through the enjoyment by all of certain individual rights, e.g. freedom of speech, or freedom of association.[6][7] Besides these general types of democracy, there have been a wealth of further types (see below). 
",2
772,"Democracy makes all forces struggle repeatedly to realize their interests and devolves power from groups of people to sets of rules.[8] Western democracy, as distinct from that which existed in antiquity, is generally considered to have originated in city-states such as Classical Athens and the Roman Republic, where various schemes and degrees of enfranchisement of the free male population were observed before the form disappeared in the West at the beginning of late antiquity. The English word dates back to the 16th century, from the older Middle French and Middle Latin equivalents.
",2
773,"According to American political scientist Larry Diamond, democracy consists of four key elements: a political system for choosing and replacing the government through free and fair elections; the active participation of the people, as citizens, in politics and civic life; protection of the human rights of all citizens; and a rule of law, in which the laws and procedures apply equally to all citizens.[9] Todd Landman, nevertheless, draws our attention to the fact that democracy and human rights are two different concepts and that ""there must be greater specificity in the conceptualisation and operationalisation of democracy and human rights"".[10]
",2
774,"The term appeared in the 5th century BC to denote the political systems then existing in Greek city-states, notably Athens, to mean ""rule of the people"", in contrast to aristocracy (ἀριστοκρατία, aristokratía), meaning ""rule of an elite"". While theoretically, these definitions are in opposition, in practice the distinction has been blurred historically.[11] The political system of Classical Athens, for example, granted democratic citizenship to free men and excluded slaves and women from political participation. In virtually all democratic governments throughout ancient and modern history, democratic citizenship consisted of an elite class, until full enfranchisement was won for all adult citizens in most modern democracies through the suffrage movements of the 19th and 20th centuries.
",2
775,"Democracy contrasts with forms of government where power is either held by an individual, as in an absolute monarchy, or where power is held by a small number of individuals, as in an oligarchy. Nevertheless, these oppositions, inherited from Greek philosophy,[12] are now ambiguous because contemporary governments have mixed democratic, oligarchic and monarchic elements. Karl Popper defined democracy in contrast to dictatorship or tyranny, thus focusing on opportunities for the people to control their leaders and to oust them without the need for a revolution.[13]
",2
776,"No consensus exists on how to define democracy – indeed, one study found that at least 2,234 descriptions of democracy exist in the English language[15] - but legal equality, political freedom and rule of law have been identified as important characteristics.[16][17] These principles are reflected in all eligible citizens being equal before the law and having equal access to legislative processes.[citation needed] For example, in a representative democracy, every vote has equal weight, no unreasonable restrictions can apply to anyone seeking to become a representative,[according to whom?] and the freedom of its eligible citizens is secured by legitimised rights and liberties which are typically protected by a constitution.[18][19] Other uses of ""democracy"" include that of direct democracy.
",2
777,"One theory holds that democracy requires three fundamental principles: upward control (sovereignty residing at the lowest levels of authority), political equality, and social norms by which individuals and institutions only consider acceptable acts that reflect the first two principles of upward control and political equality.[20]
",2
778,"The term ""democracy"" is sometimes used as shorthand for liberal democracy, which is a variant of representative democracy that may include elements such as political pluralism; equality before the law; the right to petition elected officials for redress of grievances; due process; civil liberties; human rights; and elements of civil society outside the government.[citation needed] Roger Scruton argues that democracy alone cannot provide personal and political freedom unless the institutions of civil society are also present.[21]
",2
779,"In some countries, notably in the United Kingdom which originated the Westminster system, the dominant principle is that of parliamentary sovereignty, while maintaining judicial independence.[22][23] In India, parliamentary sovereignty is subject to the Constitution of India which includes judicial review.[24] Though the term ""democracy"" is typically used in the context of a political state, the principles also are applicable to private organisations.
",2
780,"There are many decision-making methods used in democracies, but majority rule is the dominant form. Without compensation, like legal protections of individual or group rights, political minorities can be oppressed by the ""tyranny of the majority"". Majority rule is a competitive approach, opposed to consensus democracy, creating the need that elections, and generally deliberation, are substantively and procedurally ""fair,"" i.e. just and equitable. In some countries, freedom of political expression, freedom of speech, freedom of the press, and internet democracy are considered important to ensure that voters are well informed, enabling them to vote according to their own interests.[25][26]
",2
781,"It has also been suggested that a basic feature of democracy is the capacity of all voters to participate freely and fully in the life of their society.[27] With its emphasis on notions of social contract and the collective will of all the voters, democracy can also be characterised as a form of political collectivism because it is defined as a form of government in which all eligible citizens have an equal say in lawmaking.[28]
",2
782,"Republics, though often associated with democracy because of the shared principle of rule by consent of the governed, are not necessarily democracies, as republicanism does not specify how the people are to rule.[29]
Classically the term ""republic""  encompassed both democracies and aristocracies.[30][31] In a modern sense the republican form of government is a form of government without monarch. Because of this democracies can be republics or constitutional monarchies, such as the United Kingdom.
",2
783,"Historically, democracies and republics have been rare.[33] Republican theorists linked democracy to small size: as political units grew in size, the likelihood increased that the government would turn despotic.[33][34] At the same time, small political units were vulnerable to conquest.[33] Montesquieu wrote, ""If a republic be small, it is destroyed by a foreign force; if it be large, it is ruined by an internal imperfection.""[35] According to Johns Hopkins University political scientist Daniel Deudney, the creation of the United States, with its large size and its system of checks and balances, was a solution to the dual problems of size.[33]
",2
784,"Retrospectively different polities, outside of declared democracies, have been described as proto-democratic (see History of democracy).
",2
785,"The term democracy first appeared in ancient Greek political and philosophical thought in the city-state of Athens during classical antiquity.[36][37] The word comes from demos '(common) people' and kratos 'strength'.[38] Led by Cleisthenes, Athenians established what is generally held as the first democracy in 508–507 BC. Cleisthenes is referred to as ""the father of Athenian democracy"".[39]
",2
786,"Athenian democracy took the form of a direct democracy, and it had two distinguishing features: the random selection of ordinary citizens to fill the few existing government administrative and judicial offices,[40] and a legislative assembly consisting of all Athenian citizens.[41] All eligible citizens were allowed to speak and vote in the assembly, which set the laws of the city state. However, Athenian citizenship excluded women, slaves, foreigners (μέτοικοι / métoikoi), and men under 20 years of age.[42][43][contradictory]
Owning land was not a requirement for citizenship, but it did allow one to purchase land.[44] The exclusion of large parts of the population from the citizen body is closely related to the ancient understanding of citizenship. In most of antiquity the benefit of citizenship was tied to the obligation to fight war campaigns.[45]
",2
787,"Athenian democracy was not only direct in the sense that decisions were made by the assembled people, but also the most direct in the sense that the people through the assembly, boule and courts of law controlled the entire political process and a large proportion of citizens were involved constantly in the public business.[46] Even though the rights of the individual were not secured by the Athenian constitution in the modern sense (the ancient Greeks had no word for ""rights""[47]), the Athenians enjoyed their liberties not in opposition to the government but by living in a city that was not subject to another power and by not being subjects themselves to the rule of another person.[48]
",2
788,"Range voting appeared in Sparta as early as 700 BC. The Apella was an assembly of the people, held once a month, in which every male citizen of at least 30 years of age could participate. In the Apella, Spartans elected leaders and cast votes by range voting and shouting (the vote is then decided on how loudly the crowd shouts). Aristotle called this ""childish"", as compared with the stone voting ballots used by the Athenians. Sparta adopted it because of its simplicity, and to prevent any bias voting, buying, or cheating that was predominant in the early democratic elections.[49][50]
",2
789,"Even though the Roman Republic contributed significantly to many aspects of democracy, only a minority of Romans were citizens with votes in elections for representatives. The votes of the powerful were given more weight through a system of gerrymandering, so most high officials, including members of the Senate, came from a few wealthy and noble families.[51] In addition, the overthrow of the Roman Kingdom was the first case in the Western world of a polity being formed with the explicit purpose of being a republic, although it didn't have much of a democracy. The Roman model of governance inspired many political thinkers over the centuries,[52] and today's modern representative democracies imitate more the Roman than the Greek models because it was a state in which supreme power was held by the people and their elected representatives, and which had an elected or nominated leader.[53]
",2
790,"Vaishali, capital city of the Vajjian Confederacy of (Vrijji mahajanapada), India was also considered[by whom?] one of the first examples of a republic around the 6th century BCE.[54][55][56][failed verification]
",2
791,"Other cultures, such as the Iroquois Nation in the Americas between around 1450 and 1600 AD also developed a form of democratic society before they came in contact with the Europeans. This indicates that forms of democracy may have been invented in other societies around the world.[citation needed]
",2
792,"While most regions in Europe during the Middle Ages were ruled by clergy or feudal lords, there existed various systems involving elections or assemblies, although often only involving a small part of the population. In Scandinavia, bodies known as things consisted of freemen presided by a lawspeaker. These deliberative bodies were responsible for settling political questions, and variants included the Althing in Iceland and the Løgting in the Faeroe Islands.[57][58] The veche, found in Eastern Europe, was a similar body to the Scandinavian thing. In the Roman Catholic Church, the pope has been elected by a papal conclave composed of cardinals since 1059. The first documented parliamentary body in Europe was the Cortes of León. Established by Alfonso IX in 1188, the Cortes had authority over setting taxation, foreign affairs and legislating, though the exact nature of its role remains disputed.[59] The Republic of Ragusa, established in 1358 and centered around the city of Dubrovnik, provided representation and voting rights to its male aristocracy only. Various Italian city-states and polities had republic forms of government. For instance, the Republic of Florence, established in 1115, was led by the Signoria whose members were chosen by sortition. In 10th–15th century Frisia, a distinctly non-feudal society, the right to vote on local matters and on county officials was based on land size. The Kouroukan Fouga divided the Mali Empire into ruling clans (lineages) that were represented at a great assembly called the Gbara. However, the charter made Mali more similar to a constitutional monarchy than a democratic republic.
",2
793,"The Parliament of England had its roots in the restrictions on the power of kings written into Magna Carta (1215), which explicitly protected certain rights of the King's subjects and implicitly supported what became the English writ of habeas corpus, safeguarding individual freedom against unlawful imprisonment with right to appeal.[60][61] The first representative national assembly in England was Simon de Montfort's Parliament in 1265.[62][63] The emergence of petitioning is some of the earliest evidence of parliament being used as a forum to address the general grievances of ordinary people. However, the power to call parliament remained at the pleasure of the monarch.[64]
",2
794,"Studies have linked the emergence of parliamentary institutions in Europe during the medieval period to urban agglomeration and the creation of new classes, such as artisans,[65] as well as the presence of nobility and religious elites.[66] Scholars have also linked the emergence of representative government to Europe's relative political fragmentation.[67] New York University political scientist David Stasavage links the fragmentation of Europe, and its subsequent democratization, to the manner in which the Roman Empire collapsed: Roman territory was conquered by small fragmented groups of Germanic tribes, thus leading to the creation of small political units where rulers were relatively weak and needed the consent of the governed to ward off foreign threats.[68]
",2
795,"In 17th century England, there was renewed interest in Magna Carta.[69] The Parliament of England passed the Petition of Right in 1628 which established certain liberties for subjects. The English Civil War (1642–1651) was fought between the King and an oligarchic but elected Parliament,[70][71] during which the idea of a political party took form with groups debating rights to political representation during the Putney Debates of 1647.[72] Subsequently, the Protectorate (1653–59) and the English Restoration (1660) restored more autocratic rule, although Parliament passed the Habeas Corpus Act in 1679 which strengthened the convention that forbade detention lacking sufficient cause or evidence. After the Glorious Revolution of 1688, the Bill of Rights was enacted in 1689 which codified certain rights and liberties and is still in effect. The Bill set out the requirement for regular elections, rules for freedom of speech in Parliament and limited the power of the monarch, ensuring that, unlike much of Europe at the time, royal absolutism would not prevail.[73][74] Economic historians Douglass North and Barry Weingast have characterized the institutions implemented in the Glorious Revolution as a resounding success in terms of restraining the government and ensuring protection for property rights.[75]
",2
796,"Renewed interest in the Magna Carta, the English Civil War, and the Glorious Revolution in the 17th century prompted the growth of political philosophy on the British Isles. Thomas Hobbes was the first philosopher to articulate a detailed social contract theory. Writing in Leviathan (1651), Hobbes theorized that individuals living in the state of nature led lives that were ""solitary, poor, nasty, brutish and short"" and constantly waged a war of all against all. In order to prevent the occurrence of an anarchic state of nature, Hobbes reasoned that individuals ceded their rights to a strong, authoritarian government. Later, philosopher and physician John Locke would posit a different interpretation of social contract theory. Writing in his Two Treatises of Government (1689), Locke posited that all individuals possessed the inalienable rights to life, liberty and estate (property).[76] According to Locke, individuals would voluntarily come together to form a state for the purposes of defending their rights. Particularly important for Locke were property rights, whose protection Locke deemed to be a government's primary purpose.[77] Furthermore, Locke asserted that governments were legitimate only if they held the consent of the governed. For Locke, citizens had the right to revolt against a government that acted against their interest or became tyrannical.[78] Although they were not widely read during his lifetime, Locke's works are considered the founding documents of liberal thought and profoundly influenced the leaders of the American Revolution and later the French Revolution.[79] His liberal democratic framework of governance remains the preeminent form of democracy in the world. 
",2
797,"In the Cossack republics of Ukraine in the 16th and 17th centuries, the Cossack Hetmanate and Zaporizhian Sich, the holder of the highest post of Hetman was elected by the representatives from the country's districts.
",2
798,"In North America, representative government began in Jamestown, Virginia, with the election of the House of Burgesses (forerunner of the Virginia General Assembly) in 1619. English Puritans who migrated from 1620 established colonies in New England whose local governance was democratic;[80] although these local assemblies had some small amounts of devolved power, the ultimate authority was held by the Crown and the English Parliament. The Puritans (Pilgrim Fathers), Baptists, and Quakers who founded these colonies applied the democratic organisation of their congregations also to the administration of their communities in worldly matters.[81][82][83]
",2
799,"The first Parliament of Great Britain was established in 1707, after the merger of the Kingdom of England and the Kingdom of Scotland under the Acts of Union. Although the monarch increasingly became a figurehead,[85] Parliament was only elected by male property owners, which amounted to 3% of the population in 1780.[86] The first known British person of African heritage to vote in a general election, Ignatius Sancho, voted in 1774 and 1780.[87] During the Age of Liberty in Sweden (1718–1772), civil rights were expanded and power shifted from the monarch to parliament. The taxed peasantry was represented in parliament, although with little influence, but commoners without taxed property had no suffrage.
",2
800,"The creation of the short-lived Corsican Republic in 1755 marked the first nation in modern history to adopt a democratic constitution (all men and women above age of 25 could vote).[88] This Corsican Constitution was the first based on Enlightenment principles and included female suffrage, something that was not granted in most other democracies until the 20th century.
",2
801,"In the American colonial period before 1776, and for some time after, often only adult white male property owners could vote; enslaved Africans, most free black people and most women were not extended the franchise. This changed state by state, beginning with the republican State of New Connecticut, soon after called Vermont, which, on declaring independence of Great Britain in 1777, adopted a constitution modelled on Pennsylvania's with citizenship and democratic suffrage for males with or without property, and went on to abolish slavery.[89][90] The American Revolution led to the adoption of the United States Constitution in 1787, the oldest surviving, still active, governmental codified constitution. The Constitution provided for an elected government and protected civil rights and liberties for some, but did not end slavery nor extend voting rights in the United States, instead leaving the issue of suffrage to the individual states.[91] Generally, states limited suffrage to white male property owners and taxpayers.[92] At the time of the first Presidential election in 1789, about 6% of the population was eligible to vote.[93] The Naturalization Act of 1790 limited U.S. citizenship to whites only.[94] The Bill of Rights in 1791 set limits on government power to protect personal freedoms but had little impact on judgements by the courts for the first 130 years after ratification.[95]
",2
802,"In 1789, Revolutionary France adopted the Declaration of the Rights of Man and of the Citizen and, although short-lived, the National Convention was elected by all men in 1792.[96] The Polish-Lithuanian Constitution of 3 May 1791 sought to implement a more effective constitutional monarchy, introduced political equality between townspeople and nobility, and placed the peasants under the protection of the government, mitigating the worst abuses of serfdom. In force for less than 19 months, it was declared null and void by the Grodno Sejm that met in 1793.[97][98] Nonetheless, the 1791 Constitution helped keep alive Polish aspirations for the eventual restoration of the country's sovereignty over a century later.
",2
803,"However, in the early 19th century, little of democracy—as theory, practice, or even as word—remained in the North Atlantic world.[99] During this period, slavery remained a social and economic institution in places around the world. This was particularly the case in the United States, where eight serving presidents had owned slaves, and the last fifteen slave states kept slavery legal in the American South until the Civil War.[100] Advocating the movement of black people from the US to locations where they would enjoy greater freedom and equality, in the 1820s the abolitionist members of the ACS established the settlement of Liberia.[101] The United Kingdom's Slave Trade Act 1807 banned the trade across the British Empire, which was enforced internationally by the Royal Navy under treaties Britain negotiated with other nations.[102] In 1833, the UK passed the Slavery Abolition Act which took effect across the British Empire, although slavery was legally allowed to continue in areas controlled by the East India Company, in Ceylon, and in Saint Helena for an additional ten years.[103]
",2
804,"As the voting franchise in the United Kingdom was increased, it also was made more uniform in a series of reforms that began with the Reform Act 1832 and continued into the 20th century, notably with the Equal Franchise Act 1928. Universal male suffrage was established in France in March 1848 in the wake of the French Revolution of 1848.[104] In 1848, several revolutions broke out in Europe as rulers were confronted with popular demands for liberal constitutions and more democratic government.[105]
",2
805,"In the United States, the 1828 presidential election was the first in which non-property-holding white males could vote in the vast majority of states. Voter turnout soared during the 1830s, reaching about 80% of the adult white male population in the 1840 presidential election.[106] North Carolina was the last state to abolish property qualification in 1856 resulting in a close approximation to universal white male suffrage (however tax-paying requirements remained in five states in 1860 and survived in two states until the 20th century).[107][108][109][nb 1] In the 1860 United States Census, the slave population had grown to four million,[110] and in Reconstruction after the Civil War, three constitutional amendments were passed: the 13th Amendment (1865) that ended slavery; the 14th Amendment (1869) that gave black people citizenship, and the 15th Amendment (1870) that gave black males a nominal right to vote.[111][112] Full enfranchisement of citizens was not secured until after the civil rights movement gained passage by the US Congress of the Voting Rights Act of 1965.[113][114]
",2
806,"In 1876 the Ottoman Empire transitioned from an absolute monarchy to a constitutional one, and held two elections the next year to elect members to her newly formed parliament.[115] Provisional Electoral Regulations were issued, stating that the elected members of the Provincial Administrative Councils would elect members to the first Parliament. Later that year, a new constitution was promulgated, which provided for a bicameral Parliament with a Senate appointed by the Sultan and a popularly elected Chamber of Deputies. Only men above the age of 30 who were competent in Turkish and had full civil rights were allowed to stand for election. Reasons for disqualification included holding dual citizenship, being employed by a foreign government, being bankrupt, employed as a servant, or having ""notoriety for ill deeds"". Full universal suffrage was achieved in 1934. 
",2
807,"In 1893 the self-governing colony New Zealand became the first country in the world (except for the short-lived 18th-century Corsican Republic) to grant active universal suffrage by giving women the right to vote.[116]
",2
808,"20th-century transitions to liberal democracy have come in successive ""waves of democracy"", variously resulting from wars, revolutions, decolonisation, and religious and economic circumstances.[117] Global waves of ""democratic regression"" reversing democratization, have also occurred in the 1920s and 30s, in the 1960s and 1970s, and in the 2010s.[118][119]
",2
809,"World War I and the dissolution of the Ottoman and Austro-Hungarian empires resulted in the creation of new nation-states from Europe, most of them at least nominally democratic.
",2
810,"In the 1920s democracy flourished and women's suffrage advanced, but the Great Depression brought disenchantment and most of the countries of Europe, Latin America, and Asia turned to strong-man rule or dictatorships. Fascism and dictatorships flourished in Nazi Germany, Italy, Spain and Portugal, as well as non-democratic governments in the Baltics, the Balkans, Brazil, Cuba, China, and Japan, among others.[120]
",2
811,"World War II brought a definitive reversal of this trend in western Europe. The democratisation of the American, British, and French sectors of occupied Germany (disputed[121]), Austria, Italy, and the occupied Japan served as a model for the later theory of government change. However, most of Eastern Europe, including the Soviet sector of Germany fell into the non-democratic Soviet bloc.
",2
812,"The war was followed by decolonisation, and again most of the new independent states had nominally democratic constitutions. India emerged as the world's largest democracy and continues to be so.[122] Countries that were once part of the British Empire often adopted the British Westminster system.[123][124]
",2
813,"By 1960, the vast majority of country-states were nominally democracies, although most of the world's populations lived in nations that experienced sham elections, and other forms of subterfuge (particularly in ""Communist"" nations and the former colonies.)
",2
814,"A subsequent wave of democratisation brought substantial gains toward true liberal democracy for many nations. Portugal, Spain, and several of the military dictatorships in South America returned to civilian rule in the 1970s and 1980s.[nb 2] This was followed by nations in East and South Asia by the mid-to-late 1980s.
",2
815,"Economic malaise in the 1980s, along with resentment of Soviet oppression, contributed to the collapse of the Soviet Union, the associated end of the Cold War, and the democratisation and liberalisation of the former Eastern bloc countries. The most successful of the new democracies were those geographically and culturally closest to western Europe, and they are now members or candidate members of the European Union. In 1986, after the toppling of the most prominent Asian dictatorship, the only democratic state of its kind at the time emerged in the Philippines with the rise of Corazon Aquino, who would later be known as the Mother of Asian Democracy.
",2
816,"The liberal trend spread to some nations in Africa in the 1990s, most prominently in South Africa. Some recent examples of attempts of liberalisation include the Indonesian Revolution of 1998, the Bulldozer Revolution in Yugoslavia, the Rose Revolution in Georgia, the Orange Revolution in Ukraine, the Cedar Revolution in Lebanon, the Tulip Revolution in Kyrgyzstan, and the Jasmine Revolution in Tunisia.
",2
817,"According to Freedom House, starting in 2005, there have been eleven consecutive years in which declines in political rights and civil liberties throughout the world have outnumbered improvements,[126] as populist and nationalist political forces have gained ground everywhere from Poland (under the Law and Justice Party) to the Philippines (under Rodrigo Duterte).[126][118]
",2
818,"According to Freedom House, in 2007 there were 123 electoral democracies (up from 40 in 1972).[127] According to World Forum on Democracy, electoral democracies now represent 120 of the 192 existing countries and constitute 58.2 percent of the world's population. At the same time liberal democracies i.e. countries Freedom House regards as free and respectful of basic human rights and the rule of law are 85 in number and represent 38 percent of the global population.[128]
",2
819,"Most electoral democracies continue to exclude those younger than 18 from voting.[129] The voting age has been lowered to 16 for national elections in a number of countries, including Brazil, Austria, Cuba, and Nicaragua. In California, a 2004 proposal to permit a quarter vote at 14 and a half vote at 16 was ultimately defeated. In 2008, the German parliament proposed but shelved a bill that would grant the vote to each citizen at birth, to be used by a parent until the child claims it for themselves.
",2
820,"In 2007 the United Nations declared 15 September the International Day of Democracy.[130]
",2
821,"In a Freedom House report released in 2018, Democracy Scores for most countries declined for the 12th consecutive year.[131] The Christian Science Monitor reported that nationalist and populist political ideologies were gaining ground, at the expense of rule of law, in countries like Poland, Turkey and Hungary. For example, in Poland, the President appointed 27 new Supreme Court judges over objections from the European Union. In Turkey, thousands of judges were removed from their positions following a failed coup attempt during a government crackdown .[132]
",2
822,"Republics, though often associated with democracy because of the shared principle of rule by consent of the governed, are not necessarily democracies, as republicanism does not specify how the people are to rule.[29]
",2
823,"Aristotle contrasted rule by the many (democracy/timocracy), with rule by the few (oligarchy/aristocracy), and with rule by a single person (tyranny or today autocracy/absolute monarchy). He also thought that there was a good and a bad variant of each system (he considered democracy to be the degenerate counterpart to timocracy).[133][134]
",2
824,"A common view among early and renaissance Republican theorists was that democracy could only survive in small political communities.[135] Heeding the lessons of the Roman Republic's shift to monarchism as it grew larger or smaller, these Republican theorists held that the expansion of territory and population inevitably led to tyranny.[135] Democracy was therefore highly fragile and rare historically, as it could only survive in small political units, which due to their size were vulnerable to conquest by larger political units.[135] Montesquieu famously said, ""if a republic is small, it is destroyed by an outside force; if it is large, it is destroyed by an internal vice.""[135] Rousseau asserted, ""It is, therefore the natural property of small states to be governed as a republic, of middling ones to be subject to a monarch, and of large empires to be swayed by a despotic prince.""[135]
",2
825,"Among modern political theorists, there are three contending conceptions of democracy: aggregative democracy, deliberative democracy, and radical democracy.[136]
",2
826,"The theory of aggregative democracy claims that the aim of the democratic processes is to solicit citizens' preferences and aggregate them together to determine what social policies society should adopt. Therefore, proponents of this view hold that democratic participation should primarily focus on voting, where the policy with the most votes gets implemented.
",2
827,"Different variants of aggregative democracy exist. Under minimalism, democracy is a system of government in which citizens have given teams of political leaders the right to rule in periodic elections. According to this minimalist conception, citizens cannot and should not ""rule"" because, for example, on most issues, most of the time, they have no clear views or their views are not well-founded. Joseph Schumpeter articulated this view most famously in his book Capitalism, Socialism, and Democracy.[137] Contemporary proponents of minimalism include William H. Riker, Adam Przeworski, Richard Posner.
",2
828,"According to the theory of direct democracy, on the other hand, citizens should vote directly, not through their representatives, on legislative proposals. Proponents of direct democracy offer varied reasons to support this view. Political activity can be valuable in itself, it socialises and educates citizens, and popular participation can check powerful elites. Most importantly, citizens do not rule themselves unless they directly decide laws and policies.
",2
829,"Governments will tend to produce laws and policies that are close to the views of the median voter—with half to their left and the other half to their right. This is not a desirable outcome as it represents the action of self-interested and somewhat unaccountable political elites competing for votes. Anthony Downs suggests that ideological political parties are necessary to act as a mediating broker between individual and governments. Downs laid out this view in his 1957 book An Economic Theory of Democracy.[138]
",2
830,"Robert A. Dahl argues that the fundamental democratic principle is that, when it comes to binding collective decisions, each person in a political community is entitled to have his/her interests be given equal consideration (not necessarily that all people are equally satisfied by the collective decision). He uses the term polyarchy to refer to societies in which there exists a certain set of institutions and procedures which are perceived as leading to such democracy. First and foremost among these institutions is the regular occurrence of free and open elections which are used to select representatives who then manage all or most of the public policy of the society. However, these polyarchic procedures may not create a full democracy if, for example, poverty prevents political participation.[139] Similarly, Ronald Dworkin argues that ""democracy is a substantive, not a merely procedural, ideal.""[140]
",2
831,"Deliberative democracy is based on the notion that democracy is government by deliberation. Unlike aggregative democracy, deliberative democracy holds that, for a democratic decision to be legitimate, it must be preceded by authentic deliberation, not merely the aggregation of preferences that occurs in voting. Authentic deliberation is deliberation among decision-makers that is free from distortions of unequal political power, such as power a decision-maker obtained through economic wealth or the support of interest groups.[141][142][143] If the decision-makers cannot reach consensus after authentically deliberating on a proposal, then they vote on the proposal using a form of majority rule. Citizens assemblies are considered by many scholars as practical examples of deliberative democracy,[144][145][146] with a recent OECD report identifying citizens assemblies as an increasingly popular mechanism to involve citizens in governmental decision-making.[147]
",2
832,"Radical democracy is based on the idea that there are hierarchical and oppressive power relations that exist in society. Democracy's role is to make visible and challenge those relations by allowing for difference, dissent and antagonisms in decision-making processes.
",2
833,"Several freedom indices are published by several organisations according to their own various definitions of the term and relying on different types of data:[150]
",2
834,"Dieter Fuchs and Edeltraud Roller suggest that, in order to truly measure the quality of democracy, objective measurements need to be complemented by ""subjective measurements based on the perspective of citizens"".[158] Similarly, Quinton Mayne and Brigitte Geißel also defend that the quality of democracy does not depend exclusively on the performance of institutions, but also on the citizens' own dispositions and commitment.[159]
",2
835,"Because democracy is an overarching concept that includes the functioning of diverse institutions which are not easy to measure, strong limitations exist in quantifying and econometrically measuring the potential effects of democracy or its relationship with other phenomena—whether inequality, poverty, education etc.[160] Given the constraints in acquiring reliable data with within-country variation on aspects of democracy, academics have largely studied cross-country variations. Yet variations between democratic institutions are very large across countries which constrains meaningful comparisons using statistical approaches. Since democracy is typically measured aggregately as a macro variable using a single observation for each country and each year, studying democracy faces a range of econometric constraints and is limited to basic correlations. Cross-country comparison of a composite, comprehensive and qualitative concept like democracy may thus not always be, for many purposes, methodologically rigorous or useful.[160]
",2
836,"Democracy has taken a number of forms, both in theory and practice. Some varieties of democracy provide better representation and more freedom for their citizens than others.[161][162] However, if any democracy is not structured to prohibit the government from excluding the people from the legislative process, or any branch of government from altering the separation of powers in its favour, then a branch of the system can accumulate too much power and destroy the democracy.[163][164][165]
",2
837,"The following kinds of democracy are not exclusive of one another: many specify details of aspects that are independent of one another and can co-exist in a single system.
",2
838,"Several variants of democracy exist, but there are two basic forms, both of which concern how the whole body of all eligible citizens executes its will. One form of democracy is direct democracy, in which all eligible citizens have active participation in the political decision making, for example voting on policy initiatives directly.[166] In most modern democracies, the whole body of eligible citizens remain the sovereign power but political power is exercised indirectly through elected representatives; this is called a representative democracy.
",2
839,"Direct democracy is a political system where the citizens participate in the decision-making personally, contrary to relying on intermediaries or representatives. The use of a lot system, a characteristic of Athenian democracy, is unique to direct democracies. In this system, important governmental and administrative tasks are performed by citizens picked from a lottery.[167] A direct democracy gives the voting population the power to:
",2
840,"Within modern-day representative governments, certain electoral tools like referendums, citizens' initiatives and recall elections are referred to as forms of direct democracy.[168] However, some advocates of direct democracy argue for local assemblies of face-to-face discussion. Direct democracy as a government system currently exists in the Swiss cantons of Appenzell Innerrhoden and Glarus,[169] the Rebel Zapatista Autonomous Municipalities,[170] communities affiliated with the CIPO-RFM,[171] the Bolivian city councils of FEJUVE,[172] and Kurdish cantons of Rojava.[173]
",2
841,"Representative democracy involves the election of government officials by the people being represented. If the head of state is also democratically elected then it is called a democratic republic.[174] The most common mechanisms involve election of the candidate with a majority or a plurality of the votes. Most western countries have representative systems.[169]
",2
842,"Representatives may be elected or become diplomatic representatives by a particular district (or constituency), or represent the entire electorate through proportional systems, with some using a combination of the two. Some representative democracies also incorporate elements of direct democracy, such as referendums. A characteristic of representative democracy is that while the representatives are elected by the people to act in the people's interest, they retain the freedom to exercise their own judgement as how best to do so. Such reasons have driven criticism upon representative democracy,[175][176] pointing out the contradictions of representation mechanisms with democracy[177][178]
",2
843,"Parliamentary democracy is a representative democracy where government is appointed by, or can be dismissed by, representatives as opposed to a ""presidential rule"" wherein the president is both head of state and the head of government and is elected by the voters. Under a parliamentary democracy, government is exercised by delegation to an executive ministry and subject to ongoing review, checks and balances by the legislative parliament elected by the people.[179][180][181][182]
",2
844,"Parliamentary systems have the right to dismiss a Prime Minister at any point in time that they feel he or she is not doing their job to the expectations of the legislature. This is done through a Vote of No Confidence where the legislature decides whether or not to remove the Prime Minister from office by a majority support for his or her dismissal.[183] In some countries, the Prime Minister can also call an election whenever he or she so chooses, and typically the Prime Minister will hold an election when he or she knows that they are in good favour with the public as to get re-elected. In other parliamentary democracies, extra elections are virtually never held, a minority government being preferred until the next ordinary elections. An important feature of the parliamentary democracy is the concept of the ""loyal opposition"". The essence of the concept is that the second largest political party (or coalition) opposes the governing party (or coalition), while still remaining loyal to the state and its democratic principles.
",2
845,"Presidential Democracy is a system where the public elects the president through free and fair elections. The president serves as both the head of state and head of government controlling most of the executive powers. The president serves for a specific term and cannot exceed that amount of time. Elections typically have a fixed date and aren't easily changed. The president has direct control over the cabinet, specifically appointing the cabinet members.[183]
",2
846,"The president cannot be easily removed from office by the legislature, but he or she cannot remove members of the legislative branch any more easily. This provides some measure of separation of powers. In consequence, however, the president and the legislature may end up in the control of separate parties, allowing one to block the other and thereby interfere with the orderly operation of the state. This may be the reason why presidential democracy is not very common outside the Americas, Africa, and Central and Southeast Asia.[183]
",2
847,"A semi-presidential system is a system of democracy in which the government includes both a prime minister and a president. The particular powers held by the prime minister and president vary by country.[183]
",2
848,"Some modern democracies that are predominantly representative in nature also heavily rely upon forms of political action that are directly democratic. These democracies, which combine elements of representative democracy and direct democracy, are termed hybrid democracies,[184] semi-direct democracies or participatory democracies. Examples include Switzerland and some U.S. states, where frequent use is made of referendums and initiatives.
",2
849,"The Swiss confederation is a semi-direct democracy.[169] At the federal level, citizens can propose changes to the constitution (federal popular initiative) or ask for a referendum to be held on any law voted by the parliament.[169] Between January 1995 and June 2005, Swiss citizens voted 31 times, to answer 103 questions (during the same period, French citizens participated in only two referendums).[169] Although in the past 120 years less than 250 initiatives have been put to referendum. The populace has been conservative, approving only about 10% of the initiatives put before them; in addition, they have often opted for a version of the initiative rewritten by government.[citation needed]
",2
850,"Examples include the extensive use of referendums in the US state of California, which is a state that has more than 20 million voters.[185]
",2
851,"In New England, Town meetings are often used, especially in rural areas, to manage local government. This creates a hybrid form of government, with a local direct democracy and a representative state government. For example, most Vermont towns hold annual town meetings in March in which town officers are elected, budgets for the town and schools are voted on, and citizens have the opportunity to speak and be heard on political matters.[186]
",2
852,"Many countries such as the United Kingdom, Spain, the Netherlands, Belgium, Scandinavian countries, Thailand, Japan and Bhutan turned powerful monarchs into constitutional monarchs with limited or, often gradually, merely symbolic roles. For example, in the predecessor states to the United Kingdom, constitutional monarchy began to emerge and has continued uninterrupted since the Glorious Revolution of 1688 and passage of the Bill of Rights 1689.[22][73]
",2
853,"In other countries, the monarchy was abolished along with the aristocratic system (as in France, China, Russia, Germany, Austria, Hungary, Italy, Greece and Egypt). An elected president, with or without significant powers, became the head of state in these countries.
",2
854,"Elite upper houses of legislatures, which often had lifetime or hereditary tenure, were common in many nations. Over time, these either had their powers limited (as with the British House of Lords) or else became elective and remained powerful (as with the Australian Senate).
",2
855,"The term republic has many different meanings, but today often refers to a representative democracy with an elected head of state, such as a president, serving for a limited term, in contrast to states with a hereditary monarch as a head of state, even if these states also are representative democracies with an elected or appointed head of government such as a prime minister.[187]
",2
856,"The Founding Fathers of the United States rarely praised and often criticised democracy, which in their time tended to specifically mean direct democracy, often without the protection of a constitution enshrining basic rights; James Madison argued, especially in The Federalist No. 10, that what distinguished a direct democracy from a republic was that the former became weaker as it got larger and suffered more violently from the effects of faction, whereas a republic could get stronger as it got larger and combats faction by its very structure.
",2
857,"What was critical to American values, John Adams insisted,[188] was that the government be ""bound by fixed laws, which the people have a voice in making, and a right to defend."" As Benjamin Franklin was exiting after writing the U.S. constitution, Elizabeth Willing Powel[189] asked him ""Well, Doctor, what have we got—a republic or a monarchy?"". He replied ""A republic—if you can keep it.""[190]
",2
858,"A liberal democracy is a representative democracy in which the ability of the elected representatives to exercise decision-making power is subject to the rule of law, and moderated by a constitution or laws that emphasise the protection of the rights and freedoms of individuals, and which places constraints on the leaders and on the extent to which the will of the majority can be exercised against the rights of minorities (see civil liberties).
",2
859,"In a liberal democracy, it is possible for some large-scale decisions to emerge from the many individual decisions that citizens are free to make. In other words, citizens can ""vote with their feet"" or ""vote with their dollars"", resulting in significant informal government-by-the-masses that exercises many ""powers"" associated with formal government elsewhere.
",2
860,"Socialist thought has several different views on democracy. Social democracy, democratic socialism, and the dictatorship of the proletariat (usually exercised through Soviet democracy) are some examples. Many democratic socialists and social democrats believe in a form of participatory, industrial, economic and/or workplace democracy combined with a representative democracy.
",2
861,"Within Marxist orthodoxy there is a hostility to what is commonly called ""liberal democracy"", which is simply referred to as parliamentary democracy because of its often centralised nature. Because of orthodox Marxists' desire to eliminate the political elitism they see in capitalism, Marxists, Leninists and Trotskyists believe in direct democracy implemented through a system of communes (which are sometimes called soviets). This system ultimately manifests itself as council democracy and begins with workplace democracy.
",2
862,Democracy cannot consist solely of elections that are nearly always fictitious and managed by rich landowners and professional politicians.,2
863,"Anarchists are split in this domain, depending on whether they believe that a majority-rule is tyrannic or not.  To many anarchists, the only form of democracy considered acceptable is direct democracy. Pierre-Joseph Proudhon argued that the only acceptable form of direct democracy is one in which it is recognised that majority decisions are not binding on the minority, even when unanimous.[192] However, anarcho-communist Murray Bookchin criticised individualist anarchists for opposing democracy,[193] and says ""majority rule"" is consistent with anarchism.[194]
",2
864,"Some anarcho-communists oppose the majoritarian nature of direct democracy, feeling that it can impede individual liberty and opt-in favour of a non-majoritarian form of consensus democracy, similar to Proudhon's position on direct democracy.[195] Henry David Thoreau, who did not self-identify as an anarchist but argued for ""a better government""[196] and is cited as an inspiration by some anarchists, argued that people should not be in the position of ruling others or being ruled when there is no consent.
",2
865,"Sometimes called ""democracy without elections"", sortition chooses decision makers via a random process. The intention is that those chosen will be representative of the opinions and interests of the people at large, and be more fair and impartial than an elected official. The technique was in widespread use in Athenian Democracy and Renaissance Florence[197] and is still used in modern jury selection.
",2
866,"A consociational democracy allows for simultaneous majority votes in two or more ethno-religious constituencies, and policies are enacted only if they gain majority support from both or all of them.
",2
867,"A consensus democracy, in contrast, would not be dichotomous. Instead, decisions would be based on a multi-option approach, and policies would be enacted if they gained sufficient support, either in a purely verbal agreement or via a consensus vote—a multi-option preference vote. If the threshold of support were at a sufficiently high level, minorities would be as it were protected automatically. Furthermore, any voting would be ethno-colour blind.
",2
868,"Qualified majority voting is designed by the Treaty of Rome to be the principal method of reaching decisions in the European Council of Ministers. This system allocates votes to member states in part according to their population, but heavily weighted in favour of the smaller states. This might be seen as a form of representative democracy, but representatives to the Council might be appointed rather than directly elected.
",2
869,"Inclusive democracy is a political theory and political project that aims for direct democracy in all fields of social life: political democracy in the form of face-to-face assemblies which are confederated, economic democracy in a stateless, moneyless and marketless economy, democracy in the social realm, i.e. self-management in places of work and education, and ecological democracy which aims to reintegrate society and nature. The theoretical project of inclusive democracy emerged from the work of political philosopher Takis Fotopoulos in ""Towards An Inclusive Democracy"" and was further developed in the journal Democracy & Nature and its successor The International Journal of Inclusive Democracy.
",2
870,"The basic unit of decision making in an inclusive democracy is the demotic assembly, i.e. the assembly of demos, the citizen body in a given geographical area which may encompass a town and the surrounding villages, or even neighbourhoods of large cities. An inclusive democracy today can only take the form of a confederal democracy that is based on a network of administrative councils whose members or delegates are elected from popular face-to-face democratic assemblies in the various demoi. Thus, their role is purely administrative and practical, not one of policy-making like that of representatives in representative democracy.
",2
871,"The citizen body is advised by experts but it is the citizen body which functions as the ultimate decision-taker. Authority can be delegated to a segment of the citizen body to carry out specific duties, for example, to serve as members of popular courts, or of regional and confederal councils. Such delegation is made, in principle, by lot, on a rotation basis, and is always recallable by the citizen body. Delegates to regional and confederal bodies should have specific mandates.
",2
872,"A Parpolity or Participatory Polity is a theoretical form of democracy that is ruled by a Nested Council structure. The guiding philosophy is that people should have decision making power in proportion to how much they are affected by the decision. Local councils of 25–50 people are completely autonomous on issues that affect only them, and these councils send delegates to higher level councils who are again autonomous regarding issues that affect only the population affected by that council.
",2
873,"A council court of randomly chosen citizens serves as a check on the tyranny of the majority, and rules on which body gets to vote on which issue. Delegates may vote differently from how their sending council might wish but are mandated to communicate the wishes of their sending council. Delegates are recallable at any time. Referendums are possible at any time via votes of most lower-level councils, however, not everything is a referendum as this is most likely a waste of time. A parpolity is meant to work in tandem with a participatory economy.
",2
874,"Cosmopolitan democracy, also known as Global democracy or World Federalism, is a political system in which democracy is implemented on a global scale, either directly or through representatives. An important justification for this kind of system is that the decisions made in national or regional democracies often affect people outside the constituency who, by definition, cannot vote. By contrast, in a cosmopolitan democracy, the people who are affected by decisions also have a say in them.[198]
",2
875,"According to its supporters, any attempt to solve global problems is undemocratic without some form of cosmopolitan democracy. The general principle of cosmopolitan democracy is to expand some or all of the values and norms of democracy, including the rule of law; the non-violent resolution of conflicts; and equality among citizens, beyond the limits of the state. To be fully implemented, this would require reforming existing international organisations, e.g. the United Nations, as well as the creation of new institutions such as a World Parliament, which ideally would enhance public control over, and accountability in, international politics.
",2
876,"Cosmopolitan Democracy has been promoted, among others, by physicist Albert Einstein,[199] writer Kurt Vonnegut, columnist George Monbiot, and professors David Held and Daniele Archibugi.[200] The creation of the International Criminal Court in 2003 was seen as a major step forward by many supporters of this type of cosmopolitan democracy.
",2
877,"Creative Democracy is advocated by American philosopher John Dewey. The main idea about Creative Democracy is that democracy encourages individual capacity building and the interaction among the society. Dewey argues that democracy is a way of life in his work of ""Creative Democracy: The Task Before Us""[201] and an experience built on faith in human nature, faith in human beings, and faith in working with others. Democracy, in Dewey's view, is a moral ideal requiring actual effort and work by people; it is not an institutional concept that exists outside of ourselves. ""The task of democracy"", Dewey concludes, ""is forever that of creation of a freer and more humane experience in which all share and to which all contribute"".
",2
878,"Guided democracy is a form of democracy which incorporates regular popular elections, but which often carefully ""guides"" the choices offered to the electorate in a manner which may reduce the ability of the electorate to truly determine the type of government exercised over them.  Such democracies typically have only one central authority which is often not subject to meaningful public review by any other governmental authority.  Russian-style democracy has often been referred to as a ""Guided democracy.""[202]  Russian politicians have referred to their government as having only one center of power/ authority, as opposed to most other forms of democracy which usually attempt to incorporate two or more naturally competing sources of authority within the same government.[203]
",2
879,"Aside from the public sphere, similar democratic principles and mechanisms of voting and representation have been used to govern other kinds of groups. Many non-governmental organisations decide policy and leadership by voting. Most trade unions and cooperatives are governed by democratic elections. Corporations are controlled by shareholders on the principle of one share, one vote—sometimes supplemented by workplace democracy. Amitai Etzioni has postulated a system that fuses elements of democracy with sharia law, termed islamocracy.[204][citation needed]
",2
880,"Several justifications for democracy have been postulated.
",2
881,"Social contract theory argues that the legitimacy of government is based on consent of the governed, i.e. an election, and that political decisions must reflect the general will.
",2
882,"Condorcet's jury theorem is logical proof that if each decision-maker has a better than chance probability of making the right decision, then having the largest number of decision-makers, i.e. a democracy, will result in the best decisions. This has also been argued by theories of the wisdom of the crowd.
",2
883,"Democratic peace theory claims that liberal democracies do not go to war against each other.
",2
884,"In Why Nations Fail, Daron Acemoglu and James A. Robinson argue that democracies are more economically successful because undemocratic political systems tend to limit markets and favor monopolies at the expense of the creative destruction which is necessary for sustained economic growth.
",2
885,Arrow's impossibility theorem suggests that democracy is logically incoherent. This is based on a certain set of criteria for democratic decision-making being inherently conflicting.,2
886," However, Arrow's formal premises can be considered overly strict, and with their reasonable weakening, the logical incoherence of democracy looks much less critical.[2]
",2
887,"Some economists have criticized the efficiency of democracy, citing the premise of the irrational voter, or a voter who makes decisions without all of the facts or necessary information in order to make a truly informed decision. Another argument is that democracy slows down processes because of the amount of input and participation needed in order to go forward with a decision. A common example often quoted to substantiate this point is the high economic development achieved by China (a non-democratic country) as compared to India (a democratic country). According to economists, the lack of democratic participation in countries like China allows for unfettered economic growth.[205]
",2
888,"On the other hand, Socrates believed that democracy without educated masses (educated in the broader sense of being knowledgeable and responsible) would only lead to populism being the criteria to become an elected leader and not competence. This would ultimately lead to a demise of the nation. This was quoted by Plato in book 10 of The Republic, in Socrates' conversation with Adimantus.[206] Socrates was of the opinion that the right to vote must not be an indiscriminate right (for example by birth or citizenship), but must be given only to people who thought sufficiently of their choice.
",2
889,"The 20th-century Italian thinkers Vilfredo Pareto and Gaetano Mosca (independently) argued that democracy was illusory, and served only to mask the reality of elite rule. Indeed, they argued that elite oligarchy is the unbendable law of human nature, due largely to the apathy and division of the masses (as opposed to the drive, initiative and unity of the elites), and that democratic institutions would do no more than shift the exercise of power from oppression to manipulation.[207] As Louis Brandeis once professed, ""We may have democracy, or we may have wealth concentrated in the hands of a few, but we can't have both.""[clarification needed].[208] British writer Ivo Mosley, grandson of blackshirt Oswald Mosley describes in In the Name of the People: Pseudo-Democracy and the Spoiling of Our World, how and why current forms of electoral governance are destined to fall short of their promise.[209]
A study led by Princeton professor Martin Gilens of 1,779 U.S. government decisions concluded that
""elites and organized groups representing business interests have substantial independent impacts on U.S. government policy, while average citizens and mass-based interest groups have little or no independent influence."" [210]
",2
890,"Plato's The Republic presents a critical view of democracy through the narration of Socrates: ""Democracy, which is a charming form of government, full of variety and disorder, and dispensing a sort of equality to equals and unequaled alike.""[211] In his work, Plato lists 5 forms of government from best to worst. Assuming that the Republic was intended to be a serious critique of the political thought in Athens, Plato argues that only Kallipolis, an aristocracy led by the unwilling philosopher-kings (the wisest men), is a just form of government.[212]
",2
891,"James Madison critiqued direct democracy (which he referred to simply as ""democracy"") in Federalist No. 10, arguing that representative democracy—which he described using the term ""republic""—is a preferable form of government, saying: ""... democracies have ever been spectacles of turbulence and contention; have ever been found incompatible with personal security or the rights of property; and have in general been as short in their lives as they have been violent in their deaths."" Madison offered that republics were superior to democracies because republics safeguarded against tyranny of the majority, stating in Federalist No. 10: ""the same advantage which a republic has over a democracy, in controlling the effects of faction, is enjoyed by a large over a small republic"".
",2
892,"More recently, democracy is criticised for not offering enough political stability. As governments are frequently elected on and off there tends to be frequent changes in the policies of democratic countries both domestically and internationally. Even if a political party maintains power, vociferous, headline-grabbing protests and harsh criticism from the popular media are often enough to force sudden, unexpected political change. Frequent policy changes with regard to business and immigration are likely to deter investment and so hinder economic growth. For this reason, many people have put forward the idea that democracy is undesirable for a developing country in which economic growth and the reduction of poverty are top priorities.[213]
",2
893,"This opportunist alliance not only has the handicap of having to cater to too many ideologically opposing factions, but it is usually short-lived since any perceived or actual imbalance in the treatment of coalition partners, or changes to leadership in the coalition partners themselves, can very easily result in the coalition partner withdrawing its support from the government.
",2
894,"Biased media has been accused of causing political instability, resulting in the obstruction of democracy, rather than its promotion.[214]
",2
895,"In representative democracies, it may not benefit incumbents to conduct fair elections. A study showed that incumbents who rig elections stay in office 2.5 times as long as those who permit fair elections.[215] Democracies in countries with high per capita income have been found to be less prone to violence, but in countries with low incomes the tendency is the reverse.[215] Election misconduct is more likely in countries with low per capita incomes, small populations, rich in natural resources, and a lack of institutional checks and balances. Sub-Saharan countries, as well as Afghanistan, all tend to fall into that category.[215]
",2
896,"Governments that have frequent elections tend to have significantly more stable economic policies than those governments who have infrequent elections. However, this trend does not apply to governments where fraudulent elections are common.[215]
",2
897,"Democracy in modern times has almost always faced opposition from the previously existing government, and many times it has faced opposition from social elites. The implementation of a democratic government within a non-democratic state is typically brought about by democratic revolution.
",2
898,"Several philosophers and researchers have outlined historical and social factors seen as supporting the evolution of democracy.
",2
899,"Other commentators have mentioned the influence of economic development.[216] In a related theory, Ronald Inglehart suggests that improved living-standards in modern developed countries can convince people that they can take their basic survival for granted, leading to increased emphasis on self-expression values, which correlates closely with democracy.[217][218]
",2
900,"Douglas M. Gibler and Andrew Owsiak in their study argued about the importance of peace and stable borders for the development of democracy. It has often been assumed that democracy causes peace, but this study shows that, historically, peace has almost always predated the establishment of democracy.[219]
",2
901,"Carroll Quigley concludes that the characteristics of weapons are the main predictor of democracy:[220][221] Democracy—this scenario—tends to emerge only when the best weapons available are easy for individuals to obtain and use.[222] By the 1800s, guns were the best personal weapons available, and in the United States of America (already nominally democratic), almost everyone could afford to buy a gun, and could learn how to use it fairly easily. Governments couldn't do any better: it became the age of mass armies of citizen soldiers with guns.[222] Similarly, Periclean Greece was an age of the citizen soldier and democracy.[223]
",2
902,"Other theories stressed the relevance of education and of human capital—and within them of cognitive ability to increasing tolerance, rationality, political literacy and participation. Two effects of education and cognitive ability are distinguished:[224][need quotation to verify][225][226]
",2
903,"Evidence consistent with conventional theories of why democracy emerges and is sustained has been hard to come by. Statistical analyses have challenged modernisation theory by demonstrating that there is no reliable evidence for the claim that democracy is more likely to emerge when countries become wealthier, more educated, or less unequal.[227] Neither is there convincing evidence that increased reliance on oil revenues prevents democratisation, despite a vast theoretical literature on ""the Resource Curse"" that asserts that oil revenues sever the link between citizen taxation and government accountability, seen as the key to representative democracy.[228] The lack of evidence for these conventional theories of democratisation have led researchers to search for the ""deep"" determinants of contemporary political institutions, be they geographical or demographic.[229][230] More inclusive institutions lead to democracy because as people gain more power, they are able to demand more from the elites, who in turn have to concede more things to keep their position.[citation needed] This virtuous circle may end up in democracy.
",2
904,"An example of this is the disease environment. Places with different mortality rates had different populations and productivity levels around the world. For example, in Africa, the tsetse fly—which afflicts humans and livestock—reduced the ability of Africans to plow the land. This made Africa less settled. As a consequence, political power was less concentrated.[231] This also affected the colonial institutions European countries established in Africa.[232] Whether colonial settlers could live or not in a place made them develop different institutions which led to different economic and social paths. This also affected the distribution of power and the collective actions people could take. As a result, some African countries ended up having democracies and others autocracies.
",2
905,"An example of geographical determinants for democracy is having access to coastal areas and rivers. This natural endowment has a positive relation with economic development thanks to the benefits of trade.[233] Trade brought economic development, which in turn, broadened power. Rulers wanting to increase revenues had to protect property-rights to create incentives for people to invest. As more people had more power, more concessions had to be made by the ruler and in many[quantify] places this process lead to democracy. These determinants defined the structure of the society moving the balance of political power.[234]
",2
906,"In the 21st century, democracy has become such a popular method of reaching decisions that its application beyond politics to other areas such as entertainment, food and fashion, consumerism, urban planning, education, art, literature, science and theology has been criticised as ""the reigning dogma of our time"".[235] The argument suggests that applying a populist or market-driven approach to art and literature (for example), means that innovative creative work goes unpublished or unproduced. In education, the argument is that essential but more difficult studies are not undertaken. Science, as a truth-based discipline, is particularly corrupted by the idea that the correct conclusion can be arrived at by popular vote. However, more recently, theorists[which?] have also advanced the concept epistemic democracy to assert that democracy actually does a good job tracking the truth.
",2
907,"Robert Michels asserts that although democracy can never be fully realised, democracy may be developed automatically in the act of striving for democracy:
",2
908,"The peasant in the fable, when on his death-bed, tells his sons that a treasure is buried in the field. After the old man's death the sons dig everywhere in order to discover the treasure. They do not find it. But their indefatigable labor improves the soil and secures for them a comparative well-being. The treasure in the fable may well symbolise democracy.[236]",2
909,"Dr. Harald Wydra, in his book Communism and The Emergence of Democracy (2007), maintains that the development of democracy should not be viewed as a purely procedural or as a static concept but rather as an ongoing ""process of meaning formation"".[237] Drawing on Claude Lefort's idea of the empty place of power, that ""power emanates from the people [...] but is the power of nobody"", he remarks that democracy is reverence to a symbolic mythical authority—as in reality, there is no such thing as the people or demos. Democratic political figures are not supreme rulers but rather temporary guardians of an empty place. Any claim to substance such as the collective good, the public interest or the will of the nation is subject to the competitive struggle and times of for[clarification needed] gaining the authority of office and government. The essence of the democratic system is an empty place, void of real people, which can only be temporarily filled and never be appropriated. The seat of power is there but remains open to constant change. As such, people's definitions of ""democracy"" or of ""democratic"" progress throughout history as a continual and potentially never-ending process of social construction.[238]
",2
910,"
",2
911,"Barack Hussein Obama II (/bəˈrɑːk huːˈseɪn oʊˈbɑːmə/ (listen) bə-RAHK hoo-SAYN oh-BAH-mə;[1] born August 4, 1961) is an American politician and attorney who served as the 44th president of the United States from 2009 to 2017. A member of the Democratic Party, Obama was the first African-American president of the United States. He previously served as a U.S. senator from Illinois from 2005 to 2008 and as an Illinois state senator from 1997 to 2004.
",2
912,"Obama was born in Honolulu, Hawaii. After graduating from Columbia University in 1983, he worked as a community organizer in Chicago. In 1988, he enrolled in Harvard Law School, where he was the first black person to be president of the Harvard Law Review. After graduating, he became a civil rights attorney and an academic, teaching constitutional law at the University of Chicago Law School from 1992 to 2004. Turning to elective politics, he represented the 13th district from 1997 until 2004 in the Illinois Senate, when he ran for the U.S. Senate. Obama received national attention in 2004 with his March Senate primary win, his well-received July Democratic National Convention keynote address, and his landslide November election to the Senate. In 2008, he was nominated by the Democratic Party for president a year after his presidential campaign began, and after a close primary campaign against Hillary Clinton, Obama was elected over Republican nominee John McCain and was inaugurated alongside his running mate, Joe Biden, on January 20, 2009. Nine months later, he was named the 2009 Nobel Peace Prize laureate.
",2
913,"Obama signed many landmark bills into law during his first two years in office. The main reforms that were passed include the Affordable Care Act (commonly referred to as ACA or ""Obamacare""), although without a public health insurance option, the Dodd–Frank Wall Street Reform and Consumer Protection Act, and the Don't Ask, Don't Tell Repeal Act of 2010. The American Recovery and Reinvestment Act of 2009 and Tax Relief, Unemployment Insurance Reauthorization, and Job Creation Act of 2010 served as economic stimuli amidst the Great Recession. After a lengthy debate over the national debt limit, he signed the Budget Control and the American Taxpayer Relief Acts. In foreign policy, he increased U.S. troop levels in Afghanistan, reduced nuclear weapons with the United States–Russia New START treaty, and ended military involvement in the Iraq War. He ordered military involvement in Libya for the implementation of the UN Security Council Resolution 1973, contributing to the overthrow of Muammar Gaddafi. He also ordered the military operations that resulted in the deaths of Osama bin Laden and suspected Yemeni Al-Qaeda operative Anwar al-Awlaki.
",2
914,"After winning re-election by defeating Republican opponent Mitt Romney, Obama was sworn in for a second term in 2013. During this term, he promoted inclusion for LGBT Americans. His administration filed briefs that urged the Supreme Court to strike down same-sex marriage bans as unconstitutional (United States v. Windsor and Obergefell v. Hodges); same-sex marriage was legalized nationwide in 2015 after the Court ruled so in Obergefell. He advocated for gun control in response to the Sandy Hook Elementary School shooting, indicating support for a ban on assault weapons, and issued wide-ranging executive actions concerning global warming and immigration. In foreign policy, he ordered military intervention in Iraq in response to gains made by ISIL after the 2011 withdrawal from Iraq, continued the process of ending U.S. combat operations in Afghanistan in 2016, promoted discussions that led to the 2015 Paris Agreement on global climate change, initiated sanctions against Russia following the invasion in Ukraine and again after interference in the 2016 U.S. elections, brokered the JCPOA nuclear deal with Iran, and normalized U.S. relations with Cuba. Obama nominated three justices to the Supreme Court: Sonia Sotomayor and Elena Kagan were confirmed as justices, while Merrick Garland faced partisan obstruction from the Republican-led Senate led by Mitch McConnell, which never held hearings or a vote on the nomination. Obama left office in January 2017 and continues to reside in Washington, D.C.[2][3]
",2
915,"During Obama's term in office, the United States' reputation abroad, as well as the American economy, significantly improved.[4] Obama's presidency has generally been regarded favorably, and evaluations of his presidency among historians, political scientists, and the general public frequently place him among the upper tier of American presidents.
",2
916,"Obama was born on August 4, 1961,[5] at Kapiolani Medical Center for Women and Children in Honolulu, Hawaii.[6][7][8] He is the only president born outside the contiguous 48 states.[9] He was born to an American mother of European descent and an African father. His mother, Ann Dunham (1942–1995), was born in Wichita, Kansas; she was mostly of English descent,[10] with some German, Irish, Scottish,[11][12][13][14][15] Swiss, and Welsh ancestry.[16] In July 2012, Ancestry.com found a strong likelihood that Dunham was descended from John Punch, an enslaved African man who lived in the Colony of Virginia during the seventeenth century.[17][18] Obama's father, Barack Obama Sr. (1936–1982),[19] was a married[20][21][22] Luo Kenyan from Nyang'oma Kogelo.[20][23] Obama's parents met in 1960 in a Russian language class at the University of Hawaii at Manoa, where his father was a foreign student on a scholarship.[24][25] The couple married in Wailuku, Hawaii, on February 2, 1961, six months before Obama was born.[26][27]
",2
917,"In late August 1961, a few weeks after he was born, Barack and his mother moved to the University of Washington in Seattle, where they lived for a year. During that time, the elder Obama completed his undergraduate degree in economics in Hawaii, graduating in June 1962. He left to attend graduate school on a scholarship at Harvard University, where he earned an M.A. in economics. Obama's parents divorced in March 1964.[28] Obama Sr. returned to Kenya in 1964, where he married for a third time and worked for the Kenyan government as the Senior Economic Analyst in the Ministry of Finance.[29] He visited his son in Hawaii only once, at Christmas 1971,[30] before he was killed in an automobile accident in 1982, when Obama was 21 years old.[31] Recalling his early childhood, Obama said, ""That my father looked nothing like the people around me—that he was black as pitch, my mother white as milk—barely registered in my mind.""[25] He described his struggles as a young adult to reconcile social perceptions of his multiracial heritage.[32]
",2
918,"In 1963, Dunham met Lolo Soetoro at the University of Hawaii; he was an Indonesian East–West Center graduate student in geography. The couple married on Molokai on March 15, 1965.[33] After two one-year extensions of his J-1 visa, Lolo returned to Indonesia in 1966. His wife and stepson followed sixteen months later in 1967. The family initially lived in the Menteng Dalam neighborhood in the Tebet sub district of south Jakarta. From 1970, they lived in a wealthier neighborhood in the Menteng sub district of central Jakarta.[34]
",2
919,"When he was six years old, Obama and his mother moved to Indonesia to join his step-father; from age six to ten, he attended local Indonesian-language schools: Sekolah Dasar Katolik Santo Fransiskus Asisi (St. Francis of Assisi Catholic Elementary School) for two years and Sekolah Dasar Negeri Menteng 01 (State Elementary School Menteng 01) for one and a half years, supplemented by English-language Calvert School homeschooling by his mother.[36][37] As a result of those four years in Jakarta, he was able to speak Indonesian fluently as a child.[38][39][40] During his time in Indonesia, Obama's step-father taught him to be resilient and gave him ""a pretty hardheaded assessment of how the world works"".[41]
",2
920,"In 1971, Obama returned to Honolulu to live with his maternal grandparents, Madelyn and Stanley Dunham. He attended Punahou School—a private college preparatory school—with the aid of a scholarship from fifth grade until he graduated from high school in 1979.[42] In his youth, Obama went by the nickname ""Barry"".[43] Obama lived with his mother and half-sister, Maya Soetoro, in Hawaii for three years from 1972 to 1975 while his mother was a graduate student in anthropology at the University of Hawaii.[44] Obama chose to stay in Hawaii with his grandparents for high school at Punahou when his mother and half-sister returned to Indonesia in 1975, so his mother could begin anthropology field work.[45] His mother spent most of the next two decades in Indonesia, divorcing Lolo in 1980 and earning a PhD degree in 1992, before dying in 1995 in Hawaii following unsuccessful treatment for ovarian and uterine cancer.[46]
",2
921,"Obama later reflected on his years in Honolulu and wrote: ""The opportunity that Hawaii offered—to experience a variety of cultures in a climate of mutual respect—became an integral part of my world view, and a basis for the values that I hold most dear.""[47] Obama has also written and talked about using alcohol, marijuana, and cocaine during his teenage years to ""push questions of who I was out of my mind"".[48] Obama was also a member of the ""choom gang"", a self-named group of friends who spent time together and occasionally smoked marijuana.[49][50]
",2
922,"After graduating from high school in 1979, Obama moved to Los Angeles to attend Occidental College on a full scholarship. In February 1981, Obama made his first public speech, calling for Occidental to participate in the disinvestment from South Africa in response to that nation's policy of apartheid.[51] In mid-1981, Obama traveled to Indonesia to visit his mother and half-sister Maya, and visited the families of college friends in Pakistan and India for three weeks.[51] Later in 1981, he transferred to Columbia University in New York City as a junior, where he majored in political science with a specialty in international relations[52] and in English literature[53] and lived off-campus on West 109th Street.[54] He graduated with a Bachelor of Arts degree in 1983 and a 3.7 GPA. After graduating, Obama worked for about a year at the Business International Corporation, where he was a financial researcher and writer,[55][56] then as a project coordinator for the New York Public Interest Research Group on the City College of New York campus for three months in 1985.[57][58][59]
",2
923,"In a 2006 interview, Obama highlighted the diversity of his extended family: ""It's like a little mini-United Nations,"" he said. ""I've got relatives who look like Bernie Mac, and I've got relatives who look like Margaret Thatcher.""[60] Obama has a half-sister with whom he was raised (Maya Soetoro-Ng) and seven other half-siblings from his Kenyan father's family—six of them living.[61] Obama's mother was survived by her Kansas-born mother, Madelyn Dunham,[62] until her death on November 2, 2008,[63] two days before his election to the Presidency. Obama also has roots in Ireland; he met with his Irish cousins in Moneygall in May 2011.[64] In Dreams from My Father, Obama ties his mother's family history to possible Native American ancestors and distant relatives of Jefferson Davis, President of the Confederate States of America during the American Civil War. He also shares distant ancestors in common with George W. Bush and Dick Cheney, among others.[65][66][67]
",2
924,"Obama lived with anthropologist Sheila Miyoshi Jager while he was a community organizer in Chicago in the 1980s.[68] He proposed to her twice, but both Jager and her parents turned him down.[68][69] The relationship was not made public until May 2017, several months after his presidency had ended.[69]
",2
925,"In June 1989, Obama met Michelle Robinson when he was employed as a summer associate at the Chicago law firm of Sidley Austin.[70] Robinson was assigned for three months as Obama's adviser at the firm, and she joined him at several group social functions but declined his initial requests to date.[71] They began dating later that summer, became engaged in 1991, and were married on October 3, 1992.[72] After suffering a miscarriage, Michelle underwent in vitro fertilization to conceive their children.[73] The couple's first daughter, Malia Ann, was born in 1998,[74] followed by a second daughter, Natasha (""Sasha""), in 2001.[75] The Obama daughters attended the University of Chicago Laboratory Schools. When they moved to Washington, D.C., in January 2009, the girls started at the Sidwell Friends School.[76] The Obamas have two Portuguese Water Dogs; the first, a male named Bo, was a gift from Senator Ted Kennedy.[77] In 2013, Bo was joined by Sunny, a female.[78]
",2
926,"Obama is a supporter of the Chicago White Sox, and he threw out the first pitch at the 2005 ALCS when he was still a senator.[79] In 2009, he threw out the ceremonial first pitch at the All-Star Game while wearing a White Sox jacket.[80] He is also primarily a Chicago Bears football fan in the NFL, but in his childhood and adolescence was a fan of the Pittsburgh Steelers, and rooted for them ahead of their victory in Super Bowl XLIII 12 days after he took office as president.[81] In 2011, Obama invited the 1985 Chicago Bears to the White House; the team had not visited the White House after their Super Bowl win in 1986 due to the Space Shuttle Challenger disaster.[82] He plays basketball, a sport he participated in as a member of his high school's varsity team,[83] and he is left-handed.[84]
",2
927,"In 2005, the Obama family applied the proceeds of a book deal and moved from a Hyde Park, Chicago condominium to a $1.6 million house (equivalent to $2.1 million in 2019) in neighboring Kenwood, Chicago.[85] The purchase of an adjacent lot—and sale of part of it to Obama by the wife of developer, campaign donor and friend Tony Rezko—attracted media attention because of Rezko's subsequent indictment and conviction on political corruption charges that were unrelated to Obama.[86]
",2
928,"In December 2007, Money Magazine estimated Obama's net worth at $1.3 million (equivalent to $1.6 million in 2019) .[87] Their 2009 tax return showed a household income of $5.5 million—up from about $4.2 million in 2007 and $1.6 million in 2005—mostly from sales of his books.[88][89] On his 2010 income of $1.7 million, he gave 14 percent to non-profit organizations, including $131,000 to Fisher House Foundation, a charity assisting wounded veterans' families, allowing them to reside near where the veteran is receiving medical treatments.[90][91] Per his 2012 financial disclosure, Obama may be worth as much as $10 million.[92]
",2
929,"In early 2010, Michelle spoke about her husband's smoking habit and said Barack had quit smoking.[93][94]
",2
930,"On his 55th birthday, August 4, 2016, Obama penned an essay in Glamour, in which he described how his daughters and the presidency have made him a feminist.[95][96][97]
",2
931,"Obama is a Protestant Christian whose religious views developed in his adult life.[98] He wrote in The Audacity of Hope that he ""was not raised in a religious household"". He described his mother, raised by non-religious parents, as being detached from religion, yet ""in many ways the most spiritually awakened person ... I have ever known"", and ""a lonely witness for secular humanism"". He described his father as a ""confirmed atheist"" by the time his parents met, and his stepfather as ""a man who saw religion as not particularly useful"". Obama explained how, through working with black churches as a community organizer while in his twenties, he came to understand ""the power of the African-American religious tradition to spur social change"".[99]
",2
932,"
In January 2008, Obama told Christianity Today: ""I am a Christian, and I am a devout Christian. I believe in the redemptive death and resurrection of Jesus Christ. I believe that faith gives me a path to be cleansed of sin and have eternal life.""[100] On September 27, 2010, Obama released a statement commenting on his religious views, saying: ",2
933,"I'm a Christian by choice. My family didn't—frankly, they weren't folks who went to church every week. And my mother was one of the most spiritual people I knew, but she didn't raise me in the church. So I came to my Christian faith later in life, and it was because the precepts of Jesus Christ spoke to me in terms of the kind of life that I would want to lead—being my brothers' and sisters' keeper, treating others as they would treat me.[101][102]",2
934,"Obama met Trinity United Church of Christ pastor Jeremiah Wright in October 1987 and became a member of Trinity in 1992.[103] During Obama's first presidential campaign in May 2008, he resigned from Trinity after some of Wright's statements were criticized.[104] Since moving to Washington, D.C., in 2009, the Obama family has attended several Protestant churches, including Shiloh Baptist Church and St. John's Episcopal Church, as well as Evergreen Chapel at Camp David, but the members of the family do not attend church on a regular basis.[105][106][107]
",2
935,"Two years after graduating from Columbia, Obama moved from New York to Chicago when he was hired as director of the Developing Communities Project, a church-based community organization originally comprising eight Catholic parishes in Roseland, West Pullman, and Riverdale on Chicago's South Side. He worked there as a community organizer from June 1985 to May 1988.[58][108] He helped set up a job training program, a college preparatory tutoring program, and a tenants' rights organization in Altgeld Gardens.[109] Obama also worked as a consultant and instructor for the Gamaliel Foundation, a community organizing institute.[110] In mid-1988, he traveled for the first time in Europe for three weeks and then for five weeks in Kenya, where he met many of his paternal relatives for the first time.[111][112]
",2
936,"Despite being offered a full scholarship to Northwestern University School of Law, Obama enrolled at Harvard Law School in the fall of 1988, living in nearby Somerville, Massachusetts.[114] He was selected as an editor of the Harvard Law Review at the end of his first year,[115] president of the journal in his second year,[109][116] and research assistant to the constitutional scholar Laurence Tribe while at Harvard for two years.[117] During his summers, he returned to Chicago, where he worked as a summer associate at the law firms of Sidley Austin in 1989 and Hopkins & Sutter in 1990.[118] After graduating with a JD degree magna cum laude[119] from Harvard in 1991, he returned to Chicago.[115] Obama's election as the first black president of the Harvard Law Review gained national media attention[109][116] and led to a publishing contract and advance for a book about race relations,[120] which evolved into a personal memoir. The manuscript was published in mid-1995 as Dreams from My Father.[120]
",2
937,"In 1991, Obama accepted a two-year position as Visiting Law and Government Fellow at the University of Chicago Law School to work on his first book.[120][121] He then taught constitutional law at the University of Chicago Law School for twelve years, first as a lecturer from 1992 to 1996, and then as a senior lecturer from 1996 to 2004.[122]
",2
938,"From April to October 1992, Obama directed Illinois's Project Vote, a voter registration campaign with ten staffers and seven hundred volunteer registrars; it achieved its goal of registering 150,000 of 400,000 unregistered African Americans in the state, leading Crain's Chicago Business to name Obama to its 1993 list of ""40 under Forty"" powers to be.[123]
",2
939,"He joined Davis, Miner, Barnhill & Galland, a 13-attorney law firm specializing in civil rights litigation and neighborhood economic development, where he was an associate for three years from 1993 to 1996, then of counsel from 1996 to 2004. In 1994, he was listed as one of the lawyers in Buycks-Roberson v. Citibank Fed. Sav. Bank, 94 C 4094 (N.D. Ill.).[124] This class action lawsuit was filed in 1994 with Selma Buycks-Roberson as lead plaintiff and alleged that Citibank Federal Savings Bank had engaged in practices forbidden under the Equal Credit Opportunity Act and the Fair Housing Act.[125] The case was settled out of court.[126] Final judgment was issued on May 13, 1998, with Citibank Federal Savings Bank agreeing to pay attorney fees.[127] His law license became inactive in 2007.[128][129]
",2
940,"From 1994 to 2002, Obama served on the boards of directors of the Woods Fund of Chicago—which in 1985 had been the first foundation to fund the Developing Communities Project—and of the Joyce Foundation.[58] He served on the board of directors of the Chicago Annenberg Challenge from 1995 to 2002, as founding president and chairman of the board of directors from 1995 to 1999.[58]
",2
941,"Obama was elected to the Illinois Senate in 1996, succeeding Democratic State Senator Alice Palmer from Illinois's 13th District, which, at that time, spanned Chicago South Side neighborhoods from Hyde Park–Kenwood south to South Shore and west to Chicago Lawn.[130] Once elected, Obama gained bipartisan support for legislation that reformed ethics and health care laws.[131][132] He sponsored a law that increased tax credits for low-income workers, negotiated welfare reform, and promoted increased subsidies for childcare.[133] In 2001, as co-chairman of the bipartisan Joint Committee on Administrative Rules, Obama supported Republican Governor Ryan's payday loan regulations and predatory mortgage lending regulations aimed at averting home foreclosures.[134][135]
",2
942,"He was reelected to the Illinois Senate in 1998, defeating Republican Yesse Yehudah in the general election, and was re-elected again in 2002.[136][137] In 2000, he lost a Democratic primary race for Illinois's 1st congressional district in the United States House of Representatives to four-term incumbent Bobby Rush by a margin of two to one.[138]
",2
943,"In January 2003, Obama became chairman of the Illinois Senate's Health and Human Services Committee when Democrats, after a decade in the minority, regained a majority.[139] He sponsored and led unanimous, bipartisan passage of legislation to monitor racial profiling by requiring police to record the race of drivers they detained, and legislation making Illinois the first state to mandate videotaping of homicide interrogations.[133][140][141][142] During his 2004 general election campaign for the U.S. Senate, police representatives credited Obama for his active engagement with police organizations in enacting death penalty reforms.[143] Obama resigned from the Illinois Senate in November 2004 following his election to the U.S. Senate.[144]
",2
944,"In May 2002, Obama commissioned a poll to assess his prospects in a 2004 U.S. Senate race. He created a campaign committee, began raising funds, and lined up political media consultant David Axelrod by August 2002. Obama formally announced his candidacy in January 2003.[145]
",2
945,"Obama was an early opponent of the George W. Bush administration's 2003 invasion of Iraq.[146] On October 2, 2002, the day President Bush and Congress agreed on the joint resolution authorizing the Iraq War,[147] Obama addressed the first high-profile Chicago anti-Iraq War rally,[148] and spoke out against the war.[149] He addressed another anti-war rally in March 2003 and told the crowd ""it's not too late"" to stop the war.[150]
",2
946,"Decisions by Republican incumbent Peter Fitzgerald and his Democratic predecessor Carol Moseley Braun to not participate in the election resulted in wide-open Democratic and Republican primary contests involving 15 candidates.[151] In the March 2004 primary election, Obama won in an unexpected landslide—which overnight made him a rising star within the national Democratic Party, started speculation about a presidential future, and led to the reissue of his memoir, Dreams from My Father.[152] In July 2004, Obama delivered the keynote address at the 2004 Democratic National Convention,[153] seen by nine million viewers. His speech was well received and elevated his status within the Democratic Party.[154]
",2
947,"Obama's expected opponent in the general election, Republican primary winner Jack Ryan, withdrew from the race in June 2004.[155] Six weeks later, Alan Keyes accepted the Republican nomination to replace Ryan.[156] In the November 2004 general election, Obama won with 70 percent of the vote in a landslide.[157]
",2
948,"Obama was sworn in as a senator on January 3, 2005,[158] becoming the only Senate member of the Congressional Black Caucus.[159] CQ Weekly characterized him as a ""loyal Democrat"" based on analysis of all Senate votes from 2005 to 2007. Obama announced on November 13, 2008, that he would resign his Senate seat on November 16, 2008, before the start of the lame-duck session, to focus on his transition period for the presidency.[160]
",2
949,"Obama cosponsored the Secure America and Orderly Immigration Act.[161] He introduced two initiatives that bore his name: Lugar–Obama, which expanded the Nunn–Lugar Cooperative Threat Reduction concept to conventional weapons;[162] and the Federal Funding Accountability and Transparency Act of 2006, which authorized the establishment of USAspending.gov, a web search engine on federal spending.[163] On June 3, 2008, Senator Obama—along with Senators Tom Carper, Tom Coburn, and John McCain—introduced follow-up legislation: Strengthening Transparency and Accountability in Federal Spending Act of 2008.[164]
",2
950,"Obama sponsored legislation that would have required nuclear plant owners to notify state and local authorities of radioactive leaks, but the bill failed to pass in the full Senate after being heavily modified in committee.[165] Regarding tort reform, Obama voted for the Class Action Fairness Act of 2005 and the FISA Amendments Act of 2008, which grants immunity from civil liability to telecommunications companies complicit with NSA warrantless wiretapping operations.[166]
",2
951,"In December 2006, President Bush signed into law the Democratic Republic of the Congo Relief, Security, and Democracy Promotion Act, marking the first federal legislation to be enacted with Obama as its primary sponsor.[168][169] In January 2007, Obama and Senator Feingold introduced a corporate jet provision to the Honest Leadership and Open Government Act, which was signed into law in September 2007.[170][171] Obama also introduced two unsuccessful bills: the Deceptive Practices and Voter Intimidation Prevention Act to criminalize deceptive practices in federal elections,[172][173] and the Iraq War De-Escalation Act of 2007.[174]
",2
952,"Later in 2007, Obama sponsored an amendment to the Defense Authorization Act to add safeguards for personality-disorder military discharges.[175] This amendment passed the full Senate in the spring of 2008.[176] He sponsored the Iran Sanctions Enabling Act supporting divestment of state pension funds from Iran's oil and gas industry, which was never enacted but later incorporated in the Comprehensive Iran Sanctions, Accountability, and Divestment Act of 2010;[177] and co-sponsored legislation to reduce risks of nuclear terrorism.[178] Obama also sponsored a Senate amendment to the State Children's Health Insurance Program, providing one year of job protection for family members caring for soldiers with combat-related injuries.[179]
",2
953,"Obama held assignments on the Senate Committees for Foreign Relations, Environment and Public Works and Veterans' Affairs through December 2006.[180] In January 2007, he left the Environment and Public Works committee and took additional assignments with Health, Education, Labor and Pensions and Homeland Security and Governmental Affairs.[181] He also became Chairman of the Senate's subcommittee on European Affairs.[182] As a member of the Senate Foreign Relations Committee, Obama made official trips to Eastern Europe, the Middle East, Central Asia and Africa. He met with Mahmoud Abbas before Abbas became President of the Palestinian National Authority, and gave a speech at the University of Nairobi in which he condemned corruption within the Kenyan government.[183]
",2
954,"On February 10, 2007, Obama announced his candidacy for President of the United States in front of the Old State Capitol building in Springfield, Illinois.[184][185] The choice of the announcement site was viewed as symbolic because it was also where Abraham Lincoln delivered his historic ""House Divided"" speech in 1858.[184][186] Obama emphasized issues of rapidly ending the Iraq War, increasing energy independence, and reforming the health care system,[187] in a campaign that projected themes of hope and change.[188]
",2
955,"Numerous candidates entered the Democratic Party presidential primaries. The field narrowed to a duel between Obama and Senator Hillary Clinton after early contests, with the race remaining close throughout the primary process but with Obama gaining a steady lead in pledged delegates due to better long-range planning, superior fundraising, dominant organizing in caucus states, and better exploitation of delegate allocation rules.[189] On June 7, 2008, Clinton ended her campaign and endorsed Obama.[190]
",2
956,"On August 23, 2008, Obama announced his selection of Delaware Senator Joe Biden as his vice presidential running mate.[191] Obama selected Biden from a field speculated to include former Indiana Governor and Senator Evan Bayh and Virginia Governor Tim Kaine.[191] At the Democratic National Convention in Denver, Colorado, Hillary Clinton called for her supporters to endorse Obama, and she and Bill Clinton gave convention speeches in his support.[192] Obama delivered his acceptance speech, not at the center where the Democratic National Convention was held, but at Invesco Field at Mile High to a crowd of about eighty-four thousand; the speech was viewed by over three million people worldwide.[193][194][195]
",2
957,"During both the primary process and the general election, Obama's campaign set numerous fundraising records, particularly in the quantity of small donations.[196] On June 19, 2008, Obama became the first major-party presidential candidate to turn down public financing in the general election since the system was created in 1976.[197]
",2
958,"John McCain was nominated as the Republican candidate, and he selected Sarah Palin as his running mate. The two candidates engaged in three presidential debates in September and October 2008.[198] On November 4, Obama won the presidency with 365 electoral votes to 173 received by McCain.[199] Obama won 52.9 percent of the popular vote to McCain's 45.7 percent.[200] He became the first African American to be elected president.[201] Obama delivered his victory speech before hundreds of thousands of supporters in Chicago's Grant Park.[202]
",2
959,"On April 4, 2011, Obama announced his reelection campaign for 2012 in a video titled ""It Begins with Us"" that he posted on his website and filed election papers with the Federal Election Commission.[203][204][205] As the incumbent president, he ran virtually unopposed in the Democratic Party presidential primaries,[206] and on April 3, 2012, Obama had secured the 2778 convention delegates needed to win the Democratic nomination.[207]
",2
960,"At the Democratic National Convention in Charlotte, North Carolina, Obama and Joe Biden were formally nominated by former President Bill Clinton as the Democratic Party candidates for president and vice president in the general election. Their main opponents were Republicans Mitt Romney, the former governor of Massachusetts, and Representative Paul Ryan of Wisconsin.[208]
",2
961,"On November 6, 2012, Obama won 332 electoral votes, exceeding the 270 required for him to be reelected as president.[209][210][211] With 51.1 percent of the popular vote,[212] Obama became the first Democratic president since Franklin D. Roosevelt to win the majority of the popular vote twice.[213][214] Obama addressed supporters and volunteers at Chicago's McCormick Place after his reelection and said: ""Tonight you voted for action, not politics as usual. You elected us to focus on your jobs, not ours. And in the coming weeks and months, I am looking forward to reaching out and working with leaders of both parties.""[215][216]
",2
962,"The inauguration of Barack Obama as the 44th President took place on January 20, 2009. In his first few days in office, Obama issued executive orders and presidential memoranda directing the U.S. military to develop plans to withdraw troops from Iraq.[217] He ordered the closing of the Guantanamo Bay detention camp,[218] but Congress prevented the closure by refusing to appropriate the required funds[219][220][221] and preventing moving any Guantanamo detainee into the U.S. or to other countries.[222] Obama reduced the secrecy given to presidential records.[223] He also revoked President George W. Bush's restoration of President Ronald Reagan's Mexico City policy prohibiting federal aid to international family planning organizations that perform or provide counseling about abortion.[224]
",2
963,"The first bill signed into law by Obama was the Lilly Ledbetter Fair Pay Act of 2009, relaxing the statute of limitations for equal-pay lawsuits.[225] Five days later, he signed the reauthorization of the State Children's Health Insurance Program (SCHIP) to cover an additional four million uninsured children.[226] In March 2009, Obama reversed a Bush-era policy that had limited funding of embryonic stem cell research and pledged to develop ""strict guidelines"" on the research.[227]
",2
964,"Obama appointed two women to serve on the Supreme Court in the first two years of his presidency. He nominated Sonia Sotomayor on May 26, 2009 to replace retiring Associate Justice David Souter; she was confirmed on August 6, 2009,[228] becoming the first Supreme Court Justice of Hispanic descent.[229] Obama nominated Elena Kagan on May 10, 2010 to replace retiring Associate Justice John Paul Stevens. She was confirmed on August 5, 2010, bringing the number of women sitting simultaneously on the Court to three justices for the first time in American history.[230]
",2
965,"On March 30, 2010, Obama signed the Health Care and Education Reconciliation Act, a reconciliation bill that ended the process of the federal government giving subsidies to private banks to give out federally insured loans, increased the Pell Grant scholarship award, and made changes to the Patient Protection and Affordable Care Act.[231][232]
",2
966,"In a major space policy speech in April 2010, Obama announced a planned change in direction at NASA, the U.S. space agency. He ended plans for a return of human spaceflight to the moon and development of the Ares I rocket, Ares V rocket and Constellation program, in favor of funding Earth science projects, a new rocket type, and research and development for an eventual crewed mission to Mars, and ongoing missions to the International Space Station.[233]
",2
967,"President Obama's 2011 State of the Union Address focused on themes of education and innovation, stressing the importance of innovation economics to make the United States more competitive globally. He spoke of a five-year freeze in domestic spending, eliminating tax breaks for oil companies and reversing tax cuts for the wealthiest Americans, banning congressional earmarks, and reducing healthcare costs. He promised the United States would have one million electric vehicles on the road by 2015 and set a goal for 80 percent reliance on ""clean"" electricity by 2035.[234][235]
",2
968,"On October 8, 2009, Obama signed the Matthew Shepard and James Byrd Jr. Hate Crimes Prevention Act, a measure that expanded the 1969 United States federal hate-crime law to include crimes motivated by a victim's actual or perceived gender, sexual orientation, gender identity, or disability.[236]
",2
969,"On October 30, 2009, Obama lifted the ban on travel to the United States by those infected with HIV, which was celebrated by Immigration Equality.[237]
",2
970,"On December 22, 2010, Obama signed the Don't Ask, Don't Tell Repeal Act of 2010, which fulfilled a key promise made in the 2008 presidential campaign[238][239] to end the don't ask, don't tell policy of 1993 that had prevented gay and lesbian people from serving openly in the United States Armed Forces.[240] In 2016, the Pentagon also ended the policy that barred transgender people from serving openly in the military.[241]
",2
971,"As a candidate for the Illinois state senate in 1996, Obama had said he favored legalizing same-sex marriage.[242] By the time of his Senate run in 2004, he said he supported civil unions and domestic partnerships for same-sex partners but opposed same-sex marriages.[243] In 2008, he reaffirmed this position by stating ""I believe marriage is between a man and a woman. I am not in favor of gay marriage.""[244] On May 9, 2012, shortly after the official launch of his campaign for re-election as president, Obama said his views had evolved, and he publicly affirmed his personal support for the legalization of same-sex marriage, becoming the first sitting U.S. president to do so.[245][246]
",2
972,"During his second inaugural address on January 21, 2013,[216] Obama became the first U.S. president in office to call for full equality for gay Americans: ""Our journey is not complete until our gay brothers and sisters are treated like anyone else under the law—for if we are truly created equal, then surely the love we commit to one another must be equal as well."" This was the first time that a president mentioned gay rights or the word ""gay"" in an inaugural address.[247][248]
",2
973,"In 2013, the Obama Administration filed briefs that urged the Supreme Court to rule in favor of same-sex couples in the cases of Hollingsworth v. Perry (regarding same-sex marriage)[249] and United States v. Windsor (regarding the Defense of Marriage Act).[250] Then, following the Supreme Court's 2015 decision in Obergefell v. Hodges (ruling same-sex marriage to be a fundamental right), Obama asserted that, ""This decision affirms what millions of Americans already believe in their hearts: When all Americans are treated as equal we are all more free.""[251]
",2
974,"On July 30, 2015, the White House Office of National AIDS Policy revised its strategy for addressing the disease, which included widespread testing and linkage to healthcare, which was celebrated by the Human Rights Campaign.[252]
",2
975,"On March 11, 2009, Obama created the White House Council on Women and Girls, which formed part of the Office of Intergovernmental Affairs, having been established by Executive Order 13506 with a broad mandate to advise him on issues relating to the welfare of American women and girls.[253] The council was chaired by Senior Advisor to the President Valerie Jarrett.[254] Obama also established the White House Task Force to Protect Students from Sexual Assault through a government memorandum on January 22, 2014, with a broad mandate to advise him on issues relating to sexual assault on college and university campuses throughout the United States.[254][255][256] The co-chairs of the Task Force were Vice President Joe Biden and Jarrett.[255] The Task Force was a development out of the White House Council on Women and Girls and Office of the Vice President of the United States, and prior to that the 1994 Violence Against Women Act first drafted by Biden.[257]
",2
976,"On February 17, 2009, Obama signed the American Recovery and Reinvestment Act of 2009, a $787 billion economic stimulus package aimed at helping the economy recover from the deepening worldwide recession.[258] The act includes increased federal spending for health care, infrastructure, education, various tax breaks and incentives, and direct assistance to individuals.[259]
",2
977,"In March 2009, Obama's Treasury Secretary, Timothy Geithner, took further steps to manage the financial crisis, including introducing the Public–Private Investment Program for Legacy Assets, which contains provisions for buying up to two trillion dollars in depreciated real estate assets.[260]
",2
978,"Obama intervened in the troubled automotive industry[261] in March 2009, renewing loans for General Motors and Chrysler to continue operations while reorganizing. Over the following months the White House set terms for both firms' bankruptcies, including the sale of Chrysler to Italian automaker Fiat[262] and a reorganization of GM giving the U.S. government a temporary 60 percent equity stake in the company, with the Canadian government taking a 12 percent stake.[263] In June 2009, dissatisfied with the pace of economic stimulus, Obama called on his cabinet to accelerate the investment.[264] He signed into law the Car Allowance Rebate System, known colloquially as ""Cash for Clunkers"", which temporarily boosted the economy.[265][266][267]
",2
979,"The Bush and Obama administrations authorized spending and loan guarantees from the Federal Reserve and the Treasury Department. These guarantees totaled about $11.5 trillion, but only $3 trillion had been spent by the end of November 2009.[268] Obama and the Congressional Budget Office predicted the 2010 budget deficit would be $1.5 trillion or 10.6 percent of the nation's gross domestic product (GDP) compared to the 2009 deficit of $1.4 trillion or 9.9 percent of GDP.[269][270] For 2011, the administration predicted the deficit would shrink to $1.34 trillion, and the 10-year deficit would increase to $8.53 trillion or 90 percent of GDP.[271] The most recent increase in the U.S. debt ceiling to $17.2 trillion took effect in February 2014.[272] On August 2, 2011, after a lengthy congressional debate over whether to raise the nation's debt limit, Obama signed the bipartisan Budget Control Act of 2011. The legislation enforces limits on discretionary spending until 2021, establishes a procedure to increase the debt limit, creates a Congressional Joint Select Committee on Deficit Reduction to propose further deficit reduction with a stated goal of achieving at least $1.5 trillion in budgetary savings over 10 years, and establishes automatic procedures for reducing spending by as much as $1.2 trillion if legislation originating with the new joint select committee does not achieve such savings.[273] By passing the legislation, Congress was able to prevent a U.S. government default on its obligations.[274]
",2
980,"As it did throughout 2008, the unemployment rate rose in 2009, reaching a peak in October at 10.0 percent and averaging 10.0 percent in the fourth quarter. Following a decrease to 9.7 percent in the first quarter of 2010, the unemployment rate fell to 9.6 percent in the second quarter, where it remained for the rest of the year.[277] Between February and December 2010, employment rose by 0.8 percent, which was less than the average of 1.9 percent experienced during comparable periods in the past four employment recoveries.[278] By November 2012, the unemployment rate fell to 7.7 percent,[279] decreasing to 6.7 percent in the last month of 2013.[280] During 2014, the unemployment rate continued to decline, falling to 6.3 percent in the first quarter.[281] GDP growth returned in the third quarter of 2009, expanding at a rate of 1.6 percent, followed by a 5.0 percent increase in the fourth quarter.[282] Growth continued in 2010, posting an increase of 3.7 percent in the first quarter, with lesser gains throughout the rest of the year.[282] In July 2010, the Federal Reserve noted that economic activity continued to increase, but its pace had slowed, and chairman Ben Bernanke said the economic outlook was ""unusually uncertain"".[283] Overall, the economy expanded at a rate of 2.9 percent in 2010.[284]
",2
981,"The Congressional Budget Office (CBO) and a broad range of economists credit Obama's stimulus plan for economic growth.[285][286] The CBO released a report stating that the stimulus bill increased employment by 1–2.1 million,[286][287][288][289] while conceding that ""It is impossible to determine how many of the reported jobs would have existed in the absence of the stimulus package.""[285] Although an April 2010, survey of members of the National Association for Business Economics showed an increase in job creation (over a similar January survey) for the first time in two years, 73 percent of 68 respondents believed the stimulus bill has had no impact on employment.[290] The economy of the United States has grown faster than the other original NATO members by a wider margin under President Obama than it has anytime since the end of World War II.[291] The Organisation for Economic Co-operation and Development credits the much faster growth in the United States to the stimulus plan of the U.S. and the austerity measures in the European Union.[292]
",2
982,"Within a month of the 2010 midterm elections, Obama announced a compromise deal with the Congressional Republican leadership that included a temporary, two-year extension of the 2001 and 2003 income tax rates, a one-year payroll tax reduction, continuation of unemployment benefits, and a new rate and exemption amount for estate taxes.[293] The compromise overcame opposition from some in both parties, and the resulting $858 billion Tax Relief, Unemployment Insurance Reauthorization, and Job Creation Act of 2010 passed with bipartisan majorities in both houses of Congress before Obama signed it on December 17, 2010.[294]
",2
983,"In December 2013, Obama declared that growing income inequality is a ""defining challenge of our time"" and called on Congress to bolster the safety net and raise wages. This came on the heels of the nationwide strikes of fast-food workers and Pope Francis' criticism of inequality and trickle-down economics.[295]
",2
984,"Obama urged Congress to ratify a 12-nation free trade pact called the Trans-Pacific Partnership.[296]
",2
985,"While campaigning, Obama expressed hope that Congress would regulate greenhouse gases and that, as a second-best route, such regulation would come from the Environmental Protection Agency.[297]
",2
986,"On September 30, 2009, the Obama administration proposed new regulations on power plants, factories, and oil refineries in an attempt to limit greenhouse gas emissions and to curb global warming.[298][299]
",2
987,"On April 20, 2010, an explosion destroyed an offshore drilling rig at the Macondo Prospect in the Gulf of Mexico, causing a major sustained oil leak. Obama visited the Gulf, announced a federal investigation, and formed a bipartisan commission to recommend new safety standards, after a review by Secretary of the Interior Ken Salazar and concurrent Congressional hearings. He then announced a six-month moratorium on new deepwater drilling permits and leases, pending regulatory review.[300] As multiple efforts by BP failed, some in the media and public expressed confusion and criticism over various aspects of the incident, and stated a desire for more involvement by Obama and the federal government.[301]
",2
988,"In July 2013, Obama expressed reservations and said he ""would reject the Keystone XL pipeline if it increased carbon pollution"" or ""greenhouse emissions"".[302][303] Obama's advisers called for a halt to petroleum exploration in the Arctic in January 2013.[304] On February 24, 2015, Obama vetoed a bill that would have authorized the pipeline.[305] It was the third veto of Obama's presidency and his first major veto.[306]
",2
989,"Obama emphasized the conservation of federal lands during his term in office. He used his power under the Antiquities Act to create 25 new national monuments during his presidency and expand four others, protecting a total of 553,000,000 acres (224,000,000 ha) of federal lands and waters, more than any other U.S. president.[307][308][309][310]
",2
990,"Obama called for Congress to pass legislation reforming health care in the United States, a key campaign promise and a top legislative goal.[311] He proposed an expansion of health insurance coverage to cover the uninsured, cap premium increases, and allow people to retain their coverage when they leave or change jobs. His proposal was to spend $900 billion over ten years and include a government insurance plan, also known as the public option, to compete with the corporate insurance sector as a main component to lowering costs and improving quality of health care. It would also make it illegal for insurers to drop sick people or deny them coverage for pre-existing conditions, and require every American to carry health coverage. The plan also includes medical spending cuts and taxes on insurance companies that offer expensive plans.[312][313]
",2
991,"On July 14, 2009, House Democratic leaders introduced a 1,017-page plan for overhauling the U.S. health care system, which Obama wanted Congress to approve by the end of 2009.[311] After much public debate during the Congressional summer recess of 2009, Obama delivered a speech to a joint session of Congress on September 9 where he addressed concerns over the proposals.[315] In March 2009, Obama lifted a ban on using federal funds for stem cell research.[316]
",2
992,"On November 7, 2009, a health care bill featuring the public option was passed in the House.[317][318] On December 24, 2009, the Senate passed its own bill—without a public option—on a party-line vote of 60–39.[319] On March 21, 2010, the Patient Protection and Affordable Care Act (ACA) passed by the Senate in December was passed in the House by a vote of 219 to 212.[320] Obama signed the bill into law on March 23, 2010.[321]
",2
993,"The ACA includes health-related provisions, most of which took effect in 2014, including expanding Medicaid eligibility for people making up to 133 percent of the federal poverty level (FPL) starting in 2014,[322] subsidizing insurance premiums for people making up to 400 percent of the FPL ($88,000 for family of four in 2010) so their maximum ""out-of-pocket"" payment for annual premiums will be from 2 percent to 9.5 percent of income,[323][324] providing incentives for businesses to provide health care benefits, prohibiting denial of coverage and denial of claims based on pre-existing conditions, establishing health insurance exchanges, prohibiting annual coverage caps, and support for medical research. According to White House and CBO figures, the maximum share of income that enrollees would have to pay would vary depending on their income relative to the federal poverty level.[323][325]
",2
994,"The costs of these provisions are offset by taxes, fees, and cost-saving measures, such as new Medicare taxes for those in high-income brackets, taxes on indoor tanning, cuts to the Medicare Advantage program in favor of traditional Medicare, and fees on medical devices and pharmaceutical companies;[327] there is also a tax penalty for those who do not obtain health insurance, unless they are exempt due to low income or other reasons.[328] In March 2010, the CBO estimated that the net effect of both laws will be a reduction in the federal deficit by $143 billion over the first decade.[329]
",2
995,"The law faced several legal challenges, primarily based on the argument that an individual mandate requiring Americans to buy health insurance was unconstitutional. On June 28, 2012, the Supreme Court ruled by a 5–4 vote in National Federation of Independent Business v. Sebelius that the mandate was constitutional under the U.S. Congress's taxing authority.[330] In Burwell v. Hobby Lobby the Court ruled that ""closely-held"" for-profit corporations could be exempt on religious grounds under the Religious Freedom Restoration Act from regulations adopted under the ACA that would have required them to pay for insurance that covered certain contraceptives. In June 2015, the Court ruled 6–3 in King v. Burwell that subsidies to help individuals and families purchase health insurance were authorized for those doing so on both the federal exchange and state exchanges, not only those purchasing plans ""established by the State"", as the statute reads.[331]
",2
996,"Prior to June 2014, Obama offered substantial support for a broadly-based ""All of the above"" approach to domestic energy policy, which Obama has maintained since his first term and which he last confirmed at his State of the Union speech in January 2014 to a mixed reception by both parties. In June 2014, Obama made indications that his administration would consider a shift towards an energy policy more closely tuned to the manufacturing industry and its impact on the domestic economy.[332] Obama's approach of selectively combining regulation and incentive to various issues in the domestic energy policy, such as coal mining and oil fracking, has received mixed commentary for not being as responsive to the needs of the domestic manufacturing sector as needed, following claims that the domestic manufacturing sector utilizes as much as a third of the nation's available energy resources.[333][334]
",2
997,"On January 16, 2013, one month after the Sandy Hook Elementary School shooting, Obama signed 23 executive orders and outlined a series of sweeping proposals regarding gun control.[335] He urged Congress to reintroduce an expired ban on military-style assault weapons, such as those used in several recent mass shootings, impose limits on ammunition magazines to 10 rounds, introduce background checks on all gun sales, pass a ban on possession and sale of armor-piercing bullets, introduce harsher penalties for gun-traffickers, especially unlicensed dealers who buy arms for criminals and approving the appointment of the head of the federal Bureau of Alcohol, Tobacco, Firearms and Explosives for the first time since 2006.[336] On January 5, 2016, Obama announced new executive actions extending background check requirements to more gun sellers.[337] In a 2016 editorial in The New York Times, Obama compared the struggle for what he termed ""common-sense gun reform"" to women's suffrage and other civil rights movements in American history.[338]
",2
998,"Obama called the November 2, 2010 election, where the Democratic Party lost 63 seats in, and control of, the House of Representatives,[339] ""humbling"" and a ""shellacking"".[340] He said that the results came because not enough Americans had felt the effects of the economic recovery.[341]
",2
999,"On November 10, 2014, President Obama recommended the Federal Communications Commission reclassify broadband Internet service as a telecommunications service in order to preserve net neutrality.[342][343] On February 12, 2013, President Obama signed Executive Order 13636, ""Improving Critical Infrastructure Cybersecurity"".[344]
",2
1000,"In 2005 and 2006, Obama criticized certain aspects of the Patriot Act for infringing too much on civil liberties and sought as Senator to strengthen civil liberties protections.[345][346][347] In 2006, he voted to reauthorize a revised version of the Patriot Act, saying the law was not ideal but that the revised version had strengthened civil liberties.[347] In 2011, he signed a four-year renewal of the Patriot Act.[348] Following the 2013 global surveillance disclosures by whistleblower Edward Snowden, Obama condemned the leak as unpatriotic,[346] but called for increased restrictions on the NSA to address violations of privacy.[349][350] The changes which Obama ordered have been described as ""modest"" however.[351]
",2
1001,"In February and March 2009, Vice President Joe Biden and Secretary of State Hillary Clinton made separate overseas trips to announce a ""new era"" in U.S. foreign relations with Russia and Europe, using the terms ""break"" and ""reset"" to signal major changes from the policies of the preceding administration.[352] Obama attempted to reach out to Arab leaders by granting his first interview to an Arab satellite TV network, Al Arabiya.[353]
",2
1002,"On March 19, Obama continued his outreach to the Muslim world, releasing a New Year's video message to the people and government of Iran.[354][355] In April, Obama gave a speech in Ankara, Turkey, which was well received by many Arab governments.[356] On June 4, 2009, Obama delivered a speech at Cairo University in Egypt calling for ""A New Beginning"" in relations between the Islamic world and the United States and promoting Middle East peace.[357]
",2
1003,"On June 26, 2009, Obama responded to the Iranian government's actions towards protesters following Iran's 2009 presidential election by saying: ""The violence perpetrated against them is outrageous. We see it and we condemn it.""[358] While in Moscow on July 7, he responded to Vice President Biden's comment on a possible Israeli military strike on Iran by saying: ""We have said directly to the Israelis that it is important to try and resolve this in an international setting in a way that does not create major conflict in the Middle East.""[359]
",2
1004,"On September 24, 2009, Obama became the first sitting U.S. president to preside over a meeting of the United Nations Security Council.[360]
",2
1005,"In March 2010, Obama took a public stance against plans by the government of Israeli Prime Minister Benjamin Netanyahu to continue building Jewish housing projects in predominantly Arab neighborhoods of East Jerusalem.[361][362] During the same month, an agreement was reached with the administration of Russian President Dmitry Medvedev to replace the 1991 Strategic Arms Reduction Treaty with a new pact reducing the number of long-range nuclear weapons in the arsenals of both countries by about a third.[363] Obama and Medvedev signed the New START treaty in April 2010, and the U.S. Senate ratified it in December 2010.[364]
",2
1006,"In December 2011, Obama instructed agencies to consider LGBT rights when issuing financial aid to foreign countries.[365] In August 2013, he criticized Russia's law that discriminates against gays,[366] but he stopped short of advocating a boycott of the upcoming 2014 Winter Olympics in Sochi, Russia.[367]
",2
1007,"In December 2014, Obama announced that he intended to normalize relationships between Cuba and the United States.[368] The countries' respective ""interests sections"" in one another's capitals were upgraded to embassies on July 20, 2015.
",2
1008,"In March 2015, Obama declared that he had authorized U.S. forces to provide logistical and intelligence support to the Saudis in their military intervention in Yemen, establishing a ""Joint Planning Cell"" with Saudi Arabia.[369][370] In 2016, the Obama administration proposed a series of arms deals with Saudi Arabia worth $115 billion.[371] Obama halted the sale of guided munition technology to Saudi Arabia after Saudi warplanes targeted a funeral in Yemen's capital Sanaa, killing more than 140 people.[372]
",2
1009,"Before leaving office, Obama said German Chancellor Angela Merkel had been his ""closest international partner"" throughout his tenure as president.[373]
",2
1010,"On February 27, 2009, Obama announced that combat operations in Iraq would end within 18 months. His remarks were made to a group of Marines preparing for deployment to Afghanistan. Obama said, ""Let me say this as plainly as I can: by August 31, 2010, our combat mission in Iraq will end.""[374] The Obama administration scheduled the withdrawal of combat troops to be completed by August 2010, decreasing troop's levels from 142,000 while leaving a transitional force of about 50,000 in Iraq until the end of 2011. On August 19, 2010, the last U.S. combat brigade exited Iraq. Remaining troops transitioned from combat operations to counter-terrorism and the training, equipping, and advising of Iraqi security forces.[375][376] On August 31, 2010, Obama announced that the United States combat mission in Iraq was over.[377] On October 21, 2011 President Obama announced that all U.S. troops would leave Iraq in time to be ""home for the holidays"".[378]
",2
1011,"In June 2014, following the capture of Mosul by ISIS, Obama sent 275 troops to provide support and security for U.S. personnel and the U.S. Embassy in Baghdad. ISIS continued to gain ground and to commit widespread massacres and ethnic cleansing.[379][380]
",2
1012,"In August 2014, during the Sinjar massacre, Obama ordered a campaign of U.S. airstrikes against ISIS.[381]
",2
1013,"By the end of 2014, 3,100 American ground troops were committed to the conflict[382] and 16,000 sorties were flown over the battlefield, primarily by U.S. Air Force and Navy pilots.[383]
",2
1014,"In early 2015, with the addition of the ""Panther Brigade"" of the 82nd Airborne Division the number of U.S. ground troops in Iraq surged to 4,400,[384] and by July American-led coalition air forces counted 44,000 sorties over the battlefield.[385]
",2
1015,"Early in his presidency, Obama moved to bolster U.S. troop strength in Afghanistan.[386] He announced an increase in U.S. troop levels to 17,000 military personnel in February 2009 to ""stabilize a deteriorating situation in Afghanistan"", an area he said had not received the ""strategic attention, direction and resources it urgently requires"".[387] He replaced the military commander in Afghanistan, General David D. McKiernan, with former Special Forces commander Lt. Gen. Stanley A. McChrystal in May 2009, indicating that McChrystal's Special Forces experience would facilitate the use of counterinsurgency tactics in the war.[388] On December 1, 2009, Obama announced the deployment of an additional 30,000 military personnel to Afghanistan and proposed to begin troop withdrawals 18 months from that date;[389] this took place in July 2011. David Petraeus replaced McChrystal in June 2010, after McChrystal's staff criticized White House personnel in a magazine article.[390] In February 2013, Obama said the U.S. military would reduce the troop level in Afghanistan from 68,000 to 34,000 U.S. troops by February 2014.[391]
",2
1016,"In October 2015, the White House announced a plan to keep U.S. Forces in Afghanistan indefinitely in light of the deteriorating security situation.[392]
",2
1017,"In 2011, the United States vetoed a Security Council resolution condemning Israeli settlements, with the United States being the only nation to do so.[393] Obama supports the two-state solution to the Arab–Israeli conflict based on the 1967 borders with land swaps.[394]
",2
1018,"In June 2011, Obama said the bond between the United States and Israel is ""unbreakable"".[395] During the initial years of the Obama administration, the U.S. increased military cooperation with Israel, including increased military aid, re-establishment of the U.S.-Israeli Joint Political Military Group and the Defense Policy Advisory Group, and an increase in visits among high-level military officials of both countries.[396] The Obama administration asked Congress to allocate money toward funding the Iron Dome program in response to the waves of Palestinian rocket attacks on Israel.[397]
",2
1019,"In 2013, Jeffrey Goldberg reported that, in Obama's view, ""with each new settlement announcement, Netanyahu is moving his country down a path toward near-total isolation.""[398] In 2014, Obama likened the Zionist movement to the Civil Rights Movement in the United States. He said both movements seek to bring justice and equal rights to historically persecuted peoples. He explained, ""To me, being pro-Israel and pro-Jewish is part and parcel with the values that I've been fighting for since I was politically conscious and started getting involved in politics.""[399] Obama expressed support for Israel's right to defend itself during the 2014 Israel–Gaza conflict.[400] In 2015, Obama was harshly criticized by Israel for advocating and signing the Iran Nuclear Deal; Israeli Prime Minister Benjamin Netanyahu, who had advocated the U.S. congress to oppose it, said the deal was ""dangerous"" and ""bad"".[401]
",2
1020,"On December 23, 2016, under the Obama Administration, the United States abstained from United Nations Security Council Resolution 2334, which condemned Israeli settlement building in the occupied Palestinian territories as a violation of international law, effectively allowing it to pass.[402] Netanyahu strongly criticized the Obama Administration's actions,[403][404] and the Israeli government withdrew its annual dues from the organization, which totaled $6 million, on January 6, 2017.[405] On January 5, 2017, the United States House of Representatives voted 342–80 to condemn the UN Resolution.[406][407]
",2
1021,"In February 2011, protests in Libya began against long-time dictator Muammar Gaddafi as part of the Arab Spring. They soon turned violent. In March, as forces loyal to Gaddafi advanced on rebels across Libya, calls for a no-fly zone came from around the world, including Europe, the Arab League, and a resolution[408] passed unanimously by the U.S. Senate.[409] In response to the unanimous passage of United Nations Security Council Resolution 1973 on March 17, Gaddafi—who had previously vowed to ""show no mercy"" to the rebels of Benghazi[410]—announced an immediate cessation of military activities,[411] yet reports came in that his forces continued shelling Misrata. The next day, on Obama's orders, the U.S. military took part in air strikes to destroy the Libyan government's air defense capabilities to protect civilians and enforce a no-fly-zone,[412] including the use of Tomahawk missiles, B-2 Spirits, and fighter jets.[413][414][415] Six days later, on March 25, by unanimous vote of all its 28 members, NATO took over leadership of the effort, dubbed Operation Unified Protector.[416] Some Representatives[417] questioned whether Obama had the constitutional authority to order military action in addition to questioning its cost, structure and aftermath.[418][419]
",2
1022,"On August 18, 2011, several months after the start of the Syrian Civil War, Obama issued a written statement that said: ""The time has come for President Assad to step aside.""[420][421] This stance was reaffirmed in November 2015.[422] In 2012, Obama authorized multiple programs run by the CIA and the Pentagon to train anti-Assad rebels.[423] The Pentagon-run program was later found to have failed and was formally abandoned in October 2015.[424][425]
",2
1023,"In the wake of a chemical weapons attack in Syria, formally blamed by the Obama administration on the Assad government, Obama chose not to enforce the ""red line"" he had pledged[426] and, rather than authorize the promised military action against Assad, went along with the Russia-brokered deal that led to Assad giving up chemical weapons; however attacks with chlorine gas continued.[427][428] In 2014, Obama authorized an air campaign aimed primarily at ISIL.[429]
",2
1024,"Starting with information received from Central Intelligence Agency operatives in July 2010, the CIA developed intelligence over the next several months that determined what they believed to be the hideout of Osama bin Laden. He was living in seclusion in a large compound in Abbottabad, Pakistan, a suburban area 35 miles (56 km) from Islamabad.[430] CIA head Leon Panetta reported this intelligence to President Obama in March 2011.[430] Meeting with his national security advisers over the course of the next six weeks, Obama rejected a plan to bomb the compound, and authorized a ""surgical raid"" to be conducted by United States Navy SEALs.[430] The operation took place on May 1, 2011, and resulted in the shooting death of bin Laden and the seizure of papers, computer drives and disks from the compound.[431][432] DNA testing was one of five methods used to positively identify bin Laden's corpse,[433] which was buried at sea several hours later.[434] Within minutes of the President's announcement from Washington, DC, late in the evening on May 1, there were spontaneous celebrations around the country as crowds gathered outside the White House, and at New York City's Ground Zero and Times Square.[431][435] Reaction to the announcement was positive across party lines, including from former presidents Bill Clinton and George W. Bush.[436]
",2
1025,"On October 1, 2009, the Obama administration went ahead with a Bush administration program, increasing nuclear weapons production. The ""Complex Modernization"" initiative expanded two existing nuclear sites to produce new bomb parts. The administration built new plutonium pits at the Los Alamos lab in New Mexico and expanded enriched uranium processing at the Y-12 facility in Oak Ridge, Tennessee.[437] In November 2013, the Obama administration opened negotiations with Iran to prevent it from acquiring nuclear weapons, which included an interim agreement. Negotiations took two years with numerous delays, with a deal being announced on July 14, 2015. The deal titled the ""Joint Comprehensive Plan of Action"" saw sanctions removed in exchange for measures that would prevent Iran from producing nuclear weapons. While Obama hailed the agreement as being a step towards a more hopeful world, the deal drew strong criticism from Republican and conservative quarters, and from Israeli Prime Minister Benjamin Netanyahu.[438][439][440] In addition, the transfer of $1.7 billion in cash to Iran shortly after the deal was announced was criticized by the republican party. The Obama administration said that the payment in cash was because of the ""effectiveness of U.S. and international sanctions"".[441] In order to advance the deal, the Obama administration shielded Hezbollah from the Drug Enforcement Administration's Project Cassandra investigation regarding drug smuggling and from the Central Intelligence Agency.[442][443]
On a side note, the very same year, in December 2015, Obama started a $348 billion worth program to back the biggest U.S. buildup of nuclear arms since Ronald Reagan left the White House.[444]
",2
1026,"Since the spring of 2013, secret meetings were conducted between the United States and Cuba in the neutral locations of Canada and Vatican City.[445] The Vatican first became involved in 2013 when Pope Francis advised the U.S. and Cuba to exchange prisoners as a gesture of goodwill.[446] On December 10, 2013, Cuban President Raúl Castro, in a significant public moment, greeted and shook hands with Obama at the Nelson Mandela memorial service in Johannesburg.[447]
",2
1027,"In December 2014, after the secret meetings, it was announced that Obama, with Pope Francis as an intermediary, had negotiated a restoration of relations with Cuba, after nearly sixty years of détente.[448] Popularly dubbed the Cuban Thaw, The New Republic deemed the Cuban Thaw to be ""Obama's finest foreign policy achievement"".[449] On July 1, 2015, President Obama announced that formal diplomatic relations between Cuba and the United States would resume, and embassies would be opened in Washington and Havana.[450] The countries' respective ""interests sections"" in one another's capitals were upgraded to embassies on July 20 and August 13, 2015, respectively.[451]
",2
1028,"Obama visited Havana, Cuba for two days in March 2016, becoming the first sitting U.S. president to arrive since Calvin Coolidge in 1928.[452]
",2
1029,"Obama spoke in front of the African Union in Addis Ababa, Ethiopia, on July 29, 2015, the first sitting U.S. president to do so. He gave a speech encouraging the world to increase economic ties via investments and trade with the continent, and lauded the progress made in education, infrastructure, and economy. He also criticized the lack of democracy and leaders who refuse to step aside, discrimination against minorities (LGBT people, religious groups and ethnicities), and corruption. He suggested an intensified democratization and free trade, to significantly improve the quality of life for Africans.[453][454] During his July 2015 trip, Obama also was the first U.S. president ever to visit Kenya, which is the homeland of his father.[455]
",2
1030,"On May 27, 2016, Obama became the first sitting American president to visit Hiroshima, Japan, 71 years after the U.S. atomic bombing of Hiroshima that ended World War II. Accompanied by Japanese Prime Minister Shinzō Abe, Obama paid tribute to the victims of the bombing at the Hiroshima Peace Memorial Museum.[456]
",2
1031,"After Russia's invasion of Crimea in 2014, military intervention in Syria in 2015, and the interference in the 2016 U.S. presidential election,[457] Obama's Russia policy was widely seen as a failure.[458] George Robertson, a former UK defense secretary and NATO secretary-general, said Obama had ""allowed Putin to jump back on the world stage and test the resolve of the West"", adding that the legacy of this disaster would last.[459]
",2
1032,"Obama's family history, upbringing, and Ivy League education differ markedly from those of African-American politicians who launched their careers in the 1960s through participation in the civil rights movement.[460] Expressing puzzlement over questions about whether he is ""black enough"", Obama told an August 2007 meeting of the National Association of Black Journalists that ""we're still locked in this notion that if you appeal to white folks then there must be something wrong.""[461] Obama acknowledged his youthful image in an October 2007 campaign speech, saying: ""I wouldn't be here if, time and again, the torch had not been passed to a new generation.""[462]
",2
1033,"Obama is frequently referred to as an exceptional orator.[463] During his pre-inauguration transition period and continuing into his presidency, Obama delivered a series of weekly Internet video addresses.[464] In his speeches as president, Obama did not make more overt references to race relations than his predecessors,[465][466] but according to one study, he implemented stronger policy action on behalf of African-Americans than any president since the Nixon era.[467]
",2
1034,"According to the Gallup Organization, Obama began his presidency with a 68 percent approval rating[468] before gradually declining for the rest of the year, and eventually bottoming out at 41 percent in August 2010,[469] a trend similar to Ronald Reagan's and Bill Clinton's first years in office.[470] He experienced a small poll bounce shortly after the death of Osama bin Laden on May 2, 2011. This bounce lasted until around June 2011, when his approval numbers dropped back to where they were previously.[471][472] His approval ratings rebounded around the same time as his reelection in 2012, with polls showing an average job approval of 52 percent shortly after his second inauguration.[473] Despite approval ratings dropping to 39 percent in late-2013 due to the ACA roll-out, they climbed to 50 percent in January 2015 according to Gallup.[474]
",2
1035,"Polls showed strong support for Obama in other countries both before and during his presidency.[475][476] In a February 2009 poll conducted in Western Europe and the U.S. by Harris Interactive for France 24 and the International Herald Tribune, Obama was rated as the most respected world leader, as well as the most powerful.[477] In a similar poll conducted by Harris in May 2009, Obama was rated as the most popular world leader, as well as the one figure most people would pin their hopes on for pulling the world out of the economic downturn.[478][479]
",2
1036,"Obama won Best Spoken Word Album Grammy Awards for abridged audiobook versions of Dreams from My Father in February 2006 and for The Audacity of Hope in February 2008.[480] His concession speech after the New Hampshire primary was set to music by independent artists as the music video ""Yes We Can"", which was viewed ten million times on YouTube in its first month[481] and received a Daytime Emmy Award.[482] In December 2008 and in 2012, Time magazine named Obama as its Person of the Year.[483] The 2008 awarding was for his historic candidacy and election, which Time described as ""the steady march of seemingly impossible accomplishments"".[484] On May 25, 2011, Obama became the first President of the United States to address both houses of the UK Parliament in Westminster Hall, London. This was only the fifth occurrence since the start of the 20th century of a head of state's being extended this invitation, following Charles de Gaulle in 1960, Nelson Mandela in 1996, Queen Elizabeth II in 2002 and Pope Benedict XVI in 2010.[485][486]
",2
1037,"On October 9, 2009, the Norwegian Nobel Committee announced that Obama had won the 2009 Nobel Peace Prize ""for his extraordinary efforts to strengthen international diplomacy and cooperation between peoples"".[487] Obama accepted this award in Oslo, Norway on December 10, 2009, with ""deep gratitude and great humility"".[488] The award drew a mixture of praise and criticism from world leaders and media figures.[489][490][491][492] Obama's peace prize was called a ""stunning surprise"" by The New York Times.[493] Some neoconservatives praised his speech for what they viewed as pro-American content.[494][495] He became the fourth U.S. president to be awarded the Nobel Peace Prize and the third to become a Nobel laureate while in office.[496] Obama's Nobel Prize has been viewed skeptically in subsequent years, especially after the director of the Nobel Institute, Geir Lundestad, said Obama's Peace Prize did not have the desired effect of encouraging the president.[497]
",2
1038,"Obama's presidency ended at noon on January 20, 2017, immediately following the inauguration of his Republican successor, Donald Trump. Obama and Biden attended Trump's inaguration.[498][499] After the inauguration, Obama lifted off on Executive One, circled the White House, and flew to Joint Base Andrews.[500] The family currently rents a house in Kalorama, Washington, D.C.[501]
",2
1039,"On March 2, 2017, the John F. Kennedy Presidential Library and Museum awarded the annual Profile in Courage Award to Obama ""for his enduring commitment to democratic ideals and elevating the standard of political courage"".[502] In his first public appearance out of office, Obama appeared at a seminar at the University of Chicago on April 24. The seminar was aimed at the engagement with a new generation as well as an appeal for their participation in politics.[503] On May 4, three days ahead of the French presidential election, Obama publicly endorsed centrist Emmanuel Macron over right-wing populist Marine Le Pen: ""He appeals to people's hopes and not their fears, and I enjoyed speaking to Emmanuel recently to hear about his independent movement and his vision for the future of France.""[504] Macron went on to win the election.
",2
1040,"While in Berlin on May 25, Obama made a joint public appearance with Chancellor Angela Merkel where he stressed inclusion and for leaders to question themselves. Obama had been formally invited to Berlin while still in office as part of an effort to boost Merkel's re-election campaign.[505] Obama traveled to Kensington Palace in England and met with Prince Harry on May 27, 2017; Obama tweeted afterward that the two discussed their foundations and offering condolences in the wake of the Manchester Arena bombing that occurred five days prior.[506]
",2
1041,"After President Trump announced his withdrawal of the United States from the Paris Agreement on June 1, Obama released a statement disagreeing with the choice: ""But even in the absence of American leadership; even as this administration joins a small handful of nations that reject the future; I'm confident that our states, cities, and businesses will step up and do even more to lead the way, and help protect for future generations the one planet we've got.""[507]
",2
1042,"After Senate Republicans revealed the Better Care Reconciliation Act of 2017, their discussion draft of a health care bill to replace the Affordable Care Act, on June 22, Obama released a Facebook post calling the bill ""a massive transfer of wealth from middle-class and poor families to the richest people in America"".[508] On September 19, while delivering the keynote address at Goalkeepers, Obama admitted his frustration with Republicans backing ""a bill that will raise costs, reduce coverage, and roll back protections for older Americans and people with pre-existing conditions"".[509]
",2
1043,"After Attorney General Jeff Sessions announced the termination of the Deferred Action for Childhood Arrivals (DACA) program on September 5, Obama released a Facebook post criticizing the decision.[510] Two days later, he partnered with former presidents Jimmy Carter, George H. W. Bush, Bill Clinton, and George W. Bush to work with One America Appeal to help the victims of Hurricane Harvey and Hurricane Irma in the Gulf Coast and Texas communities.[511]
",2
1044,"Obama hosted the inaugural summit of the Obama Foundation in Chicago from October 31 to November 1, 2017.[512] Obama intends for the foundation to be the central focus of his post-presidency and part of his ambitions for his subsequent activities following his presidency to be more consequential than his time in office.[513] Obama has also written a presidential memoir, in a reported $65 million deal with Penguin Random House.[514] The book, A Promised Land, was released on November 17, 2020.[515][516][517]
",2
1045,"Obama went on an international trip from November 28 to December 2, 2017, and visited China, India and France. In China, he delivered remarks at the Global Alliance of SMEs Summit in Shanghai and met with Chinese Communist Party leader Xi Jinping in Beijing.[518][519] He then went to India, where he spoke at the Hindustan Times Leadership Summit before meeting with Indian Prime Minister Narendra Modi over lunch. In addition, he held a town hall for young leaders, organized by the Obama Foundation.[520][521] He also met with the Dalai Lama while in New Delhi.[522] He ended his five-day trip in France where he met with French President Emmanuel Macron, former President François Hollande and Paris Mayor Anne Hidalgo and then spoke at an invitation-only event, touching on climate issues.[523]
",2
1046,"In May 2018, Obama criticized President Trump's decision to withdraw from the nuclear deal with Iran under the Joint Comprehensive Plan of Action saying ""the deal was working and it was in U.S. interests.""[524]
",2
1047,"Barack and Michelle Obama signed a deal on May 22, 2018 to produce docu-series, documentaries and features for Netflix under the Obamas' newly formed production company, Higher Ground Productions. On the deal, Michelle said ""I have always believed in the power of storytelling to inspire us, to make us think differently about the world around us, and to help us open our minds and hearts to others.""[525][526] Higher Ground's first film, American Factory, won the Academy Award for Best Documentary Feature in 2020.[527]
",2
1048,"A package that contained a pipe bomb was sent to Obama's home in Washington, D.C, on October 24, 2018. The package was intercepted by the Secret Service during routine mail screenings. Similar packages were sent to several other Democratic leaders, mostly those who voiced strong objections to the policies of Donald Trump, as well as one to CNN. Debbie Wasserman Schultz was addressed as the purported sender of the packages. On October 26, 2018, Cesar Sayoc was arrested and faced five federal charges in Manhattan carrying a combined maximum sentence of 48 years behind bars in relation to the pipe bombs.[528][529] He was sentenced to a maximum of 20 years in prison on August 5, 2019.[530]
",2
1049,"In 2019, Barack and Michelle Obama bought a home on Martha's Vineyard from Wyc Grousbeck.[531][532]
",2
1050,"On April 14, 2020, Obama endorsed his former vice president Joe Biden for president in the 2020 election, stating that he has ""all the qualities we need in a president right now"".[533][534]
",2
1051,"In May 2020, Obama criticized President Trump for his handling of the COVID-19 pandemic, calling his response to the crisis ""an absolute chaotic disaster"", and stating that the consequences of the Trump presidency have been ""our worst impulses unleashed, our proud reputation around the world badly diminished, and our democratic institutions threatened like never before"".[535] Michelle also criticized Trump, calling him ""the wrong president for America"". Trump retaliated by accusing Obama of having committed ""the biggest political crime in American history"", though he refused to say what he was talking about, telling reporters, ""You know what the crime is, the crime is very obvious to everybody.""[536]
",2
1052,"On May 16, 2020, Obama delivered two commencement speeches on behalf of the graduating youth who were not able to go to their physical graduation ceremonies due to the COVID-19 pandemic. His first speech was for part of the video streamed online program, ""Show Me Your Walk H.B.C.U. Edition"" virtual commencement.[537] In his address, he spoke about systemic racism, touching on both the pandemic, the shooting death of Ahmaud Arbery, and the fight to stay politically active saying, ""The fight for equality and justice begins with awareness, empathy, passion, even righteous anger. Don't just activate yourself online, change requires strategy, action, organizing, marching, and voting in the real world like never before."" His next commencement address was a part of a nationally televised event, titled Graduate Together: America Honors the High School Class of 2020 which aired on NBC.[538]
",2
1053,"In early December 2020, Obama criticized the ""defund the police"" slogan, claiming that it could derail social justice activists' attempts at making change and that ""you lost a big audience the minute you say it"".[539]
",2
1054,"On January 20, 2021, Obama and Michelle attended the inauguration of Joe Biden, alongside George W. Bush, Laura Bush, Bill Clinton and Hillary Clinton.[540]
",2
1055,"Obama's most significant legacy is generally considered to be the Patient Protection and Affordable Care Act (PPACA), provisions of which went into effect from 2010 to 2020. Many attempts by Senate Republicans to repeal the PPACA, including a ""skinny repeal"", have thus far failed.[541] Together with the Health Care and Education Reconciliation Act amendment, it represents the U.S. healthcare system's most significant regulatory overhaul and expansion of coverage since the passage of Medicare and Medicaid in 1965.[542][543][544][545]
",2
1056,"Many commentators credit Obama with averting a threatened depression and pulling the economy back from the Great Recession.[541] According to the U.S. Bureau of Labor Statistics, the Obama administration created 11.3 million jobs from the month after his first inauguration to the end of his term.[546] In 2010, Obama signed into effect the Dodd–Frank Wall Street Reform and Consumer Protection Act. Passed as a response to the financial crisis of 2007–08, it brought the most significant changes to financial regulation in the United States since the regulatory reform that followed the Great Depression under Democratic President Franklin D. Roosevelt.[547]
",2
1057,"In 2009, Obama signed into law the National Defense Authorization Act for Fiscal Year 2010, which contained in it the Matthew Shepard and James Byrd Jr. Hate Crimes Prevention Act, the first addition to existing federal hate crime law in the United States since Democratic President Bill Clinton signed into law the Church Arson Prevention Act of 1996. The Matthew Shepard and James Byrd Jr. Hate Crimes Prevention Act expanded existing federal hate crime laws in the United States to apply to crimes motivated by a victim's actual or perceived gender, sexual orientation, gender identity, or disability, and dropped the prerequisite that the victim be engaged in a federally protected activity.
",2
1058,"As president, Obama advanced LGBT rights.[548] In 2010, he signed the Don't Ask, Don't Tell Repeal Act, which brought an end to ""don't ask, don't tell"" policy in the U.S. armed forces that banned open service from LGB people; the law went into effect the following year.[549] In 2016, his administration brought an end to the ban on transgender people serving openly in the U.S. armed forces.[550][241] A Gallup poll, taken in the final days of Obama's term, showed that 68 percent of Americans believed the U.S. had made progress in the situation for gays and lesbians during Obama's eight years in office.[551]
",2
1059,"Obama substantially escalated the use of drone strikes against suspected militants and terrorists associated with al-Qaeda and the Taliban.[552][553] In 2016, the last year of his presidency, the U.S. dropped 26,171 bombs on seven different countries.[554][555] Obama left about 8,400 U.S. troops in Afghanistan, 5,262 in Iraq, 503 in Syria, 133 in Pakistan, 106 in Somalia, seven in Yemen, and two in Libya at the end of his presidency.[556][557]
",2
1060,"According to Pew Research Center and United States Bureau of Justice Statistics, from December 31, 2009, to December 31, 2015, inmates sentenced in U.S. federal custody declined by five percent. This is the largest decline in sentenced inmates in U.S. federal custody since Democratic President Jimmy Carter. By contrast, the federal prison population increased significantly under presidents Ronald Reagan, George H. W. Bush, Bill Clinton, and George W. Bush.[558]
",2
1061,"Obama left office in January 2017 with a 60 percent approval rating.[559][560] A 2018 survey of historians by the American Political Science Association ranked Obama the 8th-greatest American President.[3] Obama gained 10 spots from the same survey in 2015 from the Brookings Institution that ranked him the 18th-greatest American President.[561]
",2
1062,"The Barack Obama Presidential Center is Obama's planned presidential library. It will be hosted by the University of Chicago and located in Jackson Park on the South Side of Chicago.[562]
",2
1063,"
",2
1064,"
",2
1065,"Donald John Trump (born June 14, 1946) is an American media personality and businessman who served as the 45th president of the United States from 2017 to 2021.
",2
1066,"Born and raised in Queens, New York City, Trump attended Fordham University for two years and received a bachelor's degree in economics from the Wharton School of the University of Pennsylvania. He became the president of his father Fred Trump's real estate business in 1971, and renamed it to The Trump Organization. Trump expanded the company's operations to building and renovating skyscrapers, hotels, casinos, and golf courses. He later started various side ventures, mostly by licensing his name. Trump and his businesses have been involved in more than 4,000 state and federal legal actions, including six bankruptcies. He owned the Miss Universe brand of beauty pageants from 1996 to 2015. From 2003 to 2015 he co-produced and hosted the reality television series The Apprentice.
",2
1067,"Trump's political positions have been described as populist, protectionist, isolationist, and nationalist. He entered the 2016 presidential race as a Republican and was elected in an upset victory over Democratic nominee Hillary Clinton while losing the popular vote.[a] He became the first U.S. president without prior military or government service. His election and policies sparked numerous protests. Trump made many false and misleading statements during his campaigns and presidency, to a degree unprecedented in American politics. Many of his comments and actions have been characterized as racially charged or racist.
",2
1068,"During his presidency, Trump ordered a travel ban on citizens from several Muslim-majority countries, citing security concerns; after legal challenges, the Supreme Court upheld the policy's third revision. He enacted a tax-cut package for individuals and businesses, rescinding the individual health insurance mandate penalty of the Affordable Care Act. He signed criminal justice reform and appointed Neil Gorsuch, Brett Kavanaugh and Amy Coney Barrett to the Supreme Court. He reacted slowly to the COVID-19 pandemic, ignored or contradicted many recommendations from health officials in his messaging, and promoted misinformation about unproven treatments and the availability of testing. In foreign policy, Trump pursued an America First agenda: he renegotiated the North American Free Trade Agreement as the U.S.–Mexico–Canada Agreement and withdrew the U.S. from the Trans-Pacific Partnership trade negotiations, the Paris Agreement on climate change and the Iran nuclear deal. He imposed import tariffs which triggered a trade war with China, withdrew U.S. troops from northern Syria, and met three times with North Korean leader Kim Jong-un. Negotiations with Kim on denuclearization eventually broke down.
",2
1069,"A special counsel investigation led by Robert Mueller found that Trump and his campaign benefited from Russian interference in the 2016 presidential election, but did not find sufficient evidence to press charges of criminal conspiracy or coordination with Russia.[b] Mueller also investigated Trump for obstruction of justice and his report neither indicted nor exonerated Trump on that offense. After Trump solicited Ukraine to investigate his political rival Joe Biden, the House of Representatives impeached him in December 2019 for abuse of power and obstruction of Congress. The Senate acquitted him of both charges in February 2020. 
",2
1070,"Trump lost the 2020 presidential election to Biden, but refused to concede defeat. He attempted to overturn the results by making false claims of electoral fraud, pressuring government officials, mounting scores of unsuccessful legal challenges and obstructing the presidential transition. On the day Congress met to tally the electoral votes, January 6, 2021, Trump rallied his supporters and told them to march to the Capitol. When they arrived, hundreds of them broke through security barricades and stormed the Capitol, resulting in the deaths of five people and forcing Congress to evacuate. Seven days later, the House impeached Trump for incitement of insurrection, making him the only federal officeholder in American history to be impeached twice. The Senate acquitted Trump for the second time on February 13, 2021.
",2
1071,"Donald John Trump was born on June 14, 1946, at Jamaica Hospital in the borough of Queens in New York City,[1][2] the fourth child of Fred Trump, a Bronx-born real estate developer whose parents were German immigrants, and Mary Anne MacLeod Trump, an immigrant from Scotland. Trump grew up with older siblings Maryanne, Fred Jr., and Elizabeth, and younger brother Robert in the Jamaica Estates neighborhood of Queens and attended the private Kew-Forest School from kindergarten through seventh grade.[3][4][5] At age 13, he was enrolled in the New York Military Academy, a private boarding school,[6] and in 1964, he enrolled at Fordham University. Two years later he transferred to the Wharton School of the University of Pennsylvania, graduating in May 1968 with a B.S. in economics.[7][8] The New York Times reported in 1973 and 1976 that he had graduated first in his class at Wharton, but he had never made the school's honor roll.[9] In 2015, Trump's lawyer Michael Cohen threatened Fordham University and the New York Military Academy with legal action if they released Trump's academic records.[10] While in college, Trump obtained four student draft deferments.[11] In 1966, he was deemed fit for military service based upon a medical examination, and in July 1968 a local draft board classified him as eligible to serve.[12] In October 1968, he was classified 1-Y, a conditional medical deferment,[13] and in 1972, he was reclassified 4-F due to bone spurs, permanently disqualifying him from service.[14][15]
",2
1072,"In 1977, Trump married Czech model Ivana Zelníčková.[16] They have three children, Donald Jr. (born 1977), Ivanka (born 1981), and Eric (born 1984).[17] Ivana became a naturalized United States citizen in 1988.[18] The couple divorced in 1992, following Trump's affair with actress Marla Maples.[19] Maples and Trump married in 1993[20] and had one daughter, Tiffany (born 1993).[21] They were divorced in 1999,[22] and Tiffany was raised by Marla in California.[23] In 2005, Trump married Slovenian model Melania Knauss.[24] They have one son, Barron (born 2006).[25] Melania gained U.S. citizenship in 2006.[26]
",2
1073,"Trump went to Sunday school and was confirmed in 1959 at the First Presbyterian Church in Jamaica, Queens.[27][28] In the 1970s, his parents joined the Marble Collegiate Church in Manhattan, which belongs to the Reformed Church.[27][29] The pastor at Marble, Norman Vincent Peale,[27] ministered to Trump's family until Peale's death in 1993.[29] Trump has described Peale as a mentor.[30] In 2015, after Trump said he attends Marble, the church stated he ""is not an active member"" of the church.[28] In November 2019, Trump appointed his personal pastor, televangelist Paula White, to the White House Office of Public Liaison.[31] In October 2020, Trump said that he identified as a non-denominational Christian.[32]
",2
1074,"Trump says he has never drunk alcohol, smoked cigarettes, or used drugs.[33][34] He sleeps about four or five hours a night.[35][36] Trump has called golfing his ""primary form of exercise"" but usually does not walk the course.[37] He considers exercise a waste of energy, because he believes the body is ""like a battery, with a finite amount of energy"" which is depleted by exercise.[38]
",2
1075,"In 2015, Harold Bornstein, who had been Trump's personal physician since 1980, wrote that Trump would ""be the healthiest individual ever elected to the presidency"" in a letter released by the Trump campaign.[39] In 2018, Bornstein said Trump had dictated the contents of the letter and that three agents of Trump had removed his medical records in February 2017 without authorization.[39][40]
",2
1076,"Trump was hospitalized at Walter Reed National Military Medical Center for COVID-19 treatment on October 2, 2020, reportedly with a fever and difficulty breathing. It was revealed in 2021 that his condition had been much more serious. He had extremely low blood oxygen levels, a high fever, and lung infiltrates, indicating a severe case of the disease.[41] He was treated with the antiviral drug remdesevir, the steroid dexamethasone, and the unapproved experimental antibody REGN-COV2.[42] Trump returned to the White House on October 5, still struggling with the disease.[41]
",2
1077,"In 1982, Trump was listed on the initial Forbes list of wealthy individuals as having a share of his family's estimated $200 million net worth. His financial losses in the 1980s caused him to be dropped from the list between 1990 and 1995.[43] In its 2020 billionaires ranking, Forbes estimated Trump's net worth at $2.1 billion[c] (1,001st in the world),[46] making him one of the richest politicians in American history and the first billionaire American president.[46] Forbes estimated that his net worth declined 31 percent and his ranking fell 138 spots between 2015 and 2018.[47] When he filed mandatory financial disclosure forms with the Federal Election Commission (FEC) in July 2015, Trump claimed a net worth of about $10 billion;[48] however, FEC figures cannot corroborate this estimate because they only show each of his largest buildings as being worth over $50 million, yielding total assets worth more than $1.4 billion and debt of more than $265 million.[49]
",2
1078,"Journalist Jonathan Greenberg reported in 2018 that Trump, using the pseudonym ""John Barron"" and claiming to be a Trump Organization official, called him in 1984 to falsely assert that he owned ""in excess of ninety percent"" of the Trump family's business, to secure a higher ranking on the Forbes 400 list of wealthy Americans. Greenberg also wrote that Forbes had vastly overestimated Trump's wealth and wrongly included him on the Forbes 400 rankings of 1982, 1983, and 1984.[50]
",2
1079,"Trump has often said he began his career with ""a small loan of one million dollars"" from his father, and that he had to pay it back with interest.[51] In October 2018, The New York Times reported that Trump ""was a millionaire by age 8,"" borrowed at least $60 million from his father, largely failed to repay those loans, and had received $413 million (adjusted for inflation) from his father's business empire over his lifetime.[52][53] According to the report, Trump and his family committed tax fraud, which a lawyer for Trump denied. The tax department of New York said it is investigating.[54][55] Trump's investments underperformed the stock market and the New York property market.[56][57] Forbes estimated in October 2018 that the value of Trump's personal brand licensing business had declined by 88 percent since 2015, to $3 million.[58]
",2
1080,"Trump's tax returns from 1985 to 1994 show net losses totaling $1.17 billion over the ten-year period, in contrast to his claims about his financial health and business abilities. The New York Times reported that ""year after year, Mr. Trump appears to have lost more money than nearly any other individual American taxpayer"" and that Trump's ""core business losses in 1990 and 1991—more than $250 million each year—were more than double those of the nearest taxpayers in the I.R.S. information for those years."" In 1995 his reported losses were $915.7 million.[59][60]
",2
1081,"According to a September 2020 analysis by The New York Times of twenty years of data from Trump's tax returns, Trump had accumulated hundreds of millions in losses and deferred declaring $287 million in forgiven debt as taxable income.[61] According to the analysis, Trump's main sources of income were his share of revenue from The Apprentice and income from businesses in which he was a minority partner, while his majority-owned businesses were largely running at losses.[61] A significant portion of Trump's income was in tax credits due to his losses, which enables him to avoid paying income tax, or paying as little as $750, for several years.[61] Over the past decade, Trump has been balancing his businesses' losses by selling and taking out loans against assets, including a $100 million mortgage on Trump Tower (due in 2022) and the liquidation of over $200 million in stocks and bonds.[61] Trump has personally guaranteed $421 million in debt, most of which is due to be repaid by 2024. The tax records also showed Trump had unsuccessfully pursued business deals in China, including by developing a partnership with a major government-controlled company.[62]
",2
1082,"Trump has a total of over $1 billion in debts, borrowed to finance his assets, reported Forbes in October 2020. Around $640 million or more was owed to various banks and trust organizations. Around $450 million was owed to unknown creditors. However, Trump's assets still outvalue his debts, reported Forbes.[63]
",2
1083,"While a student at Wharton and after graduating in 1968, Trump worked at his father Fred's real estate company, Trump Management, which owned middle-class rental housing in New York City's outer boroughs.[64][65][66] In 1971, he became president of the company and began using The Trump Organization as an umbrella brand.[67] It was registered as a corporation in 1981.[68]
",2
1084,"Trump attracted public attention in 1978 with the launch of his family's first Manhattan venture, the renovation of the derelict Commodore Hotel, adjacent to Grand Central Terminal. The financing was facilitated by a $400 million city property tax abatement arranged by Fred Trump,[69] who also joined Hyatt in guaranteeing $70 million in bank construction financing.[70][71] The hotel reopened in 1980 as the Grand Hyatt Hotel,[72] and that same year, Trump obtained rights to develop Trump Tower, a mixed-use skyscraper in Midtown Manhattan.[73] The building houses the headquarters of the Trump Organization and was Trump's primary residence until 2019.[74][75]
",2
1085,"In 1988, Trump acquired the Plaza Hotel in Manhattan with a loan of $425 million from a consortium of banks. Two years later, the hotel filed for bankruptcy protection, and a reorganization plan was approved in 1992.[76] In 1995, Trump lost the hotel to Citibank and investors from Singapore and Saudi Arabia, who assumed $300 million of the debt.[77][78]
",2
1086,"In 1996, Trump acquired the vacant 71-story skyscraper at 40 Wall Street. After an extensive renovation, the high-rise was renamed the Trump Building.[79] In the early 1990s, Trump won the right to develop a 70-acre (28 ha) tract in the Lincoln Square neighborhood near the Hudson River. Struggling with debt from other ventures in 1994, Trump sold most of his interest in the project to Asian investors, who were able to finance completion of the project, Riverside South.[80]
",2
1087,"In 1985, Trump acquired the Mar-a-Lago estate in Palm Beach, Florida.[81] Trump converted the estate into a private club with an initiation fee and annual dues and used a wing of the house as a private residence.[82] In 2019, Trump declared Mar-a-Lago his primary residence,[75] although under a 1993 agreement with the Town of Palm Beach, Trump may spend no more than three weeks per year there.[83]
",2
1088,"In 1984, Trump opened Harrah's at Trump Plaza, a hotel and casino in Atlantic City, New Jersey. The project received financing from the Holiday Corporation, which also managed the operation. Gambling had been legalized there in 1977 to revitalize the once-popular seaside destination.[84] The property's poor financial results worsened tensions between Holiday and Trump, who paid Holiday $70 million in May 1986 to take sole control of the property.[85] Earlier, Trump had also acquired a partially completed building in Atlantic City from the Hilton Corporation for $320 million. Upon its completion in 1985, that hotel and casino were called Trump Castle. Trump's then-wife Ivana managed it until 1988.[86][87]
",2
1089,"Trump acquired a third casino in Atlantic City, the Trump Taj Mahal, in 1988 in a highly leveraged transaction.[88] It was financed with $675 million in junk bonds and completed at a cost of $1.1 billion, opening in April 1990.[89][90][91] The project went bankrupt the following year,[90] and the reorganization left Trump with only half his initial ownership stake and required him to pledge personal guarantees of future performance.[92] Facing ""enormous debt,"" he gave up control of his money-losing airline, Trump Shuttle, and sold his megayacht, the Trump Princess, which had been indefinitely docked in Atlantic City while leased to his casinos for use by wealthy gamblers.[93][94]
",2
1090,"In 1995, Trump founded Trump Hotels & Casino Resorts (THCR), which assumed ownership of Trump Plaza, Trump Castle, and the Trump Casino in Gary, Indiana.[95] THCR purchased the Taj Mahal in 1996 and underwent successive bankruptcies in 2004, 2009, and 2014, leaving Trump with only ten percent ownership.[96] He remained chairman of THCR until 2009.[97]
",2
1091,"The Trump Organization began acquiring and constructing golf courses in 1999.[98] It owned 16 golf courses and resorts worldwide and operated another two as of December 2016[update].[99]
",2
1092,"From his inauguration until the end of 2019, Trump spent around one of every five days at one of his golf clubs.[100]
",2
1093,"The Trump name has been licensed for various consumer products and services, including foodstuffs, apparel, adult learning courses, and home furnishings.[101][102] According to an analysis by The Washington Post, there are more than fifty licensing or management deals involving Trump's name, which have generated at least $59 million in yearly revenue for his companies.[103] By 2018, only two consumer goods companies continued to license his name.[102]
",2
1094,"Fixer Roy Cohn served as Trump's lawyer and mentor for 13 years in the 1970s and 1980s.[104][105] According to Trump, Cohn sometimes waived fees due to their friendship.[65] In 1973, Cohn helped Trump countersue the United States government for $100 million over its charges that Trump's properties had racial discriminatory practices. Trump and Cohn lost that case when the countersuit was dismissed and the government's case went forward.[106] In 1975 an agreement was struck requiring Trump's properties to furnish the New York Urban League with a list of all apartment vacancies, every week for two years, among other things.[107] Cohn introduced political consultant Roger Stone to Trump, who enlisted Stone's services to deal with the federal government.[108]
",2
1095,"As of April 2018[update], Trump and his businesses had been involved in more than 4,000 state and federal legal actions, according to a running tally by USA Today.[109]
",2
1096,"While Trump has not filed for personal bankruptcy, his over-leveraged hotel and casino businesses in Atlantic City and New York filed for Chapter 11 bankruptcy protection six times between 1991 and 2009.[110][111] They continued to operate while the banks restructured debt and reduced Trump's shares in the properties.[110][111]
",2
1097,"During the 1980s, more than 70 banks had lent Trump $4 billion,[112] but in the aftermath of his corporate bankruptcies of the early 1990s, most major banks declined to lend to him, with only Deutsche Bank still willing to lend money.[113] The New York Times reported days after the 2021 storming of the United States Capitol that the bank had decided not to do business with Trump or his company in the future.[114]
",2
1098,"In April 2019, the House Oversight Committee issued subpoenas seeking financial details from Trump's banks, Deutsche Bank and Capital One, and his accounting firm, Mazars USA. In response, Trump sued the banks, Mazars, and committee chairman Elijah Cummings to prevent the disclosures.[115][116] In May, DC District Court judge Amit Mehta ruled that Mazars must comply with the subpoena,[117] and judge Edgardo Ramos of the Southern District Court of New York ruled that the banks must also comply.[118][119] Trump's attorneys appealed the rulings,[120] arguing that Congress was attempting to usurp the ""exercise of law-enforcement authority that the Constitution reserves to the executive branch.""[121][122]
",2
1099,"In September 1983, Trump purchased the New Jersey Generals, a team in the United States Football League. After the 1985 season, the league folded, largely due to Trump's strategy of moving games to a fall schedule (where they competed with the NFL for audience) and trying to force a merger with the NFL by bringing an antitrust suit against the organization.[123][124]
",2
1100,"Trump's businesses have hosted several boxing matches at the Atlantic City Convention Hall adjacent to and promoted as taking place at the Trump Plaza in Atlantic City.[125][126] In 1989 and 1990, Trump lent his name to the Tour de Trump cycling stage race, which was an attempt to create an American equivalent of European races such as the Tour de France or the Giro d'Italia.[127]
",2
1101,"In the late 1980s, Trump mimicked the actions of Wall Street's so-called corporate raiders. Trump began to purchase significant blocks of shares in various public companies, leading some observers to think he was engaged in the practice called greenmail, or feigning the intent to acquire the companies and then pressuring management to repurchase the buyer's stake at a premium. The New York Times found that Trump initially made millions of dollars in such stock transactions, but later ""lost most, if not all, of those gains after investors stopped taking his takeover talk seriously.""[59][128][129]
",2
1102,"In 1988, Trump purchased the defunct Eastern Air Lines shuttle, with 21 planes and landing rights in New York City, Boston, and Washington, D.C. He financed the purchase with $380 million from 22 banks, rebranded the operation the Trump Shuttle, and operated it until 1992. Trump failed to earn a profit with the airline and sold it to USAir.[130]
",2
1103,"In 1992, Trump, his siblings Maryanne, Elizabeth, and Robert, and his cousin John W. Walter, each with a 20 percent share, formed All County Building Supply & Maintenance Corp. The company had no offices and is alleged to have been a shell company for paying the vendors providing services and supplies for Trump's rental units and then billing those services and supplies to Trump Management with markups of 20–50 percent and more. The proceeds generated by the markups were shared by the owners.[53][131] The increased costs were used as justification to get state approval for increasing the rents of Trump's rent-stabilized units.[53]
",2
1104,"From 1996 to 2015, Trump owned all or part of the Miss Universe pageants, including Miss USA and Miss Teen USA.[132][133] Due to disagreements with CBS about scheduling, he took both pageants to NBC in 2002.[134][135] In 2007, Trump received a star on the Hollywood Walk of Fame for his work as producer of Miss Universe.[136] After NBC and Univision dropped the pageants from their broadcasting lineups in June 2015,[137] Trump bought NBC's share of the Miss Universe Organization and sold the entire company to the William Morris talent agency.[132]
",2
1105,"In 2004, Trump co-founded Trump University, a company that sold real estate training courses priced from $1,500 to $35,000.[138][139] After New York State authorities notified the company that its use of the word ""university"" violated state law, its name was changed to Trump Entrepreneur Initiative in 2010.[140]
",2
1106,"In 2013, the State of New York filed a $40 million civil suit against Trump University, alleging that the company made false statements and defrauded consumers.[141][142] In addition, two class actions were filed in federal court against Trump and his companies. Internal documents revealed that employees were instructed to use a hard-sell approach, and former employees testified that Trump University had defrauded or lied to its students.[143][144][145] Shortly after he won the presidency, Trump agreed to pay a total of $25 million to settle the three cases.[146]
",2
1107,"The Donald J. Trump Foundation was a private foundation established in 1988.[147][148] In the foundation's final years its funds mostly came from donors other than Trump, who did not donate any personal funds to the charity from 2009 until 2014.[149] The foundation gave to health care and sports-related charities, as well as conservative groups.[150]
",2
1108,"In 2016, The Washington Post reported that the charity had committed several potential legal and ethical violations, including alleged self-dealing and possible tax evasion.[151] Also in 2016, the New York State attorney general's office said the foundation appeared to be in violation of New York laws regarding charities and ordered it to immediately cease its fundraising activities in New York.[152][153] Trump's team announced in December 2016 that the foundation would be dissolved.[154]
",2
1109,"In June 2018 the New York attorney general's office filed a civil suit against the foundation, Trump, and his adult children, seeking $2.8 million in restitution and additional penalties.[155][156] In December 2018, the foundation ceased operation and disbursed all its assets to other charities.[157] In November 2019, a New York state judge ordered Trump to pay $2 million to a group of charities for misusing the foundation's funds, in part to finance his presidential campaign.[158][159]
",2
1110,"Trump has written up to 19 books on business, financial, or political topics, though he has used ghostwriters to do this.[160] Trump's first book, The Art of the Deal (1987), was a New York Times Best Seller. While Trump was credited as co-author, the entire book was ghostwritten by Tony Schwartz.[161] According to The New Yorker, ""The book expanded Trump's renown far beyond New York City, making him an emblem of the successful tycoon.""[161] Trump has called the book his second favorite, after the Bible.[162]
",2
1111,"Trump made cameo appearances in eight films and television shows from 1985 to 2001.[163][164]
",2
1112,"Trump had a sporadic relationship with the professional wrestling promotion WWE since the late 1980s.[165] He appeared at WrestleMania 23 in 2007 and was inducted into the celebrity wing of the WWE Hall of Fame in 2013.[166]
",2
1113,"Starting in the 1990s, Trump was a guest about 24 times on the nationally syndicated Howard Stern Show.[167] He also had his own short-form talk radio program called Trumped! (one to two minutes on weekdays) from 2004 to 2008.[168][169] From 2011 until 2015, he was a weekly unpaid guest commentator on Fox & Friends.[170][171]
",2
1114,"In 2003, Trump became the co-producer and host of The Apprentice, a reality show in which Trump played the role of a chief executive and contestants competed for a year of employment at the Trump Organization. Trump eliminated contestants with the catchphrase ""You're fired.""[172] He later co-hosted The Celebrity Apprentice, in which celebrities competed to win money for charities.[172] Trump, who had been a member since 1989, resigned from the Screen Actors Guild in February 2021 rather than face a disciplinary committee hearing for inciting the January 6, 2021 mob attack on the U.S. Capitol and for his ""reckless campaign of misinformation aimed at discrediting and ultimately threatening the safety of journalists.""[173] Two days later, the union permanently barred him from readmission.[174]
",2
1115,"Trump's political party affiliation changed numerous times. He registered as a Republican in 1987, a member of the Independence Party, the New York state affiliate of the Reform Party, in 1999,[175] a Democrat in 2001, a Republican in 2009, unaffiliated in 2011, and a Republican in 2012.[176]
",2
1116,"In 1987, Trump placed full-page advertisements in three major newspapers,[177] advocating peace in Central America, accelerated nuclear disarmament talks with the Soviet Union, and reduction of the federal budget deficit by making American allies pay ""their fair share"" for military defense.[178] He ruled out running for local office but not for the presidency.[177]
",2
1117,"Trump ran in the California and Michigan primaries for nomination as the Reform Party candidate for the 2000 presidential election but withdrew from the race in February 2000.[179][180][181] A July 1999 poll matching him against likely Republican nominee George W. Bush and likely Democratic nominee Al Gore showed Trump with seven percent support.[182]
",2
1118,"Trump speculated about running against President Barack Obama in the 2012 election, making his first speaking appearance at the Conservative Political Action Conference (CPAC) in February 2011 and giving speeches in early primary states.[183][184] In May 2011 he announced he would not run,[183] and he endorsed Mitt Romney in February 2012.[185] Trump's presidential ambitions were generally not taken seriously at the time.[186]
",2
1119,"On June 16, 2015, Trump announced his candidacy for President of the United States.[187][188] His campaign was initially not taken seriously by political analysts, but he quickly rose to the top of opinion polls.[189]
",2
1120,"On Super Tuesday, Trump received the most votes, and he remained the front-runner throughout the primaries.[190] After a landslide win in Indiana on May 3, 2016 – which prompted the remaining candidates Ted Cruz and John Kasich to suspend their presidential campaigns – RNC chairman Reince Priebus declared Trump the presumptive Republican nominee.[191]
",2
1121,"Hillary Clinton had a significant lead over Trump in national polls throughout most of 2016. In early July, her lead narrowed in national polling averages.[192][193]
",2
1122,"On July 15, 2016, Trump announced his selection of Indiana governor Mike Pence as his vice presidential running mate.[194] Four days later, the two were officially nominated by the Republican Party at the Republican National Convention.[195]
",2
1123,"Trump and Clinton faced off in three presidential debates in September and October 2016. Trump's refusal to say whether he would accept the result of the election drew attention, with some saying it undermined democracy.[196][197]
",2
1124,"Trump's campaign platform emphasized renegotiating U.S.–China relations and free trade agreements such as NAFTA and the Trans-Pacific Partnership, strongly enforcing immigration laws, and building a new wall along the U.S.–Mexico border. His other campaign positions included pursuing energy independence while opposing climate change regulations such as the Clean Power Plan and the Paris Agreement, modernizing and expediting services for veterans, repealing and replacing the Affordable Care Act, abolishing Common Core education standards, investing in infrastructure, simplifying the tax code while reducing taxes for all economic classes, and imposing tariffs on imports by companies that offshore jobs. During the campaign, he advocated a largely non-interventionist approach to foreign policy while increasing military spending, extreme vetting or banning immigrants from Muslim-majority countries[198] to pre-empt domestic Islamic terrorism, and aggressive military action against the Islamic State of Iraq and the Levant. He described NATO as ""obsolete"".[199][200]
",2
1125,"Trump's political positions and rhetoric were right-wing populist.[201][202][203] Politico has described his positions as ""eclectic, improvisational and often contradictory,""[204] while NBC News counted ""141 distinct shifts on 23 major issues"" during his campaign.[205]
",2
1126,"Trump said he disdained political correctness and frequently made claims of media bias.[206][207][208] His fame and provocative statements earned him an unprecedented amount of free media coverage, elevating his standing in the Republican primaries.[209]
",2
1127,"Trump made a record number of false statements compared to other candidates;[210][211][212] the press reported on his campaign lies and falsehoods, with the Los Angeles Times saying, ""Never in modern presidential politics has a major candidate made false statements as routinely as Trump has.""[213] His campaign statements were often opaque or suggestive.[214]
",2
1128,"Trump adopted the phrase ""truthful hyperbole,"" coined by his ghostwriter Tony Schwartz, to describe his public speaking style.[215][216]
",2
1129,"According to Michael Barkun, the Trump campaign was remarkable for bringing fringe ideas, beliefs, and organizations into the mainstream.[217] During his presidential campaign, Trump was accused of pandering to white supremacists.[218] He retweeted racist Twitter accounts,[219] and repeatedly refused to condemn David Duke, the Ku Klux Klan or white supremacists.[220] Duke enthusiastically supported Trump and said he and like-minded people voted for Trump because of his promises to ""take our country back"".[221][222] After repeated questioning by reporters, Trump said he disavowed Duke and the Klan.[223]
",2
1130,"The alt-right movement coalesced around and enthusiastically supported Trump's candidacy,[224][225] due in part to its opposition to multiculturalism and immigration.[226][227][228]
",2
1131,"In August 2016, he appointed Steve Bannon, the executive chairman of Breitbart News — described by Bannon as ""the platform for the alt-right"" — as his campaign CEO.[229] After the election, Trump condemned supporters who celebrated his victory with Nazi salutes.[230][231]
",2
1132,"As a candidate, Trump's FEC-required reports listed assets above $1.4 billion[49][232] and outstanding debts of at least $315 million.[99]
",2
1133,"Trump has not released his tax returns, contrary to the practice of every major candidate since 1976 and his promises in 2014 and 2015 to do so if he ran for office.[233][234] He said his tax returns were being audited, and his lawyers had advised him against releasing them.[235] After a lengthy court battle to block release of his tax returns and other records to the Manhattan district attorney for a criminal investigation, including two appeals by Trump to the United States Supreme Court, in February 2021 the high court allowed the records to be released to the prosecutor for review by a grand jury.[236][237]
",2
1134,"In October 2016, portions of Trump's state filings for 1995 were leaked to a reporter from The New York Times. They show that Trump had declared a loss of $916 million that year, which could have let him avoid taxes for up to 18 years.[238] In March 2017, the first two pages of Trump's 2005 federal income tax returns were leaked to MSNBC. The document states that Trump had a gross adjusted income of $150 million and paid $38 million in federal taxes. The White House confirmed the authenticity of the documents.[239][240]
",2
1135,"On November 8, 2016, Trump received 306 pledged electoral votes versus 232 for Clinton. The official counts were 304 and 227 respectively, after defections on both sides.[241] Trump received nearly 2.9 million fewer popular votes than Clinton, which made him the fifth person to be elected president while losing the popular vote.[242]
",2
1136,"Trump's victory was a political upset.[243] Polls had consistently shown Clinton with a nationwide – though diminishing – lead, as well as an advantage in most of the competitive states. Trump's support had been modestly underestimated, while Clinton's had been overestimated.[244]
",2
1137,"Trump won 30 states; included were Michigan, Pennsylvania, and Wisconsin, which had been part of what was considered a blue wall of Democratic strongholds since the 1990s. Clinton won 20 states and the District of Columbia. Trump's victory marked the return of an undivided Republican government – a Republican White House combined with Republican control of both chambers of Congress.[245]
",2
1138,"Trump was the oldest person to take office as president at the time of his inauguration. He is also the first president who did not serve in the military or hold any government office prior to becoming president.[246][247]
",2
1139,"Trump's election victory sparked numerous protests.[248][249] In the weeks following Trump's inauguration, massive demonstrations took place, such as the Women's Marches, which gathered 2.6 million people worldwide.[250] Marches against his travel ban began across the country on January 29, 2017, just nine days after his inauguration.[251]
",2
1140,"Trump was inaugurated as the 45th president of the United States on January 20, 2017. During his first week in office, he signed six executive orders: interim procedures in anticipation of repealing the Affordable Care Act (""Obamacare""), withdrawal from the Trans-Pacific Partnership negotiations, reinstatement of the Mexico City Policy, authorizing the Keystone XL and Dakota Access Pipeline construction projects, reinforcing border security, and beginning the planning and design process to construct a wall along the U.S. border with Mexico.[252]
",2
1141,"Trump's daughter Ivanka and her husband Jared Kushner became Assistant to the President and Senior Advisor to the President, respectively.[253][254]
",2
1142,"Before being inaugurated, Trump moved his businesses into a revocable trust run by his sons, Eric and Donald Jr, and a business associate.[255][256] However Trump continued to profit from his businesses[257] and continued to have knowledge of how his administration's policies affected his businesses.[256] Though Trump said he would eschew ""new foreign deals,"" the Trump Organization pursued expansions of its operations in Dubai, Scotland, and the Dominican Republic.[257]
",2
1143,"Lawsuits alleged that Trump violated the Domestic and Foreign Emoluments Clauses of the U.S. Constitution.[258] The plaintiffs said that Trump's business interests could allow foreign governments to influence him.[258][257][259][260] NBC News reported in 2019 that representatives of at least 22 foreign governments, including some facing charges of corruption or human rights abuses, appeared to have spent money at Trump Organization businesses during his presidency.[261][262] The litigation marked the first time that the Emoluments Clauses were substantively litigated.[258][260] As president, Trump mocked the Emoluments Clause as ""phony.""[263][257] In January 2021, the U.S. Supreme Court dismissed the lawsuits as Trump was no longer president.[264]
",2
1144,"Trump took office at the height of the longest economic expansion in American history,[265] which began in June 2009 and continued until February 2020, when the COVID-19 recession began.[266] Throughout his presidency, Trump mischaracterized the economy as the best in American history.[267]
",2
1145,"In December 2017, Trump signed tax legislation that permanently cut the corporate tax rate to 21 percent, lowered personal income tax rates until 2025, increased child tax credits, doubled the estate tax exemption to $11.2 million, and limited the state and local tax deduction to $10,000.[268]
",2
1146,"Trump is a skeptic of trade liberalization, adopting these views in the 1980s, and sharply criticized NAFTA during the Republican primary campaign in 2015.[269][270][271] He withdrew the U.S. from the Trans-Pacific Partnership (TPP) negotiations,[272] imposed tariffs on steel and aluminum imports,[273] and launched a trade war with China by sharply increasing tariffs on 818 categories (worth $50 billion) of Chinese goods imported into the U.S.[274][275] On several occasions, Trump said incorrectly that these import tariffs are paid by China into the U.S. Treasury.[276] Although Trump pledged during his 2016 campaign to significantly reduce the U.S.'s large trade deficits, the U.S. trade deficit reached its highest level in 12 years under his administration.[277] Following a 2017–2018 renegotiation, Trump signed the United States-Mexico-Canada Agreement (USMCA) as the successor to NAFTA on January 29, 2020.[278] The revised trade deal became effective on July 1, 2020.[279]
",2
1147,"Despite a campaign promise to eliminate the national debt in eight years, Trump as president approved large increases in government spending, as well as the 2017 tax cut. As a result, the federal budget deficit increased by almost 50 percent, to nearly $1 trillion in 2019.[280] Under Trump, the U.S. national debt increased by 39 percent, reaching $27.75 trillion by the end of his term; the U.S. debt-to-GDP ratio also hit a post-World War II high.[281]
",2
1148,"Although the U.S. unemployment rate hit a 50-year low (3.5 percent) in February 2020, the unemployment rate hit a 90-year high (14.7 percent), matching Great Depression levels, just two months later, due to the COVID-19 pandemic.[282] Trump left office with 3 million fewer jobs in the U.S. than when he took office, making Trump the only modern U.S. president to leave office with a smaller workforce.[265]
",2
1149,"Analysis published by The Wall Street Journal in October 2020 found the trade war Trump initiated in early 2018 neither revived American manufacturing nor resulted in the reshoring of factory production.[283]
",2
1150,"Trump rejects the scientific consensus on climate change.[284][285] He slashed the budget for renewable energy research and reversed Obama-era policies directed at curbing climate change.[286] In June 2017, Trump announced the withdrawal of the United States from the Paris Agreement, making the U.S. the only nation in the world to not ratify the agreement.[287]
",2
1151,"Trump rolled back more 100 federal environmental regulations, including those that curbed greenhouse gas emissions, air and water pollution, and the use of toxic substances. He weakened protections for animals and environmental standards for federal infrastructure projects, and expanded permitted areas for drilling and resource extraction, such as allowing drilling in the Arctic Refuge.[288] Trump aimed to boost the production and exports of fossil fuels;[289][290] under Trump, natural gas expanded, but coal continued to decline.[291][292] Through September 2020 the Trump administration won less than 16 percent of its deregulation efforts challenged in courts, compared to an average of about 70 percent during the two preceding administrations.[293]
",2
1152,"During his presidency, Trump dismantled many federal regulations on health, labor, and the environment, among other topics.[294] Trump signed 15 Congressional Review Act resolutions repealing federal regulations, becoming the second president to sign a CRA resolution, and the first president to sign more than one CRA resolution.[295] During his first six weeks in office, he delayed, suspended or reversed ninety federal regulations.[296][297]
",2
1153,"On January 30, 2017, Trump signed Executive Order 13771, which directed that for every new regulation administrative agencies issue ""at least two prior regulations be identified for elimination.""[298] Agency defenders expressed opposition to Trump's criticisms, saying the bureaucracy exists to protect people against well-organized, well-funded interest groups.[299]
",2
1154,"During his campaign, Trump vowed to repeal and replace the Affordable Care Act,[300] and urged Congress to do so. In May 2017, the Republican-controlled House of Representatives passed a bill to repeal the ACA in a party-line vote,[301] but repeal proposals were narrowly voted down in the Senate after three Republicans joined all Democrats in opposing it.[302]
",2
1155,"Trump scaled back the implementation of the ACA through Executive Orders 13765[303] and 13813.[304] Trump has expressed a desire to ""let Obamacare fail""; his administration cut the ACA enrollment period in half and drastically reduced funding for advertising and other ways to encourage enrollment.[305][306] The 2017 tax bill signed by Trump effectively repealed the ACA's individual health insurance mandate in 2019,[307] and a budget bill Trump signed in 2019 repealed the Cadillac plan tax, medical device tax, and tanning tax.[308][better source needed] As president, Trump falsely claimed he saved the coverage of pre-existing conditions provided by the ACA;[309] in fact, the Trump administration joined a lawsuit seeking to strike down the entire ACA, including protections for those with pre-existing conditions.[310][311] If successful, the lawsuit would eliminate health insurance coverage for up to 23 million Americans.[310] As a 2016 candidate, Trump promised to protect funding for Medicare and other social safety-net programs, but in January 2020 he suggested he was willing to consider cuts to such programs.[312]
",2
1156,"Trump's policies in response to the opioid epidemic have been widely criticized as ineffectual and harmful. U.S. opioid overdose deaths declined slightly in 2018, but surged to a new record of 50,052 deaths in 2019.[313]
",2
1157,"Trump favored modifying the 2016 Republican platform opposing abortion, to allow for exceptions in cases of rape, incest, and circumstances endangering the health of the mother.[314] He said he was committed to appointing ""pro-life"" justices, pledging in 2016 to appoint justices who would ""automatically"" overturn Roe v. Wade.[315] He says he personally supports ""traditional marriage"" but considers the nationwide legality of same-sex marriage a ""settled"" issue.[316] In March 2017, the Trump administration rolled back key components of the Obama administration's workplace protections against discrimination of LGBT people.[317]
",2
1158,"Trump says he is opposed to gun control in general, although his views have shifted over time.[318] After several mass shootings during his term, Trump initially said he would propose legislation to curtail gun violence, but this was abandoned in November 2019.[319] The Trump administration has taken an anti-marijuana position, revoking Obama-era policies that provided protections for states that legalized marijuana.[320]
",2
1159,"Long favoring capital punishment,[321] Trump approved the first federal executions in 17 years;[322] under Trump, the federal government executed 13 prisoners, more than in the previous 56 years combined.[323] In 2016, Trump said he supported the use of interrogation torture methods such as waterboarding[324][325] but later appeared to recant this due to the opposition of Defense Secretary James Mattis.[326]
",2
1160,"Most of Trump's pardons were granted to people with personal or political connections to him.[327][328] In his term, Trump sidestepped regular Department of Justice procedures for considering pardons; instead he often entertained pardon requests from his associates or from celebrities.[327]
",2
1161,"In 2017, Trump pardoned former Arizona sheriff Joe Arpaio who was convicted of contempt of court for disobeying a court order to halt the racial profiling of Latinos.[329] In 2018, Trump pardoned former Navy sailor Kristian Saucier, who was convicted of taking classified photographs of a submarine;[330] Scooter Libby, a political aide to former vice president Dick Cheney, who was convicted of obstruction of justice, perjury, and making false statements to the FBI;[331] conservative commentator Dinesh D'Souza, who had made illegal political campaign contributions;[332] and he commuted the life sentence of Alice Marie Johnson, who had been convicted of drug trafficking, following a request by celebrity Kim Kardashian.[333] In February 2020, Trump pardoned white-collar criminals Michael Milken, Bernard Kerik, and Edward J. DeBartolo Jr., and commuted former Illinois governor Rod Blagojevich's 14-year corruption sentence.[334][335] Trump in 2019 pardoned or reversed the sentences of three American soldiers convicted or accused of war crimes in Afghanistan or Iraq.[336] In 2020 he pardoned four Blackwater mercenaries convicted of killing Iraqi civilians in the 2007 Nisour Square massacre.[337] In December 2020, he pardoned Charles Kushner, father of Trump's son-in-law Jared Kushner; the elder Kushner previously pleaded guilty to witness tampering, tax evasion, and conducting illegal campaign donations.[327]
",2
1162,"Trump pardoned or commuted the sentences for five people convicted as a result of investigations into Russian interference in the 2016 presidential elections.[327][337] In July 2020, Trump commuted the 40-month sentence for his friend and adviser Roger Stone, who had been soon due to report to prison for witness tampering, lying to Congress, and obstructing congressional investigations.[338] In November 2020, Trump pardoned his former National Security Advisor Michael Flynn, then in December 2020, Trump pardoned his 2016 campaign adviser George Papadopoulos and lawyer Alex van der Zwaan; all three had pleaded guilty of lying to federal officials during the investigations.[337] Also in December 2020, Trump pardoned Stone and his 2016 campaign chairman Paul Manafort; the latter had pleaded guilty of conspiracy to obstruct justice and was convicted of fraud.[327]
",2
1163,"In his last full day in office, Trump granted 143 pardons and commutations. He pardoned his former chief strategist Steve Bannon; Trump fundraiser Elliott Broidy; and former Republican congressmen Rick Renzi, Robert Hayes, and Randall ""Duke"" Cunningham, and commuted the sentences of dozens of people including former Detroit mayor Kwame Kilpatrick and sports gambler Billy Walters; the latter had paid tens of thousands of dollars to former Trump attorney John M. Dowd to plead his case with Trump.[339]
",2
1164,"On June 1, 2020, federal law enforcement officials used batons, rubber bullets, pepper spray projectiles,[340] stun grenades, and smoke to remove a largely peaceful crowd of protesters from Lafayette Square, outside the White House. The removal had been ordered by Attorney General William Barr.[340][341] Trump then walked to St. John's Episcopal Church, where protesters had set a small fire the night before.[342] He posed for photographs holding a Bible, with Cabinet members and other officials later joining him in photos.[340][341][343]
",2
1165,"Religious leaders condemned the treatment of protesters and the photo opportunity itself.[344][345] Many retired military leaders and defense officials condemned Trump's proposal to use the U.S. military against the protesters.[345][346] The chairman of the Joint Chiefs of Staff, General Mark A. Milley, later apologized for accompanying Trump on the walk and thereby ""creat[ing] the perception of the military involved in domestic politics.""[347]
",2
1166,"Trump's proposed immigration policies were a topic of bitter and contentious debate during the campaign. He promised to build a wall on the Mexico–United States border to restrict illegal movement and vowed Mexico would pay for it.[348] He pledged to deport millions of illegal immigrants residing in the United States,[349] and criticized birthright citizenship for incentivizing ""anchor babies.""[350] As president, he frequently described illegal immigration as an ""invasion"" and conflated immigrants with the criminal gang MS-13, though research shows undocumented immigrants have a lower crime rate than native-born Americans.[351]
",2
1167,"Trump has attempted to drastically escalate immigration enforcement, including harsher immigration enforcement policies against asylum seekers from Central America than any modern U.S. president.[352][353] This was accompanied by the Trump administration's mandating in 2018 that immigration judges must complete 700 cases a year to be evaluated as performing satisfactorily.[354] Under Trump, migrant apprehensions at the U.S.–Mexico border rose to their highest level in 12 years, but deportations remained below the record highs of fiscal years 2012–2014.[355]
",2
1168,"From 2018 onwards, Trump deployed nearly 6,000 troops to the U.S.–Mexico border,[356] to stop most Central American migrants from seeking U.S. asylum, and from 2020 used the public charge rule to restrict immigrants using government benefits from getting permanent residency via green cards.[357] Trump has reduced the number of refugees admitted into the U.S. to record lows. When Trump took office, the annual limit was 110,000; Trump set a limit of 18,000 in the 2020 fiscal year and 15,000 in the 2021 fiscal year.[358][359] Additional restrictions implemented by the Trump administration caused significant bottlenecks in processing refugee applications, resulting in fewer refugees accepted compared to the allowed limits.[360]
",2
1169,"Following the 2015 San Bernardino attack, Trump proposed to ban Muslim foreigners from entering the United States until stronger vetting systems could be implemented.[361] He later reframed the proposed ban to apply to countries with a ""proven history of terrorism.""[362]
",2
1170,"On January 27, 2017, Trump signed Executive Order 13769, which suspended admission of refugees for 120 days and denied entry to citizens of Iraq, Iran, Libya, Somalia, Sudan, Syria, and Yemen for 90 days, citing security concerns. The order took effect immediately and without warning.[363] Confusion and protests caused chaos at airports.[364] Multiple legal challenges were filed against the order, and a federal judge blocked its implementation nationwide.[365] On March 6, Trump issued a revised order, which excluded Iraq and gave other exemptions, but was again blocked by federal judges in three states.[366] In a decision in June 2017, the Supreme Court ruled that the ban could be enforced on visitors who lack a ""credible claim of a bona fide relationship with a person or entity in the United States.""[367]
",2
1171,"The temporary order was replaced by Presidential Proclamation 9645 on September 24, 2017, which permanently restricts travel from the originally targeted countries except Iraq and Sudan, and further bans travelers from North Korea and Chad, along with certain Venezuelan officials.[368] After lower courts partially blocked the new restrictions, the Supreme Court allowed the September version to go into full effect on December 4, 2017,[369] and ultimately upheld the travel ban in a June 2019 ruling.[370]
",2
1172,"The Trump administration separated more than 5,400 children of migrant families from their parents at the U.S.–Mexico border while attempting to enter the U.S, a sharp increase in the number of family separations at the border starting from the summer of 2017.[371][372] In April 2018, the Trump administration announced a ""zero tolerance"" policy whereby every adult suspected of illegal entry would be criminally prosecuted.[373] This resulted in family separations, as the migrant adults were put in criminal detention for prosecution, while their children were separated as unaccompanied alien minors.[374] Administration officials described the policy as a way to deter illegal immigration.[375]
",2
1173,"The policy of family separations was unprecedented in previous administrations and sparked public outrage.[375][376] Trump falsely asserted that his administration was merely following the law, blaming Democrats, despite the separations being his administration's policy.[377][378][379]
",2
1174,"Although Trump originally argued that the separations could not be stopped by an executive order, he proceeded to sign an executive order on June 20, 2018, mandating that migrant families be detained together, unless the administration judged that doing so would harm the child.[380][381] On June 26, 2018, a federal judge concluded that the Trump administration had ""no system in place to keep track of"" the separated children, nor any effective measures for family communication and reunification;[382] the judge ordered for the families to be reunited, and family separations stopped, except in the cases where the parent(s) are judged unfit to take care of the child, or if there is parental approval.[383] Despite the federal court order, the Trump administration continued to practice family separations, with more than a thousand migrant children separated.[372]
",2
1175,"Trump's administration significantly increased the rates of migrant detentions and deportations compared to the Obama administration.[384]
",2
1176,"The Department of Homeland Security Office of Inspector General inspections of migrant detention centers in 2018 and 2019 found that U.S. Customs and Border Protection (CBP) ""in many instances"" violated federal guidelines for detaining migrant children and that migrants were detained for prolonged periods under dangerous conditions failing federal standards, enduring dangerous overcrowding and poor hygiene and food.[385][386][387] CBP Commissioner Kevin McAleenan said in 2019 that there was a ""border security and a humanitarian crisis"" and that the immigration system was at a ""breaking point.""[388]
",2
1177,"On December 22, 2018, the federal government was partially shut down after Trump declared that any funding extension must include $5.6 billion in federal funds for a U.S.–Mexico border wall to partly fulfill his campaign promise.[389] The shutdown was caused by a lapse in funding for nine federal departments, affecting about one-fourth of federal government activities.[390]
",2
1178,"As a result of the shutdown, about 380,000 government employees were furloughed and 420,000 government employees worked without pay.[391] According to a CBO estimate, the shutdown resulted in a permanent loss of $3 billion to the U.S. economy.[392] About half of Americans blamed Trump for the shutdown, and Trump's approval ratings dropped.[393]
",2
1179,"On January 25, 2019, Congress unanimously approved a temporary funding bill that provided no funds for the wall but would provide delayed paychecks to government workers. Trump signed the bill that day, ending the shutdown at 35 days. It was the longest U.S. government shutdown in history.[394][395]
",2
1180,"Since the government funding was temporary, another shutdown loomed. On February 14, 2019, Congress approved a funding bill that included $1.375 billion for 55 miles of border fences, in lieu of Trump's intended wall.[396] Trump signed the bill the next day.[397]
",2
1181,"On February 15, 2019, after Trump received from Congress only $1.375 billion for border fencing after demanding $5.7 billion for the Trump wall, he declared a National Emergency Concerning the Southern Border of the United States in hopes of getting another $6.7 billion without congressional approval, using funds for military construction, drug interdiction, and money from the Treasury.[397] In doing so, Trump acknowledged that he ""didn't need to"" declare a national emergency, but he ""would rather do it much faster.""[397]
",2
1182,"Congress twice passed resolutions to block Trump's national emergency declarations, but Trump vetoed both and there were not enough votes in Congress for a veto override.[398][399][400] Trump's decision to divert other government funding to fund the wall resulted in legal challenges. In July 2019, the Supreme Court allowed Trump to use $2.5 billion (originally meant for anti-drug programs) from the Department of Defense to build the Trump wall.[401][402] In December 2019, a federal judge stopped the Trump administration from using $3.6 billion of military construction funds for the Trump wall.[402]
",2
1183,"As a presidential candidate, Trump promised to construct a wall along the U.S.–Mexico border to prevent migration.[403] In 2017, the border had 654 miles of primary fencing, 37 miles of secondary fencing and 14 miles of tertiary fencing.[404] Trump's target, from 2015 to 2017, was 1,000 miles of wall.[405] The Trump administration set a target of 450 miles of new or renovated barriers by December 2020, with an ultimate goal of 509 miles of new or renovated barriers by August 2021.[406] Even into 2020, Trump repeatedly provided false assertions that Mexico was paying for the Trump wall, although American taxpayers were footing the bill from funds being diverted from the U.S. Department of Defense.[407]
",2
1184,"In October 2018, the administration revealed two miles of replacement fences made of steel posts, which it called the first section of Trump's 'wall', although earlier that year Border Patrol had said the project was unrelated to the Trump wall and was long planned (dating to 2009).[408][409] In December 2018 and January 2019, Trump tweeted out a design of a steel fence, and a picture of a fence, while declaring ""the wall is coming.""[405]
",2
1185,"By November 2019, the Trump administration had replaced around 78 miles of fences made of bollards along the border.[410][411] The administration in November 2019 said it had ""just started breaking ground"" to build new barriers in areas where no structure existed.[410] By May 2020, the Trump administration had replaced 172 miles of dilapidated or outdated design barriers, and constructed 15 miles of new border barriers.[412]
",2
1186,"Trump described himself as a ""nationalist""[413] and his foreign policy as ""America First.""[414][415] He espoused isolationist, non-interventionist, and protectionist views.[416][417] His foreign policy was marked by praise and support of populist, neo-nationalist and authoritarian governments.[418] Hallmarks of foreign relations during Trump's tenure included unpredictability and uncertainty,[415] a lack of a consistent foreign policy,[419] and strained and sometimes antagonistic relationships with the U.S.'s European allies.[420]
",2
1187,"As a candidate, Trump questioned the need for NATO;[416] and as president publicly criticized NATO and the U.S.'s NATO allies, and privately suggested on multiple occasions that the United States should withdraw from NATO.[421]
",2
1188,"Trump actively supported the Saudi Arabian-led intervention in Yemen against the Houthis and signed a $110 billion agreement to sell arms to Saudi Arabia.[422][423] As allies in the conflict with Iran,[424] Trump approved the deployment of additional U.S. troops to Saudi Arabia and the United Arab Emirates following the 2019 attack on Saudi oil facilities which the United States has blamed on Iran.[425]
",2
1189,"U.S. troop numbers in Afghanistan increased from 8,500 to 14,000, as of January 2017[update],[426] reversing his pre-election position critical of further involvement in Afghanistan.[427] In February 2020, the Trump administration signed a conditional peace agreement with the Taliban, which calls for the withdrawal of foreign troops in 14 months if the Taliban uphold the terms of the agreement.[428][429]
",2
1190,"Trump supported many of the policies of Israeli Prime Minister Benjamin Netanyahu.[430] Under Trump, the U.S. recognized Jerusalem as the capital of Israel in 2017,[431] and recognized Israel's annexation of the Golan Heights.[432] These actions received international condemnation, including from the United Nations General Assembly, the European Union and the Arab League.[433][434]
",2
1191,"Trump ordered missile strikes in April 2017 and in April 2018 against the Assad regime in Syria, in retaliation for the Khan Shaykhun and Douma chemical attacks, respectively.[435][436]
",2
1192,"In December 2018, Trump declared ""we have won against ISIS,"" contradicting Department of Defense assessments, and ordered the withdrawal of all troops from Syria.[437][438] The next day, Mattis resigned in protest, calling his decision an abandonment of the U.S.'s Kurdish allies who played a key role in fighting ISIS.[439] One week after his announcement, Trump said he would not approve any extension of the American deployment in Syria.[440] In January 2019, national security advisor John Bolton announced America would remain in Syria until ISIS is eradicated and Turkey guarantees it will not strike the Kurds.[441]
",2
1193,"In October 2019, after Trump spoke to Turkish president Recep Tayyip Erdoğan, the White House acknowledged Turkey would carry out a military offensive into northern Syria, and U.S. troops in northern Syria were withdrawn from the area, and said that ISIS fighters captured by the U.S. in the area would be Turkey's responsibility.[442] As a result, Turkey launched an invasion, attacking and displacing American-allied Kurds in the area. Later that month, the U.S. House of Representatives, in a rare bipartisan vote of 354 to 60, condemned Trump's withdrawal of U.S. troops from Syria, for ""abandoning U.S. allies, undermining the struggle against ISIS, and spurring a humanitarian catastrophe.""[443][444]
",2
1194,"In May 2018, Trump announced the U.S.' unilateral departure from the Joint Comprehensive Plan of Action (JCPOA), a nuclear deal negotiated with the U.S., Iran, and five other world powers in 2015.[445] After withdrawing from the agreement, the Trump administration applied a policy of ""maximum pressure"" on Iran via economic sanctions, without support of other parties to the deal.[446][447] The Trump State Department certified Iran's compliance with the deal in July 2017, but Iran began breaching its terms in May 2020, and by September the IAEA reported the country had ten times the amount of enriched uranium allowed under the deal.[448][449][450] In  mid-2020 the United States attempted to ""snap back"" pre-deal sanctions by asserting to the UN Security Council that it remained a participant in the deal, without significant international support.[451]
",2
1195,"Following Iranian missile tests in January 2017, the Trump administration sanctioned 25 Iranian individuals and entities.[452][453][454] In August 2017, Trump signed legislation imposing additional sanctions against Iran, Russia, and North Korea.[455]
",2
1196,"In January 2020, Trump ordered a U.S. airstrike that killed Iranian general and Quds Force commander Qasem Soleimani, Iraqi Popular Mobilization Forces commander Abu Mahdi al-Muhandis, and eight other people.[456] Several days later, Iran retaliated with airstrikes against Al Asad Air Base in Iraq; more than a hundred U.S. troops suffered traumatic brain injuries.[457] Trump publicly threatened to attack Iranian cultural sites, or react ""in a disproportionate manner"" if Iran retaliated.[458]
",2
1197,"Before and during his presidency, Trump repeatedly accused China of taking unfair advantage of the U.S.[459] During his presidency, Trump launched a trade war against China, sanctioned Huawei for its alleged ties to Iran,[460] significantly increased visa restrictions on Chinese students and scholars,[461] and classified China as a ""currency manipulator.""[462] Trump also juxtaposed verbal attacks on China with praise of Chinese Communist Party leader Xi Jinping,[463] which was attributed to trade war negotiations with the leader.[464][465] After initially praising China for its handling of the COVID-19 pandemic,[466] he began a campaign of criticism over its response starting in March.[467]
",2
1198,"Trump said he resisted punishing China for its human rights abuses against ethnic minorities in the northwestern Xinjiang region for fear of jeopardizing trade negotiations.[468] In July 2020, the Trump administration imposed sanctions and visa restrictions against senior Chinese officials, in response to expanded mass detention camps holding more than a million of the country's Uyghur Muslim ethnic minority.[469]
",2
1199,"In 2017, when North Korea's nuclear weapons were increasingly seen as a serious threat,[470] Trump escalated his rhetoric, warning that North Korean aggression would be met with ""fire and fury like the world has never seen.""[471][472] In 2017, Trump declared that he wanted North Korea's ""complete denuclearization,"" and engaged in name-calling with leader Kim Jong-un.[471][473] After this period of tension, Trump and Kim exchanged at least 27 letters in which the two men described a warm personal friendship.[474][475]
",2
1200,"At Kim's suggestion,[476] Trump met Kim three times: in Singapore in 2018, in Hanoi in 2019, and in the Korean Demilitarized Zone in 2019.[477] Trump became the first sitting U.S. president to meet a North Korean leader or to set foot in North Korea.[477] Trump also lifted some U.S. sanctions against North Korea.[478] However, no denuclearization agreement was reached,[479] and talks in October 2019 broke down after one day.[480] North Korea continued to build up its arsenal of nuclear weapons and ballistic missiles.[481][482]
",2
1201,"Trump has repeatedly praised and rarely criticized Russian president Vladimir Putin,[483][484] but has opposed some actions of the Russian government.[485][486] The Trump administration lifted U.S. sanctions imposed on Russia after its 2014 annexation of Crimea.[487][488] Trump also supported a potential return of Russia to the G7,[489] and did not confront Putin over its alleged bounties against American soldiers in Afghanistan.[490]
",2
1202,"Trump withdrew the U.S. from the Intermediate-Range Nuclear Forces Treaty, citing alleged Russian non-compliance.[491][492] After he met Putin at the Helsinki Summit in July 2018, Trump drew bipartisan criticism for accepting Putin's denial of Russian interference in the 2016 presidential election, rather than accepting the findings of U.S. intelligence agencies.[493][494][495]
",2
1203,"Trump's Cabinet nominations included U.S. senator from Alabama Jeff Sessions as Attorney General,[496] banker Steve Mnuchin as Treasury Secretary,[497] retired Marine Corps general James Mattis as Defense Secretary,[498] and ExxonMobil CEO Rex Tillerson as Secretary of State.[499] Trump also brought on board politicians who had opposed him during the presidential campaign, such as neurosurgeon Ben Carson as Secretary of Housing and Urban Development,[500] and South Carolina governor Nikki Haley as Ambassador to the United Nations.[501]",2
1204,"The Trump administration had a high turnover of personnel, particularly among White House staff. By the end of Trump's first year in office, 34 percent of his original staff had resigned, been fired, or been reassigned.[502] As of early July 2018[update], 61 percent of Trump's senior aides had left[503] and 141 staffers had left in the previous year.[504] Both figures set a record for recent presidents – more change in the first 13 months than his four immediate predecessors saw in their first two years.[505] Notable early departures included National Security Advisor Michael Flynn (after just 25 days in office), and Press Secretary Sean Spicer.[505] Close personal aides to Trump including Steve Bannon, Hope Hicks, John McEntee, and Keith Schiller quit or were forced out.[506] Some, like Hicks and McEntee, later returned to the White House in different posts.[507] Trump publicly disparaged several of his former top officials, calling them incompetent, stupid, or crazy.[508]
",2
1205,"Trump had four White House chiefs of staff, marginalizing or pushing out several.[509] Reince Priebus was replaced after seven months by retired Marine general John F. Kelly.[510] Kelly resigned in December 2018 after a tumultuous tenure in which his influence waned, and Trump subsequently disparaged him.[511] Kelly was succeeded by Mick Mulvaney as acting chief of staff; he was replaced in March 2020 by Mark Meadows.[509]
",2
1206,"On May 9, 2017, Trump dismissed FBI director James Comey. He first attributed this action to recommendations from Attorney General Jeff Sessions and Deputy AG Rod Rosenstein, which criticized Comey's conduct in the investigation about Hillary Clinton's emails.[512] A few days later, Trump said he was concerned with the ongoing Trump-Russia investigations, and that he had intended to fire Comey earlier, regardless of DOJ advice.[513][514] According to a Comey memo of a private conversation in February, Trump said he ""hoped"" Comey would drop the investigation into National Security Advisor Michael Flynn.[515]
In March and April, Trump told Comey the ongoing suspicions formed a ""cloud"" impairing his presidency,[516] and asked him to publicly state that he was not personally under investigation.[517]
",2
1207,"Two of Trump's 15 original Cabinet members were gone within 15 months: Health and Human Services Secretary Tom Price was forced to resign in September 2017 due to excessive use of private charter jets and military aircraft, and Trump replaced Tillerson as Secretary of State with Mike Pompeo in March 2018 over disagreements on foreign policy.[518][506] In 2018, EPA Administrator Scott Pruitt and Interior Secretary Ryan Zinke resigned amid multiple investigations into their conduct.[519][520]
",2
1208,"Trump was slow to appoint second-tier officials in the executive branch, saying many of the positions are unnecessary. In October 2017, there were still hundreds of sub-cabinet positions without a nominee.[521] By January 8, 2019, of 706 key positions, 433 had been filled (61 percent) and Trump had no nominee for 264 (37 percent).[522]
",2
1209,"Trump appointed more than 200 federal judges who were confirmed by the Senate.[523][524] Senate Republicans, led by Senate Majority Leader Mitch McConnell, rapidly confirmed Trump's judicial appointees, usually against unified Democratic opposition, shifting the federal judiciary to the right.[524][525] The appointees were overwhelmingly white men and younger on average than the appointees of Trump's predecessors.[525] Many are affiliated with the Federalist Society.[525][526]
",2
1210,"Trump made three nominations to the Supreme Court: Neil Gorsuch, Brett Kavanaugh, and Amy Coney Barrett.[527] Gorsuch was confirmed in 2017 in a mostly party-line vote of 54–45, after Republicans invoked the ""nuclear option"" (a historic change to Senate rules removing the 60-vote threshold for advancing Supreme Court nominations) to defeat a Democratic filibuster.[528] Trump's predecessor Obama had nominated Merrick Garland in 2016 to fill the vacancy, left by the death of Antonin Scalia, but Senate Republicans under McConnell refused to consider the nomination in the last year of Obama's presidency, angering Democrats.[528] Trump nominated Kavanaugh in 2018 to replace retiring Justice Anthony Kennedy; the Senate confirmed Kavanaugh in a mostly party-line vote of 50–48, after a bitter confirmation battle centered on Christine Blasey Ford's allegation that Kavanaugh had attempted to rape her when they were teenagers, which Kavanaugh denied.[529] In 2020, weeks before the elections, Trump nominated Amy Coney Barrett to fill the vacancy left by the death of Justice Ruth Bader Ginsburg.[527] On October 26, 2020, the Senate voted 52–48 to confirm her nomination.[530]
",2
1211,"As president, Trump disparaged courts and judges whom he disagreed with, often in personal terms, and questioned the judiciary's constitutional authority. Trump's attacks on the courts have drawn rebukes from observers, including sitting federal judges, who are concerned about the effect of Trump's statements on the judicial independence and public confidence in the judiciary.[531][532][533]
",2
1212,"In December 2019, COVID-19 erupted in Wuhan, China; the SARS-CoV-2 virus spread worldwide within weeks.[534][535] The first confirmed case in the U.S. was reported on January 20, 2020.[536] The outbreak was officially declared a public health emergency by Health and Human Services Secretary Alex Azar on January 31, 2020.[537]
",2
1213,"Trump's public statements on COVID-19 were at odds with his private statements. In February 2020 Trump publicly asserted that the outbreak in the U.S. was less deadly than influenza, was ""very much under control,"" and would soon be over.[538] At the same time he acknowledged the opposite in a private conversation with Bob Woodward. In March 2020, Trump privately told Woodward that he was deliberately ""playing it down"" in public so as not to create panic.[539][540]
",2
1214,"Trump was slow to address the spread of the disease, initially dismissing the imminent threat and ignoring persistent public health warnings and calls for action from health officials within his administration and Secretary Azar.[541][542] Instead, throughout January and February he focused on economic and political considerations of the outbreak.[543] By mid-March, most global financial markets had severely contracted in response to the emerging pandemic.[544] Trump continued to claim that a vaccine was months away, although HHS and Centers for Disease Control and Prevention (CDC) officials had repeatedly told him that vaccine development would take 12–18 months.[545] Trump also falsely claimed that ""anybody that wants a test can get a test,"" despite the availability of tests being severely limited.[546]
",2
1215,"On March 6, Trump signed the Coronavirus Preparedness and Response Supplemental Appropriations Act into law, which provided $8.3 billion in emergency funding for federal agencies.[547] On March 11, the World Health Organization (WHO) recognized the spread of COVID-19 as a pandemic,[534] and Trump announced partial travel restrictions for most of Europe, effective March 13.[548] That same day, he gave his first serious assessment of the virus in a nationwide Oval Office address, calling the outbreak ""horrible"" but ""a temporary moment"" and saying there was no financial crisis.[549] On March 13, he declared a national emergency, freeing up federal resources.[550]
",2
1216,"In September 2019, the Trump administration terminated United States Agency for International Development's PREDICT program, a $200 million epidemiological research program initiated in 2009 to provide early warning of pandemics abroad.[551][552] The program trained scientists in sixty foreign laboratories to detect and respond to viruses that have the potential to cause pandemics. One such laboratory was the Wuhan lab that first identified the virus that causes COVID-19. After revival in April 2020, the program was given two 6-month extensions to help fight COVID-19 in the U.S. and other countries.[553][554]
",2
1217,"On April 22, Trump signed an executive order restricting some forms of immigration to the United States.[555] In late spring and early summer, with infections and death counts continuing to rise, he adopted a strategy of blaming the states for the growing pandemic, rather than accepting that his initial assessments of the course of the pandemic were overly-optimistic or his failure to provide presidential leadership.[556]
",2
1218,"Trump established the White House Coronavirus Task Force on January 29, 2020.[557] Beginning in mid-March, Trump held a daily task force press conference, joined by medical experts and other administration officials,[558] sometimes disagreeing with them by promoting unproven treatments.[559] Trump was the main speaker at the briefings, where he praised his own response to the pandemic, frequently criticized rival presidential candidate Joe Biden, and denounced the press.[558][560] On March 16, he acknowledged for the first time that the pandemic was not under control and that months of disruption to daily lives and a recession might occur.[561] His repeated use of the terms ""Chinese virus"" and ""China virus"" to describe COVID-19 drew criticism from health experts.[562][563][564]
",2
1219,"By early April, as the pandemic worsened and amid criticism of his administration's response, Trump refused to admit any mistakes in his handling of the outbreak, instead blaming the media, Democratic state governors, the previous administration, China, and the WHO.[565] By mid-April 2020, some national news agencies began limiting live coverage of his daily press briefings, with The Washington Post reporting that ""propagandistic and false statements from Trump alternate with newsworthy pronouncements from members of his White House Coronavirus Task Force, particularly coronavirus response coordinator Deborah Birx and National Institute of Allergy and Infectious Diseases Director Anthony S. Fauci.""[566] The daily coronavirus task force briefings ended in late April, after a briefing at which Trump suggested the dangerous idea of injecting a disinfectant to treat COVID-19;[567] the comment was widely condemned by medical professionals.[568][569]
",2
1220,"In early May, Trump proposed the phase-out of the coronavirus task force and its replacement with another group centered on reopening the economy. Amid a backlash, Trump said the task force would ""indefinitely"" continue.[570] By the end of May, the coronavirus task force's meetings were sharply reduced.[571]
",2
1221,"Prior to the pandemic, Trump criticized the WHO and other international bodies, which he asserted were taking advantage of U.S. aid.[572] His administration's proposed 2021 federal budget, released in February, proposed reducing WHO funding by more than half.[572] In May and April, Trump accused the WHO of ""severely mismanaging and covering up the spread of the coronavirus"" and alleged without evidence that the organization was under Chinese control and had enabled the Chinese government's concealment of the origins of the pandemic.[572][573][574] He then announced that he was withdrawing funding for the organization.[572] Trump's criticisms and actions regarding the WHO were seen as attempts to distract attention from his own mishandling of the pandemic.[572][575][576] In July 2020, Trump announced the formal withdrawal of the United States from the WHO effective July 2021.[573][574] The decision was widely condemned by health and government officials as ""short-sighted,"" ""senseless,"" and ""dangerous.""[573][574]
",2
1222,"In June and July, Trump said several times that the U.S. would have fewer cases of coronavirus if it did less testing, that having a large number of reported cases ""makes us look bad.""[577][578] The CDC guideline at the time was that any person exposed to the virus should be ""quickly identified and tested"" even if they are not showing symptoms, because asymptomatic people can still spread the virus.[579][580] In August 2020, however, the CDC quietly lowered its recommendation for testing, advising that people who have been exposed to the virus, but are not showing symptoms, ""do not necessarily need a test."" The change in guidelines was made by HHS political appointees under Trump administration pressure, against the wishes of CDC scientists.[581][582][583] The day after this political interference was reported, the testing guideline was changed back to its original recommendation, stressing that anyone who has been in contact with an infected person should be tested.[583]
",2
1223,"In April 2020, Republican-connected groups organized anti-lockdown protests against the measures state governments were taking to combat the pandemic;[584][585] Trump encouraged the protests on Twitter,[586] even though the targeted states did not meet the Trump administration's own guidelines for reopening.[587] In April 2020, he first supported, then later criticized, Georgia Governor Brian Kemp's plan to reopen some nonessential businesses.[588] Throughout the spring he increasingly pushed for ending the restrictions as a way to reverse the damage to the country's economy.[589]
",2
1224,"Trump often refused to wear a face mask at public events, contrary to his own administration's April 2020 guidance that Americans should wear masks in public[590] and despite nearly unanimous medical consensus that masks are important to preventing the spread of the virus.[591] By June, Trump had said masks were a ""double-edged sword""; ridiculed Biden for wearing masks; continually emphasized that mask-wearing was optional; and suggested that wearing a mask was a political statement against him personally.[591] Trump's contradiction of medical recommendations weakened national efforts to mitigate the pandemic.[590][591]
",2
1225,"Despite record numbers of COVID-19 cases in the U.S. from mid-June onward and an increasing percentage of positive test results, Trump continued to mostly downplay the pandemic, including his false claim in early July 2020 that 99 percent of COVID-19 cases are ""totally harmless.""[592][593] He also began insisting that all states should open schools to in-person education in the fall despite a July spike in reported cases.[594]
",2
1226,"Trump repeatedly pressured federal health agencies to take actions he favored,[581] such as approving unproven treatments[595][596] or speeding up the approval of vaccines.[596] Trump administration political appointees at HHS sought to control CDC communications to the public that undermined Trump's claims that the pandemic was under control. CDC resisted many of the changes, but increasingly allowed HHS personnel to review articles and suggest changes before publication.[597][598] Trump alleged without evidence that FDA scientists were part of a ""deep state"" opposing him, and delaying approval of vaccines and treatments to hurt him politically.[599]
",2
1227,"On October 2, 2020, Trump announced that he had tested positive for COVID-19.[600][601] He was treated at Walter Reed National Military Medical Center for a severe case of the disease while continuing to downplay the virus. His wife, son Barron, as well as numerous staff members and visitors also became infected.
[602][42]
",2
1228,"By July 2020, Trump's handling of the COVID-19 pandemic became a major issue for the 2020 presidential election.[603] Democratic challenger Joe Biden sought to make the election a referendum on Trump's performance on the COVID-19 pandemic and the economy.[604] Polls indicated voters blamed Trump for his pandemic response[603] and disbelieved his rhetoric concerning the virus, with an Ipsos/ABC News poll indicating 65 percent of Americans disapproving of his pandemic response.[605] In the final months of the campaign, Trump repeatedly claimed that the U.S. was ""rounding the turn"" in managing the pandemic, despite increasing numbers of reported cases and deaths.[606] A few days before the November 3 election, the United States reported more than 100,000 cases in a single day for the first time.[607]
",2
1229,"The Crossfire Hurricane FBI investigation into possible links between Russia and the Trump campaign was launched in mid-2016 during the campaign season. After he assumed the presidency, Trump was the subject of increasing Justice Department and congressional scrutiny, with investigations covering his election campaign, transition and inauguration, actions taken during his presidency, along with his private businesses, personal taxes, and charitable foundation.[55] There were 30 investigations of Trump, including ten federal criminal investigations, eight state and local investigations, and twelve Congressional investigations.[608]
",2
1230,"During the 2016 presidential election campaign, American Media, Inc. (AMI), the parent company of the National Enquirer,[609] and a company set up by Trump's attorney Michael Cohen paid Playboy model Karen McDougal and adult film actress Stormy Daniels for keeping silent about their alleged affairs with Trump between 2006 and 2007.[610] Cohen pleaded guilty in 2018 to breaking campaign finance laws, saying he had arranged both payments at the direction of Trump to influence the presidential election.[611] Trump denied the affairs and claimed he was not aware of Cohen's payment to Daniels, but he reimbursed him in 2017.[612][613] Federal prosecutors asserted that Trump had been involved in discussions regarding non-disclosure payments as early as 2014.[614] Court documents showed that the FBI believed Trump was directly involved in the payment to Daniels, based on calls he had with Cohen in October 2016.[615][616] Federal prosecutors closed the investigation,[617] but the Manhattan District Attorney subpoenaed the Trump Organization and AMI for records related to the payments[618] and Trump and the Trump Organization for eight years of tax returns.[619]
",2
1231,"In January 2017, American intelligence agencies – the CIA, the FBI, and the NSA, represented by the Director of National Intelligence – jointly stated with ""high confidence"" that the Russian government interfered in the 2016 presidential election to favor the election of Trump.[620][621] In March 2017, FBI Director James Comey told Congress ""the FBI, as part of our counterintelligence mission, is investigating the Russian government's efforts to interfere in the 2016 presidential election. That includes investigating the nature of any links between individuals associated with the Trump campaign and the Russian government, and whether there was any coordination between the campaign and Russia's efforts.""[622]
",2
1232,"The connections between Trump associates and Russia were widely reported by the press.[623][624] One of Trump's campaign managers, Paul Manafort, worked from December 2004 to February 2010 to help pro-Russian politician Viktor Yanukovych win the Ukrainian presidency.[625] Other Trump associates, including former National Security Advisor Michael T. Flynn and political consultant Roger Stone, were connected to Russian officials.[626][627] Russian agents were overheard during the campaign saying they could use Manafort and Flynn to influence Trump.[628] Members of Trump's campaign and later his White House staff, particularly Flynn, were in contact with Russian officials both before and after the November election.[629][630] On December 29, 2016, Flynn talked with Russian Ambassador Sergey Kislyak about sanctions that were imposed that same day; Flynn later resigned in the midst of controversy over whether he misled Pence.[631] Trump told Kislyak and Sergei Lavrov in May 2017 he was unconcerned about Russian interference in U.S. elections.[632]
",2
1233,"Trump and his allies promoted a conspiracy theory that Ukraine, rather than Russia, interfered in the 2016 election – which was also promoted by Russia to frame Ukraine.[633] After the Democratic National Committee was hacked, Trump first claimed it withheld ""its server"" from the FBI (in actuality there were more than 140 servers, of which digital copies were given to the FBI); second that CrowdStrike, the company which investigated the servers, was Ukraine-based and Ukrainian-owned (in actuality, CrowdStrike is U.S.-based, with the largest owners being American companies); and third that ""the server"" was hidden in Ukraine. Members of the Trump administration spoke out against the conspiracy theories.[634]
",2
1234,"After Trump fired FBI director James Comey in May 2017, the FBI opened a counterintelligence investigation into Trump's personal and business dealings with Russia. It was discontinued after deputy attorney general Rod Rosenstein gave the bureau the false impression that the incipient Special Counsel investigation would pursue it.[635]
",2
1235,"On May 17, 2017, Deputy Attorney General Rod Rosenstein appointed Robert Mueller, a former director of the FBI, to serve as special counsel for the Department of Justice (DOJ) investigating ""links and/or coordination"" between the Russian government and Trump's campaign and any matters directly arising from the investigation, taking over the existing ""Crossfire Hurricane"" FBI investigation.[636] The special counsel also investigated whether Trump's dismissal of James Comey as FBI director constituted obstruction of justice[637] and the Trump campaign's possible ties to Saudi Arabia, the United Arab Emirates, Turkey, Qatar, Israel, and China.[638]
",2
1236,"Trump denied collusion between his campaign and the Russian government.[639] He sought to fire Mueller and shut down the investigation multiple times but backed down after his staff objected or after changing his mind.[640] He bemoaned the recusal of his first Attorney General Jeff Sessions regarding Russia matters, and believed Sessions should have stopped the investigation.[641]
",2
1237,"On March 22, 2019, Mueller concluded his investigation and gave his report to Attorney General William Barr.[642] Two days later, Barr sent a letter to Congress purporting to summarize the report's main conclusions. A federal court, as well as Mueller himself, said Barr had mischaracterized the investigation's conclusions, confusing the public.[643][644][645] Trump repeatedly and falsely claimed that the investigation ""exonerated"" him; in fact, the Mueller report expressly stated that it did not exonerate Trump.[646][647]
",2
1238,"A redacted version of the report was publicly released on April 18, 2019. The first volume found that Russia interfered in 2016 to favor Trump's candidacy and hinder Clinton's.[648] Despite ""numerous links between the Russian government and the Trump campaign,"" the prevailing evidence ""did not establish"" that Trump campaign members conspired or coordinated with Russian interference.[649][650] The report revealed sweeping Russian interference[650] and detailed how Trump and his campaign welcomed and encouraged it, believing they would politically benefit.[651][652][653]
",2
1239,"The Mueller report's second volume set forth ten ""episodes"" of potential obstruction of justice by Trump, but opted not to make any ""traditional prosecutorial judgment"" on whether Trump broke the law, suggesting that Congress should make such a determination.[654][655] Investigators decided they could not ""apply an approach that could potentially result in a judgment that the President committed crimes"" as an Office of Legal Counsel opinion stated that a sitting president could not be indicted, and investigators would not accuse him of a crime when he cannot clear his name in court.[656] The report concluded that Congress, having the authority to take action against a president for wrongdoing, ""may apply the obstruction laws.""[657] The House of Representatives subsequently launched an impeachment inquiry following the Trump–Ukraine scandal, but did not pursue an article of impeachment related to the Mueller investigation.[658][659]
",2
1240,"In August 2018, former Trump campaign chairman Paul Manafort was convicted on eight felony counts of false tax filing and bank fraud.[660] Trump said he felt very badly for Manafort and praised him for resisting the pressure to cooperate with prosecutors. According to Rudy Giuliani, Trump's personal attorney, Trump had sought advice about pardoning Manafort but was counseled against it.[661]
",2
1241,"In November 2018, Trump's former attorney Michael Cohen pleaded guilty to lying to Congress about Trump's 2016 attempts to reach a deal with Russia to build a Trump Tower in Moscow. Cohen said he had made the false statements on behalf of Trump, who was identified as ""Individual-1"" in the court documents.[662]
",2
1242,"Five Trump associates pleaded guilty or were convicted in connection with Mueller's investigation and related cases: Manafort, Cohen, deputy campaign manager Rick Gates, foreign policy advisor George Papadopoulos, Michael Flynn.[663][664]
",2
1243,"In February 2020, Trump campaign adviser Roger Stone was sentenced to 40 months in prison for lying to Congress and witness tampering regarding his attempts to learn more about hacked Democratic emails during the 2016 election. The sentencing judge said Stone ""was prosecuted for covering up for the president.""[665]
",2
1244,"In August 2019, a whistleblower filed a complaint with the Inspector General of the Intelligence Community about a July 25 phone call between Trump and President of Ukraine Volodymyr Zelensky, during which Trump had pressured Zelensky to investigate CrowdStrike and Democratic presidential candidate Joe Biden and his son Hunter, adding that the White House had attempted to cover-up the incident.[666] The whistleblower stated that the call was part of a wider campaign by the Trump administration and Trump's personal attorney Rudy Giuliani, which may have included withholding financial aid from Ukraine in July 2019 and canceling Vice President Pence's May 2019 Ukraine trip.[667] Trump later confirmed that he withheld military aid from Ukraine, offering contradictory reasons for the decision.[668]
",2
1245,"House Speaker Nancy Pelosi initiated a formal impeachment inquiry on September 24, 2019.[669] The Trump administration subsequently released a memorandum of the July 25 phone call, confirming that after Zelensky mentioned purchasing American anti-tank missiles, Trump asked Zelensky to investigate and to discuss these matters with Giuliani and Attorney General William Barr.[666][670] The testimony of multiple administration officials and former officials confirmed that this was part of a broader effort to further Trump's personal interests by giving him an advantage in the upcoming presidential election.[671] In October 2019, William B. Taylor Jr., the chargé d'affaires for Ukraine, testified before congressional committees that soon after arriving in Ukraine in June 2019, he found that Zelensky was being subjected to pressure directed by Trump and led by Giuliani. According to Taylor and others, the goal was to coerce Zelensky into making a public commitment to investigate the company that employed Hunter Biden, as well as rumors about Ukrainian involvement in the 2016 U.S. presidential election.[672] He said it was made clear that until Zelensky made such an announcement, the administration would not release scheduled military aid for Ukraine and not invite Zelensky to the White House.[673]
",2
1246,"On December 13, 2019, the House Judiciary Committee voted along party lines to pass two articles of impeachment: one for abuse of power and one for obstruction of Congress.[674] After debate, the House of Representatives impeached Trump on both articles on December 18.[675]
",2
1247,"The Senate impeachment trial began on January 16, 2020.[676] On January 22, the Republican Senate majority rejected amendments proposed by the Democratic minority to call witnesses and subpoena documents; evidence collected during the House impeachment proceedings was entered into the Senate record.[677]
",2
1248,"For three days, January 22–24, the House impeachment managers presented their case to the Senate. They cited evidence to support charges of abuse of power and obstruction of Congress, and asserted that Trump's actions were exactly what the founding fathers had in mind when they created the Constitution's impeachment process.[678]
",2
1249,"Responding over the next three days, Trump's lawyers did not deny the facts as presented in the charges but said Trump had not broken any laws or obstructed Congress.[679] They argued that the impeachment was ""constitutionally and legally invalid"" because Trump was not charged with a crime and that abuse of power is not an impeachable offense.[679]  On January 31, the Senate voted against allowing subpoenas for witnesses or documents; 51 Republicans formed the majority for this vote.[680] The impeachment trial was the first in U.S. history without witness testimony.[681]
",2
1250,"Trump was acquitted of both charges by the Republican Senate majority, 52–48 on abuse of power and 53–47 on obstruction of Congress. Senator Mitt Romney was the only Republican who voted to convict Trump on one of the charges, the abuse of power.[682]
",2
1251,"Following his acquittal, Trump fired impeachment witnesses and other political appointees and career officials he deemed insufficiently loyal.[683]
",2
1252,"Breaking with precedent, Trump filed to run for a second term with the FEC within a few hours of assuming the presidency.[684] Trump held his first re-election rally less than a month after taking office.[685][686] In his first two years in office, Trump's reelection committee reported raising $67.5 million, allowing him to begin 2019 with $19.3 million cash on hand.[687] From the beginning of 2019 through July 2020, the Trump campaign and Republican Party raised $1.1 billion but spent $800 million of that amount, losing their cash advantage over the Democratic nominee, former vice president Joe Biden.[688] The cash shortage forced the campaign to scale-back advertising spending.[689]
",2
1253,"Starting in spring 2020, Trump began to sow doubts about the election, repeatedly claiming without evidence that the election would be ""rigged""[690] and that the expected widespread use of mail balloting would produce ""massive election fraud.""[691][692] On July 30, Trump raised the idea of delaying the election.[693] When in August the House of Representatives voted for a US$25 billion grant to the U.S. Postal Service for the expected surge in mail voting, Trump blocked funding, saying he wanted to prevent any increase in voting by mail.[694] Trump became the Republican nominee on August 24, 2020.[695] He repeatedly refused to say whether he would accept the results of the election and commit to a peaceful transition of power if he lost.[696][697]
",2
1254,"Trump campaign advertisements focused on crime, claiming that cities would descend into lawlessness if his opponent, Biden, won the presidency.[698] Trump repeatedly misrepresented Biden's positions during the campaign.[699][700][701] Trump's campaign message shifted to racist rhetoric in an attempt to reclaim voters lost from his base.[702][703]
",2
1255,"Biden won the election on November 3, receiving 81.3 million votes (51.3 percent) to Trump's 74.2 million (46.8 percent)[704][705] and winning the Electoral College by 306 to 232.[706][705][704]
",2
1256,"At 2 a.m. the morning after the election, with the results still unclear, Trump declared victory.[707] After Biden was projected the winner days later, Trump said, ""this election is far from over"" and baselessly alleged election fraud.[708] Trump and his allies filed many legal challenges to the results, which were rejected by at least 86 judges in both the state and federal courts, including by federal judges appointed by Trump himself, finding no factual or legal basis.[709][710] Trump's unsubstantiated allegations of widespread voting fraud were also refuted by state election officials.[711] After Cybersecurity and Infrastructure Security Agency (CISA) director Chris Krebs contradicted Trump's fraud allegations, Trump dismissed him on November 17.[712] On December 11, the U.S. Supreme Court declined to hear a case from the Texas attorney general which asked the court to overturn the election results in four states won by Biden.[713]
",2
1257,"Trump withdrew from public activities in the weeks following the election.[714] He initially blocked government officials from cooperating in the presidential transition of Joe Biden.[715][716] After three weeks, the administrator of the General Services Administration ascertained Biden the ""apparent winner"" of the election, allowing the disbursement of transition resources to his team.[717] Trump still did not formally concede while claiming he recommended the GSA begin transition protocols.[718]
",2
1258,"The Electoral College formalized Biden's victory on December 14.[706] From November to January, Trump repeatedly sought help to overturn the results of the election, personally communicating with various Republican local and state office-holders, Republican state and federal legislators, and Vice President Pence, urging various actions such as replacing presidential electors, or a request for Georgia officials to ""find"" votes and announce a ""recalculated"" result.[719][720][721] On February 10, 2021, Georgia prosecutors opened a criminal investigation into Trump's efforts to subvert the election in Georgia.[722]
",2
1259,"Trump did not attend Biden's inauguration, leaving Washington for Florida hours before.[723]
",2
1260,"On January 6, 2021, while congressional certification of the presidential election results was occurring in the Capitol, Trump held a rally nearby, where he called for the election result to be overturned and urged his supporters to ""take back our country"" by marching to the Capitol to ""show strength"" and ""fight like hell.""[724][725] Thousands of those supporters then stormed the Capitol around 1 pm, disrupting certification and causing the evacuation of Congress. During the violence, Trump posted mixed messages on Twitter and Facebook, eventually tweeting to the rioters at 6 pm, ""go home with love & in peace,"" but describing them as ""great patriots"" and ""very special,"" 
while still complaining that the election was stolen.[726][727] After the mob was removed from the Capitol, Congress reconvened and confirmed the Biden election win in the early hours of the following morning.[728] Five people, including a Capitol Police officer, died as a consequence of the riot.[729][730][731]
",2
1261,"On January 11, 2021, an article of impeachment charging Trump with incitement of insurrection against the U.S. government was introduced to the House.[732] The House voted 232–197 to impeach Trump on January 13, making him the first U.S. officeholder to be impeached twice.[733]  The impeachment, which was the most rapid in history, followed an unsuccessful bipartisan effort to strip Trump of his powers and duties via Section 4 of the 25th Ammendment.[734] Ten Republicans voted for impeachment – the most members of a party ever to vote to impeach a president of their own party.[735]
",2
1262,"Senate Democrats asked to begin the trial immediately, while Trump was still in office, but then-Senate majority leader Mitch McConnell blocked the plan.[736] On February 13, following a five-day Senate trial, Trump was acquitted when the Senate voted 57–43 for conviction, falling ten votes short of the two-thirds majority required to convict; seven Republicans joined every Democrat in voting to convict, the most bipartisan support in any Senate impeachment trial of a president or former president.[737][738] Most Republicans voted to acquit Trump, though some held him responsible but felt the Senate did not have jurisdiction over former presidents (Trump had left office on January 20; the Senate voted 56–44 the trial was constitutional[739]). Included in the latter group was McConnell, who said Trump was ""practically and morally responsible for provoking the events of the day"" but ""constitutionally not eligible for conviction.""[740]
",2
1263,"After his term ended, Trump went to live at his Mar-a-Lago club in Palm Beach, Florida.[741][83] As provided for by the Former Presidents Act,[742] he established an office at Mar-a-Lago to handle his post-presidential activities.[742][743]
",2
1264,"On February 28, 2021, Trump made his first major post-presidency speech at the Conservative Political Action Conference in which he attacked his successor Joe Biden, repeated false claims that he had won the 2020 election, and named Republican members of Congress who had voted to impeach and convict him.[744][745]
",2
1265,"For much of his term through September 2020, Trump's approval and disapproval ratings were unusually stable, reaching a high of 49 percent and a low of 35 percent.[746][747] He completed his term with a record-low approval rating of between 29 percent to 34 percent (the lowest of any president since modern scientific polling began); his average approval rating throughout his term was a record-low 41 percent.[748][749] Trump's approval ratings showed a record partisan gap: over of the course of his presidency, Trump's approval rating among Republicans was 88 percent and his approval rating among Democrats was 7 percent.[749]
",2
1266,"In Gallup's annual poll asking Americans to name the man they admire the most, Trump placed second to Obama in 2017 and 2018, tied with Obama for most admired man in 2019, and was named most admired in 2020.[750][751] Since Gallup started conducting the poll in 1948,[752] Trump is the first elected president not to be named most admired in his first year in office.[752]
",2
1267,"Globally, a Gallup poll on 134 countries comparing the approval ratings of U.S. leadership between the years 2016 and 2017 found that only in 29 of them did Trump lead Obama in job approval,[753] with more international respondents disapproving rather than approving of the Trump administration. Overall ratings were similar to those in the last two years of the George W. Bush presidency.[754] Only 16 percent of international respondents expressed confidence in Trump by mid-2020, according to a 13-nation Pew Research poll; a score lower than those of Russia's Vladimir Putin and China's Xi Jinping.[755]
",2
1268,"Trump's presence on social media attracted attention worldwide since he joined Twitter in 2009. He frequently tweeted during the 2016 election campaign and as president, until his ban in the final days of his term.[756] Over twelve years, Trump posted around 57,000 tweets.[757] Trump frequently used Twitter as a direct means of communication with the public, sidelining the press.[757] A White House press secretary said early in his presidency that Trump's tweets were official presidential statements, used for announcing policies and personnel changes.[758][759][760]
",2
1269,"Trump's tweets often contained falsehoods, eventually causing Twitter to tag some Trump tweets with fact-checking warnings beginning in May 2020.[761] Trump responded by threatening to ""strongly regulate"" or ""close down"" social media platforms.[762] In the days after the 2021 storming of the United States Capitol, Trump was banned from Facebook, Instagram, Twitter and other platforms.[763] Twitter blocked attempts by Trump and his staff to circumvent the ban through the use of others' accounts.[764] The loss of Trump's social media megaphone, including his 88.7 million Twitter followers, diminished his ability to shape events,[765][766] and prompted a dramatic decrease in the volume of misinformation shared on Twitter.[767]
",2
1270,"As a candidate and as president, Trump frequently made false statements in public speeches and remarks[771][210] to an extent unprecedented in American politics.[772][773][216] His falsehoods became a distinctive part of his political identity.[773]
",2
1271,"Trump's false and misleading statements were documented by fact-checkers, including at the Washington Post, which tallied a total of 30,573 false or misleading statements made by Trump over his four-year term.[768] Trump's falsehoods increased in frequency over time, rising from about 6 false or misleading claims per day in his first year as president to 16 per day in his second year to 22 per day in his third year to 39 per day in his final year.[774] He reached 10,000 false or misleading claims 27 months into his term; 20,000 false or misleading claims 14 months later, and 30,000 false or misleading claims five months later.[774]
",2
1272,"Some of Trump's falsehoods were inconsequential, such as his claims of a large crowd size during his inauguration.[775][776] Others had more far-reaching effects, such as Trump's promotion of unproven antimalarial drugs as a treatment for COVID‑19 in a press conference and on Twitter in March 2020.[777][778] The claims had consequences worldwide, such as a shortage of these drugs in the United States and panic-buying in Africa and South Asia.[779][780] Other misinformation, such as misattributing a rise in crime in England and Wales to the ""spread of radical Islamic terror,"" served Trump's domestic political purposes.[781] As a matter of principle, Trump does not apologize for his falsehoods.[782]
",2
1273,"Despite the frequency of Trump's falsehoods, the media rarely referred to them as lies.[783][784] Nevertheless, in August 2018 The Washington Post declared for the first time that some of Trump's misstatements (statements concerning hush money paid to Stormy Daniels and Playboy model Karen McDougal) were lies.[785][784]
",2
1274,"In 2020, Trump was a significant source of disinformation on national voting practices and the COVID-19 virus.[786] Trump's attacks on mail-in ballots and other election practices served to weaken public faith in the integrity of the 2020 presidential election,[690][787] while his disinformation about the pandemic delayed and weakened the national response to it.[786][542][788]
",2
1275,"Some view the nature and frequency of Trump's falsehoods as having profound and corrosive consequences on democracy.[789] James Pfiffner, professor of policy and government at George Mason University, wrote in 2019 that Trump lies differently from previous presidents, because he offers ""egregious false statements that are demonstrably contrary to well-known facts""; these lies are the ""most important"" of all Trump lies. By calling facts into question, people will be unable to properly evaluate their government, with beliefs or policy irrationally settled by ""political power""; this erodes liberal democracy, wrote Pfiffner.[790]
",2
1276,"Before and throughout his presidency, Trump has promoted numerous conspiracy theories, including ""birtherism,"" the Clinton Body Count theory, QAnon, and alleged Ukrainian interference in U.S. elections.[791] In October 2020, Trump retweeted a QAnon follower who asserted that Osama bin Laden was still alive, a body double had been killed in his place, and that ""Biden and Obama may have had SEAL Team Six killed.""[792]
",2
1277,"During and since the 2020 United States presidential election, Trump has promoted various conspiracy theories for his defeat including the ""dead voter"" conspiracy theory,[793] and without providing any evidence he has created other conspiracy theories such as that ""some states allowed voters to turn in ballots after Election Day; that vote-counting machines were rigged to favor Mr Biden; and even that the FBI, the Justice Department and the federal court system were complicit in an attempt to cover up election fraud.""[794]
",2
1278,"Throughout his career, Trump has sought media attention, with a ""love–hate"" relationship with the press.[795] Trump began promoting himself in the press in the 1970s.[796] Fox News anchor Bret Baier and former House speaker Paul Ryan have characterized Trump as a ""troll"" who makes controversial statements to see people's ""heads explode.""[797][798]
",2
1279,"In the 2016 campaign, Trump benefited from a record amount of free media coverage, elevating his standing in the Republican primaries.[209] New York Times writer Amy Chozick wrote in 2018 that Trump's media dominance, which enthralls the public and creates ""can't miss"" reality television-type coverage, was politically beneficial for him.[799]
",2
1280,"As a candidate and as president, Trump frequently accused the press of bias, calling it the ""fake news media"" and ""the enemy of the people.""[800] In 2018, journalist Lesley Stahl recounted Trump's saying he intentionally demeaned and discredited the media ""so when you write negative stories about me no one will believe you.""[801]
",2
1281,"As president, Trump privately and publicly mused about revoking the press credentials of journalists he views as critical.[802] His administration moved to revoke the press passes of two White House reporters, which were restored by the courts.[803] In 2019, a member of the foreign press reported many of the same concerns as those of media in the U.S., expressing concern that a normalization process by reporters and media results in an inaccurate characterization of Trump.[804] The Trump White House held about a hundred formal press briefings in 2017, declining by half during 2018 and to two in 2019.[803]
",2
1282,"Trump has employed the legal system as an intimidation tactic against the press.[805] In early 2020, the Trump campaign sued The New York Times, The Washington Post, and CNN for alleged defamation.[806][807] These lawsuits lacked merit and were not likely to succeed, however.[805][808] The Times suit was dismissed in March 2021.[809]
",2
1283,"Many of Trump's comments and actions have been considered racist.[810] He has repeatedly denied this, asserting: ""I am the least racist person there is anywhere in the world.""[811] In national polling, about half of Americans say that Trump is racist; a greater proportion believe that he has emboldened racists.[812][813][814] Several studies and surveys have found that racist attitudes fueled Trump's political ascendance and have been more important than economic factors in determining the allegiance of Trump voters.[815][816] Racist and Islamophobic attitudes are a strong indicator of support for Trump.[817]
",2
1284,"In 1975, he settled a 1973 Department of Justice lawsuit that alleged housing discrimination against black renters.[65] He has also been accused of racism for insisting a group of black and Latino teenagers were guilty of raping a white woman in the 1989 Central Park jogger case, even after they were exonerated by DNA evidence in 2002. As of 2019, he maintained this position.[818]
",2
1285,"Trump relaunched his political career in 2011 as a leading proponent of ""birther"" conspiracy theories alleging that Barack Obama, the first black U.S. president, was not born in the United States.[819][820] In April 2011, Trump claimed credit for pressuring the White House to publish the ""long-form"" birth certificate, which he considered fraudulent, and later saying this made him ""very popular"".[821][822] In September 2016, amid pressure, he acknowledged that Obama was born in the U.S. and falsely claimed the rumors had been started by Hillary Clinton during her 2008 presidential campaign.[823] In 2017, he reportedly still expressed birther views in private.[824]
",2
1286,"According to an analysis in Political Science Quarterly, Trump made ""explicitly racist appeals to whites"" during his 2016 presidential campaign.[825] In particular, his campaign launch speech drew widespread criticism for claiming Mexican immigrants were ""bringing drugs, they're bringing crime, they're rapists.""[826][827] His later comments about a Mexican-American judge presiding over a civil suit regarding Trump University were also criticized as racist.[828]
",2
1287,"Trump's comment on the 2017 far-right rally in Charlottesville, Virginia—that there were ""very fine people on both sides""—was widely criticized as implying a moral equivalence between white supremacist demonstrators and counter-protesters.[829][830][831]
",2
1288,"In a January 2018 Oval Office meeting to discuss immigration legislation, Trump reportedly referred to El Salvador, Haiti, Honduras, and African nations as ""shithole countries.""[832] His remarks were condemned as racist.[833][834]
",2
1289,"In July 2019, Trump tweeted that four Democratic congresswomen – all minorities, three of whom are native-born Americans – should ""go back"" to the countries they ""came from.""[835] Two days later the House of Representatives voted 240–187, mostly along party lines, to condemn his ""racist comments.""[836] White nationalist publications and social media sites praised his remarks, which continued over the following days.[837] Trump continued to make similar remarks during his 2020 campaign.[838]
",2
1290,"Trump has a history of insulting and belittling women when speaking to media and in tweet. He made lewd comments, demeaned women's looks, and called them names like 'dog', 'crazed, crying lowlife', 'face of a pig', or 'horseface'.[839][840][841]
",2
1291,"In October 2016, two days before the second presidential debate, a 2005 ""hot mic"" recording surfaced in which Trump was heard bragging about kissing and groping women without their consent, saying ""when you're a star, they let you do it, you can do anything... grab 'em by the pussy.""[842] The incident's widespread media exposure led to Trump's first public apology during the campaign[843] and caused outrage across the political spectrum.[844]
",2
1292,"At least twenty-six women have publicly accused Trump of sexual misconduct as of September 2020[update], including his then-wife Ivana. There were allegations of rape, violence, being kissed and groped without consent, looking under women's skirts, and walking in on naked women.[845][846][847] In 2016, he denied all accusations, calling them ""false smears,"" and alleged there was a conspiracy against him.[848]
",2
1293,"Research suggests Trump's rhetoric caused an increased incidence of hate crimes.[849][850][851] During the 2016 campaign, he urged or praised physical attacks against protesters or reporters.[852][853] Since then, some defendants prosecuted for hate crimes or violent acts cited Trump's rhetoric in arguing that they were not culpable or should receive a lighter sentence.[854] In May 2020, a nationwide review by ABC News identified at least 54 criminal cases from August 2015 to April 2020 in which Trump was invoked in direct connection with violence or threats of violence by mostly white men against mostly members of minority groups.[855] On January 13, 2021, the House of Representatives impeached Trump for incitement of insurrection for his actions prior to the storming of the U.S. Capitol by a violent mob of his supporters[733] who acted in his name.[856]
",2
1294,"Trump has been the subject of parody, comedy, and caricature. He has been parodied regularly on Saturday Night Live by Phil Hartman, Darrell Hammond, and Alec Baldwin and in South Park as Mr. Garrison. The Simpsons episode ""Bart to the Future""—written during his 2000 campaign for the Reform Party—anticipated a Trump presidency. Trump's wealth and lifestyle had been a fixture of hip-hop lyrics since the 1980s; he was named in hundreds of songs, most often with a positive tone.[857] Mentions of Trump in hip-hop turned negative and pejorative after he ran for office in 2015.[857]
",2
1295,"
",2
1296,"Nationalism is an idea and movement that promotes the interests of a particular nation (as in a group of people),[1] especially with the aim of gaining and maintaining the nation's sovereignty (self-governance) over its homeland. Nationalism holds that each nation should govern itself, free from outside interference (self-determination), that a nation is a natural and ideal basis for a polity[2] and that the nation is the only rightful source of political power (popular sovereignty).[1][3] It further aims to build and maintain a single national identity, based on shared social characteristics of culture, ethnicity, geographic location, language, politics (or the government), religion, traditions and belief in a shared singular history,[4][5] and to promote national unity or solidarity.[1] Nationalism seeks to preserve and foster a nation's traditional cultures and cultural revivals have been associated with nationalist movements.[6] It also encourages pride in national achievements and is closely linked to patriotism.[7][8][page needed] Nationalism is often combined with other ideologies such as conservatism (national conservatism) or socialism (left-wing nationalism).[2]
",2
1297,"Throughout history, people have had an attachment to their kin group and traditions, territorial authorities and their homeland, but nationalism did not become a widely recognized concept until the end of the 18th century.[9] There are three paradigms for understanding the origins and basis of nationalism. Primordialism (perennialism) proposes that there have always been nations and that nationalism is a natural phenomenon. Ethnosymbolism explains nationalism as a dynamic, evolutionary phenomenon and stresses the importance of symbols, myths and traditions in the development of nations and nationalism. Modernization theory proposes that nationalism is a recent social phenomenon that needs the socio-economic structures of modern society to exist.[10]
",2
1298,"There are various definitions of a ""nation"" which leads to different types of nationalism. Ethnic nationalism defines the nation in terms of shared ethnicity, heritage and culture while civic nationalism defines the nation in terms of shared citizenship, values and institutions, and is linked to constitutional patriotism. The adoption of national identity in terms of historical development has often been a response by influential groups unsatisfied with traditional identities due to mismatch between their defined social order and the experience of that social order by its members, resulting in an anomie that nationalists seek to resolve.[11] This anomie results in a society reinterpreting identity, retaining elements deemed acceptable and removing elements deemed unacceptable, to create a unified community.[11] This development may be the result of internal structural issues or the result of resentment by an existing group or groups towards other communities, especially foreign powers that are (or are deemed to be) controlling them.[11] National symbols and flags, national anthems, national languages, national myths and other symbols of national identity are highly important in nationalism.[12][13][14][15]
",2
1299,"In practice, nationalism can be seen as positive or negative depending on context and individual outlook. Nationalism has been an important driver in independence movements such as the Greek Revolution, the Irish Revolution, the Zionist movement that created modern Israel and the dissolution of the Soviet Union.[16][17] Conversely, radical nationalism combined with racial hatred was also a key factor in the Holocaust perpetrated by Nazi Germany.[18] More recently,[vague] nationalism was an important driver of the controversial annexation of Crimea by Russia.[19]
",2
1300,"The terminological use of ""nations"", ""sovereignty"" and associated concepts was significantly refined with the writing by Hugo Grotius of De jure belli ac pacis in the early 17th century. Living in the times of the Eighty Years' War between Spain and the Netherlands and the Thirty Years' War between Catholic and Protestant European nations (Catholic France being in the otherwise Protestant camp), it is not surprising that Grotius was deeply concerned with matters of conflicts between nations in the context of oppositions stemming from religious differences. The word nation was also usefully applied before 1800 in Europe to refer to the inhabitants of a country as well as to collective identities that could include shared history, law, language, political rights, religion and traditions, in a sense more akin to the modern conception.[20]
",2
1301,"Nationalism as derived from the noun designating 'nations' is a newer word; in English the term dates from 1844, although the concept is older.[21] It became important in the 19th century.[22] The term increasingly became negative in its connotations after 1914. Glenda Sluga notes that ""The twentieth century, a time of profound disillusionment with nationalism, was also the great age of globalism.""[23]
",2
1302,"American philosopher and historian Hans Kohn wrote in 1944 that nationalism emerged in the 17th century.[24] Other sources variously place the beginning in the 18th century during revolts of American states against Spain or with the French Revolution. The consensus is that nationalism as a concept was firmly established by the 19th century.[25][26][27]
",2
1303,"In Britons, Forging the Nation 1707–1837 (Yale University Press, 1992), Linda Colley explores how the role of nationalism emerged about 1700 and developed in Britain reaching full form in the 1830s. Typically historians of nationalism in Europe begin with the French Revolution (1789), not only for its impact on French nationalism but even more for its impact on Germans and Italians and on European intellectuals.[28] The template of nationalism, as a method for mobilising public opinion around a new state based on popular sovereignty, went back further than 1789: philosophers such as Rousseau and Voltaire, whose ideas influenced the French Revolution, had themselves been influenced or encouraged by the example of earlier constitutionalist liberation movements, notably the Corsican Republic (1755–68) and American Revolution (1765–83).[29]
",2
1304,"Due to the Industrial Revolution, there was an emergence of an integrated, nation-encompassing economy and a national public sphere, where the British people began to identify with the country at large, rather than the smaller units of their province, town or family. The early emergence of a popular patriotic nationalism took place in the mid-18th century, and was actively promoted by the British government and by the writers and intellectuals of the time.[30] National symbols, anthems, myths, flags and narratives were assiduously constructed by nationalists and widely adopted. The Union Jack was adopted in 1801 as the national one.[31] Thomas Arne composed the patriotic song ""Rule, Britannia!"" in 1740,[32] and the cartoonist John Arbuthnot invented the character of John Bull as the personification of the English national spirit in 1712.[33]
",2
1305,"The political convulsions of the late 18th century associated with the American and French revolutions massively augmented the widespread appeal of patriotic nationalism.[34][35]
",2
1306,"The Prussian scholar Johann Gottfried Herder (1744–1803) originated the term in 1772 in his ""Treatise on the Origin of Language"" stressing the role of a common language.[36][37] He attached exceptional importance to the concepts of nationality and of patriotism  –  ""he that has lost his patriotic spirit has lost himself and the whole world about himself"", whilst teaching that ""in a certain sense every human perfection is national"".[38]
",2
1307,"The political development of nationalism and the push for popular sovereignty culminated with the ethnic/national revolutions of Europe. During the 19th century nationalism became one of the most significant political and social forces in history; it is typically listed among the top causes of World War I.[44][45]
",2
1308,"Napoleon's conquests of the German and Italian states around 1800–06 played a major role in stimulating nationalism and the demands for national unity.[46]
",2
1309,"English historian J. P. T. Bury argues:
",2
1310,"Between 1830 and 1870 nationalism had thus made great strides. It had inspired great literature, quickened scholarship and nurtured heroes. It had shown its power both to unify and to divide. It had led to great achievements of political construction and consolidation in Germany and Italy; but it was more clearly than ever a threat to the Ottoman and Habsburg empires, which were essentially multi-national. European culture had been enriched by the new vernacular contributions of little-known or forgotten peoples, but at the same time such unity as it had was imperilled by fragmentation. Moreover, the antagonisms fostered by nationalism had made not only for wars, insurrections, and local hatreds —^they had accentuated or created new spiritual divisions in a nominally Christian Europe.[47]",2
1311,"Nationalism in France gained early expressions in France's revolutionary government. In 1793, that government declared a mass conscription (levée en masse) with a call to service:
",2
1312,"Henceforth, until the enemies have been driven from the territory of the Republic, all the French are in permanent requisition for army service. The young men shall go to battle; the married men shall forge arms in the hospitals; the children shall turn old linen to lint; the old men shall repair to the public places, to stimulate the courage of the warriors and preach the unity of the Republic and the hatred of kings.[48]",2
1313,"This nationalism gained pace after the French Revolution came to a close. Defeat in war, with a loss in territory, was a powerful force in nationalism. In France, revenge and return of Alsace-Lorraine was a powerful motivating force for a quarter century after their defeat by Germany in 1871. After 1895, French nationalists focused on Dreyfus and internal subversion, and the Alsace issue petered out.[49]
",2
1314,"The French reaction was a famous case of Revanchism (""revenge"") which demands the return of lost territory that ""belongs"" to the national homeland. Revanchism draws its strength from patriotic and retributionist thought and it is often motivated by economic or geo-political factors. Extreme revanchist ideologues often represent a hawkish stance, suggesting that their desired objectives can be achieved through the positive outcome of another war. It is linked with irredentism, the conception that a part of the cultural and ethnic nation remains ""unredeemed"" outside the borders of its appropriate nation state. Revanchist politics often rely on the identification of a nation with a nation state, often mobilizing deep-rooted sentiments of ethnic nationalism, claiming territories outside the state where members of the ethnic group live, while using heavy-handed nationalism to mobilize support for these aims. Revanchist justifications are often presented as based on ancient or even autochthonous occupation of a territory since ""time immemorial"", an assertion that is usually inextricably involved in revanchism and irredentism, justifying them in the eyes of their proponents.[50]
",2
1315,"The Dreyfus Affair in France 1894–1906 made the battle against treason and disloyalty a central theme for conservative Catholic French nationalists. Dreyfus, a Jew, was an outsider, that is in the views of intense nationalists, not a true Frenchman, not one to be trusted, not one to be given the benefit of the doubt. True loyalty to the nation, from the conservative viewpoint, was threatened by liberal and republican principles of liberty and equality that were leading the country to disaster.[51]
",2
1316,"Before 1815, the sense of Russian nationalism was weak – what there was focused on loyal obedience to the tsar. 
The Russian motto ""Orthodoxy, Autocracy, and Nationality"" was coined by Count Sergey Uvarov and adopted by Emperor Nicholas I as official ideology.[52] Three components of Uvarov's triad were:
",2
1317,"By the 1860s, as a result of educational indoctrination, and conservative resistance to ideas and ideologies from Western Europe, a pan-Slavic movement had emerged that produce both a sense of Russian nationalism, and a nationalistic mission to support and protect pan-Slavism. This Slavophile movement became popular in 19th-century Russia. Pan-Slavism was fueled by and was the fuel for Russia's numerous wars against the Ottoman Empire with the goal of liberating Orthodox nations, such as Bulgarians, Romanians, Serbs and Greeks, from Ottoman rule. Slavophiles opposed the influences of Western Europe in Russia and were determined to protect Russian culture and traditions. Aleksey Khomyakov, Ivan Kireyevsky, and Konstantin Aksakov are credited with co-founding the movement.[54]
",2
1318,"An upsurge in nationalism in Latin America in 1810s and 1820s sparked revolutions that cost Spain nearly all its colonies there.[55] Spain was at war with Britain from 1798 to 1808, and the British Royal Navy cut off its contacts with its colonies so nationalism flourished and trade with Spain was suspended. The colonies set up temporary governments or juntas which were effectively independent from Spain. These juntas were established as a result of Napoleon's resistance failure in Spain. They served to determine new leadership and, in colonies like Caracas, abolished the slave trade as well as the Indian tribute. [56] The division exploded between Spaniards who were born in Spain (called ""peninsulares"") versus those of Spanish descent born in New Spain (called ""criollos"" in Spanish or ""creoles"" in English). The two groups wrestled for power, with the criollos leading the call for independence. Spain tried to use its armies to fight back but had no help from European powers. Indeed, Britain[57] and the United States worked against Spain, enforcing the Monroe Doctrine. Spain lost all of its American colonies, except Cuba and Puerto Rico, in a complex series of revolts from 1808 to 1826.[58]
",2
1319,"In the German states west of Prussia, Napoleon abolished many of the old or medieval relics, such as dissolving the Holy Roman Empire in 1806.[59] He imposed rational legal systems and demonstrated how dramatic changes were possible. His organization of the Confederation of the Rhine in 1806 promoted a feeling of nationalism.
",2
1320,"Nationalists sought to encompass masculinity in their quest for strength and unity.[60] It was Prussian chancellor Otto von Bismarck who achieved German unification through a series of highly successful short wars against Denmark, Austria and France which thrilled the pan-German nationalists in the smaller German states. They fought in his wars and eagerly joined the new German Empire, which Bismarck ran as a force for balance and peace in Europe after 1871.[61]
",2
1321,"In the 19th century, German nationalism was promoted by Hegelian-oriented academic historians who saw Prussia as the true carrier of the German spirit, and the power of the state as the ultimate goal of nationalism. The three main historians were Johann Gustav Droysen (1808–1884), Heinrich von Sybel (1817–1895) and Heinrich von Treitschke (1834–1896). Droysen moved from liberalism to an intense nationalism that celebrated Prussian Protestantism, efficiency, progress, and reform, in striking contrast to Austrian Catholicism, impotency and backwardness. He idealized the Hohenzollern kings of Prussia. His large-scale History of Prussian Politics (14 vol 1855–1886) was foundational for nationalistic students and scholars. Von Sybel founded and edited the leading academic history journal, Historische Zeitschrift and as the director of the Prussian state archives published massive compilations that were devoured by scholars of nationalism.[62]
",2
1322,"The most influential of the German nationalist historians, was Treitschke who had an enormous influence on elite students at Heidelberg and Berlin universities.[63] Treitschke vehemently attacked parliamentarianism, socialism, pacifism, the English, the French, the Jews, and the internationalists. The core of his message was the need for a strong, unified state—a unified Germany under Prussian supervision. ""It is the highest duty of the State to increase its power,"" he stated. Although he was a descendant of a Czech family he considered himself not Slavic but German: ""I am 1000 times more the patriot than a professor.""[64]
",2
1323,"German nationalism, expressed through the ideology of Nazism, however, may also be understood as trans-national in nature. This aspect was primarily advocated by Adolf Hitler, who later became the leader of the Nazi Party. This party was devoted to what they identified as an Aryan race, residing in various European countries, but sometime mixed with alien elements such as Jews.[66]
",2
1324,"Meanwhile, the Nazis rejected many of the well-established citizens within those same countries, such as the Romani (Gypsies) and of course Jews, whom they did not identify as Aryan. A key Nazi doctrine was ""Living Space"" (for Aryans only) or ""Lebensraum,"" which was a vast undertaking to transplant Aryans throughout Poland, much of Eastern Europe and the Baltic nations, and all of Western Russia and Ukraine. Lebensraum was thus a vast project for advancing the Aryan race far outside of any particular nation or national borders. The Nazi's goals were racist focused on advancing the Aryan race as they perceived it, eugenics modification of the human race, and the eradication of human beings that they deemed inferior. But their goals were trans-national and intended to spread across as much of the world as they could achieve. Although Nazism glorified German history, it also embraced the supposed virtues and achievements of the Aryan race in other countries,[67] including India.[68] The Nazis' Aryanism longed for now-extinct species of superior bulls once used as livestock by Aryans and other features of Aryan history that never resided within the borders of Germany as a nation.[69]
",2
1325,"Italian nationalism emerged in the 19th century and was the driving force for Italian unification or the Risorgimento (meaning the ""Resurgence"" or ""Revival""). It was the political and intellectual movement that consolidated the different states of the Italian peninsula into the single state of the Kingdom of Italy in 1861. The memory of the Risorgimento is central to Italian nationalism but it was based in the liberal middle classes and ultimately proved a bit weak.[70] The new government treated the newly-annexed South as a kind of underdeveloped province for its ""backward"" and poverty-stricken society, its poor grasp of standard Italian (as Italo-Dalmatian dialects of Neapolitan and Sicilian were prevalent in the common use) and its traditions.[citation needed] The liberals had always been strong opponents of the pope and the very well organized Catholic Church. The liberal government under the Sicilian Francesco Crispi sought to enlarge his political base by emulating Otto von Bismarck and firing up Italian nationalism with a aggressive foreign policy. It partially crashed and his cause was set back. Of his nationalistic foreign policy, historian R. J. B. Bosworth says:
",2
1326,"[Crispi] pursued policies whose openly aggressive character would not be equaled until the days of the Fascist regime. Crispi increased military expenditure, talked cheerfully of a European conflagration, and alarmed his German or British friends with this suggestions of preventative attacks on his enemies.  His policies were ruinous, both for Italy's trade with France, and, more humiliatingly, for colonial ambitions in East Africa. Crispi's lust for territory there was thwarted when on 1 March 1896, the armies of Ethiopian Emperor Menelik routed Italian forces at Adowa [...] in what has been defined as an unparalleled disaster for a modern army. Crispi, whose private life and personal finances [...] were objects of perennial scandal, went into dishonorable retirement.[71]",2
1327,"Italy joined the Allies in the First World War after getting promises of territory, but its war effort were not honored after the war and this fact discredited liberalism paving the way for Benito Mussolini and a political doctrine of his own creation, Fascism. Mussolini's 20-year dictatorship involved a highly aggressive nationalism that led to a series of wars with the creation of the Italian Empire, an alliance with Hitler's Germany, and humiliation and hardship in the Second World War. After 1945, the Catholics returned to government and tensions eased somewhat, but the former two Sicilies remained poor and partially underdeveloped (by industrial country standards). However in the fifties and early sixties Italy enjoyed an economic boom, that pushed its economy to the fifth place between the world nations.
",2
1328,"The working class in those decades voted mostly for the Communist Party, and it looked to Moscow rather than Rome for inspiration, and was kept out of the national government even as it controlled some industrial cities across the North. In the 21st century, the Communists have become marginal but political tensions remained high as shown by Umberto Bossi's Padanism in the 1980s[72] (whose party Lega Nord has come to partially embrace a moderate version of Italian nationalism over the years) and other separatist movements spread across the country.[citation needed]
",2
1329,"During the early 19th century, inspired by romanticism, classicism, former movements of Greek nationalism and failed Greek revolts against the Ottoman Empire (such as the Orlofika revolt in southern Greece in 1770, and the Epirus-Macedonian revolt of Northern Greece in 1575), Greek nationalism led to the Greek war of independence.[73] The Greek drive for independence from the Ottoman Empire in the 1820s and 1830s inspired supporters across Christian Europe, especially in Britain, which was the result of western idealization of Classical Greece and romanticism. France, Russia and Britain critically intervened to ensure the success of this nationalist endeavour.[74]
",2
1330,"For centuries the Orthodox Christian Serbs were ruled by the Muslim Ottoman Empire. The success of the Serbian Revolution against Ottoman rule in 1817 marked the birth of the Principality of Serbia. It achieved de facto independence in 1867 and finally gained international recognition in 1878. Serbia had sought to liberate and unite with Bosnia and Herzegovina to the west and Old Serbia (Kosovo and Vardar Macedonia) to the south. Nationalist circles in both Serbia and Croatia (part of Austria-Hungary) began to advocate for a greater South Slavic union in the 1860s, claiming Bosnia as their common land based on shared language and tradition.[75] In 1914, Serb revolutionaries in Bosnia assassinated Archduke Ferdinand. Austria-Hungary, with German backing, tried to crush Serbia in 1914, thus igniting the First World War in which Austria-Hungary dissolved into nation states.[76]
",2
1331,"In 1918, the region of Banat, Bačka and Baranja came under control of the Serbian army, later the Great National Assembly of Serbs, Bunjevci and other Slavs voted to join Serbia; the Kingdom of Serbia joined the union with State of Slovenes, Croats and Serbs on 1 December 1918, and the country was named Kingdom of Serbs, Croats, and Slovenes. It was renamed Yugoslavia, and a Yugoslav identity was promoted, which ultimately failed. After the Second World War, Yugoslav Communists established a new socialist republic of Yugoslavia. That state broke up in the 1990s.[77]
",2
1332,"The cause of Polish nationalism was repeatedly frustrated before 1918. In the 1790s, the Habsburg Monarchy, Prussia and Russia
invaded, annexed, and subsequently partitioned Poland. Napoleon set up the Duchy of Warsaw, a new Polish state that ignited a spirit of nationalism. Russia took it over in 1815 as Congress Poland with the tsar proclaimed as ""King of Poland"". Large-scale nationalist revolts erupted in 1830 and 1863–64 but were harshly crushed by Russia, which tried to make the Polish language, culture and religion more like Russia's. The collapse of the Russian Empire in the First World War enabled the major powers to re-establish an independent Poland, which survived until 1939. Meanwhile, Poles in areas controlled by Germany moved into heavy industry but their religion came under attack by Bismarck in the Kulturkampf of the 1870s. The Poles joined German Catholics in a well-organized new Centre Party, and defeated Bismarck politically. He responded by stopping the harassment and cooperating with the Centre Party.[78][79]
",2
1333,"In the late 19th and early 20th century, many Polish nationalist leaders endorsed the Piast Concept. It held there was a Polish utopia during the Piast Dynasty a thousand years before, and modern Polish nationalists should restore its central values of Poland for the Poles. Jan Poplawski had developed the ""Piast Concept"" in the 1890s, and it formed the centerpiece of Polish nationalist ideology, especially as presented by the National Democracy Party, known as the ""Endecja,"" which was led by Roman Dmowski. In contrast with the Jagiellon concept, there was no concept for a multi-ethnic Poland.[80]
",2
1334,"The Piast concept stood in opposition to the ""Jagiellon Concept,"" which allowed for multi-ethnicism and Polish rule over numerous minority groups such as those in the Kresy. The Jagiellon Concept was the official policy of the government in the 1920s and 1930s. Soviet dictator Josef Stalin at Tehran in 1943 rejected the Jagiellon Concept because it involved Polish rule over Ukrainians and Belarusians. He instead endorsed the Piast Concept, which justified a massive shift of Poland's frontiers to the west.[81] After 1945 the Soviet-back puppet communist regime wholeheartedly adopted the Piast Concept, making it the centerpiece of their claim to be the ""true inheritors of Polish nationalism"". After all the killings, including Nazi German occupation, terror in Poland and population transfers during and after the war, the nation was officially declared as 99% ethnically Polish.[82]
",2
1335,"Jewish nationalism arose in the latter half of the 19th century and it was largely correlated with the Zionist movement. This term originated from the word Zion, which was one of the Torah's names for the city of Jerusalem. The end goal of the nationalists and Zionists was a Jewish majority and in most cases, a state, in the land of Palestine. A tumultuous history of living in oppressive, foreign, and uncertain circumstances led the supporters of the movement to draft a declaration of independence, claiming Israel as a birthplace. The first and second destructions of the temple and ancient Torah prophecies largely shaped the incentives of the Jewish nationalists. Many prominent theories in Jewish theology and eschatology were formed by supporters and opponents of the movement in this era.
",2
1336,"It was the French Revolution of 1789 which sparked new waves of thinking across Europe regarding governance and sovereignty. A shift from the traditional hierarchy-based system towards political individualism and citizen-states posed a dilemma for the Jews. Citizenship was now essential, when it came to ensuring basic legal and residential rights. This resulted in more and more Jews choosing to identify with certain nationalities in order to maintain these rights. Logic said that a nation-based system of states would require the Jews themselves to claim their own right to be considered a nation due to a distinguishable language and history. Historian David Engel has explained that Zionism was more about fear that a majority of worldwide Jews would end up dispersed and unprotected, rather than fulfilling old prophecies and traditions of historical texts.[83]
",2
1337,"The awakening of nationalism across Asia helped shape the history of the continent. The key episode was the decisive defeat of Russia by Japan in 1905, demonstrating the military advancement of non-Europeans in a modern war. The defeat which quickly led to manifestations of a new interest in nationalism in China, as well as Turkey, and Persia.[84] In China Sun Yat-sen (1866–1925) launched his new party the Kuomintang (National People's Party) in defiance of the decrepit Empire, which was run by outsiders. The Kuomintang recruits pledged:
",2
1338,"[F]rom this moment I will destroy the old and build the new, and fight for the self-determination of the people, and will apply all my strength to the support of the Chinese Republic and the realization of democracy through the Three Principles, ... for the progress of good government, the happiness and perpetual peace of the people, and for the strengthening of the foundations of the state in the name of peace throughout the world.[85]",2
1339,"The Kuomintang largely ran China until the Communists took over in 1949. But the latter had also been strongly influenced by Sun's nationalism as well as by the May Fourth Movement in 1919. It was a nationwide protest movement about the domestic backwardness of China and has often been depicted as the intellectual foundation for Chinese Communism.[86] The New Culture Movement stimulated by the May Fourth Movement waxed strong throughout the 1920s and 1930s. Historian Patricia Ebrey says:
",2
1340,"Nationalism, patriotism, progress, science, democracy, and freedom were the goals; imperialism, feudalism, warlordism, autocracy, patriarchy, and blind adherence to tradition were the enemies. Intellectuals struggled with how to be strong and modern and yet Chinese, how to preserve China as a political entity in the world of competing nations.[87]",2
1341,"Nationalist irredentist movements Greek advocating for Enosis (unity of ethnically Greek states with the Hellenic Republic to create a unified Greek state), used today in the case of Cyprus, as well as the Megali Idea, the Greek movement that advocated for the reconquering of Greek ancestral lands from the Ottoman Empire (such as Crete, Ionia, Pontus, Northern Epirus, Cappadocia, Thrace among others) that were popular in the late 19th and early to 20th centuries, led to many Greek states and regions that were ethnically Greek to eventually unite with Greece and the Greco-Turkish war of 1919.
",2
1342,"The 4th of August regime was a fascist or fascistic nationalist authoritarian dictatorship inspired by Mussolini's Fascist Italy and Hitler's Germany and led by Greek general Ioannis Metaxas from 1936 to his death in 1941. It advocated for the Third Hellenic Civilization, a culturally superior Greek civilization that would be the successor of the First and Second Greek civilizations, that were Ancient Greece and the Byzantine empire respectively. It promoted Greek traditions, folk music and dances, classicism as well as medievalism.
",2
1343,"In the 1880s the European powers divided up almost all of Africa (only Ethiopia and Liberia were independent). They ruled until after World War II when forces of nationalism grew much stronger. In the 1950s and 1960s the colonial holdings became independent states. The process was usually peaceful but there were several long bitter bloody civil wars, as in Algeria,[88] Kenya[89] and elsewhere.
Across Africa nationalism drew upon the organizational skills that natives learned in the British and French and other armies in the world wars. It led to organizations that were not controlled by or endorsed by either the colonial powers nor the traditional local power structures that were collaborating with the colonial powers. Nationalistic organizations began to challenge both the traditional and the new colonial structures and finally displaced them. Leaders of nationalist movements took control when the European authorities exited; many ruled for decades or until they died off. These structures included political, educational, religious, and other social organizations. In recent decades, many African countries have undergone the triumph and defeat of nationalistic fervor, changing in the process the loci of the centralizing state power and patrimonial state.[90][91][92]
",2
1344,"South Africa, a British colony, was exceptional in that it became virtually independent by 1931. From 1948 it was controlled by white Afrikaner nationalists focused on racial segregation and white minority rule known officially as apartheid, which lasted until 1994, when elections were held. The international anti-apartheid movement supported black nationalist until success was achieved and Nelson Mandela was elected president.[93]
",2
1345,"Arab nationalism, a movement toward liberating and empowering the Arab peoples of the Middle East, emerged during the latter 19th century, inspired by other independence movements of the 18th and 19th centuries. As the Ottoman Empire declined and the Middle East was carved up by the Great Powers of Europe, Arabs sought to establish their own independent nations ruled by Arabs rather than foreigners. Syria was established in 1920; Transjordan (later Jordan) gradually gained independence between 1921 and 1946; Saudi Arabia was established in 1932; and Egypt achieved gradually gained independence between 1922 and 1952. The Arab League was established in 1945 to promote Arab interests and cooperation between the new Arab states.
",2
1346,"Parallel to these efforts was the Zionist movement which emerged among European Jews in the 19th century. Beginning in 1882 Jews, predominantly from Europe, began emigrating to Ottoman Palestine with the goal of establishing a new Jewish homeland. The effort culminated in the declaration of the State of Israel in 1948. As this move conflicted with the belief among Arab nationalists that Palestine was part of the Arab nation, the neighboring Arab nations launched an invasion to claim the region. The invasion was only partly successful and led to decades of clashes between the Arab and Jewish nationalist ideologies.
",2
1347,"There was a rise in extreme nationalism after the Revolutions of 1989 triggered the collapse of communism in the 1990s. When communism fell, it left many people with no identity. The people under communist rule had to integrate, and they found themselves free to choose. Given free choice, long dormant conflicts rose up and created sources of serious conflict.[94] When communism fell in Yugoslavia, serious conflict arose, which led to the rise in extreme nationalism.
",2
1348,"In his 1992 article Jihad vs. McWorld, Benjamin Barber proposed that the fall of communism will cause large numbers of people to search for unity and that small scale wars will become common; groups will attempt to redraw boundaries, identities, cultures and ideologies.[95] Communism's fall also allowed for an ""us vs. them"" mentality to sprout up.[96] Governments become vehicles for social interests and the country will attempt to form national policies based on the majority, for example culture, religion or ethnicity.[94] Some newly sprouted democracies have large differences in policies on matters that ranged from immigration and human rights to trade and commerce.
",2
1349,"Academic Steven Berg felt that at the root of nationalist conflicts is the demand for autonomy and a separate existence.[94] This nationalism can give rise to strong emotions that may lead to a group fighting to survive, especially as after the fall of communism, political boundaries did not match ethnic boundaries.[94] Serious conflicts often arose and escalated very easily as individuals and groups acted upon their beliefs, causing death and destruction.[94] When this would happen, those states who were unable to contain the conflict ran the risk of slowing their democratization progress.
",2
1350,"Yugoslavia was established after WWI and was a merger of three separate ethnic groups; Serbs, Croats and Slovenes. The national census numbers for a ten-year span 1971–1981 measured an increase from 1.3 to 5.4% in their population that ethnically identified as Yugoslav.[97] This meant that the country, almost as a whole, was divided by distinctive religious, ethnic or national loyalties after nearly 50 years.
",2
1351,"Within Yugoslavia, separating Croatia and Slovenia from the rest of Yugoslavia is an invisible line of previous conquests of the region. Croatia and Slovenia to the northwest were conquered by Catholics or Protestants, and benefited from European history; the Renaissance, French Revolution, Industrial Revolution and are more inclined towards democracy.[96] The remaining Yugoslavian territory was conquered by the Ottoman or Tsarists empires; are Orthodox or Muslims, are less economically advanced and are less inclined toward democracy.
",2
1352,"In the 1970s the leadership of the separate territories within Yugoslavia protected only territorial interests at the expense of other territories. In Croatia, there was almost a split within the territory between Serbs and Croats so any political decision would kindle unrest, and tensions could cross the territories adjacent; Bosnia and Herzegovina.[97] Within Bosnia there was no group who had a majority; Muslim, Serb, Croat, and Yugoslav were all there so the leadership could not advance here either. Political organizations were not able to deal successfully with such diverse nationalism. Within the territories the leadership could not compromise. To do so would create a winner in one ethnic group and a loser in another, raising the possibility of a serious conflict. This strengthened the political stance promoting ethnic identities. This caused intense and divided political leadership within Yugoslavia.
",2
1353,"In the 1980s Yugoslavia began to break into fragments.[95] The economic conditions within Yugoslavia were deteriorating. Conflict in the disputed territories was stimulated by the rise in mass nationalism and inter-ethnic hostilities.[97] The per-capita income of people in the northwest territory, encompassing Croatia and Slovenia, in contrast to the southern territory were several times higher. This combined with escalating violence from ethnic Albanians and Serbs within Kosovo intensified economic conditions.[97] This violence greatly contributed to the rise of extreme nationalism of Serbs in Serbia and within Yugoslavia. The ongoing conflict in Kosovo was propagandized by Communist Serbian Slobodan Milosevic to further increase Serb nationalism. As mentioned, this nationalism did give rise to powerful emotions which grew the force of Serbian nationalism through highly nationalist demonstrations in Vojvodina, Serbia, Montenegro, and Kosovo. Serbian nationalism was so high, Slobodan Milosevic was able to oust leaders in Vojvodina and Montenegro, further repressed Albanians within Kosovo and eventually controlled four of the eight regions/territories.[97] Slovenia, one of the four regions not under Communist control, favoring a democratic state.
",2
1354,"Within Slovenia, fear was mounting because Milosevic was using the militia to suppress a in Kosovo, what would he do to Slovenia.[97] Half of Yugoslavia wanted to be democratic, the other wanted a new nationalist authoritarian regime. In fall of 1989 tensions came to a head and Slovenia asserted its political and economic independence from Yugoslavia and seceded. In January 1990, there was a total break with Serbia at the League of Communists of Yugoslavia, an institution conceived by Milosevic to strengthen unity and became the backdrop for the fall of communism within Yugoslavia.
",2
1355,"In August 1990, a warning to the region was issued when ethnically divided groups attempted to alter the government structure. The republic borders established by the Communist regime in the postwar period were extremely vulnerable to challenges from ethnic communities. Ethnic communities arose because they did not share the identity with everyone within the new post-Communist borders.[97] This threatened the new governments. The same disputes were erupting that were in place prior to Milosevic and were compounded by actions from his regime.
",2
1356,"Also within the territory the Croats and the Serbs were in direct competition for control of government. Elections were held and increased potential conflicts between Serb and Croat nationalism. Serbia wanted to be separate and decide its own future based on its own ethnic composition. But this would then give Kosovo encouragement to become independent from Serbia. Albanians in Kosovo were already independent from Kosovo. Serbia didn't want to let Kosovo become independent. Muslims nationalists wanted their own territory but it would require a redrawing of the map, and would threaten neighboring territories. When communism fell in Yugoslavia, serious conflict arose, which led to the rise in extreme nationalism.
",2
1357,"Nationalism again gave rise to powerful emotions which evoked in some extreme cases, a willingness to die for what you believe in, a fight for the survival of the group.[94] The end of communism began a long period of conflict and war for the region. In the six years following the collapse 200,000-500-000 people died in the Bosnian war.[98] Bosnian Muslims suffered at the hands of the Serbs and Croats.[96] The war garnered assistance from groups; Muslim, Orthodox and Western Christian as well as state actors who supplied all sides; Saudi Arabia and Iran supported Bosnia, Russia supported Serbia, Central European and Western countries including the U.S. supported Croatia, and the Pope supported Slovenia and Croatia.
",2
1358,"Arab nationalism began to decline in the 21st century leading to localized nationalism, culminating in a series of revolts against authoritarian regimes between 2010 and 2012, known as the Arab Spring. Following these revolts, which mostly failed to improve conditions in the affected nations, Arab nationalism and even most local nationalistic movements declined dramatically.[99] A consequence of the Arab Spring as well as the 2003 invasion of Iraq were the civil wars in Iraq and Syria, which eventually joined to form a single conflict. However, a new form of Arab nationalism has developed in the wake of the Arab Winter, embodied by Egyptian President Abdel Fatteh el-Sisi, Saudi Crown Prince Mohammad bin Salman and UAE leader Mohammed bin Zayed.
",2
1359,"The rise of globalism in the late 20th century led to a rise in nationalism and populism in Europe and North America. This trend was further fueled by increased terrorism in the West (the September 11 attacks in the United States being a prime example), increasing unrest and civil wars in the Middle East, and waves of Muslim refugees flooding into Europe (as of 2016[update] the refugee crisis appears to have peaked).[100][101] Nationalist groups like Germany's Pegida, France's National Front and the UK Independence Party gained prominence in their respective nations advocating restrictions on immigration to protect the local populations.[102][103]
",2
1360,"Since 2010, Catalan nationalists have led a renewed Catalan independence movement and declared Catalonia's independence. The movement has been opposed by Spanish nationalists.[104][105] In the 2010s, the Greek economic crisis and waves of immigration have led to a significant rise of Fascism and Greek nationalism across Greece, especially among the youth.[106]
",2
1361,"In Russia, exploitation of nationalist sentiments allowed Vladimir Putin to consolidate power.[107] This nationalist sentiment was used in Russia's annexation of Crimea in 2014 and other actions in Ukraine.[103] Nationalist movements gradually began to rise in Central Europe as well, particularly Poland, under the influence of the ruling party, Law and Justice (led by Jaroslaw Kaczynski).[108] In Hungary, the anti-immigration rhetoric and stance against foreign influence is a powerful national glue promoted the ruling Fidesz party (led by Viktor Orbán).[109] Nationalist parties have also joined governing coalitions in Bulgaria,[110] Slovakia,[111] Latvia[112] and Ukraine.[113]
",2
1362,"In India, Hindu nationalism has grown extremely popular with the rise of the Bharatiya Janata Party, a right-wing Hindu nationalist party which has been ruling India at the national level since 2014.[114][115] The rise in religious nationalism comes with the rise of right-wing populism in India, with the election and re-election of populist leader Narendra Modi as Prime Minister, who promised economic prosperity for all and an end to corruption. In 2013, Modi declared himself to be a Hindu nationalist.[116] The BJP rule in India is characterized by religious nationalism, the persecution of religious minorities, the erosion of civil liberties as well as an authoritarian shift in governance. [117] [118] [119] Militant Buddhist nationalism is also on the rise in Myanmar, Thailand and Sri Lanka.[120][121]
",2
1363,"In Japan, nationalist influences in the government developed over the course of the early 21 century, thanks in large part to the Nippon Kaigi organization. The new movement has advocated re-establishing Japan as a military power and revising historical narratives to support the notion of a moral and strong Japan.[122][123]
",2
1364,"A referendum on Scottish independence from the United Kingdom was held on 18 September 2014. The proposal was defeated, with 55.3% voting against independence. In a 2016 referendum, the British populace voted to withdraw the United Kingdom from the European Union (the so-called Brexit). The result had been largely unexpected and was seen as a victory of populism. As the promise of continued European Union membership was a core feature of the anti-independence campaign during the Scottish referendum, the months since the EU Referendum vote have seen renewed calls for a second referendum on Scottish independence.
",2
1365,"The 2016 United States presidential campaign saw the unprecedented rise of Donald Trump, a businessman with no political experience who ran on a populist/nationalist platform and struggled to gain endorsements from mainstream political figures, even within his own party. Trump's slogans ""Make America Great Again"" and ""America First"" exemplified his campaign's repudiation of globalism and its staunchly nationalistic outlook. His unexpected victory in the election was seen as part of the same trend that had brought about the Brexit vote.[124] On 22 October 2018, two weeks before the mid-term elections President Trump openly proclaimed that he was a nationalist to a cheering crowd at a rally in Texas in support of re-electing Sen. Ted Cruz who was once an adversary.[125] On 29 October 2018 he equated nationalism to patriotism, saying ""I'm proud of this country and I call that 'nationalism.'""[126]
",2
1366,"In 2016, Rodrigo Duterte became president of the Philippines running a distinctly nationalist campaign. Contrary to the policies of his recent predecessors, he distanced the country from the Philippines' former ruler, the United States, and sought closer ties with China (as well as Russia).[127]
",2
1367,"In 2017, Turkish nationalism propelled President Recep Tayyip Erdoğan to gain unprecedented power in a national referendum.[128] Reactions from world leaders were mixed, with Western European leaders generally expressing concern while the leaders of many of the more authoritarian regimes as well as President Trump offered their congratulations.
",2
1368,"Many political scientists have theorized about the foundations of the modern nation-state and the concept of sovereignty. The concept of nationalism in political science draws from these theoretical foundations. Philosophers like Machiavelli, Locke, Hobbes, and Rousseau conceptualized the state as the result of a ""social contract"" between rulers and individuals.[129] Max Weber provides the most commonly used definition of the state, ""that human community which successfully lays claim to the monopoly of legitimate physical violence within a certain territory"".[130] According to Benedict Anderson, nations are ""Imagined Communities"", or socially constructed institutions.[131]
",2
1369,"Many scholars have noted the relationship between state-building, war, and nationalism. Many scholars believe that the development of nationalism in Europe and subsequently the modern nation-state was due to the threat of war. ""External threats have such a powerful effect on nationalism because people realize in a profound manner that they are under threat because of who they are as a nation; they are forced to recognize that it is only as a nation that they can successfully defeat the threat"".[132] With increased external threats, the state's extractive capacities increase. Jeffrey Herbst argues that the lack of external threats to countries in Sub-Saharan Africa, post-independence, is linked to weak state nationalism and state capacity.[132] Barry Posen argues that nationalism increases the intensity of war, and that states deliberately promote nationalism with the aim of improving their military capabilities.[133]
",2
1370,"It has also been observed that nationalist parties benefit from the ability to diversify from niche positions under electoral systems based on proportional representation.[134]
",2
1371,"The sociological or modernist interpretation of nationalism and nation-building argues that nationalism arises and flourishes in modern societies that have an industrial economy capable of self-sustainability, a central supreme authority capable of maintaining authority and unity, and a centralized language understood by a community of people.[135] Modernist theorists note that this is only possible in modern societies, while traditional societies typically lack the prerequisites for nationalism. They lack a modern self-sustainable economy, have divided authorities, and use multiple languages resulting in many groups being unable to communicate with each other.[135]
",2
1372,"Prominent theorists who developed the modernist interpretation of nations and nationalism include: Carlton J. H. Hayes, Henry Maine, Ferdinand Tönnies, Rabindranath Tagore, Émile Durkheim, Max Weber, Arnold Joseph Toynbee and Talcott Parsons.[135]
",2
1373,"In his analysis of the historical changes and development of human societies, Henry Maine noted that the key distinction between traditional societies defined as ""status"" societies based on family association and functionally diffuse roles for individuals and modern societies defined as ""contract"" societies where social relations are determined by rational contracts pursued by individuals to advance their interests. Maine saw the development of societies as moving away from traditional status societies to modern contract societies.[136]
",2
1374,"In his book Gemeinschaft und Gesellschaft (1887), Ferdinand Tönnies defined a Gemeinschaft (""community"") as being based on emotional attachments as attributed with traditional societies while defining a Gesellschaft (""society"") as an impersonal society that is modern. Although he recognized the advantages of modern societies, he also criticized them for their cold and impersonal nature that caused alienation while praising the intimacy of traditional communities.[136]
",2
1375,"Émile Durkheim expanded upon Tönnies' recognition of alienation, and defined the differences between traditional and modern societies as being between societies based upon ""mechanical solidarity"" versus societies based on ""organic solidarity"".[136] Durkheim identified mechanical solidarity as involving custom, habit, and repression that was necessary to maintain shared views. Durkheim identified organic solidarity-based societies as modern societies where there exists a division of labour based on social differentiation that causes alienation. Durkheim claimed that social integration in traditional society required authoritarian culture involving acceptance of a social order. Durkheim claimed that modern society bases integration on the mutual benefits of the division of labour, but noted that the impersonal character of modern urban life caused alienation and feelings of anomie.[136]
",2
1376,"Max Weber claimed the change that developed modern society and nations is the result of the rise of a charismatic leader to power in a society who creates a new tradition or a rational-legal system that establishes the supreme authority of the state. Weber's conception of charismatic authority has been noted as the basis of many nationalist governments.[136]
",2
1377,"Another approach emerging from biology and psychology looks at long-term evolutionary forces that might lead to nationalism. The primordialist perspective is based upon evolutionary theory.[137][138]
",2
1378,"This approach has been popular with the general public but is typically rejected by experts. Laland and Brown report that ""the vast majority of professional academics in the social sciences not only ... ignore evolutionary methods but in many cases [are] extremely hostile to the arguments"" that draw vast generalizations from rather limited evidence.[139]
",2
1379,"The evolutionary theory of nationalism perceives nationalism to be the result of the evolution of human beings into identifying with groups, such as ethnic groups, or other groups that form the foundation of a nation.[137] Roger Masters in The Nature of Politics describes the primordial explanation of the origin of ethnic and national groups as recognizing group attachments that are thought to be unique, emotional, intense, and durable because they are based upon kinship and promoted along lines of common ancestry.[140]
",2
1380,"The primordialist evolutionary views of nationalism often reference the evolutionary theories of Charles Darwin as well as Social Darwinist views of the late nineteenth century. Thinkers like Herbert Spencer and Walter Bagehot reinterpreted Darwin's theory of natural selection ""often in ways inconsistent with Charles Darwin's theory of evolution"" by making unsupported claims of biological difference among groups, ethnicities, races, and nations.[141] Modern evolutionary sciences have distanced themselves from such views, but notions of long-term evolutionary change remain foundational to the work of evolutionary psychologists like John Tooby and Leda Cosmides.[142]
",2
1381,"Approached through the primordialist perspective, the example of seeing the mobilization of a foreign military force on the nation's borders may provoke members of a national group to unify and mobilize themselves in response.[143] There are proximate environments where individuals identify nonimmediate real or imagined situations in combination with immediate situations that make individuals confront a common situation of both subjective and objective components that affect their decisions.[144] As such proximate environments cause people to make decisions based on existing situations and anticipated situations.[144]
",2
1382,"Critics argue that primordial models relying on evolutionary psychology are based not on historical evidence but on assumptions of unobserved changes over thousands of years and assume stable genetic composition of the population living in a specific area, and are incapable of handling the contingencies that characterize every known historical process. Robert Hislope argues:
",2
1383,"[T]he articulation of cultural evolutionary theory represents theoretical progress over sociobiology, but its explanatory payoff remains limited due to the role of contingency in human affairs and the significance of non-evolutionary, proximate causal factors. While evolutionary theory undoubtedly elucidates the development of all organic life, it would seem to operate best at macro-levels of analysis, ""distal"" points of explanation, and from the perspective of the long-term. Hence, it is bound to display shortcomings at micro-level events that are highly contingent in nature.[145]",2
1384,"In 1920, English historian G. P. Gooch argued that ""[w]hile patriotism is as old as human association and has gradually widened its sphere from the clan and the tribe to the city and the state, nationalism as an operative principle and an articulate creed only made its appearance among the more complicated intellectual processes of the modern world.""[146]
",2
1385,"In The Communist Manifesto, Karl Marx and Friedrich Engels declared that ""the working men have no country"".[147]
",2
1386,"Vladimir Lenin supported the concept of self-determination.[148]
",2
1387,"Joseph Stalin's Marxism and the National Question (1913) declares that ""a nation is not a racial or tribal, but a historically constituted community of people;"" ""a nation is not a casual or ephemeral conglomeration, but a stable community of people""; ""a nation is formed only as a result of lengthy and systematic intercourse, as a result of people living together generation after generation""; and, in its entirety: ""a nation is a historically constituted, stable community of people, formed on the basis of a common language, territory, economic life, and psychological make-up manifested in a common culture.""[149]
",2
1388,"Historians, sociologists and anthropologists have debated different types of nationalism since at least the 1930s.[150] Generally, the most common way of classifying nationalism has been to describe movements as having either ""civic"" or ""ethnic"" nationalist characteristics. This distinction was popularized in the 1950s by Hans Kohn who described ""civic"" nationalism as ""Western"" and more democratic while depicting ""ethnic"" nationalism as ""Eastern"" and undemocratic.[151] Since the 1980s, however, scholars of nationalism have pointed out numerous flaws in this rigid division and proposed more specific classifications and numerous varieties.[152][153]
",2
1389,"Anti-colonial nationalism is an intellectual framework that preceded, accompanied and followed the process of decolonization in the mid-1900s. Benedict Anderson defined a nation as a socially constructed community that is co-created by individuals who imagine themselves as part of this group.[154] He points to the New World as the cite of nationalism, which is defined by its imagination of an ahistorical identity that negates colonialism by definition. 
",2
1390,"Anti-colonial independence movements in Africa and Asia in the 1900s were led by individuals who had a set of shared identities and imagined a homeland without external rule. Anderson argues that the racism often experienced as a result of colonial rule and attributed to nationalism is rather due to theories of class.[131]
",2
1391,"Gellner’s theory of nationalism argues that nationalism works for combining one culture or ethnicity in one state, which leads to that state’s success. For Gellner, nationalism is ethnic, and state political parties should reflect the ethnic majority in the state. This definition of nationalism also contributes to anti-colonial nationalism, if one conceives of anti-colonial movements to be movements consisting of one specific ethnic group against an outside ruling party.[155] Edward Said also saw nationalism as ethnic, at least in part, and argued that nationalist narratives often go hand in hand with racism, as communities define themselves in relation to the other.[156]
",2
1392,"Anti-colonial nationalism is not static, and is defined by different forms of nationalism depending on location. In the anti-colonial movement that took place in the Indian subcontinent, Mahatma Gandhi  and his allies argued for a composite nationalism, not believing that nation should be defined by religious identity.[157] Because of the British policies of divide and rule, they fomented divisions between groups that had never before been divided along those lines. However, Pakistan and India were partitioned on religious lines after independence, and those not within majority religious groups living in both countries continue to experience discrimination as a result. 
",2
1393,"Because of colonialism’s creation of state and country lines across ethnic, religious, linguistic and other historical boundaries, anti-colonial nationalism is largely related to land first. After independence, especially in countries with particularly diverse populations with historic enmity, there have been a series of smaller independence movements that are also defined by anti-colonialisms.
",2
1394,"Philosopher and scholar Achille Mbembe argues that post-colonialism is a contradictory term, because colonialism is ever present.[158] Those that participate in this intellectual practice envision a post-colonialism despite its being the defining frame for the world. This is the case with anti-colonialism as well. Anti-colonial nationalism as an intellectual framework persisted into the late 20th century with the resistance movements in Soviet satellite states, and continues with independence movements in the Arab world in the 21st century. It is also one of the defining factors of stateless nationalism in Turkey, Morocco and Palestine.  
",2
1395,"Civic nationalism defines the nation as an association of people who identify themselves as belonging to the nation, who have equal and shared political rights, and allegiance to similar political procedures.[159] According to the principles of civic nationalism, the nation is not based on common ethnic ancestry, but is a political entity whose core identity is not ethnicity. This civic concept of nationalism is exemplified by Ernest Renan in his lecture in 1882 ""What is a Nation?"", where he defined the nation as a ""daily referendum"" (frequently translated ""daily plebiscite"") dependent on the will of its people to continue living together.[159]
",2
1396,"Civic nationalism is normally associated with liberal nationalism, although the two are distinct, and did not always coincide. On the one hand, until the late 19th and early 20th century adherents to anti-Enlightenment movements such as French Legitimism or Spanish Carlism often rejected the liberal, national unitary state, yet identified themselves not with an ethnic nation but with a non-national dynasty and regional feudal privileges. Xenophobic movements in long-established Western European states indeed often took a 'civic national' form, rejecting a given group's ability to assimilate with the nation due to its belonging to a cross-border community (Irish Catholics in Britain, Ashkenazic Jews in France). On the other hand, while subnational separatist movements were commonly associated with ethnic nationalism, this was not always so, and such nationalists as the Corsican Republic, United Irishmen, Breton Federalist League or Catalan Republican Party could combine a rejection of the unitary civic-national state with a belief in liberal universalism.
",2
1397,"Liberal nationalism is kind of non-xenophobic nationalism that is claimed to be compatible with liberal values of freedom, tolerance, equality, and individual rights.[160][161][162] Ernest Renan[163] and John Stuart Mill[164] are often thought to be early liberal nationalists. Liberal nationalists often defend the value of national identity by saying that individuals need a national identity to lead meaningful, autonomous lives,[165][166] and that liberal democratic polities need national identity to function properly.[167][168]
",2
1398,"Civic nationalism lies within the traditions of rationalism and liberalism, but as a form of nationalism it is usually contrasted with ethnic nationalism. Civic nationalism is correlated with long-established states whose dynastic rulers had gradually acquired multiple distinct territories, with little change to boundaries, but which contained historical populations of multiple linguistic and/or confessional backgrounds. Since individuals resident within different parts of the state territory might have little obvious common ground, civic nationalism developed as a way for rulers to both explain a contemporary reason for such heterogeneity and to provide a common purpose (Ernest Renan's classic description in What is a Nation? (1882) as a voluntary partnership for a common endeavour). Renan argued that factors such as ethnicity, language, religion, economics, geography, ruling dynasty and historic military deeds were important but not sufficient. Needed was a spiritual soul that allowed as a ""daily referendum"" among the people.[169] Civic-national ideals influenced the development of representative democracy in multiethnic countries such as the United States and France, as well as in constitutional monarchies such as Great Britain, Belgium and Spain.[51]
",2
1399,"German philosopher Monika Kirloskar-Steinbach does not think liberalism and nationalism are compatible, but she points out there are many liberals who think they are. Kirloskar-Steinbach states:
",2
1400,"Justifications of nationalism seem to be making a headway in political philosophy. Its proponents contend that liberalism and nationalism are not necessarily mutually exclusive and that they can in fact be made compatible. Liberal nationalists urge one to consider nationalism not as the pathology of modernity but as an answer to its malaise. For them, nationalism is more than an infantile disease, more than ""the measles of mankind"" as Einstein once proclaimed it to be. They argue that nationalism is a legitimate way of understanding one's role and place in life. They strive for a normative justification of nationalism which lies within liberal limits. The main claim which seems to be involved here is that as long as a nationalism abhors violence and propagates liberal rights and equal citizenship for all citizens of its state, its philosophical credentials can be considered to be sound.[170]",2
1401,"Creole nationalism is the ideology that emerged in independence movements among the creoles (descendants of the colonizers), especially in Latin America in the early 19th century. It was facilitated when French Emperor Napoleon seized control of Spain and Portugal, breaking the chain of control from the Spanish and Portuguese kings to the local governors. Allegiance to the Napoleonic states was rejected, and increasingly the creoles demanded independence. They achieved it after civil wars 1808–1826.[171]
",2
1402,"Ethnic nationalism, also known as ethno-nationalism, is a form of nationalism wherein the ""nation"" is defined in terms of ethnicity.[172] The central theme of ethnic nationalists is that ""nations are defined by a shared heritage, which usually includes a common language, a common faith, and a common ethnic ancestry"".[173] It also includes ideas of a culture shared between members of the group, and with their ancestors. However, it is different from a purely cultural definition of ""the nation,"" which allows people to become members of a nation by cultural assimilation; and from a purely linguistic definition, according to which ""the nation"" consists of all speakers of a specific language.
",2
1403,"Whereas nationalism in and of itself does not imply a belief in the superiority of one ethnicity or country over others, some nationalists support ethnocentric supremacy or protectionism.
",2
1404,"The humiliation of being a second-class citizen led regional minorities in multiethnic states, such as Great Britain, Spain, France, Germany, Russia and the Ottoman Empire, to define nationalism in terms of loyalty to their minority culture, especially language and religion. Forced assimilation was anathema.[174]
",2
1405,"For the politically dominant cultural group, assimilation was necessary to minimize disloyalty and treason and therefore became a major component of nationalism. A second factor for the politically dominant group was competition with neighboring states—nationalism involved a rivalry, especially in terms of military prowess and economic strength.[175]
",2
1406,"Economic nationalism, or economic patriotism, is an ideology that favors state interventionism in the economy, with policies that emphasize domestic control of the economy, labor, and capital formation, even if this requires the imposition of tariffs and other restrictions on the movement of labor, goods and capital.
",2
1407,"Feminist critique interprets nationalism as a mechanism through which sexual control and repression are justified and legitimised, often by a dominant masculine power. The gendering of nationalism through socially constructed notions of masculinity and femininity not only shapes what masculine and feminine participation in the building of that nation will look like, but also how the nation will be imagined by nationalists.[176] A nation having its own identity is viewed as necessary, and often inevitable, and these identities are gendered.[177] The physical land itself is often gendered as female (i.e. ""Motherland""), with a body in constant danger of violation by foreign males, while national pride and protectiveness of ""her"" borders is gendered as masculine.[178]
",2
1408,"History, political ideologies, and religions place most nations along a continuum of muscular nationalism.[177] Muscular nationalism conceptualises a nation's identity as being derived from muscular or masculine attributes that are unique to a particular country.[177] If definitions of nationalism and gender are understood as socially and culturally constructed, the two may be constructed in conjunction by invoking an ""us"" versus ""them"" dichotomy for the purpose of the exclusion of the so-called ""other,"" who is used to reinforce the unifying ties of the nation.[176] The empowerment of one gender, nation or sexuality tends to occur at the expense and disempowerment of another; in this way, nationalism can be used as an instrument to perpetuate heteronormative structures of power.[179] The gendered manner in which dominant nationalism has been imagined in most states in the world has had important implications on not only individual's lived experience, but on international relations.[180] Colonialism is heavily connected to muscular nationalism, from research linking British hegemonic masculinity and empire-building,[176] to intersectional oppression being justified by colonialist images of “others”, a practice integral in the formation of Western identity.[181] This “othering” may come in the form of orientalism, whereby the East is feminized and sexualized by the West. The imagined feminine East, or “other,” exists in contrast to the masculine West.
",2
1409,"The status of conquered nations can become a causality dilemma: the nation was “conquered because they were effeminate and seen as effeminate because they were conquered.”[176] In defeat they are considered militaristically unskilled, not aggressive, and thus not muscular. In order for a nation to be considered “proper”, it must possess the male-gendered characteristics of virility, as opposed to the stereotypically female characteristics of subservience and dependency.[177] Muscular nationalism is often inseparable from the concept of a warrior, which shares ideological commonalities across many nations; they are defined by the masculine notions of aggression, willingness to engage in war, decisiveness, and muscular strength, as opposed to the feminine notions of peacefulness, weakness, non-violence, and compassion.[176] This masculinized image of a warrior has been theorised to be “the culmination of a series of gendered historical and social processes"" played out in a national and international context.[176] Ideas of cultural dualism—of a martial man and chaste woman—which are implicit in muscular nationalism, underline the raced, classed, gendered, and heteronormative nature of dominant national identity.[177]
",2
1410,"Nations and gender systems are mutually supportive constructions: the nation fulfils the masculine ideals of comradeship and brotherhood.[182] Masculinity has been cited as a notable factor in producing political militancy.[182] A common feature of national crisis is a drastic shift in the socially acceptable ways of being a man,[183] which then helps to shape the gendered perception of the nation as a whole.
",2
1411,"There are different types of nationalism including Risorgimento nationalism and Integral nationalism.[184][185] Whereas risorgimento nationalism applies to a nation seeking to establish a liberal state (for example the Risorgimento in Italy and similar movements in Greece, Germany, Poland during the 19th century or the civic American nationalism), integral nationalism results after a nation has achieved independence and has established a state. Fascist Italy and Nazi Germany, according to Alter and Brown, were examples of integral nationalism.
",2
1412,"Some of the qualities that characterize integral nationalism are anti-individualism, statism, radical extremism, and aggressive-expansionist militarism. The term Integral Nationalism often overlaps with fascism, although many natural points of disagreement exist. Integral nationalism arises in countries where a strong military ethos has become entrenched through the independence struggle, when, once independence is achieved, it is believed that a strong military is required to ensure the security and viability of the new state. Also, the success of such a liberation struggle results in feelings of national superiority that may lead to extreme nationalism.
",2
1413,"Pan-nationalism is unique in that it covers a large area span. Pan-nationalism focuses more on ""clusters"" of ethnic groups. Pan-Slavism is one example of Pan-nationalism. The goal is to unite all Slavic people into one country. They did succeed by uniting several south Slavic people into Yugoslavia in 1918.[186]
",2
1414,"Left-wing nationalism, occasionally known as socialist nationalism, not to be confused with the German fascist National Socialism,[187] is a political movement that combines left-wing politics with nationalism.
",2
1415,"Many nationalist movements are dedicated to national liberation, in the view that their nations are being persecuted by other nations and thus need to exercise self-determination by liberating themselves from the accused persecutors. Anti-revisionist Marxist–Leninism is closely tied with this ideology, and practical examples include Stalin's early work Marxism and the National Question and his socialism in one country edict, which declares that nationalism can be used in an internationalist context, fighting for national liberation without racial or religious divisions.
",2
1416,"Other examples of left-wing nationalism include Fidel Castro's 26th of July Movement that launched the Cuban Revolution in 1959, Cornwall's Mebyon Kernow, Ireland's Sinn Féin, Wales's Plaid Cymru, the Awami League in Bangladesh, the African National Congress in South Africa and numerous movements in Eastern Europe.[188][189]
",2
1417,"Among the first advocates of national-anarchism were Hans Cany, Peter Töpfer and former National Front activist Troy Southgate, founder of the National Revolutionary Faction, a since disbanded British-based organization which cultivated links to certain far-left and far-right circles in the United Kingdom and in post-Soviet states, not to be confused with the national-anarchism of the Black Ram Group.[190][191][192] In the United Kingdom, national-anarchists worked with Albion Awake, Alternative Green (published by former Green Anarchist editor Richard Hunt) and Jonathan Boulter to develop the Anarchist Heretics Fair.[191] Those national-anarchists cite their influences primarily from Mikhail Bakunin, William Godwin, Peter Kropotkin, Pierre-Joseph Proudhon, Max Stirner and Leo Tolstoy.[190]
",2
1418,"A position developed in Europe during the 1990s, national-anarchist groups have seen arisen worldwide, most prominently in Australia (New Right Australia/New Zealand), Germany (International National Anarchism) and the United States (BANA).[191][192] National-anarchism has been described as a radical right-wing[193][194][195] nationalist ideology which advocates racial separatism and white racial purity.[190][191][192] National-anarchists claim to syncretize neotribal ethnic nationalism with philosophical anarchism, mainly in their support for a stateless society whilst rejecting anarchist social philosophy.[190][191][192] The main ideological innovation of national-anarchism is its anti-state palingenetic ultranationalism.[193] National-anarchists advocate homogeneous communities in place of the nation state. National-anarchists claim that those of different ethnic or racial groups would be free to develop separately in their own tribal communes while striving to be politically meritocratic, economically non-capitalist, ecologically sustainable and socially and culturally traditional.[190][192]
",2
1419,"Although the term national-anarchism dates back as far as the 1920s, the contemporary national-anarchist movement has been put forward since the late 1990s by British political activist Troy Southgate, who positions it as being ""beyond left and right"".[190] The few scholars who have studied national-anarchism conclude that it represents a further evolution in the thinking of the radical right rather than an entirely new dimension on the political spectrum.[193][194][195] National-anarchism is considered by anarchists as being a rebranding of totalitarian fascism and an oxymoron due to the inherent contradiction of anarchist philosophy of anti-fascism, abolition of unjustified hierarchy, dismantling of national borders and universal equality between different nationalities as being incompatible with the idea of a synthesis between anarchism and fascism.[192][196]
",2
1420,"National-anarchism has elicited skepticism and outright hostility from both left-wing and far-right critics.[191][192] Critics, including scholars, accuse national-anarchists of being nothing more than white nationalists who promote a communitarian and racialist form of ethnic and racial separatism while wanting the militant chic of calling themselves anarchists without the historical and philosophical baggage that accompanies such a claim, including the anti-racist egalitarian anarchist philosophy and the contributions of Jewish anarchists.[191][192] Some scholars are skeptical that implementing national-anarchism would result in an expansion of freedom and describe it as an authoritarian anti-statism that would result in authoritarianism and oppression, only on a smaller scale.[197]
",2
1421,"Nativist nationalism is a type of nationalism similar to creole or territorial types of nationalism, but which defines belonging to a nation solely by being born on its territory. In countries where strong nativist nationalism exists, people who were not born in the country are seen as lesser nationals than those who were born there and are called immigrants even if they became naturalized. It is cultural as people will never see a foreign-born person as one of them and is legal as such people are banned for life from holding certain jobs, especially government jobs. In scholarly studies, nativism is a standard technical term, although those who hold this political view do not typically accept the label. ""[N]ativists . . . do not consider themselves nativists. For them it is a negative term and they rather consider themselves as 'Patriots'.""[198]
",2
1422,"Racial nationalism is an ideology that advocates a racial definition of national identity. Racial nationalism seeks to preserve a given race through policies such as banning race mixing and the immigration of other races. Specific examples are black nationalism and white nationalism.
",2
1423,"Religious nationalism is the relationship of nationalism to a particular religious belief, dogma, or affiliation where a shared religion can be seen to contribute to a sense of national unity, a common bond among the citizens of the nation. Saudi Arabian, Iranian, Egyptian, Iraqi, Indian and the Pakistani-Islamic nationalism (Two-Nation Theory) are some examples.
",2
1424,"
Some nationalists exclude certain groups. Some nationalists, defining the national community in ethnic, linguistic, cultural, historic, or religious terms (or a combination of these), may then seek to deem certain minorities as not truly being a part of the 'national community' as they define it. Sometimes a mythic homeland is more important for the national identity than the actual territory occupied by the nation.[199]",2
1425,"Territorial nationalists assume that all inhabitants of a particular nation owe allegiance to their country of birth or adoption.[200] A sacred quality is sought in the nation and in the popular memories it evokes. Citizenship is idealized by territorial nationalists. A criterion of a territorial nationalism is the establishment of a mass, public culture based on common values, codes and traditions of the population.[201]
",2
1426,"Sport spectacles like football's World Cup command worldwide audiences as nations battle for supremacy and the fans invest intense support for their national team. Increasingly people have tied their loyalties and even their cultural identity to national teams.[202] The globalization of audiences through television and other media has generated revenues from advertisers and subscribers in the billions of dollars, as the FIFA Scandals of 2015 revealed.[203] Jeff Kingston looks at football, the Commonwealth Games, baseball, cricket, and the Olympics and finds that, ""The capacity of sports to ignite and amplify nationalist passions and prejudices is as extraordinary as is their power to console, unify, uplift and generate goodwill.""[204] The phenomenon is evident across most of the world.[205][206][207] The British Empire strongly emphasized sports among its soldiers and agents across the world, and often the locals joined in enthusiastically.[208] It established a high prestige competition in 1930, named the British Empire Games from 1930–50, the British Empire and Commonwealth Games from 1954–66, British Commonwealth Games from 1970–74 and since then the Commonwealth Games.[209]
",2
1427,"The French Empire was not far behind the British in the use of sports to strengthen colonial solidarity with France. Colonial officials promoted and subsidized gymnastics, table games, and dance and helped football spread to French colonies.[210]
",2
1428,"Critics of nationalism have argued that it is often unclear what constitutes a nation, or whether a nation is a legitimate unit of political rule. Nationalists hold that the boundaries of a nation and a state should coincide with one another, thus nationalism tends to oppose multiculturalism.[211] It can also lead to conflict when more than one national group finds itself claiming rights to a particular territory or seeking to take control of the state.[4]
",2
1429,"Philosopher A. C. Grayling describes nations as artificial constructs, ""their boundaries drawn in the blood of past wars"". He argues that ""there is no country on earth which is not home to more than one different but usually coexisting culture. Cultural heritage is not the same thing as national identity"".[212]
",2
1430,"Nationalism is inherently divisive because it highlights perceived differences between people, emphasizing an individual's identification with their own nation. The idea is also potentially oppressive because it submerges individual identity within a national whole and gives elites or political leaders potential opportunities to manipulate or control the masses.[213] Much of the early opposition to nationalism was related to its geopolitical ideal of a separate state for every nation. The classic nationalist movements of the 19th century rejected the very existence of the multi-ethnic empires in Europe. However, even in that early stage there was an ideological critique of nationalism which has developed into several forms of internationalism and anti-nationalism. The Islamic revival of the 20th century also produced an Islamist critique of the nation-state. (see Pan-Islamism)[214]
",2
1431,"At the end of the 19th century, Marxists and other socialists and communists (such as Rosa Luxemburg) produced political analyses that were critical of the nationalist movements then active in Central and Eastern Europe, although a variety of other contemporary socialists and communists, from Vladimir Lenin (a communist) to Józef Piłsudski (a socialist), were more sympathetic to national self-determination.[215]
",2
1432,"In his classic essay on the topic, George Orwell distinguishes nationalism from patriotism which he defines as devotion to a particular place. More abstractly, nationalism is ""power-hunger tempered by self-deception"".[216] For Orwell, the nationalist is more likely than not dominated by irrational negative impulses:
",2
1433,"There are, for example, Trotskyists who have become simply enemies of the U.S.S.R. without developing a corresponding loyalty to any other unit. When one grasps the implications of this, the nature of what I mean by nationalism becomes a good deal clearer. A nationalist is one who thinks solely, or mainly, in terms of competitive prestige. He may be a positive or a negative nationalist—that is, he may use his mental energy either in boosting or in denigrating—but at any rate his thoughts always turn on victories, defeats, triumphs and humiliations. He sees history, especially contemporary history, as the endless rise and decline of great power units and every event that happens seems to him a demonstration that his own side is on the upgrade and some hated rival is on the downgrade. But finally, it is important not to confuse nationalism with mere worship of success. The nationalist does not go on the principle of simply ganging up with the strongest side. On the contrary, having picked his side, he persuades himself that it is the strongest and is able to stick to his belief even when the facts are overwhelmingly against him.[216]",2
1434,"In the liberal political tradition there was mostly a negative attitude toward nationalism as a dangerous force and a cause of conflict and war between nation-states. The historian Lord Acton put the case for ""nationalism as insanity"" in 1862. He argued that nationalism suppresses minorities, it places country above moral principles and especially it creates a dangerous individual attachment to the state. However, Acton opposed democracy and was trying to defend the pope from Italian nationalism.[217] Since the late 20th century, liberals have been increasingly divided, with some philosophers such as Michael Walzer, Isaiah Berlin, Charles Taylor and David Miller emphasizing that a liberal society needed to be based in a stable nation state.[218]
",2
1435,"The pacifist critique of nationalism also concentrates on the violence of nationalist movements, the associated militarism, and on conflicts between nations inspired by jingoism or chauvinism. National symbols and patriotic assertiveness are in some countries discredited by their historical link with past wars, especially in Germany. British Socialist pacifist Bertrand Russell criticized nationalism for diminishing the individual's capacity to judge his or her fatherland's foreign policy.[219][220] Albert Einstein stated that ""Nationalism is an infantile disease. It is the measles of mankind"".[221]
",2
1436,"
",2
1437,"
",2
1438,"The Democratic Party is one of the two major contemporary political parties in the United States, along with its main, historic rival, the Republican Party. It was founded around 1828 by supporters of Andrew Jackson, making it the world's oldest active political party.[13]
",2
1439,"Before 1860, the party supported limited government and state sovereignty while opposing a national bank and high tariffs. It split in two in 1860 over slavery and won the presidency only twice between 1860 and 1910. In the late 19th century, it continued to oppose high tariffs and had bitter internal debates on the gold standard. In the early 20th century, it supported progressive reforms and opposed imperialism, with Woodrow Wilson winning the White House in 1912 and 1916. Since Franklin D. Roosevelt and his New Deal coalition after 1932, the Democratic Party has promoted a social liberal platform.[3][14] The New Deal attracted strong support for the party from recent European immigrants, many of whom were Catholics based in the cities, but caused a decline of the party's conservative pro-business wing.[15][16][17] Following the Civil Rights Act of 1964 and the Voting Rights Act of 1965, the core bases of the two parties shifted, with the Southern states becoming more reliably Republican in presidential politics and the Northeastern states becoming more reliably Democratic. The once-powerful labor union element became smaller after the 1970s, although the working class remains an important component of the Democratic base. Women, people living in urban areas, younger Americans, and college graduates, as well as sexual, religious, and racial minorities, also tend to support the Democratic Party.[18][19][20][21]
",2
1440,"The Democratic Party's philosophy of modern liberalism blends notions of civil liberty and social equality with support for a mixed economy.[22] In Congress, the party is a big-tent coalition with influential centrist, progressive, and conservative wings.[23] Corporate governance reform, environmental protection, support for organized labor, expansion of social programs, affordable college tuition, universal health care, equal opportunity, and consumer protection form the core of the party's economic agenda.[24][25] On social issues, it advocates campaign finance reform,[26] LGBT rights,[27] criminal justice and immigration reform,[28] stricter gun laws,[29] abortion rights,[30] and the legalization of marijuana.[31]
",2
1441,"Including the incumbent, Joe Biden, 16 Democrats have served as President of the United States. As of 2021, the party holds a federal government trifecta (the presidency and majorities in both the U.S. House and the U.S. Senate),[a] as well as 23 state governorships, 18 state legislatures, 15 state government trifectas (governorship and both legislative chambers), and the mayoralty of most major cities.[32] Three of the nine justices on the U.S. Supreme Court were appointed by Democratic presidents.
",2
1442,"Democratic Party officials often trace its origins to the Democratic-Republican Party, founded by Thomas Jefferson, James Madison and other influential opponents of the Federalists in 1792.[33] That party also inspired the Whigs and modern Republicans. Organizationally, the modern Democratic Party truly arose in the 1830s with the election of Andrew Jackson. Since the nomination of William Jennings Bryan in 1896, the party has generally positioned itself to the left of the Republican Party on economic issues. Democrats have been more liberal on civil rights since 1948, although conservative factions within the Democratic Party that opposed them persisted in the South until the 1960s. On foreign policy, both parties have changed position several times.[34]
",2
1443,"The Democratic Party evolved from the Jeffersonian Republican or Democratic-Republican Party organized by Jefferson and Madison in opposition to the Federalist Party. The Democratic-Republican Party favored republicanism; a weak federal government; states' rights; agrarian interests (especially Southern planters); and strict adherence to the Constitution. The party opposed a national bank and Great Britain.[35] After the War of 1812, the Federalists virtually disappeared and the only national political party left was the Democratic-Republicans, which was prone to splinter along regional lines. The era of one-party rule in the United States, known as the Era of Good Feelings, lasted from 1816 until 1828 when Andrew Jackson became president. Jackson and Martin Van Buren worked with allies in each state to form a new Democratic Party on a national basis. In the 1830s the rivals coalesced into the main rival to the Democrats.
",2
1444,"
The Democratic-Republican Party split over the choice of a successor to President James Monroe. The faction that supported many of the old Jeffersonian principles, led by Andrew Jackson and Martin Van Buren, became the modern Democratic Party.[36] As Norton explains the transformation in 1828: .mw-parser-output .templatequote{overflow:hidden;margin:1em 0;padding:0 40px}.mw-parser-output .templatequote .templatequotecite{line-height:1.5em;text-align:left;padding-left:1.6em;margin-top:0}",2
1445,"Jacksonians believed the people's will had finally prevailed. Through a lavishly financed coalition of state parties, political leaders, and newspaper editors, a popular movement had elected the president. The Democrats became the nation's first well-organized national party [...] and tight party organization became the hallmark of nineteenth-century American politics.[37]",2
1446,"
Behind the platforms issued by state and national parties stood a widely shared political outlook that characterized the Democrats: ",2
1447,"The Democrats represented a wide range of views but shared a fundamental commitment to the Jeffersonian concept of an agrarian society. They viewed the central government as the enemy of individual liberty. The 1824 ""corrupt bargain"" had strengthened their suspicion of Washington politics. [...] Jacksonians feared the concentration of economic and political power. They believed that government intervention in the economy benefited special-interest groups and created corporate monopolies that favored the rich. They sought to restore the independence of the individual—the artisan and the ordinary farmer—by ending federal support of banks and corporations and restricting the use of paper currency, which they distrusted. Their definition of the proper role of government tended to be negative, and Jackson's political power was largely expressed in negative acts. He exercised the veto more than all previous presidents combined. Jackson and his supporters also opposed reform as a movement. Reformers eager to turn their programs into legislation called for a more active government. But Democrats tended to oppose programs like educational reform mid the establishment of a public education system. They believed, for instance, that public schools restricted individual liberty by interfering with parental responsibility and undermined freedom of religion by replacing church schools. Nor did Jackson share reformers' humanitarian concerns. He had no sympathy for American Indians, initiating the removal of the Cherokees along the Trail of Tears.[38]",2
1448,"Opposing factions led by Henry Clay helped form the Whig Party. The Democratic Party had a small yet decisive advantage over the Whigs until the 1850s, when the Whigs fell apart over the issue of slavery. In 1854, angry with the Kansas–Nebraska Act, anti-slavery Democrats left the party and joined Northern Whigs to form the Republican Party.[39][40]
",2
1449,"The Democrats split over slavery, with Northern and Southern tickets in the election of 1860, in which the Republican Party gained ascendancy.[41] The radical pro-slavery Fire-Eaters led walkouts at the two conventions when the delegates would not adopt a resolution supporting the extension of slavery into territories even if the voters of those territories did not want it. These Southern Democrats nominated the pro-slavery incumbent Vice President, John C. Breckinridge of Kentucky, for President and General Joseph Lane, of Oregon, for vice president. The Northern Democrats nominated Senator Stephen A. Douglas of Illinois for president and former Georgia Governor Herschel V. Johnson for vice president.  This fracturing of the Democrats led to a Republican victory and Abraham Lincoln was elected the 16th President of the United States.[42]
",2
1450,"As the American Civil War broke out, Northern Democrats were divided into War Democrats and Peace Democrats. The Confederate States of America deliberately avoided organized political parties. Most War Democrats rallied to Republican President Abraham Lincoln and the Republicans' National Union Party in the election of 1864, which featured Andrew Johnson on the Union ticket to attract fellow Democrats. Johnson replaced Lincoln in 1865, but he stayed independent of both parties.[43]
",2
1451,"The Democrats benefited from white Southerners' resentment of Reconstruction after the war and consequent hostility to the Republican Party. After Redeemers ended Reconstruction in the 1870s and following the often extremely violent disenfranchisement of African Americans led by such white supremacist Democratic politicians as Benjamin Tillman of South Carolina in the 1880s and 1890s, the South, voting Democratic, became known as the ""Solid South."" Although Republicans won all but two presidential elections, the Democrats remained competitive. The party was dominated by pro-business Bourbon Democrats led by Samuel J. Tilden and Grover Cleveland, who represented mercantile, banking, and railroad interests; opposed imperialism and overseas expansion; fought for the gold standard; opposed bimetallism; and crusaded against corruption, high taxes and tariffs. Cleveland was elected to non-consecutive presidential terms in 1884 and 1892.[44]
",2
1452,"Agrarian Democrats demanding free silver, drawing on Populist ideas, overthrew the Bourbon Democrats in 1896 and nominated William Jennings Bryan for the presidency (a nomination repeated by Democrats in 1900 and 1908). Bryan waged a vigorous campaign attacking Eastern moneyed interests, but he lost to Republican William McKinley.[45]
",2
1453,"The Democrats took control of the House in 1910, and Woodrow Wilson won election as president in 1912 (when the Republicans split) and 1916. Wilson effectively led Congress to put to rest the issues of tariffs, money and antitrust, which had dominated politics for 40 years, with new progressive laws. He failed to secure Senate passage of the Versailles Treaty (ending the war with Germany and joining the League of Nations).[46] The weak party was deeply divided by issues such as the KKK and prohibition in the 1920s. However, it did organize new ethnic voters in Northern cities.[47]
",2
1454,"The Great Depression in 1929 that began under Republican President Herbert Hoover and the Republican Congress set the stage for a more liberal government as the Democrats controlled the House of Representatives nearly uninterrupted from 1930 until 1994, the Senate for 44 of 48 years from 1930, and won most presidential elections until 1968. Franklin D. Roosevelt, elected to the presidency in 1932, came forth with federal government programs called the New Deal. New Deal liberalism meant the regulation of business (especially finance and banking) and the promotion of labor unions as well as federal spending to aid the unemployed, help distressed farmers and undertake large-scale public works projects. It marked the start of the American welfare state.[48] The opponents, who stressed opposition to unions, support for business and low taxes, started calling themselves ""conservatives"".[49]
",2
1455,"Until the 1980s, the Democratic Party was a coalition of two parties divided by the Mason–Dixon line: liberal Democrats in the North and culturally conservative voters in the South, who though benefitting from many of the New Deal public works projects opposed increasing civil rights initiatives advocated by Northeastern liberals. The polarization grew stronger after Roosevelt died. Southern Democrats formed a key part of the bipartisan conservative coalition in an alliance with most of the Midwestern Republicans. The economically activist philosophy of Franklin D. Roosevelt, which has strongly influenced American liberalism, shaped much of the party's economic agenda after 1932.[50] From the 1930s to the mid-1960s, the liberal New Deal coalition usually controlled the presidency while the conservative coalition usually controlled Congress.[51]
",2
1456,"Issues facing parties and the United States after World War II included the Cold War and the civil rights movement. Republicans attracted conservatives and, after the 1960s, white Southerners from the Democratic coalition with their use of the Southern strategy and resistance to New Deal and Great Society liberalism. Until the 1950s, African Americans had traditionally supported the Republican Party because of its anti-slavery civil rights policies. Following the passage of the Civil Rights Act of 1964 and Voting Rights Act of 1965, the Southern states became more reliably Republican in presidential politics, while Northeastern states became more reliably Democratic.[52][53][54][55][56][57][58][59] Studies show that Southern whites, which were a core constituency in the Democratic Party, shifted to the Republican Party due to racial conservatism.[58][60][61]
",2
1457,"The election of President John F. Kennedy from Massachusetts in 1960 was a partial reflection of this shift. In the campaign, Kennedy attracted a new generation of younger voters. In his agenda dubbed the New Frontier, Kennedy introduced a host of social programs and public works projects, along with enhanced support of the space program, proposing a manned spacecraft trip to the moon by the end of the decade. He pushed for civil rights initiatives and proposed the Civil Rights Act of 1964, but with his assassination in November 1963, he was not able to see its passage.[62]
",2
1458,"Kennedy's successor Lyndon B. Johnson was able to persuade the largely conservative Congress to pass the Civil Rights Act of 1964 and with a more progressive Congress in 1965 passed much of the Great Society, which consisted of an array of social programs designed to help the poor. Kennedy and Johnson's advocacy of civil rights further solidified black support for the Democrats but had the effect of alienating Southern whites who would eventually gravitate toward the Republican Party, particularly after the election of Ronald Reagan to the presidency in 1980. The United States' involvement in the Vietnam War in the 1960s was another divisive issue that further fractured the fault lines of the Democrats' coalition. After the Gulf of Tonkin Resolution in 1964, President Johnson committed a large contingency of combat troops to Vietnam, but the escalation failed to drive the Viet Cong from South Vietnam, resulting in an increasing quagmire, which by 1968 had become the subject of widespread anti-war protests in the United States and elsewhere. With increasing casualties and nightly news reports bringing home troubling images from Vietnam, the costly military engagement became increasingly unpopular, alienating many of the kinds of young voters that the Democrats had attracted the early 1960s. The protests that year along with assassinations of Martin Luther King Jr. and Democratic presidential candidate Senator Robert F. Kennedy (younger brother of John F. Kennedy) climaxed in turbulence at the hotly-contested Democratic National Convention that summer in Chicago (which amongst the ensuing turmoil inside and outside of the convention hall nominated Vice President Hubert Humphrey) in a series of events that proved to mark a significant turning point in the decline of the Democratic Party's broad coalition.[63]
",2
1459,"Republican presidential nominee Richard Nixon was able to capitalize on the confusion of the Democrats that year, and won the 1968 election to become the 37th president. He won re-election in a landslide in 1972 against Democratic nominee George McGovern, who like Robert F. Kennedy, reached out to the younger anti-war and counterculture voters, but unlike Kennedy, was not able to appeal to the party's more traditional white working-class constituencies. During Nixon's second term, his presidency was rocked by the Watergate scandal, which forced him to resign in 1974. He was succeeded by vice president Gerald Ford, who served a brief tenure. Watergate offered the Democrats an opportunity to recoup, and their nominee Jimmy Carter won the 1976 presidential election. With the initial support of evangelical Christian voters in the South, Carter was temporarily able to reunite the disparate factions within the party, but inflation and the Iran Hostage Crisis of 1979–1980 took their toll, resulting in a landslide victory for Republican presidential nominee Ronald Reagan in 1980, which shifted the political landscape in favor of the Republicans for years to come.
",2
1460,"With the ascendancy of the Republicans under Ronald Reagan, the Democrats searched for ways to respond yet were unable to succeed by running traditional candidates, such as former vice president and Democratic presidential nominee Walter Mondale, who lost to Reagan in the 1984 presidential election. Many Democrats attached their hopes to the future star of Gary Hart, who had challenged Mondale in the 1984 primaries running on a theme of ""New Ideas""; and in the subsequent 1988 primaries became the de facto front-runner and virtual ""shoo-in"" for the Democratic presidential nomination before his campaign was ended by a sex scandal. The party nevertheless began to seek out a younger generation of leaders, who like Hart had been inspired by the pragmatic idealism of John F. Kennedy.[64]
",2
1461,"Arkansas governor Bill Clinton was one such figure, who was elected president in 1992 as the Democratic nominee. He labeled himself and governed as a ""New Democrat."" The party adopted a centrist economic yet socially progressive agenda, with the voter base after Reagan having shifted considerably to the right. In an effort to appeal both to liberals and to fiscal conservatives, Democrats began to advocate for a balanced budget and market economy tempered by government intervention (mixed economy), along with a continued emphasis on social justice and affirmative action. The economic policy adopted by the Democratic Party, including the former Clinton administration, has been referred to as ""Third Way."" The Democrats lost control of Congress in the election of 1994 to the Republican Party. Re-elected in 1996, Clinton was the first Democratic president since Franklin D. Roosevelt to be elected to two terms.[65]
",2
1462,"In the wake of the 2001 terrorist attacks on the World Trade Center and the Pentagon as well as the growing concern over global warming, some of the party's key issues in the early 21st century have included combating terrorism while preserving human rights, expanding access to health care, labor rights, and environmental protection. Democrats regained majority control of both the House and the Senate in the 2006 elections. Barack Obama won the Democratic Party's nomination and was elected as the first African American president in 2008. Under the Obama presidency, the party moved forward reforms including an economic stimulus package, the Dodd–Frank financial reform act, and the Affordable Care Act. In the 2010 elections, the Democratic Party lost control of the House and lost its majority in state legislatures and state governorships. In the 2012 elections, President Obama was re-elected, but the party remained in the minority in the House of Representatives and lost control of the Senate in 2014. After the 2016 election of Donald Trump, the Democratic Party transitioned into the role of an opposition party and held neither the presidency nor the Senate but won back a majority in the House in the 2018 midterm elections.[66] Democrats were extremely critical of President Trump, particularly his policies on immigration, healthcare, and abortion, as well as his response to the COVID-19 pandemic.[67][68][69]
",2
1463,"Based on a poll conducted in 2014, Gallup found that 30% of Americans identified as Democrats, 23% as Republicans, and 45% as independents.[70] In the same poll, a survey of registered voters stated that 47% identified as Democrats or leaned toward the party compared to 40% of registered voters who identified as or leaned toward the Republicans.
",2
1464,"In 2018, Democratic congressional candidate Tom Malinowski, who was later elected, described the party:
",2
1465,We're now the party of fiscal responsibility in America. We didn't just add $2 trillion to the national debt for that tax cut that Warren Buffett didn't want ... We're the party of law enforcement in America; we don't vilify the Federal Bureau of Investigation every single day. We're the party of family values. We don't ... take kids from their parents at the border. We're the party of patriotism in America that wants to defend this country against our foreign adversaries.,2
1466," In November 2020, Democrat Joe Biden won the 2020 presidential election.[72] He began his term with narrow Democratic majorities in the House and the Senate.[73][74]
",2
1467,"The Democratic-Republican Party splintered in 1824 into the short-lived National Republican Party and the Jacksonian movement which in 1828 became the Democratic Party. Under the Jacksonian era, the term ""The Democracy"" was in use by the party, but the name ""Democratic Party"" was eventually settled upon[75] and became the official name in 1844.[76] Members of the party are called ""Democrats"" or ""Dems"".
",2
1468,"The term ""Democrat Party"" has also been in local use, but has usually been used by opponents since 1952 as a disparaging term.
",2
1469,"The most common mascot symbol for the party has been the donkey, or jackass.[77] Andrew Jackson's enemies twisted his name to ""jackass"" as a term of ridicule regarding a stupid and stubborn animal. However, the Democrats liked the common-man implications and picked it up too, therefore the image persisted and evolved.[78] Its most lasting impression came from the cartoons of Thomas Nast from 1870 in Harper's Weekly. Cartoonists followed Nast and used the donkey to represent the Democrats and the elephant to represent the Republicans.
",2
1470,"In the early 20th century, the traditional symbol of the Democratic Party in Indiana, Kentucky, Oklahoma and Ohio was the rooster, as opposed to the Republican eagle. This symbol still appears on Oklahoma, Kentucky, Indiana, and West Virginia ballots.[79] The rooster was adopted as the official symbol of the national Democratic Party.[80] In New York, the Democratic ballot symbol is a five-pointed star.[81]
",2
1471,"Although both major political parties (and many minor ones) use the traditional American colors of red, white and blue in their marketing and representations, since election night 2000 blue has become the identifying color for the Democratic Party while red has become the identifying color for the Republican Party. That night, for the first time all major broadcast television networks used the same color scheme for the electoral map: blue states for Al Gore (Democratic nominee) and red states for George W. Bush (Republican nominee). Since then, the color blue has been widely used by the media to represent the party. This is contrary to common practice outside of the United States where blue is the traditional color of the right and red the color of the left.[82] For example, in Canada red represents the Liberals while blue represents the Conservatives. In the United Kingdom, red denotes the Labour Party and blue symbolizes the Conservative Party. Any use of the color blue to denote the Democratic Party prior to 2000 would be historically inaccurate and misleading. Since 2000, blue has also been used both by party supporters for promotional efforts—ActBlue, BuyBlue and BlueFund as examples—and by the party itself in 2006 both for its ""Red to Blue Program"", created to support Democratic candidates running against Republican incumbents in the midterm elections that year and on its official website.
",2
1472,"In September 2010, the Democratic Party unveiled its new logo, which featured a blue D inside a blue circle. It was the party's first official logo; the donkey logo had only been semi-official.
",2
1473,"Jefferson-Jackson Day is the annual fundraising event (dinner) held by Democratic Party organizations across the United States.[83] It is named after Presidents Thomas Jefferson and Andrew Jackson, whom the party regards as its distinguished early leaders.
",2
1474,"The song ""Happy Days Are Here Again"" is the unofficial song of the Democratic Party. It was used prominently when Franklin D. Roosevelt was nominated for president at the 1932 Democratic National Convention and remains a sentimental favorite for Democrats today. For example, Paul Shaffer played the theme on the Late Show with David Letterman after the Democrats won Congress in 2006. ""Don't Stop"" by Fleetwood Mac was adopted by Bill Clinton's presidential campaign in 1992 and has endured as a popular Democratic song. The emotionally similar song ""Beautiful Day"" by the band U2 has also become a favorite theme song for Democratic candidates. John Kerry used the song during his 2004 presidential campaign and several Democratic Congressional candidates used it as a celebratory tune in 2006.[84][85]
",2
1475,"The 2016 campaign of Democratic Party presidential candidate Bernie Sanders used the hopeful Simon & Garfunkel song ""America"" for one of its campaign advertisements,[86] with the complete permission of the still-active duo of popular American musicians.[87] As a traditional anthem for its presidential nominating convention, Aaron Copland's ""Fanfare for the Common Man"" is traditionally performed at the beginning of the Democratic National Convention.
",2
1476,"The Democratic National Committee (DNC) is responsible for promoting Democratic campaign activities. While the DNC is responsible for overseeing the process of writing the Democratic Platform, the DNC is more focused on campaign and organizational strategy than public policy. In presidential elections, it supervises the Democratic National Convention. The national convention is subject to the charter of the party and the ultimate authority within the Democratic Party when it is in session, with the DNC running the party's organization at other times. The DNC is chaired by Jaime Harrison.[88]
",2
1477,"Each state also has a state committee, made up of elected committee members as well as ex officio committee members (usually elected officials and representatives of major constituencies), which in turn elects a chair. County, town, city and ward committees generally are composed of individuals elected at the local level. State and local committees often coordinate campaign activities within their jurisdiction, oversee local conventions and in some cases primaries or caucuses and may have a role in nominating candidates for elected office under state law. Rarely do they have much funding, but in 2005 DNC Chairman Dean began a program (called the ""50 State Strategy"") of using DNC national funds to assist all state parties and pay for full-time professional staffers.[89]
",2
1478,"The Democratic Congressional Campaign Committee (DCCC) assists party candidates in House races and its current chairman (selected by the party caucus) is Representative Sean Patrick Maloney of New York. Similarly, the Democratic Senatorial Campaign Committee (DSCC), headed by Senator Gary Peters of Michigan, raises funds for Senate races. The Democratic Legislative Campaign Committee (DLCC), chaired by Majority Leader of the New York State Senate Andrea Stewart-Cousins, is a smaller organization that focuses on state legislative races. The DNC sponsors the College Democrats of America (CDA), a student-outreach organization with the goal of training and engaging a new generation of Democratic activists. Democrats Abroad is the organization for Americans living outside the United States and they work to advance the goals of the party and encourage Americans living abroad to support the Democrats. The Young Democrats of America (YDA) and the High School Democrats of America (HSDA) are young adult and youth-led organizations respectively that attempt to draw in and mobilize young people for Democratic candidates but operates outside of the DNC. The Democratic Governors Association (DGA) is an organization supporting the candidacies of Democratic gubernatorial nominees and incumbents. Likewise, the mayors of the largest cities and urban centers convene as the National Conference of Democratic Mayors.[90]
",2
1479,"Upon foundation, the Democratic Party supported agrarianism and the Jacksonian democracy movement of President Andrew Jackson, representing farmers and rural interests and traditional Jeffersonian democrats.[91] Since the 1890s, especially in northern states, the party began to favor more liberal positions (the term ""liberal"" in this sense describes modern liberalism, rather than classical liberalism or economic liberalism). In recent exit polls, the Democratic Party has had broad appeal across all socio-ethno-economic demographics.[92][93][94]
",2
1480,"Historically, the party has represented farmers, laborers, and religious and ethnic minorities as it has opposed unregulated business and finance and favored progressive income taxes. In foreign policy, internationalism (including interventionism) was a dominant theme from 1913 to the mid-1960s. In the 1930s, the party began advocating social programs targeted at the poor. The party had a fiscally conservative, pro-business wing, typified by Grover Cleveland and Al Smith, and a Southern conservative wing that shrank after President Lyndon B. Johnson supported the Civil Rights Act of 1964. The major influences for liberalism were labor unions (which peaked in the 1936–1952 era) and African Americans. Environmentalism has been a major component since the 1970s. The 21st century Democratic Party is predominantly a coalition of centrists, liberals, and progressives, with significant overlap between the three groups.[95]
",2
1481,"The Democratic Party, once dominant in the Southeastern United States, is now strongest in the Northeast (Mid-Atlantic and New England), the Great Lakes region, and the West Coast (including Hawaii). The party is also very strong in major cities (regardless of region).[96]
",2
1482,"Centrist Democrats, or New Democrats, are an ideologically centrist faction within the Democratic Party that emerged after the victory of Republican George H. W. Bush in the 1988 presidential election. They are an economically liberal and ""Third Way"" faction which dominated the party for around 20 years starting in the late 1980s after the United States populace turned much further to the political right. They are represented by organizations such as the New Democrat Network and the New Democrat Coalition. The New Democrat Coalition is a pro-growth and fiscally moderate congressional coalition.[97]
",2
1483,"One of the most influential centrist groups was the Democratic Leadership Council (DLC), a nonprofit organization that advocated centrist positions for the party. The DLC hailed President Bill Clinton as proof of the viability of ""Third Way"" politicians and a DLC success story. The DLC disbanded in 2011 and much of the former DLC is now represented in the think tank Third Way.[98]
",2
1484,"Some Democratic elected officials have self-declared as being centrists, including former President Bill Clinton, former Vice President Al Gore, Senator Mark Warner, former Pennsylvania governor Ed Rendell, former Senator Jim Webb, President Joe Biden, congresswoman Ann Kirkpatrick, and former congressman Dave McCurdy.[99][100]
",2
1485,"The New Democrat Network supports socially liberal and fiscally moderate Democratic politicians and is associated with the congressional New Democrat Coalition in the House.[101] Suzan DelBene is the chair of the coalition,[99] and former senator and 2016 Democratic presidential nominee Hillary Clinton was a member while in Congress.[102] In 2009, President Barack Obama was self-described as a New Democrat.[103]
",2
1486,"A conservative Democrat is a member of the Democratic Party with conservative political views, or with views relatively conservative with respect to those of the national party. While such members of the Democratic Party can be found throughout the nation, actual elected officials are disproportionately found within the Southern states and to a lesser extent within rural regions of the United States generally, more commonly in the West. Historically, Southern Democrats were generally much more ideologically conservative than conservative Democrats are now.
",2
1487,"Many conservative Southern Democrats defected to the Republican Party, beginning with the passage of the Civil Rights Act of 1964 and the general leftward shift of the party. Strom Thurmond of South Carolina, Billy Tauzin of Louisiana, Kent Hance and Ralph Hall of Texas and Richard Shelby of Alabama are examples of this. The influx of conservative Democrats into the Republican Party is often cited as a reason for the Republican Party's shift further to the right during the late 20th century as well as the shift of its base from the Northeast and Midwest to the South.
",2
1488,"Into the 1980s, the Democratic Party had a conservative element, mostly from the South and Border regions. Their numbers declined sharply as the Republican Party built up its Southern base. They were sometimes humorously called ""Yellow dog Democrats"", or ""boll weevils"" and ""Dixiecrats."" In the House, they form the Blue Dog Coalition, a caucus of conservatives and centrists willing to broker compromises with the Republican leadership. They have acted as a unified voting bloc in the past, giving its members some ability to change legislation, depending on their numbers in Congress.
",2
1489,"Split-ticket voting was common among conservative Southern Democrats in the 1970s and 1980s. These voters supported conservative Democrats for local and statewide office while simultaneously voting for Republican presidential candidates.[104]
",2
1490,"Social-liberals (modern liberals) are a large portion of the Democratic base. According to 2018 exit polls, liberals constituted 27% of the electorate, and 91% of American liberals favored the candidate of the Democratic Party.[105] White-collar college-educated professionals were mostly Republican until the 1950s, but they now compose a vital component of the Democratic Party.[106]
",2
1491,"A large majority of liberals favor moving toward universal health care, with many supporting an eventual gradual transition to a single-payer system in particular. A majority also favor diplomacy over military action, stem cell research, the legalization of same-sex marriage, stricter gun control and environmental protection laws as well as the preservation of abortion rights. Immigration and cultural diversity are deemed positive as liberals favor cultural pluralism, a system in which immigrants retain their native culture in addition to adopting their new culture. They tend to be divided on free trade agreements such as the North American Free Trade Agreement (NAFTA) and organizations, with some seeing them as more favorable to corporations than workers. Most liberals oppose increased military spending and the mixing of church and state.[107]
",2
1492,"This ideological group differs from the traditional organized labor base. According to the Pew Research Center, a plurality of 41% resided in mass affluent households and 49% were college graduates, the highest figure of any typographical group. It was also the fastest growing typological group between the late 1990s and early 2000s.[107] Liberals include most of academia[108] and large portions of the professional class.[92][93][94]
",2
1493,"Progressives are the most left-leaning faction in the party and support strong business regulations, social programs, and workers' rights.[109][110] Progressive ideological stances have much in common with the programs of European social-democratic parties. Many progressive Democrats are descendants of the New Left of Democratic presidential candidate Senator George McGovern of South Dakota whereas others were involved in the 2016 presidential candidacy of Vermont Senator Bernie Sanders. Progressives are often considered to be synonymous with liberals, though progressives are sometimes considered to show stronger support for universal health care, solutions for economic inequality, and environmental regulations.[111]
",2
1494,"In 2014, progressive Senator Elizabeth Warren set out ""Eleven Commandments of Progressivism"": tougher regulation on corporations, affordable education, scientific investment and environmentalism, net neutrality, increased wages, equal pay for women, collective bargaining rights, defending social programs, same-sex marriage, immigration reform, and unabridged access to reproductive healthcare.[112] In addition, progressives strongly oppose political corruption and seek to advance electoral reforms such as campaign finance rules and voting rights protections.[113] Today, many progressives have made combating economic inequality their top priority.[114]
",2
1495,"The Congressional Progressive Caucus (CPC) is a caucus of progressive Democrats chaired by Pramila Jayapal of Washington.[115] Its members have included Representatives Dennis Kucinich of Ohio, John Conyers of Michigan, Jim McDermott of Washington, John Lewis of Georgia, Barbara Lee of California, and Senator Paul Wellstone of Minnesota. Senators Sherrod Brown of Ohio, Tammy Baldwin of Wisconsin, Mazie Hirono of Hawaii, and Ed Markey of Massachusetts were members of the caucus when in the House of Representatives. While no Democratic Senators currently belong to the CPC, independent Senator Bernie Sanders is a member.[116]
",2
1496,"Equal economic opportunity, a social safety net, and strong labor unions have historically been at the heart of Democratic economic policy.[22] Democrats support a progressive tax system, higher minimum wages, Social Security, universal health care, public education, and subsidized housing.[22] They also support infrastructure development and clean energy investments to achieve economic development and job creation.[137] Since the 1990s, the party has at times supported centrist economic reforms that cut the size of government and reduced market regulations.[138] The party has generally rejected both laissez-faire economics and market socialism, instead favoring Keynesian economics within a capitalist market-based system.[139]
",2
1497,"Democrats support a more progressive tax structure to provide more services and reduce economic inequality by making sure that the wealthiest Americans pay the highest amount in taxes.[140] They oppose the cutting of social services, such as Social Security, Medicare, and Medicaid,[141] believing it to be harmful to efficiency and social justice. Democrats believe the benefits of social services in monetary and non-monetary terms are a more productive labor force and cultured population and believe that the benefits of this are greater than any benefits that could be derived from lower taxes, especially on top earners, or cuts to social services. Furthermore, Democrats see social services as essential toward providing positive freedom, freedom derived from economic opportunity. The Democratic-led House of Representatives reinstated the PAYGO (pay-as-you-go) budget rule at the start of the 110th Congress.[142]
",2
1498,"The Democratic Party favors raising the minimum wage. The Fair Minimum Wage Act of 2007 was an early component of the Democrats' agenda during the 110th Congress. In 2006, the Democrats supported six state ballot initiatives to increase the minimum wage and all six initiatives passed.[143]
",2
1499,"In 2017, Senate Democrats introduced the Raise the Wage Act which would raise the minimum wage to $15 an hour by 2024.[144] In 2021, Democratic president Joe Biden proposed increasing the minimum wage to $15 by 2025.[145]
",2
1500,"Democrats call for ""affordable and quality health care"" and favor moving toward universal health care in a variety of forms to address rising healthcare costs. Some Democratic politicians favor a single-payer program or Medicare for All, while others prefer creating a public health insurance option.[146]
",2
1501,"The Patient Protection and Affordable Care Act, signed into law by President Barack Obama on March 23, 2010, has been one of the most significant pushes for universal health care. As of December 2019, more than 20 million Americans have gained health insurance under the Affordable Care Act.[147]
",2
1502,"Democrats favor improving public education by raising school standards and reforming the Head Start program. They also support universal preschool and expanding access to primary education, including through charter schools. They call for addressing student loan debt and reforms to reduce college tuition.[148] Other proposals have included tuition-free public universities and reform of standardized testing. Democrats have the long-term aim of having publicly funded college education with low tuition fees (like in much of Europe and Canada), which would be available to every eligible American student. Alternatively, they encourage expanding access to post-secondary education by increasing state funding for student financial aid such as Pell Grants and college tuition tax deductions.[149]
",2
1503,"Democrats believe that the government should protect the environment and have a history of environmentalism. In more recent years, this stance has emphasized renewable energy generation as the basis for an improved economy, greater national security, and general environmental benefits.[151]
",2
1504,"The Democratic Party also favors expansion of conservation lands and encourages open space and rail travel to relieve highway and airport congestion and improve air quality and economy as it ""believe[s] that communities, environmental interests, and the government should work together to protect resources while ensuring the vitality of local economies. Once Americans were led to believe they had to make a choice between the economy and the environment. They now know this is a false choice"".[152]
",2
1505,"The foremost environmental concern of the Democratic Party is climate change. Democrats, most notably former Vice President Al Gore, have pressed for stern regulation of greenhouse gases. On October 15, 2007, Gore won the Nobel Peace Prize for his efforts to build greater knowledge about man-made climate change and laying the foundations for the measures needed to counteract it.[153]
",2
1506,"Democrats have supported increased domestic renewable energy development, including wind and solar power farms, in an effort to reduce carbon pollution. The party's platform calls for an ""all of the above"" energy policy including clean energy, natural gas and domestic oil, with the desire of becoming energy independent.[143] The party has supported higher taxes on oil companies and increased regulations on coal power plants, favoring a policy of reducing long-term reliance on fossil fuels.[154][155] Additionally, the party supports stricter fuel emissions standards to prevent air pollution.
",2
1507,"Many Democrats support fair trade policies when it comes to the issue of international trade agreements and some in the party have started supporting free trade in recent decades.[156] In the 1990s, the Clinton administration and a number of prominent Democrats pushed through a number of agreements such as the North American Free Trade Agreement (NAFTA). Since then, the party's shift away from free trade became evident in the Central American Free Trade Agreement (CAFTA) vote, with 15 House Democrats voting for the agreement and 187 voting against.[157][158]
",2
1508,"The modern Democratic Party emphasizes social equality and equal opportunity. Democrats support voting rights and minority rights, including LGBT rights. The party championed the Civil Rights Act of 1964, which for the first time outlawed segregation. Carmines and Stimson wrote ""the Democratic Party appropriated racial liberalism and assumed federal responsibility for ending racial discrimination.""[159][160][161]
",2
1509,"Ideological social elements in the party include cultural liberalism, civil libertarianism, and feminism. Some Democratic social policies are immigration reform, electoral reform, and women's reproductive rights.
",2
1510,"The Democratic Party supports equal opportunity for all Americans regardless of sex, age, race, ethnicity, sexual orientation, gender identity, religion, creed, or national origin. Many Democrats support affirmative action programs to further this goal. Democrats also strongly support the Americans with Disabilities Act to prohibit discrimination against people based on physical or mental disability. As such, the Democrats pushed as well the ADA Amendments Act of 2008, a disability rights expansion that became law.[162]
",2
1511,"The party is very supportive of improving voting rights as well as election accuracy and accessibility.[163] They support ending voter ID laws and increasing voting time, including making election day a holiday. They support reforming the electoral system to eliminate gerrymandering as well as passing comprehensive campaign finance reform.[26]
",2
1512,"The Democratic Party believes that all women should have access to birth control and supports public funding of contraception for poor women. In its national platforms from 1992 to 2004, the Democratic Party has called for abortion to be ""safe, legal and rare""—namely, keeping it legal by rejecting laws that allow governmental interference in abortion decisions and reducing the number of abortions by promoting both knowledge of reproduction and contraception and incentives for adoption. The wording changed in the 2008 platform. When Congress voted on the Partial-Birth Abortion Ban Act in 2003, Congressional Democrats were split, with a minority (including former Senate Majority Leader Harry Reid) supporting the ban and the majority of Democrats opposing the legislation.[164]
",2
1513,"The Democratic Party opposes attempts to reverse the 1973 Supreme Court decision Roe v. Wade, which declared abortion covered by the constitutionally protected individual right to privacy under the Ninth Amendment; and Planned Parenthood v. Casey, which lays out the legal framework in which government action alleged to violate that right is assessed by courts. As a matter of the right to privacy and of gender equality, many Democrats believe all women should have the ability to choose to abort without governmental interference. They believe that each woman, conferring with her conscience, has the right to choose for herself whether abortion is morally correct.
",2
1514,"Former Senate Minority Leader Harry Reid was anti-abortion and former President Jimmy Carter has expressed his wish to see the Democratic Party becoming more pro-life,[165] while former President Barack Obama and Speaker of the House Nancy Pelosi favor abortion rights. Groups such as Democrats for Life of America represent the anti-abortion faction of the party while groups such as EMILY's List represent the abortion rights faction. A Newsweek poll from October 2006 found that 25% of Democrats were anti-abortion while a 69% majority was in favor of abortion rights.[166]
",2
1515,"According to the 2020 Democratic Party platform, ""Democrats believe every woman should be able to access high-quality reproductive health care services, including safe and legal abortion.""[167]
",2
1516,"Many Democratic politicians have called for systematic reform of the immigration system such that residents that have come into the United States illegally have a pathway to legal citizenship. President Obama remarked in November 2013 that he felt it was ""long past time to fix our broken immigration system"", particularly to allow ""incredibly bright young people"" that came over as students to become full citizens. The Public Religion Research Institute found in a late 2013 study that 73% of Democrats supported the pathway concept, compared to 63% of Americans as a whole.[168]
",2
1517,"In 2013, Democrats in the Senate passed S.744, which would reform immigration policy to allow citizenship for illegal immigrants in the United States and improve the lives of all immigrants currently living in the United States.[169]
",2
1518,"The Democratic Party is supportive of LGBT rights. Most support for same-sex marriage in the United States has come from Democrats. Support for same-sex marriage has increased in the past decade according to ABC News. An April 2009 ABC News/Washington Post public opinion poll put support among Democrats at 62%[170] whereas a June 2008 Newsweek poll found that 42% of Democrats support same-sex marriage while 23% support civil unions or domestic partnership laws and 28% oppose any legal recognition at all.[171] A broad majority of Democrats have supported other LGBT-related laws such as extending hate crime statutes, legally preventing discrimination against LGBT people in the workforce and repealing Don't ask, don't tell. A 2006 Pew Research Center poll of Democrats found that 55% supported gays adopting children with 40% opposed while 70% support gays in the military, with only 23% opposed.[172] Gallup polling from May 2009 stated that 82% of Democrats support open enlistment.[173]
",2
1519,"The 2004 Democratic National Platform stated that marriage should be defined at the state level and it repudiated the Federal Marriage Amendment.[174] While not stating support of same-sex marriage, the 2008 platform called for repeal of the Defense of Marriage Act, which banned federal recognition of same-sex marriage and removed the need for interstate recognition, supported antidiscrimination laws and the extension of hate crime laws to LGBT people and opposed the Don't ask, don't tell military policy.[175] The 2012 platform included support for same-sex marriage and for the repeal of DOMA.[27]
",2
1520,"On May 9, 2012, Barack Obama became the first sitting president to say he supports same-sex marriage.[176][177] Previously, he had opposed restrictions on same-sex marriage such as the Defense of Marriage Act, which he promised to repeal,[178] California's Prop 8,[179] and a constitutional amendment to ban same-sex marriage (which he opposed saying that ""decisions about marriage should be left to the states as they always have been""),[180] but also stated that he personally believed marriage to be between a man and a woman and that he favored civil unions that would ""give same-sex couples equal legal rights and privileges as married couples"".[178] Earlier, when running for the Illinois Senate in 1996 he said, ""I favor legalizing same-sex marriages, and would fight efforts to prohibit such marriages"".[181] John Kerry, Democratic presidential candidate in 2004, did not support same-sex marriage. Former presidents Bill Clinton[182] and Jimmy Carter[183] and former vice presidents Al Gore[184] and Walter Mondale[185] also support gay marriage. President Joe Biden has been in favor of same-sex marriage since 2012 when he became the highest-ranking government official to support it.[186]
",2
1521,"The 2016 Democratic Party platform declares: ""We are committed to addressing the extraordinary challenges faced by our fellow citizens in Puerto Rico. Many stem from the fundamental question of Puerto Rico's political status. Democrats believe that the people of Puerto Rico should determine their ultimate political status from permanent options that do not conflict with the Constitution, laws, and policies of the United States. Democrats are committed to promoting economic opportunity and good-paying jobs for the hardworking people of Puerto Rico. We also believe that Puerto Ricans must be treated equally by Medicare, Medicaid, and other programs that benefit families. Puerto Ricans should be able to vote for the people who make their laws, just as they should be treated equally. All American citizens, no matter where they reside, should have the right to vote for the President of the United States. Finally, we believe that federal officials must respect Puerto Rico's local self-government as laws are implemented and Puerto Rico's budget and debt are restructured so that it can get on a path towards stability and prosperity"".[123]
",2
1522,"With a stated goal of reducing crime and homicide, the Democratic Party has introduced various gun control measures, most notably the Gun Control Act of 1968, the Brady Bill of 1993 and Crime Control Act of 1994. However, some Democrats, especially rural, Southern, and Western Democrats, favor fewer restrictions on firearm possession and warned the party was defeated in the 2000 presidential election in rural areas because of the issue.[187] In the national platform for 2008, the only statement explicitly favoring gun control was a plan calling for renewal of the 1994 Assault Weapons Ban.[188]
",2
1523,"The Democratic Party supports the death penalty far less than the Republican Party. Although most Democrats in Congress have never seriously moved to overturn the rarely used federal death penalty, both Russ Feingold and Dennis Kucinich have introduced such bills with little success. Democrats have led efforts to overturn state death penalty laws, particularly in New Jersey and in New Mexico. They have also sought to prevent the reinstatement of the death penalty in those states which prohibit it, including Massachusetts and New York. During the Clinton administration, Democrats led the expansion of the federal death penalty. These efforts resulted in the passage of the Antiterrorism and Effective Death Penalty Act of 1996, signed into law by President Clinton, which heavily limited appeals in death penalty cases.
",2
1524,"In 1992, 1993 and 1995, Democratic Texas Congressman Henry González unsuccessfully introduced the Death Penalty Abolition Amendment which prohibited the use of capital punishment in the United States. Democratic Missouri Congressman William Lacy Clay, Sr. cosponsored the amendment in 1993.
",2
1525,"During his Illinois Senate career, former President Barack Obama successfully introduced legislation intended to reduce the likelihood of wrongful convictions in capital cases, requiring videotaping of confessions. When campaigning for the presidency, Obama stated that he supports the limited use of the death penalty, including for people who have been convicted of raping a minor under the age of 12, having opposed the Supreme Court's ruling in Kennedy v. Louisiana that the death penalty was unconstitutional in child rape cases.[189] Obama has stated that he thinks the ""death penalty does little to deter crime"" and that it is used too frequently and too inconsistently.[190]
",2
1526,"In June 2016, the Democratic Platform Drafting Committee unanimously adopted an amendment to abolish the death penalty, marking the first time the party had done so in its history.[191]
",2
1527,"Many Democrats are opposed to the use of torture against individuals apprehended and held prisoner by the United States military and hold that categorizing such prisoners as unlawful combatants does not release the United States from its obligations under the Geneva Conventions. Democrats contend that torture is inhumane, damages the United States' moral standing in the world, and produces questionable results. Democrats are largely against waterboarding.[192]
",2
1528,"Torture became a divisive issue in the party after Barack Obama was elected president.[193]
",2
1529,"Many Democrats are opposed to the Patriot Act, but when the law was passed most Democrats were supportive of it and all but two Democrats in the Senate voted for the original Patriot Act legislation in 2001. The lone nay vote was from Russ Feingold of Wisconsin as Mary Landrieu of Louisiana did not vote.[194] In the House, the Democrats voted for the Act by 145 yea and 62 nay. Democrats were split on the renewal in 2006. In the Senate, Democrats voted 34 for the 2006 renewal and nine against. In the House, Democrats voted 66 voted for the renewal and 124 against.[195]
",2
1530,"The Democratic Party believes that individuals should have a right to privacy. For example, many Democrats have opposed the NSA warrantless surveillance of American citizens.
",2
1531,"Some Democratic officeholders have championed consumer protection laws that limit the sharing of consumer data between corporations. Most Democrats oppose sodomy laws and believe that government should not regulate consensual noncommercial sexual conduct among adults as a matter of personal privacy.[196]
",2
1532,"The foreign policy of the voters of the two major parties has largely overlapped since the 1990s. A Gallup poll in early 2013 showed broad agreement on the top issues, albeit with some divergence regarding human rights and international cooperation through agencies such as the United Nations.[197]
",2
1533,"In June 2014, the Quinnipiac Poll asked Americans which foreign policy they preferred:
",2
1534,"A) The United States is doing too much in other countries around the world, and it is time to do less around the world and focus more on our own problems here at home.
B) The United States must continue to push forward to promote democracy and freedom in other countries around the world because these efforts make our own country more secure.",2
1535,"Democrats chose A over B by 65% to 32%; Republicans chose A over B by 56% to 39%; and independents chose A over B by 67% to 29%.[198]
",2
1536,"In 2002, Congressional Democrats were divided on the Authorization for Use of Military Force Against Iraq: 147 voted against it (21 in the Senate and 126 in the House) and 110 voted for it (29 in the Senate and 81 in the House). Since then, many prominent Democrats, such as former senator John Edwards, have expressed regret about this decision and have called it a mistake while others, such as Senator Hillary Clinton, have criticized the conduct of the war yet not repudiated their initial vote for it (though Clinton later went on to repudiate her stance during the 2008 primaries). Referring to Iraq, Senate Majority Leader Harry Reid declared in April 2007 the war to be ""lost"" while other Democrats (especially during the 2004 presidential election cycle) accused the President of lying to the public about weapons of mass destruction in Iraq. Among lawmakers, Democrats are the most vocal opponents of Operation Iraqi Freedom and campaigned on a platform of withdrawal ahead of the 2006 midterm elections.
",2
1537,"A March 2003 CBS News poll taken a few days before the invasion of Iraq found that 34% of Democrats nationwide would support it without United Nations backing, 51% would support it only with its backing and 14% would not support it at all.[199] The Los Angeles Times stated in early April 2003 that 70% of Democrats supported the decision to invade while 27% opposed it.[200] The Pew Research Center stated in August 2007 that opposition increased from 37% during the initial invasion to 74%.[201] In April 2008, a CBS News poll found that about 90% of Democrats disapprove of the Bush administration's conduct and want to end the war within the next year.[202]
",2
1538,"Democrats in the House of Representatives near-unanimously supported a non-binding resolution disapproving of President Bush's decision to send additional troops into Iraq in 2007. Congressional Democrats overwhelmingly supported military funding legislation that included a provision that set ""a timeline for the withdrawal of all US combat troops from Iraq"" by March 31, 2008, but also would leave combat forces in Iraq for purposes such as targeted counter-terrorism operations.[203][204] After a veto from the President and a failed attempt in Congress to override the veto,[205] the U.S. Troop Readiness, Veterans' Care, Katrina Recovery, and Iraq Accountability Appropriations Act, 2007 was passed by Congress and signed by the President after the timetable was dropped. Criticism of the Iraq War subsided after the Iraq War troop surge of 2007 led to a dramatic decrease in Iraqi violence. The Democratic-controlled 110th Congress continued to fund efforts in both Iraq and Afghanistan. Presidential candidate Barack Obama advocated a withdrawal of combat troops within Iraq by late 2010 with a residual force of peacekeeping troops left in place.[206] He stated that both the speed of withdrawal and the number of troops left over would be ""entirely conditions-based"".[206]
",2
1539,"On February 27, 2009, President Obama announced: ""As a candidate for president, I made clear my support for a timeline of 16 months to carry out this drawdown, while pledging to consult closely with our military commanders upon taking office to ensure that we preserve the gains we've made and protect our troops [...] Those consultations are now complete, and I have chosen a timeline that will remove our combat brigades over the next 18 months"".[207] Around 50,000 non-combat-related forces would remain.[207] Obama's plan drew wide bipartisan support, including that of defeated Republican presidential candidate Senator John McCain.[207][needs update]
",2
1540,"The Democratic Party has been critical of the Iran's nuclear weapon program and supported economic sanctions against the Iranian government. In 2013, the Democratic-led administration worked to reach a diplomatic agreement with the government of Iran to halt the Iranian nuclear weapon program in exchange for international economic sanction relief.[208] As of 2014[update], negotiations had been successful and the party called for more cooperation with Iran in the future.[209] In 2015, the Obama administration agreed to the Joint Comprehensive Plan of Action, which provides sanction relief in exchange for international oversight of the Iranian nuclear program. In February 2019, the Democratic National Committee passed a resolution calling on the United States to re-enter the JCPOA, which President Trump withdrew from in 2018.[210]
",2
1541,"Democrats in the House of Representatives and in the Senate near-unanimously voted for the Authorization for Use of Military Force Against Terrorists against ""those responsible for the recent attacks launched against the United States"" in Afghanistan in 2001, supporting the NATO coalition invasion of the nation. Most elected Democrats continue to support the Afghanistan conflict and some, such as a Democratic National Committee spokesperson, have voiced concerns that the Iraq War shifted too many resources away from the presence in Afghanistan.[211][212] Since 2006, Democratic candidate Barack Obama has called for a ""surge"" of troops into Afghanistan.[212] As president, Obama sent a ""surge"" force of additional troops to Afghanistan. Troop levels were 94,000 in December 2011 and kept falling, with a target of 68,000 by fall 2012. Obama planned to bring all the troops home by 2014.[213]
",2
1542,"Support for the war among the American people has diminished over time and many Democrats have changed their opinion and now oppose a continuation of the conflict.[214][215] In July 2008, Gallup found that 41% of Democrats called the invasion a ""mistake"" while a 55% majority disagreed. In contrast, Republicans were more supportive of the war. The survey described Democrats as evenly divided about whether or not more troops should be sent—56% support it if it would mean removing troops from Iraq and only 47% support it otherwise.[215] A CNN survey in August 2009 stated that a majority of Democrats now oppose the war. CNN polling director Keating Holland said: ""Nearly two thirds of Republicans support the war in Afghanistan. Three quarters of Democrats oppose the war"".[214] An August 2009 Washington Post poll found similar results and the paper stated that Obama's policies would anger his closest supporters.[216]
",2
1543,"The Democratic Party has both recently and historically supported Israel.[217][218] A 2008 Gallup poll found that 64% of Americans have a favorable image of Israel while only 16% say that they have a favorable image of the Palestinian Authority.[217] A pro-Israel view is held by the party leadership although some Democrats, including former President Jimmy Carter, have criticized Israel.[218]
",2
1544,"The 2008 Democratic Party platform acknowledges a ""special relationship with Israel, grounded in shared interests and shared values, and a clear, strong, fundamental commitment to the security of Israel, our strongest ally in the region and its only established democracy."" It also included:
",2
1545,"It is in the best interests of all parties, including the United States, that we take an active role to help secure a lasting settlement of the Israeli-Palestinian conflict with a democratic, viable Palestinian state dedicated to living in peace and security side by side with the Jewish State of Israel. To do so, we must help Israel identify and strengthen those partners who are truly committed to peace while isolating those who seek conflict and instability, and stand with Israel against those who seek its destruction. The United States and its Quartet partners should continue to isolate Hamas until it renounces terrorism, recognizes Israel's right to exist, and abides by past agreements. Sustained American leadership for peace and security will require patient efforts and the personal commitment of the President of the United States. The creation of a Palestinian state through final status negotiations, together with an international compensation mechanism, should resolve the issue of Palestinian refugees by allowing them to settle there, rather than in Israel. All understand that it is unrealistic to expect the outcome of final status negotiations to be a full and complete return to the armistice lines of 1949. Jerusalem is and will remain the capital of Israel. The parties have agreed that Jerusalem is a matter for final status negotiations. It should remain an undivided city accessible to people of all faiths.[219]",2
1546,"A January 2009 Pew Research Center study found that when asked ""which side do you sympathize with more"", 42% of Democrats and 33% of liberals (a plurality in both groups) sympathize most with the Israelis. Around half of all political moderates or independents sided with Israel.[220] The years leading up to the 2016 election have brought more discussion of the party's stance on Israel as polls reported declining support for Israel among the party faithful.[221] Gallup suggested that the decline in support might be due to tensions between Israeli Prime Minister Benjamin Netanyahu and President Barack Obama.[221]
",2
1547,"The rise of the progressive Bernie Sanders-aligned faction of the party, which tends to trend more pro-Palestine, is also likely responsible for the decline in support for Israel. A 2016 Pew Research poll found that while Clinton supporters sympathized more with Israel than Palestinians by a 20-point margin, Sanders supporters sympathized more with Palestinians than with Israel by a 6-point margin.[222] In June 2016, DNC members voted against an amendment to the party platform proposed by Sanders supporter James Zogby calling for an ""end to occupation and illegal settlements"".[223] In August 2018, Rashida Tlaib, who supports a one-state solution,[224] and Ilhan Omar, who has referred to Israel as an ""apartheid regime""[225] won Democratic primaries in Michigan and Minnesota. In November 2018, shortly after being elected to Congress, Omar came out in support of the Boycott, Divestment and Sanctions (BDS) campaign against Israel.[226]
",2
1548,"Professionals, those who have a college education and those whose work revolves around the conception of ideas, have tended to support the Democratic Party since 2000. While the professional class was once a stronghold of the Republican Party, it has become increasingly in favor of the Democratic Party. Support for Democratic candidates among professionals may be traced to the prevalence of liberal cultural values among this group:[227]
",2
1549,"Professionals, who are, roughly speaking, college-educated producers of services and ideas, used to be the most staunchly Republican of all occupational groups [...] now chiefly working for large corporations and bureaucracies rather than on their own, and heavily influenced by the environmental, civil-rights, and feminist movements—began to vote Democratic. In the four elections from 1988 to 2000, they backed Democrats by an average of 52 percent to 40 percent.",2
1550,"The highly educated constitute an important part of the Democratic voter base. The party has strong support among scientists, with 55% identifying as Democrats, 32% as independents, and 6% as Republicans in a 2009 study.[228] Those with a college education have become increasingly Democratic in the 1992,[229] 1996,[229] 2000,[92] 2004,[93] and 2008[230] elections. In exit polls for the 2018 elections, 65% of those with a graduate degree said they voted Democratic, and Democrats won college graduates overall by a 20-point margin.[105]
",2
1551,"Since the 1930s, a critical component of the Democratic Party coalition has been organized labor. Labor unions supply a great deal of the money, grass roots political organization, and voters for the party. Democrats are far more likely to be represented by unions, although union membership has declined in general during the last few decades. This trend is depicted in the following graph from the book Democrats and Republicans—Rhetoric and Reality.[231] It is based on surveys conducted by the National Election Studies (NES).
",2
1552,"The three most significant labor groupings in the Democratic coalition today are the AFL-CIO and Change to Win labor federations as well as the National Education Association, a large, unaffiliated teachers' union. Important issues for labor unions include supporting industrial policy that sustains unionized manufacturing jobs, raising the minimum wage, and promoting broad social programs such as Social Security and Medicare.
",2
1553,"The American working class is a stronghold of the Democratic Party and continues to be an essential part of the Democratic base. Economic insecurity makes the majority of working-class people left-of-center on economic issues. However, many working class Democrats differ from liberals in their more socially conservative views. Working class Democrats tend to be more religious and more likely to belong to an ethnic minority. The continued importance of the working class manifests itself in exit polls, which show that the majority of those with working class incomes and education vote for the Democratic Party.[93][94] Since 1980,[232] there has been a decline in support for the Democratic Party among white working class voters.[233][234][235]
",2
1554,"Younger Americans, including millennials and Generation Z, tend to vote mostly for Democratic candidates in recent years.[18]
",2
1555,"The young have voted in favor of the Democratic presidential candidate in every election since Bill Clinton in 1992 and are more likely to identify as liberals than the general population.[238] In the 2004 presidential election, Democratic presidential candidate John Kerry received 54% of the vote from voters of the age group 18–29 while Republican George W. Bush received 45%. In the 2006 midterm elections, the Democrats received 60% of the vote from the same age group.[93][94]
",2
1556,"Polls suggest that younger Americans have more liberal views than the general public on same-sex marriage and universal health care, helping Barack Obama carry 66% of their votes in 2008. In the 2018 midterm elections, 67% of those in the 18–29 age range voted for the Democratic candidate. Democrats also won those in the 30–44 age range by a 19-point margin.[105]
",2
1557,"Although the gender gap has varied over many years, women of all ages are more likely than men to identify as Democrats.
",2
1558,"Since the 1990s, women have supported Democratic Party candidates to various offices at higher rates than men.[239] Polls in 2009 indicated that 41% of women identify as Democrats while only 25% of women identify as Republicans and 26% as independents whereas 32% of men identify as Democrats, 28% as Republicans and 34% as independents. Among ethnic minorities, women also are more likely than men to identify as Democrats.
",2
1559,"The National Federation of Democratic Women is an affiliated organization meant to advocate for women's issues. National women's organizations that support Democratic candidates include Emily's List, which aims to help elect pro-choice female Democratic candidates to office.
",2
1560,"Of the 118 women in the United States House of Representatives, 89 are Democrats.[240]
",2
1561,"Americans that identify as single, living with a domestic partner, divorced, separated, or widowed are more likely to vote Democratic in contrast to married Americans which split about equally between Democrat and Republican.[21]
",2
1562,"General Social Surveys of more than 11,000 Democrats and Republicans conducted between 1996 and 2006 came to the result that the differences in fertility rates are not statistically significant between these parties, with the average Democrat having 1.94 children and the average Republican having 1.91 children.[241] However, there is a significant difference in fertility rates between the two related groups liberals and conservatives, with liberals reproducing at a much lower rate than conservatives.[241]
",2
1563,"According to exit polling, LGBT Americans typically vote Democratic in national elections within the 70–80% range. In heavily gay precincts in large cities across the nation, the average was higher, ranging from 85% to 94%. This trend has continued since 1996 when Bill Clinton won 71% of the LGBT vote compared to Bob Dole's 16%. In 2000 Al Gore won 70% to George W. Bush's 25%, in 2004 John Kerry won 77% to George W. Bush's 23%, in 2008 Barack Obama won 70% to John McCain's 27%,[242] in 2012 Barack Obama won 76% to Mitt Romney's 22%,[243] in 2016 Hillary Clinton won 78% to Donald Trump's 14%, and in 2020 Joe Biden won 73% to Donald Trump's 25%.[244] Patrick Egan, a professor at New York University specializing in LGBT voting patterns, calls this a ""remarkable continuity"", saying that ""about three-fourths vote Democratic and one-fourth Republican from year to year"".[242]
",2
1564,"Notable LGBT Democrats include Senator Tammy Baldwin of Wisconsin, Senator Kyrsten Sinema of Arizona, Representative David Cicilline of Rhode Island, Governor Kate Brown of Oregon, and Governor Jared Polis of Colorado. The late activist and San Francisco Supervisor Harvey Milk was a Democrat as is former Representative Barney Frank of Massachusetts.
",2
1565,"The Stonewall Democrats is an LGBT advocacy group associated with the Democratic Party. The Congressional LGBT Equality Caucus is a congressional caucus of 164 Democrats and 1 Republican that advocate for LGBT rights within the House of Representatives.[245]
",2
1566,"By winning the 2020 Iowa Democratic presidential caucuses, former Mayor of South Bend, Indiana, Pete Buttigieg became the first openly gay candidate to win a presidential primary or caucus. In December 2020, Buttigieg was selected to serve as United States Secretary of Transportation, and he became the first openly gay cabinet secretary to be confirmed by the U.S. Senate in February 2021.[246][247]
",2
1567,"From the end of the Civil War to the early 20th century, African Americans primarily favored the Republican Party due to its role in achieving the abolition of slavery, particularly through President Lincoln's Emancipation Proclamation.[248] The South had long been a Democratic stronghold, favoring a state's right to legal slavery. In addition, the ranks of the fledgling Ku Klux Klan were composed almost entirely of white Democrats who were angry over the treatment they had received at the hands of Northerners and who were also bent on reversing the policies of Reconstruction.[249]
",2
1568,"African Americans began drifting to the Democratic Party when Franklin D. Roosevelt was elected president.[248] Support for the civil rights movement in the 1960s by Democratic presidents John F. Kennedy and Lyndon B. Johnson helped give the Democrats even greater support in the African-American community, which has consistently voted between 85% and 95% Democratic from the 1960s to the present day, making African Americans one of the biggest support groups in any US party.[248]
",2
1569,"Prominent modern-day African-American Democratic politicians include Jim Clyburn, Maxine Waters, Barbara Lee, Charles Rangel, John Conyers, Karen Bass, Ayanna Pressley, Ilhan Omar, Senator Cory Booker, Vice President Kamala Harris, and former President Barack Obama, who managed to win over 95% of the African-American vote in the 2008 election.[250] Despite not having a partisan affiliation, the NAACP often participates in organizing voter turnout drives and advocates for progressive causes, especially those that affect people of color.[251]
",2
1570,"Within the House of Representatives, the Congressional Black Caucus, consisting of 54 black Democrats, serves to represent the interests of African Americans and advocate on issues that affect them.[252]
",2
1571,"The Hispanic population, particularly the large Mexican-American population in the Southwest and the large Puerto Rican and Dominican populations in the Northeast, have been strong supporters of the Democratic Party. In the 1996 presidential election, Democratic President Bill Clinton received 72% of the Hispanic vote.[253] In following years, the Republican Party gained increasing support from the Hispanic community, especially among Hispanic Protestants and Pentecostals. With his much more liberal views on immigration, President Bush was the first Republican president to gain 40% of the Hispanic vote in the 2004 presidential election. But the Republican Party's support among Hispanics eroded in the 2006 midterm elections, dropping from 44% to 30%, with the Democrats gaining in the Hispanic vote from 55% in 2004 to 69% in 2006.[93][94] Democrats increased their share of the Hispanic vote in the 2008 presidential election, with Barack Obama receiving 67%. According to exit polls by Edison Research, Obama increased his support again in 2012, winning 71% of Hispanic voters.[254]
",2
1572,"Cuban Americans still tend to vote Republican, though there has been a noticeable change starting with the 2008 elections. During the 2008 elections, Barack Obama received 47% of the Cuban-American vote in Florida.[255] According to Bendixen's exit polls, 84% of Miami-Dade Cuban-American voters 65 or older backed McCain, while 55% of those 29 or younger backed Obama,[256] showing that the younger Cuban-American generation has become more liberal.
",2
1573,"Unaffiliated Hispanic advocacy groups that often support progressive candidates and causes include the National Council of La Raza and the League of United Latin American Citizens. In the House of Representatives, the Democratic caucus of Hispanic Americans is the Congressional Hispanic Caucus.
",2
1574,"In the 2018 elections, 69% of Latino Americans voted for the Democratic House candidate.[105]
",2
1575,"The Democratic Party has considerable support in the small yet growing Asian-American population. Asian Americans had been a stronghold of the Republican Party up to and including the 1992 presidential election, in which George H. W. Bush won 55% of the Asian-American vote. Originally, the vast majority of Asian Americans were strongly anti-communist Vietnamese refugees, Chinese Americans, Taiwanese Americans, Korean Americans, and Filipino Americans, and the Republican Party's positions resonated with this demographic. The Democratic Party made gains among Asian Americans starting in 1996 and in 2006 won 62% of the Asian-American vote. Exit polls after the 2008 presidential election indicated that Democratic candidate, Barack Obama, won 62% of the Asian-American vote.[257] In the 2012 presidential election, 73% of the Asian-American electorate voted for Obama's re-election.[258]
",2
1576,"Barack Obama had the support of 85% of Indian Americans, 68% of Chinese Americans, and 57% of Filipino Americans.[259] The Asian-American community's increasing number of young voters has also helped to erode traditionally reliably Republican voting blocs such as Vietnamese and Filipino Americans, leading to an increase in support for Democrats. Prominent Asian-American Democrats include Vice President Kamala Harris, Senators Tammy Duckworth, Daniel Inouye, Daniel Akaka, and Mazie Hirono, former Governor and Secretary of Commerce Gary Locke, and Representatives Mike Honda, Judy Chu, Doris Matsui, Ro Khanna, Pramila Jayapal, Norman Mineta and Dalip Singh Saund, the first Asian-American representative.
",2
1577,"In the 2018 elections, 77% of Asian Americans voted for the Democratic candidate.[105]
",2
1578,"The Democratic Party also has strong support among the Native American population, particularly in Arizona, New Mexico, Montana, North Dakota, South Dakota, Washington, Alaska, Idaho, Minnesota, Wisconsin, Oklahoma,[260] and North Carolina. Although now a small percentage of the population (virtually non-existent in some regions), most Native American precincts vote Democratic in margins exceeded only by African Americans.[261]
",2
1579,"Modern-day Democratic Native American politicians include former Congressman Brad Carson of Oklahoma as well as Principal Chief Bill John Baker of the Cherokee Nation, Governor Bill Anoatubby of the Chickasaw Nation, and Chief Gary Batton of the Choctaw Nation of Oklahoma.
",2
1580,"In 2018, Democrats Deb Haaland of New Mexico and Sharice Davids of Kansas became the first Native American women to be elected to Congress.[262] Democrat Peggy Flanagan was also elected in 2018 and currently serves as Lieutenant Governor of Minnesota. Flanagan is the second Native American woman to be elected to statewide executive office in U.S. history and the highest-ranking Native woman to be elected to executive office.[263]
",2
1581,"In December 2020, Deb Haaland was chosen by Joe Biden to serve as United States Secretary of the Interior; if confirmed, she would be the first Native American Cabinet secretary.
",2
1582,"Black churches, mainline Protestants, evangelicals, and Catholics contributed to Franklin D. Roosevelt's New Deal coalition.[264] During the New Deal era, President Roosevelt appealed to notions of Christian charity.[265] In explaining his philosophy, he said: ""I am a Christian and a Democrat"".[265]
",2
1583,"Catholic Americans have traditionally been a stronghold for the Democratic Party, although they have become more divided between the two major parties in recent years. Both Catholics elected to be president, John F. Kennedy and Joe Biden, have been Democrats.[266] Speaker of the House Nancy Pelosi is also Catholic.[267]
",2
1584,"In response to high white evangelical support for Donald Trump and the Republican Party,[268] Hillary Scholten, a member of the Christian Reformed Church, founded the Christian Democrats of America.[269][undue weight?  – discuss] During the 2020 primaries, Christians were more likely to support Joe Biden than Bernie Sanders, who was favored among religiously unaffiliated Democrats.[270] 1,600 faith leaders (mostly mainline Protestants, evangelicals, and Catholics) supported Joe Biden's 2020 presidential bid.[271][undue weight?  – discuss] Robb Ryerse, political director at Vote Common Good, a religiously-motivated anti-Trump organization, estimated that there were roughly a dozen evangelical Christians running for political office as Democrats in 2020, as opposed to two or three in 2018.[269][undue weight?  – discuss]
",2
1585,"As of 2021[update], every Democratic president, Democratic vice president, and Democratic presidential nominee has been a Christian. According to the Pew Research Center, 78.4% of Democrats in the 116th United States Congress were Christian.[272]
",2
1586,"Jewish American communities tend to be a stronghold for the Democratic Party. Al Gore received 79% of the Jewish votes in 2000, and Barack Obama won about 77% of the Jewish vote in 2008.[273] In the 2018 House of Representatives elections, 79% of Jewish Americans voted for the Democratic candidate.[105]
",2
1587,"Jewish Americans as an important Democratic constituency are especially politically active and influential in large cities such as New York City, Los Angeles, Boston, and Chicago and play critical roles in large cities within presidential swing states, such as Philadelphia, Miami, and Las Vegas. Many prominent national Democrats in recent decades have been Jewish, including Chuck Schumer, Carl Levin, Abraham Ribicoff, Ben Cardin, Henry Waxman, Joseph Lieberman, Bernie Sanders, Dianne Feinstein, Barney Frank, Barbara Boxer, Paul Wellstone, Rahm Emanuel, Russ Feingold, Herb Kohl, and Howard Metzenbaum.[274]
",2
1588,"Arab Americans and Muslim Americans have leaned Democratic since the Iraq War.[275] Zogby found in June 2007 that 39% of Arab Americans identify as Democrats, 26% as Republicans, and 28% as independents.[275] Arab Americans, who are in general socially conservative but have more diverse economic views, historically voted Republican until recent years, having supported George W. Bush over Al Gore in 2000.[276] A 2012 poll found that 68% of Muslim Americans surveyed support Barack Obama.[277] A 2017 Pew Research Center report found that majority (66%) of American Muslims identify with or learn toward the Democratic Party, receiving consistent support from 2011 at 70% and 63% at 2007.[278]
",2
1589,"The Democratic Party receives support from secular organizations such as the Secular Coalition for America[279] and many agnostic and atheist Americans. Exit polls from the 2008 election showed that voters with a religious affiliation of ""none"" accounted for the 12% of the electorate and voted for Obama by a 75–25% margin.[280] In his first inaugural address, Obama acknowledged atheists by saying that the United States is not just ""Christians and Muslims, Jews and Hindus but non-believers as well"".[281] In the 2012 election cycle, Obama had moderate to high ratings with the Secular Coalition for America while the majority of the Republican candidates had ratings in the low-to-failing range.[282] In 2020 United States presidential election, exit polls show that voters with religious affiliation of ""none"" accounted for 22% of the electorate and voted for Biden by a 65-31% margin.[283]
",2
1590,"As of 2021[update], there have been a total of 16 Democratic Party presidents.
",2
1591,"In the Supreme Court, as of January 2021[update], three of the nine seats are filled by justices appointed by Democratic presidents Bill Clinton and Barack Obama.[284]
",2
1592,"Associate Justice of the Supreme Court of the United States
",2
1593,"Associate Justice of the Supreme Court of the United States
",2
1594,"Associate Justice of the Supreme Court of the United States
",2
1595,"year
",2
1596,"seats won
",2
1597,"seats won
",2
1598,"year
",2
1599,"
",2
1600,"The Republican Party, also referred to as the GOP (""Grand Old Party""), is one of the two major contemporary political parties in the United States, along with its main, historic rival, the Democratic Party.
",2
1601,"The GOP was founded in 1854 by opponents of the Kansas–Nebraska Act,[10] which allowed for the potential expansion of chattel slavery into the western territories. The party supported economic reform and classical liberalism while opposing the expansion of slavery.[11][12] Abraham Lincoln was the first Republican president. Under the leadership of Lincoln and a Republican Congress, slavery was banned in the United States in 1865. The GOP was generally dominant during the Third and the Fourth Party System periods. It was strongly committed to protectionism and tariffs at its founding, but grew more supportive of free trade in the 20th century.
",2
1602,"After 1912, the Republican Party began to undergo an ideological shift to the right.[13] Following the Civil Rights Act of 1964 and the Voting Rights Act of 1965, the party's core base shifted, with Southern states becoming more reliably Republican in presidential politics.[14] After the Supreme Court's 1973 decision in Roe v. Wade, the Republican Party opposed abortion in its party platform and grew its support among evangelicals.[15] Its 21st-century ideology is American conservatism, which incorporates both social conservatism and fiscal conservatism. The GOP supports lower taxes, free-market capitalism, restrictions on immigration, increased military spending, gun rights, restrictions on abortion, deregulation, and restrictions on labor unions.[16] The party's voter base in the 21st century largely includes white men,[17] people living in rural areas, members of the Silent Generation, people with less education,[18] and evangelical Christians.[19]  Its most recent presidential nominee was Donald Trump, and most Republicans are generally supportive of his opinions and actions.[20][21]
",2
1603,"There have been 19 Republican presidents, the most from any one political party. As of early 2021, the GOP controls 27 state governorships, 30 state legislatures, and 23 state government trifectas (governorship and both legislative chambers). Six of the nine sitting U.S. Supreme Court justices were nominated by Republican presidents.
",2
1604,"The Republican Party emerged from the great political realignment of the mid-1850s. William Gienapp argues that the great realignment of the 1850s began before the Whig party collapse, and was caused not by politicians but by voters at the local level. The central forces were ethno-cultural, involving tensions between pietistic Protestants versus liturgical Catholics, Lutherans and Episcopalians regarding Catholicism, prohibition, and nativism. Anti-slavery did play a role but it was less important at first. The Know-Nothing party embodied the social forces at work, but its weak leadership was unable to solidify its organization, and the Republicans picked it apart. Nativism was so powerful that the Republicans could not avoid it, but they did minimize it and turn voter wrath against the threat that slave owners would buy up the good farm lands wherever chattel slavery was allowed. The realignment was powerful because it forced voters to switch parties, as typified by the rise and fall of the Know-Nothings, the rise of the Republican Party, and the splits in the Democratic Party.[22][23]
",2
1605,"The Republican Party was founded in the Northern states in 1854 by forces opposed to the expansion of chattel slavery, ex-Whigs, and ex-Free Soilers. The Republican Party quickly became the principal opposition to the dominant Democratic Party and the briefly popular Know Nothing Party. The party grew out of opposition to the Kansas–Nebraska Act, which repealed the Missouri Compromise and opened Kansas Territory and Nebraska Territory to chattel slavery and future admission as slave states.[24][25] The Republicans called for economic and social modernization. They denounced the expansion of chattel slavery as a great evil, but did not call for ending it in the Southern states. The first public meeting of the general anti-Nebraska movement, at which the name Republican was proposed, was held on March 20, 1854 at the Little White Schoolhouse in Ripon, Wisconsin.[26] The name was partly chosen to pay homage to Thomas Jefferson's Republican Party.[27] The first official party convention was held on July 6, 1854 in Jackson, Michigan.[28]
",2
1606,"At the 1856 Republican National Convention, the party adopted a national platform emphasizing opposition to the expansion of chattel slavery into U.S. territories.[29] While Republican candidate John C. Frémont lost the 1856 United States presidential election to James Buchanan, he did win 11 of the 16 northern states.[30][better source needed]
",2
1607,"The Republican Party first came to power in the elections of 1860 when it won control of both houses of Congress and its candidate, former congressman Abraham Lincoln, was elected president. In the election of 1864, it united with War Democrats to nominate Lincoln on the National Union Party ticket;[30] Lincoln won re-election.[31] Under Republican congressional leadership, the Thirteenth Amendment to the United States Constitution—which banned chattel slavery in the United States—passed the Senate in 1864 and the House in 1865; it was ratified in December 1865.[32]
",2
1608,"The party's success created factionalism within the party in the 1870s. Those who believed that Reconstruction had been accomplished, and was continued mostly to promote the large-scale corruption tolerated by President Ulysses S. Grant, ran Horace Greeley for the presidency in 1872 on the Liberal Republican Party line. The Stalwart faction defended Grant and the spoils system, whereas the Half-Breeds pushed for reform of the civil service.[33] The Pendleton Civil Service Reform Act was passed in 1883;[34] the bill was signed into law by Republican President Chester A. Arthur.[35]
",2
1609,"The Republican Party supported hard money (i.e. the gold standard), high tariffs to promote economic growth, high wages and high profits, generous pensions for Union veterans, and (after 1893) the annexation of Hawaii. The Republicans had strong support from pietistic Protestants, but they resisted demands for prohibition. As the Northern postwar economy boomed with heavy and light industry, railroads, mines, fast-growing cities, and prosperous agriculture, the Republicans took credit and promoted policies to sustain the fast growth.[citation needed]
",2
1610,"The GOP was usually dominant over the Democrats during the Third Party System (1850s–1890s). However, by 1890 the Republicans had agreed to the Sherman Antitrust Act and the Interstate Commerce Commission in response to complaints from owners of small businesses and farmers. The high McKinley Tariff of 1890 hurt the party and the Democrats swept to a landslide in the off-year elections, even defeating McKinley himself. The Democrats elected Grover Cleveland in 1884 and 1892. The election of William McKinley in 1896 was marked by a resurgence of Republican dominance that lasted (except for 1912 and 1916) until 1932. McKinley promised that high tariffs would end the severe hardship caused by the Panic of 1893 and that Republicans would guarantee a sort of pluralism in which all groups would benefit.[36]
",2
1611,"The Republican Civil War era program included free homestead farms, a federally subsidized transcontinental railroad, a national banking system, a large national debt, land grants for higher education, a new national banking system, a wartime income tax and permanent high tariffs to promote industrial growth and high wages. By the 1870s, they had adopted as well a hard money system based on the gold standard and fought off efforts to promote inflation through Free Silver.[37] They created the foundations of the modern welfare state through an extensive program of pensions for Union veterans.[38] Foreign-policy issues were rarely a matter of partisan dispute, but briefly in the 1893–1904 period the GOP supported imperialistic expansion regarding Hawaii, the Philippines and the Panama Canal.[39]
",2
1612,"The 1896 realignment cemented the Republicans as the party of big businesses while Theodore Roosevelt added more small business support by his embrace of trust busting. He handpicked his successor William Howard Taft in 1908, but they became enemies as the party split down the middle. Taft defeated Roosevelt for the 1912 nomination and Roosevelt ran on the ticket of his new Progressive (""Bull Moose"") Party. He called for social reforms, many of which were later championed by New Deal Democrats in the 1930s. He lost and when most of his supporters returned to the GOP they found they did not agree with the new conservative economic thinking, leading to an ideological shift to the right in the Republican Party.[40] The Republicans returned to the White House throughout the 1920s, running on platforms of normalcy, business-oriented efficiency and high tariffs. The national party platform avoided mention of prohibition, instead issuing a vague commitment to law and order.[41]
",2
1613,"Warren G. Harding, Calvin Coolidge and Herbert Hoover were resoundingly elected in 1920, 1924 and 1928, respectively. The Teapot Dome scandal threatened to hurt the party, but Harding died and the opposition splintered in 1924. The pro-business policies of the decade seemed to produce an unprecedented prosperity until the Wall Street Crash of 1929 heralded the Great Depression.[42]
",2
1614,"The New Deal coalition of Democrat Franklin D. Roosevelt controlled American politics for most of the next three decades, excluding the two-term presidency of Republican Dwight D. Eisenhower. After Roosevelt took office in 1933, New Deal legislation sailed through Congress and the economy moved sharply upward from its nadir in early 1933. However, long-term unemployment remained a drag until 1940. In the 1934 midterm elections, 10 Republican senators went down to defeat, leaving the GOP with only 25 senators against 71 Democrats. The House of Representatives likewise had overwhelming Democratic majorities.[43]
",2
1615,"The Republican Party factionalized into a majority ""Old Right"" (based in the Midwest) and a liberal wing based in the Northeast that supported much of the New Deal. The Old Right sharply attacked the ""Second New Deal"" and said it represented class warfare and socialism. Roosevelt was re-elected in a landslide in 1936; however, as his second term began, the economy declined, strikes soared, and he failed to take control of the Supreme Court or to purge the Southern conservatives from the Democratic Party. Republicans made a major comeback in the 1938 elections and had new rising stars such as Robert A. Taft of Ohio on the right and Thomas E. Dewey of New York on the left.[44] Southern conservatives joined with most Republicans to form the conservative coalition, which dominated domestic issues in Congress until 1964. Both parties split on foreign policy issues, with the anti-war isolationists dominant in the Republican Party and the interventionists who wanted to stop Adolf Hitler dominant in the Democratic Party. Roosevelt won a third and fourth term in 1940 and 1944, respectively. Conservatives abolished most of the New Deal during the war, but they did not attempt to reverse Social Security or the agencies that regulated business.[45]
",2
1616,"
Historian George H. Nash argues: ",2
1617,"Unlike the ""moderate"", internationalist, largely eastern bloc of Republicans who accepted (or at least acquiesced in) some of the ""Roosevelt Revolution"" and the essential premises of President Harry S. Truman's foreign policy, the Republican Right at heart was counterrevolutionary. Anti-collectivist, anti-Communist, anti-New Deal, passionately committed to limited government, free market economics, and congressional (as opposed to executive) prerogatives, the G.O.P. conservatives were obliged from the start to wage a constant two-front war: against liberal Democrats from without and ""me-too"" Republicans from within.[46]",2
1618,"After 1945, the internationalist wing of the GOP cooperated with Truman's Cold War foreign policy, funded the Marshall Plan and supported NATO, despite the continued isolationism of the Old Right.[47]
",2
1619,"The second half of the 20th century saw the election or succession of Republican presidents Dwight D. Eisenhower, Richard Nixon, Gerald Ford, Ronald Reagan and George H. W. Bush. Eisenhower had defeated conservative leader Senator Robert A. Taft for the 1952 nomination, but conservatives dominated the domestic policies of the Eisenhower administration. Voters liked Eisenhower much more than they liked the GOP and he proved unable to shift the party to a more moderate position. Since 1976, liberalism has virtually faded out of the Republican Party, apart from a few Northeastern holdouts.[48] Historians cite the 1964 United States presidential election and its respective 1964 Republican National Convention as a significant shift, which saw the conservative wing, helmed by Senator Barry Goldwater of Arizona, battle the liberal New York Governor Nelson Rockefeller and his eponymous Rockefeller Republican faction for the party presidential nomination. With Goldwater poised to win, Rockefeller, urged to mobilize his liberal faction, relented, ""You’re looking at it, buddy. I’m all that’s left.""[49][50] Though Goldwater lost in a landslide, Reagan would make himself known as a prominent supporter of his throughout the campaign, delivering the ""A Time for Choosing"" speech for him. He'd go on to become governor of California two years later, and in 1980, win the presidency.[51]
",2
1620,"The presidency of Reagan, lasting from 1981 to 1989, constituted what is known as the ""Reagan Revolution"".[52] It was seen as a fundamental shift from the stagflation of the 1970s before it, with the introduction of Reaganomics intended to cut taxes, prioritize government deregulation, and shift funding from the domestic sphere into the military to combat the Soviet Union by utilizing deterrence theory. A defining moment in Reagan's term of office was his speech in then-West Berlin where he demanded Soviet General Secretary Mikhail Gorbachev to ""[t]ear down this wall"", referring to the Berlin Wall constructed to separate West and East Berlin.[53][54]
",2
1621,"Since he left office in 1989, Reagan has been an iconic conservative Republican and Republican presidential candidates frequently claim to share his views and aim to establish themselves and their policies as the more appropriate heir to his legacy.[55]
",2
1622,"In the Republican Revolution of 1994, the party—led by House Minority Whip Newt Gingrich, who campaigned on the ""Contract with America""—won majorities in both Houses of Congress. However, as House Speaker, Gingrich was unable to deliver on many of its promises, including a balanced-budget amendment and term limits for members of Congress. During the impeachment and acquittal of President Bill Clinton, Republicans suffered surprise losses in the 1998 midterm elections. Gingrich's popularity sank to 17%; he resigned the speakership and later resigned from Congress altogether.[56][57][58]
",2
1623,"For most of the post-World War II era, Republicans had little presence at the state legislative level. This trend began to reverse in the late 1990s, with Republicans increasing their state legislative presence and taking control of state legislatures in the South. From 2004 to 2014, the Republican State Leadership Committee (RSLC) raised over $140 million targeted to state legislature races, while the Democratic Legislative Campaign Committee (DLSC) raised less than half that during that time period. Following the 2014 midterm elections, Republicans controlled 68 of 98 partisan state legislative houses (the most in the party's history) and controlled both the executive and legislative branches of government in 24 states (Democrats had control of only seven).[59]
",2
1624,"A Republican ticket of George W. Bush and Dick Cheney won the 2000 and 2004 presidential elections.[60] Bush campaigned as a ""compassionate conservative"" in 2000, wanting to better appeal to immigrants and minority voters.[61] The goal was to prioritize drug rehabilitation programs and aide for prisoner reentry into society, a move intended to capitalize on President Bill Clinton's tougher crime initiatives such as the 1994 crime bill passed under his administration. The platform failed to gain much traction among members of the party during his presidency.[62]
",2
1625,"With the inauguration of Bush as president, the Republican Party remained fairly cohesive for much of the 2000s as both strong economic libertarians and social conservatives opposed the Democrats, whom they saw as the party of bloated, secular, and liberal government.[63] This period saw the rise of ""pro-government conservatives""—a core part of the Bush's base—a considerable group of the Republicans who advocated for increased government spending and greater regulations covering both the economy and people's personal lives as well as for an activist, interventionist foreign policy.[64] Survey groups such as the Pew Research Center found that social conservatives and free market advocates remained the other two main groups within the party's coalition of support, with all three being roughly equal in number.[65][66] However, libertarians and libertarian-leaning conservatives increasingly found fault with what they saw as Republicans' restricting of vital civil liberties while corporate welfare and the national debt hiked considerably under Bush's tenure.[67] In contrast, some social conservatives expressed dissatisfaction with the party's support for economic policies that conflicted with their moral values.[68]
",2
1626,"The Republican Party lost its Senate majority in 2001 when the Senate became split evenly; nevertheless, the Republicans maintained control of the Senate due to the tie-breaking vote of Republican Vice President Dick Cheney. Democrats gained control of the Senate on June 6, 2001, when Republican Senator Jim Jeffords of Vermont switched his party affiliation to Democrat. The Republicans regained the Senate majority in the 2002 elections. Republican majorities in the House and Senate were held until the Democrats regained control of both chambers in the mid-term elections of 2006.[69][70]
",2
1627,"In 2008, Republican Senator John McCain of Arizona and Governor Sarah Palin of Alaska were defeated by Democratic Senators Barack Obama and Joe Biden of Illinois and Delaware, respectively.[71]
",2
1628,"The Republicans experienced electoral success in the wave election of 2010, which coincided with the ascendancy of the Tea Party movement,[72][73][74][75] a fiscally conservative political movement. Members of the movement called for lower taxes, and for a reduction of the national debt of the United States and federal budget deficit through decreased government spending.[76][77] It was also described as a popular constitutional movement[78] composed of a mixture of libertarian, right-wing populist, and conservative activism. That success began with the upset win of Scott Brown in the Massachusetts special Senate election for a seat that had been held for decades by the Democratic Kennedy brothers.[79] In the November elections, Republicans recaptured control of the House, increased their number of seats in the Senate and gained a majority of governorships.[80]
",2
1629,"When Obama and Biden won re-election in 2012, defeating a Mitt Romney-Paul Ryan ticket,[81] the  Republicans lost seven seats in the House in the November congressional elections, but still retained control of that chamber.[82] However, Republicans were not able to gain control of the Senate, continuing their minority status with a net loss of two seats.[83] In the aftermath of the loss, some prominent Republicans spoke out against their own party.[84][85][86] A post-2012 post-mortem report by the Republican Party concluded that the party needed to do more on the national level to attract votes from minorities and young voters.[87] In March 2013, National Committee Chairman Reince Priebus gave a stinging report on the party's electoral failures in 2012, calling on Republicans to reinvent themselves and officially endorse immigration reform. He said: ""There's no one reason we lost. Our message was weak; our ground game was insufficient; we weren't inclusive; we were behind in both data and digital, and our primary and debate process needed improvement."" He proposed 219 reforms that included a $10 million marketing campaign to reach women, minorities and gays as well as setting a shorter, more controlled primary season and creating better data collection facilities.[88]
",2
1630,"A March 2013 poll found that a majority of Republicans and Republican-leaning independents under the age of 49 supported legal recognition of same-sex marriages. Former House Speaker Newt Gingrich remarked that the ""[p]arty is going to be torn on this issue"".[89][90] A Reuters/Ipsos survey from April 2015 found that 68% of Americans overall would attend the same-sex wedding of a loved one, with 56% of Republicans agreeing. Reuters journalist Jeff Mason remarked that ""Republicans who stake out strong opposition to gay marriage could be on shaky political ground if their ultimate goal is to win the White House"" given the divide between the social conservative stalwarts and the rest of the United States that opposes them.[91] In 2015, the Supreme Court of the United States ruled bans on same-sex marriage to be unconstitutional, thus legalizing same-sex marriage nationwide.[92] In 2016, after being elected president, Republican Donald Trump stated that he was ""fine"" with same-sex marriage.[93]
",2
1631,"Following the 2014 midterm elections, the Republican Party took control of the Senate by gaining nine seats.[94] With a final total of 247 seats (57%) in the House and 54 seats in the Senate, the Republicans ultimately achieved their largest majority in the Congress since the 71st Congress in 1929.[95]
",2
1632,"The election of Republican Donald Trump to the presidency in 2016 marked a populist shift in the Republican Party.[96] Trump's defeat of Democratic candidate Hillary Clinton was unexpected, as polls had shown Clinton leading the race.[97] Trump's victory was fueled by narrow victories in three states—Michigan, Pennsylvania and Wisconsin—that had traditionally been part of the Democratic blue wall for decades. According to NBC News, ""Trump’s power famously came from his 'silent majority'—working-class white voters who felt mocked and ignored by an establishment loosely defined by special interests in Washington, news outlets in New York and tastemakers in Hollywood. He built trust within that base by abandoning Republican establishment orthodoxy on issues like trade and government spending in favor of a broader nationalist message"".[98][99]
",2
1633,"After the 2016 elections, Republicans maintained a majority in the Senate, House, state governorships and wielded newly acquired executive power with the ascension of Trump to the presidency. The Republican Party controlled 69 of 99 state legislative chambers in 2017, the most it had held in history;[100] and at least 33 governorships, the most it had held since 1922.[101] The party had total control of government (legislative chambers and governorship) in 25 states,[102][103] the most since 1952;[104] the opposing Democratic Party had full control in only five states.[105] Following the results of the 2018 midterm elections, the Republicans lost control of the House yet maintained hold of the Senate.[106]
",2
1634,"In the course of his term of office, Trump appointed three justices to the Supreme Court: Neil Gorsuch replacing Antonin Scalia, Brett Kavanaugh replacing Anthony Kennedy, and Amy Coney Barrett replacing Ruth Bader Ginsburg. The most appointments of any president in a single term since fellow Republican Richard Nixon, Trump's was seen as solidifying a 6–3 conservative majority.[107][108]
",2
1635,"Trump was impeached on December 18, 2019, on charges of abuse of power and obstruction of Congress.[109][110] He was acquitted by the Senate on February 5, 2020.[111] 195 of the 197 Republicans within the House voted against the charges with none voting in favor, the two abstaining Republicans were due to external reasons unrelated to the impeachment itself.[112] 52 of the 53 Republicans within the Senate voted against the charges as well, successfully acquitting Trump as a result, with only Senator Mitt Romney of Utah dissenting and voting in favor of one of the charges (abuse of power).[113][114] Following his refusal to concede his loss in the 2020 elections, which led to the U.S. Capitol being stormed by his supporters on January 6, 2021, the House impeached Trump for a second time on charges of incitement of insurrection, making him the only federal officeholder in the history of the United States to be impeached twice.[115][116] He left office on January 20, 2021, but the impeachment continued into the early weeks of the Biden administration, with him being ultimately acquitted a second time by the Senate on February 13, 2021.[117] Seven Republicans voted to impeach, including Romney once again, Richard Burr, Bill Cassidy, Susan Collins, Lisa Murkowski, Ben Sasse and Pat Toomey. Their states' respective Republican parties condemned them for doing so, as well, Republican U.S. Representative Liz Cheney was censured by her state GOP for her impeachment vote in the House.[118][119] In response to Trump's efforts to overturn the 2020 elections and the subsequent storming of the U.S. Capitol, dozens of Republican former members of the Bush administration made their abandonment of the party public, calling it the ""cult of Trump.""[120]
",2
1636,"The party's founding members chose the name Republican Party in the mid-1850s as homage to the values of republicanism promoted by Thomas Jefferson's Republican Party.[122] The idea for the name came from an editorial by the party's leading publicist, Horace Greeley, who called for ""some simple name like 'Republican' [that] would more fitly designate those who had united to restore the Union to its true mission of champion and promulgator of Liberty rather than propagandist of slavery"".[123] The name reflects the 1776 republican values of civic virtue and opposition to aristocracy and corruption.[124] It is important to note that ""republican"" has a variety of meanings around the world and the Republican Party has evolved such that the meanings no longer always align.[125][126]
",2
1637,"The term ""Grand Old Party"" is a traditional nickname for the Republican Party and the abbreviation ""GOP"" is a commonly used designation. The term originated in 1875 in the Congressional Record, referring to the party associated with the successful military defense of the Union as ""this gallant old party."" The following year in an article in the Cincinnati Commercial, the term was modified to ""grand old party."" The first use of the abbreviation is dated 1884.[127]
",2
1638,"The traditional mascot of the party is the elephant. A political cartoon by Thomas Nast, published in Harper's Weekly on November 7, 1874, is considered the first important use of the symbol.[128] An alternate symbol of the Republican Party in states such as Indiana, New York and Ohio is the bald eagle as opposed to the Democratic rooster or the Democratic five-pointed star.[129][130] In Kentucky, the log cabin is a symbol of the Republican Party (not related to the gay Log Cabin Republicans organization).[131]
",2
1639,"Traditionally the party had no consistent color identity.[132][133][134] After the 2000 election, the color red became associated with Republicans. During and after the election, the major broadcast networks used the same color scheme for the electoral map: states won by Republican nominee George W. Bush were colored red and states won by Democratic nominee Al Gore were colored blue. Due to the weeks-long dispute over the election results, these color associations became firmly ingrained, persisting in subsequent years. Although the assignment of colors to political parties is unofficial and informal, the media has come to represent the respective political parties using these colors. The party and its candidates have also come to embrace the color red.[135]
",2
1640,"Republicans believe that free markets and individual achievement are the primary factors behind economic prosperity. Republicans frequently advocate in favor of fiscal conservatism during Democratic administrations; however, they have shown themselves willing to increase federal debt when they are in charge of the government (the implementation of the Bush tax cuts, Medicare Part D and the Tax Cuts and Jobs Act of 2017 are examples of this willingness).[136][137][138] Despite pledges to roll back government spending, Republican administrations have, since the late 1960s, sustained or increased previous levels of government spending.[139][140]
",2
1641,"Modern Republicans advocate the theory of supply-side economics, which holds that lower tax rates increase economic growth.[141] Many Republicans oppose higher tax rates for higher earners, which they believe are unfairly targeted at those who create jobs and wealth. They believe private spending is more efficient than government spending. Republican lawmakers have also sought to limit funding for tax enforcement and tax collection.[142]
",2
1642,"Republicans believe individuals should take responsibility for their own circumstances. They also believe the private sector is more effective in helping the poor through charity than the government is through welfare programs and that social assistance programs often cause government dependency.[citation needed]
",2
1643,"Republicans believe corporations should be able to establish their own employment practices, including benefits and wages, with the free market deciding the price of work. Since the 1920s, Republicans have generally been opposed by labor union organizations and members. At the national level, Republicans supported the Taft-Hartley Act of 1947, which gives workers the right not to participate in unions. Modern Republicans at the state level generally support various right-to-work laws, which prohibit union security agreements requiring all workers in a unionized workplace to pay dues or a fair-share fee, regardless of if they are members of the union or not.[143]
",2
1644,"Most Republicans oppose increases in the minimum wage, believing that such increases hurt businesses by forcing them to cut and outsource jobs while passing on costs to consumers.[144]
",2
1645,"The party opposes a single-payer health care system, describing it as socialized medicine. The Republican Party has a mixed record of supporting the historically popular Social Security, Medicare and Medicaid programs,[145] whereas it has sought to repeal the Affordable Care Act since its introduction in 2010.[146]
",2
1646,"Historically, progressive leaders in the Republican Party supported environmental protection. Republican President Theodore Roosevelt was a prominent conservationist whose policies eventually led to the creation of the National Park Service.[148] While Republican President Richard Nixon was not an environmentalist, he signed legislation to create the Environmental Protection Agency in 1970 and had a comprehensive environmental program.[149] However, this position has changed since the 1980s and the administration of President Ronald Reagan, who labeled environmental regulations a burden on the economy.[150] Since then, Republicans have increasingly taken positions against environmental regulation, with some Republicans rejecting the scientific consensus on climate change.[150][151][152][153]
",2
1647,"In 2006, then-California Governor Arnold Schwarzenegger broke from Republican orthodoxy to sign several bills imposing caps on carbon emissions in California. Then-President George W. Bush opposed mandatory caps at a national level. Bush's decision not to regulate carbon dioxide as a pollutant was challenged in the Supreme Court by 12 states,[154] with the court ruling against the Bush administration in 2007.[155] Bush also publicly opposed ratification of the Kyoto Protocols[150][156] which sought to limit greenhouse gas emissions and thereby combat climate change; his position was heavily criticized by climate scientists.[157]
",2
1648,"The Republican Party rejects cap-and-trade policy to limit carbon emissions.[158] In the 2000s, Senator John McCain proposed bills (such as the McCain-Lieberman Climate Stewardship Act) that would have regulated carbon emissions, but his position on climate change was unusual among high-ranking party members.[150] Some Republican candidates have supported the development of alternative fuels in order to achieve energy independence for the United States. Some Republicans support increased oil drilling in protected areas such as the Arctic National Wildlife Refuge, a position that has drawn criticism from activists.[159]
",2
1649,"Many Republicans during the presidency of Barack Obama opposed his administration's new environmental regulations, such as those on carbon emissions from coal. In particular, many Republicans supported building the Keystone Pipeline; this position was supported by businesses, but opposed by indigenous peoples' groups and environmental activists.[160][161][162]
",2
1650,"According to the Center for American Progress, a non-profit liberal advocacy group, more than 55% of congressional Republicans were climate change deniers in 2014.[163][164] PolitiFact in May 2014 found ""relatively few Republican members of Congress ... accept the prevailing scientific conclusion that global warming is both real and man-made."" The group found eight members who acknowledged it, although the group acknowledged there could be more and that not all members of Congress have taken a stance on the issue.[165][166]
",2
1651,"From 2008 to 2017, the Republican Party went from ""debating how to combat human-caused climate change to arguing that it does not exist"", according to The New York Times.[167] In January 2015, the Republican-led U.S. Senate voted 98–1 to pass a resolution acknowledging that ""climate change is real and is not a hoax""; however, an amendment stating that ""human activity significantly contributes to climate change"" was supported by only five Republican senators.[168]
",2
1652,"In the period 1850–1870, the Republican Party was more opposed to immigration than Democrats, in part because the Republican Party relied on the support of anti-Catholic and anti-immigrant parties, such as the Know-Nothings, at the time. In the decades following the Civil War, the Republican Party grew more supportive of immigration, as it represented manufacturers in the Northeast (who wanted additional labor) whereas the Democratic Party came to be seen as the party of labor (which wanted fewer laborers to compete with). Starting in the 1970s, the parties switched places again, as the Democrats grew more supportive of immigration than Republicans.[169]
",2
1653,"Republicans are divided on how to confront illegal immigration between a platform that allows for migrant workers and a path to citizenship for undocumented immigrants (supported more by the Republican establishment), versus a position focused on securing the border and deporting illegal immigrants (supported by populists). In 2006, the White House supported and Republican-led Senate passed comprehensive immigration reform that would eventually allow millions of illegal immigrants to become citizens, but the House (also led by Republicans) did not advance the bill.[170] After the defeat in the 2012 presidential election, particularly among Latinos, several Republicans advocated a friendlier approach to immigrants. However, in 2016 the field of candidates took a sharp position against illegal immigration, with leading candidate Donald Trump proposing building a wall along the southern border. Proposals calling for immigration reform with a path to citizenship for undocumented immigrants have attracted broad Republican support in some[which?] polls. In a 2013 poll, 60% of Republicans supported the pathway concept.[171]
",2
1654,"Some[who?] in the Republican Party support unilateralism on issues of national security, believing in the ability and right of the United States to act without external support in matters of its national defense. In general, Republican thinking on defense and international relations is heavily influenced by the theories of neorealism and realism, characterizing conflicts between nations as struggles between faceless forces of an international structure as opposed to being the result of the ideas and actions of individual leaders. The realist school's influence shows in Reagan's Evil Empire stance on the Soviet Union and George W. Bush's Axis of evil stance.[citation needed]
",2
1655,"Since the September 11, 2001 attacks, many[who?] in the party have supported neoconservative policies with regard to the War on Terror, including the 2001 war in Afghanistan and the 2003 invasion of Iraq. The George W. Bush administration took the position that the Geneva Conventions do not apply to unlawful combatants, while other[which?] prominent Republicans strongly oppose the use of enhanced interrogation techniques, which they view as torture.[172]
",2
1656,"Republicans have frequently advocated for restricting foreign aid as a means of asserting the national security and immigration interests of the United States.[173][174][175]
",2
1657,"The Republican Party generally supports a strong alliance with Israel and efforts to secure peace in the Middle East between Israel and its Arab neighbors.[176][177] In recent years, Republicans have begun to move away from the two-state solution approach to resolving the Israeli–Palestinian conflict.[178][179] In a 2014 poll, 59% of Republicans favored doing less abroad and focusing on the country's own problems instead.[180]
",2
1658,"According to the 2016 platform,[181] the party's stance on the status of Taiwan is: ""We oppose any unilateral steps by either side to alter the status quo in the Taiwan Straits on the principle that all issues regarding the island's future must be resolved peacefully, through dialogue, and be agreeable to the people of Taiwan."" In addition, if ""China were to violate those principles, the United States, in accord with the Taiwan Relations Act, will help Taiwan defend itself"".
",2
1659,"The Republican Party is generally associated with social conservative policies, although it does have dissenting centrist and libertarian factions. The social conservatives support laws that uphold their traditional values, such as opposition to same-sex marriage, abortion, and marijuana.[182] Most conservative Republicans also oppose gun control, affirmative action, and illegal immigration.[182][183]
",2
1660,"A majority of the party's national and state candidates are anti-abortion and oppose elective abortion on religious or moral grounds. While many advocate exceptions in the case of incest, rape or the mother's life being at risk, in 2012 the party approved a platform advocating banning abortions without exception.[184] There were not highly polarized differences between the Democratic Party and the Republican Party prior to the Roe v. Wade 1973 Supreme Court ruling (which made prohibitions on abortion rights unconstitutional), but after the Supreme Court ruling, opposition to abortion became an increasingly key national platform for the Republican Party.[15][185][186] As a result, Evangelicals gravitated towards the Republican Party.[15][185]
",2
1661,"Most Republicans oppose government funding for abortion providers, notably Planned Parenthood.[187] This includes support for the Hyde Amendment.
",2
1662,"Until its dissolution in 2018, Republican Majority for Choice, an abortion rights PAC, advocated for amending the GOP platform to include pro-abortion rights members.[188]
",2
1663,"Although Republicans have voted for increases in government funding of scientific research, members of the Republican Party actively oppose the federal funding of embryonic stem cell research beyond the original lines because it involves the destruction of human embryos.[189][190][191][192]
",2
1664,"Republicans are generally against affirmative action for women and some minorities, often describing it as a ""quota system"" and believing that it is not meritocratic and that it is counter-productive socially by only further promoting discrimination. Many[who?] Republicans support race-neutral admissions policies in universities, but support taking into account the socioeconomic status of the student.[193][194]
",2
1665,"Republicans generally support gun ownership rights and oppose laws regulating guns. Party members and Republican-leaning independents are twice more likely to own a gun than Democrats and Democratic-leaning independents.[195]
",2
1666,"The National Rifle Association, a special interest group in support of gun ownership, has consistently aligned itself with the Republican Party. Following gun control measures under the Clinton administration, such as the Violent Crime Control and Law Enforcement Act of 1994, the Republicans allied with the NRA during the Republican Revolution in 1994.[196] Since then, the NRA has consistently backed Republican candidates and contributed financial support, such as in the 2013 Colorado recall election which resulted in the ousting of two pro-gun control Democrats for two anti-gun control Republicans.[197]
",2
1667,"In contrast, George H. W. Bush, formerly a lifelong NRA member, was highly critical of the organization following their response to the Oklahoma City bombing authored by CEO Wayne LaPierre, and publicly resigned in protest.[198]
",2
1668,"Republicans have historically supported the War on Drugs, as well as oppose legalization or decriminalization of drugs, including marijuana.[199][200] The opposition to the legalization of marijuana has softened over time.[201][202]
",2
1669,"Republicans have historically opposed same-sex marriage, while being divided on civil unions and domestic partnerships, with the issue being one that many believe helped George W. Bush win re-election in 2004.[203] In both 2004[204] and 2006,[205] President Bush, Senate Majority Leader Bill Frist, and House Majority Leader John Boehner promoted the Federal Marriage Amendment, a proposed constitutional amendment which would legally restrict the definition of marriage to heterosexual couples.[206][207][208] In both attempts, the amendment failed to secure enough votes to invoke cloture and thus ultimately was never passed. As more states legalized same-sex marriage in the 2010s, Republicans increasingly supported allowing each state to decide its own marriage policy.[209] As of 2014, most state GOP platforms expressed opposition to same-sex marriage.[210] The 2016 GOP Platform defined marriage as ""natural marriage, the union of one man and one woman,"" and condemned the Supreme Court's ruling legalizing same-sex marriages.[211][212] The 2020 platform retained the 2016 language against same-sex marriage.[213][214][215]
",2
1670,"However, public opinion on this issue within the party has been changing.[216] Following his election as president in 2016, Donald Trump stated that he had no objection to same-sex marriage or to the Supreme Court decision in Obergefell v. Hodges.[93] In office, Trump was the first sitting Republican president to recognize LGBT Pride Month.[217] Conversely, the Trump administration banned transgender individuals from service in the United States military and rolled back other protections for transgender people which had been enacted during the previous Democratic presidency.[218]
",2
1671,"The Republican Party platform previously opposed the inclusion of gay people in the military and opposed adding sexual orientation to the list of protected classes since 1992.[219][220][221] The Republican Party opposed the inclusion of sexual preference in anti-discrimination statutes from 1992 to 2004.[222] The 2008 and 2012 Republican Party platform supported anti-discrimination statutes based on sex, race, age, religion, creed, disability, or national origin, but both platforms were silent on sexual orientation and gender identity.[223][224] The 2016 platform was opposed to sex discrimination statutes that included the phrase ""sexual orientation.""[225][226]
",2
1672,"The Log Cabin Republicans is a group within the Republican Party that represents LGBT conservatives and allies and advocates for LGBT rights and equality.[227]
",2
1673,"Virtually all restrictions on voting have in recent years been implemented by Republicans. Republicans, mainly at the state level, argue that the restrictions (such as purging voter rolls, limiting voting locations, and prosecuting double voting) are vital to prevent voter fraud, claiming that voter fraud is an underestimated issue in elections. However, research has indicated that voter fraud is very uncommon, as civil and voting rights organizations often accuse Republicans of enacting restrictions to influence elections in the party's favor. Many laws or regulations restricting voting enacted by Republicans have been successfully challenged in court, with court rulings striking down such regulations and accusing Republicans of establishing them with partisan purpose.[228][229]
",2
1674,"Towards the end of the 1990s and in the early 21st century, the Republican Party increasingly resorted to ""constitutional hardball"" practices.[230][231][232]
",2
1675,"A number of scholars have asserted that the House speakership of Republican Newt Gingrich played a key role in undermining democratic norms in the United States, hastening political polarization, and increasing partisan prejudice.[233][234][235][236][237] According to Harvard University political scientists Daniel Ziblatt and Steven Levitsky, Gingrich's speakership had a profound and lasting impact on American politics and the health of American democracy. They argue that Gingrich instilled a ""combative"" approach in the Republican Party, where hateful language and hyper-partisanship became commonplace, and where democratic norms were abandoned. Gingrich frequently questioned the patriotism of Democrats, called them corrupt, compared them to fascists, and accused them of wanting to destroy the United States. Gingrich was also involved in several major government shutdowns.[237][238][239][240]
",2
1676,"Scholars have also characterized Mitch McConnell's tenure as Senate Minority Leader and Senate Majority Leader during the Obama presidency as one where obstructionism reached all-time highs.[241] Political scientists have referred to McConnell's use of the filibuster as ""constitutional hardball"", referring to the misuse of procedural tools in a way that undermines democracy.[230][237][242][243] McConnell delayed and obstructed health care reform and banking reform, which were two landmark pieces of legislation that Democrats sought to pass (and in fact did pass[244]) early in Obama's tenure.[245][246] By delaying Democratic priority legislation, McConnell stymied the output of Congress. Political scientists Eric Schickler and Gregory J. Wawro write, ""by slowing action even on measures supported by many Republicans, McConnell capitalized on the scarcity of floor time, forcing Democratic leaders into difficult trade-offs concerning which measures were worth pursuing. That is, given that Democrats had just two years with sizeable majorities to enact as much of their agenda as possible, slowing the Senate's ability to process even routine measures limited the sheer volume of liberal bills that could be adopted.""[246]
",2
1677,"McConnell's refusal to hold hearings on Supreme Court nominee Merrick Garland during the final year of Obama's presidency was described by political scientists and legal scholars as ""unprecedented"",[247][248] a ""culmination of this confrontational style"",[249] a ""blatant abuse of constitutional norms"",[250] and a ""classic example of constitutional hardball.""[243]
",2
1678,"After the 2020 United States presidential election was declared for Biden, President Donald Trump's refusal to concede and demands of Republican state legislatures and officials to ignore the popular vote of the states was described as ""unparalleled"" in American history[251] and ""profoundly antidemocratic"".[252] Some journalists and foreign officials have also referred to Trump as a fascist in the aftermath of the 2021 storming of the United States Capitol.[253][254][255]
",2
1679,"Following the storming of the Capitol, a survey conducted by the American Enterprise Institute found that 56% of Republicans agreed with the statement, ""The traditional American way of life is disappearing so fast that we may have to use force to save it,"" compared to 36% of respondents overall. Sixty percent of white evangelical Republicans agreed with the statement.[256][257][258]
",2
1680,"An October 2020 study by the V-Dem Institute found that the Republican party had become increasingly illiberal in recent decades, appearing to follow a similar trajectory to authoritarian parties such as Fidesz of Hungary, the AKP of Turkey and the BJP of India. The study found “data shows that the Republican party in 2018 was far more illiberal than almost all other governing parties in democracies.” [259][260][261][262]
",2
1681,"In the Party's early decades, its base consisted of Northern white Protestants and African Americans nationwide. Its first presidential candidate, John C. Frémont, received almost no votes in the South. This trend continued into the 20th century. Following the passage of the Civil Rights Act of 1964 and Voting Rights Act of 1965, the Southern states became more reliably Republican in presidential politics, while Northeastern states became more reliably Democratic.[263][264][265][266][267][268][269][270] Studies show that Southern whites shifted to the Republican Party due to racial conservatism.[269][271][272]
",2
1682,"While scholars agree that a racial backlash played a central role in the racial realignment of the two parties, there is a dispute as to the extent in which the racial realignment was a top-driven elite process or a bottom-up process.[273] The ""Southern Strategy"" refers primarily to ""top-down"" narratives of the political realignment of the South which suggest that Republican leaders consciously appealed to many white Southerners' racial grievances in order to gain their support. This top-down narrative of the Southern Strategy is generally believed to be the primary force that transformed Southern politics following the civil rights era. Scholar Matthew Lassiter argues that ""demographic change played a more important role than racial demagoguery in the emergence of a two-party system in the American South"".[274][275] Historians such as Matthew Lassiter, Kevin M. Kruse and Joseph Crespino, have presented an alternative, ""bottom-up"" narrative, which Lassiter has called the ""suburban strategy."" This narrative recognizes the centrality of racial backlash to the political realignment of the South,[273] but suggests that this backlash took the form of a defense of de facto segregation in the suburbs rather than overt resistance to racial integration and that the story of this backlash is a national rather than a strictly Southern one.[276][277][278][279]
",2
1683,"The Party's 21st-century base consists of groups such as older white men; white, married Protestants; rural residents; and non-union workers without college degrees, with urban residents, ethnic minorities, the unmarried and union workers having shifted to the Democratic Party. The suburbs have become a major battleground.[280] According to a 2015 Gallup poll, 25% of Americans identify as Republican and 16% identify as leaning Republican. In comparison, 30% identify as Democratic and 16% identify as leaning Democratic. The Democratic Party has typically held an overall edge in party identification since Gallup began polling on the issue in 1991.[281] In 2016, The New York Times noted that the Republican Party was strong in the South, the Great Plains, and the Mountain States.[282] The 21st century Republican Party also draws strength from rural areas of the United States.[283]
",2
1684,"In 2018, Gallup polling found that 69% of Republicans described themselves as ""conservative"", while 25% opted for the term ""moderate"", and another 5% self-identified as ""liberal"".[284]
",2
1685,"When ideology is separated into social and economic issues, a 2020 Gallup poll found that 61% of Republicans and Republican-leaning independents called themselves ""socially conservative"", 28% chose the label ""socially moderate"", and 10% called themselves ""socially liberal"".[285] On economic issues, the same 2020 poll revealed that 65% of Republicans (and Republican leaners) chose the label ""economic conservative"" to describe their views on fiscal policy, while 26% selected the label ""economic moderate"", and 7% opted for the ""economic liberal"" label.[285]
",2
1686,"The modern Republican Party includes conservatives,[2] centrists,[3] fiscal conservatives, libertarians,[4] neoconservatives,[4] paleoconservatives,[286] right-wing populists,[5][6] and social conservatives.[287][288][289]
",2
1687,"In addition to splits over ideology, the 21st-century Republican Party can be broadly divided into establishment and anti-establishment wings.[290][291] Nationwide polls of Republican voters in 2014 by the Pew Center identified a growing split in the Republican coalition, between ""business conservatives"" or ""establishment conservatives"" on one side and ""steadfast conservatives"" or ""populist conservatives"" on the other.[292]
",2
1688,"In the 21st century, conservatives on talk radio and Fox News, as well as online media outlets such as the Daily Caller and Breitbart News, became a powerful influence on shaping the information received and judgments made by rank-and-file Republicans.[293][294] They include Rush Limbaugh, Sean Hannity, Larry Elder, Glenn Beck, Mark Levin, Dana Loesch, Hugh Hewitt, Mike Gallagher, Neal Boortz, Laura Ingraham, Dennis Prager, Michael Reagan, Howie Carr and Michael Savage, as well as many local commentators who support Republican causes while vocally opposing the left.[295][296][297][298] Vice President Mike Pence also had an early career in conservative talk radio, hosting The Mike Pence Show in the late 1990s before successfully running for Congress in 2000.[299]
",2
1689,"The Republican Party has traditionally been a pro-business party. It garners major support from a wide variety of industries from the financial sector to small businesses. Republicans are about 50 percent more likely to be self-employed and are more likely to work in management.[300][clarification needed]
",2
1690,"A survey cited by The Washington Post in 2012 stated that 61 percent of small business owners planned to vote for Republican presidential candidate Mitt Romney. Small business became a major theme of the 2012 Republican National Convention.[301]
",2
1691,"In 2006, Republicans won 38% of the voters aged 18–29.[302] In a 2018 study, members of the Silent and Baby Boomer generations were more likely to express approval of Trump's presidency than those of Generation X and Millennials.[303]
",2
1692,"Low-income voters are more likely to identify as Democrats while high-income voters are more likely to identify as Republicans.[304] In 2012, Obama won 60% of voters with income under $50,000 and 45% of those with incomes higher than that.[305] Bush won 41% of the poorest 20% of voters in 2004, 55% of the richest twenty percent and 53% of those in between. In the 2006 House races, the voters with incomes over $50,000 were 49% Republican while those with incomes under that amount were 38% Republican.[302]
",2
1693,"Since 1980, a ""gender gap"" has seen stronger support for the Republican Party among men than among women. Unmarried and divorced women were far more likely to vote for Democrat John Kerry than for Republican George W. Bush in the 2004 presidential election.[306] In 2006 House races, 43% of women voted Republican while 47% of men did so.[302] In the 2010 midterms, the ""gender gap"" was reduced, with women supporting Republican and Democratic candidates equally (49%-49%).[307][308] Exit polls from the 2012 elections revealed a continued weakness among unmarried women for the GOP, a large and growing portion of the electorate.[309] Although women supported Obama over Mitt Romney by a margin of 55–44% in 2012, Romney prevailed amongst married women, 53–46%.[310] Obama won unmarried women 67–31%.[311] According to a December 2019 study, ""white women are the only group of female voters who support Republican Party candidates for president. They have done so by a majority in all but 2 of the last 18 elections"".[312]
",2
1694,"In 2012, the Pew Research Center conducted a study of registered voters with a 35–28 Democrat-to-Republican gap. They found that self-described Democrats had an eight-point advantage over Republicans among college graduates and a fourteen-point advantage among all post-graduates polled. Republicans had an eleven-point advantage among white men with college degrees; Democrats had a ten-point advantage among women with degrees. Democrats accounted for 36% of all respondents with an education of high school or less; Republicans accounted for 28%. When isolating just white registered voters polled, Republicans had a six-point advantage overall and a nine-point advantage among those with a high school education or less.[313] Following the 2016 presidential election, exit polls indicated that ""Donald Trump attracted a large share of the vote from whites without a college degree, receiving 72 percent of the white non-college male vote and 62 percent of the white non-college female vote."" Overall, 52% of voters with college degrees voted for Hillary Clinton in 2016, while 52% of voters without college degrees voted for Trump.[314]
",2
1695,"Republicans have been winning under 15% of the black vote in recent national elections (1980 to 2016). The party abolished chattel slavery under Abraham Lincoln, defeated the Slave Power, and gave blacks the legal right to vote during Reconstruction in the late 1860s. Until the New Deal of the 1930s, blacks supported the Republican Party by large margins.[315] Black delegates were a sizable share of Southern delegates to the national Republican convention from Reconstruction until the start of the 20th century when their share began to decline.[316] Black voters began shifting away from the Republican Party after the close of Reconstruction through the early 20th century, with the rise of the southern-Republican lily-white movement.[317] Blacks shifted in large margins to the Democratic Party in the 1930s, when major Democratic figures such as Eleanor Roosevelt began to support civil rights and the New Deal offered them employment opportunities. They became one of the core components of the New Deal coalition. In the South, after the Voting Rights Act to prohibit racial discrimination in elections was passed by a bipartisan coalition in 1965, blacks were able to vote again and ever since have formed a significant portion (20–50%) of the Democratic vote in that region.[318]
",2
1696,"In the 2010 elections, two African-American Republicans—Tim Scott and Allen West—were elected to the House of Representatives.[319]
",2
1697,"In recent decades, Republicans have been moderately successful in gaining support from Hispanic and Asian American voters. George W. Bush, who campaigned energetically for Hispanic votes, received 35% of their vote in 2000 and 44% in 2004.[320] The party's strong anti-communist stance has made it popular among some minority groups from current and former Communist states, in particular Cuban Americans, Korean Americans, Chinese Americans and Vietnamese Americans. The 2007 election of Bobby Jindal as Governor of Louisiana was hailed as pathbreaking.[321] Jindal became the first elected minority governor in Louisiana and the first state governor of Indian descent.[322] According to John Avlon, in 2013, the Republican party was more ethnically diverse at the statewide elected official level than the Democratic Party was; GOP statewide elected officials included Latino Nevada Governor Brian Sandoval and African-American U.S. senator Tim Scott of South Carolina.[323]
",2
1698,"In 2012, 88% of Romney voters were white while 56% of Obama voters were white.[324] In the 2008 presidential election, John McCain won 55% of white votes, 35% of Asian votes, 31% of Hispanic votes and 4% of African American votes.[325] In the 2010 House election, Republicans won 60% of the white votes, 38% of Hispanic votes and 9% of the African American vote.[326]
",2
1699,"As of 2020, Republican candidates had lost the popular vote in seven out of the last eight presidential elections.[327] Since 1992, the only time they won the popular vote in a presidential election is the 2004 United States presidential election. Demographers have pointed to the steady decline (as a percentage of the eligible voters) of its core base of older, less educated men.[328][329][330][331] However, Donald Trump managed to increase nonwhite support to 26% of his total votes in the 2020 election — the highest percentage for a GOP presidential candidate since 1960.[332][333]
",2
1700,"Religion has always played a major role for both parties, but in the course of a century, the parties' religious compositions have changed. Religion was a major dividing line between the parties before 1960, with Catholics, Jews, and Southern Protestants heavily Democratic and Northeastern Protestants heavily Republican. Most of the old differences faded away after the realignment of the 1970s and 1980s that undercut the New Deal coalition.[334] Voters who attended church weekly gave 61% of their votes to Bush in 2004; those who attended occasionally gave him only 47%; and those who never attended gave him 36%. Fifty-nine percent of Protestants voted for Bush, along with 52% of Catholics (even though John Kerry was Catholic). Since 1980, a large majority of evangelicals has voted Republican; 70–80% voted for Bush in 2000 and 2004 and 70% for Republican House candidates in 2006. Jews continue to vote 70–80% Democratic. Democrats have close links with the African American churches, especially the National Baptists, while their historic dominance among Catholic voters has eroded to 54–46 in the 2010 midterms.[335] The mainline traditional Protestants (Methodists, Lutherans, Presbyterians, Episcopalians and Disciples) have dropped to about 55% Republican (in contrast to 75% before 1968).
",2
1701,"Members of the Church of Jesus Christ of Latter-day Saints in Utah and neighboring states voted 75% or more for George W. Bush in 2000.[336] Members of the Mormon faith had a mixed relationship with Donald Trump during his tenure, despite 67% of them voting for him in 2016 and 56% of them supporting his presidency in 2018, disapproving of his personal behavior such as that shown during the Access Hollywood controversy.[337] Their opinion on Trump hadn't affected their party affiliation, however, as 76% of Mormons in 2018 expressed preference for generic Republican congressional candidates.[338]
",2
1702,"While Catholic Republican leaders try to stay in line with the teachings of the Catholic Church on subjects such as abortion, euthanasia, embryonic stem cell research and same-sex marriage, they differ on the death penalty and contraception.[339] Pope Francis' 2015 encyclical Laudato si' sparked a discussion on the positions of Catholic Republicans in relation to the positions of the Church. The Pope's encyclical on behalf of the Catholic Church officially acknowledges a man-made climate change caused by burning fossil fuels.[340] The Pope says the warming of the planet is rooted in a throwaway culture and the developed world's indifference to the destruction of the planet in pursuit of short-term economic gains. According to The New York Times, Laudato si' put pressure on the Catholic candidates in the 2016 election: Jeb Bush, Bobby Jindal, Marco Rubio and Rick Santorum.[341] With leading Democrats praising the encyclical, James Bretzke, a professor of moral theology at Boston College, has said that both sides were being disingenuous: ""I think it shows that both the Republicans and the Democrats ... like to use religious authority and, in this case, the Pope to support positions they have arrived at independently ... There is a certain insincerity, hypocrisy I think, on both sides"".[342] While a Pew Research poll indicates Catholics are more likely to believe the Earth is warming than non-Catholics, 51% of Catholic Republicans believe in global warming (less than the general population) and only 24% of Catholic Republicans believe global warming is caused by human activity.[343]
",2
1703,"In 2016, a slim majority of Orthodox Jews voted for the Republican Party, following years of growing Orthodox Jewish support for the party due to its social conservatism and increasingly pro-Israel foreign policy stance.[344] An exit poll conducted by the Associated Press for 2020 found 35% of Muslims voted for Donald Trump.[345]
",2
1704,"As of 2021, there have been a total of 19 Republican presidents.
",2
1705,"As of January 2021[update], six of the nine seats are filled by Justices appointed by Republican Presidents George H. W. Bush, George W. Bush, and Donald Trump.
",2
1706,"Associate Justice of the Supreme Court of the United States
",2
1707,"Chief Justice of the Supreme Court of the United States
",2
1708,"Associate Justice of the Supreme Court of the United States
",2
1709,"Associate Justice of the Supreme Court of the United States
",2
1710,"Associate Justice of the Supreme Court of the United States
",2
1711,"Associate Justice of the Supreme Court of the United States
",2
1712,"
",2
1713,"
",2
1714,"
",2
1715,"Socialism is a political, social, and economic philosophy encompassing a range of economic and social systems characterised by social ownership of the means of production.[1][2][3][4][5][6][7][8] It includes the political theories and movements associated with such systems.[9] Social ownership can be public, collective, cooperative, or of equity.[10] While no single definition encapsulates the many types of socialism,[11] social ownership is the one common element.[1][12][13] Socialists disagree about the degree to which social control or regulation of the economy is necessary, how far society should intervene and whether government, particularly existing government, is the correct vehicle for change.[14]
",2
1716,"Socialist systems are divided into non-market and market forms.[15] Non-market socialism substitutes factor markets and money with integrated economic planning and engineering or technical criteria based on calculation performed in-kind, thereby producing a different economic mechanism that functions according to different economic laws and dynamics than those of capitalism.[16][17][18][19] A non-market socialist system eliminates the inefficiencies and crises traditionally associated with capital accumulation and the profit system in capitalism.[20][21][22][23] The socialist calculation debate, originated by the economic calculation problem,[24][25] concerns the feasibility and methods of resource allocation for a planned socialist system.[26][27][28] By contrast, market socialism retains the use of monetary prices, factor markets and in some cases the profit motive, with respect to the operation of socially owned enterprises and the allocation of capital goods between them. Profits generated by these firms would be controlled directly by the workforce of each firm or accrue to society at large in the form of a social dividend.[29][30][31] Anarchism and libertarian socialism oppose the use of the state as a means to establish socialism, favouring decentralisation above all, whether to establish non-market socialism or market socialism.[32][33]
",2
1717,"Socialist politics has been both internationalist and nationalist in orientation; organised through political parties and opposed to party politics; at times overlapping with trade unions and at other times independent and critical of them; and present in both industrialised and developing nations.[34] Social democracy originated within the socialist movement,[35] supporting economic and social interventions to promote social justice.[36][37] While retaining socialism as a long-term goal,[38][39][40][41][42] since the post-war period it has come to embrace a Keynesian mixed economy within a predominantly developed capitalist market economy and liberal democratic polity that expands state intervention to include income redistribution, regulation and a welfare state.[43] Economic democracy proposes a sort of market socialism, with more democratic control of companies, currencies, investments and natural resources.[44]
",2
1718,"The socialist political movement includes a set of political philosophies that originated in the revolutionary movements of the mid-to-late 18th century and out of concern for the social problems that were associated with capitalism.[11] By the late 19th century, after the work of Karl Marx and his collaborator Friedrich Engels, socialism had come to signify opposition to capitalism and advocacy for a post-capitalist system based on some form of social ownership of the means of production.[45][46] By the 1920s, communism and social democracy had become the two dominant political tendencies within the international socialist movement,[47] with socialism itself becoming the most influential secular movement of the 20th century.[48] Socialist parties and ideas remain a political force with varying degrees of power and influence on all continents, heading national governments in many countries around the world. Today, many socialists have also adopted the causes of other social movements such as environmentalism, feminism and progressivism.[49]
",2
1719,"While the emergence of the Soviet Union as the world's first nominally socialist state led to socialism's widespread association with the Soviet economic model, some economists and intellectuals argued that in practice the model functioned as a form of state capitalism[50][51][52] or a non-planned administrative or command economy.[53][54] Academics, political commentators and other scholars sometimes refer to Western Bloc countries which have been democratically governed by socialist parties such as Britain, France, Sweden and Western social-democracies in general as democratic socialist.[55][56][57][58]
",2
1720,"For Andrew Vincent, ""[t]he word 'socialism' finds its root in the Latin sociare, which means to combine or to share. The related, more technical term in Roman and then medieval law was societas. This latter word could mean companionship and fellowship as well as the more legalistic idea of a consensual contract between freemen"".[59]
",2
1721,"Socialism was coined by Henri de Saint-Simon, one of the founders of what would later be labelled utopian socialism. Simon contrasted it to the liberal doctrine of individualism that emphasized the moral worth of the individual whilst stressing that people act or should act as if they are in isolation from one another. The original utopian socialists condemned this doctrine of individualism for failing to address social concerns during the Industrial Revolution, including poverty, oppression and vast wealth inequality. They viewed their society as harming community life by basing society on competition. They presented socialism as an alternative to liberal individualism based on the shared ownership of resources.[60] Saint-Simon proposed economic planning, scientific administration and the application of scientific understanding to the organisation of society. By contrast, Robert Owen proposed to organise production and ownership via cooperatives.[60][61] Socialism is also attributed in France to Pierre Leroux[62] and Marie Roch Louis Reybaud while in Britain it is associated to Owen, who became one of the fathers of the cooperative movement.[63][64]
",2
1722,"The definition and usage of socialism settled by the 1860s, replacing associationist, co-operative and mutualist that had been used as synonyms while communism fell out of use during this period.[65] An early distinction between communism and socialism was that the latter aimed to only socialise production while the former aimed to socialise both production and consumption (in the form of free access to final goods).[66] By 1888, Marxists employed socialism in place of communism as the latter had come to be considered an old-fashioned synonym for socialism. It was not until after the Bolshevik Revolution that socialism was appropriated by Vladimir Lenin to mean a stage between capitalism and communism. He used it to defend the Bolshevik program from Marxist criticism that Russia's productive forces were not sufficiently developed for communism.[67] The distinction between communism and socialism became salient in 1918 after the Russian Social Democratic Labour Party renamed itself to the All-Russian Communist Party, interpreting communism specifically to mean socialists who supported the politics and theories of Bolshevism, Leninism and later that of Marxism–Leninism,[68] although communist parties continued to describe themselves as socialists dedicated to socialism.[69] According to The Oxford Handbook of Karl Marx, ""Marx used many terms to refer to a post-capitalist society—positive humanism, socialism, Communism, realm of free individuality, free association of producers, etc. He used these terms completely interchangeably. The notion that 'socialism' and 'Communism' are distinct historical stages is alien to his work and only entered the lexicon of Marxism after his death"".[70]
",2
1723,"In Christian Europe, communists were believed to have adopted atheism. In Protestant England, communism was too close to the Roman Catholic communion rite, hence socialist was the preferred term.[71] Engels argued that in 1848, when The Communist Manifesto was published, socialism was respectable in Europe while communism was not. The Owenites in England and the Fourierists in France were considered respectable socialists while working-class movements that ""proclaimed the necessity of total social change"" denoted themselves communists. This branch of socialism produced the communist work of Étienne Cabet in France and Wilhelm Weitling in Germany.[72] British moral philosopher John Stuart Mill discussed a form of economic socialism within a liberal context that would later be known as liberal socialism. In later editions of his Principles of Political Economy (1848), Mill further argued that ""as far as economic theory was concerned, there is nothing in principle in economic theory that precludes an economic order based on socialist policies""[73][74] and promoted substituting capitalist businesses with worker cooperatives.[75] While democrats looked to the Revolutions of 1848 as a democratic revolution which in the long run ensured liberty, equality and fraternity, Marxists denounced it as a betrayal of working-class ideals by a bourgeoisie indifferent to the proletariat.[76]
",2
1724,"Socialist models and ideas espousing common or public ownership have existed since antiquity. The economy of the 3rd century BCE Mauryan Empire of India, an absolute monarchy, has been described by some scholars as ""a socialized monarchy"" and ""a sort of state socialism"" due to ""nationalisation of industries"".[77][78] Other scholars have suggested that elements of socialist thought were present in the politics of classical Greek philosophers Plato[79] and Aristotle.[80] Mazdak the Younger (died c. 524 or 528 CE), a Persian communal proto-socialist,[81] instituted communal possessions and advocated the public good. Abu Dharr al-Ghifari, a Companion of Muhammad, is credited by multiple authors as a principal antecedent of Islamic socialism.[82][83][84][85][86] The teachings of Jesus are frequently described as socialist, especially by Christian socialists.[87] Acts 4:35 records that in the early church in Jerusalem ""[n]o one claimed that any of their possessions was their own"", although the pattern soon disappears from church history except within monasticism. Christian socialism was one of the founding threads of the British Labour Party and is claimed to begin with the uprising of Wat Tyler and John Ball in the 14th century CE.[88] After the French Revolution, activists and theorists such as François-Noël Babeuf, Étienne-Gabriel Morelly, Philippe Buonarroti and Auguste Blanqui influenced the early French labour and socialist movements.[89] In Britain, Thomas Paine proposed a detailed plan to tax property owners to pay for the needs of the poor in Agrarian Justice[90] while Charles Hall wrote The Effects of Civilization on the People in European States, denouncing capitalism's effects on the poor of his time.[91] This work influenced the utopian schemes of Thomas Spence.[92]
",2
1725,"The first self-conscious socialist movements developed in the 1820s and 1830s. Fourierists, Owenites and Saint-Simonians and provided a series of analyses and interpretations of society. Especially the Owenites overlapped with other working-class movements such as the Chartists in the United Kingdom.[93] The Chartists gathered significant numbers around the People's Charter of 1838 which sought democratic reforms focused on the extension of suffrage to all male adults. Leaders in the movement called for a more equitable distribution of income and better living conditions for the working classes. The first trade unions and consumer cooperative societies followed the Chartist movement.[94] Pierre-Joseph Proudhon proposed his philosophy of mutualism in which ""everyone had an equal claim, either alone or as part of a small cooperative, to possess and use land and other resources as needed to make a living"".[95] Other currents inspired Christian socialism ""often in Britain and then usually coming out of left liberal politics and a romantic anti-industrialism""[89] which produced theorists such as Edward Bellamy, Charles Kingsley and Frederick Denison Maurice.[96]
",2
1726,"The first advocates of socialism favoured social levelling in order to create a meritocratic or technocratic society based on individual talent.[97] Henri de Saint-Simon was fascinated by the potential of science and technology and advocated a socialist society that would eliminate the disorderly aspects of capitalism based on equal opportunities.[98][unreliable source?] He sought a society in which each person was ranked according to his or her capacities and rewarded according to his or her work.[97] His key focus was on administrative efficiency and industrialism and a belief that science was essential to progress.[99] This was accompanied by a desire for a rationally organised economy based on planning and geared towards large-scale scientific and material progress.[97] Other early socialist thinkers such as Charles Hall and Thomas Hodgkin based their ideas on David Ricardo's economic theories. They reasoned that the equilibrium value of commodities approximated prices charged by the producer when those commodities were in elastic supply and that these producer prices corresponded to the embodied labour—the cost of the labour (essentially the wages paid) that was required to produce the commodities. The Ricardian socialists viewed profit, interest and rent as deductions from this exchange-value.[citation needed]
",2
1727,"West European social critics, including Louis Blanc, Charles Fourier, Charles Hall, Robert Owen, Pierre-Joseph Proudhon and Saint-Simon were the first modern socialists who criticised the poverty and inequality of the Industrial Revolution. They advocated reform, Owen advocating the transformation of society to small communities without private property. Owen's contribution to modern socialism was his claim that individual actions and characteristics were largely determined by their social environment.[99] On the other hand, Fourier advocated Phalanstères (communities that respected individual desires, including sexual preferences), affinities and creativity and saw that work has to be made enjoyable for people.[100] Owen and Fourier's ideas were practiced in intentional communities around Europe and North America in the mid-19th century.
",2
1728,"The Paris Commune was a government that ruled Paris from 18 March (formally, from 28 March) to 28 May 1871. The Commune was the result of an uprising in Paris after France was defeated in the Franco-Prussian War. The Commune elections were held on 26 March. They elected a Commune council of 92 members, one member for each 20,000 residents.[101] Despite internal differences, the council began to organise public services. It reached a consensus on certain policies that tended towards a progressive, secular and highly democratic social democracy.
",2
1729,"Because the Commune was able to meet on fewer than 60 days in total, only a few decrees were actually implemented. These included the separation of church and state; the remission of rents owed for the period of the siege (during which payment had been suspended); the abolition of night work in the hundreds of Paris bakeries; the granting of pensions to the unmarried companions and children of National Guards killed on active service; and the free return of all workmen's tools and household items valued up to 20 francs that had been pledged during the siege.[102] The Commune was concerned that skilled workers had been forced to pawn their tools during the war; the postponement of commercial debt obligations and the abolition of interest on the debts; and the right of employees to take over and run an enterprise if it were deserted by its owner. The Commune nonetheless recognised the previous owner's right to compensation.[102]
",2
1730,"In 1864, the First International was founded in London. It united diverse revolutionary currents, including socialists such as the French followers of Proudhon,[103] Blanquists, Philadelphes, English trade unionists and social democrats. In 1865 and 1866, it held a preliminary conference and had its first congress in Geneva, respectively. Due to their wide variety of philosophies, conflict immediately erupted. The first objections to Marx came from the mutualists who opposed state socialism. Shortly after Mikhail Bakunin and his followers joined in 1868, the First International became polarised into camps headed by Marx and Bakunin.[104] The clearest differences between the groups emerged over their proposed strategies for achieving their visions. The First International became the first major international forum for the promulgation of socialist ideas.
",2
1731,"Bakunin's followers were called collectivists and sought to collectivise ownership of the means of production while retaining payment proportional to the amount and kind of labour of each individual. Like Proudhonists, they asserted the right of each individual to the product of his labour and to be remunerated for his particular contribution to production. By contrast, anarcho-communists sought collective ownership of both the means and the products of labour. As Errico Malatesta put it, ""instead of running the risk of making a confusion in trying to distinguish what you and I each do, let us all work and put everything in common. In this way each will give to society all that his strength permits until enough is produced for every one; and each will take all that he needs, limiting his needs only in those things of which there is not yet plenty for every one"".[105] Anarcho-communism as a coherent economic-political philosophy was first formulated in the Italian section of the First International by Malatesta, Carlo Cafiero, Emilio Covelli, Andrea Costa and other ex-Mazzinian republicans.[106] Out of respect for Bakunin, they did not make their differences with collectivist anarchism explicit until after his death.[107]
",2
1732,"Syndicalism emerged in France inspired in part by Proudhon and later by Pelloutier and Georges Sorel.[108] It developed at the end of the 19th century out of the French trade-union movement (syndicat is the French word for trade union). It was a significant force in Italy and Spain in the early 20th century until it was crushed by the fascist regimes in those countries. In the United States, syndicalism appeared in the guise of the Industrial Workers of the World, or ""Wobblies"", founded in 1905.[108] Syndicalism is an economic system that organises industries into confederations (syndicates)[109] and the economy is managed by negotiation between specialists and worker representatives of each field, comprising multiple non-competitive categorised units.[110] Syndicalism is a form of communism and economic corporatism, but also refers to the political movement and tactics used to bring about this type of system. An influential anarchist movement based on syndicalist ideas is anarcho-syndicalism.[111] The International Workers Association is an international anarcho-syndicalist federation of various labour unions.
",2
1733,"The Fabian Society is a British socialist organisation established to advance socialism via gradualist and reformist means.[112] The society laid many foundations of the Labour Party and subsequently affected the policies of states emerging from the decolonisation of the British Empire, most notably India and Singapore. Originally, the Fabian Society was committed to the establishment of a socialist economy, alongside a commitment to British imperialism as a progressive and modernising force.[113] Later, the society functioned primarily as a think tank and is one of fifteen socialist societies affiliated with the Labour Party. Similar societies exist in Australia (the Australian Fabian Society), in Canada (the Douglas-Coldwell Foundation and the now disbanded League for Social Reconstruction) and in New Zealand.
",2
1734,"Guild socialism is a political movement advocating workers' control of industry through the medium of trade-related guilds ""in an implied contractual relationship with the public"".[114] It originated in the United Kingdom and was at its most influential in the first quarter of the 20th century. Inspired by medieval guilds, theorists such as Samuel George Hobson and G. D. H. Cole advocated the public ownership of industries and their workforces' organisation into guilds, each of which under the democratic control of its trade union. Guild socialists were less inclined than Fabians to invest power in a state.[108] At some point, like the American Knights of Labor, guild socialism wanted to abolish the wage system.[115]
",2
1735,"As the ideas of Marx and Engels gained acceptance, particularly in central Europe, socialists sought to unite in an international organisation. In 1889 (the centennial of the French Revolution), the Second International was founded, with 384 delegates from twenty countries representing about 300 labour and socialist organisations.[116] It was termed the Socialist International and Engels was elected honorary president at the third congress in 1893. Anarchists were banned, mainly due to pressure from Marxists.[117] It has been argued that at some point the Second International turned ""into a battleground over the issue of libertarian versus authoritarian socialism. Not only did they effectively present themselves as champions of minority rights; they also provoked the German Marxists into demonstrating a dictatorial intolerance which was a factor in preventing the British labour movement from following the Marxist direction indicated by such leaders as H. M. Hyndman"".[117]
",2
1736,"Reformism arose as an alternative to revolution. Eduard Bernstein was a leading social democrat in Germany who proposed the concept of evolutionary socialism. Revolutionary socialists quickly targeted reformism: Rosa Luxemburg condemned Bernstein's Evolutionary Socialism in her 1900 essay Social Reform or Revolution? Revolutionary socialism encompasses multiple social and political movements that may define ""revolution"" differently. The Social Democratic Party of Germany (SPD) became the largest and most powerful socialist party in Europe, despite working illegally until the anti-socialist laws were dropped in 1890. In the 1893 elections, it gained 1,787,000 votes, a quarter of the total votes cast, according to Engels. In 1895, the year of his death, Engels emphasised The Communist Manifesto's emphasis on winning, as a first step, the ""battle of democracy"".[118]
",2
1737,"In Argentina, the Socialist Party of Argentina was established in the 1890s led by Juan B. Justo and Nicolás Repetto, among others. It was the first mass party in the country and in Latin America. The party affiliated itself with the Second International.[119] Between 1924 and 1940, it was a member of the Labour and Socialist International.[120]
",2
1738,"In 1904, Australians elected Chris Watson as the first Australian Labor Party Prime Minister, becoming the first democratically elected socialist.[121] In 1909, the first Kibbutz was established in Palestine[122] by Russian Jewish Immigrants. The Kibbutz Movement expanded through the 20th century following a doctrine of Zionist socialism.[123] The British Labour Party first won seats in the House of Commons in 1902. The International Socialist Commission (ISC, also known as Berne International) was formed in February 1919 at a meeting in Bern by parties that wanted to resurrect the Second International.[124]
",2
1739,"By 1917, the patriotism of World War I changed into political radicalism in Australia, most of Europe and the United States. Other socialist parties from around the world who were beginning to gain importance in their national politics in the early 20th century included the Italian Socialist Party, the French Section of the Workers' International, the Spanish Socialist Workers' Party, the Swedish Social Democratic Party, the Russian Social Democratic Labour Party and the Socialist Party in Argentina, the Socialist Workers' Party in Chile and the Socialist Party of America in the United States.
",2
1740,"In February 1917, revolution exploded in Russia. Workers, soldiers and peasants established soviets (councils), the monarchy fell and a provisional government convened pending the election of a constituent assembly. In April of that year, Vladimir Lenin, leader of the Bolshevik faction of socialists in Russia and known for his profound and controversial expansions of Marxism, was allowed to cross Germany to return from exile in Switzerland.
",2
1741,"Lenin had published essays on his analysis of imperialism, the monopoly and globalisation phase of capitalism, as well as analyses on social conditions. He observed that as capitalism had further developed in Europe and America, the workers remained unable to gain class consciousness so long as they were too busy working to pay their expenses. He therefore proposed that the social revolution would require the leadership of a vanguard party of class-conscious revolutionaries from the educated and politically active part of the population.[125]
",2
1742,"Upon arriving in Petrograd, Lenin declared that the revolution in Russia had only begun, and that the next step was for the workers' soviets to take full authority. He issued a thesis outlining the Bolshevik programme, including rejection of any legitimacy in the provisional government and advocacy for state power to be administered through the soviets. The Bolsheviks became the most influential force. On 7 November, the capitol of the provisional government was stormed by Bolshevik Red Guards in what afterwards became known as the Great October Socialist Revolution. The provisional government ended and the Russian Socialist Federative Soviet Republic—the world's first constitutionally socialist state—was established. On 25 January 1918, Lenin declared ""Long live the world socialist revolution!"" at the Petrograd Soviet[126] and proposed an immediate armistice on all fronts and transferred the land of the landed proprietors, the crown and the monasteries to the peasant committees without compensation.[127]
",2
1743,"The day after assuming executive power on 25 January, Lenin wrote Draft Regulations on Workers' Control, which granted workers control of businesses with more than five workers and office employees and access to all books, documents and stocks and whose decisions were to be ""binding upon the owners of the enterprises"".[128] Governing through the elected soviets and in alliance with the peasant-based Left Socialist-Revolutionaries, the Bolshevik government began nationalising banks and industry; and disavowed the national debts of the deposed Romanov royal régime. It sued for peace, withdrawing from World War I and convoked a Constituent Assembly in which the peasant Socialist-Revolutionary Party (SR) won a majority.[129]
",2
1744,"The Constituent Assembly elected SR leader Victor Chernov President of a Russian republic, but rejected the Bolshevik proposal that it endorse the Soviet decrees on land, peace and workers' control and acknowledge the power of the Soviets of Workers', Soldiers' and Peasants' Deputies. The next day, the Bolsheviks declared that the assembly was elected on outdated party lists[130] and the All-Russian Central Executive Committee of the Soviets dissolved it.[131][132] In March 1919, world communist parties formed Comintern (also known as the Third International) at a meeting in Moscow.[133]
",2
1745,"Parties which did not want to be a part of the resurrected Second International (ISC) or Comintern formed the International Working Union of Socialist Parties (IWUSP, also known as Vienna International/Vienna Union/Two-and-a-Half International) on 27 February 1921 at a conference in Vienna.[134] The ISC and the IWUSP joined to form the Labour and Socialist International (LSI) in May 1923 at a meeting in Hamburg[135] Left-wing groups which did not agree to the centralisation and abandonment of the soviets by the Bolshevik Party led left-wing uprisings against the Bolsheviks—such groups included Socialist Revolutionaries,[136] Left Socialist Revolutionaries, Mensheviks and anarchists.[137]
",2
1746,"Within this left-wing discontent, the most large-scale events were the worker's Kronstadt rebellion[138][139][140] and the anarchist led Revolutionary Insurrectionary Army of Ukraine uprising which controlled an area known as the Free Territory.[141][142][143]
",2
1747,"The Bolshevik Russian Revolution of January 1918 launched communist parties in many countries and concomitant revolutions from 1917–1923. Few communists doubted that the Russian experience depended on successful, working-class socialist revolutions in developed capitalist countries.[144][145] In 1919, Lenin and Trotsky organised the world's communist parties into an international association of workers—the Communist International (Comintern), also called the Third International.
",2
1748,"The Russian Revolution influenced uprisings in other countries. The German Revolution of 1918–1919 replaced Germany's imperial government with a republic. The revolution lasted from November 1918 until the establishment of the Weimar Republic in August 1919. It included an episode known as the Bavarian Soviet Republic[146][147][148][149] and the Spartacist uprising. In Italy, the events known as the Biennio Rosso[150][151] were characterised by mass strikes, worker demonstrations and self-management experiments through land and factory occupations. In Turin and Milan, workers' councils were formed and many factory occupations took place led by anarcho-syndicalists organised around the Unione Sindacale Italiana.[152]
",2
1749,"By 1920, the Red Army under Trotsky had largely defeated the royalist White Armies. In 1921, War Communism was ended and under the New Economic Policy (NEP) private ownership was allowed for small and medium peasant enterprises. While industry remained largely state-controlled, Lenin acknowledged that the NEP was a necessary capitalist measure for a country unready for socialism. Profiteering returned in the form of ""NEP men"" and rich peasants (kulaks) gained power.[153] Trotsky's role was questioned by other socialists, including ex-Trotskyists. In the United States, Dwight Macdonald broke with Trotsky and left the Trotskyist Socialist Workers Party by noting the Kronstadt rebellion, which Trotsky and the other Bolsheviks had brutally repressed. He then moved towards democratic socialism[154] and anarchism.[155]
",2
1750,"A similar critique of Trotsky's role in the Kronstadt rebellion was raised by American anarchist Emma Goldman. In her essay ""Trotsky Protests Too Much"", she states, ""I admit, the dictatorship under Stalin's rule has become monstrous. That does not, however, lessen the guilt of Leon Trotsky as one of the actors in the revolutionary drama of which Kronstadt was one of the bloodiest scenes"".[156]
",2
1751,"In 1922, the fourth congress of the Communist International took up the policy of the united front. It urged communists to work with rank and file social democrats while remaining critical of their leaders. They criticised those leaders for betraying the working class by supporting the capitalists' war efforts. The social democrats pointed to the dislocation caused by revolution and later the growing authoritarianism of the communist parties. The Labour Party rejected the Communist Party of Great Britain's application to affiliate to them in 1920.
",2
1752,"On seeing the Soviet State's growing coercive power in 1923, a dying Lenin said Russia had reverted to ""a bourgeois tsarist machine [...] barely varnished with socialism"".[157] After Lenin's death in January 1924, the Communist Party of the Soviet Union—then increasingly under the control of Joseph Stalin—rejected the theory that socialism could not be built solely in the Soviet Union in favour of the concept of socialism in one country. Despite the marginalised Left Opposition's demand for the restoration of Soviet democracy, Stalin developed a bureaucratic, authoritarian government that was condemned by democratic socialists, anarchists and Trotskyists for undermining the Revolution's ideals.[158][159][self-published source?][unreliable source?]
",2
1753,"In 1924, the Mongolian People's Republic was established and was ruled by the Mongolian People's Party. The Russian Revolution and its aftermath motivated national communist parties elsewhere that gained political and social influence, in France, the United States, Italy, China, Mexico, the Brazil, Chile and Indonesia.
",2
1754,"In Spain in 1936, the national anarcho-syndicalist trade union Confederación Nacional del Trabajo (CNT) initially refused to join a popular front electoral alliance. Their abstention led to a right-wing election victory. In 1936, the CNT changed its policy and anarchist votes helped return the popular front to power. Months later, the former ruling class attempted a coup, sparking the Spanish Civil War (1936–1939).[160]
",2
1755,"In response to the army rebellion, an anarchist-inspired movement of peasants and workers, supported by armed militias, took control of Barcelona and of large areas of rural Spain where they collectivised the land.[161] The Spanish Revolution was a workers' social revolution that began with the Spanish Civil War in 1936 and resulted in the widespread implementation of anarchist and more broadly libertarian socialist organisational principles in some areas for two to three years, primarily Catalonia, Aragon, Andalusia and parts of Levante.
",2
1756,"Much of Spain's economy came under worker control. In anarchist strongholds like Catalonia the figure was as high as 75%, but lower in areas with heavy Communist Party influence, which actively resisted attempts at collectivisation. Factories were run through worker committees, agrarian areas became collectivised and run as libertarian communes. Anarchist historian Sam Dolgoff estimated that about eight million people participated directly or indirectly in the Spanish Revolution.[162]
",2
1757,"Trotsky's Fourth International was established in France in 1938 when Trotskyists argued that the Comintern or Third International had become irretrievably ""lost to Stalinism"" and thus incapable of leading the working class to power.[163] The rise of Nazism and the start of World War II led to the dissolution of the LSI in 1940. After the War, the Socialist International was formed in Frankfurt in July 1951 as its successor.[164]
",2
1758,"After World War II, social democratic governments introduced social reform and wealth redistribution via welfare and taxation. Social democratic parties dominated post-war politics in countries such as France, Italy, Czechoslovakia, Belgium and Norway. At one point, France claimed to be the world's most state-controlled capitalist country. It nationalised public utilities including Charbonnages de France (CDF), Électricité de France (EDF), Gaz de France (GDF), Air France, Banque de France and Régie Nationale des Usines Renault.[165]
",2
1759,"In 1945, the British Labour Party led by Clement Attlee was elected based on a radical socialist programme. The Labour government nationalised industries including mines, gas, coal, electricity, rail, iron, steel and the Bank of England. British Petroleum was officially nationalised in 1951.[166] Anthony Crosland said that in 1956 25% of British industry was nationalised and that public employees, including those in nationalised industries, constituted a similar proportion of the country's workers.[167] The Labour Governments of 1964–1970 and 1974–1979 intervened further.[168] It re-nationalised British Steel (1967) after the Conservatives had denationalised it and nationalised British Leyland (1976).[169] The National Health Service provided taxpayer-funded health care to everyone, free at the point of service.[170] Working-class housing was provided in council housing estates and university education became available via a school grant system.[171]
",2
1760,"During most of the post-war era, Sweden was governed by the Swedish Social Democratic Party largely in cooperation with trade unions and industry.[172] In Sweden, the Swedish Social Democratic Party held power from 1936 to 1976, 1982 to 1991, 1994 to 2006 and 2014 through 2023, most recently in a minority coalition. Tage Erlander was the first leader of the Swedish Social Democratic Party (SSDP). He led the government from 1946 to 1969, the longest uninterrupted parliamentary government. These governments substantially expanded the welfare state.[173] Swedish Prime Minister Olof Palme identified as a ""democratic socialist""[174] and was described as a ""revolutionary reformist"".[175]
",2
1761,"The Norwegian Labour Party was established in 1887 and was largely a trade union federation. The party did not proclaim a socialist agenda, elevating universal suffrage and dissolution of the union with Sweden as its top priorities. In 1899, the Norwegian Confederation of Trade Unions separated from the Labour Party. Around the time of the Russian Revolution, the Labour Party moved to the left and joined the Communist International from 1919 through 1923. Thereafter, the party still regarded itself as revolutionary, but the party's left-wing broke away and established the Communist Party of Norway while the Labour Party gradually adopted a reformist line around 1930. In 1935, Johan Nygaardsvold established a coalition that lasted until 1945.[176]
",2
1762,"From 1946 to 1962, the Norwegian Labour Party held an absolute majority in the parliament led by Einar Gerhardsen, who remained Prime Minister for seventeen years. Although the party abandoned most of its pre-war socialist ideas, the welfare state was expanded under Gerhardsen to ensure the universal provision of basic human rights and stabilise the economy.[177] In the 1945 Norwegian parliamentary election, the Communist Party took 12% of the votes, but it largely vanished during the Cold War.[178] In the 1950s, popular socialism emerged in Nordic countries. It placed itself between communism and social democracy.[179] In the early 1960s, the Socialist Left Party challenged the Labour Party from the left.[176] Also in the 1960s, Gerhardsen established a planning agency and tried to establish a planned economy.[177] In the 1970s, a more radical socialist party, the Worker's Communist Party (AKP), broke from the Socialist Left Party and had notable influence in student associations and some trade unions. The AKP identified with Communist China and Albania rather than the Soviet Union.[180]
",2
1763,"In countries such as Sweden, the Rehn–Meidner model[181] allowed capitalists owning productive and efficient firms to retain profits at the expense of the firms' workers, exacerbating inequality and causing workers to agitate for a share of the profits in the 1970s. At that time, women working in the state sector began to demand better wages. Rudolf Meidner established a study committee that came up with a 1976 proposal to transfer excess profits into worker-controlled investment funds, with the intention that firms would create jobs and pay higher wages rather than reward company owners and managers.[182] Capitalists immediately labeled this proposal as socialism and launched an unprecedented opposition—including calling off the class compromise established in the 1938 Saltsjöbaden Agreement.[183] Social democratic parties are some of the oldest such parties and operate in all Nordic countries. Countries or political systems that have long been dominated by social democratic parties are often labelled social democratic.[184][185] Those countries fit the social democratic type of ""high socialism"" which is described as favouring ""a high level of decommodification and a low degree of stratification"".[186]
",2
1764,"The Nordic model is a form of economic-political system common to the Nordic countries (Denmark, Finland, Iceland, Norway and Sweden). It has three main ingredients, namely peaceful, institutionalised negotiation between employers and trade unions; active, predictable and measured macroeconomic policy; and universal welfare and free education. The welfare system is governmental in Norway and Sweden whereas trade unions play a greater role in Denmark, Finland and Iceland.[187][188][189][190][191] The Nordic model is often labelled social democratic and contrasted with the conservative continental model and the liberal Anglo-American model. Major reforms in the Nordic countries are the results of consensus and compromise across the political spectrum. Key reforms were implemented under social democratic cabinets in Denmark, Norway and Sweden while centre-right parties dominated during the implementation of the model in Finland and Iceland. Since World War II, Nordic countries have largely maintained a social democratic mixed economy, characterised by labour force participation, gender equality, egalitarian and universal benefits, redistribution of wealth and expansionary fiscal policy.[177][187][192]
",2
1765,"In Norway, the first mandatory social insurances were introduced by conservative cabinets in 1895 (Francis Hagerups's cabinet) and 1911 (Konow's Cabinet). During the 1930s, the Labour Party adopted the conservatives' welfare state project. After World War II, all political parties agreed that the welfare state should be expanded. Universal social security (Folketrygden) was introduced by the conservative Borten's Cabinet.[193][194] Norway's economy is open to the international or European market for most products and services, joining the European Union's internal market in 1994 through European Economic Area. Some of the mixed economy institutions from the post-war period were relaxed by the conservative cabinet of the 1980s and the finance market was deregulated.[195] Within the Varieties of Capitalism-framework, Finland, Norway and Sweden are identified as coordinated market economies.[196]
",2
1766,"The Soviet era saw some of the most significant technological achievements of the 20th century, including the world's first spacecraft and the first astronaut. The Soviet economy was the modern world's first centrally planned economy. It adopted state ownership of industry managed through Gosplan (the State Planning Commission), Gosbank (the State Bank) and the Gossnab (State Commission for Materials and Equipment Supply).
",2
1767,"Economic planning was conducted through serial Five-Year Plans. The emphasis was on development of heavy industry. The nation became one of the world's top manufacturers of basic and heavy industrial products, while deemphasizing light industrial production and consumer durables.[citation needed] Modernisation brought about a general increase in the standard of living.[197]
",2
1768,"The Eastern Bloc was the group of Communist states of Central and Eastern Europe, including the Soviet Union and the countries of the Warsaw Pact,[198][199][200] including Poland, the German Democratic Republic, the Hungary, Bulgaria, Czechoslovakia, Romania, Albania and Yugoslavia. The Hungarian Revolution of 1956 was a spontaneous nationwide revolt against the Communist government, lasting from 23 October until 10 November 1956. Soviet leader Nikita Khrushchev's denunciation of the excesses of Stalin's regime during the Twentieth Communist Party Congress in 1956[201] as well as the Hungarian revolt,[202][203][204][205] produced disunity within Western European communist and socialist parties.
",2
1769,"In the post-war years, socialism became increasingly influential in many then-developing countries. Embracing Third World socialism, countries in Africa, Asia and Latin America often nationalised industries.
",2
1770,"The Chinese Communist Revolution was the second stage in the Chinese Civil War, which ended with the establishment of the People's Republic of China led by the Chinese Communist Party. The then-Chinese Kuomintang Party in the 1920s incorporated Chinese socialism as part of its ideology.[206][207]
",2
1771,"The emergence of this new political entity in the frame of the Cold War was complex and painful. Several tentative efforts were made to organise newly independent states in order to establish a common front to limit the United States' and the Soviet Union's influence on them. This led to the Sino-Soviet split. The Non-Aligned Movement gathered around the figures of Jawaharlal Nehru of India, Sukarno of Indonesia, Josip Broz Tito of Yugoslavia and Gamal Abdel Nasser of Egypt. After the 1954 Geneva Conference which ended the French war in Vietnam, the 1955 Bandung Conference gathered Nasser, Nehru, Tito, Sukarno and Chinese Premier Zhou Enlai.[citation needed] As many African countries gained independence during the 1960s, some of them rejected capitalism in favour of African socialism as defined by Julius Nyerere of Tanzania, Léopold Senghor of Senegal, Kwame Nkrumah of Ghana and Sékou Touré of Guinea.[208]
",2
1772,"The Cuban Revolution (1953–1959) was an armed revolt conducted by Fidel Castro's 26th of July Movement and its allies against the government of Fulgencio Batista. Castro's government eventually adopted communism, becoming the Communist Party of Cuba in October 1965.[209]
",2
1773,"In Indonesia, a right-wing military regime led by Suharto killed between 500,000 and one million people in 1965 and 1966, mainly to crush the growing influence of the Communist Party and other leftist groups, with support from the United States which provided kill lists containing thousands of names of suspected high-ranking Communists.[210][211][212][213][214]
",2
1774,"The New Left was a term used mainly in the United Kingdom and United States in reference to activists, educators, agitators and others in the 1960s and 1970s who sought to implement a broad range of reforms on issues such as gay rights, abortion, gender roles and drugs[215] in contrast to earlier leftist or Marxist movements that had taken a more vanguardist approach to social justice and focused mostly on labour unionisation and questions of social class.[216][217][218] The New Left rejected involvement with the labour movement and Marxism's historical theory of class struggle.[219]
",2
1775,"In the United States, the New Left was associated with the Hippie movement and anti-war college campus protest movements as well as the black liberation movements such as the Black Panther Party.[220] While initially formed in opposition to the ""Old Left"" Democratic Party, groups composing the New Left gradually became central players in the Democratic coalition.[215]
",2
1776,"The protests of 1968 represented a worldwide escalation of social conflicts, predominantly characterised by popular rebellions against military, capitalist and bureaucratic elites who responded with an escalation of political repression. These protests marked a turning point for the civil rights movement in the United States which produced revolutionary movements like the Black Panther Party. The prominent civil rights leader Martin Luther King Jr. organised the ""Poor People's Campaign"" to address issues of economic justice,[221] while personally showing sympathy with democratic socialism.[222] In reaction to the Tet Offensive, protests also sparked a broad movement in opposition to the Vietnam War all over the United States and even into London, Paris, Berlin and Rome. In 1968, the International of Anarchist Federations was founded during an international anarchist conference held in Carrara by the three existing European federations of France, the Italian and the Iberian Anarchist Federation as well as the Bulgarian federation in French exile.
",2
1777,"Mass socialist or communist movements grew not only in the United States, but also in most European countries. The most spectacular manifestation of this were the May 1968 protests in France in which students linked up with strikes of up to ten million workers and for a few days the movement seemed capable of overthrowing the government.[citation needed]
",2
1778,"In many other capitalist countries, struggles against dictatorships, state repression and colonisation were also marked by protests in 1968, such as the beginning of the Troubles in Northern Ireland, the Tlatelolco massacre in Mexico City and the escalation of guerrilla warfare against the military dictatorship in Brazil. Countries governed by communist parties had protests against bureaucratic and military elites. In Eastern Europe there were widespread protests that escalated particularly in the Prague Spring in Czechoslovakia. In response, Soviet Union occupied Czechoslovakia, but the occupation was denounced by the Italian and French[223] communist parties and the Communist Party of Finland. Few western European political leaders defended the occupation, among them the Portuguese communist secretary-general Álvaro Cunhal.[224] along with the Luxembourg party[223] and conservative factions of the Communist Party of Greece.[223]
",2
1779,"In the Chinese Cultural Revolution, a social-political youth movement mobilised against ""bourgeois"" elements which were seen to be infiltrating the government and society at large, aiming to restore capitalism. This movement motivated Maoism-inspired movements around the world in the context of the Sino-Soviet split.[citation needed]
",2
1780,"In the 1960s, a socialist tendency within the Latin American Catholic church appeared and was known as liberation theology[226][227] It motivated the Colombian priest Camilo Torres Restrepo to enter the ELN guerrilla. In Chile, Salvador Allende, a physician and candidate for the Socialist Party of Chile, was elected president in 1970. In 1973, his government was ousted by the United States-backed military dictatorship of Augusto Pinochet, which lasted until the late 1980s.[228] Pinochet's regime was a leader of Operation Condor, a U.S.-backed campaign of repression and state terrorism carried out by the intelligence services of the Southern Cone countries of Latin America to eliminate suspected Communist subversion.[229][230][231] In Jamaica, the democratic socialist[232] Michael Manley served as the fourth Prime Minister of Jamaica from 1972 to 1980 and from 1989 to 1992. According to opinion polls, he remains one of Jamaica's most popular Prime Ministers since independence.[233] The Nicaraguan Revolution encompassed the rising opposition to the Somoza dictatorship in the 1960s and 1970s, the campaign led by the Sandinista National Liberation Front (FSLN) to violently oust the dictatorship in 1978–1979, the subsequent efforts of the FSLN to govern Nicaragua from 1979 until 1990[234] and the socialist measures which included wide-scale agrarian reform[235][236] and educational programs.[237] The People's Revolutionary Government was proclaimed on 13 March 1979 in Grenada which was overthrown by armed forces of the United States in 1983. The Salvadoran Civil War (1979–1992) was a conflict between the military-led government of El Salvador and the Farabundo Martí National Liberation Front (FMLN), a coalition or umbrella organisation of five socialist guerrilla groups. A coup on 15 October 1979 led to the killings of anti-coup protesters by the government as well as anti-disorder protesters by the guerrillas, and is widely seen as the tipping point towards the civil war.[238]
",2
1781,"In Italy, Autonomia Operaia was a leftist movement particularly active from 1976 to 1978. It took an important role in the autonomist movement in the 1970s, aside earlier organisations such as Potere Operaio (created after May 1968) and Lotta Continua.[239] This experience prompted the contemporary socialist radical movement autonomism.[240] In 1982, the newly elected French socialist government of François Mitterrand made nationalisations in a few key industries, including banks and insurance companies.[241] Eurocommunism was a trend in the 1970s and 1980s in various Western European communist parties to develop a theory and practice of social transformation that was more relevant for a Western European country and less aligned to the influence or control of the Communist Party of the Soviet Union. Outside Western Europe, it is sometimes called neocommunism.[242] Some communist parties with strong popular support, notably the Italian Communist Party (PCI) and the Communist Party of Spain (PCE) adopted Eurocommunism most enthusiastically and the Communist Party of Finland was dominated by Eurocommunists. The French Communist Party (PCF) and many smaller parties strongly opposed Eurocommunism and stayed aligned with the Communist Party of the Soviet Union until the end of the Soviet Union.
",2
1782,"In the late 1970s and in the 1980s, the Socialist International (SI) had extensive contacts and discussion with the two powers of the Cold War, the United States and the Soviet Union, about east–west relations and arms control. Since then, the SI has admitted as member parties the Nicaraguan FSLN, the left-wing Puerto Rican Independence Party, as well as former communist parties such as the Democratic Party of the Left of Italy and the Front for the Liberation of Mozambique (FRELIMO). The SI aided social democratic parties in re-establishing themselves when dictatorship gave way to democracy in Portugal (1974) and Spain (1975). Until its 1976 Geneva Congress, the SI had few members outside Europe and no formal involvement with Latin America.[243]
",2
1783,"After Mao Zedong's death in 1976 and the arrest of the faction known as the Gang of Four, who were blamed for the excesses of the Cultural Revolution, Deng Xiaoping took power and led the People's Republic of China to significant economic reforms. The Chinese Communist Party (CCP) loosened governmental control over citizens' personal lives and the communes were disbanded in favour of private land leases, thus China's transition from a planned economy to a mixed economy named as ""socialism with Chinese characteristics""[244] which maintained state ownership rights over land, state or cooperative ownership of much of the heavy industrial and manufacturing sectors and state influence in the banking and financial sectors. China adopted its current constitution on 4 December 1982. Chinese Communist Party General Secretary Jiang Zemin, Premiers Li Peng and Zhu Rongji led the nation in the 1990s. Under their administration, China's economic performance pulled an estimated 150 million peasants out of poverty and sustained an average annual gross domestic product growth rate of 11.2%.[245][246] At the Sixth National Congress of the Communist Party of Vietnam in December 1986, reformist politicians replaced the ""old guard"" government with new leadership.[247][248] The reformers were led by 71-year-old Nguyen Van Linh, who became the party's new general secretary.[247][248] Linh and the reformers implemented a series of free market reforms—known as Đổi Mới (""Renovation"")—which carefully managed the transition from a planned economy to a ""socialist-oriented market economy"".[249][250] Mikhail Gorbachev wished to move the Soviet Union towards of Nordic-style social democracy, calling it ""a socialist beacon for all mankind"".[251][252] Prior to its dissolution in 1991, the economy of the Soviet Union was the second largest in the world after the United States.[253] With the collapse of the Soviet Union, the economic integration of the Soviet republics was dissolved and overall industrial activity declined substantially.[254] A lasting legacy remains in the physical infrastructure created during decades of combined industrial production practices, and widespread environmental destruction.[255] The transition to capitalism in the former Soviet Union and Eastern Bloc, which was accompanied by Washington Consensus-inspired ""shock therapy"",[256] resulted in a steep fall in the standard of living. The region experienced rising economic inequality and poverty[257] a surge in excess mortality[258][259] and a decline in life expectancy,[260] which was accompanied by the entrenchment of a newly established business oligarchy in the former.[257] The average post-communist country had returned to 1989 levels of per-capita GDP by 2005,[261] although some are still far behind that.[262] These developments led to increased nationalist sentiment and nostalgia for the Communist era.[263][264][265]
",2
1784,"Many social democratic parties, particularly after the Cold War, adopted neoliberal market policies including privatisation, deregulation and financialisation. They abandoned their pursuit of moderate socialism in favour of economic liberalism. By the 1980s, with the rise of conservative neoliberal politicians such as Ronald Reagan in the United States, Margaret Thatcher in Britain, Brian Mulroney in Canada and Augusto Pinochet in Chile, the Western welfare state was attacked from within, but state support for the corporate sector was maintained.[266] Monetarists and neoliberals attacked social welfare systems as impediments to private entrepreneurship. In the United Kingdom, Labour Party leader Neil Kinnock made a public attack against the entryist group Militant at the 1985 Labour Party conference. Labour ruled that Militant was ineligible for affiliation with the party and it gradually expelled Militant supporters. The Kinnock leadership had refused to support the 1984–1985 miner's strike over pit closures, a decision that the party's left wing and the National Union of Mineworkers blamed for the strike's eventual defeat. In 1989, the 18th Congress of the Socialist International adopted a new Declaration of Principles, stating:
",2
1785,"Democratic socialism is an international movement for freedom, social justice, and solidarity. Its goal is to achieve a peaceful world where these basic values can be enhanced and where each individual can live a meaningful life with the full development of his or her personality and talents, and with the guarantee of human and civil rights in a democratic framework of society.[267]",2
1786,"In the 1990s, the British Labour Party under Tony Blair enacted policies based on the free market economy to deliver public services via the private finance initiative. Influential in these policies was the idea of a Third Way which called for a re-evaluation of welfare state policies.[268] In 1995, the Labour Party re-defined its stance on socialism by re-wording Clause IV of its constitution, defining socialism in ethical terms and removing all references to public, direct worker or municipal ownership of the means of production. The Labour Party stated: ""The Labour Party is a democratic socialist party. It believes that, by the strength of our common endeavour we achieve more than we achieve alone, so as to create, for each of us, the means to realise our true potential, and, for all of us, a community in which power, wealth, and opportunity are in the hands of the many, not the few"".[269]
",2
1787,"African socialism has been and continues to be a major ideology around the continent. Julius Nyerere was inspired by Fabian socialist ideals.[270] He was a firm believer in rural Africans and their traditions and ujamaa, a system of collectivisation that according to Nyerere was present before European imperialism. Essentially he believed Africans were already socialists. Other African socialists include Jomo Kenyatta, Kenneth Kaunda, Nelson Mandela and Kwame Nkrumah. Fela Kuti was inspired by socialism and called for a democratic African republic. In South Africa the African National Congress (ANC) abandoned its partial socialist allegiances after taking power and followed a standard neoliberal route. From 2005 through to 2007, the country was wracked by many thousands of protests from poor communities. One of these gave rise to a mass movement of shack dwellers, Abahlali baseMjondolo that despite major police suppression continues to work for popular people's planning and against the creation of a market economy in land and housing.
",2
1788,"In Asia, states with socialist economies—such as the People's Republic of China, North Korea, Laos and Vietnam—have largely moved away from centralised economic planning in the 21st century, placing a greater emphasis on markets. Forms include the Chinese socialist market economy and the Vietnamese socialist-oriented market economy. They use state-owned corporate management models as opposed to modelling socialist enterprise on traditional management styles employed by government agencies. In China living standards continued to improve rapidly despite the late-2000s recession, but centralised political control remained tight.[271] Brian Reynolds Myers in his book The Cleanest Race, later supported by other academics,[272][273] dismisses the idea that Juche is North Korea's leading ideology, regarding its public exaltation as designed to deceive foreigners and that it exists to be praised and not actually read,[274] pointing out that North Korea's constitution of 2009 omits all mention of communism.[273]
",2
1789,"Although the authority of the state remained unchallenged under Đổi Mới, the government of Vietnam encourages private ownership of farms and factories, economic deregulation and foreign investment, while maintaining control over strategic industries.[250] The Vietnamese economy subsequently achieved strong growth in agricultural and industrial production, construction, exports and foreign investment. However, these reforms have also caused a rise in income inequality and gender disparities.[275][276]
",2
1790,"Elsewhere in Asia, some elected socialist parties and communist parties remain prominent, particularly in India and Nepal. Communist Party of Nepal (Unified Marxist–Leninist) in particular calls for multi-party democracy, social equality and economic prosperity.[277] In Singapore, a majority of the GDP is still generated from the state sector comprising government-linked companies.[278] In Japan, there has been a resurgent interest in the Japanese Communist Party among workers and youth.[279][280] In Malaysia, the Socialist Party of Malaysia got its first Member of Parliament, Michael Jeyakumar Devaraj, after the 2008 general election. In 2010, there were 270 kibbutzim in Israel. Their factories and farms account for 9% of Israel's industrial output, worth US$8 billion and 40% of its agricultural output, worth over $1.7 billion.[281] Some Kibbutzim had also developed substantial high-tech and military industries. Also in 2010, Kibbutz Sasa, containing some 200 members, generated $850 million in annual revenue from its military-plastics industry.[282]
",2
1791,"The United Nations World Happiness Report 2013 shows that the happiest nations are concentrated in Northern Europe, where the Nordic model is employed, with Denmark topping the list. This is at times attributed to the success of the Nordic model in the region that has been labelled social democratic in contrast with the conservative continental model and the liberal Anglo-American model. The Nordic countries ranked highest on the metrics of real GDP per capita, healthy life expectancy, having someone to count on, perceived freedom to make life choices, generosity and freedom from corruption.[283]
",2
1792,"The objectives of the Party of European Socialists, the European Parliament's socialist and social democratic bloc, are now ""to pursue international aims in respect of the principles on which the European Union is based, namely principles of freedom, equality, solidarity, democracy, respect of Human Rights and Fundamental Freedoms, and respect for the Rule of Law"". As a result, today the rallying cry of the French Revolution—Liberté, égalité, fraternité—is promoted as essential socialist values.[284] To the left of the PES at the European level is the Party of the European Left (PEL), also commonly abbreviated ""European Left""), which is a political party at the European level and an association of democratic socialist, socialist[285] and communist[285] political parties in the European Union and other European countries. It was formed in January 2004 for the purposes of running in the 2004 European Parliament elections. PEL was founded on 8–9 May 2004 in Rome.[286] Elected MEPs from member parties of the European Left sit in the European United Left–Nordic Green Left (GUE/NGL) group in the European parliament.
",2
1793,"The socialist Left Party in Germany grew in popularity[287] due to dissatisfaction with the increasingly neoliberal policies of the SPD, becoming the fourth biggest party in parliament in the general election on 27 September 2009.[288] Communist candidate Dimitris Christofias won a crucial presidential runoff in Cyprus, defeating his conservative rival with a majority of 53%.[289] In Ireland, in the 2009 European election Joe Higgins of the Socialist Party took one of three seats in the capital Dublin European constituency.
",2
1794,"In Denmark, the Socialist People's Party (SF) more than doubled its parliamentary representation to 23 seats from 11, making it the fourth largest party.[290] In 2011, the Social Democrats, Socialist People's Party and the Danish Social Liberal Party formed government, after a slight victory over the main rival political coalition. They were led by Helle Thorning-Schmidt, and had the Red-Green Alliance as a supporting party.
",2
1795,"In Norway, the Red-Green Coalition consists of the Labour Party (Ap), the Socialist Left Party (SV) and the Centre Party (Sp) and governed the country as a majority government from the 2005 general election until 2013.
",2
1796,"In the Greek legislative election of January 2015, the Coalition of the Radical Left (SYRIZA) led by Alexis Tsipras won a legislative election for the first time while the Communist Party of Greece won 15 seats in parliament. SYRIZA has been characterised as an anti-establishment party,[291] whose success has sent ""shock-waves across the EU"".[292]
",2
1797,"In the United Kingdom, the National Union of Rail, Maritime and Transport Workers put forward a slate of candidates in the 2009 European Parliament elections under the banner of No to EU – Yes to Democracy, a broad left-wing alter-globalisation coalition involving socialist groups such as the Socialist Party, aiming to offer an alternative to the ""anti-foreigner"" and pro-business policies of the UK Independence Party.[293][294][295] In the following May 2010 United Kingdom general election, the Trade Unionist and Socialist Coalition, launched in January 2010[296] and backed by Bob Crow, the leader of the National Union of Rail, Maritime and Transport Workers union (RMT), other union leaders and the Socialist Party among other socialist groups, stood against Labour in 40 constituencies.[297][298] The Trade Unionist and Socialist Coalition contested the 2011 local elections, having gained the endorsement of the RMT June 2010 conference, but gained no seats.[299] Left Unity was also founded in 2013 after the film director Ken Loach appealed for a new party of the left to replace the Labour Party, which he claimed had failed to oppose austerity and had shifted towards neoliberalism.[300][301][302][303] In 2015, following a defeat at the 2015 United Kingdom general election, self-described socialist Jeremy Corbyn took over from Ed Miliband as leader of the Labour Party.[304]
",2
1798,"In France, Olivier Besancenot, the Revolutionary Communist League (LCR) candidate in the 2007 presidential election, received 1,498,581 votes, 4.08%, double that of the communist candidate.[305] The LCR abolished itself in 2009 to initiate a broad anti-capitalist party, the New Anticapitalist Party, whose stated aim is to ""build a new socialist, democratic perspective for the twenty-first century"".[306]
",2
1799,"On 25 May 2014, the Spanish left-wing party Podemos entered candidates for the 2014 European parliamentary elections, some of which were unemployed. In a surprise result, it polled 7.98% of the vote and thus was awarded five seats out of 54[307][308] while the older United Left was the third largest overall force obtaining 10.03% and 5 seats, 4 more than the previous elections.[309]
",2
1800,"The government of Portugal established on 26 November 2015 was a Socialist Party (PS) minority government led by prime minister António Costa, who succeeded in securing support for a Socialist minority government by the Left Bloc (B.E.), the Portuguese Communist Party (PCP) and the Ecologist Party ""The Greens"" (PEV).[310]
",2
1801,"All around Europe and in some places of Latin America there exists a social centre and squatting movement mainly inspired by autonomist and anarchist ideas.[311][312]
",2
1802,"According to a 2013 article in The Guardian, ""[c]ontrary to popular belief, Americans don't have an innate allergy to socialism. Milwaukee has had several socialist mayors (Frank Zeidler, Emil Seidel and Daniel Hoan), and there is currently an independent socialist in the US Senate, Bernie Sanders of Vermont"".[313] Sanders, once mayor of Vermont's largest city, Burlington, has described himself as a democratic socialist[314][315] and has praised Scandinavian-style social democracy.[316][317] In 2016, Sanders made a bid for the Democratic Party presidential candidate, thereby gaining considerable popular support, particularly among the younger generation, but lost the nomination to Hillary Clinton. As of 2019, the Democratic Socialists of America have two members in Congress, and various members in state legislatures and city councils.[318] According to a 2018 Gallup poll, 37% of American adults have a positive view of socialism, including 57% of Democrat-leaning voters and 16% of Republican-leaning voters.[319] A 2019 YouGov poll found that 7 out of 10 millennials would vote for a socialist presidential candidate, and 36% had a favorable view of communism.[320] An earlier 2019 Harris Poll found that socialism is more popular with women than men, with 55% of women between the ages of 18 and 54 preferring to live in a socialist society while a majority of men surveyed in the poll chose capitalism over socialism.[321]
",2
1803,"Anti-capitalism, anarchism and the anti-globalisation movement rose to prominence through events such as protests against the World Trade Organization Ministerial Conference of 1999 in Seattle. Socialist-inspired groups played an important role in these movements, which nevertheless embraced much broader layers of the population and were championed by figures such as Noam Chomsky. In Canada, the Co-operative Commonwealth Federation (CCF), the precursor to the social democratic New Democratic Party (NDP), had significant success in provincial politics. In 1944, the Saskatchewan CCF formed the first socialist government in North America. At the federal level, the NDP was the Official Opposition, from 2011 through 2015.[322]
",2
1804,"In their Johnson linguistics column, The Economist opines that in the 21st century United States, the term socialism, without clear definition, has become a pejorative used by conservatives to attack liberal and progressive policies, proposals, and public figures.[323]
",2
1805,"For the Encyclopedia Britannica, ""the attempt by Salvador Allende to unite Marxists and other reformers in a socialist reconstruction of Chile is most representative of the direction that Latin American socialists have taken since the late 20th century. [...] Several socialist (or socialist-leaning) leaders have followed Allende's example in winning election to office in Latin American countries"".[95] The success of the Workers' Party (Portuguese: Partido dos Trabalhadores – PT) of Brazil, formed in 1980 and governing Brazil from 2003 to 2016, was the first major breakthrough for this trend.
",2
1806,"Foro de São Paulo is a conference of leftist political parties and other organisations from Latin America and the Caribbean. It was launched by the Workers' Party in 1990 in the city of São Paulo, after the PT approached other parties and social movements of Latin America and the Caribbean with the objective of debating the new international scenario after the fall of the Berlin Wall and the consequences of the implementation of what were taken as neoliberal policies adopted at the time by contemporary right-leaning governments in the region, the stated main objective of the conference being to argue for alternatives to neoliberalism.[324] Among its members have been socialist and social-democratic parties in government in the region such as Bolivia's Movement for Socialism, the Communist Party of Cuba, Ecuador's PAIS Alliance, the United Socialist Party of Venezuela, the Socialist Party of Chile, Uruguay's Broad Front, Nicaragua's Sandinista National Liberation Front, El Salvador's Farabundo Martí National Liberation Front and members of Argentina's Frente de Todos.
",2
1807,"In the first decade of the 21st century, Venezuelan President Hugo Chávez, Nicaraguan President Daniel Ortega, Bolivian President Evo Morales and Ecuadorian president Rafael Correa referred to their political programmes as socialist, and Chávez adopted the term ""socialism of the 21st century"". After winning re-election in December 2006, Chávez said: ""Now more than ever, I am obliged to move Venezuela's path towards socialism"".[325] Chávez was also reelected in October 2012 for his third six-year term as president, but he died in March 2013 from cancer. After Chávez's death on 5 March 2013, Vice President from Chavez's party Nicolás Maduro assumed the powers and responsibilities of the President. A special election was held on 14 April of the same year to elect a new president, which Maduro won by a tight margin as the candidate of the United Socialist Party of Venezuela and he was formally inaugurated on 19 April.[326] Pink tide is a term used in political analysis, in the media and elsewhere to describe the perception that leftist ideology in general and left-wing politics in particular were increasingly influential in Latin America in the 2000s.[327][328][329] Some of the pink tide governments were criticised for turning from socialism to populism and authoritarianism.[330][331] The pink tide was followed in the 2010s by a ""conservative wave"" as right-wing governments came to power in Argentina, Brazil and Chile, and Venezuela and Nicaragua experienced political crises. However, socialism saw a resurgence in 2018–19 after successive electoral victories of left-wing and centre-left candidates in Mexico, Panama, and Argentina.[332][333][334]
",2
1808,"Australia saw an increase in interest of socialism in the early 21st century, especially amongst youth.[335] It is strongest in Victoria, where three socialist parties have merged into the Victorian Socialists, who aim to address problems in housing and public transportation.
",2
1809,"In New Zealand, socialism emerged within the budding trade union movement during the late 19th century and early 20th century. In July 1916, several left-wing political organisations and trade unions merged to form the New Zealand Labour Party.[336][337] While Labour traditionally had a socialist orientation, the party shifted towards a more social democratic orientation during the 1920s and 1930s. Following the 1935 general election, the First Labour Government pursued socialist policies such as nationalising industry, broadcasting, transportation, and implementing a Keynesian welfare state. However, the party did not seek to abolish capitalism, instead opting for a mixed economy. Labour's welfare state and mixed economy were not challenged until the 1980s.[338][339] During the 1980s, the Fourth Labour Government implemented a raft of neoliberal economic reforms known as Rogernomics which saw New Zealand society and the economy shift towards a more free market model. Labour's abandonment of its traditional values fractured the party. Successive Labour governments have since pursued centre-left social and economic policies while maintaining a free-market economy.[340] The current Prime Minister of New Zealand Jacinda Ardern formerly served as President of the International Union of Socialist Youth.[341] Ardern is a self-described social democrat[342] who has criticized capitalism as a ""blatant failure"" due to high levels of homelessness and low wages.[343] New Zealand still has a small socialist scene, mainly dominated by Trotskyist groups.[citation needed]
",2
1810,"Melanesian socialism developed in the 1980s, inspired by African socialism. It aims to achieve full independence from Britain and France in Melanesian territories and creation of a Melanesian federal union. It is very popular with the New Caledonia independence movement.[citation needed]
",2
1811,"The Progressive Alliance is a political international founded on 22 May 2013 by political parties, the majority of whom are current or former members of the Socialist International. The organisation states the aim of becoming the global network of ""the progressive, democratic, social-democratic, socialist and labour movement"".[344][345]
",2
1812,"Early socialist thought took influences from a diverse range of philosophies such as civic republicanism, Enlightenment rationalism, romanticism, forms of materialism, Christianity (both Catholic and Protestant), natural law and natural rights theory, utilitarianism and liberal political economy.[346] Another philosophical basis for a lot of early socialism was the emergence of positivism during the European Enlightenment. Positivism held that both the natural and social worlds could be understood through scientific knowledge and be analysed using scientific methods. This core outlook influenced early social scientists and different types of socialists ranging from anarchists like Peter Kropotkin to technocrats like Saint Simon.[347]
",2
1813,"The fundamental objective of socialism is to attain an advanced level of material production and therefore greater productivity, efficiency and rationality as compared to capitalism and all previous systems, under the view that an expansion of human productive capability is the basis for the extension of freedom and equality in society.[348] Many forms of socialist theory hold that human behaviour is largely shaped by the social environment. In particular, socialism holds that social mores, values, cultural traits and economic practices are social creations and not the result of an immutable natural law.[349][350] The object of their critique is thus not human avarice or human consciousness, but the material conditions and man-made social systems (i.e. the economic structure of society) that gives rise to observed social problems and inefficiencies. Bertrand Russell, often considered to be the father of analytic philosophy, identified as a socialist. Russell opposed the class struggle aspects of Marxism, viewing socialism solely as an adjustment of economic relations to accommodate modern machine production to benefit all of humanity through the progressive reduction of necessary work time.[351]
",2
1814,"Socialists view creativity as an essential aspect of human nature and define freedom as a state of being where individuals are able to express their creativity unhindered by constraints of both material scarcity and coercive social institutions.[352] The socialist concept of individuality is intertwined with the concept of individual creative expression. Karl Marx believed that expansion of the productive forces and technology was the basis for the expansion of human freedom and that socialism, being a system that is consistent with modern developments in technology, would enable the flourishing of ""free individualities"" through the progressive reduction of necessary labour time. The reduction of necessary labour time to a minimum would grant individuals the opportunity to pursue the development of their true individuality and creativity.[353]
",2
1815,"Socialists argue that the accumulation of capital generates waste through externalities that require costly corrective regulatory measures. They also point out that this process generates wasteful industries and practices that exist only to generate sufficient demand for products such as high-pressure advertisement to be sold at a profit, thereby creating rather than satisfying economic demand.[354][355]
",2
1816,"Socialists argue that capitalism consists of irrational activity, such as the purchasing of commodities only to sell at a later time when their price appreciates, rather than for consumption, even if the commodity cannot be sold at a profit to individuals in need and therefore a crucial criticism often made by socialists is that ""making money"", or accumulation of capital, does not correspond to the satisfaction of demand (the production of use-values).[356] The fundamental criterion for economic activity in capitalism is the accumulation of capital for reinvestment in production, but this spurs the development of new, non-productive industries that do not produce use-value and only exist to keep the accumulation process afloat (otherwise the system goes into crisis), such as the spread of the financial industry, contributing to the formation of economic bubbles.[357]
",2
1817,"Socialists view private property relations as limiting the potential of productive forces in the economy. According to socialists, private property becomes obsolete when it concentrates into centralised, socialised institutions based on private appropriation of revenue—but based on cooperative work and internal planning in allocation of inputs—until the role of the capitalist becomes redundant.[358] With no need for capital accumulation and a class of owners, private property in the means of production is perceived as being an outdated form of economic organisation that should be replaced by a free association of individuals based on public or common ownership of these socialised assets.[359][360] Private ownership imposes constraints on planning, leading to uncoordinated economic decisions that result in business fluctuations, unemployment and a tremendous waste of material resources during crisis of overproduction.[361]
",2
1818,"Excessive disparities in income distribution lead to social instability and require costly corrective measures in the form of redistributive taxation, which incurs heavy administrative costs while weakening the incentive to work, inviting dishonesty and increasing the likelihood of tax evasion while (the corrective measures) reduce the overall efficiency of the market economy.[362] These corrective policies limit the incentive system of the market by providing things such as minimum wages, unemployment insurance, taxing profits and reducing the reserve army of labour, resulting in reduced incentives for capitalists to invest in more production. In essence, social welfare policies cripple capitalism and its incentive system and are thus unsustainable in the long-run.[363] Marxists argue that the establishment of a socialist mode of production is the only way to overcome these deficiencies. Socialists and specifically Marxian socialists argue that the inherent conflict of interests between the working class and capital prevent optimal use of available human resources and leads to contradictory interest groups (labour and business) striving to influence the state to intervene in the economy in their favour at the expense of overall economic efficiency.
",2
1819,"Early socialists (utopian socialists and Ricardian socialists) criticised capitalism for concentrating power and wealth within a small segment of society.[364] In addition, they complained that capitalism does not use available technology and resources to their maximum potential in the interests of the public.[360]
",2
1820,"—Karl Marx, Critique of the Gotha Program
",2
1821,"Karl Marx and Friedrich Engels argued that socialism would emerge from historical necessity as capitalism rendered itself obsolete and unsustainable from increasing internal contradictions emerging from the development of the productive forces and technology. It was these advances in the productive forces combined with the old social relations of production of capitalism that would generate contradictions, leading to working-class consciousness.[366]
",2
1822,"Marx and Engels held the view that the consciousness of those who earn a wage or salary (the working class in the broadest Marxist sense) would be moulded by their conditions of wage slavery, leading to a tendency to seek their freedom or emancipation by overthrowing ownership of the means of production by capitalists and consequently, overthrowing the state that upheld this economic order. For Marx and Engels, conditions determine consciousness and ending the role of the capitalist class leads eventually to a classless society in which the state would wither away. The Marxist conception of socialism is that of a specific historical phase that would displace capitalism and precede communism. The major characteristics of socialism (particularly as conceived by Marx and Engels after the Paris Commune of 1871) are that the proletariat would control the means of production through a workers' state erected by the workers in their interests. Economic activity would still be organised through the use of incentive systems and social classes would still exist, but to a lesser and diminishing extent than under capitalism.
",2
1823,"For orthodox Marxists, socialism is the lower stage of communism based on the principle of ""from each according to his ability, to each according to his contribution"" while upper stage communism is based on the principle of ""from each according to his ability, to each according to his need"", the upper stage becoming possible only after the socialist stage further develops economic efficiency and the automation of production has led to a superabundance of goods and services.[367][368] Marx argued that the material productive forces (in industry and commerce) brought into existence by capitalism predicated a cooperative society since production had become a mass social, collective activity of the working class to create commodities but with private ownership (the relations of production or property relations). This conflict between collective effort in large factories and private ownership would bring about a conscious desire in the working class to establish collective ownership commensurate with the collective efforts their daily experience.[365]
",2
1824,"Socialists have taken different perspectives on the state and the role it should play in revolutionary struggles, in constructing socialism and within an established socialist economy.
",2
1825,"In the 19th century, the philosophy of state socialism was first explicitly expounded by the German political philosopher Ferdinand Lassalle. In contrast to Karl Marx's perspective of the state, Lassalle rejected the concept of the state as a class-based power structure whose main function was to preserve existing class structures. Lassalle also rejected the Marxist view that the state was destined to ""wither away"". Lassalle considered the state to be an entity independent of class allegiances and an instrument of justice that would therefore be essential for achieving socialism.[369]
",2
1826,"Preceding the Bolshevik-led revolution in Russia, many socialists including reformists, orthodox Marxist currents such as council communism, anarchists and libertarian socialists criticised the idea of using the state to conduct central planning and own the means of production as a way to establish socialism. Following the victory of Leninism in Russia, the idea of ""state socialism"" spread rapidly throughout the socialist movement and eventually state socialism came to be identified with the Soviet economic model.[370]
",2
1827,"Joseph Schumpeter rejected the association of socialism and social ownership with state ownership over the means of production because the state as it exists in its current form is a product of capitalist society and cannot be transplanted to a different institutional framework. Schumpeter argued that there would be different institutions within socialism than those that exist within modern capitalism, just as feudalism had its own distinct and unique institutional forms. The state, along with concepts like property and taxation, were concepts exclusive to commercial society (capitalism) and attempting to place them within the context of a future socialist society would amount to a distortion of these concepts by using them out of context.[371]
",2
1828,"Utopian socialism is a term used to define the first currents of modern socialist thought as exemplified by the work of Henri de Saint-Simon, Charles Fourier and Robert Owen which inspired Karl Marx and other early socialists.[372] However, visions of imaginary ideal societies, which competed with revolutionary social democratic movements, were viewed as not being grounded in the material conditions of society and as reactionary.[373] Although it is technically possible for any set of ideas or any person living at any time in history to be a utopian socialist, the term is most often applied to those socialists who lived in the first quarter of the 19th century who were ascribed the label ""utopian"" by later socialists as a negative term in order to imply naivete and dismiss their ideas as fanciful or unrealistic.[99]
",2
1829,"Religious sects whose members live communally such as the Hutterites are not usually called ""utopian socialists"", although their way of living is a prime example. They have been categorised as religious socialists by some. Similarly, modern intentional communities based on socialist ideas could also be categorised as ""utopian socialist"".
",2
1830,"For Marxists, the development of capitalism in Western Europe provided a material basis for the possibility of bringing about socialism because according to The Communist Manifesto ""[w]hat the bourgeoisie produces above all is its own grave diggers"",[374] namely the working class, which must become conscious of the historical objectives set it by society.
",2
1831,"Revolutionary socialists believe that a social revolution is necessary to effect structural changes to the socioeconomic structure of society. Among revolutionary socialists there are differences in strategy, theory and the definition of revolution. Orthodox Marxists and left communists take an impossibilist stance, believing that revolution should be spontaneous as a result of contradictions in society due to technological changes in the productive forces. Lenin theorised that under capitalism the workers cannot achieve class consciousness beyond organising into trade unions and making demands of the capitalists. Therefore, Leninists advocate that it is historically necessary for a vanguard of class conscious revolutionaries to take a central role in coordinating the social revolution to overthrow the capitalist state and eventually the institution of the state altogether.[375] Revolution is not necessarily defined by revolutionary socialists as violent insurrection,[376] but as a complete dismantling and rapid transformation of all areas of class society led by the majority of the masses: the working class.
",2
1832,"Reformism is generally associated with social democracy and gradualist democratic socialism. Reformism is the belief that socialists should stand in parliamentary elections within capitalist society and if elected use the machinery of government to pass political and social reforms for the purposes of ameliorating the instabilities and inequities of capitalism. Within socialism, reformism is used in two different ways. One has no intention of bringing about socialism or fundamental economic change to society and is used to oppose such structural changes. The other is based on the assumption that while reforms are not socialist in themselves, they can help rally supporters to the cause of revolution by popularizing the cause of socialism to the working class.[377]
",2
1833,"The debate on the ability for social democratic reformism to lead to a socialist transformation of society is over a century old. Reformism is criticized for being paradoxical as it seeks to overcome the existing economic system of capitalism while trying to improve the conditions of capitalism, thereby making it appear more tolerable to society. According to Rosa Luxemburg, capitalism is not overthrown, ""but is on the contrary strengthened by the development of social reforms"".[378] In a similar vein, Stan Parker of the Socialist Party of Great Britain argues that reforms are a diversion of energy for socialists and are limited because they must adhere to the logic of capitalism.[377] French social theorist Andre Gorz criticized reformism by advocating a third alternative to reformism and social revolution that he called ""non-reformist reforms"", specifically focused on structural changes to capitalism as opposed to reforms to improve living conditions within capitalism or to prop it up through economic interventions.[379]
",2
1834,"—Albert Einstein, Why Socialism?, 1949
",2
1835,"Socialist economics starts from the premise that ""individuals do not live or work in isolation but live in cooperation with one another. Furthermore, everything that people produce is in some sense a social product, and everyone who contributes to the production of a good is entitled to a share in it. Society as whole, therefore, should own or at least control property for the benefit of all its members"".[108]
",2
1836,"The original conception of socialism was an economic system whereby production was organised in a way to directly produce goods and services for their utility (or use-value in classical and Marxian economics), with the direct allocation of resources in terms of physical units as opposed to financial calculation and the economic laws of capitalism (see law of value), often entailing the end of capitalistic economic categories such as rent, interest, profit and money.[381] In a fully developed socialist economy, production and balancing factor inputs with outputs becomes a technical process to be undertaken by engineers.[382]
",2
1837,"Market socialism refers to an array of different economic theories and systems that use the market mechanism to organise production and to allocate factor inputs among socially owned enterprises, with the economic surplus (profits) accruing to society in a social dividend as opposed to private capital owners.[383] Variations of market socialism include libertarian proposals such as mutualism, based on classical economics, and neoclassical economic models such as the Lange Model. However, some economists such as Joseph Stiglitz, Mancur Olson and others not specifically advancing anti-socialists positions have shown that prevailing economic models upon which such democratic or market socialism models might be based have logical flaws or unworkable presuppositions.[384][385]
",2
1838,"The ownership of the means of production can be based on direct ownership by the users of the productive property through worker cooperative; or commonly owned by all of society with management and control delegated to those who operate/use the means of production; or public ownership by a state apparatus. Public ownership may refer to the creation of state-owned enterprises, nationalisation, municipalisation or autonomous collective institutions. Some socialists feel that in a socialist economy, at least the ""commanding heights"" of the economy must be publicly owned.[386] However, economic liberals and right libertarians view private ownership of the means of production and the market exchange as natural entities or moral rights which are central to their conceptions of freedom and liberty and view the economic dynamics of capitalism as immutable and absolute, therefore they perceive public ownership of the means of production, cooperatives and economic planning as infringements upon liberty.[387][388]
",2
1839,"Management and control over the activities of enterprises are based on self-management and self-governance, with equal power-relations in the workplace to maximise occupational autonomy. A socialist form of organisation would eliminate controlling hierarchies so that only a hierarchy based on technical knowledge in the workplace remains. Every member would have decision-making power in the firm and would be able to participate in establishing its overall policy objectives. The policies/goals would be carried out by the technical specialists that form the coordinating hierarchy of the firm, who would establish plans or directives for the work community to accomplish these goals.[389]
",2
1840,"The role and use of money in a hypothetical socialist economy is a contested issue. According to the Austrian school economist Ludwig von Mises, an economic system that does not use money, financial calculation and market pricing would be unable to effectively value capital goods and coordinate production and therefore these types of socialism are impossible because they lack the necessary information to perform economic calculation in the first place.[390][391] Socialists including Karl Marx, Robert Owen, Pierre-Joseph Proudhon and John Stuart Mill advocated various forms of labour vouchers or labour credits, which like money would be used to acquire articles of consumption, but unlike money they are unable to become capital and would not be used to allocate resources within the production process. Bolshevik revolutionary Leon Trotsky argued that money could not be arbitrarily abolished following a socialist revolution. Money had to exhaust its ""historic mission"", meaning it would have to be used until its function became redundant, eventually being transformed into bookkeeping receipts for statisticians and only in the more distant future would money not be required for even that role.[392]
",2
1841,"A planned economy is a type of economy consisting of a mixture of public ownership of the means of production and the coordination of production and distribution through economic planning. A planned economy can be either decentralised or centralised. Enrico Barone provided a comprehensive theoretical framework for a planned socialist economy. In his model, assuming perfect computation techniques, simultaneous equations relating inputs and outputs to ratios of equivalence would provide appropriate valuations in order to balance supply and demand.[393]
",2
1842,"The most prominent example of a planned economy was the economic system of the Soviet Union and as such the centralised-planned economic model is usually associated with the communist states of the 20th century, where it was combined with a single-party political system. In a centrally planned economy, decisions regarding the quantity of goods and services to be produced are planned in advance by a planning agency (see also the analysis of Soviet-type economic planning). The economic systems of the Soviet Union and the Eastern Bloc are further classified as ""command economies"", which are defined as systems where economic coordination is undertaken by commands, directives and production targets.[394] Studies by economists of various political persuasions on the actual functioning of the Soviet economy indicate that it was not actually a planned economy. Instead of conscious planning, the Soviet economy was based on a process whereby the plan was modified by localised agents and the original plans went largely unfulfilled. Planning agencies, ministries and enterprises all adapted and bargained with each other during the formulation of the plan as opposed to following a plan passed down from a higher authority, leading some economists to suggest that planning did not actually take place within the Soviet economy and that a better description would be an ""administered"" or ""managed"" economy.[395]
",2
1843,"Although central planning was largely supported by Marxist–Leninists, some factions within the Soviet Union before the rise of Stalinism held positions contrary to central planning. Leon Trotsky rejected central planning in favour of decentralised planning. He argued that central planners, regardless of their intellectual capacity, would be unable to coordinate effectively all economic activity within an economy because they operated without the input and tacit knowledge embodied by the participation of the millions of people in the economy. As a result, central planners would be unable to respond to local economic conditions.[396] State socialism is unfeasible in this view because information cannot be aggregated by a central body and effectively used to formulate a plan for an entire economy, because doing so would result in distorted or absent price signals.[397]
",2
1844,"—Upton Sinclair
",2
1845,"A self-managed, decentralised economy is based on autonomous self-regulating economic units and a decentralised mechanism of resource allocation and decision-making. This model has found support in notable classical and neoclassical economists including Alfred Marshall, John Stuart Mill and Jaroslav Vanek. There are numerous variations of self-management, including labour-managed firms and worker-managed firms. The goals of self-management are to eliminate exploitation and reduce alienation.[399] Guild socialism is a political movement advocating workers' control of industry through the medium of trade-related guilds ""in an implied contractual relationship with the public"".[400] It originated in the United Kingdom and was at its most influential in the first quarter of the 20th century.[400] It was strongly associated with G. D. H. Cole and influenced by the ideas of William Morris.
",2
1846,"One such system is the cooperative economy, a largely free market economy in which workers manage the firms and democratically determine remuneration levels and labour divisions. Productive resources would be legally owned by the cooperative and rented to the workers, who would enjoy usufruct rights.[401] Another form of decentralised planning is the use of cybernetics, or the use of computers to manage the allocation of economic inputs. The socialist-run government of Salvador Allende in Chile experimented with Project Cybersyn, a real-time information bridge between the government, state enterprises and consumers.[402] Another, more recent variant is participatory economics, wherein the economy is planned by decentralised councils of workers and consumers. Workers would be remunerated solely according to effort and sacrifice, so that those engaged in dangerous, uncomfortable and strenuous work would receive the highest incomes and could thereby work less.[403] A contemporary model for a self-managed, non-market socialism is Pat Devine's model of negotiated coordination. Negotiated coordination is based upon social ownership by those affected by the use of the assets involved, with decisions made by those at the most localised level of production.[404]
",2
1847,"Michel Bauwens identifies the emergence of the open software movement and peer-to-peer production as a new alternative mode of production to the capitalist economy and centrally planned economy that is based on collaborative self-management, common ownership of resources and the production of use-values through the free cooperation of producers who have access to distributed capital.[405]
",2
1848,"Anarcho-communism is a theory of anarchism which advocates the abolition of the state, private property and capitalism in favour of common ownership of the means of production.[406][407] Anarcho-syndicalism was practised in Catalonia and other places in the Spanish Revolution during the Spanish Civil War. Sam Dolgoff estimated that about eight million people participated directly or at least indirectly in the Spanish Revolution.[408]
",2
1849,"The economy of the former Socialist Federal Republic of Yugoslavia established a system based on market-based allocation, social ownership of the means of production and self-management within firms. This system substituted Yugoslavia's Soviet-type central planning with a decentralised, self-managed system after reforms in 1953.[409]
",2
1850,"The Marxian economist Richard D. Wolff argues that ""re-organising production so that workers become collectively self-directed at their work-sites"" not only moves society beyond both capitalism and state socialism of the last century, but would also mark another milestone in human history, similar to earlier transitions out of slavery and feudalism.[410] As an example, Wolff claims that Mondragon is ""a stunningly successful alternative to the capitalist organisation of production"".[411]
",2
1851,"State socialism can be used to classify any variety of socialist philosophies that advocates the ownership of the means of production by the state apparatus, either as a transitional stage between capitalism and socialism, or as an end-goal in itself. Typically, it refers to a form of technocratic management, whereby technical specialists administer or manage economic enterprises on behalf of society and the public interest instead of workers' councils or workplace democracy.
",2
1852,"A state-directed economy may refer to a type of mixed economy consisting of public ownership over large industries, as promoted by various Social democratic political parties during the 20th century. This ideology influenced the policies of the British Labour Party during Clement Attlee's administration. In the biography of the 1945 United Kingdom Labour Party Prime Minister Clement Attlee, Francis Beckett states: ""[T]he government [...] wanted what would become known as a mixed economy"".[412]
",2
1853,"Nationalisation in the United Kingdom was achieved through compulsory purchase of the industry (i.e. with compensation). British Aerospace was a combination of major aircraft companies British Aircraft Corporation, Hawker Siddeley and others. British Shipbuilders was a combination of the major shipbuilding companies including Cammell Laird, Govan Shipbuilders, Swan Hunter and Yarrow Shipbuilders, whereas the nationalisation of the coal mines in 1947 created a coal board charged with running the coal industry commercially so as to be able to meet the interest payable on the bonds which the former mine owners' shares had been converted into.[413][414]
",2
1854,"Market socialism consists of publicly owned or cooperatively owned enterprises operating in a market economy. It is a system that uses the market and monetary prices for the allocation and accounting of the means of production, thereby retaining the process of capital accumulation. The profit generated would be used to directly remunerate employees, collectively sustain the enterprise or finance public institutions.[415] In state-oriented forms of market socialism, in which state enterprises attempt to maximise profit, the profits can be used to fund government programs and services through a social dividend, eliminating or greatly diminishing the need for various forms of taxation that exist in capitalist systems. Neoclassical economist Léon Walras believed that a socialist economy based on state ownership of land and natural resources would provide a means of public finance to make income taxes unnecessary.[416] Yugoslavia implemented a market socialist economy based on cooperatives and worker self-management.
",2
1855,"Mutualism is an economic theory and anarchist school of thought that advocates a society where each person might possess a means of production, either individually or collectively, with trade representing equivalent amounts of labour in the free market.[417] Integral to the scheme was the establishment of a mutual-credit bank that would lend to producers at a minimal interest rate, just high enough to cover administration.[418] Mutualism is based on a labour theory of value that holds that when labour or its product is sold, in exchange it ought to receive goods or services embodying ""the amount of labour necessary to produce an article of exactly similar and equal utility"".[419]
",2
1856,"The current economic system in China is formally referred to as a socialist market economy with Chinese characteristics. It combines a large state sector that comprises the commanding heights of the economy, which are guaranteed their public ownership status by law,[420] with a private sector mainly engaged in commodity production and light industry responsible from anywhere between 33%[421] to over 70% of GDP generated in 2005.[422] Although there has been a rapid expansion of private-sector activity since the 1980s, privatisation of state assets was virtually halted and were partially reversed in 2005.[423] The current Chinese economy consists of 150 corporatised state-owned enterprises that report directly to China's central government.[424] By 2008, these state-owned corporations had become increasingly dynamic and generated large increases in revenue for the state,[425][426] resulting in a state-sector led recovery during the 2009 financial crises while accounting for most of China's economic growth.[427] However, the Chinese economic model is widely cited as a contemporary form of state capitalism, the major difference between Western capitalism and the Chinese model being the degree of state-ownership of shares in publicly listed corporations.
",2
1857,"The Socialist Republic of Vietnam has adopted a similar model after the Doi Moi economic renovation, but slightly differs from the Chinese model in that the Vietnamese government retains firm control over the state sector and strategic industries, but allows for private-sector activity in commodity production.[428]
",2
1858,"While major socialist political movements include anarchism, communism, the labour movement, Marxism, social democracy and syndicalism, independent socialist theorists, utopian socialist authors and academic supporters of socialism may not be represented in these movements. Some political groups have called themselves socialist while holding views that some consider antithetical to socialism. The term socialist has also been used by some politicians on the political right as an epithet against certain individuals who do not consider themselves to be socialists and against policies that are not considered socialist by their proponents. There are many variations of socialism and as such there is no single definition encapsulating all of socialism. However, there have been common elements identified by scholars.[429]
",2
1859,"In his Dictionary of Socialism (1924), Angelo S. Rappoport analysed forty definitions of socialism to conclude that common elements of socialism include general criticism of the social effects of private ownership and control of capital—as being the cause of poverty, low wages, unemployment, economic and social inequality and a lack of economic security; a general view that the solution to these problems is a form of collective control over the means of production, distribution and exchange (the degree and means of control vary amongst socialist movements); an agreement that the outcome of this collective control should be a society based upon social justice, including social equality, economic protection of people and should provide a more satisfying life for most people.[430]
",2
1860,"In The Concepts of Socialism (1975), Bhikhu Parekh identifies four core principles of socialism and particularly socialist society, namely sociality, social responsibility, cooperation and planning.[431] In his study Ideologies and Political Theory (1996), Michael Freeden states that all socialists share five themes: the first is that socialism posits that society is more than a mere collection of individuals; second, that it considers human welfare a desirable objective; third, that it considers humans by nature to be active and productive; fourth, it holds the belief of human equality; and fifth, that history is progressive and will create positive change on the condition that humans work to achieve such change.[431]
",2
1861,"Anarchism advocates stateless societies often defined as self-governed voluntary institutions,[432][433][434][435] but that several authors have defined as more specific institutions based on non-hierarchical free associations.[436][437][438][439] While anarchism holds the state to be undesirable, unnecessary or harmful,[440][441] it is not the central aspect.[442] Anarchism entails opposing authority or hierarchical organisation in the conduct of human relations, including the state system.[436][443][444][445][446][447][448] Mutualists support market socialism, collectivist anarchists favour workers cooperatives and salaries based on the amount of time contributed to production, anarcho-communists advocate a direct transition from capitalism to libertarian communism and a gift economy and anarcho-syndicalists prefer workers' direct action and the general strike.[449]
",2
1862,"The authoritarian–libertarian struggles and disputes within the socialist movement go back to the First International and the expulsion in 1872 of the anarchists, who went on to lead the Anti-authoritarian International and then founded their own libertarian international, the Anarchist St. Imier International.[450] In 1888, the individualist anarchist Benjamin Tucker, who proclaimed himself to be an anarchistic socialist and libertarian socialist in opposition to the authoritarian state socialism and the compulsory communism, included the full text of a ""Socialistic Letter"" by Ernest Lesigne[451] in his essay on ""State Socialism and Anarchism"". According to Lesigne, there are two types of socialism: ""One is dictatorial, the other libertarian"".[452] Tucker's two socialisms were the authoritarian state socialism which he associated to the Marxist school and the libertarian anarchist socialism, or simply anarchism, that he advocated. Tucker noted that the fact that the authoritarian ""State Socialism has overshadowed other forms of Socialism gives it no right to a monopoly of the Socialistic idea"".[453] According to Tucker, what those two schools of socialism had in common was the labor theory of value and the ends, by which anarchism pursued different means.[454]
",2
1863,"According to anarchists such as the authors of An Anarchist FAQ, anarchism is one of the many traditions of socialism. For anarchists and other anti-authoritarian socialists, socialism ""can only mean a classless and anti-authoritarian (i.e. libertarian) society in which people manage their own affairs, either as individuals or as part of a group (depending on the situation). In other words, it implies self-management in all aspects of life"", including at the workplace.[449] Michael Newman includes anarchism as one of many socialist traditions.[455] Peter Marshall argues that ""[i]n general anarchism is closer to socialism than liberalism. [...] Anarchism finds itself largely in the socialist camp, but it also has outriders in liberalism. It cannot be reduced to socialism, and is best seen as a separate and distinctive doctrine"".[456]
",2
1864,"—Martin Luther King Jr., 1966
",2
1865,"Democratic socialism represents any socialist movement that seeks to establish an economy based on economic democracy by and for the working class. Democratic socialism is difficult to define and groups of scholars have radically different definitions for the term. Some definitions simply refer to all forms of socialism that follow an electoral, reformist or evolutionary path to socialism rather than a revolutionary one.[460] According to Christopher Pierson, ""[i]f the contrast which 1989 highlights is not that between socialism in the East and liberal democracy in the West, the latter must be recognized to have been shaped, reformed and compromised by a century of social democratic pressure"". Pierson further claims that ""social democratic and socialist parties within the constitutional arena in the West have almost always been involved in a politics of compromise with existing capitalist institutions (to whatever far distant prize its eyes might from time to time have been lifted)"". For Pierson, ""if advocates of the death of socialism accept that social democrats belong within the socialist camp, as I think they must, then the contrast between socialism (in all its variants) and liberal democracy must collapse. For actually existing liberal democracy is, in substantial part, a product of socialist (social democratic) forces"".[461]
",2
1866,"Social democracy is a socialist tradition of political thought.[462][463] Many social democrats refer to themselves as socialists or democratic socialists and some such as Tony Blair employ these terms interchangeably.[464][465][466] Others found ""clear differences"" between the three terms and prefer to describe their own political beliefs by using the term social democracy.[467] The two main directions were to establish democratic socialism or to build first a welfare state within the capitalist system. The first variant advances democratic socialism through reformist and gradualist methods.[468] In the second variant, social democracy is a policy regime involving a welfare state, collective bargaining schemes, support for publicly financed public services and a mixed economy. It is often used in this manner to refer to Western and Northern Europe during the later half of the 20th century.[469][470] It was described by Jerry Mander as ""hybrid economics"", an active collaboration of capitalist and socialist visions.[471] Numerous studies and surveys indicate that people tend to live happier lives in social democratic societies rather than neoliberal ones.[472][473][474][475]
",2
1867,"Social democrats advocate for a peaceful, evolutionary transition of the economy to socialism through progressive social reform.[476][477] It asserts that the only acceptable constitutional form of government is representative democracy under the rule of law.[478] It promotes extending democratic decision-making beyond political democracy to include economic democracy to guarantee employees and other economic stakeholders sufficient rights of co-determination.[478] It supports a mixed economy that opposes inequality, poverty and oppression while rejecting both a totally unregulated market economy or a fully planned economy.[479] Common social democratic policies include universal social rights and universally accessible public services such as education, health care, workers' compensation and other services, including child care and elder care.[478] Social democracy supports the trade union labour movement and supports collective bargaining rights for workers.[480] Most social democratic parties are affiliated with the Socialist International.[468]
",2
1868,"Modern democratic socialism is a broad political movement that seeks to promote the ideals of socialism within the context of a democratic system. Some democratic socialists support social democracy as a temporary measure to reform the current system while others reject reformism in favour of more revolutionary methods. Modern social democracy emphasises a program of gradual legislative modification of capitalism in order to make it more equitable and humane while the theoretical end goal of building a socialist society is relegated to the indefinite future. According to Sheri Berman, Marxism is loosely held to be valuable for its emphasis on changing the world for a more just, better future.[481]
",2
1869,"The two movements are widely similar both in terminology and in ideology, although there are a few key differences. The major difference between social democracy and democratic socialism is the object of their politics in that contemporary social democrats support a welfare state and unemployment insurance as well as other practical, progressive reforms of capitalism and are more concerned to administrate and humanise it. On the other hand, democratic socialists seek to replace capitalism with a socialist economic system, arguing that any attempt to humanise capitalism through regulations and welfare policies would distort the market and create economic contradictions.[482]
",2
1870,"Ethical socialism appeals to socialism on ethical and moral grounds as opposed to economic, egoistic and consumeristic grounds. It emphasizes the need for a morally conscious economy based upon the principles of altruism, cooperation and social justice while opposing possessive individualism.[483] Ethical socialism has been the official philosophy of mainstream socialist parties.[484]
",2
1871,"Liberal socialism incorporates liberal principles to socialism.[485] It has been compared to post-war social democracy[486] for its support of a mixed economy that includes both public and private capital goods.[487][488] While democratic socialism and social democracy are anti-capitalist positions insofar as criticism of capitalism is linked to the private ownership of the means of production,[489] liberal socialism identifies artificial and legalistic monopolies to be the fault of capitalism[490] and opposes an entirely unregulated market economy.[491] It considers both liberty and social equality to be compatible and mutually dependent.[485]
",2
1872,"Principles that can be described as ethical or liberal socialist have been based upon or developed by philosophers such as John Stuart Mill, Eduard Bernstein, John Dewey, Carlo Rosselli, Norberto Bobbio and Chantal Mouffe.[492] Other important liberal socialist figures include Guido Calogero, Piero Gobetti, Leonard Trelawny Hobhouse, John Maynard Keynes and R. H. Tawney.[491] Liberal socialism has been particularly prominent in British and Italian politics.[491]
",2
1873,"Blanquism is a conception of revolution named for Louis Auguste Blanqui. It holds that socialist revolution should be carried out by a relatively small group of highly organised and secretive conspirators.[493] Upon seizing power, the revolutionaries introduce socialism.[494] Rosa Luxemburg and Eduard Bernstein[495] criticised Lenin, stating that his conception of revolution was elitist and Blanquist.[496] Marxism–Leninism combines Marx's scientific socialist concepts and Lenin's anti-imperialism, democratic centralism and vanguardism.[497]
",2
1874,"Hal Draper defined socialism from above as the philosophy which employs an elite administration to run the socialist state. The other side of socialism is a more democratic socialism from below.[498] The idea of socialism from above is much more frequently discussed in elite circles than socialism from below—even if that is the Marxist ideal—because it is more practical.[499] Draper viewed socialism from below as being the purer, more Marxist version of socialism.[500] According to Draper, Karl Marx and Friedrich Engels were devoutly opposed to any socialist institution that was ""conducive to superstitious authoritarianism"". Draper makes the argument that this division echoes the division between ""reformist or revolutionary, peaceful or violent, democratic or authoritarian, etc."" and further identifies six major varieties of socialism from above, among them ""Philanthropism"", ""Elitism"", ""Pannism"", ""Communism"", ""Permeationism"" and ""Socialism-from-Outside"".[501]
",2
1875,"According to Arthur Lipow, Marx and Engels were ""the founders of modern revolutionary democratic socialism"", described as a form of ""socialism from below"" that is ""based on a mass working-class movement, fighting from below for the extension of democracy and human freedom"". This type of socialism is contrasted to that of the ""authoritarian, antidemocratic creed"" and ""the various totalitarian collectivist ideologies which claim the title of socialism"" as well as ""the many varieties of 'socialism from above' which have led in the twentieth century to movements and state forms in which a despotic 'new class' rules over a statified economy in the name of socialism"", a division that ""runs through the history of the socialist movement"". Lipow identifies Bellamyism and Stalinism as two prominent authoritarian socialist currents within the history of the socialist movement.[502]
",2
1876,"Libertarian socialism, sometimes called left-libertarianism,[505][506] social anarchism[507][508] and socialist libertarianism,[509] is an anti-authoritarian, anti-statist and libertarian[510] tradition within socialism that rejects centralised state ownership and control[511] including criticism of wage labour relationships (wage slavery)[512] as well as the state itself.[513] It emphasises workers' self-management[513] and decentralised structures of political organisation.[514] Libertarian socialism asserts that a society based on freedom and equality can be achieved through abolishing authoritarian institutions that control production.[515] Libertarian socialists generally prefer direct democracy and federal or confederal associations such as libertarian municipalism, citizens' assemblies, trade unions and workers' councils.[516][517]
",2
1877,"Anarcho-syndicalist Gaston Leval explained: ""We therefore foresee a Society in which all activities will be coordinated, a structure that has, at the same time, sufficient flexibility to permit the greatest possible autonomy for social life, or for the life of each enterprise, and enough cohesiveness to prevent all disorder. [...] In a well-organised society, all of these things must be systematically accomplished by means of parallel federations, vertically united at the highest levels, constituting one vast organism in which all economic functions will be performed in solidarity with all others and that will permanently preserve the necessary cohesion"".[518] All of this is generally done within a general call for libertarian[519] and voluntary free associations[520] through the identification, criticism and practical dismantling of illegitimate authority in all aspects of human life.[443][521][522]
",2
1878,"As part of the larger socialist movement, it seeks to distinguish itself from Bolshevism, Leninism and Marxism–Leninism as well as social democracy.[523] Past and present political philosophies and movements commonly described as libertarian socialist include anarchism (anarcho-communism, anarcho-syndicalism[524] collectivist anarchism, individualist anarchism[525][526][527] and mutualism),[528] autonomism, Communalism, participism, libertarian Marxism (council communism and Luxemburgism),[529] revolutionary syndicalism and utopian socialism (Fourierism).[530]
",2
1879,Christian socialism is a broad concept involving an intertwining of Christian religion with socialism.,2
1880,"Islamic socialism is a more spiritual form of socialism. Muslim socialists believe that the teachings of the Qur'an and Muhammad are not only compatible with, but actively promoting the principles of equality and public ownership, drawing inspiration from the early Medina welfare state he established. Muslim socialists are more conservative than their Western contemporaries and find their roots in anti-imperialism, anti-colonialism and sometimes, if in an Arab speaking country, Arab nationalism. Islamic socialists believe in deriving legitimacy from political mandate as opposed to religious texts. 
",2
1881,"Socialist feminism is a branch of feminism that argues that liberation can only be achieved by working to end both economic and cultural sources of women's oppression.[531] Marxist feminism's foundation was laid by Engels in The Origin of the Family, Private Property, and the State (1884). August Bebel's Woman under Socialism (1879), is the ""single work dealing with sexuality most widely read by rank-and-file members of the Social Democratic Party of Germany (SPD)"".[532] In the late 19th and early 20th centuries, both Clara Zetkin and Eleanor Marx were against the demonisation of men and supported a proletariat revolution that would overcome as many male-female inequalities as possible.[533] As their movement already had the most radical demands in women's equality, most Marxist leaders, including Clara Zetkin[534][535] and Alexandra Kollontai,[536][537] counterposed Marxism against liberal feminism rather than trying to combine them. Anarcha-feminism began with late 19th- and early 20th-century authors and theorists such as anarchist feminists Goldman and Voltairine de Cleyre[538] In the Spanish Civil War, an anarcha-feminist group, Mujeres Libres (""Free Women"") linked to the Federación Anarquista Ibérica, organised to defend both anarchist and feminist ideas.[539] In 1972, the Chicago Women's Liberation Union published ""Socialist Feminism: A Strategy for the Women's Movement"", which is believed to be the first published use of the term ""socialist feminism"".[540]
",2
1882,"Many socialists were early advocates for LGBT rights. For early socialist Charles Fourier, true freedom could only occur without suppressing passions, as the suppression of passions is not only destructive to the individual, but to society as a whole. Writing before the advent of the term ""homosexuality"", Fourier recognised that both men and women have a wide range of sexual needs and preferences which may change throughout their lives, including same-sex sexuality and androgénité. He argued that all sexual expressions should be enjoyed as long as people are not abused and that ""affirming one's difference"" can actually enhance social integration.[541][542] In Oscar Wilde's The Soul of Man Under Socialism, he advocates for an egalitarian society where wealth is shared by all, while warning of the dangers of social systems that crush individuality.[543] Edward Carpenter actively campaigned for homosexual rights. His work The Intermediate Sex: A Study of Some Transitional Types of Men and Women was a 1908 book arguing for gay liberation.[544] who was an influential personality in the foundation of the Fabian Society and the Labour Party. After the Russian Revolution under the leadership of Lenin and Trotsky, the Soviet Union abolished previous laws against homosexuality.[545] Harry Hay was an early leader in the American LGBT rights movement as well as a member of the Communist Party USA. He is known for his roles in helping to found gay organisations, including the Mattachine Society, the first sustained gay rights group in the United States which in its early days reflected a strong Marxist influence. The Encyclopedia of Homosexuality reports that ""[a]s Marxists the founders of the group believed that the injustice and oppression which they suffered stemmed from relationships deeply embedded in the structure of American society"".[546] Emerging from events such as the May 1968 insurrection in France, the anti-Vietnam war movement in the US and the Stonewall riots of 1969, militant gay liberation organisations began to spring up around the world. Many sprang from left radicalism more than established homophile groups,[547] although the Gay Liberation Front took an anti-capitalist stance and attacked the nuclear family and traditional gender roles.[548]
",2
1883,"Eco-socialism is a political strain merging aspects of socialism, Marxism or libertarian socialism with green politics, ecology and alter-globalisation. Eco-socialists generally claim that the expansion of the capitalist system is the cause of social exclusion, poverty, war and environmental degradation through globalisation and imperialism under the supervision of repressive states and transnational structures.[549] Contrary to the depiction of Karl Marx by some environmentalists,[550] social ecologists[551] and fellow socialists[552] as a productivist who favoured the domination of nature, eco-socialists revisited Marx's writings and believe that he ""was a main originator of the ecological world-view"".[553] Marx discussed a ""metabolic rift"" between man and nature, stating that ""private ownership of the globe by single individuals will appear quite absurd as private ownership of one man by another"" and his observation that a society must ""hand it [the planet] down to succeeding generations in an improved condition"".[554] English socialist William Morris is credited with developing principles of what was later called eco-socialism.[555] During the 1880s and 1890s, Morris promoted his ideas within the Social Democratic Federation and Socialist League.[556] Green anarchism blends anarchism with environmental issues. An important early influence was Henry David Thoreau and his book Walden[557] as well as Élisée Reclus.[558][559]
",2
1884,"In the late 19th century, anarcho-naturism fused anarchism and naturist philosophies within individualist anarchist circles in France, Spain, Cuba[560] and Portugal.[561] Murray Bookchin's first book Our Synthetic Environment[562] was followed by his essay ""Ecology and Revolutionary Thought"" which introduced ecology as a concept in radical politics.[563] In the 1970s, Barry Commoner, claimed that capitalist technologies were chiefly responsible for environmental degradation as opposed to population pressures.[564] In the 1990s socialist/feminists Mary Mellor[565] and Ariel Salleh[566] adopt an eco-socialist paradigm. An ""environmentalism of the poor"" combining ecological awareness and social justice has also become prominent.[567] Pepper critiqued the current approach of many within green politics, particularly deep ecologists.[568]
",2
1885,"Many green parties around the world such as the Dutch Green Left Party (GroenLinks) employ eco-socialist elements. Radical red-green alliances have been formed in many countries by eco-socialists, radical greens and other radical left groups. In Denmark, the Red-Green Alliance was formed as a coalition of numerous radical parties. Within the European Parliament, a number of leftist parties from Northern Europe have organised themselves into the Nordic Green Left Alliance.[citation needed]
",2
1886,"Syndicalism operates through industrial trade unions. It rejects state socialism and the use of establishment politics. Syndicalists reject state power in favour of strategies such as the general strike. Syndicalists advocate a socialist economy based on federated unions or syndicates of workers who own and manage the means of production. Some Marxist currents advocate syndicalism, such as De Leonism. Anarcho-syndicalism views syndicalism as a method for workers in capitalist society to gain control of an economy. The Spanish Revolution was largely orchestrated by the anarcho-syndicalist trade union CNT.[569] The International Workers' Association is an international federation of anarcho-syndicalist labour unions and initiatives.[570]
",2
1887,"Socialism is criticized in terms of its models of economic organization as well as its political and social implications. Other critiques are directed at the socialist movement, parties or existing states. Some criticisms occupy theoretical grounds (such as in the economic calculation problem and the socialist calculation debate) while others support their criticism by examining historical attempts to establish socialist societies. Because of socialism's many varieties, most critiques focused on a specific approach. Proponents of one approach typically criticize others.[citation needed]
",2
1888,"
",2
1889,"
",2
1890,"
",2
1891,"Liberalism is a political and moral philosophy based on liberty, consent of the governed and equality before the law.[1][2][3] Liberals espouse a wide array of views depending on their understanding of these principles, but they generally support free markets, free trade, limited government, individual rights (including civil rights and human rights), capitalism, democracy, secularism, gender equality, racial equality, internationalism, freedom of speech, freedom of the press and freedom of religion.[4][5][6][7][8][9][10] Yellow is the political colour most commonly associated with liberalism.[11][12][13]
",2
1892,"Liberalism became a distinct movement in the Age of Enlightenment, when it became popular among Western philosophers and economists. Liberalism sought to replace the norms of hereditary privilege, state religion, absolute monarchy, the divine right of kings and traditional conservatism with representative democracy and the rule of law. Liberals also ended mercantilist policies, royal monopolies and other barriers to trade, instead promoting free trade and free markets.[14] Philosopher John Locke is often credited with founding liberalism as a distinct tradition, based on the social contract, arguing that each man has a natural right to life, liberty and property and governments must not violate these rights.[15] While the British liberal tradition has emphasized expanding democracy, French liberalism has emphasized rejecting authoritarianism and is linked to nation-building.[16]
",2
1893,"Leaders in the British Glorious Revolution of 1688,[17] the American Revolution of 1776 and the French Revolution of 1789 used liberal philosophy to justify the armed overthrow of royal tyranny. Liberalism started to spread rapidly especially after the French Revolution. The 19th century saw liberal governments established in nations across Europe and South America, whereas it was well-established alongside republicanism in the United States.[18] In Victorian Britain, it was used to critique the political establishment, appealing to science and reason on behalf of the people.[19] During 19th and early 20th century, liberalism in the Ottoman Empire and Middle East influenced periods of reform such as the Tanzimat and Al-Nahda as well as the rise of constitutionalism, nationalism and secularism. These changes, along with other factors, helped to create a sense of crisis within Islam, which continues to this day, leading to Islamic revivalism. Before 1920, the main ideological opponents of liberalism were communism, conservatism and socialism,[20] but liberalism then faced major ideological challenges from fascism and Marxism–Leninism as new opponents. During the 20th century, liberal ideas spread even further, especially in Western Europe, as liberal democracies found themselves on the winning side in both world wars.[21]
",2
1894,"In Europe and North America, the establishment of social liberalism (often called simply liberalism in the United States) became a key component in the expansion of the welfare state.[22] Today, liberal parties continue to wield power and influence throughout the world. The fundamental elements of contemporary society have liberal roots. The early waves of liberalism popularised economic individualism while expanding constitutional government and parliamentary authority.[14] Liberals sought and established a constitutional order that prized important individual freedoms, such as  freedom of speech and freedom of association; an independent judiciary and public trial by jury; and the abolition of aristocratic privileges.[14] Later waves of modern liberal thought and struggle were strongly influenced by the need to expand civil rights.[23] Liberals have advocated gender and racial equality in their drive to promote civil rights and a global civil rights movement in the 20th century achieved several objectives towards both goals. Other goals often accepted by liberals include universal suffrage and universal access to education.
",2
1895,"Words such as liberal, liberty, libertarian and libertine all trace their history to the Latin liber, which means ""free"".[24] One of the first recorded instances of the word liberal occurs in 1375, when it was used to describe the liberal arts in the context of an education desirable for a free-born man.[24] The word's early connection with the classical education of a medieval university soon gave way to a proliferation of different denotations and connotations. Liberal could refer to ""free in bestowing"" as early as 1387, ""made without stint"" in 1433, ""freely permitted"" in 1530 and ""free from restraint""—often as a pejorative remark—in the 16th and the 17th centuries.[24] In 16th century England, liberal could have positive or negative attributes in referring to someone's generosity or indiscretion.[24] In Much Ado About Nothing, William Shakespeare wrote of ""a liberal villaine"" who ""hath [...] confest his vile encounters"".[24] With the rise of the Enlightenment, the word acquired decisively more positive undertones, being defined as ""free from narrow prejudice"" in 1781 and ""free from bigotry"" in 1823.[24] In 1815, the first use of the word ""liberalism"" appeared in English.[25] In Spain, the liberales, the first group to use the liberal label in a political context,[26] fought for decades for the implementation of the 1812 Constitution. From 1820 to 1823 during the Trienio Liberal, King Ferdinand VII was compelled by the liberales to swear to uphold the Constitution. By the middle of the 19th century, liberal was used as a politicised term for parties and movements worldwide.[27]
",2
1896,"Over time, the meaning of the word liberalism began to diverge in different parts of the world. According to the Encyclopædia Britannica: ""In the United States, liberalism is associated with the welfare-state policies of the New Deal programme of the Democratic administration of Pres. Franklin D. Roosevelt, whereas in Europe it is more commonly associated with a commitment to limited government and laissez-faire economic policies"".[28] Consequently, in the United States the ideas of individualism and laissez-faire economics previously associated with classical liberalism became the basis for the emerging school of libertarian thought[29][better source needed] and are key components of American conservatism.
",2
1897,"Unlike Europe and Latin America, the word liberalism in North America almost exclusively refers to social liberalism. The dominant Canadian party is the Liberal Party and the Democratic Party is usually considered liberal in the United States.[30][31][32]
",2
1898,"Liberalism—both as a political current and an intellectual tradition—is mostly a modern phenomenon that started in the 17th century, although some liberal philosophical ideas had precursors in classical antiquity and in Imperial China.[33][34] The Roman Emperor Marcus Aurelius praised, ""the idea of a polity administered with regard to equal rights and equal freedom of speech, and the idea of a kingly government which respects most of all the freedom of the governed"".[35] Scholars have also recognised a number of principles familiar to contemporary liberals in the works of several Sophists and in the Funeral Oration by Pericles.[36] Liberal philosophy symbolises an extensive intellectual tradition that has examined and popularised some of the most important and controversial principles of the modern world. Its immense scholarly and academic output has been characterised as containing ""richness and diversity"", but that diversity often has meant that liberalism comes in different formulations and presents a challenge to anyone looking for a clear definition.[37]
",2
1899,"Continental European liberalism is divided between moderates and progressives, with the moderates tending to elitism and the progressives supporting the universalisation of fundamental institutions such as universal suffrage, universal education and the expansion of property rights. Over time, the moderates displaced the progressives as the main guardians of continental European liberalism.[16]
",2
1900,"Although all liberal doctrines possess a common heritage, scholars frequently assume that those doctrines contain ""separate and often contradictory streams of thought"".[37] The objectives of liberal theorists and philosophers have differed across various times, cultures and continents. The diversity of liberalism can be gleaned from the numerous qualifiers that liberal thinkers and movements have attached to the very term ""liberalism"", including classical, egalitarian, economic, social, welfare state, ethical, humanist, deontological, perfectionist, democratic and institutional,  to name a few.[38] Despite these variations, liberal thought does exhibit a few definite and fundamental conceptions. At its very root, liberalism is a philosophy about the meaning of humanity and society.[citation needed]
",2
1901,"Political philosopher John Gray identified the common strands in liberal thought as being individualist, egalitarian, meliorist and universalist. The individualist element avers the ethical primacy of the human being against the pressures of social collectivism, the egalitarian element assigns the same moral worth and status to all individuals, the meliorist element asserts that successive generations can improve their sociopolitical arrangements and the universalist element affirms the moral unity of the human species and marginalises local cultural differences.[39] The meliorist element has been the subject of much controversy, defended by thinkers such as Immanuel Kant who believed in human progress while suffering criticism by thinkers such as Jean-Jacques Rousseau, who instead believed that human attempts to improve themselves through social cooperation would fail.[40] Describing the liberal temperament, Gray claimed that it ""has been inspired by scepticism and by a fideistic certainty of divine revelation [...] it has exalted the power of reason even as, in other contexts, it has sought to humble reason's claims"".[citation needed]
",2
1902,"The liberal philosophical tradition has searched for validation and justification through several intellectual projects. The moral and political suppositions of liberalism have been based on traditions such as natural rights and utilitarian theory, although sometimes liberals even requested support from scientific and religious circles.[39] Through all these strands and traditions, scholars have identified the following major common facets of liberal thought: believing in equality and individual liberty, supporting private property and individual rights, supporting the idea of limited constitutional government, and recognising the importance of related values such as pluralism, toleration, autonomy, bodily integrity and consent.[41]
",2
1903,"Enlightenment philosophers are given credit for shaping liberal ideas. These ideas were first drawn together and systematized as a distinct ideology by the English philosopher John Locke, generally regarded as the father of modern liberalism.[42][43] Thomas Hobbes attempted to determine the purpose and the justification of governing authority in a post-civil war England. Employing the idea of a state of nature — a hypothetical war-like scenario prior to the state — he constructed the idea of a social contract that individuals enter into to guarantee their security and in so doing form the State, concluding that only an absolute sovereign would be fully able to sustain such a peace. Hobbes had developed the concept of the social contract, according to which individuals in the anarchic and brutal state of nature came together and voluntarily ceded some of their individual rights to an established state authority, which would create laws to regulate social interactions to mitigate or mediate conflicts and enforce justice. Whereas Hobbes advocated a strong monarchical commonwealth (the Leviathan), Locke developed the then radical notion that government acquires consent from the governed which has to be constantly present for the government to remain legitimate.[44] While adopting Hobbes's idea of a state of nature and social contract, Locke nevertheless argued that when the monarch becomes a tyrant, it constituted a violation of the social contract, which protects life, liberty and property as a natural right. He concluded that the people have a right to overthrow a tyrant. By placing life, liberty and property as the supreme value of law and authority, Locke formulated the basis of liberalism based on social contract theory. To these early enlightenment thinkers, securing the most essential amenities of life—liberty and private property among them—required the formation of a ""sovereign"" authority with universal jurisdiction.[45]
",2
1904,"His influential Two Treatises (1690), the foundational text of liberal ideology, outlined his major ideas. Once humans moved out of their natural state and formed societies, Locke argued as follows: ""Thus that which begins and actually constitutes any political society is nothing but the consent of any number of freemen capable of a majority to unite and incorporate into such a society. And this is that, and that only, which did or could give beginning to any lawful government in the world"".[46] The stringent insistence that lawful government did not have a supernatural basis was a sharp break with the dominant theories of governance which advocated the divine right of kings[47] and echoed the earlier thought of Aristotle. One political scientist described this new thinking as follows: ""In the liberal understanding, there are no citizens within the regime who can claim to rule by natural or supernatural right, without the consent of the governed"".[48]
",2
1905,"Locke had other intellectual opponents besides Hobbes. In the First Treatise, Locke aimed his arguments first and foremost at one of the doyens of 17th century English conservative philosophy: Robert Filmer. Filmer's Patriarcha (1680) argued for the divine right of kings by appealing to biblical teaching, claiming that the authority granted to Adam by God gave successors of Adam in the male line of descent a right of dominion over all other humans and creatures in the world.[49] However, Locke disagreed so thoroughly and obsessively with Filmer that the First Treatise is almost a sentence-by-sentence refutation of Patriarcha. Reinforcing his respect for consensus, Locke argued that ""conjugal society is made up by a voluntary compact between men and women"".[50] Locke maintained that the grant of dominion in Genesis was not to men over women, as Filmer believed, but to humans over animals.[50] Locke was certainly no feminist by modern standards, but the first major liberal thinker in history accomplished an equally major task on the road to making the world more pluralistic: the integration of women into social theory.[50]
",2
1906,"Locke also originated the concept of the separation of church and state.[51] Based on the social contract principle, Locke argued that the government lacked authority in the realm of individual conscience, as this was something rational people could not cede to the government for it or others to control. For Locke, this created a natural right in the liberty of conscience, which he argued must therefore remain protected from any government authority.[52] He also formulated a general defence for religious toleration in his Letters Concerning Toleration. Three arguments are central: (1) earthly judges, the state in particular, and human beings generally, cannot dependably evaluate the truth-claims of competing religious standpoints; (2) even if they could, enforcing a single ""true religion"" would not have the desired effect because belief cannot be compelled by violence; (3) coercing religious uniformity would lead to more social disorder than allowing diversity.[53]
",2
1907,"Locke was also influenced by the liberal ideas of Presbyterian politician and poet John Milton, who was a staunch advocate of freedom in all its forms.[54] Milton argued for disestablishment as the only effective way of achieving broad toleration. Rather than force a man's conscience, government should recognise the persuasive force of the gospel.[55] As assistant to Oliver Cromwell, Milton also took part in drafting a constitution of the independents (Agreement of the People; 1647) that strongly stressed the equality of all humans as a consequence of democratic tendencies.[56] In his Areopagitica, Milton provided one of the first arguments for the importance of freedom of speech—""the liberty to know, to utter, and to argue freely according to conscience, above all liberties"". His central argument was that the individual is capable of using reason to distinguish right from wrong. To be able to exercise this right, everyone must have unlimited access to the ideas of his fellow men in ""a free and open encounter"" and this will allow the good arguments to prevail.
",2
1908,"In a natural state of affairs, liberals argued, humans were driven by the instincts of survival and self-preservation and the only way to escape from such a dangerous existence was to form a common and supreme power capable of arbitrating between competing human desires.[57] This power could be formed in the framework of a civil society that allows individuals to make a voluntary social contract with the sovereign authority, transferring their natural rights to that authority in return for the protection of life, liberty and property.[57] These early liberals often disagreed about the most appropriate form of government, but they all shared the belief that liberty was natural and that its restriction needed strong justification.[57] Liberals generally believed in limited government, although several liberal philosophers decried government outright, with Thomas Paine writing ""government even in its best state is a necessary evil"".[58]
",2
1909,"As part of the project to limit the powers of government, liberal theorists such as James Madison and Montesquieu conceived the notion of separation of powers, a system designed to equally distribute governmental authority among the executive, legislative and judicial branches.[58] Governments had to realise, liberals maintained, that poor and improper governance gave the people authority to overthrow the ruling order through any and all possible means, even through outright violence and revolution, if needed.[59] Contemporary liberals, heavily influenced by social liberalism, have continued to support limited constitutional government while also advocating for state services and provisions to ensure equal rights. Modern liberals claim that formal or official guarantees of individual rights are irrelevant when individuals lack the material means to benefit from those rights and call for a greater role for government in the administration of economic affairs.[60] Early liberals also laid the groundwork for the separation of church and state. As heirs of the Enlightenment, liberals believed that any given social and political order emanated from human interactions, not from divine will.[61] Many liberals were openly hostile to religious belief itself, but most concentrated their opposition to the union of religious and political authority, arguing that faith could prosper on its own, without official sponsorship or administration by the state.[61]
",2
1910,"Beyond identifying a clear role for government in modern society, liberals also have argued over the meaning and nature of the most important principle in liberal philosophy, namely liberty. From the 17th century until the 19th century, liberals (from Adam Smith to John Stuart Mill) conceptualised liberty as the absence of interference from government and from other individuals, claiming that all people should have the freedom to develop their own unique abilities and capacities without being sabotaged by others.[62] Mill's On Liberty (1859), one of the classic texts in liberal philosophy, proclaimed, ""the only freedom which deserves the name, is that of pursuing our own good in our own way"".[62] Support for laissez-faire capitalism is often associated with this principle, with Friedrich Hayek arguing in The Road to Serfdom (1944) that reliance on free markets would preclude totalitarian control by the state.[63]
",2
1911,"The development into maturity of modern classical in contrast to ancient liberalism took place before and soon after the French Revolution. One of the historic centres of this development was at Coppet Castle near Geneva where the eponymous Coppet group gathered under the aegis of the exiled writer and salonnière, Madame de Staël in the period between the establishment of Napoleon's First Empire (1804) and the Bourbon Restoration of 1814–1815.[64][65][66][67] The unprecedented concentration of European thinkers who met there were to have a considerable influence on the development of nineteenth century liberalism and incidentally of romanticism.[68][69][70] They included Wilhelm von Humboldt, Jean de Sismondi, Charles Victor de Bonstetten, Prosper de Barante, Henry Brougham, Lord Byron, Alphonse de Lamartine, Sir James Mackintosh, Juliette Récamier and August Wilhelm Schlegel.[71]
",2
1912,"Among them was also one of the first thinkers to go by the name of ""liberal"", the Edinburgh University educated Swiss Protestant, Benjamin Constant, who looked to the United Kingdom rather than to ancient Rome for a practical model of freedom in a large mercantile society. He drew a distinction between the ""Liberty of the Ancients"" and the ""Liberty of the Moderns"".[72] The Liberty of the Ancients was a participatory republican liberty, which gave the citizens the right to influence politics directly through debates and votes in the public assembly.[72]  In order to support this degree of participation, citizenship was a burdensome moral obligation requiring a considerable investment of time and energy. Generally, this required a sub-group of slaves to do much of the productive work, leaving citizens free to deliberate on public affairs. Ancient Liberty was also limited to relatively small and homogenous male societies, in which they could congregate in one place to transact public affairs.[72]
",2
1913,"The Liberty of the Moderns, in contrast, was based on the possession of civil liberties, the rule of law, and freedom from excessive state interference. Direct participation would be limited: a necessary consequence of the size of modern states, and also the inevitable result of having created a mercantile society in which there were no slaves but almost everybody had to earn a living through work. Instead, the voters would elect representatives, who would deliberate in Parliament on behalf of the people and would save citizens from daily political involvement.[72] The importance of Constant's writings on the liberty of the ancients and that of the ""moderns"" has informed understanding of liberalism, as has his critique of the French Revolution.[73] The British philosopher and historian of ideas, Sir Isaiah Berlin has pointed to the debt owed to Constant.[74]
",2
1914,"Liberalism in Britain was based on core concepts such as classical economics, free trade, laissez-faire government with minimal intervention and taxation and a balanced budget. Classical liberals were committed to individualism, liberty and equal rights. Writers such as John Bright and Richard Cobden opposed both aristocratic privilege and property, which they saw as an impediment to the development of a class of yeoman farmers.[75]
",2
1915,"
Beginning in the late 19th century, a new conception of liberty entered the liberal intellectual arena. This new kind of liberty became known as positive liberty to distinguish it from the prior negative version and it was first developed by British philosopher Thomas Hill Green. Green rejected the idea that humans were driven solely by self-interest, emphasising instead the complex circumstances that are involved in the evolution of our moral character.[76] In a very profound step for the future of modern liberalism, he also tasked society and political institutions with the enhancement of individual freedom and identity and the development of moral character, will and reason and the state to create the conditions that allow for the above, giving the opportunity for genuine choice.[76] Foreshadowing the new liberty as the freedom to act rather than to avoid suffering from the acts of others, Green wrote the following: .mw-parser-output .templatequote{overflow:hidden;margin:1em 0;padding:0 40px}.mw-parser-output .templatequote .templatequotecite{line-height:1.5em;text-align:left;padding-left:1.6em;margin-top:0}",2
1916,If it were ever reasonable to wish that the usage of words had been other than it has been [...] one might be inclined to wish that the term 'freedom' had been confined to the [...] power to do what one wills.[77],2
1917,"Rather than previous liberal conceptions viewing society as populated by selfish individuals, Green viewed society as an organic whole in which all individuals have a duty to promote the common good.[78] His ideas spread rapidly and were developed by other thinkers such as Leonard Trelawny Hobhouse and John A. Hobson. In a few years, this New Liberalism had become the essential social and political programme of the Liberal Party in Britain[79] and it would encircle much of the world in the 20th century. In addition to examining negative and positive liberty, liberals have tried to understand the proper relationship between liberty and democracy. As they struggled to expand suffrage rights, liberals increasingly understood that people left out of the democratic decision-making process were liable to the ""tyranny of the majority"", a concept explained in Mill's On Liberty and in Democracy in America (1835) by Alexis de Tocqueville.[80] As a response, liberals began demanding proper safeguards to thwart majorities in their attempts at suppressing the rights of minorities.[80]
",2
1918,"Besides liberty, liberals have developed several other principles important to the construction of their philosophical structure, such as equality, pluralism and toleration. Highlighting the confusion over the first principle, Voltaire commented that ""equality is at once the most natural and at times the most chimeral of things"".[81] All forms of liberalism assume in some basic sense that individuals are equal.[82] In maintaining that people are naturally equal, liberals assume that they all possess the same right to liberty.[83] In other words, no one is inherently entitled to enjoy the benefits of liberal society more than anyone else and all people are equal subjects before the law.[84] Beyond this basic conception, liberal theorists diverge on their understanding of equality. American philosopher John Rawls emphasised the need to ensure not only equality under the law, but also the equal distribution of material resources that individuals required to develop their aspirations in life.[84] Libertarian thinker Robert Nozick disagreed with Rawls, championing the former version of Lockean equality instead.[84]
",2
1919,"To contribute to the development of liberty, liberals also have promoted concepts like pluralism and toleration. By pluralism, liberals refer to the proliferation of opinions and beliefs that characterise a stable social order.[85] Unlike many of their competitors and predecessors, liberals do not seek conformity and homogeneity in the way that people think. In fact, their efforts have been geared towards establishing a governing framework that harmonises and minimises conflicting views, but still allows those views to exist and flourish.[86] For liberal philosophy, pluralism leads easily to toleration. Since individuals will hold diverging viewpoints, liberals argue, they ought to uphold and respect the right of one another to disagree.[87] From the liberal perspective, toleration was initially connected to religious toleration, with Baruch Spinoza condemning ""the stupidity of religious persecution and ideological wars"".[87] Toleration also played a central role in the ideas of Kant and John Stuart Mill. Both thinkers believed that society will contain different conceptions of a good ethical life and that people should be allowed to make their own choices without interference from the state or other individuals.[87]
",2
1920,"Adam Smith's The Wealth of Nations, published in 1776, followed by the French liberal economist, Jean-Baptiste Say's treatise on Political Economy published in 1803 and expanded in 1830 with practical applications, were to provide most of the ideas of economics until the publication of John Stuart Mill's Principles in 1848.[88] Smith addressed the motivation for economic activity, the causes of prices and the distribution of wealth and the policies the state should follow in order to maximise wealth.[89]
",2
1921,"Smith wrote that as long as supply, demand, prices and competition were left free of government regulation, the pursuit of material self-interest, rather than altruism, would maximise the wealth of a society[90] through profit-driven production of goods and services. An ""invisible hand"" directed individuals and firms to work toward the nation's good as an unintended consequence of efforts to maximise their own gain. This provided a moral justification for the accumulation of wealth, which had previously been viewed by some as sinful.[89]
",2
1922,"Smith assumed that workers could be paid as low as was necessary for their survival, which was later transformed by David Ricardo and Thomas Robert Malthus into the ""iron law of wages"".[91] His main emphasis was on the benefit of free internal and international trade, which he thought could increase wealth through specialisation in production.[92] He also opposed restrictive trade preferences, state grants of monopolies and employers' organisations and trade unions.[93] Government should be limited to defence, public works and the administration of justice, financed by taxes based on income.[94] Smith was one of the progenitors of the idea, which was long central to classical liberalism and has resurfaced in the globalisation literature of the later 20th and early 21st centuries, that free trade promotes peace.[95] Smith's economics was carried into practice in the 19th century with the lowering of tariffs in the 1820s, the repeal of the Poor Relief Act that had restricted the mobility of labour in 1834 and the end of the rule of the East India Company over India in 1858.[96]
",2
1923,"In his Treatise (Traité d'économie politique), Say states that any production process requires effort, knowledge and the ""application"" of the entrepreneur. He sees entrepreneurs as intermediaries in the production process who combine productive factors such as land, capital and labour to meet the demand of consumers. As a result, they play a central role in the economy through their coordinating function. He also highlights qualities essential for successful entrepreneurship and focuses on judgement, in that they have continuously to assess market needs and the means to meet them. This requires an ""unerring market sense"". Say views entrepreneurial income primarily as the high revenue paid in compensation for their skills and expert knowledge. He does so by contrasting the enterprise function and the supply-of-capital-function which distinguishes the earnings of the entrepreneur on one hand and the remuneration of capital on the other. This clearly differentiates his theory from that of Joseph Schumpeter, who describes entrepreneurial rent as short-term profits which compensate for high risk (Schumpeterian rent). Say himself does also refer to risk and uncertainty along with innovation, without analysing them in detail.
",2
1924,"Say is also credited with Say's law, or the law of markets which may be summarised as: ""Aggregate supply creates its own aggregate demand"",
and ""Supply creates its own demand"" or ""Supply constitutes its own demand"" and ""Inherent in supply is the need for its own consumption"". The related phrase ""supply creates its own demand"" was actually coined by John Maynard Keynes, who criticized Say's separate formulations as amounting to the same thing. Some advocates of Say's law who disagree with Keynes, have claimed that Say's law can actually be summarized more accurately as ""production precedes consumption"" and that what Say is actually stating, is that for consumption to happen one must produce something of value so that it can be traded for money or barter for consumption later.[97][98]
Say argues, ""products are paid for with products"" (1803, p. 153) or ""a glut occurs only when too much resource is applied to making one product and not enough to another"" (1803, pp. 178–179).[99]
",2
1925,"Related reasoning appears in the work of John Stuart Mill and earlier in that of his Scottish classical economist father James Mill (1808). Mill senior restates Say's law in 1808, writing: ""production of commodities creates, and is the one and universal cause which creates a market for the commodities produced"".[100]
",2
1926,"In addition to Smith's and Say's legacies, Thomas Malthus' theories of population and David Ricardo Iron law of wages became central doctrines of classical economics.[101] Meanwhile, Jean-Baptiste Say challenged Smith's labour theory of value, believing that prices were determined by utility and also emphasised the critical role of the entrepreneur in the economy. However, neither of those observations became accepted by British economists at the time. Malthus wrote An Essay on the Principle of Population in 1798,[102] becoming a major influence on classical liberalism. Malthus claimed that population growth would outstrip food production because population grew geometrically while food production grew arithmetically. As people were provided with food, they would reproduce until their growth outstripped the food supply. Nature would then provide a check to growth in the forms of vice and misery. No gains in income could prevent this and any welfare for the poor would be self-defeating. The poor were in fact responsible for their own problems which could have been avoided through self-restraint.[103]
",2
1927,"Several liberals, including Adam Smith and Richard Cobden, argued that the free exchange of goods between nations would lead to world peace.[104] Smith argued that as societies progressed the spoils of war would rise, but the costs of war would rise further, making war difficult and costly for industrialised nations.[105] Cobden believed that military expenditures worsened the welfare of the state and benefited a small but concentrated elite minority, summing up British imperialism, which he believed was the result of the economic restrictions of mercantilist policies. To Cobden and many classical liberals, those who advocated peace must also advocate free markets.
",2
1928,"Utilitarianism was seen as a political justification for the implementation of economic liberalism by British governments, an idea dominating economic policy from the 1840s. Although utilitarianism prompted legislative and administrative reform and John Stuart Mill's later writings on the subject foreshadowed the welfare state, it was mainly used as a premise for a laissez-faire approach.[106] The central concept of utilitarianism, which was developed by Jeremy Bentham, was that public policy should seek to provide ""the greatest happiness of the greatest number"". While this could be interpreted as a justification for state action to reduce poverty, it was used by classical liberals to justify inaction with the argument that the net benefit to all individuals would be higher.[101] His philosophy proved to be extremely influential on government policy and led to increased Benthamite attempts at government social control, including Robert Peel's Metropolitan Police, prison reforms, the workhouses and asylums for the mentally ill.
",2
1929,"During the Great Depression, the definitive liberal response to the economic crisis was given by the English economist John Maynard Keynes (1883–1946). Keynes had been ""brought up"" as a classical liberal, but especially after World War I became increasingly a welfare or social liberal.[107] A prolific writer, among many other works, he had begun a theoretical work examining the relationship between unemployment, money and prices back in the 1920s.[108]  Keynes was deeply critical of the British government's austerity measures during the Great Depression. He believed that budget deficits were a good thing, a product of recessions. He wrote: ""For Government borrowing of one kind or another is nature's remedy, so to speak, for preventing business losses from being, in so severe a slump as the present one, so great as to bring production altogether to a standstill"".[109] At the height of the Great Depression in 1933, Keynes published The Means to Prosperity, which contained specific policy recommendations for tackling unemployment in a global recession, chiefly counter cyclical public spending. The Means to Prosperity contains one of the first mentions of the multiplier effect.[110]
",2
1930,"Keynes's magnum opus, The General Theory of Employment, Interest and Money, was published in 1936[111] and served as a theoretical justification for the interventionist policies Keynes favoured for tackling a recession. The General Theory challenged the earlier neo-classical economic paradigm, which had held that provided it was unfettered by government interference, the market would naturally establish full employment equilibrium. Classical economists had believed in Say's law, which simply put states that ""supply creates its own demand"" and that in a free market workers would always be willing to lower their wages to a level where employers could profitably offer them jobs. An innovation from Keynes was the concept of price stickiness, i.e. the recognition that in reality workers often refuse to lower their wage demands even in cases where a classical economist might argue it is rational for them to do so. Due in part to price stickiness, it was established that the interaction of ""aggregate demand"" and ""aggregate supply"" may lead to stable unemployment equilibria and in those cases it is the state and not the market that economies must depend on for their salvation. The book advocated activist economic policy by government to stimulate demand in times of high unemployment, for example by spending on public works. In 1928, he wrote: ""Let us be up and doing, using our idle resources to increase our wealth. [...] With men and plants unemployed, it is ridiculous to say that we cannot afford these new developments. It is precisely with these plants and these men that we shall afford them"".[109] Where the market failed to properly allocate resources, the government was required to stimulate the economy until private funds could start flowing again—a ""prime the pump"" kind of strategy designed to boost industrial production.[112]
",2
1931,"Liberal feminism, the dominant tradition in feminist history, is an individualistic form of feminist theory which focuses on women's ability to maintain their equality through their own actions and choices. Liberal feminists hope to eradicate all barriers to gender equality, claiming that the continued existence of such barriers eviscerates the individual rights and freedoms ostensibly guaranteed by a liberal social order.[113] They argue that society holds the false belief that women are by nature less intellectually and physically capable than men; thus it tends to discriminate against women in the academy, the forum and the marketplace. Liberal feminists believe that ""female subordination is rooted in a set of customary and legal constraints that blocks women's entrance to and success in the so-called public world"". They strive for sexual equality via political and legal reform.[114]
",2
1932,"British philosopher Mary Wollstonecraft (1759–1797) is widely regarded as the pioneer of liberal feminism, with A Vindication of the Rights of Woman (1792) expanding the boundaries of liberalism to include women in the political structure of liberal society.[115] In her writings such as A Vindication of the Rights of Woman, Wollstonecraft commented on society's view of the woman and encouraged women to use their voices in making decisions separate from decisions previously made for them. Wollstonecraft ""denied that women are, by nature, more pleasure seeking and pleasure giving than men. She reasoned that if they were confined to the same cages that trap women, men would develop the same flawed characters. What Wollstonecraft most wanted for women was personhood"".[114]
",2
1933,"John Stuart Mill was also an early proponent of feminism. In his article The Subjection of Women (1861, published 1869), Mill attempted to prove that the legal subjugation of women is wrong and that it should give way to perfect equality.[116][117] He believed that both sexes should have equal rights under the law and that ""until conditions of equality exist, no one can possibly assess the natural differences between women and men, distorted as they have been. What is natural to the two sexes can only be found out by allowing both to develop and use their faculties freely"".[118] Mill frequently spoke of this imbalance and wondered if women were able to feel the same ""genuine unselfishness"" that men did in providing for their families. This unselfishness Mill advocated is the one ""that motivates people to take into account the good of society as well as the good of the individual person or small family unit"".[114] Similar to Mary Wollstonecraft, Mill compared sexual inequality to slavery, arguing that their husbands are often just as abusive as masters and that a human being controls nearly every aspect of life for another human being. In his book The Subjection of Women, Mill argues that three major parts of women's lives are hindering them: society and gender construction, education and marriage.[119]
",2
1934,"Equity feminism is a form of liberal feminism discussed since the 1980s,[120][121] specifically a kind of classically liberal or libertarian feminism.[122] Steven Pinker, an evolutionary psychologist, defines equity feminism as ""a moral doctrine about equal treatment that makes no commitments regarding open empirical issues in psychology or biology"".[123] Barry Kuhle asserts that equity feminism is compatible with evolutionary psychology in contrast to gender feminism.[124]
",2
1935,"Jean Charles Léonard Simonde de Sismondi's Nouveaux principes d'économie politique, ou de la richesse dans ses rapports avec la population (1819) represents the first comprehensive liberal critique of early capitalism and laissez-faire economics, and his writings, which were studied by John Stuart Mill and Karl Marx among many others, had a profound influence on both liberal and socialist responses to the failures and contradictions of industrial society.[125][126][127] By the end of the 19th century, the principles of classical liberalism were being increasingly challenged by downturns in economic growth, a growing perception of the evils of poverty, unemployment and relative deprivation present within modern industrial cities as well as the agitation of organised labour. The ideal of the self-made individual, who through hard work and talent could make his or her place in the world, seemed increasingly implausible. A major political reaction against the changes introduced by industrialisation and laissez-faire capitalism came from conservatives concerned about social balance, although socialism later became a more important force for change and reform. Some Victorian writers, including Charles Dickens, Thomas Carlyle and Matthew Arnold, became early influential critics of social injustice.[128]
",2
1936,"New liberals began to adapt the old language of liberalism to confront these difficult circumstances, which they believed could only be resolved through a broader and more interventionist conception of the state. An equal right to liberty could not be established merely by ensuring that individuals did not physically interfere with each other, or merely by having laws that were impartially formulated and applied. More positive and proactive measures were required to ensure that every individual would have an equal opportunity of success.[129]
",2
1937,"John Stuart Mill contributed enormously to liberal thought by combining elements of classical liberalism with what eventually became known as the new liberalism. Mill's 1859 On Liberty addressed the nature and limits of the power that can be legitimately exercised by society over the individual.[130] He gave an impassioned defence of free speech, arguing that free discourse is a necessary condition for intellectual and social progress. Mill defined ""social liberty"" as protection from ""the tyranny of political rulers"". He introduced a number of different concepts of the form tyranny can take, referred to as social tyranny and tyranny of the majority, respectively. Social liberty meant limits on the ruler's power through obtaining recognition of political liberties or rights and by the establishment of a system of ""constitutional checks"".[131]
",2
1938,"His definition of liberty, influenced by Joseph Priestley and Josiah Warren, was that the individual ought to be free to do as he wishes unless he harms others.[132] However, although Mill's initial economic philosophy supported free markets and argued that progressive taxation penalised those who worked harder,[133] he later altered his views toward a more socialist bent, adding chapters to his Principles of Political Economy in defence of a socialist outlook and defending some socialist causes,[134] including the radical proposal that the whole wage system be abolished in favour of a co-operative wage system.
",2
1939,"Another early liberal convert to greater government intervention was Thomas Hill Green. Seeing the effects of alcohol, he believed that the state should foster and protect the social, political and economic environments in which individuals will have the best chance of acting according to their consciences. The state should intervene only where there is a clear, proven and strong tendency of a liberty to enslave the individual.[135] Green regarded the national state as legitimate only to the extent that it upholds a system of rights and obligations that is most likely to foster individual self-realisation.
",2
1940,"The New Liberalism or social liberalism movement emerged about 1900 in Britain.[136] The New Liberals, which included intellectuals like L. T. Hobhouse and John A. Hobson, saw individual liberty as something achievable only under favorable social and economic circumstances.[137] In their view, the poverty, squalor and ignorance in which many people lived made it impossible for freedom and individuality to flourish. New Liberals believed that these conditions could be ameliorated only through collective action coordinated by a strong, welfare-oriented and interventionist state.[138] It supports a mixed economy that includes both public and private property in capital goods.[139][140]
",2
1941,"Principles that can be described as social liberal have been based upon or developed by philosophers such as John Stuart Mill, Eduard Bernstein, John Dewey, Carlo Rosselli, Norberto Bobbio and Chantal Mouffe.[141] Other important social liberal figures include Guido Calogero, Piero Gobetti, Leonard Trelawny Hobhouse and R. H. Tawney.[142] Liberal socialism has been particularly prominent in British and Italian politics.[142]
",2
1942,"Classical liberalism advocates free trade under the rule of law. Anarcho-capitalism goes one step further, with law enforcement and the courts being provided by private companies. Various theorists have espoused legal philosophies similar to anarcho-capitalism. One of the first liberals to discuss the possibility of privatizing protection of individual liberty and property was France's Jakob Mauvillon in the 18th century. Later in the 1840s, Julius Faucher and Gustave de Molinari advocated the same. In his essay The Production of Security, Molinari argued: ""No government should have the right to prevent another government from going into competition with it, or to require consumers of security to come exclusively to it for this commodity"". Molinari and this new type of anti-state liberal grounded their reasoning on liberal ideals and classical economics. Historian and libertarian Ralph Raico argues that what these liberal philosophers ""had come up with was a form of individualist anarchism, or, as it would be called today, anarcho-capitalism or market anarchism"".[143] Unlike the liberalism of Locke, which saw the state as evolving from society, the anti-state liberals saw a fundamental conflict between the voluntary interactions of people, i.e. society; and the institutions of force, i.e. the state. This society versus state idea was expressed in various ways: natural society vs. artificial society, liberty vs. authority, society of contract vs. society of authority and industrial society vs. militant society, just to name a few.[144] The anti-state liberal tradition in Europe and the United States continued after Molinari in the early writings of Herbert Spencer as well as in thinkers such as Paul Émile de Puydt and Auberon Herbert. However, the first person to use the term anarcho-capitalism was Murray Rothbard, who in the mid-20th century synthesized elements from the Austrian School of economics, classical liberalism and 19th-century American individualist anarchists Lysander Spooner and Benjamin Tucker (while rejecting their labor theory of value and the norms they derived from it).[145] Anarcho-capitalism advocates the elimination of the state in favor of individual sovereignty, private property and free markets. Anarcho-capitalists believe that in the absence of statute (law by decree or legislation), society would improve itself through the discipline of the free market (or what its proponents describe as a ""voluntary society"").[146][147]
",2
1943,"In a theoretical anarcho-capitalist society, law enforcement, courts and all other security services would be operated by privately funded competitors rather than centrally through taxation. Money, along with all other goods and services, would be privately and competitively provided in an open market. Anarcho-capitalists say personal and economic activities under anarcho-capitalism would be regulated by victim-based dispute resolution organizations under tort and contract law, rather than by statute through centrally determined punishment under what they describe as ""political monopolies"".[148] A Rothbardian anarcho-capitalist society would operate under a mutually agreed-upon libertarian ""legal code which would be generally accepted, and which the courts would pledge themselves to follow"".[149] This pact would recognize self-ownership and the non-aggression principle (NAP), although methods of enforcement vary.
",2
1944,"Isolated strands of liberal thought had existed in Western philosophy since the Ancient Greeks and in Eastern philosophy since the Song and Ming period. These ideas were first drawn together and systematized as a distinct ideology, by the English philosopher John Locke, generally regarded as the father of modern liberalism.[42][43][34][33] The first major signs of liberal politics emerged in modern times. These ideas began to coalesce at the time of the English Civil Wars. The Levellers, a radical political movement, during the war called for freedom of religion, frequent convening of parliament and equality under the law. The impact of these ideas steadily increased during the 17th century in England, culminating in the Glorious Revolution of 1688, which enshrined parliamentary sovereignty and the right of revolution and led to the establishment of what many consider the first modern, liberal state.[150] The development of liberalism continued throughout the 18th century with the burgeoning Enlightenment ideals of the era. This was a period of profound intellectual vitality that questioned old traditions and influenced several European monarchies throughout the 18th century. Political tension between England and its American colonies grew after 1765 and the Seven Years' War over the issue of taxation without representation, culminating in the Declaration of Independence of a new republic, and the resulting American Revolutionary War to defend it. After the war, the leaders debated about how to move forward. The Articles of Confederation, written in 1776, now appeared inadequate to provide security, or even a functional government. The Confederation Congress called a Constitutional Convention in 1787, which resulted in the writing of a new Constitution of the United States establishing a federal government. In the context of the times, the Constitution was a republican and liberal document.[151][152] It remains the oldest liberal governing document in effect worldwide.
",2
1945,"In Europe, liberalism has a long tradition dating back to the 17th century.[153] The French Revolution began in 1789. The two key events that marked the triumph of liberalism were the abolition of feudalism in France on the night of 4 August 1789, which marked the collapse of feudal and old traditional rights and privileges and restrictions as well as the passage of the Declaration of the Rights of Man and of the Citizen in August.[154] During the Napoleonic Wars, the French brought to Western Europe the liquidation of the feudal system, the liberalization of property laws, the end of seigneurial dues, the abolition of guilds, the legalization of divorce, the disintegration of Jewish ghettos, the collapse of the Inquisition, the final end of the Holy Roman Empire, the elimination of church courts and religious authority, the establishment of the metric system and equality under the law for all men.[155] His most lasting achievement, the Civil Code, served as ""an object of emulation all over the globe"",[156] but it also perpetuated further discrimination against women under the banner of the ""natural order"".[157]
",2
1946,"The development into maturity of classical liberalism took place before and after the French Revolution in Britain.[75] Adam Smith's The Wealth of Nations, published in 1776, was to provide most of the ideas of economics at least until the publication of John Stuart Mill's Principles in 1848.[88] Smith addressed the motivation for economic activity, the causes of prices and the distribution of wealth and the policies the state should follow in order to maximise wealth.[89] The radical liberal movement began in the 1790s in England and concentrated on parliamentary and electoral reform, emphasizing natural rights and popular sovereignty. Radicals like Richard Price and Joseph Priestley saw parliamentary reform as a first step toward dealing with their many grievances, including the treatment of Protestant Dissenters, the slave trade, high prices and high taxes.[158]
",2
1947,"In Latin America, liberal unrest dates back to the 18th century, when liberal agitation in Latin America led to independence from the imperial power of Spain and Portugal. The new regimes were generally liberal in their political outlook and employed the philosophy of positivism, which emphasized the truth of modern science, to buttress their positions.[159] In the United States, a vicious war ensured the integrity of the nation and the abolition of slavery in the South. Historian Don Doyle has argued that the Union victory in the American Civil War (1861–1865) gave a major boost to the course of liberalism.[160]
",2
1948,"During 19th and early 20th century in the Ottoman Empire and Middle East, liberalism influenced periods of reform such as the Tanzimat and Al-Nahda; the rise of secularism, constitutionalism and nationalism; and different intellectuals and religious group and movements, like the Young Ottomans and Islamic Modernism. Prominent of the era were Rifa'a al-Tahtawi, Namık Kemal and İbrahim Şinasi. However, the reformist ideas and trends did not reach the common population successfully as the books, periodicals and newspapers were accessible primarily to intellectuals and segments of an emerging middle class while many Muslims saw them as foreign influences on the world of Islam. That perception complicated reformist efforts made by Middle Eastern states.[161][162] These changes, along with other factors, helped to create a sense of crisis within Islam, which continues to this day. This led to Islamic revivalism.[163]
",2
1949,"Abolitionist and suffrage movements spread, along with representative and democratic ideals. France established an enduring republic in the 1870s. However, nationalism also spread rapidly after 1815. A mixture of liberal and nationalist sentiment in Italy and Germany brought about the unification of the two countries in the late 19th century. A liberal regime came to power in Italy and ended the secular power of the Popes. However, the Vatican launched a counter crusade against liberalism. Pope Pius IX issued the Syllabus of Errors in 1864, condemning liberalism in all its forms. In many countries, liberal forces responded by expelling the Jesuit order. By the end of the nineteenth century, the principles of classical liberalism were being increasingly challenged and the ideal of the self-made individual seemed increasingly implausible. Victorian writers like Charles Dickens, Thomas Carlyle and Matthew Arnold were early influential critics of social injustice.[128]
",2
1950,"Liberalism gained momentum in the beginning of the 20th century. The bastion of autocracy, the Russian Tsar, was overthrown in the first phase of the Russian Revolution. The Allied victory in the First World War and the collapse of four empires seemed to mark the triumph of liberalism across the European continent, not just among the victorious allies, but also in Germany and the newly created states of Eastern Europe. Militarism, as typified by Germany, was defeated and discredited. As Blinkhorn argues, the liberal themes were ascendant in terms of ""cultural pluralism, religious and ethnic toleration, national self-determination, free market economics, representative and responsible government, free trade, unionism, and the peaceful settlement of international disputes through a new body, the League of Nations"".
",2
1951,"In the Middle East, liberalism led to constitutional periods, like the Ottoman First and Second Constitutional Era and the Persian constitutional period, but it declined in the late 1930s due to the growth and opposition of Islamism and pan-Arab nationalism.[166][167][168][169][163] However, there were various examples of intellectuals who advocated liberal values and ideas. Prominent liberals during the period were Taha Hussein, Ahmed Lutfi el-Sayed, Tawfiq al-Hakim, Abd El-Razzak El-Sanhuri and Muhammad Mandur.[170]
",2
1952,"In the United States, modern liberalism traces its history to the popular presidency of Franklin D. Roosevelt, who initiated the New Deal in response to the Great Depression and won an unprecedented four elections. The New Deal coalition established by Roosevelt left a decisive legacy and influenced many future American presidents, including John F. Kennedy.[171] Meanwhile, the definitive liberal response to the Great Depression was given by the British economist John Maynard Keynes, who had begun a theoretical work examining the relationship between unemployment, money and prices back in the 1920s.[172] The worldwide Great Depression, starting in 1929, hastened the discrediting of liberal economics and strengthened calls for state control over economic affairs. Economic woes prompted widespread unrest in the European political world, leading to the rise of fascism as an ideology and a movement arrayed against both liberalism and communism, especially in Nazi Germany and Italy.[173] The rise of fascism in the 1930s eventually culminated in World War II, the deadliest conflict in human history. The Allies prevailed in the war by 1945 and their victory set the stage for the Cold War between the Communist Eastern Bloc and the liberal Western Bloc.
",2
1953,"In Iran, liberalism enjoyed wide popularity. In April 1951, the National Front became the governing coalition when democratically elected Mohammad Mosaddegh, a liberal nationalist, took office as the Prime Minister. However, his way of governing entered in conflict with Western interest and he was removed from power in a coup on 19 August 1953. The coup ended the dominance of liberalism in the country's politics.[174][175][176][177][178]
",2
1954,"Among the various regional and national movements, the civil rights movement in the United States during the 1960s strongly highlighted the liberal efforts for equal rights.[179] The Great Society project launched by President Lyndon B. Johnson oversaw the creation of Medicare and Medicaid, the establishment of Head Start and the Job Corps as part of the War on Poverty and the passage of the landmark Civil Rights Act of 1964, an altogether rapid series of events that some historians have dubbed the ""Liberal Hour"".[180]
",2
1955,"The Cold War featured extensive ideological competition and several proxy wars, but the widely feared World War III between the Soviet Union and the United States never occurred. While communist states and liberal democracies competed against one another, an economic crisis in the 1970s inspired a move away from Keynesian economics, especially under Margaret Thatcher in the United Kingdom and Ronald Reagan in the United States. This trend, known as neoliberalism, constituted a paradigm shift away from the post-war Keynesian consensus which had lasted from 1945 to 1980.[181][182] Meanwhile, nearing the end of the 20th century, communist states in Eastern Europe collapsed precipitously, leaving liberal democracies as the only major forms of government in the West.
",2
1956,"At the beginning of World War II, the number of democracies around the world was about the same as it had been forty years before.[183] After 1945, liberal democracies spread very quickly, but then retreated. In The Spirit of Democracy, Larry Diamond argues that by 1974 ""dictatorship, not democracy, was the way of the world"" and that ""barely a quarter of independent states chose their governments through competitive, free, and fair elections"". Diamond goes on to say that democracy bounced back and by 1995 the world was ""predominantly democratic"".[184][185]
",2
1957,"Liberalism has drawn both criticism and support in its history from various ideological groups. Less friendly to the goals of liberalism has been conservatism. Edmund Burke, considered by some to be the first major proponent of modern conservative thought, offered a blistering critique of the French Revolution by assailing the liberal pretensions to the power of rationality and to the natural equality of all humans.[186]
",2
1958,"Some confusion remains about the relationship between social liberalism and socialism, despite the fact that many variants of socialism distinguish themselves markedly from liberalism by opposing capitalism, hierarchy and private property. Socialism formed as a group of related yet divergent ideologies in the 19th century such as Christian socialism, communism (with the writings of Karl Marx) and social anarchism (with the writings of Mikhail Bakunin), the latter two influenced by the Paris Commune. These ideologies—as with liberalism and conservatism—fractured into several major and minor movements in the following decades.[187] Marx rejected the foundational aspects of liberal theory, hoping to destroy both the state and the liberal distinction between society and the individual while fusing the two into a collective whole designed to overthrow the developing capitalist order of the 19th century.[188] Today, socialist parties and ideas remain a political force with varying degrees of power and influence on all continents leading national governments in many countries.
",2
1959,"Vladimir Lenin stated that—in contrast with Marxism—liberal science defends wage slavery.[189][190] However, some proponents of liberalism like George Henry Evans, Silvio Gesell and Thomas Paine were critics of wage slavery.[191][192] One of the most outspoken critics of liberalism was the Roman Catholic Church,[193] which resulted in lengthy power struggles between national governments and the Church. In the same vein, conservatives have also attacked what they perceive to be the reckless liberal pursuit of progress and material gains, arguing that such preoccupations undermine traditional social values rooted in community and continuity.[194] However, a few variations of conservatism, like liberal conservatism, expound some of the same ideas and principles championed by classical liberalism, including ""small government and thriving capitalism"".[186]
",2
1960,"Social democracy, an ideology advocating progressive modification of capitalism, emerged in the 20th century and was influenced by socialism. Broadly defined as a project that aims to correct through government reformism what it regards as the intrinsic defects of capitalism by reducing inequalities,[195] social democracy was also not against the state. Several commentators have noted strong similarities between social liberalism and social democracy, with one political scientist even calling American liberalism ""bootleg social democracy"" due to the absence of a significant social democratic tradition in the United States that liberals have tried to rectify.[196] Another movement associated with modern democracy, Christian democracy, hopes to spread Catholic social ideas and has gained a large following in some European nations.[197] The early roots of Christian democracy developed as a reaction against the industrialisation and urbanisation associated with laissez-faire liberalism in the 19th century.[198] Despite these complex relationships, some scholars have argued that liberalism actually ""rejects ideological thinking"" altogether, largely because such thinking could lead to unrealistic expectations for human society.[199]
",2
1961,"Fascists accuse liberalism of materialism and a lack of spiritual values.[200] In particular, fascism opposes liberalism for its materialism, rationalism, individualism and utilitarianism.[201] Fascists believe that the liberal emphasis on individual freedom produces national divisiveness,[200] but many fascists agree with liberals in their support of private property rights and a market economy.[201]
",2
1962,"Scholars have praised the influence of liberal internationalism, claiming that the rise of globalisation ""constitutes a triumph of the liberal vision that first appeared in the eighteenth century"" while also writing that liberalism is ""the only comprehensive and hopeful vision of world affairs"".[202]
",2
1963,"According to Russian President Vladimir Putin, as reported in the Financial Times, ""liberalism has become obsolete"".  He claims that the vast majority of people in the world oppose multiculturalism, immigration, and rights for people who are LGBT.[203]
",2
1964,"Notes
",2
1965,"Bibliography and further reading
",2
1966,"Peronism[a], also called justicialism[b], is an Argentine political movement based on the ideas and legacy of Argentine president Juan Perón (1895–1974).[1] It has been an influential movement in 20th and 21st century Argentine politics.[1] Since 1946, Peronists won 10 out of the 13 presidential elections in which they have been allowed to run.[2] The main Peronist party is the Justicialist Party.[2] The policies of Peronist presidents have differed greatly,[2] but the general ideology has been described as ""a vague blend of nationalism and labourism""[2] or populism.[1]
",2
1967,"Perón became Argentina's labour secretary after participating in the 1943 military coup and was elected president of Argentina in 1946.[1][3] He introduced social programs that benefited the working class,[4] supported labor unions and called for additional involvement of the state in the economy.[1] In addition, he helped industrialists.[2] Perón was hugely popular and gained even more admiration through his wife Eva, who championed for the rights of migrant workers and was beloved by the people.[5] Eva was so beloved that in 1949 Juan Perón formed the Female Peronist Party, a new wing within his own party under her leadership.[6] Due to rising inflation and other economic problems, the military overthrew Perón in 1955.[7] The Peronist party was banned[7] and it was not until 1973 that open elections were held again in which Perón was again elected president.[1]
",2
1968,"Perón died the next year; his widow and vice president Isabel took over the presidency.[1]  Perón's death left an intense power vacuum and the military promptly overthrew Isabel in 1976.[1] Following the return to democracy in 1983 Peronist candidates dominated the presidency. In 37 years of democracy, Peronists held the presidency for 24 years.
",2
1969,"Carlos Menem was elected in 1989 and served for two consecutive terms over ten years. His main focus was the privatization of state run enterprises,[2] the adoption of free-market policies[1] and good international relations with the United States.[2] After the De La Rúa administration collapsed, two interim Peronist leaders took over: Adolfo Rodríguez Saá and later Eduardo Duhalde. Néstor Kirchner, elected in 2003, served for only one term, while his wife, Cristina Fernández de Kirchner, served two (having been elected in 2007 and re-elected in 2011), and is, since 2019, the current vice president with Alberto Fernández as president.[1]
",2
1970,"The pillars of the Peronist ideal, known as the ""three flags"", are social justice, economic independence and political sovereignty. Peronism can be described as a third position ideology as it rejects both capitalism and communism. Peronism espouses corporatism and thus aims to mediate tensions between the classes of society, with the state responsible for negotiating compromise in conflicts between managers and workers.[citation needed]
",2
1971,"Peronism gained popularity in Argentina after the failure of its government to listen and recognize the needs of its middle class. As president of Argentina, Hipólito Yrigoyen did not listen to the workers pleas for better wages and better working conditions after World War I. Yrigoyen was notorious for failing to oppose Argentina’s oligarchy. According to Teresa Meade in A History of Modern Latin America: 1800 to the Present, Yrigoyen failed ""to establish a middle-class-based political system from 1916 to 1930 – mainly because his Radical Civic Union had neither the will nor the means to effectively oppose the dominance of the oligarchy"".[8] Many in power did not work to change the way things were. However, Juan Perón, at that time a military officer, used his experiences in Europe and his admiration for certain leaders like Mussolini to create a new political atmosphere that he felt would better the lives of citizens in Argentina.[9] Unlike Yrigoyen, Perón ""recognized that the industrial working class was not necessarily an impediment, and could be mobilized to serve as the basis for building a corporatist state that joined the interests of labor with those of at least a large section of the national bourgeoisie to promote a nationalist agenda"".[8]
",2
1972,"However, it is a generally ill-defined ideology as different and sometimes contradictory sentiments are expressed in the name of Peronism. The legacy and thought of Perón have transcended the confines of any single political party and bled into the broader political landscape of Argentina, therefore Peronists are usually described as a political movement. Traditionally, the Peronist movement has drawn its strongest support from the working class and sympathetic unions and has been characterized as proletarian in nature.[citation needed]
",2
1973,"From the perspective of opponents, Peronism is an authoritarian ideology. Perón was often compared to fascist dictators, accused of demagoguery and his policies derided as populist. Proclaiming himself the embodiment of nationality, Perón's government often silenced dissent by accusing opponents of being unpatriotic, especially noticeable in his second term from 1952 to 1955, where these policies were intensified as a form of control in the face of crisis. The corporatist character of Peronism drew attacks from socialists who accused his administration of preserving capitalist exploitation and class division. Conservatives rejected its modernist ideology and felt their status threatened by the ascent of the Peronist apparat. Liberals condemned the Perón regime's arbitrariness and dictatorial tendencies.[citation needed] The Economist has called Peronism ""an alliance between trade unions and the ""caudillos"" of the backward north"".[10]
",2
1974,"Chilean senator Ignacio Walker has criticized Peronism as having ""Fascistoid"", ""authoritarian"" and ""corporative"" traits and a ""perverse logic"" considering this ""the real wall between Chile and Argentina"" and ""not the Andes"".[11]
",2
1975,"Defenders of Peronism also describe the doctrine as populist, albeit in the sense that they believe it embodies the interests of the masses and in particular the most vulnerable social strata. Admirers hold Perón in esteem for his administration's anti-imperialism and non-alignment as well as its socially progressive initiatives. Amongst other measures introduced by Perón's governments, social security was made universal while education was made free to all who qualified and working students were given one paid week before every major examination. Vast low-income housing projects were created and paid vacations became standard. All workers (including white-collar employees) were guaranteed free medical care and half of their vacation-trip expenses and mothers-to-be received three paid months off prior to and after giving birth. Workers' recreation centers were also constructed throughout the country.[citation needed]
",2
1976,"From Peron's ""Peronist Philosophy"":[12]
",2
1977,"Perón's ideas were widely embraced by a variety of different groups in Argentina across the political spectrum. Some of Perón's personal views later became a burden on the ideology, such as his anti-clericalism, which did not strike a sympathetic chord with upper-class Argentinians.
",2
1978,"Peronism is widely regarded as a form of corporate socialism, or ""right-wing socialism"".[13] Perón's public speeches were consistently nationalist and populist. It would be difficult to separate Peronism from corporate nationalism, for Perón nationalized Argentina's large corporations, blurring distinctions between corporations and government. At the same time, the labor unions became corporate, ceding the right to strike in agreements with Perón as Secretary of Welfare in the military government from 1943–1945. In exchange, the state was to assume the role of negotiator between conflicting interests.
",2
1979,"Peronism also lacked a strong interest in matters of foreign policy other than the belief that the political and economic influences of other nations should be kept out of Argentina—he was somewhat isolationist. Early in his presidency, Perón envisioned Argentina's role as a model for other countries in Latin America and proposed economical unions with the countries of this region, which was expressed with his phrase: ""The 2000s will find us unionized or dominated"", but such ideas were ultimately abandoned. Despite his oppositional rhetoric, Perón frequently sought cooperation with the United States government on various issues.[citation needed][14]
",2
1980,"Political opponents maintain that Perón and his administration resorted to organised violence and dictatorial rule; that Perón showed contempt for any opponents, and regularly characterised them as traitors and agents of foreign powers. Perón subverted freedoms by nationalising the broadcasting system, centralising the unions under his control and monopolising the supply of newspaper print. At times, Perón also resorted to tactics such as illegally imprisoning opposition politicians and journalists, including Radical Civic Union leader Ricardo Balbin; and shutting down opposition papers, such as La Prensa.
",2
1981,"Perón's admiration for Benito Mussolini is well documented.[15] Many scholars categorise Peronism as a fascist ideology.[16] Carlos Fayt believed that Peronism was ""an Argentine implementation of Italian fascism"".[16] Hayes reaches the conclusion that ""the Peronist movement produced a form of fascism that was distinctively Latin American"".[16][17]
",2
1982,"
One of the most vocal critics of Peronism was the Argentine writer Jorge Luis Borges. After Perón ascended to the presidency in 1946, Borges spoke before the Argentine Society of Writers (SADE) by saying: ",2
1983,"Dictatorships breed oppression, dictatorships breed servility, dictatorships breed cruelty; more loathsome still is the fact that they breed idiocy. Bellboys babbling orders, portraits of caudillos, prearranged cheers or insults, walls covered with names, unanimous ceremonies, mere discipline usurping the place of clear thinking [...] Fighting these sad monotonies is one of the duties of a writer. Need I remind readers of Martín Fierro or Don Segundo that individualism is an old Argentine virtue.[18]",2
1984,"Argentina has had the largest Jewish population in Latin America since before Perón came to power. After becoming president, he invited members of the Jewish community to participate in his government. One of his advisors was José Ber Gelbard, a Jewish man from Poland. Peronism did not have an antisemitic bias.[19] The Jewish Virtual Library writes that while Juan Perón had sympathized with the Axis powers, ""Perón also expressed sympathy for Jewish rights and established diplomatic relations with Israel in 1949. Since then, more than 45,000 Jews have immigrated to Israel from Argentina"".[20]
",2
1985,"In the book Inside Argentina from Perón to Menem, author Laurence Levine, also former president of the U.S.–Argentine Chamber of Commerce, writes that ""although anti-Semitism existed in Argentina, Perón's own views and his political associations were not anti-Semitic"".[21] While Perón allowed many Nazi criminals to take refuge in Argentina, he also attracted many Jewish immigrants. Argentina has a Jewish population of over 200,000 citizens, one of the largest in the world.[22]
",2
1986,"A military and civilian coup, the Revolución Libertadora, led by General Eduardo Lonardi, overthrew the Perón regime in 1955. During the coup, Lonardi drew analogies between Perón and Juan Manuel de Rosas. Lonardi used the quote ""neither victors nor vanquished"" (Spanish: ni vencedores ni vencidos), which was used by Justo José de Urquiza after deposing Rosas in the battle of Caseros. The official perspective was that Perón was ""the second tyranny"", the first one being Rosas; and that both ones should be equally rejected and conversely both governments that ousted them should be praised. For this end, they draw the line of historical continuity ""May – Caseros – Libertadora"", matching the coup with the May Revolution and the defeat of Rosas. This approach backfired. Perón was highly popular and the military coup unpopular, so Peronists embraced the comparison established between Rosas and Perón, but viewing him with a positive light instead.[23] Nationalist historians draw then their own line of historical continuity ""San Martín – Rosas – Perón"".[24]
",2
1987,"The absence of Perón, who lived for 16 years in exile in Francoist Spain, is an important key to understanding Peronism. After he went into exile, he could be invoked by a variety of Argentine sectors opposed to the current state of affairs. In particular, the personality cult of Eva Perón was conserved by supporters while despised by the ""national bourgeoisie"". In the 1960s, John William Cooke's writings became an important source of left-wing revolutionary Peronism. Left-wing Peronism was represented by many organizations, from the Montoneros and the Fuerzas Armadas Peronistas to the Peronist Youth, the Frente Revolucionario Peronista and the Revolutionary Peronist Youth, passing by Peronismo en Lucha or Peronismo de Base.[25]
",2
1988,"On the other hand, older Peronists formed the base of the orthodox bureaucracy, represented by the Unión Obrera Metalúrgica (Augusto Vandor, famous for his 1965 slogan ""For a Peronism without Perón"" and declaring as well that ""to save Perón, one has to be against Perón"", or José Ignacio Rucci). Another current was formed by the ""62 Organizaciones 'De pie junto a Perón'"", led by José Alonso and opposed to the right-wing Peronist unionist movement. In the early 1970s, left-wing Peronism rejected liberal democracy and political pluralism as the mask of bourgeois domination. The anti-communist right-wing Peronism also rejected it in the name of corporatism, claiming to return to a ""Christian and humanist, popular, national socialism"".[25]
",2
1989,"By 1970, many groups from opposite sides of the political spectrum had come to support Perón, from the left-wing and Catholic Montoneros to the fascist-leaning and strongly antisemitic Tacuara Nationalist Movement, one of Argentina's first guerrilla movements. In March 1973, Héctor José Cámpora, who had been named as Perón's personal delegate, was elected President of Argentina, paving the way for the return of Perón from Spain. A few months after Perón's return and the subsequent Ezeiza massacre during which the Peronist Left and Right violently clashed, new elections were held in September with Perón elected president and his third wife Isabel vice president.[25]
",2
1990,"José Cámpora, a left-wing Peronist, had been replaced temporarily by interim President Raúl Alberto Lastiri while Perón had chosen to openly support the Peronist right. On 1 October 1973, Senator Humberto Martiarena, who was the national secretary of the Superior Council of the National Justicialist Movement, publicized a document giving directives to confront ""subversives, terrorist and Marxist groups"" which had allegedly initiated a ""war"" inside the Peronist organizations.[25] From then on, the Superior Council took a firm grip on the Peronist organizations to expel the Left from it.[25]
",2
1991,"On that same day, a meeting took place among President Raúl Lastiri, Interior Minister Benito Llambí, Social Welfare Minister José López Rega, general secretary of the Presidency José Humberto Martiarena and various provincial governors, which has been alleged to have been the foundational act of the Argentine Anticommunist Alliance death squad.[26]
",2
1992,"Perón's health was failing throughout his third and final term, which ended abruptly with his death and the succession of his wife to the presidency on 1 July 1974, but she was ousted by the military in another coup d'état in 1976, paving the way for the ensuing dictatorship's '""National Reorganization Process"" and the subsequent ""Dirty War"" against everyone deemed subversive, especially leftists, including left-wing Peronists.
",2
1993,"The official Peronist party is the Justicialist Party (PJ), which was the only Peronist party for a long time. During the government of Carlos Menem, a group of legislators led by Carlos Álvarez known as the ""Group of 8"" left the party, claiming that the government was not following Peronist doctrines. They created a new party, the Broad Front.
",2
1994,"A short time later, José Octavio Bordón left the PJ as well, fearing that he might lose a primary election against Menem and thus he created his own party to take part in the 1995 elections and allied with Álvarez' Broad Front in the Front for a Country in Solidarity (Frepaso) coalition. Similar breakaway movements followed frequently after that, creating many small parties which were led by single politicians claiming to be the authentic inheritors of Peronism.
",2
1995,"The PJ did not participate as such during the 2003 elections. The party allowed all three precandidates to run for the general elections, using small parties created for that purpose. Néstor Kirchner won the elections running on a Front for Victory ticket. As he did not disband his party after the election, Kirchnerism relies on both the PJ and the Front for Victory.
",2
1996,"A dictatorship is a form of government characterized by a single leader or group of leaders and little or no toleration for political pluralism or independent media.[2] According to other definitions, democracies are a form of government in which ""those who govern are selected through contested elections""; therefore, dictatorships are ""not democracies"".[2]
",2
1997,"With the advent of the 19th and 20th centuries, dictatorships and constitutional democracies emerged as the world's two major forms of government, gradually eliminating monarchies, one of the traditional widespread forms of government of the time. Typically, in a dictatorial regime, the leader of the country is identified with the title of dictator; although, their formal title may more closely resemble something similar to leader. A common aspect that characterized dictatorship is taking  advantage of their strong personality, usually by suppressing freedom of thought and speech of the masses, in order to maintain complete political and social supremacy and stability. Dictatorships and totalitarian societies generally employ political propaganda to decrease the influence of proponents of alternative governing systems.[3][4]
",2
1998,"The word dictator comes from the Latin language word dictātor, agent noun from dictare (dictāt-, past participial stem of dictāre dictate v. + -or -or suffix).[5] In Latin use, a dictator was a judge in the Roman Republic temporarily invested with absolute power.
",2
1999,"A dictatorship has been largely defined as a form of government in which absolute power is concentrated in the hands of a leader (commonly identified as a dictator), a ""small clique"", or a ""government organization"", and it aims to abolish political pluralism and civilian mobilization.[6] On the other hand, democracy, which is generally compared to the concept of dictatorship, is defined as a form of government in which power belongs to the population and rulers are elected through contested elections.[7][8]
",2
2000,"A newer form of government (originating around the early 20th century) commonly linked to the concept of dictatorship is known as totalitarianism. It is characterized by the presence of a single political party and more specifically, by a powerful leader (a real role model) who imposes his personal and political prominence. The two fundamental aspects that contribute to the maintenance of the power are a steadfast collaboration between the government and the police force, and a highly developed ideology. The government has ""total control of mass communications and social and economic organizations"".[9] According to Hannah Arendt, totalitarianism is a new and extreme form of dictatorship composed of ""atomized, isolated individuals"".[10] In addition, she affirmed that ideology plays a leading role in defining how the entire society should be organized. According to the political scientist Juan Linz, the distinction between an authoritarian regime and a totalitarian one is that while an authoritarian regime seeks suffocate politics and political mobilization, but totalitarianism seeks to control politics and political mobilization.[11]
",2
2001,"However, one of the most recent classification of dictatorships does not identify totalitarianism as a form of dictatorship. Barbara Geddes's study focuses in how elite-leader and elite-mass relations influence authoritarian politics. Her typology identifies the key institutions that structure elite politics in dictatorships (i.e. parties and militaries). The study is based on and directly related to some factors like the simplicity of the categorizations, cross-national applicability, the emphasis on elites and leaders, and the incorporation of institutions (parties and militaries) as central to shaping politics. According to her, a dictatorial government may be classified in five typologies: military dictatorships, single-party dictatorships, personalist dictatorships, monarchies, and hybrid dictatorships.[10]
",2
2002,"Military dictatorships are regimes in which a group of officers holds power, determines who will lead the country, and exercises influence over policy. High-level elites and a leader are the members of the military dictatorship. Military dictatorships are characterized by rule by a professionalized military as an institution. In military regimes, elites are referred to as junta members, who are typically senior officers (and often other high-level officers) in the military.[10][12] This type of dictatorship was imposed during the 20th century in countries such as,  Chile by Augusto Pinochet,  Argentina by Jorge Rafael Videla and other leaders,  Uruguay by Juan Maria Bordaberry,  Paraguay by Alfredo Stroessner, Bolivia by Hugo Banzer,  Brazil by Humberto de Alencar Castelo Branco. [13]
",2
2003,"Single-party dictatorships are regimes in which one party dominates politics. In single-party dictatorships, a single party has access to political posts and control over policy. In single-party dictatorships, party elites are typically members of the ruling body of the party, sometimes called the central committee, politburo, or secretariat. Those groups of individuals controls the selection of party officials and ""organizes the distribution of benefits to supporters and mobilizes citizens to vote and show support for party leaders"".[10]
",2
2004,"Current one-party states include China, Cuba, Eritrea, Laos, North Korea and Vietnam.
",2
2005,"Personalist dictatorships are regimes in which all power lies in the hands of a single individual. Personalist dictatorships differ from other forms of dictatorships in their access to key political positions, other fruits of office, and depend much more on the discretion of the personalist dictator. Personalist dictators may be members of the military or leaders of a political party. However, neither the military nor the party exercises power independently from the dictator. In personalist dictatorships, the elite corps are usually made up of close friends or family members of the dictator. These individuals are all typically handpicked to serve their posts by the dictator.[10][14]
",2
2006,"According to a 2019 study, personalist dictatorships are more repressive than other forms of dictatorship.[15]
",2
2007,"Monarchic dictatorships are in regimes in which ""a person of royal descent has inherited the position of head of state in accordance with accepted practice or constitution."" Regimes are not considered dictatorships if the monarch's role is largely ceremonial, but absolute monarchies, such as Saudi Arabia, can be considered hereditary dictatorships. Real political power must be exercised by the monarch for regimes to be classified as such. Elites in monarchies are typically members of the royal family.[10]
",2
2008,"Hybrid dictatorships are regimes that blend qualities of personalist, single-party, and military dictatorships. When regimes share characteristics of all three forms of dictatorships, they are referred to as triple threats. The most common forms of hybrid dictatorships are personalist/single-party hybrids and personalist/military hybrids.[10]
",2
2009,"One of the tasks in political science is to measure and classify regimes as either dictatorships or democracies. US based Freedom House, Polity IV and Democracy-Dictatorship Index are three of the most used data series by political scientists.[18]
",2
2010,"Generally, two research approaches exist: the minimalist approach, which focuses on whether a country has continued elections that are competitive, and the substantive approach, which expands the concept of democracy to include human rights, freedom of the press, and the rule of law. The Democracy-Dictatorship Index is seen as an example of the minimalist approach, whereas the Polity data series, is more substantive.[19][20][21][22]
",2
2011,"Between the two world wars, three types of dictatorships have been described: constitutional, counterrevolutionary and fascist. Since World War II, a broader range of dictatorships has been recognized, including Third World dictatorships, theocratic or religious dictatorships and dynastic or family-based dictatorships.[23]
",2
2012,"During the Republican phase of Ancient Rome, a Roman dictator was the special magistrate who held well defined powers, normally for six months at a time, usually in combination with a consulship.  Caesar Augustus Germanicus (Alias: Caligula) was the Roman dictator most cruel of the Roman Empire, ruled since 37 A.D. until 47 A.D. [24] [25] Roman dictators were allocated absolute power during times of emergency. In execution, their power was originally neither arbitrary nor unaccountable, being subject to law and requiring retrospective justification. There were no such dictatorships after the beginning of the 2nd century BC, and later dictators such as Sulla and the Roman emperors exercised power much more personally and arbitrarily. A concept that remained anathema to traditional Roman society, the institution was not carried forward into the Roman Empire.
",2
2013,"After the collapse of Spanish colonial rule, various dictators came to power in many liberated countries. Often leading a private army, these caudillos or self-appointed political-military leaders, attacked weak national governments once they controlled a region's political and economic powers, with examples such as Antonio López de Santa Anna in Mexico and Juan Manuel de Rosas in Argentina. Such dictatorships have been also referred to as ""personalismos"".
",2
2014,"The wave of military dictatorships in South America in the second half of the twentieth century left a particular mark on Latin American culture. In Latin American literature, the dictator novel challenging dictatorship and caudillismo is a significant genre. There are also many films depicting Latin American military dictatorships.
",2
2015,"In the first half of the 20th century, fascist dictatorships appeared in a variety of European countries at the same time as the rise of communism, which are distinct from dictatorships in Latin America and postcolonial dictatorships in Africa and Asia. The main examples of fascist dictatorship include:
",2
2016,"During the Cold War between the United States of America and the Union of Soviet Socialist Republics, several overthrows of socialist governments in South America were financed and supported by the States' Central Intelligence Agency. However, the States had previously made attempts to repress the communists, the ""National Security Doctrine"" that the States imposed since the 1950s to indoctrinate the soldiers of countries led by them to confront the alleged ""communist threat"".
",2
2017,"Paraguay under Alfredo Stroessner assumed power in the 1954 coup against President Federico Chávez,[13] which then followed by the Brazilian military dictatorship which seized power in 1964 coup and deposed President João Goulart.[33]
",2
2018,"In 1973, the Chilean military dictatorship under Augusto Pinochet seized power after a coup d'état that ended the three-year presidency and ultimately the life of socialist president Salvador Allende. On the same year the Uruguayan civic-military dictatorship seized power from President Jorge Pacheco Areco. Three years later, the Argentine military junta under Jorge Videla and later Leopoldo Galtieri deposed President Isabel Martínez de Perón.
",2
2019,"In 1971, Bolivian general Hugo Banzer deposed socialist president Juan José Torres, who would later be assassinated on Videla's Argentina. Banzer would democratically return to office in 1997. The Peruvian Military Junta in 1968 grabbed power from President Fernando Belaúnde Terry and replaced him with General Juan Velasco Alvarado before he himself was deposed by General Francisco Morales-Bermúdez.[34]
",2
2020,"In 1931 was organized a 1931 Coup d'état against the government of Arturo Araujo, starting the period known as Military Dictatorship of El Salvador from Civic Directory. The government committed several crimes against humanity, such as La Matanza ( The Massacre in english), a peasant uprising in which the military murdered between 10,000 to 40,000 peasants and civilians, the dictatorship ended in 1979.
",2
2021,"From 1942 to 1952 Rafael Leonidas Trujillo ruled Dominican Republic, repressing the Communists and their opponents.  Trujillo ordered the assassination of Romulo Betancourt, who was the founder of Democratic Action, but before he found out about this ambush, the plan of  Leonidas Trujillo failure. In October 1937 the Parsley massacre took place in which the main objective was to assassinate immigrants  Hatians residing in Dominican Republic, it is estimated that the dead during the massacre were 12,168 dead, by the president  Haitian Élie Lescot, 12,136 dead and 2419 injured by Jean Price-Mars, 17,000 dead by Joaquin Balaguer and 35,000 killed by Bernardo Vega. The  Dictatorship ended when  Trujillo was assassinated in 1961 in the city of Santo Domingo.
",2
2022,"On November 24, 1948  Venezuelan armed forces took power based on a  Coup d'état, overthrowing the government of Romulo Gallegos, who was a president of center left. Subsequently, a board composed of 3 generals was organized, one of them was Marcos Perez Jimenez, who later became dictator of Venezuela. The dictatorship repressed the Democratic Action and the Communist Party of Venezuela, both from left. Pedro Estrada led the DSN, which was a military organization  Venezuelan that repressed opponents and protesters. Among the cases of crimes against humanity are the death of the Democratic Action politician, Antonio Pinto Salinas who was assassinated while trying to flee from Venezuela. In 1958 an attempt was organized to overthrow  Perez Jimenez, faced with political pressure  Jimenez had to get rid of many of his allies such as Pedro Estrada. That same year, a movement of civilians and military men joined forces to force Marcos Perez Jimenez and his most loyal ministers to leave the country. The dictatorship ended when Marcos Perez Jimenez was exiled from the country, the civilians were To celebrate in the street, the political prisoners were released and the exiles returned to the country, the Venezuelans once again elected Romulo Betancourt, who had already been president years ago. However, he continued to use the political and economic system of the  Jimenez dictatorship.
",2
2023,"Although a large part of the Latin American dictatorships were from Right, the Soviet Union support and backing  Socialist States in Latin America. The Cuba from Fidel Castro was a great example of this, the government was established after the Cuban Revolution that overthrew the government from the dictator Fulgencio Batista in 1959, being the first Socialist State of the Western Hemisphere. In 2008 Castro he left power, being replaced by his brother  Raul.
",2
2024,"In 1972 Guillermo Rodriguez Lara established a dictatorial government, and called his government the ""Nationalist Revolution."" In 1973, the country's entry into the organization OPEC was promoted, the government also imposed agrarian reforms in practice. The dictatorship ended in 1976.
",2
2025,"After World War II, dictators established themselves in the several new states of Africa and Asia, often at the expense or failure of the constitutions inherited from the colonial powers. These constitutions often failed to work without a strong middle class or work against the preexisting autocratic rule. Some elected presidents and prime ministers captured power by suppressing the opposition and installing one-party rule and others established military dictatorships through their armies. Whatever their form, these dictatorships had an adverse impact on economic growth and the quality of political institutions.[35] Dictators who stayed in office for a long period of time found it increasingly difficult to carry out sound economic policies.
",2
2026,"The often-cited exploitative dictatorship is the regime of Mobutu Sese Seko, who ruled Zaire from 1965 to 1997, embezzling over $5 billion from his country.[36] Pakistan is another country to have been governed by 3 military dictators for almost 32 years in 7 decades of its existence. Starting with General Muhammad Ayub Khan who ruled from 1958–1969. Next was General Zia-ul-Haq who usurped power in 1977 and held on to power the longest until he died in an air crash in 1988. Ten years after Zia, General Pervez Musharraf got control after defeat against India in the Kargil war. He remained in power for 9 years until 2008.[37] Suharto of Indonesia is another prime example, having embezzled $15-35 billion[38][39] during his 31-year dictatorship known as the New Order. In the Philippines, the conjugal dictatorship[40] of Ferdinand Marcos and Imelda Marcos embezzled billions of dollars in public funds,[41][42][43] while the nation's foreign debt skyrocketed from $599 million in 1966 to $26.7 billion in 1986, with debt payment being reachable only by 2025.[44] The Marcos dictatorship has been noted for its anti-Muslim killings,[45][46][47][48] political repression, censorship, and human rights violations,[49] including various methods of torture.[50]
",2
2027,"The global dynamics of democratization has been a central question for political scientists.[51][52] The Third Wave Democracy was said to turn some dictatorships into democracies[51] (see also the contrast between the two figures of the Democracy-Dictatorship Index in 1988 and 2008).
",2
2028,"One of the rationales that the Bush Administration employed periodically during the run-up to the 2003 invasion of Iraq is that deposing Saddam Hussein and installing a democratic government in Iraq would promote democracy in other Middle Eastern countries.[53] However, according to The Huffington Post, ""The 45 nations and territories with little or no democratic rule represent more than half of the roughly 80 countries now hosting U.S. bases. ...  Research by political scientist Kent Calder confirms what's come to be known as the ""dictatorship hypothesis"": The United States tends to support dictators [and other undemocratic regimes] in nations where it enjoys basing facilities.""[54]
",2
2029,"Mancur Olson suggests that the emergence of dictatorships can be linked to the concept of ""roving bandits"", individuals in an atomic system who move from place to place extracting wealth from individuals. These bandits provide a disincentive for investment and production. Olson states that a community of individuals would be served less badly if that bandit were to establish himself as a stationary bandit to monopolize theft in the form of taxes. Except from the community, the bandits themselves will be better served, according to Olson, by transforming themselves into ""stationary bandits"". By settling down and making themselves the rulers of a territory, they will be able to make more profits through taxes than they used to obtain through plunder. By maintaining order and providing unsollicited protection to the community, the bandits will create an environment in which people can increase their surplus which means a greater taxable base. Thus a potential dictator will have a greater incentive to provide an illusion of security to a given community from which he is extracting taxes and conversely, the unthinking part of the people from whom he extracts the taxes are more likely to produce because they will be unconcerned with potential theft by other bandits. This is the rational that bandits use in order to explain their transformation from ""roving bandits"" into ""stationary bandits"".[55]
",2
2030,"
",2
2031,"
",2
2032,"An election is a formal group decision-making process by which a population chooses an individual or multiple individuals to hold public office.[1]
",2
2033,"Elections have been the usual mechanism by which modern representative democracy has operated since the 17th century.[1] Elections may fill offices in the legislature, sometimes in the executive and judiciary, and for regional and local government. This process is also used in many other private and business organizations, from clubs to voluntary associations and corporations.[2]
",2
2034,"The universal use of elections as a tool for selecting representatives in modern representative democracies is in contrast with the practice in the democratic archetype, ancient Athens, where the Elections were not used were considered an oligarchic institution and most political offices were filled using sortition, also known as allotment, by which officeholders were chosen by lot.[3]
",2
2035,"Electoral reform describes the process of introducing fair electoral systems where they are not in place, or improving the fairness or effectiveness of existing systems. Psephology is the study of results and other statistics relating to elections (especially with a view to predicting future results). Election is the fact of electing, or being elected.
",2
2036,"To elect means ""to select or make a decision"", and so sometimes other forms of ballot such as referendums are referred to as elections, especially in the United States.
",2
2037,"Elections were used as early in history as ancient Greece and ancient Rome, and throughout the Medieval period to select rulers such as the Holy Roman Emperor (see imperial election) and the pope (see papal election).[1]
",2
2038,"In Vedic period of India, the Raja (chiefs) of a gana (a tribal organization) was apparently elected by the gana. The Raja belonged to the noble Kshatriya varna (warrior class), and was typically a son of the previous Raja. However, the gana members had the final say in his elections.[4] Even during the Sangam Period people elected their representatives by casting their votes and the ballot boxes (Usually a pot) were tied by rope and sealed. After the election the votes were taken out and counted.[5] The Pala King Gopala (ruled c. 750s–770s CE) in early medieval Bengal was elected by a group of feudal chieftains. Such elections were quite common in contemporary societies of the region.[6][7] In the Chola Empire, around 920 CE, in Uthiramerur (in present-day Tamil Nadu), palm leaves were used for selecting the village committee members. The leaves, with candidate names written on them, were put inside a mud pot. To select the committee members, a young boy was asked to take out as many leaves as the number of positions available. This was known as the Kudavolai system.[8][9]
",2
2039,"The first recorded popular elections of officials to public office, by majority vote, where all citizens were eligible both to vote and to hold public office, date back to the Ephors of Sparta in 754 B.C., under the mixed government of the Spartan Constitution.[10][11] Athenian democratic elections, where all citizens could hold public office, were not introduced for another 247 years, until the reforms of Cleisthenes.[12] Under the earlier Solonian Constitution (circa 574 B.C.), all Athenian citizens were eligible to vote in the popular assemblies, on matters of law and policy, and as jurors, but only the three highest classes of citizens could vote in elections. Nor were the lowest of the four classes of Athenian citizens (as defined by the extent of their wealth and property, rather than by birth) eligible to hold public office, through the reforms of Solon.[13][14] The Spartan election of the Ephors, therefore, also predates the reforms of Solon in Athens by approximately 180 years.[15]
",2
2040,"Questions of suffrage, especially suffrage for minority groups, have dominated the history of elections. Males, the dominant cultural group in North America and Europe, often dominated the electorate and continue to do so in many countries.[1] Early elections in countries such as the United Kingdom and the United States were dominated by landed or ruling class males.[1] However, by 1920 all Western European and North American democracies had universal adult male suffrage (except Switzerland) and many countries began to consider women's suffrage.[1] Despite legally mandated universal suffrage for adult males, political barriers were sometimes erected to prevent fair access to elections (see civil rights movement).[1]
",2
2041,"The question of who may vote is a central issue in elections. The electorate does not generally include the entire population; for example, many countries prohibit those who are under the age of majority from voting, all jurisdictions require a minimum age for voting.
",2
2042,"In Australia, Aboriginal people were not given the right to vote until 1962 (see 1967 referendum entry) and in 2010 the federal government removed the rights of prisoners serving for 3 years or more to vote (a large proportion of which were Aboriginal Australians).
",2
2043,"Suffrage is typically only for citizens of the country, though further limits may be imposed.
",2
2044,"However, in the European Union, one can vote in municipal elections if one lives in the municipality and is an EU citizen; the nationality of the country of residence is not required. 
",2
2045,"In some countries, voting is required by law; if an eligible voter does not cast a vote, he or she may be subject to punitive measures such as a fine. In Western Australia, the penalty for a first time offender failing to vote is a $20.00 fine, which increases to $50.00 if the offender refused to vote prior.[16]
",2
2046,"Historically the size of eligible voters, the electorate, was small having the size of groups or communities of privileged men like aristocrats and men of a city (citizens).
",2
2047,"With the growth of the number of people with bourgeois citizen rights outside of cities, expanding the term citizen, the electorates grew to numbers beyond the thousands.
Elections with an electorate in the hundred thousands appeared in the final decades of the Roman Republic, by extending voting rights to citizens outside of Rome with the Lex Julia of 90 BC, reaching an electorate of 910,000 and estimated voter turnout of maximum 10% in 70 BC,[17] only again comparable in size to the first elections of the United States. At the same time the Kingdom of Great Britain had in 1780 about 214,000 eligible voters, 3% of the whole population.[18]
",2
2048,"A representative democracy requires a procedure to govern nomination for political office. In many cases, nomination for office is mediated through preselection processes in organized political parties.[19]
",2
2049,"Non-partisan systems tend to be different from partisan systems as concerns nominations. In a direct democracy, one type of non-partisan democracy, any eligible person can be nominated. Although elections were used in ancient Athens, in Rome, and in the selection of popes and Holy Roman emperors, the origins of elections in the contemporary world lie in the gradual emergence of representative government in Europe and North America beginning in the 17th century. In some systems no nominations take place at all, with voters free to choose any person at the time of voting—with some possible exceptions such as through a minimum age requirement—in the jurisdiction. In such cases, it is not required (or even possible) that the members of the electorate be familiar with all of the eligible persons, though such systems may involve indirect elections at larger geographic levels to ensure that some first-hand familiarity among potential electees can exist at these levels (i.e., among the elected delegates).
",2
2050,"As far as partisan systems, in some countries, only members of a particular party can be nominated (see one-party state).  Or, any eligible person can be nominated through a process; thus allowing him or her to be listed.
",2
2051,"Electoral systems are the detailed constitutional arrangements and voting systems that convert the vote into a political decision. The first step is to tally the votes, for which various vote counting systems and ballot types are used. Voting systems then determine the result on the basis of the tally. Most systems can be categorized as either proportional or majoritarian.  Among the former are party-list proportional representation and additional member system.  Among the latter are First Past the Post electoral system (relative majority) and absolute majority.  Many countries have growing electoral reform movements, which advocate systems such as approval voting, single transferable vote, instant runoff voting or a Condorcet method; these methods are also gaining popularity for lesser elections in some countries where more important elections still use more traditional counting methods.
",2
2052,"While openness and accountability are usually considered cornerstones of a democratic system, the act of casting a vote and the content of a voter's ballot are usually an important exception.  The secret ballot is a relatively modern development, but it is now considered crucial in most free and fair elections, as it limits the effectiveness of intimidation.
",2
2053,"The nature of democracy is that elected officials are accountable to the people, and they must return to the voters at prescribed intervals to seek their mandate to continue in office. For that reason most democratic constitutions provide that elections are held at fixed regular intervals. In the United States, elections for public offices are typically held between every two and six years in most states and at the federal level, with exceptions for elected judicial positions that may have longer terms of office. There is a variety of schedules, for example presidents: the President of Ireland is elected every seven years, the President of Russia and the President of Finland every six years, the President of France every five years, President of the United States every four years.
",2
2054,"Pre-decided or fixed election dates have the advantage of fairness and predictability. However, they tend to greatly lengthen campaigns, and make dissolving the legislature (parliamentary system) more problematic if the date should happen to fall at time when dissolution is inconvenient (e.g. when war breaks out). Other states (e.g., the United Kingdom) only set maximum time in office, and the executive decides exactly when within that limit it will actually go to the polls. In practice, this means the government remains in power for close to its full term, and choose an election date it calculates to be in its best interests (unless something special happens, such as a motion of no-confidence). This calculation depends on a number of variables, such as its performance in opinion polls and the size of its majority.
",2
2055,"When elections are called, politicians and their supporters attempt to influence policy by competing directly for the votes of constituents in what are called campaigns.  Supporters for a campaign can be either formally organized or loosely affiliated, and frequently utilize campaign advertising. It is common for political scientists to attempt to predict elections via Political Forecasting methods.
",2
2056,"The most expensive election campaign included US$7 billion spent on the 2012 United States presidential election and is followed by the US$5 billion spent on the 2014 Indian general election.[20]
",2
2057,"In many of the countries with weak rule of law, the most common reason why elections do not meet international standards of being ""free and fair"" is interference from the incumbent government. Dictators may use the powers of the executive (police, martial law, censorship, physical implementation of the election mechanism, etc.) to remain in power despite popular opinion in favor of removal. Members of a particular faction in a legislature may use the power of the majority or supermajority (passing criminal laws, defining the electoral mechanisms including eligibility and district boundaries) to prevent the balance of power in the body from shifting to a rival faction due to an election.[1]
",2
2058,"Non-governmental entities can also interfere with elections, through physical force, verbal intimidation, or fraud, which can result in improper casting or counting of votes. Monitoring for and minimizing electoral fraud is also an ongoing task in countries with strong traditions of free and fair elections. Problems that prevent an election from being ""free and fair"" take various forms.[21]
",2
2059,"The electorate may be poorly informed about issues or candidates due to lack of freedom of the press, lack of objectivity in the press due to state or corporate control, and/or lack of access to news and political media. Freedom of speech may be curtailed by the state, favoring certain viewpoints or state propaganda.
",2
2060,"Gerrymandering, exclusion of opposition candidates from eligibility for office, needlessly high restrictions on who may be a candidate, like ballot access rules, and manipulating thresholds for electoral success are some of the ways the structure of an election can be changed to favor a specific faction or candidate.
",2
2061,"Those in power may arrest or assassinate candidates, suppress or even criminalize campaigning, close campaign headquarters, harass or beat campaign workers, or intimidate voters with violence. Foreign electoral intervention can also occur, with the United States interfering between 1946 and 2000 in 81 elections and Russia/USSR in 36.[22]
In 2018 the most intense interventions, by means of false information, were by China in Taiwan and by Russia in Latvia; the next highest levels were in Bahrain, Qatar and Hungary.[23]
",2
2062,"This can include falsifying voter instructions,[24]
violation of the secret ballot, ballot stuffing, tampering with voting machines,[25]
destruction of legitimately cast ballots,[26]
voter suppression, voter registration fraud, failure to validate voter residency, fraudulent tabulation of results, and use of physical force or verbal intimation at polling places. Other examples include persuading candidates not to run, such as through blackmailing, bribery, intimidation or physical violence.
",2
2063,"
A sham election, or show election, is an election that is held purely for show; that is, without any significant political choice or real impact on results of election.[27]
",2
2064,"Sham elections are a common event in dictatorial regimes that feel the need to feign the appearance of public legitimacy. Published results usually show nearly 100% voter turnout and high support (typically at least 80%, and close to 100% in many cases) for the prescribed candidate(s) or for the referendum choice that favors the political party in power. Dictatorial regimes can also organize sham elections with results simulating those that might be achieved in democratic countries.[28]
",2
2065,"Sometimes, only one government approved candidate is allowed to run in sham elections with no opposition candidates allowed, or opposition candidates are arrested on false charges (or even without any charges) before the election to prevent them from running.[29][30][31]
",2
2066,"Ballots may contain only one ""yes"" option, or in the case of a simple ""yes or no"" question, security forces often persecute people who pick ""no"", thus encouraging them to pick the ""yes"" option. In other cases, those who vote receive stamps in their passport for doing so, while those who did not vote (and thus do not receive stamps) are persecuted as enemies of the people.[32][33]
",2
2067,"In some cases, sham elections can backfire against the party in power, especially if the regime believes they are popular enough to win without coercion or fraud. The most famous example of this was the 1990 Myanmar general election, in which the government-sponsored National Unity Party suffered a landslide defeat to the opposition National League for Democracy and consequently the results were annulled.[34]
",2
2068,"Examples of sham elections are the 1929 and 1934 elections in Fascist Italy, elections in Nazi Germany, the 1940 elections of the People's Parliaments in Estonia, Latvia and Lithuania, the 1928, 1935, 1942, 1949, 1951 and 1958 elections in Portugal, the 1991 Kazakh presidential election, those in North Korea,[35] and the 1995 and 2002 Iraq Presidential referendums under Saddam Hussein.
",2
2069,"In Mexico, all of the presidential elections from 1929 to 1982 are considered to be sham elections, as the Institutional Revolutionary Party (PRI) and its predecessors governed the country in a de facto single-party system without serious opposition, and won all of the presidential alections in that period with percentages of votes well over 70%. The first actually competitive presidential election in modern Mexican history was that of 1988, in which for the first time the PRI candidate faced two strong opposition candidates.
",2
2070,"A predetermined conclusion is always established by the regime through suppression of the opposition, coercion of voters, vote rigging, reporting a number of votes received greater than the number of voters, outright lying, or some combination of these.
",2
2071,"In an extreme example, Charles D. B. King of Liberia was reported to have won by 234,000 votes in the 1927 general election, a ""majority"" that was over fifteen times larger than the number of eligible voters.[36]
",2
2072,"
Coordinates: .mw-parser-output .geo-default,.mw-parser-output .geo-dms,.mw-parser-output .geo-dec{display:inline}.mw-parser-output .geo-nondefault,.mw-parser-output .geo-multi-punct{display:none}.mw-parser-output .longitude,.mw-parser-output .latitude{white-space:nowrap}38°53′23″N 77°0′32″W﻿ / ﻿38.88972°N 77.00889°W﻿ / 38.88972; -77.00889
",2
2073," 
",2
2074,"The United States Congress or U.S. Congress is the bicameral legislature of the federal government of the United States and consists of the House of Representatives and the Senate. The Congress meets in the United States Capitol in Washington, D.C. Both senators and representatives are chosen through direct election, though vacancies in the Senate may be filled by a governor's appointment. Congress has 535 voting members: 100 senators and 435 representatives. The vice-president of the United States has a vote in the senate only when senators are evenly divided; the House of Representatives has six non-voting members.[1]
",2
2075,"The sitting of a congress is for a two-year term, at present beginning every other January; the current congress is the 117th.  Elections are held every even-numbered year on Election Day.  The members of the House of Representatives are elected for the two-year term of a congress. The Reapportionment Act of 1929 establishes that they be elected in single-member constituencies or districts by first-past-the-post and that congressional districts be apportioned to states by population every ten years using the United States Census results, provided that each state has at least one congressional representative. Each senator is elected at-large in their state for a six-year term, with terms staggered, so every two years approximately one-third of the Senate is up for election. Each state, regardless of population or size, has two senators, so currently, there are 100 senators for the 50 states.
",2
2076,"Article One of the United States Constitution requires that members of Congress must be at least 25 years old (House) or 30 years old (Senate), have been a citizen of the United States for seven (House) or nine (Senate) years, and be an inhabitant of the state which they represent. Members in both chambers may stand for re-election an unlimited number of times.
",2
2077,"The Congress was created by the Constitution of the United States and first met in 1789, replacing in its legislative function the Congress of the Confederation. Although not legally mandated, in practice since the 19th century, Congress members are typically affiliated with one of the two major parties, the Republican Party or the Democratic Party and only rarely with a third party or independents affiliated with no party.
",2
2078,"Article One of the United States Constitution states, ""All legislative Powers herein granted shall be vested in a Congress of the United States, which shall consist of a Senate and House of Representatives."" The House and Senate are equal partners in the legislative process—legislation cannot be enacted without the consent of both chambers. However, the Constitution grants each chamber some unique powers. The Senate ratifies treaties and approves presidential appointments while the House initiates revenue-raising bills. 
",2
2079,"The House initiates impeachment cases, while the Senate decides impeachment cases.[2] A two-thirds vote of the Senate is required before an impeached person can be removed from office.[2]
",2
2080,"The term Congress can also refer to a particular meeting of the legislature. A Congress covers two years; the current one, the 117th Congress, began on January 3, 2021, and will end on January 3, 2023. Since the adoption of the Twentieth Amendment to the United States Constitution, the Congress has started and ended at noon on the third day of January of every odd-numbered year. Members of the Senate are referred to as senators; members of the House of Representatives are referred to as representatives, congresswomen, or congressmen.
",2
2081,"Scholar and representative Lee H. Hamilton asserted that the ""historic mission of Congress has been to maintain freedom"" and insisted it was a ""driving force in American government""[3] and a ""remarkably resilient institution.""[4] Congress is the ""heart and soul of our democracy,"" according to this view,[5] even though legislators rarely achieve the prestige or name recognition of presidents or Supreme Court justices; one wrote that ""legislators remain ghosts in America's historical imagination.""[5] One analyst argues that it is not a solely reactive institution but has played an active role in shaping government policy and is extraordinarily sensitive to public pressure.[5] Several academics described Congress:
",2
2082,"Congress reflects us in all our strengths and all our weaknesses. It reflects our regional idiosyncrasies, our ethnic, religious, and racial diversity, our multitude of professions, and our shadings of opinion on everything from the value of war to the war over values. Congress is the government's most representative body ... Congress is essentially charged with reconciling our many points of view on the great public policy issues of the day.",2
2083,"Congress is constantly changing and is constantly in flux.[6] In recent times, the American south and west have gained House seats according to demographic changes recorded by the census and includes more minorities and women although both groups are still underrepresented.[6] While power balances among the different parts of government continue to change, the internal structure of Congress is important to understand along with its interactions with so-called intermediary institutions such as political parties, civic associations, interest groups, and the mass media.[5]
",2
2084,"The Congress of the United States serves two distinct purposes that overlap: local representation to the federal government of a congressional district by representatives and a state's at-large representation to the federal government by senators.
",2
2085,"Most incumbents seek re-election, and their historical likelihood of winning subsequent elections exceeds 90 percent.[7]
",2
2086,"The historical records of the House of Representatives and the Senate are maintained by the Center for Legislative Archives, which is a part of the National Archives and Records Administration.[8]
",2
2087,"Congress is directly responsible for the governing of the District of Columbia, the current seat of the federal government.
",2
2088,"The First Continental Congress was a gathering of representatives from twelve of the thirteen colonies of North America.[9] On July 4, 1776, the Second Continental Congress adopted the Declaration of Independence, referring to the new nation as the ""United States of America."" The Articles of Confederation in 1781 created the Congress of the Confederation, a unicameral body with equal representation among the states in which each state had a veto over most decisions. Congress had executive but not legislative authority, and the federal judiciary was confined to admiralty.[10] and lacked authority to collect taxes, regulate commerce, or enforce laws.[11][12]
",2
2089,"Government powerlessness led to the Convention of 1787 which proposed a revised constitution with a two–chamber or bicameral congress.[13] Smaller states argued for equal representation for each state.[14] The two-chamber structure had functioned well in state governments.[15] A compromise plan, the Connecticut Compromise, was adopted with representatives chosen by population (benefiting larger states) and exactly two senators chosen by state governments (benefiting smaller states).[6][16] The ratified constitution created a federal structure with two overlapping power centers so that each citizen as an individual was subjected to both the power of state government and the national government.[17][18][19] To protect against abuse of power, each branch of government—executive, legislative, and judicial—had a separate sphere of authority and could check other branches according to the principle of the separation of powers.[2] Furthermore, there were checks and balances within the legislature since there were two separate chambers.[20] The new government became active in 1789.[2][21]
",2
2090,"Political scientist Julian E. Zelizer suggested there were four main congressional eras, with considerable overlap, and included the formative era (1780s–1820s), the partisan era (1830s–1900s), the committee era (1910s–1960s), and the contemporary era (1970s–today).[22]
",2
2091,"Federalists and anti-federalists jostled for power in the early years as political parties became pronounced, surprising the Constitution's Founding Fathers of the United States. With the passage of the Constitution and the Bill of Rights, the anti-federalist movement was exhausted. Some activists joined the Anti-Administration Party that James Madison and Thomas Jefferson were forming about 1790–91 to oppose policies of Treasury Secretary Alexander Hamilton; it soon became the Democratic-Republican Party or the Jeffersonian Republican Party[23] and began the era of the First Party System. Thomas Jefferson's election to the presidency marked a peaceful transition of power between the parties in 1800. John Marshall, 4th chief justice of the Supreme Court, empowered the courts by establishing the principle of judicial review in law in the landmark case Marbury v. Madison in 1803, effectively giving the Supreme Court a power to nullify congressional legislation.[24][25]
",2
2092,"These years were marked by growth in the power of political parties. The watershed event was the Civil War which resolved the slavery issue and unified the nation under federal authority, but weakened the power of states' rights. The Gilded Age (1877–1901) was marked by Republican dominance of Congress. During this time, lobbying activity became more intense, particularly during the administration of President Ulysses S. Grant in which influential lobbies advocated for railroad subsidies and tariffs on wool.[26] Immigration and high birth rates swelled the ranks of citizens and the nation grew at a rapid pace. The Progressive Era was characterized by strong party leadership in both houses of Congress as well as calls for reform; sometimes reformers would attack lobbyists as corrupting politics.[27] The position of Speaker of the House became extremely powerful under leaders such as Thomas Reed in 1890 and Joseph Gurney Cannon. The Senate was effectively controlled by a half dozen men.
",2
2093,"A system of seniority—in which long-time members of Congress gained more and more power—encouraged politicians of both parties to serve for long terms. Committee chairmen remained influential in both houses until the reforms of the 1970s.
",2
2094,"Important structural changes included the direct popular election of senators according to the Seventeenth Amendment,[16] ratified on April 8, 1913, with positive effects (senators more sensitive to public opinion) and negative effects (undermining the authority of state governments).[16] Supreme Court decisions based on the Constitution's commerce clause expanded congressional power to regulate the economy.[28] One effect of popular election of senators was to reduce the difference between the House and Senate in terms of their link to the electorate.[29] Lame duck reforms according to the Twentieth Amendment reduced the power of defeated and retiring members of Congress to wield influence despite their lack of accountability.[30]
",2
2095,"The Great Depression ushered in President Franklin Roosevelt and strong control by Democrats[31] and historic New Deal policies. Roosevelt's election in 1932 marked a shift in government power towards the executive branch. Numerous New Deal initiatives came from the White House rather than being initiated by Congress.[32] President Roosevelt pushed his agenda in Congress by detailing Executive Branch staff to friendly Senate committees (a practice that ended with the Legislative Reorganization Act of 1946).[33] The Democratic Party controlled both houses of Congress for many years.[34][35][36] During this time, Republicans and conservative southern Democrats[37] formed the Conservative Coalition.[36][38] Democrats maintained control of Congress during World War II.[39][40] Congress struggled with efficiency in the postwar era partly by reducing the number of standing congressional committees.[41] Southern Democrats became a powerful force in many influential committees although political power alternated between Republicans and Democrats during these years. More complex issues required greater specialization and expertise, such as space flight and atomic energy policy.[41] Senator Joseph McCarthy exploited the fear of communism during the Second Red Scare and conducted televised hearings.[42][43] In 1960, Democratic candidate John F. Kennedy narrowly won the presidency and power shifted again to the Democrats who dominated both houses of Congress until 1994.
",2
2096,"Congress enacted Johnson's Great Society program to fight poverty and hunger. The Watergate Scandal had a powerful effect of waking up a somewhat dormant Congress which investigated presidential wrongdoing and coverups; the scandal ""substantially reshaped"" relations between the branches of government, suggested political scientist Bruce J. Schulman.[45] Partisanship returned, particularly after 1994; one analyst attributes partisan infighting to slim congressional majorities which discouraged friendly social gatherings in meeting rooms such as the Board of Education.[5] Congress began reasserting its authority.[32][46] Lobbying became a big factor despite the 1971 Federal Election Campaign Act. Political action committees or PACs could make substantive donations to congressional candidates via such means as soft money contributions.[47] While soft money funds were not given to specific campaigns for candidates, the money often benefited candidates substantially in an indirect way and helped reelect candidates.[47] Reforms such as the 2002 Bipartisan Campaign Reform Act limited campaign donations but did not limit soft money contributions.[48] One source suggests post-Watergate laws amended in 1974 meant to reduce the ""influence of wealthy contributors and end payoffs"" instead ""legitimized PACs"" since they ""enabled individuals to band together in support of candidates.""[49] From 1974 to 1984, PACs grew from 608 to 3,803 and donations leaped from $12.5 million to $120 million[49][50][51] along with concern over PAC influence in Congress.[52][53] In 2009, there were 4,600 business, labor and special-interest PACs[54] including ones for lawyers, electricians, and real estate brokers.[55] From 2007 to 2008, 175 members of Congress received ""half or more of their campaign cash"" from PACs.[54][56][57]
",2
2097,"From 1970 to 2009, the House expanded delegates, along with their powers and privileges representing U.S. citizens in non-state areas, beginning with representation on committees for Puerto Rico's resident commissioner in 1970. In 1971, a delegate for the District of Columbia was authorized, and in 1972 new delegate positions were established for U.S. Virgin Islands and Guam. 1978 saw an additional delegate for American Samoa, and another for the Commonwealth of the Northern Mariana Islands began in 2009. These six members of Congress enjoy floor privileges to introduce bills and resolutions, and in recent congresses they vote in permanent and select committees, in party caucuses and in joint conferences with the Senate. They have Capitol Hill offices, staff and two annual appointments to each of the four military academies. While their votes are constitutional when Congress authorizes their House Committee of the Whole votes, recent Congresses have not allowed for that, and they cannot vote when the House is meeting as the House of Representatives.[58]
",2
2098,"In the late 20th century, the media became more important in Congress's work.[59] Analyst Michael Schudson suggested that greater publicity undermined the power of political parties and caused ""more roads to open up in Congress for individual representatives to influence decisions.""[59] Norman Ornstein suggested that media prominence led to a greater emphasis on the negative and sensational side of Congress, and referred to this as the tabloidization of media coverage.[6] Others saw pressure to squeeze a political position into a thirty-second soundbite.[60] A report characterized Congress in 2013 as being unproductive, gridlocked, and ""setting records for futility.""[61] In October 2013, with Congress unable to compromise, the government was shut down for several weeks and risked a serious default on debt payments, causing 60% of the public to say they would ""fire every member of Congress"" including their own representative.[62] One report suggested Congress posed the ""biggest risk to the U.S. economy"" because of its brinksmanship, ""down-to-the-wire budget and debt crises"" and ""indiscriminate spending cuts,"" resulting in slowed economic activity and keeping up to two million people unemployed.[63] There has been increasing public dissatisfaction with Congress,[64] with extremely low approval ratings[65][66] which dropped to 5% in October 2013.[67]
",2
2099,"On January 6, 2021, the Congress gathered to confirm the election of Joe Biden, when supporters of the outgoing president, Donald Trump, violently entered the building. The session of Congress ended prematurely and Congress representatives evacuated. Trump supporters occupied Congress until D.C police evacuated the area. The event was the first time since the Burning of Washington that the United States Congress was forcefully occupied.
",2
2100,"Article I of the Constitution creates and sets forth the structure and most of the powers of Congress. Sections One through Six describe how Congress is elected and gives each House the power to create its own structure. Section Seven lays out the process for creating laws, and Section Eight enumerates numerous powers.  Section Nine is a list of powers Congress does not have, and Section Ten enumerates powers of the state, some of which may only be granted by Congress.[68] Constitutional amendments have granted Congress additional powers. Congress also has implied powers derived from the Constitution's Necessary and Proper Clause.
",2
2101,"Congress has authority over financial and budgetary policy through the enumerated power to ""lay and collect Taxes, Duties, Imposts and Excises, to pay the Debts and provide for the common Defence and general Welfare of the United States."" There is vast authority over budgets, although analyst Eric Patashnik suggested that much of Congress's power to manage the budget has been lost when the welfare state expanded since ""entitlements were institutionally detached from Congress's ordinary legislative routine and rhythm.""[69] Another factor leading to less control over the budget was a Keynesian belief that balanced budgets were unnecessary.[69]
",2
2102,"The Sixteenth Amendment in 1913 extended congressional power of taxation to include income taxes without apportionment among the several States, and without regard to any census or enumeration.[70] The Constitution also grants Congress the exclusive power to appropriate funds, and this power of the purse is one of Congress's primary checks on the executive branch.[70] Congress can borrow money on the credit of the United States, regulate commerce with foreign nations and among the states, and coin money.[71] Generally, both the Senate and the House of Representatives have equal legislative authority, although only the House may originate revenue and appropriation bills.[2]
",2
2103,"Congress has an important role in national defense, including the exclusive power to declare war, to raise and maintain the armed forces, and to make rules for the military.[72] Some critics charge that the executive branch has usurped Congress's constitutionally defined task of declaring war.[73] While historically presidents initiated the process for going to war, they asked for and received formal war declarations from Congress for the War of 1812, the Mexican–American War, the Spanish–American War, World War I, and World War II,[74] although President Theodore Roosevelt's military move into Panama in 1903 did not get congressional approval.[74] In the early days after the North Korean invasion of 1950, President Truman described the American response as a ""police action.""[75] According to Time magazine in 1970, ""U.S. presidents [had] ordered troops into position or action without a formal congressional declaration a total of 149 times.""[74] In 1993, Michael Kinsley wrote that ""Congress's war power has become the most flagrantly disregarded provision in the Constitution,"" and that the ""real erosion [of Congress's war power] began after World War II.""[76][77][78] Disagreement about the extent of congressional versus presidential power regarding war has been present periodically throughout the nation's history.[79]
",2
2104,"Congress can establish post offices and post roads, issue patents and copyrights, fix standards of weights and measures, establish Courts inferior to the Supreme Court, and ""make all Laws which shall be necessary and proper for carrying into Execution the foregoing Powers, and all other Powers vested by this Constitution in the Government of the United States, or in any Department or Officer thereof."" Article Four gives Congress the power to admit new states into the Union.
",2
2105,"One of Congress's foremost non-legislative functions is the power to investigate and oversee the executive branch.[80] Congressional oversight is usually delegated to committees and is facilitated by Congress's subpoena power.[81] Some critics have charged that Congress has in some instances failed to do an adequate job of overseeing the other branches of government. In the Plame affair, critics including Representative Henry A. Waxman charged that Congress was not doing an adequate job of oversight in this case.[82] There have been concerns about congressional oversight of executive actions such as warrantless wiretapping, although others respond that Congress did investigate the legality of presidential decisions.[83] Political scientists Ornstein and Mann suggested that oversight functions do not help members of Congress win reelection. Congress also has the exclusive power of removal, allowing impeachment and removal of the president, federal judges and other federal officers.[84] There have been charges that presidents acting under the doctrine of the unitary executive have assumed important legislative and budgetary powers that should belong to Congress.[85] So-called signing statements are one way in which a president can ""tip the balance of power between Congress and the White House a little more in favor of the executive branch,"" according to one account.[86] Past presidents, including Ronald Reagan, George H. W. Bush, Bill Clinton, and George W. Bush,[87] have made public statements when signing congressional legislation about how they understand a bill or plan to execute it, and commentators, including the American Bar Association, have described this practice as against the spirit of the Constitution.[88][89] There have been concerns that presidential authority to cope with financial crises is eclipsing the power of Congress.[90] In 2008, George F. Will called the Capitol building a ""tomb for the antiquated idea that the legislative branch matters.""[91]
",2
2106,"The Constitution enumerates the powers of Congress in detail. In addition, other congressional powers have been granted, or confirmed, by constitutional amendments. The Thirteenth (1865), Fourteenth (1868), and Fifteenth Amendments (1870) gave Congress authority to enact legislation to enforce rights of African Americans, including voting rights, due process, and equal protection under the law.[92] Generally militia forces are controlled by state governments, not Congress.[93]
",2
2107,"Congress also has implied powers deriving from the Constitution's Necessary and Proper Clause which permit Congress to ""make all Laws which shall be necessary and proper for carrying into Execution the foregoing Powers, and all other Powers vested by this Constitution in the Government of the United States, or in any Department or Officer thereof.""[94] Broad interpretations of this clause and of the Commerce Clause, the enumerated power to regulate commerce, in rulings such as McCulloch v. Maryland, have effectively widened the scope of Congress's legislative authority far beyond that prescribed in Section Eight.[95][96]
",2
2108,"Constitutional responsibility for the oversight of Washington, D.C., the federal district and national capital, and the U.S. territories of Guam, American Samoa, Puerto Rico, the U.S. Virgin Islands, and the Northern Mariana Islands rests with Congress.[97] The republican form of government in territories is devolved by Congressional statute to the respective territories including direct election of governors, the D.C. mayor and locally elective territorial legislatures.[98]
",2
2109,"Each territory and Washington, D.C., elect a non-voting delegate to the U.S. House of Representatives as they have throughout Congressional history. They ""possess the same powers as other members of the House, except that they may not vote when the House is meeting as the House of Representatives."" They are assigned offices and allowances for staff, participate in debate, and appoint constituents to the four military service academies for the Army, Navy, Air Force and Coast Guard.[99]
",2
2110,"Washington, D.C., citizens alone among U.S. territories have the right to directly vote for the President of the United States, although the Democratic and Republican political parties nominate their presidential candidates at national conventions which include delegates from the five major territories.[100]
",2
2111,"Representative Lee H. Hamilton explained how Congress functions within the federal government:
",2
2112,"To me the key to understanding it is balance. The founders went to great lengths to balance institutions against each other—balancing powers among the three branches: Congress, the president, and the Supreme Court; between the House of Representatives and the Senate; between the federal government and the states; among states of different sizes and regions with different interests; between the powers of government and the rights of citizens, as spelled out in the Bill of Rights ... No one part of government dominates the other.[3]:6",2
2113,"The Constitution provides checks and balances among the three branches of the federal government. Its authors expected the greater power to lie with Congress as described in Article One.[3][101]
",2
2114,"The influence of Congress on the presidency has varied from period to period depending on factors such as congressional leadership, presidential political influence, historical circumstances such as war, and individual initiative by members of Congress. The impeachment of Andrew Johnson made the presidency less powerful than Congress for a considerable period afterwards.[102] The 20th and 21st centuries have seen the rise of presidential power under politicians such as Theodore Roosevelt, Woodrow Wilson, Franklin D. Roosevelt, Richard Nixon, Ronald Reagan, and George W. Bush.[103] However, in recent years, Congress has restricted presidential power with laws such as the Congressional Budget and Impoundment Control Act of 1974 and the War Powers Resolution. Nevertheless, the Presidency remains considerably more powerful today than during the 19th century.[3][103] Executive branch officials are often loath to reveal sensitive information to members of Congress because of concern that information could not be kept secret; in return, knowing they may be in the dark about executive branch activity, congressional officials are more likely to distrust their counterparts in executive agencies.[104] Many government actions require fast coordinated effort by many agencies, and this is a task that Congress is ill-suited for. Congress is slow, open, divided, and not well matched to handle more rapid executive action or do a good job of overseeing such activity, according to one analysis.[105]
",2
2115,"The Constitution concentrates removal powers in the Congress by empowering and obligating the House of Representatives to impeach both executive and judicial officials for ""Treason, Bribery, or other high Crimes and Misdemeanors."" Impeachment is a formal accusation of unlawful activity by a civil officer or government official. The Senate is constitutionally empowered and obligated to try all impeachments. A simple majority in the House is required to impeach an official; however, a two-thirds majority in the Senate is required for conviction. A convicted official is automatically removed from office; in addition, the Senate may stipulate that the defendant be banned from holding office in the future. Impeachment proceedings may not inflict more than this; however, a convicted party may face criminal penalties in a normal court of law. In the history of the United States, the House of Representatives has impeached sixteen officials, of whom seven were convicted. Another resigned before the Senate could complete the trial. Only three presidents have ever been impeached: Andrew Johnson in 1868, Bill Clinton in 1999, Donald Trump in 2019 and 2021. The trials of Johnson, Clinton and the 2019 trial of Trump all ended in acquittal; in Johnson's case, the Senate fell one vote short of the two-thirds majority required for conviction. In 1974, Richard Nixon resigned from office after impeachment proceedings in the House Judiciary Committee indicated he would eventually be removed from office.
",2
2116,"The Senate has an important check on the executive power by confirming Cabinet officials, judges, and other high officers ""by and with the Advice and Consent of the Senate."" It confirms most presidential nominees but rejections are not uncommon. Furthermore, treaties negotiated by the President must be ratified by a two-thirds majority vote in the Senate to take effect. As a result, presidential arm-twisting of senators can happen before a key vote; for example, President Obama's secretary of state, Hillary Clinton, urged her former senate colleagues to approve a nuclear arms treaty with Russia in 2010.[106] The House of Representatives has no formal role in either the ratification of treaties or the appointment of federal officials, other than in filling a vacancy in the office of the vice president; in such a case, a majority vote in each House is required to confirm a president's nomination of a vice president.[2]
",2
2117,"In 1803, the Supreme Court established judicial review of federal legislation in Marbury v. Madison, holding, however, that Congress could not grant unconstitutional power to the Court itself. The Constitution does not explicitly state that the courts may exercise judicial review; however, the notion that courts could declare laws unconstitutional was envisioned by the founding fathers. Alexander Hamilton, for example, mentioned and expounded upon the doctrine in Federalist No. 78. Originalists on the Supreme Court have argued that if the constitution does not say something explicitly it is unconstitutional to infer what it should, might or could have said.[107] Judicial review means that the Supreme Court can nullify a congressional law. It is a huge check by the courts on the legislative authority and limits congressional power substantially. In 1857, for example, the Supreme Court struck down provisions of a congressional act of 1820 in its Dred Scott decision.[108] At the same time, the Supreme Court can extend congressional power through its constitutional interpretations.
",2
2118,"The congressional inquiry into St. Clair's Defeat of 1791 was the first congressional investigation of the executive branch.[109] Investigations are conducted to gather information on the need for future legislation, to test the effectiveness of laws already passed, and to inquire into the qualifications and performance of members and officials of the other branches. Committees may hold hearings, and, if necessary, compel individuals to testify when investigating issues over which it has the power to legislate by issuing subpoenas.[110][111] Witnesses who refuse to testify may be cited for contempt of Congress, and those who testify falsely may be charged with perjury. Most committee hearings are open to the public (the House and Senate intelligence committees are the exception); important hearings are widely reported in the mass media and transcripts published a few months afterwards.[111] Congress, in the course of studying possible laws and investigating matters, generates an incredible amount of information in various forms, and can be described as a publisher.[112] Indeed, it publishes House and Senate reports[112] and maintains databases which are updated irregularly with publications in a variety of electronic formats.[112]
",2
2119,"Congress also plays a role in presidential elections. Both Houses meet in joint session on the sixth day of January following a presidential election to count the electoral votes, and there are procedures to follow if no candidate wins a majority.[2]
",2
2120,"The main result of congressional activity is the creation of laws,[113] most of which are contained in the United States Code, arranged by subject matter alphabetically under fifty title headings to present the laws ""in a concise and usable form.""[2]
",2
2121,"Congress is split into two chambers—House and Senate—and manages the task of writing national legislation by dividing work into separate committees which specialize in different areas. Some members of Congress are elected by their peers to be officers of these committees. Further, Congress has ancillary organizations such as the Government Accountability Office and the Library of Congress to help provide it with information, and members of Congress have staff and offices to assist them as well. In addition, a vast industry of lobbyists helps members write legislation on behalf of diverse corporate and labor interests.
",2
2122,"The committee structure permits members of Congress to study a particular subject intensely. It is neither expected nor possible that a member be an expert on all subject areas before Congress.[114] As time goes by, members develop expertise in particular subjects and their legal aspects. Committees investigate specialized subjects and advise the entire Congress about choices and trade-offs. The choice of specialty may be influenced by the member's constituency, important regional issues, prior background and experience.[115] Senators often choose a different specialty from that of the other senator from their state to prevent overlap.[116] Some committees specialize in running the business of other committees and exert a powerful influence over all legislation; for example, the House Ways and Means Committee has considerable influence over House affairs.[117]
",2
2123,"Committees write legislation. While procedures, such as the House discharge petition process, can introduce bills to the House floor and effectively bypass committee input, they are exceedingly difficult to implement without committee action. Committees have power and have been called independent fiefdoms. Legislative, oversight, and internal administrative tasks are divided among about two hundred committees and subcommittees which gather information, evaluate alternatives, and identify problems.[118] They propose solutions for consideration by the full chamber.[118] In addition, they perform the function of oversight by monitoring the executive branch and investigating wrongdoing.[118]
",2
2124,"At the start of each two-year session the House elects a speaker who does not normally preside over debates but serves as the majority party's leader. In the Senate, the vice president is the ex officio president of the Senate. In addition, the Senate elects an officer called the president pro tempore. Pro tempore means for the time being and this office is usually held by the most senior member of the Senate's majority party and customarily keeps this position until there is a change in party control. Accordingly, the Senate does not necessarily elect a new president pro tempore at the beginning of a new Congress. In both the House and Senate, the actual presiding officer is generally a junior member of the majority party who is appointed so that new members become acquainted with the rules of the chamber.
",2
2125,"The Library of Congress was established by an act of Congress in 1800. It is primarily housed in three buildings on Capitol Hill, but also includes several other sites: the National Library Service for the Blind and Physically Handicapped in Washington, D.C.; the National Audio-Visual Conservation Center in Culpeper, Virginia; a large book storage facility located at Fort Meade, Maryland; and multiple overseas offices. The Library had mostly law books when it was burned by a British raiding party during the War of 1812, but the library's collections were restored and expanded when Congress authorized the purchase of Thomas Jefferson's private library. One of the library's missions is to serve the Congress and its staff as well as the American public. It is the largest library in the world with nearly 150 million items including books, films, maps, photographs, music, manuscripts, graphics, and materials in 470 languages.[119]
",2
2126,"The Congressional Research Service, part of the Library of Congress, provides detailed, up-to-date and non-partisan research for senators, representatives, and their staff to help them carry out their official duties. It provides ideas for legislation, helps members analyze a bill, facilitates public hearings, makes reports, consults on matters such as parliamentary procedure, and helps the two chambers resolve disagreements. It has been called the ""House's think tank"" and has a staff of about 900 employees.[120]
",2
2127,"The Congressional Budget Office or CBO is a federal agency which provides economic data to Congress.[121]
",2
2128,"It was created as an independent non-partisan agency by the Congressional Budget and Impoundment Control Act of 1974. It helps Congress estimate revenue inflows from taxes and helps the budgeting process. It makes projections about such matters as the national debt[122] as well as likely costs of legislation. It prepares an annual Economic and Budget Outlook with a mid-year update and writes An Analysis of the President's Budgetary Proposals for the Senate's Appropriations Committee. The speaker of the House and the Senate's president pro tempore jointly appoint the CBO director for a four-year term.
",2
2129,"Lobbyists represent diverse interests and often seek to influence congressional decisions to reflect their clients' needs. Lobby groups and their members sometimes write legislation and whip bills. In 2007, there were approximately 17,000 federal lobbyists in Washington, D.C.[123] They explain to legislators the goals of their organizations. Some lobbyists represent non-profit organizations and work pro bono for issues in which they are personally interested.
",2
2130,"Congress has alternated between periods of constructive cooperation and compromise between parties, known as bipartisanship, and periods of deep political polarization and fierce infighting, known as partisanship. The period after the Civil War was marked by partisanship, as is the case today. It is generally easier for committees to reach accord on issues when compromise is possible. Some political scientists speculate that a prolonged period marked by narrow majorities in both chambers of Congress has intensified partisanship in the last few decades, but that an alternation of control of Congress between Democrats and Republicans may lead to greater flexibility in policies, as well as pragmatism and civility within the institution.[124]
",2
2131,"A term of Congress is divided into two ""sessions,"" one for each year; Congress has occasionally been called into an extra or special session. A new session commences on January 3 each year, unless Congress decides differently. The Constitution requires Congress meet at least once each year and forbids either house from meeting outside the Capitol without the consent of the other house.
",2
2132,"Joint sessions of the United States Congress occur on special occasions that require a concurrent resolution from both House and Senate. These sessions include counting electoral votes after a presidential election and the president's State of the Union address. The constitutionally mandated report, normally given as an annual speech, is modeled on Britain's Speech from the Throne, was written by most presidents after Jefferson but personally delivered as a spoken oration beginning with Wilson in 1913. Joint Sessions and Joint Meetings are traditionally presided over by the speaker of the House, except when counting presidential electoral votes when the vice president (acting as the president of the Senate) presides.
",2
2133,"Ideas for legislation can come from members, lobbyists, state legislatures, constituents, legislative counsel, or executive agencies. Anyone can write a bill, but only members of Congress may introduce bills. Most bills are not written by Congress members, but originate from the Executive branch; interest groups often draft bills as well. The usual next step is for the proposal to be passed to a committee for review.[2] A proposal is usually in one of these forms:
",2
2134,"Representatives introduce a bill while the House is in session by placing it in the hopper on the Clerk's desk.[113] It is assigned a number and referred to a committee which studies each bill intensely at this stage.[113] Drafting statutes requires ""great skill, knowledge, and experience"" and sometimes take a year or more.[2] Sometimes lobbyists write legislation and submit it to a member for introduction. Joint resolutions are the normal way to propose a constitutional amendment or declare war. On the other hand, concurrent resolutions (passed by both houses) and simple resolutions (passed by only one house) do not have the force of law but express the opinion of Congress or regulate procedure. Bills may be introduced by any member of either house. However, the Constitution states, ""All Bills for raising Revenue shall originate in the House of Representatives."" While the Senate cannot originate revenue and appropriation bills, it has power to amend or reject them. Congress has sought ways to establish appropriate spending levels.[2]
",2
2135,"Each chamber determines its own internal rules of operation unless specified in the Constitution or prescribed by law. In the House, a Rules Committee guides legislation; in the Senate, a Standing Rules committee is in charge. Each branch has its own traditions; for example, the Senate relies heavily on the practice of getting ""unanimous consent"" for noncontroversial matters.[2] House and Senate rules can be complex, sometimes requiring a hundred specific steps before a bill can become a law.[3] Members sometimes turn to outside experts to learn about proper Congressional procedures.[125]
",2
2136,"Each bill goes through several stages in each house including consideration by a committee and advice from the Government Accountability Office.[2] Most legislation is considered by standing committees which have jurisdiction over a particular subject such as Agriculture or Appropriations. The House has twenty standing committees; the Senate has sixteen. Standing committees meet at least once each month.[2] Almost all standing committee meetings for transacting business must be open to the public unless the committee votes, publicly, to close the meeting.[2] A committee might call for public hearings on important bills.[2] Each committee is led by a chair who belongs to the majority party and a ranking member of the minority party. Witnesses and experts can present their case for or against a bill.[113] Then, a bill may go to what is called a mark-up session, where committee members debate the bill's merits and may offer amendments or revisions.[113] Committees may also amend the bill, but the full house holds the power to accept or reject committee amendments. After debate, the committee votes whether it wishes to report the measure to the full house. If a bill is tabled then it is rejected. If amendments are extensive, sometimes a new bill with amendments built in will be submitted as a so-called clean bill with a new number.[113] Both houses have procedures under which committees can be bypassed or overruled but they are rarely used. Generally, members who have been in Congress longer have greater seniority and therefore greater power.[126]
",2
2137,"A bill which reaches the floor of the full house can be simple or complex[113] and begins with an enacting formula such as ""Be it enacted by the Senate and House of Representatives of the United States of America in Congress assembled."" Consideration of a bill requires, itself, a rule which is a simple resolution specifying the particulars of debate—time limits, possibility of further amendments, and such.[113] Each side has equal time and members can yield to other members who wish to speak.[113] Sometimes opponents seek to recommit a bill which means to change part of it.[113] Generally, discussion requires a quorum, usually half of the total number of representatives, before discussion can begin, although there are exceptions.[127] The house may debate and amend the bill; the precise procedures used by the House and Senate differ. A final vote on the bill follows.
",2
2138,"Once a bill is approved by one house, it is sent to the other which may pass, reject, or amend it. For the bill to become law, both houses must agree to identical versions of the bill.[113] If the second house amends the bill, then the differences between the two versions must be reconciled in a conference committee, an ad hoc committee that includes both senators and representatives[113] sometimes by using a reconciliation process to limit budget bills.[2] Both houses use a budget enforcement mechanism informally known as pay-as-you-go or paygo which discourages members from considering acts which increase budget deficits.[2] If both houses agree to the version reported by the conference committee, the bill passes, otherwise it fails.
",2
2139,"The Constitution specifies that a majority of members, known as a quorum, be present before doing business in each house. However, the rules of each house assume that a quorum is present unless a quorum call demonstrates the contrary and debate often continues despite the lack of a majority.
",2
2140,"Voting within Congress can take many forms, including systems using lights and bells and electronic voting.[2] Both houses use voice voting to decide most matters in which members shout ""aye"" or ""no"" and the presiding officer announces the result. The Constitution, however, requires a recorded vote if demanded by one-fifth of the members present or when voting to override a presidential veto. If the voice vote is unclear or if the matter is controversial, a recorded vote usually happens. The Senate uses roll-call voting, in which a clerk calls out the names of all the senators, each senator stating ""aye"" or ""no"" when their name is announced. In the Senate, the Vice President may cast the tie-breaking vote if present when the Senators are equally divided.
",2
2141,"The House reserves roll-call votes for the most formal matters, as a roll call of all 435 representatives takes quite some time; normally, members vote by using an electronic device. In the case of a tie, the motion in question fails. Most votes in the House are done electronically, allowing members to vote yea or nay or present or open.[2] Members insert a voting ID card and can change their votes during the last five minutes if they choose; in addition, paper ballots are used on some occasions—yea indicated by green and nay by red.[2] One member cannot cast a proxy vote for another.[2] Congressional votes are recorded on an online database.[128][129]
",2
2142,"After passage by both houses, a bill is enrolled and sent to the president for approval.[113] The president may sign it making it law or veto it, perhaps returning it to Congress with the president's objections. A vetoed bill can still become law if each house of Congress votes to override the veto with a two-thirds majority. Finally, the president may do nothing—neither signing nor vetoing the bill—and then the bill becomes law automatically after ten days (not counting Sundays) according to the Constitution. But if Congress is adjourned during this period, presidents may veto legislation passed at the end of a congressional session simply by ignoring it; the maneuver is known as a pocket veto, and cannot be overridden by the adjourned Congress.
",2
2143,"Senators face reelection every six years, and representatives every two. Reelections encourage candidates to focus their publicity efforts at their home states or districts.[59] Running for reelection can be a grueling process of distant travel and fund-raising which distracts senators and representatives from paying attention to governing, according to some critics.[130] Although others respond that the process is necessary to keep members of Congress in touch with voters.
",2
2144,"Nevertheless, incumbent members of Congress running for reelection have strong advantages over challengers.[47] They raise more money[52] because donors fund incumbents over challengers, perceiving the former as more likely to win,[50][131] and donations are vital for winning elections.[132] One critic compared being elected to Congress to receiving life tenure at a university.[131] Another advantage for representatives is the practice of gerrymandering.[133][134] After each ten-year census, states are allocated representatives based on population, and officials in power can choose how to draw the congressional district boundaries to support candidates from their party.  As a result, reelection rates of members of Congress hover around 90 percent,[7] causing some critics to accuse them of being a privileged class.[6] Academics such as Princeton's Stephen Macedo have proposed solutions to fix gerrymandering in the U.S. Both senators and representatives enjoy free mailing privileges, called franking privileges; while these are not intended for electioneering, this rule is often skirted by borderline election-related mailings during campaigns.
",2
2145,"In 1971, the cost of running for Congress in Utah was $70,000[135] but costs have climbed.[136] The biggest expense is television advertisements.[51][131][135][137][138] Today's races cost more than a million dollars for a House seat, and six million or more for a Senate seat.[6][51][137][139][140] Since fundraising is vital, ""members of Congress are forced to spend ever-increasing hours raising money for their re-election.""[attribution needed][141]
",2
2146,"Nevertheless, the Supreme Court has treated campaign contributions as a free speech issue.[136] Some see money as a good influence in politics since it ""enables candidates to communicate with voters.""[136] Few members retire from Congress without complaining about how much it costs to campaign for reelection.[6] Critics contend that members of Congress are more likely to attend to the needs of heavy campaign contributors than to ordinary citizens.[6]
",2
2147,"Elections are influenced by many variables. Some political scientists speculate there is a coattail effect (when a popular president or party position has the effect of reelecting incumbents who win by ""riding on the president's coattails""), although there is some evidence that the coattail effect is irregular and possibly declining since the 1950s.[47] Some districts are so heavily Democratic or Republican that they are called a safe seat; any candidate winning the primary will almost always be elected, and these candidates do not need to spend money on advertising.[142][143] But some races can be competitive when there is no incumbent. If a seat becomes vacant in an open district, then both parties may spend heavily on advertising in these races; in California in 1992, only four of twenty races for House seats were considered highly competitive.[144]
",2
2148,"Since members of Congress must advertise heavily on television, this usually involves negative advertising, which smears an opponent's character without focusing on the issues.[145] Negative advertising is seen as effective because ""the messages tend to stick.""[146] However, these advertisements sour the public on the political process in general as most members of Congress seek to avoid blame.[147] One wrong decision or one damaging television image can mean defeat at the next election, which leads to a culture of risk avoidance, a need to make policy decisions behind closed doors,[147][148] and concentrating publicity efforts in the members' home districts.[59]
",2
2149,"Prominent Founding Fathers writing in The Federalist Papers felt that elections were essential to liberty, that a bond between the people and the representatives was particularly essential,[149] and that ""frequent elections are unquestionably the only policy by which this dependence and sympathy can be effectually secured.""[149] In 2009, however, few Americans were familiar with leaders of Congress.[150][151][152] The percentage of Americans eligible to vote who did, in fact, vote was 63% in 1960, but has been falling since, although there was a slight upward trend in the 2008 election.[153] Public opinion polls asking people if they approve of the job Congress is doing have, in the last few decades, hovered around 25% with some variation.[6][154][155][156][157][158][159] Scholar Julian Zeliger suggested that the ""size, messiness, virtues, and vices that make Congress so interesting also create enormous barriers to our understanding the institution ... Unlike the presidency, Congress is difficult to conceptualize.""[160] Other scholars suggest that despite the criticism, ""Congress is a remarkably resilient institution ... its place in the political process is not threatened ... it is rich in resources"" and that most members behave ethically.[4] They contend that ""Congress is easy to dislike and often difficult to defend"" and this perception is exacerbated because many challengers running for Congress run against Congress, which is an ""old form of American politics"" that further undermines Congress's reputation with the public:[6]
",2
2150,"The rough-and-tumble world of legislating is not orderly and civil, human frailties too often taint its membership, and legislative outcomes are often frustrating and ineffective ... Still, we are not exaggerating when we say that Congress is essential to American democracy. We would not have survived as a nation without a Congress that represented the diverse interests of our society, conducted a public debate on the major issues, found compromises to resolve conflicts peacefully, and limited the power of our executive, military, and judicial institutions ... The popularity of Congress ebbs and flows with the public's confidence in government generally ... the legislative process is easy to dislike—it often generates political posturing and grandstanding, it necessarily involves compromise, and it often leaves broken promises in its trail. Also, members of Congress often appear self-serving as they pursue their political careers and represent interests and reflect values that are controversial. Scandals, even when they involve a single member, add to the public's frustration with Congress and have contributed to the institution's low ratings in opinion polls.",2
2151,"An additional factor that confounds public perceptions of Congress is that congressional issues are becoming more technical and complex and require expertise in subjects such as science, engineering and economics.[6] As a result, Congress often cedes authority to experts at the executive branch.[6]
",2
2152,"Since 2006, Congress has dropped 10 points in the Gallup confidence poll with only 9% having ""a great deal"" or ""quite a lot"" of confidence in their legislators.[161] Since 2011, Gallup poll has reported Congress's approval rating among Americans at 10% or below three times.[65][66] Public opinion of Congress plummeted further to 5% in October 2013 after parts of the U.S. government deemed 'nonessential government' shut down.[67]
",2
2153,"When the Constitution was ratified in 1787, the ratio of the populations of large states to small states was roughly twelve to one. The Connecticut Compromise gave every state, large and small, an equal vote in the Senate.[162] Since each state has two senators, residents of smaller states have more clout in the Senate than residents of larger states. But since 1787, the population disparity between large and small states has grown; in 2006, for example, California had seventy times the population of Wyoming.[163] Critics, such as constitutional scholar Sanford Levinson, have suggested that the population disparity works against residents of large states and causes a steady redistribution of resources from ""large states to small states.""[164][165][166] However, others argue that the Connecticut Compromise was deliberately intended by the Founding Fathers to construct the Senate so that each state had equal footing not based on population,[162] and contend that the result works well on balance.
",2
2154,"A major role for members of Congress is providing services to constituents.[167] Constituents request assistance with problems.[168] Providing services helps members of Congress win votes and elections[133][169][170] and can make a difference in close races.[171] Congressional staff can help citizens navigate government bureaucracies.[3] One academic described the complex intertwined relation between lawmakers and constituents as home style.[172]:8
",2
2155,"One way to categorize lawmakers, according to political scientist Richard Fenno, is by their general motivation:
",2
2156,"Members of Congress enjoy parliamentary privilege, including freedom from arrest in all cases except for treason, felony, and breach of the peace, and freedom of speech in debate. This constitutionally derived immunity applies to members during sessions and when traveling to and from sessions.[173] The term arrest has been interpreted broadly, and includes any detention or delay in the course of law enforcement, including court summons and subpoenas. The rules of the House strictly guard this privilege; a member may not waive the privilege on their own, but must seek the permission of the whole house to do so. Senate rules, however, are less strict and permit individual senators to waive the privilege as they choose.[citation needed]
",2
2157,"The Constitution guarantees absolute freedom of debate in both houses, providing in the Speech or Debate Clause of the Constitution that ""for any Speech or Debate in either House, they shall not be questioned in any other Place."" Accordingly, a member of Congress may not be sued in court for slander because of remarks made in either house, although each house has its own rules restricting offensive speeches, and may punish members who transgress.[174]
",2
2158,"Obstructing the work of Congress is a crime under federal law and is known as contempt of Congress. Each member has the power to cite individuals for contempt but can only issue a contempt citation—the judicial system pursues the matter like a normal criminal case. If convicted in court, an individual found guilty of contempt of Congress may be imprisoned for up to one year.[175]
",2
2159,"The franking privilege allows members of Congress to send official mail to constituents at government expense. Though they are not permitted to send election materials, borderline material is often sent, especially in the run-up to an election by those in close races.[176][177] Indeed, some academics consider free mailings as giving incumbents a big advantage over challengers.[7][failed verification][178]
",2
2160,"From 1789 to 1815, members of Congress received only a daily payment of $6 while in session. Members received an annual salary of $1,500 per year from 1815 to 1817, then a per diem salary of $8 from 1818 to 1855; since then they have received an annual salary, first pegged in 1855 at $3,000.[179][180] In 1907, salaries were raised to $7,500 per year, the equivalent of $173,000 in 2010.[180] In 2006, members of Congress received a yearly salary of $165,200.[180] Congressional leaders were paid $183,500 per year. The Speaker of the House of Representatives earns $212,100 annually. The salary of the President pro tempore for 2006 was $183,500, equal to that of the majority and minority leaders of the House and Senate.[181] Privileges include having an office and paid staff.[126] In 2008, non-officer members of Congress earned $169,300 annually.[154] Some critics complain congressional pay is high compared with a median American income of $45,113 for men and $35,102 for women.[182] Others have countered that congressional pay is consistent with other branches of government.[154] Another criticism is that members of Congress have access to free or low-cost medical care in the Washington, D.C., area. The petition, ""Remove health-care subsidies for Members of Congress and their families,"" garnered over 1,077,000 signatures on the website Change.org.[183] In January 2014, it was reported that for the first time over half of the members of Congress were millionaires.[184] Congress has been criticized for trying to conceal pay raises by slipping them into a large bill at the last minute.[185] Others have criticized the wealth of members of Congress.[135][138] Representative Jim Cooper of Tennessee told Harvard professor Lawrence Lessig that a chief problem with Congress was that members focused on lucrative careers as lobbyists after serving––that Congress was a ""Farm League for K Street""––instead of on public service.[186][187]
",2
2161,"Members elected since 1984 are covered by the Federal Employees Retirement System (FERS). Like other federal employees, congressional retirement is funded through taxes and participants' contributions. Members of Congress under FERS contribute 1.3% of their salary into the FERS retirement plan and pay 6.2% of their salary in Social Security taxes. And like federal employees, members contribute one-third of the cost of health insurance with the government covering the other two-thirds.[188]
",2
2162,"The size of a congressional pension depends on the years of service and the average of the highest three years of their salary. By law, the starting amount of a member's retirement annuity may not exceed 80% of their final salary. In 2006, the average annual pension for retired senators and representatives under the Civil Service Retirement System (CSRS) was $60,972, while those who retired under FERS, or in combination with CSRS, was $35,952.[189]
",2
2163,"Members of Congress make fact-finding missions to learn about other countries and stay informed, but these outings can cause controversy if the trip is deemed excessive or unconnected with the task of governing. For example, the Wall Street Journal reported in 2009 that lawmaker trips abroad at taxpayer expense had included spas, $300-per-night extra unused rooms, and shopping excursions.[190] Lawmakers respond that ""traveling with spouses compensates for being away from them a lot in Washington"" and justify the trips as a way to meet officials in other nations.[190]
",2
2164,"
",2
2165,"1 (1789)
2 (1791)
3 (1793)
4 (1795)
5 (1797)
6 (1799)
7 (1801)
8 (1803)
9 (1805)
10 (1807)
",2
2166,"11 (1809)
12 (1811)
13 (1813)
14 (1815)
15 (1817)
16 (1819)
17 (1821)
18 (1823)
19 (1825)
20 (1827)
",2
2167,"21 (1829)
22 (1831)
23 (1833)
24 (1835)
25 (1837)
26 (1839)
27 (1841)
28 (1843)
29 (1845)
30 (1847)
",2
2168,"31 (1849)
32 (1851)
33 (1853)
34 (1855)
35 (1857)
36 (1859)
37 (1861)
38 (1863)
39 (1865)
40 (1867)
",2
2169,"41 (1869)
42 (1871)
43 (1873)
44 (1875)
45 (1877)
46 (1879)
47 (1881)
48 (1883)
49 (1885)
50 (1887)
",2
2170,"51 (1889)
52 (1891)
53 (1893)
54 (1895)
55 (1897)
56 (1899)
57 (1901)
58 (1903)
59 (1905)
60 (1907)
",2
2171,"61 (1909)
62 (1911)
63 (1913)
64 (1915)
65 (1917)
66 (1919)
67 (1921)
68 (1923)
69 (1925)
70 (1927)
",2
2172,"71 (1929)
72 (1931)
73 (1933)
74 (1935)
75 (1937)
76 (1939)
77 (1941)
78 (1943)
79 (1945)
80 (1947)
",2
2173,"81 (1949)
82 (1951)
83 (1953)
84 (1955)
85 (1957)
86 (1959)
87 (1961)
88 (1963)
89 (1965)
90 (1967)
",2
2174,"91 (1969)
92 (1971)
93 (1973)
94 (1975)
95 (1977)
96 (1979)
97 (1981)
98 (1983)
99 (1985)
100 (1987)
",2
2175,"101 (1989)
102 (1991)
103 (1993)
104 (1995)
105 (1997)
106 (1999)
107 (2001)
108 (2003)
109 (2005)
110 (2007)
",2
2176,"111 (2009)
112 (2011)
113 (2013)
114 (2015)
115 (2017)
116 (2019)
117 (2021)
118 (2023)
",2
2177,"
",2
2178," 
",2
2179,"The Constitution of the United States is the supreme law of the United States of America.[2] This founding document, originally comprising seven articles, delineates the national frame of government. Its first three articles embody the doctrine of the separation of powers, whereby the federal government is divided into three branches: the legislative, consisting of the bicameral Congress (Article I); the executive, consisting of the president and subordinate officers  (Article II); and the judicial, consisting of the Supreme Court and other federal courts (Article III). Article IV, Article V and Article VI embody concepts of federalism, describing the rights and responsibilities of state governments, the states in relationship to the federal government, and the shared process of constitutional amendment. Article VII establishes the procedure subsequently used by the 13 States to ratify it. It is regarded as the oldest written and codified national constitution in force.[3]
",2
2180,"Since the Constitution came into force in 1789, it has been amended 27 times, including one amendment that repealed a previous one,[4] in order to meet the needs of a nation that has profoundly changed since the 18th century.[5] In general, the first ten amendments, known collectively as the Bill of Rights, offer specific protections of individual liberty and justice and place restrictions on the powers of government.[6][7] The majority of the 17 later amendments expand individual civil rights protections. Others address issues related to federal authority or modify government processes and procedures. Amendments to the United States Constitution, unlike ones made to many constitutions worldwide, are appended to the document. All four pages[8] of the original U.S. Constitution are written on parchment.[9]
",2
2181,"According to the United States Senate: ""The Constitution's first three words—We the People—affirm that the government of the United States exists to serve its citizens. For over two centuries the Constitution has remained in force because its framers wisely separated and balanced governmental powers to safeguard the interests of majority rule and minority rights, of liberty and equality, and of the federal and state governments.""[5] The first permanent constitution,[a] it is interpreted, supplemented, and implemented by a large body of federal constitutional law, and has influenced the constitutions of other nations.
",2
2182,"From September 5, 1774, to March 1, 1781, the Continental Congress functioned as the provisional government of the United States. Delegates to the First (1774) and then the Second (1775–1781) Continental Congress were chosen largely through the action of committees of correspondence in various colonies rather than through the colonial or later state legislatures. In no formal sense was it a gathering representative of existing colonial governments; it represented the dissatisfied elements of the people, such persons as were sufficiently interested to act, despite the strenuous opposition of the loyalists and the obstruction or disfavor of colonial governors.[12] The process of selecting the delegates for the First and Second Continental Congresses underscores the revolutionary role of the people of the colonies in establishing a central governing body. Endowed by the people collectively, the Continental Congress alone possessed those attributes of external sovereignty which entitled it to be called a state in the international sense, while the separate states, exercising a limited or internal sovereignty, may rightly be considered a creation of the Continental Congress, which preceded them and brought them into being.[13]
",2
2183,"The Articles of Confederation and Perpetual Union was the first constitution of the United States.[14] It was drafted by the Second Continental Congress from mid-1776 through late 1777, and ratification by all 13 states was completed by early 1781. The Articles of Confederation gave little power to the central government. The Confederation Congress could make decisions, but lacked enforcement powers. Implementation of most decisions, including modifications to the Articles, required unanimous approval of all 13 state legislatures.[15]
",2
2184,"Although, in a way, the Congressional powers in Article 9 made the ""league of states as cohesive and strong as any similar sort of republican confederation in history"",[16] the chief problem was, in the words of George Washington, ""no money"".[17] The Continental Congress could print money but it was worthless. Congress could borrow money, but couldn't pay it back.[17] No state paid all their U.S. taxes; some paid nothing. Some few paid an amount equal to interest on the national debt owed to their citizens, but no more.[17] No interest was paid on debt owed foreign governments. By 1786, the United States would default on outstanding debts as their dates came due.[17]
",2
2185,"Internationally, the United States had little ability to defend its sovereignty. Most of the troops in the 625-man United States Army were deployed facing (but not threatening) British forts on American soil. They had not been paid; some were deserting and others threatening mutiny.[18] Spain closed New Orleans to American commerce; U.S. officials protested, but to no effect. Barbary pirates began seizing American ships of commerce; the Treasury had no funds to pay their ransom. If any military crisis required action, the Congress had no credit or taxing power to finance a response.[17]
",2
2186,"Domestically, the Articles of Confederation was failing to bring unity to the diverse sentiments and interests of the various states. Although the Treaty of Paris (1783) was signed between Great Britain and the U.S., and named each of the American states, various states proceeded to violate it. New York and South Carolina repeatedly prosecuted Loyalists for wartime activity and redistributed their lands.[17] Individual state legislatures independently laid embargoes, negotiated directly with foreign authorities, raised armies, and made war, all violating the letter and the spirit of the Articles.
",2
2187,"In September 1786, during an inter–state convention to discuss and develop a consensus about reversing the protectionist trade barriers that each state had erected, James Madison questioned whether the Articles of Confederation was a binding compact or even a viable government. Connecticut paid nothing and ""positively refused"" to pay U.S. assessments for two years.[19] A rumor had it that a ""seditious party"" of New York legislators had opened a conversation with the Viceroy of Canada. To the south, the British were said to be openly funding Creek Indian raids on Georgia, and the state was under martial law.[20] Additionally, during Shays' Rebellion (August 1786 – June 1787) in Massachusetts, Congress could provide no money to support an endangered constituent state. General Benjamin Lincoln was obliged to raise funds from Boston merchants to pay for a volunteer army.[21]
",2
2188,"Congress was paralyzed. It could do nothing significant without nine states, and some legislation required all 13. When a state produced only one member in attendance, its vote was not counted. If a state's delegation was evenly divided, its vote could not be counted towards the nine-count requirement.[22] The Congress of the Confederation had ""virtually ceased trying to govern"".[23] The vision of a ""respectable nation"" among nations seemed to be fading in the eyes of revolutionaries such as George Washington, Benjamin Franklin, and Rufus King. Their dream of a republic, a nation without hereditary rulers, with power derived from the people in frequent elections, was in doubt.[24][25]
",2
2189,"On February 21, 1787, the Confederation Congress called a convention of state delegates at Philadelphia to propose a plan of government.[26] Unlike earlier attempts, the convention was not meant for new laws or piecemeal alterations, but for the ""sole and express purpose of revising the Articles of Confederation"". The convention was not limited to commerce; rather, it was intended to ""render the federal constitution adequate to the exigencies of government and the preservation of the Union."" The proposal might take effect when approved by Congress and the states.[27]
",2
2190,"On the appointed day, May 14, 1787, only the Virginia and Pennsylvania delegations were present, and so the convention's opening meeting was postponed for lack of a quorum.[28] A quorum of seven states met and deliberations began on May 25. Eventually twelve states were represented; 74 delegates were named, 55 attended and 39 signed.[29] The delegates were generally convinced that an effective central government with a wide range of enforceable powers must replace the weaker Congress established by the Articles of Confederation.
",2
2191,"Two plans for structuring the federal government arose at the convention's outset:
",2
2192,"On May 31, the Convention devolved into a ""Committee of the Whole"" to consider the Virginia Plan. On June 13, the Virginia resolutions in amended form were reported out of committee. The New Jersey Plan was put forward in response to the Virginia Plan.
",2
2193,"A ""Committee of Eleven"" (one delegate from each state represented) met from July 2 to 16[32] to work out a compromise on the issue of representation in the federal legislature. All agreed to a republican form of government grounded in representing the people in the states. For the legislature, two issues were to be decided: how the votes were to be allocated among the states in the Congress, and how the representatives should be elected. In its report, now known as the Connecticut Compromise (or ""Great Compromise""), the committee proposed proportional representation for seats in the House of Representatives based on population (with the people voting for representatives), and equal representation for each State in the Senate (with each state's legislators generally choosing their respective senators), and that all money bills would originate in the House.[33]
",2
2194,"The Great Compromise ended the stalemate between ""patriots"" and ""nationalists"", leading to numerous other compromises in a spirit of accommodation. There were sectional interests to be balanced by the Three-Fifths Compromise; reconciliation on Presidential term, powers, and method of selection; and jurisdiction of the federal judiciary.
",2
2195,"On July 24, a ""Committee of Detail""—John Rutledge (South Carolina), Edmund Randolph (Virginia), Nathaniel Gorham (Massachusetts), Oliver Ellsworth (Connecticut), and James Wilson (Pennsylvania)—was elected to draft a detailed constitution reflective of the Resolutions passed by the convention up to that point.[34] The Convention recessed from July 26 to August 6 to await the report of this ""Committee of Detail"". Overall, the report of the committee conformed to the resolutions adopted by the convention, adding some elements. A twenty-three article (plus preamble) constitution was presented.[35]
",2
2196,"From August 6 to September 10, the report of the committee of detail was discussed, section by section and clause by clause. Details were attended to, and further compromises were effected.[32][34] Toward the close of these discussions, on September 8, a ""Committee of Style and Arrangement""—Alexander Hamilton (New York), William Samuel Johnson (Connecticut), Rufus King (Massachusetts), James Madison (Virginia), and Gouverneur Morris (Pennsylvania)—was appointed to distill a final draft constitution from the twenty-three approved articles.[34] The final draft, presented to the convention on September 12, contained seven articles, a preamble and a closing endorsement, of which Morris was the primary author.[29] The committee also presented a proposed letter to accompany the constitution when delivered to Congress.[36]
",2
2197,"The final document, engrossed by Jacob Shallus,[37] was taken up on Monday, September 17, at the convention's final session. Several of the delegates were disappointed in the result, a makeshift series of unfortunate compromises. Some delegates left before the ceremony and three others refused to sign. Of the thirty-nine signers, Benjamin Franklin summed up, addressing the convention: ""There are several parts of this Constitution which I do not at present approve, but I am not sure I shall never approve them."" He would accept the Constitution, ""because I expect no better and because I am not sure that it is not the best"".[38]
",2
2198,"The advocates of the Constitution were anxious to obtain unanimous support of all twelve states represented in the convention. Their accepted formula for the closing endorsement was ""Done in Convention, by the unanimous consent of the States present."" At the end of the convention, the proposal was agreed to by eleven state delegations and the lone remaining delegate from New York, Alexander Hamilton.[39]
",2
2199,"Transmitted to the Congress of the Confederation, then sitting in New York City, it was within the power of Congress to expedite or block ratification of the proposed Constitution. The new frame of government that the Philadelphia Convention presented was technically only a revision of the Articles of Confederation. After several days of debate, Congress voted to transmit the document to the thirteen states for ratification according to the process outlined in its Article VII. Each state legislature was to call elections for a ""Federal Convention"" to ratify the new Constitution, rather than consider ratification itself; a departure from the constitutional practice of the time, designed to expand the franchise in order to more clearly embrace ""the people"". The frame of government itself was to go into force among the States so acting upon the approval of nine (i.e. two-thirds of the 13) states; also a departure from constitutional practice, as the Articles of Confederation could be amended only by unanimous vote of all the states.
",2
2200,"Three members of the Convention—Madison, Gorham, and King—were also Members of Congress. They proceeded at once to New York, where Congress was in session, to placate the expected opposition. Aware of their vanishing authority, Congress, on September 28, after some debate, resolved unanimously to submit the Constitution to the States for action, ""in conformity to the resolves of the Convention"",[40] but with no recommendation either for or against its adoption.
",2
2201,"Two parties soon developed, one in opposition, the Anti-Federalists, and one in support, the Federalists, of the Constitution; and the Constitution was debated, criticized, and expounded upon clause by clause. Hamilton, Madison, and Jay, under the name of Publius, wrote a series of commentaries, now known as The Federalist Papers, in support of ratification in the state of New York, at that time a hotbed of anti-Federalism. These commentaries on the Constitution, written during the struggle for ratification, have been frequently cited by the Supreme Court as an authoritative contemporary interpretation of the meaning of its provisions. The dispute over additional powers for the central government was close, and in some states, ratification was effected only after a bitter struggle in the state convention itself.
",2
2202,"On June 21, 1788, the constitution had been ratified by the minimum of nine states required under Article VII. Towards the end of July, and with eleven states then having ratified, the process of organizing the new government began. The Continental Congress, which still functioned at irregular intervals, passed a resolution on September 13, 1788, to put the new Constitution into operation with the eleven states that had then ratified it.[41] The federal government began operations under the new form of government on March 4, 1789. However, the initial meeting of each chamber of Congress had to be adjourned due to lack of a quorum.[42] George Washington was inaugurated as the nation's first president 8 weeks later, on April 30. The final two states, North Carolina and Rhode Island, both subsequently ratified the Constitution on November 21, 1789, and May 29, 1790, respectively.
",2
2203,"Enlightenment and Rule of law
",2
2204,"John LockeTwo Treatises of Governmentlife, liberty and property
",2
2205,"Several ideas in the Constitution were new. These were associated with the combination of consolidated government along with federal relationships with constituent states.
",2
2206,"The Due Process Clause of the Constitution was partly based on common law and on Magna Carta (1215), which had become a foundation of English liberty against arbitrary power wielded by a ruler.
",2
2207,"Among the most prominent political theorists of the late eighteenth century were William Blackstone, John Locke, and Montesquieu.[43]
",2
2208,"Both the influence of Edward Coke and William Blackstone were evident at the convention. In his Institutes of the Lawes of England, Edward Coke interpreted Magna Carta protections and rights to apply not just to nobles, but to all British subjects. In writing the Virginia Charter of 1606, he enabled the King in Parliament to give those to be born in the colonies all rights and liberties as though they were born in England. William Blackstone's Commentaries on the Laws of England were the most influential books on law in the new republic.
",2
2209,"British political philosopher John Locke following the Glorious Revolution (1688) was a major influence expanding on the contract theory of government advanced by Thomas Hobbes. Locke advanced the principle of consent of the governed in his Two Treatises of Government. Government's duty under a social contract among the sovereign people was to serve the people by protecting their rights. These basic rights were life, liberty and property.
",2
2210,"Montesquieu's influence on the framers is evident in Madison's Federalist No. 47 and Hamilton's Federalist No. 78. Jefferson, Adams, and Mason were known to read Montesquieu.[44] Supreme Court Justices, the ultimate interpreters of the Constitution, have cited Montesquieu throughout the Court's history.[45] (See, e.g., Green v. Biddle, 21 U.S. 1, 1, 36 (1823).United States v. Wood, 39 U.S. 430, 438 (1840).Myers v. United States, 272 U.S. 52, 116 (1926).Nixon v. Administrator of General Services, 433 U.S. 425, 442 (1977).Bank Markazi v. Peterson, 136 U.S. 1310, 1330 (2016).) Montesquieu emphasized the need for balanced forces pushing against each other to prevent tyranny (reflecting the influence of Polybius's 2nd century BC treatise on the checks and balances of the Roman Republic). In his The Spirit of the Laws, Montesquieu argues that the separation of state powers should be by its service to the people's liberty: legislative, executive and judicial.
",2
2211,"A substantial body of thought had been developed from the literature of republicanism in the United States, including work by John Adams and applied to the creation of state constitutions.
",2
2212,"The constitution was a federal one, and was influenced by the study of other federations, both ancient and extant. 
",2
2213,"The United States Bill of Rights consists of 10 amendments added to the Constitution in 1791, as supporters of the Constitution had promised critics during the debates of 1788.[46] The English Bill of Rights (1689) was an inspiration for the American Bill of Rights. Both require jury trials, contain a right to keep and bear arms, prohibit excessive bail and forbid ""cruel and unusual punishments"". Many liberties protected by state constitutions and the Virginia Declaration of Rights were incorporated into the Bill of Rights.
",2
2214,"Neither the Convention which drafted the Constitution nor the Congress which sent it to the 13 states for ratification in the autumn of 1787, gave it a lead caption. To fill this void, the document was most often titled ""A frame of Government"" when it was printed for the convenience of ratifying conventions and the information of the public.[47] This Frame of Government consisted of a preamble, seven articles and a signed closing endorsement.
",2
2215,"The preamble to the Constitution serves as an introductory statement of the document's fundamental purposes and guiding principles. It neither assigns powers to the federal government,[48] nor does it place specific limitations on government action. Rather, it sets out the origin, scope, and purpose of the Constitution. Its origin and authority is in ""We, the people of the United States"". This echoes the Declaration of Independence. ""One people"" dissolved their connection with another, and assumed among the powers of the earth, a sovereign nation-state. The scope of the Constitution is twofold. First, ""to form a more perfect Union"" than had previously existed in the ""perpetual Union"" of the Articles of Confederation. Second, to ""secure the blessings of liberty"", which were to be enjoyed by not only the first generation but for all who came after, ""our posterity"".[49]
",2
2216,"Article I describes the Congress, the legislative branch of the federal government. Section 1, reads, ""All legislative powers herein granted shall be vested in a Congress of the United States, which shall consist of a Senate and House of Representatives."" The article establishes the manner of election and the qualifications of members of each body. Representatives must be at least 25 years old, be a citizen of the United States for seven years, and live in the state they represent. Senators must be at least 30 years old, be a citizen for nine years, and live in the state they represent.
",2
2217,"Article I, Section 8 enumerates the powers delegated to the legislature. Financially, Congress has the power to tax, borrow, pay debt and provide for the common defense and the general welfare; to regulate commerce, bankruptcies, and coin money. To regulate internal affairs, it has the power to regulate and govern military forces and militias, suppress insurrections and repel invasions. It is to provide for naturalization, standards of weights and measures, post offices and roads, and patents; to directly govern the federal district and cessions of land by the states for forts and arsenals. Internationally, Congress has the power to define and punish piracies and offenses against the Law of Nations, to declare war and make rules of war. The final Necessary and Proper Clause, also known as the Elastic Clause, expressly confers incidental powers upon Congress without the Articles' requirement for express delegation for each and every power. Article I, Section 9 lists eight specific limits on congressional power.
",2
2218,"The Supreme Court has sometimes broadly interpreted the Commerce Clause and the Necessary and Proper Clause in Article One to allow Congress to enact legislation that is neither expressly allowed by the enumerated powers nor expressly denied in the limitations on Congress. In McCulloch v. Maryland (1819), the Supreme Court read the Necessary and Proper Clause to permit the federal government to take action that would ""enable [it] to perform the high duties assigned to it [by the Constitution] in the manner most beneficial to the people"",[50] even if that action is not itself within the enumerated powers. Chief Justice Marshall clarified: ""Let the end be legitimate, let it be within the scope of the Constitution, and all means which are appropriate, which are plainly adapted to that end, which are not prohibited, but consist with the letter and spirit of the Constitution, are Constitutional.""[50]
",2
2219,"Article II describes the office, qualifications, and duties of the President of the United States and the Vice President. The President is head of the executive branch of the federal government, as well as the nation's head of state and head of government.
",2
2220,"Article two is modified by the 12th Amendment which tacitly acknowledges political parties, and the 25th Amendment relating to office succession. The president is to receive only one compensation from the federal government. The inaugural oath is specified to preserve, protect and defend the Constitution.
",2
2221,"The president is the Commander in Chief of the United States Armed Forces, as well as of state militias when they are mobilized. He or she makes treaties with the advice and consent of a two-thirds quorum of the Senate. To administer the federal government, the president commissions all the offices of the federal government as Congress directs; he or she may require the opinions of its principal officers and make ""recess appointments"" for vacancies that may happen during the recess of the Senate. The president is to see that the laws are faithfully executed, though he or she may grant reprieves and pardons except regarding Congressional impeachment of himself or other federal officers. The president reports to Congress on the State of the Union, and by the Recommendation Clause, recommends ""necessary and expedient"" national measures. The president may convene and adjourn Congress under special circumstances.
",2
2222,"Section 4 provides for the removal of the president and other federal officers. The president is removed on impeachment for, and conviction of, treason, bribery, or other high crimes and misdemeanors.
",2
2223,"Article III describes the court system (the judicial branch), including the Supreme Court.  The article describes the kinds of cases the court takes as original jurisdiction.  Congress can create lower courts and an appeals process, and enacts law defining crimes and punishments.  Article Three also protects the right to trial by jury in all criminal cases, and defines the crime of treason.
",2
2224,"Section 1 vests the judicial power of the United States in federal courts, and with it, the authority to interpret and apply the law to a particular case. Also included is the power to punish, sentence, and direct future action to resolve conflicts. The Constitution outlines the U.S. judicial system. In the Judiciary Act of 1789, Congress began to fill in details. Currently, Title 28 of the U.S. Code[51] describes judicial powers and administration.
",2
2225,"As of the First Congress, the Supreme Court justices rode circuit to sit as panels to hear appeals from the district courts.[b] In 1891, Congress enacted a new system. District courts would have original jurisdiction. Intermediate appellate courts (circuit courts) with exclusive jurisdiction heard regional appeals before consideration by the Supreme Court. The Supreme Court holds discretionary jurisdiction, meaning that it does not have to hear every case that is brought to it.[51]
",2
2226,"To enforce judicial decisions, the Constitution grants federal courts both criminal contempt and civil contempt powers.  Other implied powers include injunctive relief and the habeas corpus remedy.  The Court may imprison for contumacy, bad-faith litigation, and failure to obey a writ of mandamus. Judicial power includes that granted by Acts of Congress for rules of law and punishment. Judicial power also extends to areas not covered by statute. Generally, federal courts cannot interrupt state court proceedings.[51]
",2
2227,"Clause 1 of Section 2 authorizes the federal courts to hear actual cases and controversies only. Their judicial power does not extend to cases that are hypothetical, or which are proscribed due to standing, mootness, or ripeness issues. Generally, a case or controversy requires the presence of adverse parties who have some interest genuinely at stake in the case.[c]
",2
2228,"Clause 2 of Section 2 provides that the Supreme Court has original jurisdiction in cases involving ambassadors, ministers, and consuls, for all cases respecting foreign nation-states,[52] and also in those controversies which are subject to federal judicial power because at least one state is a party. Cases arising under the laws of the United States and its treaties come under the jurisdiction of federal courts. Cases under international maritime law and conflicting land grants of different states come under federal courts. Cases between U.S. citizens in different states, and cases between U.S. citizens and foreign states and their citizens, come under federal jurisdiction. The trials will be in the state where the crime was committed.[51]
",2
2229,"No part of the Constitution expressly authorizes judicial review, but the Framers did contemplate the idea, and precedent has since established that the courts could exercise judicial review over the actions of Congress or the executive branch. Two conflicting federal laws are under ""pendent"" jurisdiction if one presents a strict constitutional issue. Federal court jurisdiction is rare when a state legislature enacts something as under federal jurisdiction.[d] To establish a federal system of national law, considerable effort goes into developing a spirit of comity between federal government and states. By the doctrine of 'Res judicata', federal courts give ""full faith and credit"" to State Courts.[e] The Supreme Court will decide Constitutional issues of state law only on a case-by-case basis, and only by strict Constitutional necessity, independent of state legislators' motives, their policy outcomes or its national wisdom.[f]
",2
2230,"Section 3 bars Congress from changing or modifying Federal law on treason by simple majority statute. This section also defines treason, as an overt act of making war or materially helping those at war with the United States. Accusations must be corroborated by at least two witnesses. Congress is a political body and political disagreements routinely encountered should never be considered as treason. This allows for nonviolent resistance to the government because opposition is not a life or death proposition. However, Congress does provide for other lesser subversive crimes such as conspiracy.[g]
",2
2231,"Article IV outlines the relations among the states and between each state and the federal government. In addition, it provides for such matters as admitting new states and border changes between the states. For instance, it requires states to give ""full faith and credit"" to the public acts, records, and court proceedings of the other states. Congress is permitted to regulate the manner in which proof of such acts may be admitted. The ""privileges and immunities"" clause prohibits state governments from discriminating against citizens of other states in favor of resident citizens. For instance, in criminal sentencing, a state may not increase a penalty on the grounds that the convicted person is a non-resident.
",2
2232,"It also establishes extradition between the states, as well as laying down a legal basis for freedom of movement and travel amongst the states. Today, this provision is sometimes taken for granted, but in the days of the Articles of Confederation, crossing state lines was often arduous and costly. The Territorial Clause gives Congress the power to make rules for disposing of federal property and governing non-state territories of the United States. Finally, the fourth section of Article Four requires the United States to guarantee to each state a republican form of government, and to protect them from invasion and violence.
",2
2233,"Article V outlines the process for amending the Constitution. Eight state constitutions in effect in 1787 included an amendment mechanism. Amendment making power rested with the legislature in three of the states and in the other five it was given to specially elected conventions. The Articles of Confederation provided that amendments were to be proposed by Congress and ratified by the unanimous vote of all 13 state legislatures. This proved to be a major flaw in the Articles, as it created an insurmountable obstacle to constitutional reform. The amendment process crafted during the Philadelphia Constitutional Convention was, according to The Federalist No. 43, designed to establish a balance between pliancy and rigidity:[53]
",2
2234,"It guards equally against that extreme facility which would render the Constitution too mutable; and that extreme difficulty which might perpetuate its discovered faults. It moreover equally enables the General and the State Governments to originate the amendment of errors, as they may be pointed out by the experience on one side, or on the other.",2
2235,"There are two steps in the amendment process. Proposals to amend the Constitution must be properly adopted and ratified before they change the Constitution. First, there are two procedures for adopting the language of a proposed amendment, either by (a) Congress, by two-thirds majority in both the Senate and the House of Representatives, or (b) national convention (which shall take place whenever two-thirds of the state legislatures collectively call for one). Second, there are two procedures for ratifying the proposed amendment, which requires three-fourths of the states' (presently 38 of 50) approval: (a) consent of the state legislatures, or (b) consent of state ratifying conventions. The ratification method is chosen by Congress for each amendment.[54] State ratifying conventions were used only once, for the Twenty-first Amendment.[55]
",2
2236,"Presently, the Archivist of the United States is charged with responsibility for administering the ratification process under the provisions of 1 U.S. Code § 106b. The Archivist submits the proposed amendment to the states for their consideration by sending a letter of notification to each Governor. Each Governor then formally submits the amendment to their state's legislature. When a state ratifies a proposed amendment, it sends the Archivist an original or certified copy of the state's action. Ratification documents are examined by the Office of the Federal Register for facial legal sufficiency and an authenticating signature.[56]
",2
2237,"Article Five ends by shielding certain clauses in the new frame of government from being amended. Article One, Section 9, Clause 1 prevents Congress from passing any law that would restrict the importation of slaves into the United States prior to 1808, plus the fourth clause from that same section, which reiterates the Constitutional rule that direct taxes must be apportioned according to state populations. These clauses were explicitly shielded from Constitutional amendment prior to 1808. On January 1, 1808, the first day it was permitted to do so, Congress approved legislation prohibiting the importation of slaves into the country. On February 3, 1913, with ratification of the Sixteenth Amendment, Congress gained the authority to levy an income tax without apportioning it among the states or basing it on the United States Census. The third textually entrenched provision is Article One, Section 3, Clauses 1, which provides for equal representation of the states in the Senate. The shield protecting this clause from the amendment process (""no state, without its consent, shall be deprived of its equal Suffrage in the Senate"") is less absolute but it is permanent.
",2
2238,"Article VI establishes the Constitution, and all federal laws and treaties of the United States made according to it, to be the supreme law of the land, and that ""the judges in every state shall be bound thereby, any thing in the laws or constitutions of any state notwithstanding."" It validates national debt created under the Articles of Confederation and requires that all federal and state legislators, officers, and judges take oaths or affirmations to support the Constitution. This means that the states' constitutions and laws should not conflict with the laws of the federal constitution and that in case of a conflict, state judges are legally bound to honor the federal laws and constitution over those of any state. Article Six also states ""no religious Test shall ever be required as a Qualification to any Office or public Trust under the United States.""
",2
2239,"Article VII describes the process for establishing the proposed new frame of government. Anticipating that the influence of many state politicians would be Antifederalist, delegates to the Philadelphia Convention provided for ratification of the Constitution by popularly elected ratifying conventions in each state. The convention method also made it possible that judges, ministers and others ineligible to serve in state legislatures, could be elected to a convention. Suspecting that Rhode Island, at least, might not ratify, delegates decided that the Constitution would go into effect as soon as nine states (two-thirds rounded up) ratified.[57] Once ratified by this minimum number of states, it was anticipated that the proposed Constitution would become this Constitution between the nine or more that signed. It would not cover the four or fewer states that might not have signed.[58]
",2
2240,"The signing of the United States Constitution occurred on September 17, 1787, when 39 delegates to the Constitutional Convention endorsed the constitution created during the convention. In addition to signatures, this closing endorsement, the Constitution's eschatocol, included a brief declaration that the delegates' work has been successfully completed and that those whose signatures appear on it subscribe to the final document. Included are a statement pronouncing the document's adoption by the states present, a formulaic dating of its adoption, and the signatures of those endorsing it. Additionally, the convention's secretary, William Jackson, added a note to verify four amendments made by hand to the final document, and signed the note to authenticate its validity.[59]
",2
2241,"The language of the concluding endorsement, conceived by Gouverneur Morris and presented to the convention by Benjamin Franklin, was made intentionally ambiguous in hopes of winning over the votes of dissenting delegates. Advocates for the new frame of government, realizing the impending difficulty of obtaining the consent of the states needed to make it operational, were anxious to obtain the unanimous support of the delegations from each state. It was feared that many of the delegates would refuse to give their individual assent to the Constitution. Therefore, in order that the action of the convention would appear to be unanimous, the formula, Done in convention by the unanimous consent of the states present ... was devised.[60]
",2
2242,"The document is dated: ""the Seventeenth Day of September in the Year of our Lord"" 1787, and ""of the Independence of the United States of America the Twelfth."" This two-fold epoch dating serves to place the Constitution in the context of the religious traditions of Western civilization and, at the same time, links it to the regime principles proclaimed in the Declaration of Independence. This dual reference can also be found in the Articles of Confederation and the Northwest Ordinance.[60]
",2
2243,"The closing endorsement serves an authentication function only. It neither assigns powers to the federal government nor does it provide specific limitations on government action. It does, however, provide essential documentation of the Constitution's validity, a statement of ""This is what was agreed to."" It records who signed the Constitution, and when and where.
",2
2244,"The procedure for amending the Constitution is outlined in Article Five (see above). The process is overseen by the archivist of the United States. Between 1949 and 1985, it was overseen by the administrator of General Services, and before that by the secretary of state.[56]
",2
2245,"Under Article Five, a proposal for an amendment must be adopted either by Congress or by a national convention, but as of 2020[update] all amendments have gone through Congress.[56] The proposal must receive two-thirds of the votes of both houses to proceed. It is passed as a joint resolution, but is not presented to the president, who plays no part in the process. Instead, it is passed to the Office of the Federal Register, which copies it in slip law format and submits it to the states.[56] Congress decides whether the proposal is to be ratified in the state legislature or by a state ratifying convention. To date all amendments have been ratified by the state legislatures except one, the Twenty-first Amendment.[54]
",2
2246,"A proposed amendment becomes an operative part of the Constitution as soon as it is ratified by three-fourths of the States (currently 38 of the 50 states). There is no further step. The text requires no additional action by Congress or anyone else after ratification by the required number of states.[61] Thus, when the Office of the Federal Register verifies that it has received the required number of authenticated ratification documents, it drafts a formal proclamation for the Archivist to certify that the amendment is valid and has become part of the nation's frame of government. This certification is published in the Federal Register and United States Statutes at Large and serves as official notice to Congress and to the nation that the ratification process has been successfully completed.[56]
",2
2247,"The Constitution has twenty-seven amendments. Structurally, the Constitution's original text and all prior amendments remain untouched. The precedent for this practice was set in 1789, when Congress considered and proposed the first several Constitutional amendments. Among these, Amendments 1–10 are collectively known as the Bill of Rights, and Amendments 13–15 are known as the Reconstruction Amendments. Excluding the Twenty-seventh Amendment, which was pending before the states for 202 years, 225 days, the longest pending amendment that was successfully ratified was the Twenty-second Amendment, which took 3 years, 343 days. The Twenty-sixth Amendment was ratified in the shortest time, 100 days. The average ratification time for the first twenty-six amendments was 1 year, 252 days; for all twenty-seven, 9 years, 48 days.
",2
2248,"The First Amendment (1791) prohibits Congress from obstructing the exercise of certain individual freedoms: freedom of religion, freedom of speech, freedom of the press, freedom of assembly, and right to petition. Its Free Exercise Clause guarantees a person's right to hold whatever religious beliefs they want, and to freely exercise that belief, and its Establishment Clause prevents the federal government from creating an official national church or favoring one set of religious beliefs over another. The amendment guarantees an individual's right to express and to be exposed to a wide range of opinions and views. It was intended to ensure a free exchange of ideas, even unpopular ones. It also guarantees an individual's right to physically gather or associate with others in groups for economic, political or religious purposes. Additionally, it guarantees an individual's right to petition the government for a redress of grievances.[62]
",2
2249,"The Second Amendment (1791) protects the right of individuals[63][64] to keep and bear arms.[65][66][67][68] Although the Supreme Court has ruled that this right applies to individuals, not merely to collective militias, it has also held that the government may regulate or place some limits on the manufacture, ownership and sale of firearms or other weapons.[69][70] Requested by several states during the Constitutional ratification debates, the amendment reflected the lingering resentment over the widespread efforts of the British to confiscate the colonists' firearms at the outbreak of the Revolutionary War. Patrick Henry had rhetorically asked, shall we be stronger, ""when we are totally disarmed, and when a British Guard shall be stationed in every house?""[71]
",2
2250,"The Third Amendment (1791) prohibits the federal government from forcing individuals to provide lodging to soldiers in their homes during peacetime without their consent. Requested by several states during the Constitutional ratification debates, the amendment reflected the lingering resentment over the Quartering Acts passed by the British Parliament during the Revolutionary War, which had allowed British soldiers to take over private homes for their own use.[72]
",2
2251,"The Fourth Amendment (1791) protects people against unreasonable searches and seizures of either self or property by government officials. A search can mean everything from a frisking by a police officer or to a demand for a blood test to a search of an individual's home or car. A seizure occurs when the government takes control of an individual or something in his or her possession. Items that are seized often are used as evidence when the individual is charged with a crime. It also imposes certain limitations on police investigating a crime and prevents the use of illegally obtained evidence at trial.[73]
",2
2252,"The Fifth Amendment (1791) establishes the requirement that a trial for a major crime may commence only after an indictment has been handed down by a grand jury; protects individuals from double jeopardy, being tried and put in danger of being punished more than once for the same criminal act; prohibits punishment without due process of law, thus protecting individuals from being imprisoned without fair procedures; and provides that an accused person may not be compelled to reveal to the police, prosecutor, judge, or jury any information that might incriminate or be used against him or her in a court of law. Additionally, the Fifth Amendment also prohibits government from taking private property for public use without ""just compensation"", the basis of eminent domain in the United States.[74]
",2
2253,"The Sixth Amendment (1791) provides several protections and rights to an individual accused of a crime. The accused has the right to a fair and speedy trial by a local and impartial jury. Likewise, a person has the right to a public trial. This right protects defendants from secret proceedings that might encourage abuse of the justice system, and serves to keep the public informed. This amendment also guarantees a right to legal counsel if accused of a crime, guarantees that the accused may require witnesses to attend the trial and testify in the presence of the accused, and guarantees the accused a right to know the charges against them. In 1966, the Supreme Court ruled that, with the Fifth Amendment, this amendment requires what has become known as the Miranda warning.[75]
",2
2254,"The Seventh Amendment (1791) extends the right to a jury trial to federal civil cases, and inhibits courts from overturning a jury's findings of fact. Although the Seventh Amendment itself says that it is limited to ""suits at common law"", meaning cases that triggered the right to a jury under English law, the amendment has been found to apply in lawsuits that are similar to the old common law cases. For example, the right to a jury trial applies to cases brought under federal statutes that prohibit race or gender discrimination in housing or employment. Importantly, this amendment guarantees the right to a jury trial only in federal court, not in state court.[76]
",2
2255,"The Eighth Amendment (1791) protects people from having bail or fines set at an amount so high that it would be impossible for all but the richest defendants to pay and also protects people from being subjected to cruel and unusual punishment. Although this phrase originally was intended to outlaw certain gruesome methods of punishment, it has been broadened over the years to protect against punishments that are grossly disproportionate to or too harsh for the particular crime. This provision has also been used to challenge prison conditions such as extremely unsanitary cells, overcrowding, insufficient medical care and deliberate failure by officials to protect inmates from one another.[77]
",2
2256,"The Ninth Amendment (1791) declares that individuals have other fundamental rights, in addition to those stated in the Constitution. During the Constitutional ratification debates Anti-Federalists argued that a Bill of Rights should be added. The Federalists opposed it on grounds that a list would necessarily be incomplete but would be taken as explicit and exhaustive, thus enlarging the power of the federal government by implication. The Anti-Federalists persisted, and several state ratification conventions refused to ratify the Constitution without a more specific list of protections, so the First Congress added what became the Ninth Amendment as a compromise. Because the rights protected by the Ninth Amendment are not specified, they are referred to as ""unenumerated"". The Supreme Court has found that unenumerated rights include such important rights as the right to travel, the right to vote, the right to privacy, and the right to make important decisions about one's health care or body.[78]
",2
2257,"The Tenth Amendment (1791) was included in the Bill of Rights to further define the balance of power between the federal government and the states. The amendment states that the federal government has only those powers specifically granted by the Constitution. These powers include the power to declare war, to collect taxes, to regulate interstate business activities and others that are listed in the articles or in subsequent constitutional amendments. Any power not listed is, says the Tenth Amendment, left to the states or the people. While there is no specific list of what these ""reserved powers"" may be, the Supreme Court has ruled that laws affecting family relations, commerce within a state's own borders, and local law enforcement activities, are among those specifically reserved to the states or the people.[79]
",2
2258,"The Eleventh Amendment (1795) specifically prohibits federal courts from hearing cases in which a state is sued by an individual from another state or another country, thus extending to the states sovereign immunity protection from certain types of legal liability. Article Three, Section 2, Clause 1 has been affected by this amendment, which also overturned the Supreme Court's decision in Chisholm v. Georgia (1793).[80][81]
",2
2259,"The Sixteenth Amendment (1913) removed existing Constitutional constraints that limited the power of Congress to lay and collect taxes on income. Specifically, the apportionment constraints delineated in Article 1, Section 9, Clause 4 have been removed by this amendment, which also overturned an 1895 Supreme Court decision, in Pollock v. Farmers' Loan & Trust Co., that declared an unapportioned federal income tax on rents, dividends, and interest unconstitutional. This amendment has become the basis for all subsequent federal income tax legislation and has greatly expanded the scope of federal taxing and spending in the years since.[82]
",2
2260,"The Eighteenth Amendment (1919) prohibited the making, transporting, and selling of alcoholic beverages nationwide. It also authorized Congress to enact legislation enforcing this prohibition. Adopted at the urging of a national temperance movement, proponents believed that the use of alcohol was reckless and destructive and that prohibition would reduce crime and corruption, solve social problems, decrease the need for welfare and prisons, and improve the health of all Americans. During prohibition, it is estimated that alcohol consumption and alcohol related deaths declined dramatically. But prohibition had other, more negative consequences. The amendment drove the lucrative alcohol business underground, giving rise to a large and pervasive black market. In addition, prohibition encouraged disrespect for the law and strengthened organized crime. Prohibition came to an end in 1933, when this amendment was repealed.[83]
",2
2261,"The Twenty-first Amendment (1933) repealed the Eighteenth Amendment and returned the regulation of alcohol to the states. Each state sets its own rules for the sale and importation of alcohol, including the drinking age. Because a federal law provides federal funds to states that prohibit the sale of alcohol to minors under the age of twenty-one, all fifty states have set their drinking age there. Rules about how alcohol is sold vary greatly from state to state.[84]
",2
2262,"The Thirteenth Amendment (1865) abolished slavery and involuntary servitude, except as punishment for a crime, and authorized Congress to enforce abolition. Though millions of slaves had been declared free by the 1863 Emancipation Proclamation, their post Civil War status was unclear, as was the status of other millions.[85] Congress intended the Thirteenth Amendment to be a proclamation of freedom for all slaves throughout the nation and to take the question of emancipation away from politics. This amendment rendered inoperative or moot several of the original parts of the constitution.[86]
",2
2263,"The Fourteenth Amendment (1868) granted United States citizenship to former slaves and to all persons ""subject to U.S. jurisdiction"". It also contained three new limits on state power: a state shall not violate a citizen's privileges or immunities; shall not deprive any person of life, liberty, or property without due process of law; and must guarantee all persons equal protection of the laws. These limitations dramatically expanded the protections of the Constitution. This amendment, according to the Supreme Court's Doctrine of Incorporation, makes most provisions of the Bill of Rights applicable to state and local governments as well. It superseded the mode of apportionment of representatives delineated in Article 1, Section 2, Clause 3, and also overturned the Supreme Court's decision in Dred Scott v. Sandford (1857).[87]
",2
2264,"The Fifteenth Amendment (1870) prohibits the use of race, color, or previous condition of servitude in determining which citizens may vote. The last of three post Civil War Reconstruction Amendments, it sought to abolish one of the key vestiges of slavery and to advance the civil rights and liberties of former slaves.[88]
",2
2265,"The Nineteenth Amendment (1920) prohibits the government from denying women the right to vote on the same terms as men. Prior to the amendment's adoption, only a few states permitted women to vote and to hold office.[89]
",2
2266,"The Twenty-third Amendment (1961) extends the right to vote in presidential elections to citizens residing in the District of Columbia by granting the District electors in the Electoral College, as if it were a state. When first established as the nation's capital in 1800, the District of Columbia's five thousand residents had neither a local government, nor the right to vote in federal elections. By 1960 the population of the District had grown to over 760,000.[90]
",2
2267,"The Twenty-fourth Amendment (1964) prohibits a poll tax for voting. Although passage of the Thirteenth, Fourteenth, and Fifteenth Amendments helped remove many of the discriminatory laws left over from slavery, they did not eliminate all forms of discrimination. Along with literacy tests and durational residency requirements, poll taxes were used to keep low-income (primarily African American) citizens from participating in elections. The Supreme Court has since struck down these discriminatory measures, opening democratic participation to all.[91]
",2
2268,"The Twenty-sixth Amendment (1971) prohibits the government from denying the right of United States citizens, eighteen years of age or older, to vote on account of age. The drive to lower the voting age was driven in large part by the broader student activism movement protesting the Vietnam War. It gained strength following the Supreme Court's decision in Oregon v. Mitchell (1970).[92]
",2
2269,"The Twelfth Amendment (1804) modifies the way the Electoral College chooses the President and Vice President. It stipulates that each elector must cast a distinct vote for president and Vice President, instead of two votes for president. It also suggests that the President and Vice President should not be from the same state. Article II, Section 1, Clause 3 is superseded by this amendment, which also extends the eligibility requirements to become president to the Vice President.[93]
",2
2270,"The Seventeenth Amendment (1913) modifies the way senators are elected. It stipulates that senators are to be elected by direct popular vote. The amendment supersedes Article 1, Section 2, Clauses 1 and 2, under which the two senators from each state were elected by the state legislature. It also allows state legislatures to permit their governors to make temporary appointments until a special election can be held.[94]
",2
2271,"The Twentieth Amendment (1933) changes the date on which a new president, Vice President and Congress take office, thus shortening the time between Election Day and the beginning of Presidential, Vice Presidential and Congressional terms.[95] Originally, the Constitution provided that the annual meeting was to be on the first Monday in December unless otherwise provided by law. This meant that, when a new Congress was elected in November, it did not come into office until the following March, with a ""lame duck"" Congress convening in the interim. By moving the beginning of the president's new term from March 4 to January 20 (and in the case of Congress, to January 3), proponents hoped to put an end to lame duck sessions, while allowing for a speedier transition for the new administration and legislators.[96]
",2
2272,"The Twenty-second Amendment (1951) limits an elected president to two terms in office, a total of eight years. However, under some circumstances it is possible for an individual to serve more than eight years. Although nothing in the original frame of government limited how many presidential terms one could serve, the nation's first president, George Washington, declined to run for a third term, suggesting that two terms of four years were enough for any president. This precedent remained an unwritten rule of the presidency until broken by Franklin D. Roosevelt, who was elected to a third term as president 1940 and in 1944 to a fourth.[97]
",2
2273,"The Twenty-fifth Amendment (1967) clarifies what happens upon the death, removal, or resignation of the President or Vice President and how the Presidency is temporarily filled if the President becomes disabled and cannot fulfill the responsibilities of the office. It supersedes the ambiguous succession rule established in Article II, Section 1, Clause 6. A concrete plan of succession has been needed on multiple occasions since 1789. However, for nearly 20% of U.S. history, there has been no vice president in office who can assume the presidency.[98]
",2
2274,"The Twenty-seventh Amendment (1992) prevents members of Congress from granting themselves pay raises during the current session. Rather, any raises that are adopted must take effect during the next session of Congress. Its proponents believed that Federal legislators would be more likely to be cautious about increasing congressional pay if they have no personal stake in the vote. Article One, section 6, Clause 1 has been affected by this amendment, which remained pending for over two centuries as it contained no time limit for ratification.[99]
",2
2275,"Collectively, members of the House and Senate typically propose around 150 amendments during each two-year term of Congress.[100] Most however, never get out of the Congressional committees in which they were proposed, and only a fraction of those that do receive enough support to win Congressional approval to actually go through the constitutional ratification process.
",2
2276,"Six amendments approved by Congress and proposed to the states for consideration have not been ratified by the required number of states to become part of the Constitution. Four of these are technically still pending, as Congress did not set a time limit (see also Coleman v. Miller) for their ratification. The other two are no longer pending, as both had a time limit attached and in both cases the time period set for their ratification expired.
",2
2277,"The Equal Rights Amendment (proposed 1972) would have prohibited deprivation of equality of rights (discrimination) by the federal or state governments on account of sex. A seven-year ratification time limit was initially placed on the amendment, but as the deadline approached, Congress granted a three-year extension. Thirty-five states ratified the proposed amendment prior to the original deadline, three short of the number required for it to be implemented (five of them later voted to rescind their ratification). No further states ratified the amendment within the extended deadline. In 2017, Nevada became the first state to ratify the ERA after the expiration of both deadlines,[104] followed by Illinois in 2018,[105] and Virginia in 2020,[106][107] purportedly bringing the number of ratifications to 38. However, experts and advocates have acknowledged legal uncertainty about the consequences of these ratifications, due to the expired deadlines and the five states' purported revocations.[h]
",2
2278,"The District of Columbia Voting Rights Amendment (proposed 1978) would have granted the District of Columbia full representation in the United States Congress as if it were a state, repealed the Twenty-third Amendment, granted the District unconditional Electoral College voting rights, and allowed its participation in the process by which the Constitution is amended. A seven-year ratification time limit was placed on the amendment. Sixteen states ratified the amendment (twenty-two short of the number required for it to be implemented) prior to the deadline, thus it failed to be adopted.
",2
2279,"The way the Constitution is understood is influenced by court decisions, especially those of the Supreme Court. These decisions are referred to as precedents. Judicial review is the power of the Court to examine federal legislation, federal executive, and all state branches of government, to decide their constitutionality, and to strike them down if found unconstitutional.
",2
2280,"Judicial review includes the power of the Court to explain the meaning of the Constitution as it applies to particular cases. Over the years, Court decisions on issues ranging from governmental regulation of radio and television to the rights of the accused in criminal cases have changed the way many constitutional clauses are interpreted, without amendment to the actual text of the Constitution.
",2
2281,"Legislation passed to implement the Constitution, or to adapt those implementations to changing conditions, broadens and, in subtle ways, changes the meanings given to the words of the Constitution. Up to a point, the rules and regulations of the many federal executive agencies have a similar effect. If an action of Congress or the agencies is challenged, however, it is the court system that ultimately decides whether these actions are permissible under the Constitution.
",2
2282,"The Supreme Court has indicated that once the Constitution has been extended to an area (by Congress or the Courts), its coverage is irrevocable. To hold that the political branches may switch the Constitution on or off at will would lead to a regime in which they, not this Court, say ""what the law is"".[i]
",2
2283,"Courts established by the Constitution can regulate government under the Constitution, the supreme law of the land. First, they have jurisdiction over actions by an officer of government and state law. Second, federal courts may rule on whether coordinate branches of national government conform to the Constitution. Until the twentieth century, the Supreme Court of the United States may have been the only high tribunal in the world to use a court for constitutional interpretation of fundamental law, others generally depending on their national legislature.[109]
",2
2284,"John Jay, 1789–1795New York co-authorThe Federalist Papers
",2
2285,"John Marshall, 1801–1835Fauquier County delegateVirginia Ratification Convention
",2
2286,"The basic theory of American Judicial review is summarized by constitutional legal scholars and historians as follows: the written Constitution is fundamental law. It can change only by extraordinary legislative process of national proposal, then state ratification. The powers of all departments are limited to enumerated grants found in the Constitution. Courts are expected (a) to enforce provisions of the Constitution as the supreme law of the land, and (b) to refuse to enforce anything in conflict with it.[110]
",2
2287,"In Convention. As to judicial review and the Congress, the first proposals by Madison (Va) and Wilson (Pa) called for a supreme court veto over national legislation. In this it resembled the system in New York, where the Constitution of 1777 called for a ""Council of Revision"" by the Governor and Justices of the state supreme court. The council would review and in a way, veto any passed legislation violating the spirit of the Constitution before it went into effect. The nationalist's proposal in Convention was defeated three times, and replaced by a presidential veto with Congressional over-ride. Judicial review relies on the jurisdictional authority in Article III, and the Supremacy Clause.[111]
",2
2288,"The justification for judicial review is to be explicitly found in the open ratifications held in the states and reported in their newspapers. John Marshall in Virginia, James Wilson in Pennsylvania and Oliver Ellsworth of Connecticut all argued for Supreme Court judicial review of acts of state legislature. In Federalist No. 78, Alexander Hamilton advocated the doctrine of a written document held as a superior enactment of the people. ""A limited constitution can be preserved in practice no other way"" than through courts which can declare void any legislation contrary to the Constitution. The preservation of the people's authority over legislatures rests ""particularly with judges"".[112][j]
",2
2289,"The Supreme Court was initially made up of jurists who had been intimately connected with the framing of the Constitution and the establishment of its government as law.  John Jay (New York), a co-author of The Federalist Papers, served as Chief Justice for the first six years.  The second and third Chief Justices, Oliver Ellsworth (Connecticut) and John Rutledge (South Carolina), were delegates to the Constitutional Convention.  Washington's recess appointment as Chief Justice who served in 1795. John Marshall (Virginia), the fourth Chief Justice, had served in the Virginia Ratification Convention in 1788.  His 34 years of service on the Court would see some of the most important rulings to help establish the nation the Constitution had begun.  Other early members of the Supreme Court who had been delegates to the Constitutional Convention included James Wilson (Pennsylvania) for ten years, John Blair Jr. (Virginia) for five, and John Rutledge (South Carolina) for one year as Justice, then Chief Justice in 1795.
",2
2290,"When John Marshall followed Oliver Ellsworth as Chief Justice of the Supreme Court in 1801, the federal judiciary had been established by the Judiciary Act, but there were few cases, and less prestige. ""The fate of judicial review was in the hands of the Supreme Court itself."" Review of state legislation and appeals from state supreme courts was understood. But the Court's life, jurisdiction over state legislation was limited. The Marshall Court's landmark Barron v. Baltimore held that the Bill of Rights restricted only the federal government, and not the states.[112]
",2
2291,"In the landmark Marbury v. Madison case, the Supreme Court asserted its authority of judicial review over Acts of Congress. Its findings were that Marbury and the others had a right to their commissions as judges in the District of Columbia. Marshall, writing the opinion for the majority, announced his discovered conflict between Section 13 of the Judiciary Act of 1789 and Article III.[k][114][l] In this case, both the Constitution and the statutory law applied to the particulars at the same time. ""The very essence of judicial duty"" according to Marshall was to determine which of the two conflicting rules should govern. The Constitution enumerates powers of the judiciary to extend to cases arising ""under the Constitution"". Further, justices take a Constitutional oath to uphold it as ""Supreme law of the land"".[115] Therefore, since the United States government as created by the Constitution is a limited government, the Federal courts were required to choose the Constitution over Congressional law if there were deemed to be a conflict.
",2
2292,"""This argument has been ratified by time and by practice ...""[m][n] The Supreme Court did not declare another Act of Congress unconstitutional until the controversial Dred Scott decision in 1857, held after the voided Missouri Compromise statute had already been repealed. In the eighty years following the Civil War to World War II, the Court voided Congressional statutes in 77 cases, on average almost one a year.[117]
",2
2293,"Something of a crisis arose when, in 1935 and 1936, the Supreme Court handed down twelve decisions voiding Acts of Congress relating to the New Deal. President Franklin D. Roosevelt then responded with his abortive ""court packing plan"". Other proposals have suggested a Court super-majority to overturn Congressional legislation, or a Constitutional Amendment to require that the Justices retire at a specified age by law. To date, the Supreme Court's power of judicial review has persisted.[113]
",2
2294,"The power of judicial review could not have been preserved long in a democracy unless it had been ""wielded with a reasonable measure of judicial restraint, and with some attention, as Mr. Dooley said, to the election returns."" Indeed, the Supreme Court has developed a system of doctrine and practice that self-limits its power of judicial review.[118]
",2
2295,"The Court controls almost all of its business by choosing what cases to consider, writs of certiorari. In this way, it can avoid opinions on embarrassing or difficult cases. The Supreme Court limits itself by defining for itself what is a ""justiciable question"". First, the Court is fairly consistent in refusing to make any ""advisory opinions"" in advance of actual cases.[o] Second, ""friendly suits"" between those of the same legal interest are not considered. Third, the Court requires a ""personal interest"", not one generally held, and a legally protected right must be immediately threatened by government action. Cases are not taken up if the litigant has no standing to sue. Simply having the money to sue and being injured by government action are not enough.[118]
",2
2296,"These three procedural ways of dismissing cases have led critics to charge that the Supreme Court delays decisions by unduly insisting on technicalities in their ""standards of litigability"". They say cases are left unconsidered which are in the public interest, with genuine controversy, and resulting from good faith action. ""The Supreme Court is not only a court of law but a court of justice.""[119]
",2
2297,"The Supreme Court balances several pressures to maintain its roles in national government. It seeks to be a co-equal branch of government, but its decrees must be enforceable. The Court seeks to minimize situations where it asserts itself superior to either President or Congress, but federal officers must be held accountable. The Supreme Court assumes power to declare acts of Congress as unconstitutional but it self-limits its passing on constitutional questions.[120] But the Court's guidance on basic problems of life and governance in a democracy is most effective when American political life reinforce its rulings.[121]
",2
2298,"Justice Brandeis summarized four general guidelines that the Supreme Court uses to avoid constitutional decisions relating to Congress:[p] The Court will not anticipate a question of constitutional law nor decide open questions unless a case decision requires it. If it does, a rule of constitutional law is formulated only as the precise facts in the case require. The Court will choose statutes or general law for the basis of its decision if it can without constitutional grounds. If it does, the Court will choose a constitutional construction of an Act of Congress, even if its constitutionality is seriously in doubt. [120]
",2
2299,"Likewise with the Executive Department, Edwin Corwin observed that the Court does sometimes rebuff presidential pretensions, but it more often tries to rationalize them. Against Congress, an Act is merely ""disallowed"". In the executive case, exercising judicial review produces ""some change in the external world"" beyond the ordinary judicial sphere.[122] The ""political question"" doctrine especially applies to questions which present a difficult enforcement issue. Chief Justice Charles Evans Hughes addressed the Court's limitation when political process allowed future policy change, but a judicial ruling would ""attribute finality"". Political questions lack ""satisfactory criteria for a judicial determination"".[123]
",2
2300,"John Marshall recognized that the president holds ""important political powers"" which as executive privilege allows great discretion. This doctrine was applied in Court rulings on President Grant's duty to enforce the law during Reconstruction. It extends to the sphere of foreign affairs. Justice Robert Jackson explained, Foreign affairs are inherently political, ""wholly confided by our Constitution to the political departments of the government ... [and] not subject to judicial intrusion or inquiry.""[124]
",2
2301,"Critics of the Court object in two principal ways to self-restraint in judicial review, deferring as it does as a matter of doctrine to Acts of Congress and Presidential actions.
",2
2302,"Supreme Courts under the leadership of subsequent Chief Justices have also used judicial review to interpret the Constitution among individuals, states and federal branches. Notable contributions were made by the Chase Court, the Taft Court, the Warren Court, and the Rehnquist Court.
",2
2303,"Salmon P. Chase was a Lincoln appointee, serving as Chief Justice from 1864 to 1873. His career encompassed service as a U.S. senator and Governor of Ohio. He coined the slogan, ""Free soil, free Labor, free men."" One of Lincoln's ""team of rivals"", he was appointed Secretary of Treasury during the Civil War, issuing ""greenbacks"". To appease radical Republicans, Lincoln appointed him to replace Chief Justice Roger B. Taney of Dred Scott case fame.
",2
2304,"In one of his first official acts, Chase admitted John Rock, the first African-American to practice before the Supreme Court. The ""Chase Court"" is famous for Texas v. White, which asserted a permanent Union of indestructible states. Veazie Bank v. Fenno upheld the Civil War tax on state banknotes. Hepburn v. Griswold found parts of the Legal Tender Acts unconstitutional, though it was reversed under a late Supreme Court majority.
",2
2305,"Salmon P. Chase [q]Union, Reconstruction
",2
2306,"William Howard Taft [r]commerce, incorporation
",2
2307,"Earl Warren [s]due process, civil rights
",2
2308,"William Rehnquist [t]federalism, privacy
",2
2309,"William Howard Taft was a Harding appointment to Chief Justice from 1921 to 1930. A Progressive Republican from Ohio, he was a one-term President.
",2
2310,"As Chief Justice, he advocated the Judiciary Act of 1925 that brought the Federal District Courts under the administrative jurisdiction of the Supreme Court. Taft successfully sought the expansion of Court jurisdiction over non-states such as District of Columbia and Territories of Alaska and Hawaii.
",2
2311,"In 1925, the Taft Court issued a ruling overturning a Marshall Court ruling on the Bill of Rights. In Gitlow v. New York, the Court established the doctrine of ""incorporation which applied the Bill of Rights to the states. Important cases included the Board of Trade of City of Chicago v. Olsen that upheld Congressional regulation of commerce. Olmstead v. United States allowed exclusion of evidence obtained without a warrant based on application of the 14th Amendment proscription against unreasonable searches. Wisconsin v. Illinois ruled the equitable power of the United States can impose positive action on a state to prevent its inaction from damaging another state.
",2
2312,"Earl Warren was an Eisenhower nominee, Chief Justice from 1953 to 1969. Warren's Republican career in the law reached from County Prosecutor, California state attorney general, and three consecutive terms as Governor. His programs stressed progressive efficiency, expanding state education, re-integrating returning veterans, infrastructure and highway construction.
",2
2313,"In 1954, the Warren Court overturned a landmark Fuller Court ruling on the Fourteenth Amendment interpreting racial segregation as permissible in government and commerce providing ""separate but equal"" services. Warren built a coalition of Justices after 1962 that developed the idea of natural rights as guaranteed in the Constitution. Brown v. Board of Education banned segregation in public schools. Baker v. Carr and Reynolds v. Sims established Court ordered ""one-man-one-vote"". Bill of Rights Amendments were incorporated into the states. Due process was expanded in Gideon v. Wainwright and Miranda v. Arizona. First Amendment rights were addressed in Griswold v. Connecticut concerning privacy, and Engel v. Vitale relative to free speech.
",2
2314,"William Rehnquist was a Reagan appointment to Chief Justice, serving from 1986 to 2005. While he would concur with overthrowing a state supreme court's decision, as in Bush v. Gore, he built a coalition of Justices after 1994 that developed the idea of federalism as provided for in the Tenth Amendment. In the hands of the Supreme Court, the Constitution and its Amendments were to restrain Congress, as in City of Boerne v. Flores.
",2
2315,"Nevertheless, the Rehnquist Court was noted in the contemporary ""culture wars"" for overturning state laws relating to privacy prohibiting late-term abortions in Stenberg v. Carhart, prohibiting sodomy in Lawrence v. Texas, or ruling so as to protect free speech in Texas v. Johnson or affirmative action in Grutter v. Bollinger.
",2
2316,"There is a viewpoint that some Americans have come to see the documents of the Constitution, along with the Declaration of Independence and the Bill of Rights, as being a cornerstone of a type of civil religion. This is suggested by the prominent display of the Constitution, along with the Declaration of Independence and the Bill of Rights, in massive, bronze-framed, bulletproof, moisture-controlled glass containers vacuum-sealed in a rotunda by day and in multi-ton bomb-proof vaults by night at the National Archives Building.[126]
",2
2317,"The idea of displaying the documents struck one academic critic looking from the point of view of the 1776 or 1789 America as ""idolatrous, and also curiously at odds with the values of the Revolution"".[126] By 1816, Jefferson wrote that ""[s]ome men look at constitutions with sanctimonious reverence and deem them like the Ark of the Covenant, too sacred to be touched"". But he saw imperfections and imagined that there could potentially be others, believing as he did that ""institutions must advance also"".[127]
",2
2318,"Some commentators depict the multi-ethnic, multi-sectarian United States as held together by a political orthodoxy, in contrast with a nation state of people having more ""natural"" ties.[128][129]
",2
2319,"José Rizal
",2
2320,"Sun Yat-sen
",2
2321,"The United States Constitution has been a notable model for governance around the world. Its international influence is found in similarities of phrasing and borrowed passages in other constitutions, as well as in the principles of the rule of law, separation of powers and recognition of individual rights. 
",2
2322,"The American experience of fundamental law with amendments and judicial review has motivated constitutionalists at times when they were considering the possibilities for their nation's future.[130] It informed Abraham Lincoln during the American Civil War,[u] his contemporary and ally Benito Juárez of Mexico,[v] and the second generation of 19th-century constitutional nationalists, José Rizal of the Philippines[w] and Sun Yat-sen of China.[x] The framers of the Australian constitution integrated federal ideas from the U.S. and other constitutions.[136]
",2
2323,"Since the latter half of the 20th century, the influence of the United States Constitution may be waning as other countries have revised their constitutions with new influences.[137][138]
",2
2324,"The United States Constitution has faced various criticisms since its inception in 1787.
",2
2325,"The Constitution did not originally define who was eligible to vote, allowing each state to determine who was eligible. In the early history of the U.S., most states allowed only white male adult property owners to vote.[139][140][141] Until the Reconstruction Amendments were adopted between 1865 and 1870, the five years immediately following the Civil War, the Constitution did not abolish slavery, nor give citizenship and voting rights to former slaves.[142] These amendments did not include a specific prohibition on discrimination in voting on the basis of sex; it took another amendment—the Nineteenth, ratified in 1920—for the Constitution to prohibit any United States citizen from being denied the right to vote on the basis of sex.[143]
",2
2326,"According to a 2012 study by David Law of Washington University published in the New York University Law Review, the U.S. Constitution guarantees relatively few rights compared to the constitutions of other countries and contains fewer than half (26 of 60) of the provisions listed in the average bill of rights. It is also one of the few in the world today that still features the right to keep and bear arms; the only others are the constitutions of Guatemala and Mexico.[137][138]
",2
2327,"Earlier written constitutions of independent states exist but were not adopted by bodies elected by the people, such as the Swedish Constitution of 1772, adopted by the king, the Constitution of San Marino of 1600 which is the oldest surviving constitution in the world, or the Constitution of Pylyp Orlyk, the first establishing separation of powers.
",2
2328,"
",2
2329,"
Coordinates: .mw-parser-output .geo-default,.mw-parser-output .geo-dms,.mw-parser-output .geo-dec{display:inline}.mw-parser-output .geo-nondefault,.mw-parser-output .geo-multi-punct{display:none}.mw-parser-output .longitude,.mw-parser-output .latitude{white-space:nowrap}38°53′26″N 77°0′32″W﻿ / ﻿38.89056°N 77.00889°W﻿ / 38.89056; -77.00889
",2
2330,"Minority (50)
",2
2331,"The United States Senate is the upper chamber of the United States Congress, which, along with the United States House of Representatives—the lower chamber—constitutes the legislature of the United States. The composition and powers of the Senate are established by Article One of the United States Constitution.[2]  The Senate is composed of senators, each of whom represents a single state in its entirety. Each state is equally represented by two senators who serve staggered terms of six years. There are currently 100 senators representing the 50 states. The Senate president and presiding officer is the Vice President of the United States by virtue of that office who has a vote only if the senators are equally divided. In the vice president's absence, the president pro tempore, who is traditionally the senior member of the party holding a majority of seats, presides over the Senate. 
",2
2332,"As the upper chamber of Congress, the Senate has several powers of advice and consent which are unique to it. These include the approval of treaties, and the confirmation of Cabinet secretaries, Supreme Court justices, federal judges, flag officers, regulatory officials, ambassadors, other federal executive officials and federal uniformed officers. If no candidate receives a majority of electors for vice president, the duty falls to the Senate to elect one of the top two recipients of electors for that office. The Senate conducts trials of those impeached by the House.
",2
2333,"The Senate is widely considered both a more deliberative[3] and more prestigious[4][5][6] body than the House of Representatives due to its longer terms, smaller size, and statewide constituencies, which historically led to a more collegial and less partisan atmosphere.[7]
",2
2334,"From 1789 to 1913, senators were appointed by legislatures of the states they represented.  They are now elected by popular vote following the ratification of the Seventeenth Amendment in 1913. In the early 20th century[when?], the practice of majority and minority parties electing their floor leaders began. The Senate's legislative and executive business is managed and scheduled by the Senate majority leader.
",2
2335,"The Senate chamber is located in the north wing of the Capitol Building in Washington, D.C.
",2
2336,"The drafters of the Constitution created a bicameral Congress primarily as a compromise between those who felt that each state, since it was sovereign, should be equally represented, and those who felt the legislature must directly represent the people, as the House of Commons did in Great Britain. This idea of having one chamber represent people equally, while the other gives equal representation to states regardless of population, was known as the Connecticut Compromise. There was also a desire to have two Houses that could act as an internal check on each other. One was intended to be a ""People's House"" directly elected by the people, and with short terms obliging the representatives to remain close to their constituents. The other was intended to represent the states to such extent as they retained their sovereignty except for the powers expressly delegated to the national government. The Constitution provides that the approval of both chambers is necessary for the passage of legislation.[8]
",2
2337,"First convened in 1789, the Senate of the United States was formed on the example of the ancient Roman Senate. The name is derived from the senatus, Latin for council of elders (from senex meaning old man in Latin).[9]
",2
2338,"James Madison made the following comment about the Senate:
",2
2339,"In England, at this day, if elections were open to all classes of people, the property of landed proprietors would be insecure. An agrarian law would soon take place. If these observations remain just, our government ought to secure the permanent interests of the country against innovation. Landholders ought to have a share in the government, to support these invaluable interests, and to balance and check the other. They ought to be so constituted as to protect the minority of the opulent against the majority. The Senate, therefore, ought to be this body; and to answer these purposes, the people ought to have permanency and stability.[10]",2
2340,"Article Five of the Constitution stipulates that no constitutional amendment may be created to deprive a state of its equal suffrage in the Senate without that state's consent. The District of Columbia and all other territories are not entitled to representation or allowed to vote in either house of Congress. They have official non-voting delegates in the House of Representatives, but none in the Senate. The District of Columbia and Puerto Rico each additionally elect two ""shadow senators"", but they are officials of their respective local governments and not members of the U.S. Senate.[11] The United States has had 50 states since 1959,[12] thus the Senate has had 100 senators since 1959.[8]
",2
2341,"The disparity between the most and least populous states has grown since the Connecticut Compromise, which granted each state two members of the Senate and at least one member of the House of Representatives, for a total minimum of three presidential electors, regardless of population. In 1787, Virginia had roughly ten times the population of Rhode Island, whereas today California has roughly 70 times the population of Wyoming, based on the 1790 and 2000 censuses. 
Before the adoption of the Seventeenth Amendment in 1913, senators were elected by the individual state legislatures.[14] Problems with repeated vacant seats due to the inability of a legislature to elect senators, intrastate political struggles, bribery and intimidation gradually led to a growing movement to amend the Constitution to allow for the direct election of senators.[15]
",2
2342,"The party composition of the Senate during the 117th Congress:
",2
2343,"Article I, Section 3, of the Constitution, sets three qualifications for senators: (1) they must be at least 30 years old; (2) they must have been citizens of the United States for at least nine years; and (3) they must be inhabitants of the states they seek to represent at the time of their election. The age and citizenship qualifications for senators are more stringent than those for representatives. In Federalist No. 62, James Madison justified this arrangement by arguing that the ""senatorial trust"" called for a ""greater extent of information and stability of character"".
",2
2344,"The Senate (not the judiciary) is the sole judge of a senator's qualifications. During its early years, however, the Senate did not closely scrutinize the qualifications of its members. As a result, four senators who failed to meet the age requirement were nevertheless admitted to the Senate: Henry Clay (aged 29 in 1806), John Jordan Crittenden (aged 29 in 1817), Armistead Thomson Mason (aged 28 in 1816), and John Eaton (aged 28 in 1818). Such an occurrence, however, has not been repeated since.[16] In 1934, Rush D. Holt Sr. was elected to the Senate at the age of 29; he waited until he turned 30 (on the next June 19) to take the oath of office. In November 1972, Joe Biden was elected to the Senate at the age of 29, but he reached his 30th birthday before the swearing-in ceremony for incoming senators in January 1973.
",2
2345,"The Fourteenth Amendment to the United States Constitution disqualifies as senators any federal or state officers who had taken the requisite oath to support the Constitution but who later engaged in rebellion or aided the enemies of the United States. This provision, which came into force soon after the end of the Civil War, was intended to prevent those who had sided with the Confederacy from serving. That Amendment, however, also provides a method to remove that disqualification: a two-thirds vote of both chambers of Congress.
",2
2346,"Originally, senators were selected by the state legislatures, not by popular elections. By the early years of the 20th century, the legislatures of as many as 29 states had provided for popular election of senators by referendums.[15] Popular election to the Senate was standardized nationally in 1913 by the ratification of the Seventeenth Amendment.
",2
2347,"Senators serve terms of six years each; the terms are staggered so that approximately one-third of the seats are up for election every two years. This was achieved by dividing the senators of the 1st Congress into thirds (called classes), where the terms of one-third expired after two years, the terms of another third expired after four, and the terms of the last third expired after six years. This arrangement was also followed after the admission of new states into the union. The staggering of terms has been arranged such that both seats from a given state are not contested in the same general election, except when a vacancy is being filled. Current senators whose six-year terms are set to expire on January 3, 2023, belong to Class III. There is no constitutional limit to the number of terms a senator may serve.
",2
2348,"The Constitution set the date for Congress to convene — Article 1, Section 4, Clause 2, originally set that date for the third day of December. The Twentieth Amendment, however, changed the opening date for sessions to noon on the third day of January, unless they shall by law appoint a different day. The Twentieth Amendment also states that the Congress shall assemble at least once every year, and allows the Congress to determine its convening and adjournment dates and other dates and schedules as it desires. Article 1, Section 3, provides that the president has the power to convene Congress on extraordinary occasions at his discretion.[17]
",2
2349,"A member who has been elected, but not yet seated, is called a senator-elect; a member who has been appointed to a seat, but not yet seated, is called a senator-designate.
",2
2350,"Elections to the Senate are held on the first Tuesday after the first Monday in November in even-numbered years, Election Day, and coincide with elections for the House of Representatives.[18] Senators are elected by their state as a whole. The Elections Clause of the United States Constitution grants each state (and Congress, if it so desires to implement a uniform law) the power to legislate a method by which senators are elected. Ballot access rules for independent and minor party candidates also vary from state to state.
",2
2351,"In 45 states, a primary election is held first for the Republican and Democratic parties (and a select few third parties, depending on the state) with the general election following a few months later. In most of these states, the nominee may receive only a plurality, while in some states, a runoff is required if no majority was achieved. In the general election, the winner is the candidate who receives a plurality of the popular vote.
",2
2352,"However, in five states, different methods are used. In Georgia, a runoff between the top two candidates occurs if the plurality winner in the general election does not also win a majority. In Washington, California, and Louisiana, a nonpartisan blanket primary (also known as a ""jungle primary"" or ""top-two primary"") is held in which all candidates participate in a single primary regardless of party affiliation and the top two candidates in terms of votes received at the primary election advance to the general election, where the winner is the candidate with the greater number of votes. In Louisiana, the blanket primary is considered the general election and the winner of the blanket primary can win the overall election if he or she received a majority of the vote, skipping the run-off. In Maine, following two ballot initiatives in 2016 and 2018, ranked-choice voting is used to nominate and elect candidates for federal offices, including the Senate. Alaska voted in November 2020 to adopt a system with a nonpartisan blanket primary from which four candidates would advance to a general election in which ranked-choice voting would be used.[19]
",2
2353,"The Seventeenth Amendment requires that vacancies in the Senate be filled by special election. Whenever a senator must be appointed or elected, the secretary of the Senate mails one of three forms to the state's governor to inform them of the proper wording to certify the appointment of a new senator.[20]  If a special election for one seat happens to coincide with a general election for the state's other seat, each seat is contested separately. A senator elected in a special election takes office as soon as possible after the election and serves until the original six-year term expires (i.e. not for a full-term).
",2
2354,"The Seventeenth Amendment permits state legislatures to empower their governors to make temporary appointments until the required special election takes place.
",2
2355,"The manner by which the Seventeenth Amendment is enacted varies among the states. A 2018 report breaks this down into the following three broad categories (specific procedures vary among the states):[21]
",2
2356,"In six states within the final category above – Arizona, Hawaii, Maryland, North Carolina, Utah, and Wyoming – the governor must appoint someone of the same political party as the previous incumbent.[21]:9
",2
2357,"In September 2009, Massachusetts changed its law to enable the governor to appoint a temporary replacement for the late senator Edward Kennedy until the special election in January 2010.[22][23]
",2
2358,"In 2004, Alaska enacted legislation and a separate ballot referendum that took effect on the same day, but that conflicted with each other. The effect of the ballot-approved law is to withhold from the governor authority to appoint a senator.[24] Because the 17th Amendment vests the power to grant that authority to the legislature – not the people or the state generally – it is unclear whether the ballot measure supplants the legislature's statute granting that authority.[24] As a result, it is uncertain whether an Alaska governor may appoint an interim senator to serve until a special election is held to fill the vacancy.
",2
2359," 
",2
2360,"
The Constitution requires that senators take an oath or affirmation to support the Constitution.[25] Congress has prescribed the following oath for all federal officials (except the President), including senators: ",2
2361,"I, ___ ___, do solemnly swear (or affirm) that I will support and defend the Constitution of the United States against all enemies, foreign and domestic; that I will bear true faith and allegiance to the same; that I take this obligation freely, without any mental reservation or purpose of evasion; and that I will well and faithfully discharge the duties of the office on which I am about to enter. So help me God.[26]",2
2362,"The annual salary of each senator, since 2009, is $174,000;[27] the president pro tempore and party leaders receive $193,400.[27][28] In June 2003, at least 40 senators were millionaires;[29] in 2018, over 50 senators were millionaires.[30]
",2
2363,"Along with earning salaries, senators receive retirement and health benefits that are identical to other federal employees, and are fully vested after five years of service.[28] Senators are covered by the Federal Employees Retirement System (FERS) or Civil Service Retirement System (CSRS). FERS has been the Senate's retirement system since January 1, 1987, while CSRS applies only for those senators who were in the Senate from December 31, 1986, and prior. As it is for federal employees, congressional retirement is funded through taxes and the participants' contributions. Under FERS, senators contribute 1.3% of their salary into the FERS retirement plan and pay 6.2% of their salary in Social Security taxes. The amount of a senator's pension depends on the years of service and the average of the highest three years of their salary. The starting amount of a senator's retirement annuity may not exceed 80% of their final salary. In 2006, the average annual pension for retired senators and representatives under CSRS was $60,972, while those who retired under FERS, or in combination with CSRS, was $35,952.[28]
",2
2364,"According to the convention of Senate seniority, the senator with the longer tenure in each state is known as the ""senior senator""; the other is the ""junior senator"". This convention does not have official significance, though seniority generally is a factor in the selection of physical offices and in party caucuses' assignment of committees.[31] In the 117th Congress, the most-senior ""junior senator"" is Maria Cantwell of Washington, who was sworn in on January 3, 2001, and is currently 16th in seniority, behind Patty Murray who was sworn in on January 3, 1993, and is currently 6th in seniority. The most-junior ""senior senator"" is Jon Ossoff of Georgia, who was sworn in on January 20, 2021, and is 99th in seniority, ahead of Raphael Warnock, who was sworn in on the same day.
",2
2365,"The Senate may expel a senator by a two-thirds vote. Fifteen senators have been expelled in the Senate's history: William Blount, for treason, in 1797, and fourteen in 1861 and 1862 for supporting the Confederate secession. Although no senator has been expelled since 1862, many senators have chosen to resign when faced with expulsion proceedings – for example, Bob Packwood in 1995. The Senate has also censured and condemned senators; censure requires only a simple majority and does not remove a senator from office. Some senators have opted to withdraw from their re-election races rather than face certain censure or expulsion, such as Robert Torricelli in 2002.
",2
2366,"The ""majority party"" is the political party that either has a majority of seats or can form a coalition or caucus with a majority of seats; if two or more parties are tied, the vice president's affiliation determines which party is the majority party. The next-largest party is known as the minority party. The president pro tempore, committee chairs, and some other officials are generally from the majority party; they have counterparts (for instance, the ""ranking members"" of committees) in the minority party. Independents and members of third parties (so long as they do not caucus support either of the larger parties) are not considered in determining which is the majority party.
",2
2367,"At one end of the chamber of the Senate is a dais from which the presiding officer presides. The lower tier of the dais is used by clerks and other officials. One hundred desks are arranged in the chamber in a semicircular pattern and are divided by a wide central aisle. The Democratic Party traditionally sits to the presiding officer's right, and the Republican Party traditionally sits to the presiding officer's left, regardless of which party has a majority of seats.[32] In this respect, the Senate differs from the House of Commons of the United Kingdom and other parliamentary bodies in the Commonwealth of Nations and elsewhere.
",2
2368,"Each senator chooses a desk based on seniority within the party. By custom, the leader of each party sits in the front row along the center aisle. Forty-eight of the desks date back to 1819, when the Senate chamber was reconstructed after the original contents were destroyed in the 1812 Burning of Washington. Further desks of similar design were added as new states entered the Union.[33] It is a tradition that each senator who uses a desk inscribes their name on the inside of the desk's drawer.[34]
",2
2369,"Except for the president of the Senate, the Senate elects its own officers,[2] who maintain order and decorum, manage and schedule the legislative and executive business of the Senate, and interpret the Senate's rules, practices and precedents. Many non-member officers are also hired to run various day-to-day functions of the Senate.
",2
2370,"Under the Constitution, the vice president serves as president of the Senate. They may vote in the Senate (ex officio, for they are not an elected member of the Senate) in the case of a tie, but is not required to.[35] For much of the nation's history the task of presiding over Senate sessions was one of the vice president's principal duties (the other being to receive from the states the tally of electoral ballots cast for president and vice president and to open the certificates ""in the Presence of the Senate and House of Representatives"", so that the total votes could be counted). Since the 1950s, vice presidents have presided over few Senate debates. Instead, they have usually presided only on ceremonial occasions, such as swearing in new senators, joint sessions, or at times to announce the result of significant legislation or nomination, or when a tie vote on an important issue is anticipated.
",2
2371,"The Constitution authorizes the Senate to elect a president pro tempore (Latin for ""president for a time""), who presides over the chamber in the vice president's absence and is, by custom, the senator of the majority party with the longest record of continuous service.[36] Like the vice president, the president pro tempore does not normally preside over the Senate, but typically delegates the responsibility of presiding to a majority-party senator who presides over the Senate, usually in blocks of one hour on a rotating basis. Frequently, freshmen senators (newly elected members) are asked to preside so that they may become accustomed to the rules and procedures of the body. It is said that, ""in practice they are usually mere mouthpieces for the Senate’s parliamentarian, who whispers what they should do"".[37]
",2
2372,"The presiding officer sits in a chair in the front of the Senate chamber. The powers of the presiding officer of the Senate are far less extensive than those of the speaker of the House. The presiding officer calls on senators to speak (by the rules of the Senate, the first senator who rises is recognized); ruling on points of order (objections by senators that a rule has been breached, subject to appeal to the whole chamber); and announcing the results of votes.
",2
2373,"Each party elects Senate party leaders. Floor leaders act as the party chief spokesmen. The Senate majority leader is responsible for controlling the agenda of the chamber by scheduling debates and votes. Each party elects an assistant leader (whip), who works to ensure that his party's senators vote as the party leadership desires.
",2
2374,"In addition to the vice president, the Senate has several officers who are not members. The Senate's chief administrative officer is the secretary of the Senate, who maintains public records, disburses salaries, monitors the acquisition of stationery and supplies, and oversees clerks. The assistant secretary of the Senate aids the secretary's work. Another official is the sergeant at arms who, as the Senate's chief law enforcement officer, maintains order and security on the Senate premises. The Capitol Police handle routine police work, with the sergeant at arms primarily responsible for general oversight. Other employees include the chaplain, who is elected by the Senate, and pages, who are appointed.
",2
2375,"The Senate uses Standing Rules for operation. Like the House of Representatives, the Senate meets in the United States Capitol in Washington, D.C. At one end of the chamber of the Senate is a dais from which the presiding officer presides. The lower tier of the dais is used by clerks and other officials. Sessions of the Senate are opened with a special prayer or invocation and typically convene on weekdays. Sessions of the Senate are generally open to the public and are broadcast live on television, usually by C-SPAN 2.
",2
2376,"Senate procedure depends not only on the rules, but also on a variety of customs and traditions. The Senate commonly waives some of its stricter rules by unanimous consent. Unanimous consent agreements are typically negotiated beforehand by party leaders. A senator may block such an agreement, but in practice, objections are rare. The presiding officer enforces the rules of the Senate, and may warn members who deviate from them. The presiding officer sometimes uses the gavel of the Senate to maintain order.
",2
2377,"A ""hold"" is placed when the leader's office is notified that a senator intends to object to a request for unanimous consent from the Senate to consider or pass a measure. A hold may be placed for any reason and can be lifted by a senator at any time. A senator may place a hold simply to review a bill, to negotiate changes to the bill, or to kill the bill. A bill can be held for as long as the senator who objects to the bill wishes to block its consideration.
",2
2378,"Holds can be overcome, but require time-consuming procedures such as filing cloture. Holds are considered private communications between a senator and the leader, and are sometimes referred to as ""secret holds"". A senator may disclose that he or she has placed a hold.
",2
2379,"The Constitution provides that a majority of the Senate constitutes a quorum to do business. Under the rules and customs of the Senate, a quorum is always assumed present unless a quorum call explicitly demonstrates otherwise. A senator may request a quorum call by ""suggesting the absence of a quorum""; a clerk then calls the roll of the Senate and notes which members are present. In practice, senators rarely request quorum calls to establish the presence of a quorum. Instead, quorum calls are generally used to temporarily delay proceedings; usually, such delays are used while waiting for a senator to reach the floor to speak or to give leaders time to negotiate. Once the need for a delay has ended, a senator may request unanimous consent to rescind the quorum call.
",2
2380,"Debate, like most other matters governing the internal functioning of the Senate, is governed by internal rules adopted by the Senate. During a debate, senators may only speak if called upon by the presiding officer, but the presiding officer is required to recognize the first senator who rises to speak. Thus, the presiding officer has little control over the course of the debate. Customarily, the majority leader and minority leader are accorded priority during debates even if another senator rises first. All speeches must be addressed to the presiding officer, who is addressed as ""Mr. President"" or ""Madam President"", and not to another member; other Members must be referred to in the third person. In most cases, senators do not refer to each other by name, but by state or position, using forms such as ""the senior senator from Virginia"", ""the gentleman from California"", or ""my distinguished friend the chairman of the Judiciary Committee"". Senators address the Senate standing next to their desks.[38]
",2
2381,"Apart from rules governing civility, there are few restrictions on the content of speeches; there is no requirement that speeches pertain to the matter before the Senate.
",2
2382,"The rules of the Senate provide that no senator may make more than two speeches on a motion or bill on the same legislative day. A legislative day begins when the Senate convenes and ends with adjournment; hence, it does not necessarily coincide with the calendar day. The length of these speeches is not limited by the rules; thus, in most cases, senators may speak for as long as they please. Often, the Senate adopts unanimous consent agreements imposing time limits. In other cases (for example, for the budget process), limits are imposed by statute. However, the right to unlimited debate is generally preserved.
",2
2383,"Within the United States, the Senate is sometimes referred to as ""world's greatest deliberative body"".[39][40][41]
",2
2384,"The filibuster is a tactic used to defeat bills and motions by prolonging debate indefinitely. A filibuster may entail long speeches, dilatory motions, and an extensive series of proposed amendments. The Senate may end a filibuster by invoking cloture. In most cases, cloture requires the support of three-fifths of the Senate; however, if the matter before the Senate involves changing the rules of the body – this includes amending provisions regarding the filibuster – a two-thirds majority is required. In current practice, the threat of filibuster is more important than its use; almost any motion that does not have the support of three-fifths of the Senate effectively fails. This means that 41 senators can make a filibuster happen. Historically, cloture has rarely been invoked because bipartisan support is usually necessary to obtain the required supermajority, so a bill that already has bipartisan support is rarely subject to threats of filibuster. However, motions for cloture have increased significantly in recent years.
",2
2385,"If the Senate invokes cloture, the debate does not necessarily end immediately; instead, it is limited to up to 30 additional hours unless increased by another three-fifths vote. The longest filibuster speech in the Senate's history was delivered by Strom Thurmond (D-SC), who spoke for over 24 hours in an unsuccessful attempt to block the passage of the Civil Rights Act of 1957.[42]
",2
2386,"Under certain circumstances, the Congressional Budget Act of 1974 provides for a process called ""reconciliation"" by which Congress can pass bills related to the budget without those bills being subject to a filibuster. This is accomplished by limiting all Senate floor debate to 20 hours.[43]
",2
2387,"When the debate concludes, the motion in question is put to a vote. The Senate often votes by voice vote. The presiding officer puts the question, and Members respond either ""Yea/Aye"" (in favor of the motion) or ""Nay"" (against the motion). The presiding officer then announces the result of the voice vote. A senator, however, may challenge the presiding officer's assessment and request a recorded vote. The request may be granted only if it is seconded by one-fifth of the senators present. In practice, however, senators second requests for recorded votes as a matter of courtesy. When a recorded vote is held, the clerk calls the roll of the Senate in alphabetical order; senators respond when their name is called. Senators who were not in the chamber when their name was called may still cast a vote so long as the voting remains open. The vote is closed at the discretion of the presiding officer, but must remain open for a minimum of 15 minutes. A majority of those voting determines whether the motion carries.[44] If the vote is tied, the vice president, if present, is entitled to cast a tie-breaking vote. If the vice president is not present, the motion fails.[45]
",2
2388,"Filibustered bills require a three-fifths majority to overcome the cloture vote (which usually means 60 votes) and get to the normal vote where a simple majority (usually 51 votes) approves the bill. This has caused some news media to confuse the 60 votes needed to overcome a filibuster with the 51 votes needed to approve a bill, with for example USA Today erroneously stating ""The vote was 58–39 in favor of the provision establishing concealed carry permit reciprocity in the 48 states that have concealed weapons laws. That fell two votes short of the 60 needed to approve the measure"".[44]
",2
2389,"On occasion, the Senate may go into what is called a secret or closed session. During a closed session, the chamber doors are closed, cameras are turned off, and the galleries are completely cleared of anyone not sworn to secrecy, not instructed in the rules of the closed session, or not essential to the session. Closed sessions are rare and usually held only when the Senate is discussing sensitive subject matter such as information critical to national security, private communications from the president, or deliberations during impeachment trials. A senator may call for and force a closed session if the motion is seconded by at least one other member, but an agreement usually occurs beforehand.[46] If the Senate does not approve the release of a secret transcript, the transcript is stored in the Office of Senate Security and ultimately sent to the national archives. The proceedings remain sealed indefinitely until the Senate votes to remove the injunction of secrecy.[47] In 1973, the House adopted a rule that all committee sessions should be open unless a majority on the committee voted for a closed session.
",2
2390,"The Senate maintains a Senate Calendar and an Executive Calendar.[48] The former identifies bills and resolutions awaiting Senate floor actions. The latter identifies executive resolutions, treaties, and nominations reported out by Senate committee(s) and awaiting Senate floor action. Both are updated each day the Senate is in session.
",2
2391,"The Senate uses committees (and their subcommittees) for a variety of purposes, including the review of bills and the oversight of the executive branch. Formally, the whole Senate appoints committee members. In practice, however, the choice of members is made by the political parties. Generally, each party honors the preferences of individual senators, giving priority based on seniority. Each party is allocated seats on committees in proportion to its overall strength.
",2
2392,"Most committee work is performed by 16 standing committees, each of which has jurisdiction over a field such as finance or foreign relations. Each standing committee may consider, amend, and report bills that fall under its jurisdiction. Furthermore, each standing committee considers presidential nominations to offices related to its jurisdiction. (For instance, the Judiciary Committee considers nominees for judgeships, and the Foreign Relations Committee considers nominees for positions in the Department of State.) Committees may block nominees and impede bills from reaching the floor of the Senate. Standing committees also oversee the departments and agencies of the executive branch. In discharging their duties, standing committees have the power to hold hearings and to subpoena witnesses and evidence.
",2
2393,"The Senate also has several committees that are not considered standing committees. Such bodies are generally known as select or special committees; examples include the Select Committee on Ethics and the Special Committee on Aging. Legislation is referred to some of these committees, although the bulk of legislative work is performed by the standing committees. Committees may be established on an ad hoc basis for specific purposes; for instance, the Senate Watergate Committee was a special committee created to investigate the Watergate scandal. Such temporary committees cease to exist after fulfilling their tasks.
",2
2394,"The Congress includes joint committees, which include members from both the Senate and the House of Representatives. Some joint committees oversee independent government bodies; for instance, the Joint Committee on the Library oversees the Library of Congress. Other joint committees serve to make advisory reports; for example, there exists a Joint Committee on Taxation. Bills and nominees are not referred to joint committees. Hence, the power of joint committees is considerably lower than those of standing committees.
",2
2395,"Each Senate committee and subcommittee is led by a chair (usually a member of the majority party). Formerly, committee chairs were determined purely by seniority; as a result, several elderly senators continued to serve as chair despite severe physical infirmity or even senility.[49] Committee chairs are elected, but, in practice, seniority is rarely bypassed. The chairs hold extensive powers: they control the committee's agenda, and so decide how much, if any, time to devote to the consideration of a bill; they act with the power of the committee in disapproving or delaying a bill or a nomination by the president; they manage on the floor of the full Senate the consideration of those bills the committee reports. This last role was particularly important in mid-century, when floor amendments were thought not to be collegial. They also have considerable influence: senators who cooperate with their committee chairs are likely to accomplish more good for their states than those who do not. The Senate rules and customs were reformed in the twentieth century, largely in the 1970s. Committee chairmen have less power and are generally more moderate and collegial in exercising it, than they were before reform.[50] The second-highest member, the spokesperson on the committee for the minority party, is known in most cases as the ranking member.[51] In the Select Committee on Intelligence and the Select Committee on Ethics, however, the senior minority member is known as the vice-chair.
",2
2396,"Recent criticisms of the Senate's operations object to what the critics argue is obsolescence as a result of partisan paralysis and a preponderance of arcane rules.[52][53]
",2
2397,"The Senate filibuster is frequently debated. The Constitution specifies a 50% threshold to pass legislation, and some critics feel the de facto three-fifths threshold for general legislation prevents beneficial laws from passing. (The nuclear option was exercised by both parties in the 2010s to eliminate the filibuster for confirmations.) Supporters generally consider the filibuster to be an important protection for the minority views and a check against the unfettered single-party rule when the same party holds the Presidency and a majority in both the House and Senate.
",2
2398,"Though this was an intentional part of the Connecticut Compromise, critics have described the fact that representation in the Senate is not proportional to the population as ""anti-democratic"" and ""minority rule"".[54][55] Opinion columnist David Leonhardt points out[56] that because small states are disproportionately non-Hispanic European American, African Americans have 75% of their proportionate voting power in the Senate, and Hispanic Americans have just 55%. The approximately four million Americans that have no representation in the Senate (in the District of Columbia and U.S. territories) are heavily African and Hispanic American. Leonhardt and others advocate for admitting Washington, D.C. and Puerto Rico as states (both have more residents than the smallest existing states) to reduce this inequity.
",2
2399,"There are presently three Senate office buildings located along Constitution Avenue, north of the Capitol. They are the Russell Senate Office Building, the Dirksen Senate Office Building, and the Hart Senate Office Building.
",2
2400,"Bills may be introduced in either chamber of Congress. However, the Constitution's Origination Clause provides that ""All bills for raising Revenue shall originate in the House of Representatives"".[57] As a result, the Senate does not have the power to initiate bills imposing taxes. Furthermore, the House of Representatives holds that the Senate does not have the power to originate appropriation bills, or bills authorizing the expenditure of federal funds.[58][59][60][61] Historically, the Senate has disputed the interpretation advocated by the House. However, when the Senate originates an appropriations bill, the House simply refuses to consider it, thereby settling the dispute in practice. The constitutional provision barring the Senate from introducing revenue bills is based on the practice of the British Parliament, in which only the House of Commons may originate such measures.[62]
",2
2401,"Although the Constitution gave the House the power to initiate revenue bills, in practice the Senate is equal to the House in the respect of spending. As Woodrow Wilson wrote:
",2
2402,"The Senate's right to amend general appropriation bills has been allowed the widest possible scope. The upper house may add to them what it pleases; may go altogether outside of their original provisions and tack to them entirely new features of legislation, altering not only the amounts but even the objects of expenditure, and making out of the materials sent them by the popular chamber measures of an almost totally new character.[63]",2
2403,"The approval of both houses is required for any bill, including a revenue bill, to become law. Both Houses must pass the same version of the bill; if there are differences, they may be resolved by sending amendments back and forth or by a conference committee, which includes members of both bodies.
",2
2404,"The Constitution provides several unique functions for the Senate that form its ability to ""check and balance"" the powers of other elements of the Federal Government. These include the requirement that the Senate may advise and must consent to some of the president's government appointments; also the Senate must consent to all treaties with foreign governments; it tries all impeachments, and it elects the vice president in the event no person gets a majority of the electoral votes.
",2
2405,"The president can make certain appointments only with the advice and consent of the Senate. Officials whose appointments require the Senate's approval include members of the Cabinet, heads of most federal executive agencies, ambassadors, justices of the Supreme Court, and other federal judges. Under Article II, Section 2, of the Constitution, a large number of government appointments are subject to potential confirmation; however, Congress has passed legislation to authorize the appointment of many officials without the Senate's consent (usually, confirmation requirements are reserved for those officials with the most significant final decision-making authority). Typically, a nominee is the first subject to a hearing before a Senate committee. Thereafter, the nomination is considered by the full Senate. The majority of nominees are confirmed, but in a small number of cases each year, Senate committees purposely fail to act on a nomination to block it. In addition, the president sometimes withdraws nominations when they appear unlikely to be confirmed. Because of this, outright rejections of nominees on the Senate floor are infrequent (there have been only nine Cabinet nominees rejected outright in United States history).[64]
",2
2406,"The powers of the Senate concerning nominations are, however, subject to some constraints. For instance, the Constitution provides that the president may make an appointment during a congressional recess without the Senate's advice and consent. The recess appointment remains valid only temporarily; the office becomes vacant again at the end of the next congressional session. Nevertheless, presidents have frequently used recess appointments to circumvent the possibility that the Senate may reject the nominee. Furthermore, as the Supreme Court held in Myers v. United States, although the Senate's advice and consent are required for the appointment of certain executive branch officials, it is not necessary for their removal.[65][66] Recess appointments have faced a significant amount of resistance and in 1960, the U.S. Senate passed a legally non-binding resolution against recess appointments.[citation needed]
",2
2407,"The Senate also has a role in ratifying treaties. The Constitution provides that the president may only ""make Treaties, provided two-thirds of the senators present concur"" in order to benefit from the Senate's advice and consent and give each state an equal vote in the process. However, not all international agreements are considered treaties under US domestic law, even if they are considered treaties under international law. Congress has passed laws authorizing the president to conclude executive agreements without action by the Senate. Similarly, the president may make congressional-executive agreements with the approval of a simple majority in each House of Congress, rather than a two-thirds majority in the Senate. Neither executive agreements nor congressional-executive agreements are mentioned in the Constitution, leading some scholars such as Laurence Tribe and John Yoo[67] to suggest that they unconstitutionally circumvent the treaty-ratification process. However, courts have upheld the validity of such agreements.[68]
",2
2408,"The Constitution empowers the House of Representatives to impeach federal officials for ""Treason, Bribery, or other high Crimes and Misdemeanors"" and empowers the Senate to try such impeachments. If the sitting president of the United States is being tried, the chief justice of the United States presides over the trial. During an impeachment trial, senators are constitutionally required to sit on oath or affirmation. Conviction requires a two-thirds majority of the senators present. A convicted official is automatically removed from office; in addition, the Senate may stipulate that the defendant be banned from holding office. No further punishment is permitted during the impeachment proceedings; however, the party may face criminal penalties in a normal court of law.
",2
2409,"The House of Representatives has impeached sixteen officials, of whom seven were convicted (one resigned before the Senate could complete the trial).[69] Only three presidents of the United States have ever been impeached: Andrew Johnson in 1868, Bill Clinton in 1998, and Donald Trump in 2019 and 2021. The trials of Johnson, Clinton and both Trump trials ended in acquittal; in Johnson's case, the Senate fell one vote short of the two-thirds majority required for conviction.
",2
2410,"Under the Twelfth Amendment, the Senate has the power to elect the vice president if no vice-presidential candidate receives a majority of votes in the Electoral College. The Twelfth Amendment requires the Senate to choose from the two candidates with the highest numbers of electoral votes. Electoral College deadlocks are rare. The Senate has only broken a deadlock once; in 1837, it elected Richard Mentor Johnson. The House elects the president if the Electoral College deadlocks on that choice.
",2
2411,"The following are published by the Senate Historical Office.
",2
2412,"
",3
2413,"
",3
2414,"
",3
2415,"Argentine professional footballer
",3
2416,"Eponym
",3
2417,"Films
",3
2418,"Lionel Andrés Messi[note 1] (Spanish pronunciation: [ljoˈnel anˈdɾes ˈmesi] (listen);[A] born 24 June 1987) is an Argentine professional footballer who plays as a forward and captains both the Spanish club Barcelona and the Argentina national team. Often considered as the best player in the world and widely regarded as one of the greatest players of all time, Messi has won a record six Ballon d'Or awards,[note 2] a record six European Golden Shoes, and in 2020 was named to the Ballon d'Or Dream Team. He has spent his entire professional career with Barcelona, where he has won a club-record 34 trophies, including ten La Liga titles, six Copa del Rey titles and four UEFA Champions Leagues. A prolific goalscorer and creative playmaker, Messi holds the records for most goals in La Liga (463), a La Liga and European league season (50), most hat-tricks in La Liga (36) and the UEFA Champions League (8), and most assists in La Liga (189), a La Liga and European league season (21)[9] and the Copa América (12). He has scored over 750 senior career goals for club and country, and has the most goals ever by a player for a single club.
",3
2419,"Born and raised in central Argentina, Messi relocated to Spain to join Barcelona at age 13, for whom he made his competitive debut aged 17 in October 2004. He established himself as an integral player for the club within the next three years, and in his first uninterrupted season in 2008–09 he helped Barcelona achieve the first treble in Spanish football; that year, aged 22, Messi won his first Ballon d'Or. Three successful seasons followed, with Messi winning four consecutive Ballons d'Or, making him the first player to win the award four times and in a row.[10] During the 2011–12 season, he set the La Liga and European records for most goals scored in a single season, while establishing himself as Barcelona's all-time top scorer. The following two seasons, Messi finished second for the Ballon d'Or behind Cristiano Ronaldo (his perceived career rival), before regaining his best form during the 2014–15 campaign, becoming the all-time top scorer in La Liga and leading Barcelona to a historic second treble, after which he was awarded a fifth Ballon d'Or in 2015. Messi assumed the captaincy of Barcelona in 2018, and in 2019 he secured a record sixth Ballon d'Or.
",3
2420,"An Argentine international, Messi is his country's all-time leading goalscorer. At youth level, he won the 2005 FIFA World Youth Championship, finishing the tournament with both the Golden Ball and Golden Shoe, and an Olympic gold medal at the 2008 Summer Olympics. His style of play as a diminutive, left-footed dribbler drew comparisons with his compatriot Diego Maradona, who described Messi as his successor. After his senior debut in August 2005, Messi became the youngest Argentine to play and score in a FIFA World Cup during the 2006 edition, and reached the final of the 2007 Copa América, where he was named young player of the tournament. As the squad's captain from August 2011, he led Argentina to three consecutive finals: the 2014 FIFA World Cup, for which he won the Golden Ball, and the 2015 and 2016 Copa América. After announcing his international retirement in 2016, he reversed his decision and led his country to qualification for the 2018 FIFA World Cup, and a third-place finish at the 2019 Copa América.
",3
2421,"One of the most famous athletes in the world, Messi has been sponsored by sportswear company Adidas since 2006 and has established himself as their leading brand endorser. According to France Football, he was the world's highest-paid footballer for five years out of six between 2009 and 2014, and was ranked the world's highest-paid athlete by Forbes in 2019. Messi was among Time's 100 most influential people in the world in 2011 and 2012. In February 2020, he was awarded the Laureus World Sportsman of the Year, thus becoming the first footballer and also the first team sport athlete to win the award. Later that year, Messi became the second footballer (and second team-sport athlete) behind Cristiano Ronaldo to surpass $1 billion in career earnings.[11]
",3
2422,"Messi was born on 24 June 1987 in Rosario, the third of four children of Jorge Messi, a steel factory manager, and his wife Celia Cuccittini, who worked in a magnet manufacturing workshop. On his father's side, he is of Italian and Spanish descent, the great-grandson of immigrants from the northcentral Adriatic Marche region of Italy and Catalonia, and on his mother's side, he has primarily Italian ancestry.[4][12] Growing up in a tight-knit, football-loving family, ""Leo"" developed a passion for the sport from an early age, playing constantly with his older brothers, Rodrigo and Matías, and his cousins, Maximiliano and Emanuel Biancucchi, both of whom became professional footballers.[13] At the age of four he joined local club Grandoli, where he was coached by his father, though his earliest influence as a player came from his maternal grandmother, Celia, who accompanied him to training and matches.[14] He was greatly affected by her death, shortly before his eleventh birthday; since then, as a devout Catholic, he has celebrated his goals by looking up and pointing to the sky in tribute to his grandmother.[15][16]
",3
2423,"– Newell's Old Boys youth coach Adrián Coria shares his first impression of the 12-year-old Messi.[17]
",3
2424,"A lifelong supporter of Newell's Old Boys, Messi joined the Rosario club when he was six years old. During the six years he played for Newell's, he scored almost 500 goals as a member of ""The Machine of '87"", the near-unbeatable youth side named for the year of their birth, and regularly entertained crowds by performing ball tricks during half-time of the first team's home games.[18][19] However, his future as a professional player was threatened when, at age 10, he was diagnosed with a growth hormone deficiency. As his father's health insurance covered only two years of growth hormone treatment, which cost at least $1,000 per month, Newell's agreed to contribute, but later reneged on their promise.[20] He was scouted by Buenos Aires club River Plate, whose playmaker, Pablo Aimar, he idolised, but they were also unable to pay for his treatment due to Argentina's economic collapse.[21][22] His goalscoring idol growing up was Ronaldo, with Messi calling him ""the best forward I've ever seen"".[23]
",3
2425,"As the Messi family had relatives in Catalonia, they sought to arrange a trial with Barcelona in September 2000. First team director Charly Rexach immediately wanted to sign him, but the board of directors hesitated; at the time it was highly unusual for European clubs to sign foreign players of such a young age. On 14 December, an ultimatum was issued for Barcelona to prove their commitment, and Rexach, with no other paper at hand, offered a contract on a paper napkin.[21][24] In February 2001, the family relocated to Barcelona, where they moved into an apartment near the club's stadium, Camp Nou. During his first year in Spain, Messi rarely played with the Infantiles due to a transfer conflict with Newell's; as a foreigner, he could only be fielded in friendlies and the Catalan league. Without football, he struggled to integrate into the team; already reserved by nature, he was so quiet that his teammates initially believed he was mute. At home, he suffered from homesickness after his mother moved back to Rosario with his brothers and little sister, María Sol, while he stayed in Barcelona with his father.[18][24][25]
",3
2426,"After a year at Barcelona's youth academy, La Masia, Messi was finally enrolled in the Royal Spanish Football Federation (RFEF) in February 2002. Now playing in all competitions, he befriended his teammates, among whom were Cesc Fàbregas and Gerard Piqué.[26] After completing his growth hormone treatment aged 14,[27] Messi became an integral part of the ""Baby Dream Team"", Barcelona's greatest-ever youth side. During his first full season (2002–03), he was top scorer with 36 goals in 30 games for the Cadetes A, who won an unprecedented treble of the league and both the Spanish and Catalan cups.[26][28] The Copa Catalunya final, a 4–1 victory over Espanyol, became known in club lore as the partido de la máscara, the final of the mask. A week after suffering a broken cheekbone during a league match, Messi was allowed to start the game on the condition that he wear a plastic protector; soon hindered by the mask, he took it off and scored two goals in 10 minutes before his substitution.[29] At the close of the season, he received an offer to join Arsenal, his first from a foreign club, but while Fàbregas and Piqué soon left for England, he chose to remain in Barcelona.[24][30][31]
",3
2427,"– Barcelona's then assistant coach Henk Ten Cate on Messi's first-team debut.[32]
",3
2428,"During the 2003–04 season, his fourth with Barcelona, Messi rapidly progressed through the club's ranks, debuting for a record five youth teams in a single campaign.[33] After being named player of the tournament in four international pre-season competitions with the Juveniles B, he played only one official match with the team before being promoted to the Juveniles A, where he scored 18 goals in 11 league games.[34][35] Messi was then one of several youth players called up to strengthen a depleted first team during the international break. French winger Ludovic Giuly explained how a teenage Leo caught the eye in a training session with Frank Rijkaard's first team: ""He destroyed us all... They were kicking him all over the place to avoid being ridiculed by this kid, he just got up and kept on playing. He would dribble past four players and score a goal. Even the team's starting centre-backs were nervous. He was an alien.""[36]
",3
2429,"At 16 years, four months, and 23 days old, Messi made his first team debut when he came on in the 75th minute during a friendly against José Mourinho's Porto on 16 November 2003.[24][37] His performance, creating two chances and a shot on goal, impressed the technical staff, and he subsequently began training daily with the club's reserve side, Barcelona B, as well as weekly with the first team.[38] After his first training session with the senior squad, Barça's new star player, Ronaldinho, told his teammates that he believed the 16-year-old would become an even better player than himself.[39] Ronaldinho soon befriended Messi, whom he called ""little brother"", which greatly eased his transition into the first team.[40][41]
",3
2430,"To gain further match experience, Messi joined Barcelona C in addition to the Juveniles A, playing his first game for the third team on 29 November. He helped save them from the relegation zone of the Tercera División, scoring five goals in ten games, including a hat-trick in eight minutes during a Copa del Rey match while man-marked by Sevilla's Sergio Ramos.[34][42] His progress was reflected in his first professional contract, signed on 4 February 2004, which lasted until 2012 and contained an initial buyout clause of €30 million. A month later, on 6 March, he made his debut for Barcelona B in the Segunda División B, and his buyout clause automatically increased to €80 million.[34][43] He played five games with the B team that season but did not score.[44] Physically he was weaker than his opponents, who were often much older and taller, and in training he worked on increasing his muscle mass and overall strength in order to be able to shake off defenders. Towards the end of the season, he returned to both youth teams, helping the Juveniles B win the league. He finished the campaign having scored for four of his five teams with a total of 36 goals in all official competitions.[34][42]
",3
2431,"During the 2004–05 season, Messi was a guaranteed starter for the B team, playing 17 games throughout the campaign and scoring on six occasions.[39][45] Since his debut the previous November, he had not been called up to the first team again, but in October 2004, the senior players asked manager Frank Rijkaard to promote him.[39] Since Ronaldinho already played on the left wing, Rijkaard moved Messi from his usual position onto the right flank (though initially against the player's wishes), allowing him to cut into the centre of the pitch and shoot with his dominant left foot.[46][47] Messi made his league debut during the next match on 16 October, against Espanyol, coming on in the 82nd minute.[24] At 17 years, three months, and 22 days old, he was at the time the youngest player to represent Barcelona in an official competition.[41] As a substitute player, he played 77 minutes in nine matches for the first team that season, including his debut in the UEFA Champions League against Shakhtar Donetsk.[45][48] He scored his first senior goal on 1 May 2005, against Albacete, from an assist by Ronaldinho, becoming – at that time – the youngest-ever scorer for the club.[46][49] Barcelona, in their second season under Rijkaard, won the league for the first time in six years.[50]
",3
2432,"– Fabio Capello praises the 18-year-old Messi following the Joan Gamper trophy in August 2005.[51]
",3
2433,"On 24 June 2005, his 18th birthday, Messi signed his first contract as a senior team player. It made him a Barcelona player until 2010, two years less than his previous contract, but his buyout clause increased to €150 million.[43] His breakthrough came two months later, on 24 August, during the Joan Gamper Trophy, Barcelona's pre-season competition. A starter for the first time, he gave a well-received performance against Fabio Capello's Juventus, receiving an ovation from the Camp Nou.[51] While Capello requested to loan Messi, a bid to buy him came from Inter Milan, who were willing to pay his €150 million buyout clause and triple his wages.[52] According to then-president Joan Laporta, it was the only time the club faced a real risk of losing Messi, but he ultimately decided to stay.[53] On 16 September, his contract was updated for the second time in three months and extended to 2014.[43][54]
",3
2434,"Due to issues regarding his legal status in the Royal Spanish Football Federation, Messi missed the start of La Liga, but on 26 September, he acquired Spanish citizenship and became eligible to play.[54][55] Wearing the number 19 shirt, he gradually established himself as the first-choice right winger, forming an attacking trio with Ronaldinho and striker Samuel Eto'o.[31][56][57] He was in the starting line-up in major matches like his first Clásico against rivals Real Madrid on 19 November, as well as Barcelona's away victory over Chelsea in the last 16 round of the Champions League.[58][56] After he had scored 8 goals in 25 games, including his first in the Champions League,[59] in a 5–0 win over Panathinaikos on 2 November 2005,[60] his season ended prematurely during the return leg against Chelsea on 7 March 2006, when he suffered a torn hamstring. Messi worked to regain fitness in time for the Champions League final, but on 17 May, the day of the final, he was eventually ruled out. He was so disappointed that he did not celebrate his team's victory over Arsenal in Paris, something he later came to regret.[50][56]
",3
2435,"While Barcelona began a gradual decline, the 19-year-old Messi established himself as one of the best players in the world during the 2006–07 campaign.[61][62] Already an idol to the culés, the club's supporters, he scored 17 goals  in 36 games across all competitions.[62][63] However, he continued to be plagued by major injuries; a metatarsal fracture sustained on 12 November 2006 kept him out of action for three months.[64][65] He recovered in time for the last 16 round of the Champions League against Liverpool, but was effectively marked out of the game; Barcelona, the reigning champions, were out of the competition.[66] In the league, his goal contribution increased towards the end of the season; 11 of his 14 goals came from the last 13 games.[63] On 10 March 2007, he scored his first hat-trick in a Clásico, the first player to do so in 12 years, equalising after each goal by Real Madrid to end the match in a 3–3 draw in injury time.[67] His growing importance to the club was reflected in a new contract, signed that month, which greatly increased his wages.[68]
",3
2436,"Already frequently compared to compatriot Diego Maradona, Messi proved their similarity when he nearly replicated Maradona's two most famous goals in the span of seven weeks.[69] During a Copa del Rey semi-final against Getafe on 18 April, he scored a goal remarkably similar to Maradona's second goal in the quarter-finals of the 1986 FIFA World Cup, known as the Goal of the Century. Messi collected the ball on the right side near the halfway line, ran 60 metres (66 yd), and beat five defenders before scoring with an angled finish, just as Maradona had done.[21][70] A league match against Espanyol on 9 June saw him score by launching himself at the ball and guiding it past the goalkeeper with his hand in similar fashion to Maradona's Hand of God goal in the same World Cup match.[71] As Messi continued his individual rise, Barcelona faltered; the team failed to reach the Copa del Rey final after Messi was rested during the second leg against Getafe and lost the league to Real Madrid on head-to-head results.[72][73]
",3
2437,"After Ronaldinho lost form, Messi became Barça's new star player at only 20 years old, receiving the nickname ""Messiah"" from the Spanish media.[21][74][75] His efforts in 2007 also earned him award recognition; journalists voted him the third-best player of the year for the 2007 Ballon d'Or, behind Kaká and runner-up Cristiano Ronaldo, while international managers and national team captains voted him second for the FIFA World Player of the Year award, again behind Kaká.[76][77] Although he managed to score 16 goals  during the 2007–08 campaign,[78] the second half of his season was again marred by injuries after he suffered a torn hamstring on 15 December.[79] He returned to score twice in their away victory against Celtic in the last 16 round of the Champions League, becoming the competition's top scorer at that point with six goals,[80] but reinjured himself during the return leg on 4 March 2008. Rijkaard had fielded him despite warning from the medical staff, leading captain Carles Puyol to criticise the Spanish media for pressuring Messi to play every match.[79] Barcelona finished the season without trophies, eliminated in the Champions League semi-finals by the eventual champions, Manchester United, and placed third in the league.[81]
",3
2438,"After two unsuccessful seasons, Barcelona were in need of an overhaul, leading to the departure of Rijkaard and Ronaldinho. Upon the latter's departure, Messi was given the number 10 shirt.[57] He signed a new contract in July 2008 on an annual salary of €7.8 million, becoming the club's highest-paid player.[82][83] Ahead of the new season, a major concern remained his frequent muscular injuries, which had left him side-lined for a total of eight months between 2006 and 2008. To combat the problem, the club implemented new training, nutrition, and lifestyle regimens, and assigned him a personal physiotherapist, who would travel with him during call-ups for the Argentina national team. As a result, Messi remained virtually injury-free during the next four years, allowing him to reach his full potential.[65][84] Despite his injuries early in the year, his performances in 2008 saw him again voted runner-up for the Ballon d'Or and the FIFA World Player of the Year award, both times behind Cristiano Ronaldo.[76][85]
",3
2439,"In his first uninterrupted campaign, the 2008–09 season, he scored 38 goals  in 51 games, contributing alongside Eto'o and winger Thierry Henry to a total of 100 goals in all competitions, a record at the time for the club.[86][87]
",3
2440,"During his first season under Barcelona's new manager, former captain Pep Guardiola, Messi played mainly on the right wing, like he had under Rijkaard, though this time as a false winger with the freedom to cut inside and roam the centre. During the Clásico on 2 May 2009, however, he played for the first time as a false nine, positioned as a centre-forward but dropping deep into midfield to link up with Xavi and Andrés Iniesta. He assisted his side's first goal and scored twice to end the match in an emphatic 6–2 victory, the team's greatest-ever score at Real Madrid's Santiago Bernabéu Stadium.[88][89] Returning to the wing, he played his first final since breaking into the first team on 13 May, scoring once and assisting a second goal as Barcelona defeated Athletic Bilbao 4–1 to win the Copa del Rey.[90] With 23 league goals from Messi that season, Barcelona became La Liga champions three days later and achieved its fifth double.[86][91]
",3
2441,"As the season's Champions League top scorer with nine goals, the youngest in the tournament's history,[92] Messi scored two goals and assisted two more to ensure a 4–0 quarter-final victory over Bayern Munich.[88] He returned as a false nine during the final on 27 May in Rome against Manchester United. Barcelona were crowned champions of Europe by winning the match 2–0, the second goal coming from a Messi header over goalkeeper Edwin van der Sar. Barcelona thus achieved the first treble in the history of Spanish football.[93][94] This success was reflected in a new contract, signed on 18 September, which committed Messi to the club through 2016 with a new buyout clause of €250 million, while his salary increased to €12 million.[82] His team's prosperity continued into the second half of 2009, as Barcelona became the first club to achieve the sextuple, winning six top-tier trophies in a single year.[95] After victories in the Supercopa de España and UEFA Super Cup in August, Barcelona won the FIFA Club World Cup against Estudiantes de La Plata on 19 December, with Messi scoring the winning 2–1 goal with his chest.[96] At 22 years old, Messi won the Ballon d'Or and the FIFA World Player of the Year award, both times by the greatest voting margin in each trophy's history.[76]
",3
2442,"– Arsène Wenger commends Messi for his four–goal display against Arsenal in April 2010.[97]
",3
2443,"Unsatisfied with his position on the right wing – with the club's summer acquisition Zlatan Ibrahimović occupying the central forward role – Messi resumed playing as a false nine in early 2010, beginning with a Champions League last 16-round match against VfB Stuttgart. After a first-leg draw, Barcelona won the second leg 4–0 with two goals and an assist from Messi. At that point, he effectively became the tactical focal point of Guardiola's team, and his goalscoring rate increased.[98] Messi scored a total of 47 goals in all competitions that season, equaling Ronaldo's club record from the 1996–97 campaign.[99][100] He scored all of his side's four goals in the Champions League quarter-final against Arsène Wenger's Arsenal on 6 April while becoming Barcelona's all-time top scorer in the competition.[101][102] Although Barcelona were eliminated in the Champions League semi-finals by the eventual champions, Inter Milan, Messi finished the season as top scorer (with 8 goals) for the second consecutive year.[103] As the league's top scorer with 34 goals (again tying Ronaldo's record), he helped Barcelona win a second consecutive La Liga trophy with only a single defeat.[100][104]
",3
2444,"Messi secured Barcelona's first trophy of the 2010–11 campaign, the Supercopa de España, by scoring a hat-trick in his side's second-leg 4–0 victory over Sevilla, after a first-leg defeat.[105] Assuming a playmaking role, he was again instrumental in a Clásico on 29 November 2010, the first with José Mourinho in charge of Real Madrid, as Barcelona defeated their rivals 5–0.[106] Messi helped the team achieve 16 consecutive league victories, a record in Spanish football, concluding with another hat-trick against Atlético Madrid on 5 February 2011.[107][108] His club performances in 2010 earned him the inaugural FIFA Ballon d'Or, an amalgamation of the Ballon d'Or and the FIFA World Player of the Year award, though his win was met with some criticism due to his lack of success with Argentina at the 2010 FIFA World Cup.[76][109] Under the award's old format, he would have placed just outside the top three, owing his win to the votes from the international coaches and captains.[109]
",3
2445,"Towards the end of the season, Barcelona played four Clásicos in the span of 18 days. A league match on 16 April ended in a draw after a penalty from Messi. After Barcelona lost the Copa del Rey final four days later, Messi scored both goals in his side's 2–0 win in the first leg of the Champions League semi-finals in Madrid, the second of which – a slaloming dribble past three Real players – was acclaimed as one of the best ever in the competition.[110] Although he did not score, he was again important in the second-leg draw that sent Barcelona through to the Champions League final,[111][112] where they faced Manchester United in a repeat of the final two years earlier. As the competition's top scorer for the third consecutive year, with 12 goals, Messi gave a man-of-the-match performance at Wembley on 28 May, scoring the match-winning goal of Barça's 3–1 victory.[113][114] Barcelona won a third consecutive La Liga title. In addition to his 31 goals, Messi was also the league's top assist provider with 18.[115][116] He finished the season with 53 goals and 24 assists in all competitions, becoming Barcelona's all-time single-season top scorer and the first player in Spanish football to reach the 50-goal benchmark.[115][117]
",3
2446,"As Messi developed into a combination of a number 8 (a creator), a 9 (scorer), and a 10 (assistant),[118] he scored an unprecedented 73 goals and provided 29 assists in all club competitions during the 2011–12 season, producing a hat-trick or more on 10 occasions.[119][120][121] He began the campaign by helping Barcelona win both the Spanish and European Super Cups; in the Supercopa de España, he scored three times to achieve a 5–4 aggregate victory over Real Madrid, overtaking Raúl as the competition's all-time top scorer with eight goals.[122][123] At the close of the year, on 18 December, he scored twice in the FIFA Club World Cup final, a 4–0 victory over Santos, earning the Golden Ball as the best player of the tournament, as he had done two years previously.[124] For his efforts in 2011, he again received the FIFA Ballon d'Or, becoming only the fourth player in history to win the Ballon d'Or three times, after Johan Cruyff, Michel Platini, and Marco van Basten.[125] Additionally, he won the inaugural UEFA Best Player in Europe Award, a revival of the old-style Ballon d'Or.[126] By then, Messi was already widely considered one of the best footballers in history, alongside players like Diego Maradona and Pelé.[25]
",3
2447,"– Pep Guardiola after Messi became Barcelona's all-time top scorer at age 24 in March 2012[127][128]
",3
2448,"As Messi maintained his goalscoring form into the second half of the season, the year 2012 saw him break several longstanding records. On 7 March, two weeks after scoring four goals in a league fixture against Valencia, he scored five times in a Champions League last 16-round match against Bayer Leverkusen, an unprecedented achievement in the history of the competition.[129][130] In addition to being the joint top assist provider with five assists, this feat made him top scorer with 14 goals, tying José Altafini's record from the 1962–63 season, as well as becoming only the second player after Gerd Müller to be top scorer in four campaigns.[131][132] Two weeks later, on 20 March, Messi became the top goalscorer in Barcelona's history at 24 years old, overtaking the 57-year record of César Rodríguez's 232 goals with a hat-trick against Granada.[128]
",3
2449,"Despite Messi's individual form, Barcelona's four-year cycle of success under Guardiola – one of the greatest eras in the club's history – drew to an end.[133] Although Barcelona won the Copa del Rey against Athletic Bilbao on 25 May, its 14th title of that period, the team lost the league to Real Madrid and was eliminated in the Champions League semi-finals by the eventual champions, Chelsea, with Messi sending a crucial second-leg penalty kick against the crossbar.[134][135] In Barça's last home league match on 5 May, against Espanyol, Messi scored all four goals before approaching the bench to embrace Guardiola, who had announced his resignation as manager.[136] He finished the season as league top scorer in Spain and Europe for a second time, with 50 goals, a La Liga record, while his 73 goals in all competitions surpassed Gerd Müller's 67 goals in the 1972–73 Bundesliga season, making him the single-season top scorer in the history of European club football.[137][138]
",3
2450,"Under manager Tito Vilanova, who had first coached him aged 14 at La Masia, Messi helped the club achieve its best-ever start to a La Liga season during the second half of 2012, amassing 55 points by the competition's midway point, a record in Spanish football.[139][140] A double scored on 9 December against Real Betis saw Messi break two longstanding records: he surpassed César Rodríguez's record of 190 league goals, becoming Barcelona's all-time top scorer in La Liga, and Gerd Müller's record of most goals scored in a calendar year, overtaking his 85 goals scored in 1972 for Bayern Munich and West Germany.[141] Messi sent Müller a number 10 Barcelona shirt, signed ""with respect and admiration"", after breaking his 40-year record.[142] At the close of the year, Messi had scored a record 91 goals in all competitions for Barcelona and Argentina.[143] Although FIFA did not acknowledge the achievement, citing verifiability issues, he received the Guinness World Records title for most goals scored in a calendar year.[144][145] As the odds-on favourite, Messi again won the FIFA Ballon d'Or, becoming the only player in history to win the Ballon d'Or four times.[143][146]
",3
2451,"Barcelona had virtually secured their La Liga title by the start of 2013, eventually equalling Real Madrid's 100-point record of the previous season. However, their performances deteriorated in the second half of the 2012–13 campaign, concurrently with Vilanova's absence due to ill health.[147] After losing successive Clásicos, including the Copa del Rey semi-finals, they were nearly eliminated in the first knockout round of the Champions League by Milan, but a revival of form in the second leg led to a 4–0 comeback, with two goals and an assist from Messi.[148] Now in his ninth senior season with Barcelona, Messi signed a new contract on 7 February, committing himself to the club through 2018, while his fixed wage rose to €13 million.[149][150] He wore the captain's armband for the first time a month later, on 17 March, in a league match against Rayo Vallecano; by then, he had become the team's tactical focal point to a degree that was arguably rivalled only by former Barcelona players Josep Samitier, László Kubala and Johan Cruyff.[151] Since his evolution into a false nine three years earlier, his input into the team's attack had increased; from 24% in their treble-winning campaign, his goal contribution rose to more than 40% that season.[152]
",3
2452,"– Defender Gerard Piqué explains Barcelona's reliance on an unfit Messi against Paris Saint-Germain in April 2013.[153]
",3
2453,"After four largely injury-free seasons, the muscular injuries that had previously plagued Messi reoccurred. After he suffered a hamstring strain on 2 April, during the first quarter-final against Paris Saint-Germain, his appearances became sporadic. In the second leg against PSG, with an underperforming Barcelona down a goal, Messi came off the bench in the second half and within nine minutes helped create their game-tying goal, which allowed them to progress to the semi-finals. Still unfit, he proved ineffective during the first leg against Bayern Munich and was unable to play at all during the second, as Barcelona were defeated 7–0 on aggregate by the eventual champions.[154] These matches gave credence to the notion of Messidependencia, Barcelona's perceived tactical and psychological dependence on their star player.[154]
",3
2454,"Messi continued to struggle with injury throughout 2013, eventually parting ways with his long-time personal physiotherapist.[155] Further damage to his hamstring sustained on 12 May ended his goalscoring streak of 21 consecutive league games, a worldwide record; he had netted 33 goals during his run, including a four-goal display against Osasuna, while becoming the first player to score consecutively against all 19 opposition teams in La Liga.[156][157] With 60 goals  in all competitions, including 46 goals in La Liga, he finished the campaign as league top scorer in Spain and Europe for the second consecutive year, becoming the first player in history to win the European Golden Shoe three times.[158][159] Following an irregular start to the new season under manager Gerardo Martino, formerly of his boyhood club Newell's Old Boys, Messi suffered his fifth injury of 2013 when he tore his hamstring on 10 November, leaving him sidelined for two months.[160][161] Despite his injuries, he was voted runner-up for the FIFA Ballon d'Or, relinquishing the award after a four-year monopoly to Cristiano Ronaldo.[162]
",3
2455,"During the second half of the 2013–14 season, doubts persisted over Messi's form, leading to a perception among the culés that he was reserving himself for the 2014 FIFA World Cup. Statistically, his contribution of goals, shots, and passes had dropped significantly compared to previous seasons.[163][164] He still managed to break two longstanding records in a span of seven days: a hat-trick on 16 March against Osasuna saw him overtake Paulino Alcántara's 369 goals to become Barcelona's top goalscorer in all competitions including friendlies, while another hat-trick against Real Madrid on 23 March made him the all-time top scorer in El Clásico, ahead of the 18 goals scored by former Real Madrid player Alfredo Di Stéfano.[163][165] Messi finished the campaign with his worst output in five seasons, though he still managed to score 41 goals in all competitions.[164][166] For the first time in five years, Barcelona ended the season without a major trophy; they were defeated in the Copa del Rey final by Real Madrid and lost the league in the last game to Atlético Madrid, causing Messi to be booed by sections of fans at the Camp Nou.[167] After prolonged speculation over his future with the club, Messi signed a new contract on 19 May 2014, only a year after his last contractual update; his salary increased to €20 million, or €36 million before taxes, the highest wage in the sport.[168]
",3
2456,"Under new manager and former captain Luis Enrique, Messi experienced a largely injury-free start to the 2014–15 season, allowing him to break three more longstanding records towards the end of the year.[169] A hat-trick scored against Sevilla on 22 November made him the all-time top scorer in La Liga, as he surpassed the 59-year record of 251 league goals held by Telmo Zarra.[170] A third hat-trick, scored against city rivals Espanyol on 7 December, allowed him to surpass César Rodríguez as the all-time top scorer in the Derbi barceloní with 12 goals.[171] Messi again placed second in the FIFA Ballon d'Or behind Cristiano Ronaldo, largely owing to his second-place achievement with Argentina at the World Cup.[172]
",3
2457,"At the start of 2015, Barcelona were perceived to be headed for another disappointing end to the season, with renewed speculation in the media that Messi was leaving the club. A turning point came on 11 January during a 3–1 victory over Atlético Madrid, the first time Barça's attacking trident of Messi, Luis Suárez and Neymar, dubbed ""MSN"", each scored in a match, marking the beginning of a highly successful run.[173][174] After five years of playing in the centre of the pitch, Messi had returned to his old position on the right wing late the previous year, by his own suggestion according to Suárez, their striker.[174][175] From there, he regained his best – arguably his best-ever – form, while Suárez and Neymar ended the team's attacking dependency on their star player.[176][177] With 58 goals  from Messi, the trio scored a total of 122 goals in all competitions that season, a record in Spanish football.[178]
",3
2458,"Towards the end of the campaign, Messi scored in a 1–0 away win over Atlético Madrid on 17 May, securing the La Liga title.[180] Among his 43 league goals that season was a hat-trick scored in 11 minutes against Rayo Vallecano on 8 March, the fastest of his senior career; it was his 32nd hat-trick overall for Barcelona, allowing him to overtake Telmo Zarra with the most hat-tricks in Spanish football.[181] As the season's top assist provider with 18 he surpassed Luís Figo with the most assists in La Liga;[note 3] he made his record 106th assist in a fixture against Levante on 15 February, in which he also scored a hat-trick.[182][183][184] Messi scored twice as Barcelona defeated Athletic Bilbao 3–1 in the Copa del Rey final on 30 May, achieving the sixth double in their history. His opening goal was hailed as one of the greatest in his career; he collected the ball near the halfway line and beat four opposing players, before feinting the goalkeeper to score in a tight space by the near post.[185]
",3
2459,"In the Champions League, Messi scored twice and assisted on another in their 3–0 semi-final victory over Bayern Munich, now under the stewardship of Guardiola.[186] His second goal, which came only three minutes after his first, saw him chip the ball over goalkeeper Manuel Neuer after his dribble past Jérôme Boateng had made the defender drop to the ground; it went viral, becoming the year's most tweeted about sporting moment, and was named the best goal of the season by UEFA.[187][188] Despite a second-leg loss, Barcelona progressed to the final on 6 June in Berlin, where they defeated Juventus 3–1 to win their second treble, becoming the first team in history to do so.[189][190] Although Messi did not score, he participated in each of his side's goals, particularly the second as he forced a parried save from goalkeeper Gianluigi Buffon from which Suárez scored the match-winning goal on the rebound.[178] In addition to being the top assist provider with six assists, Messi finished the competition as the joint top scorer with ten goals, which earned him the distinction of being the first player ever to achieve the top scoring mark in five Champions League seasons.[191][192] For his efforts during the season, he received the UEFA Best Player in Europe award for a second time.[193]
",3
2460,"Messi opened the 2015–16 season by scoring twice from free kicks in Barcelona's 5–4 victory (after extra time) over Sevilla in the UEFA Super Cup.[194] On 16 September, he became the youngest player to make 100 appearances in the UEFA Champions League in a 1–1 away draw to Roma.[195] After a knee injury, he returned to the pitch on 21 November, making a substitute appearance in Barcelona's 4–0 away win over rivals Real Madrid in El Clásico.[196] Messi capped off the year by winning the 2015 FIFA Club World Cup Final on 20 December, collecting his fifth club trophy of 2015 as Barcelona defeated River Plate 3–0 in Yokohama.[197] On 30 December, Messi scored on his 500th appearance for Barcelona, in a 4–0 home win over Real Betis.[198]
",3
2461,"On 11 January 2016, Messi won the FIFA Ballon d'Or for a record fifth time in his career.[199] On 3 February, he scored a hat-trick in Barcelona's 7–0 win against Valencia in the first leg of the Copa del Rey semi-final at the Camp Nou.[200] In a 6–1 home win against Celta Vigo in the league, Messi assisted Suárez from a penalty kick. Some saw it as ""a touch of genius"", while others criticised it as being disrespectful to the opponent. The Celta players never complained and their coach defended the penalty, stating, ""Barca's forwards are very respectful."" The penalty routine has been compared to that of Barça icon Johan Cruyff in 1982, who was battling lung cancer, leading many fans to indicate that the penalty was a tribute to him. Cruyff himself was ""very happy"" with the play, insisting ""it was legal and entertaining"".[201][202]
",3
2462,"On 17 February, Messi reached his 300th league goal in a 1–3 away win against Sporting de Gijón.[203] A few days later, he scored both goals in Barcelona's 0–2 win against Arsenal at the Emirates Stadium, in the first leg of the 2015–16 UEFA Champions League round of 16, with the second goal being Barcelona's 10,000th in official competitions.[204] On 17 April, Messi ended a five-match scoring drought with his 500th senior career goal for club and country in Barcelona's 2–1 home loss to Valencia.[205] Messi finished the 2015–16 season by setting up both goals in Barcelona's 2–0 extra time win over Sevilla in the 2016 Copa del Rey Final, at the Vicente Calderón Stadium, on 22 May 2016, as the club celebrated winning the domestic double for the second consecutive season.[206] In total, Messi scored 41 goals and provided 23 assists, as Barcelona's attacking trio managed a Spanish record of 131 goals throughout the season, breaking the record they had set the previous season.[207]
",3
2463,"– In an interview with Barcelona's official magazine, Javier Mascherano outlines Messi's importance to the team.[208]
",3
2464,"Messi opened the 2016–17 season by lifting the 2016 Supercopa de España as Barcelona's captain in the absence of the injured Andrés Iniesta;[209] he set-up Munir's goal in a 2–0 away win over Sevilla in the first leg on 14 August,[210] and subsequently scored and assisted in a 3–0 win in the return leg on 17 August.[211] Three days later, he scored two goals and provided an assist to lead Barcelona to a 6–2 victory against Real Betis in the opening game of the 2016–17 La Liga season.[212] On 13 September 2016, Messi scored his first hat-trick of the season in the opening game of the 2016–17 UEFA Champions League campaign against Celtic in a 7–0 victory; this was also Messi's sixth hat-trick in the Champions League, the most by any player. A week later, Messi sustained a groin injury in a 1–1 draw against Atlético Madrid and was ruled out with injury for three weeks.[213] He marked his return with a goal, scoring three minutes after coming off the bench in a 4–0 home win over Deportivo de La Coruña, on 16 October.[214] Three days after this, he netted his thirty-seventh club hat-trick as Barcelona defeated Manchester City 4–0.[215] On 1 November, Messi scored his 54th Champions League group stage goal in Barcelona's 3–1 away loss to Manchester City, surpassing the previous record of 53 goals held by Raúl.[216]
",3
2465,"Messi finished the year with 51 goals, making him Europe's top scorer, one ahead of Zlatan Ibrahimović.[217] After placing second in the 2016 Ballon d'Or, on 9 January 2017 Messi also finished in second place – behind Cristiano Ronaldo once again – in the 2016 Best FIFA Men's Player Award.[218] On 11 January, Messi scored from a free-kick in Barcelona's 3–1 victory against Athletic Bilbao in the second leg of the round of 16 of the Copa del Rey, which enabled Barcelona to advance to the quarter-finals of the competition; with his 26th goal from a free-kick for Barcelona in all competitions, he equalled the club's all-time record, which had previously been set by Ronald Koeman.[219] In his next league match, on 14 January, Messi scored in a 5–0 win against Las Palmas; with this goal, he equalled Raúl's record for the most teams scored against in La Liga (35).[220]
",3
2466,"On 4 February 2017, Messi scored his 27th free-kick for Barcelona in a 3–0 home win over Athletic Bilbao in the league, overtaking Koeman as the club's all-time top-scorer from free-kicks.[221] On 23 April, Messi scored twice in a 3–2 away win over Real Madrid. His game-winning goal in stoppage time was his 500th for Barcelona.[222] His memorable celebration saw him taking off his Barcelona shirt and holding it up to incensed Real Madrid fans – with his name and number facing the crowd.[223] On 27 May, Messi scored a goal and set up another for Paco Alcácer in the 2017 Copa del Rey Final, helping Barcelona to a 3–1 victory over Alavés, and was named Man of the Match.[224] In total, Messi finished the 2016–17 season with 54 goals and 16 assists, while his 37 goals in La Liga saw him claim both the Pichichi and European Golden Boot Awards for the fourth time in his career.[225]
",3
2467,"Messi opened the 2017–18 season by converting a penalty in Barcelona's 1–3 first leg home defeat to Real Madrid in Supercopa de España.[226] Thereby, Messi also extended his El Clásico goalscoring record with the goal being his 24th official and 25th overall.[227]
On 9 September, Messi scored his first hat-trick of the 2017–18 league campaign, against Espanyol in Derbi barceloní, thus helping to secure a 5–0 home victory for Blaugrana over local rivals.[228] Messi netted twice against Gianluigi Buffon, on 12 September, as Barça defeated the last season's Italian champions Juventus 3–0 at home in the UEFA Champions League.[229] On 19 September, Messi found the net four times in a 6–1 trashing of Eibar at the Camp Nou in La Liga.[230] Three weeks later, on 1 October, Messi surpassed his former teammate Carles Puyol to become the third highest appearance maker in the club's history, as he helped Barça defeat Las Palmas 3–0 by assisting Sergio Busquets' opener and later adding two himself in his 594th official game for the club; the league game was played behind closed doors at the Camp Nou due to violence in Catalonia relating to an ongoing independence referendum.[231]
",3
2468,"On 18 October, in his 122nd European club appearance, Messi scored his 97th UEFA Champions League goal, and his 100th in all UEFA club competitions, in a 3–1 home victory over Olympiacos.[232] Messi became only the second player after Cristiano Ronaldo to reach this century milestone, but accomplished it in 21 fewer appearances than the Portuguese counterpart.[233] On 4 November, he made his 600th appearance for Barcelona in a 2–1 home win over Sevilla in La Liga.[234] Following the reception of his fourth Golden Boot, Messi signed a new deal with Barcelona on 25 November, keeping him with the club through the 2020–21 season. His buyout clause was set at €700 million.[235] On 7 January 2018, Messi made his 400th La Liga appearance with Barcelona in a 3–0 home win over Levante, marking the occasion with his 144th league assist and 365th league goal for the club, the latter of which saw him equal Gerd Müller's record for the most league goals scored for the same club in one of Europe's top five divisions.[236] A week later, he broke the record, scoring his 366th La Liga goal from a free kick in a 4–2 away win against Real Sociedad.[236]
",3
2469,"On 4 March, he scored his 600th senior career goal from a free kick in a 1–0 home win over Atlético Madrid, in La Liga.[237] On 14 March, Messi scored his 99th and 100th Champions League goals in a 3–0 home win over Chelsea, becoming only the second player after Cristiano Ronaldo to reach this landmark, in fewer appearances, at a younger age and having taken fewer shots than his Portuguese counterpart.[238] His opening goal, which came after only two minutes and eight seconds, was also the fastest of his career, as Barcelona advanced to the quarter-finals of the competition for the eleventh consecutive season.[239] On 7 April, he scored a hat-trick in a 3–1 win over Leganés including his sixth goal scored from a free-kick for the season, matching the record set by former teammate Ronaldinho.[240] He once again finished the season as the top scorer in La Liga, with 34 goals, which also saw him win his fifth Golden Shoe award.[241] On 21 April, Messi scored Barcelona's second goal – his 40th of the season – in a 5–0 win over Sevilla in the 2018 Copa del Rey Final, later also setting up Suárez's second goal; this was Barcelona's fourth consecutive title and their 30th overall.[242] On 29 April, Messi scored a hat-trick in a 4–2 away win over Deportivo de La Coruña, which saw Barcelona claim their 25th league title.[243] On 9 May, Messi scored as Barcelona defeated Villarreal 5–1 to set the longest unbeaten streak (43 games) in La Liga history.[244]
",3
2470,"With the departure of former captain Andrés Iniesta in May 2018, Messi was named the team's new captain for the following season.[245] On 12 August 2018, he lifted his first title as Barcelona's captain, the Supercopa de España, following a 2–1 victory over Sevilla. On 19 August, Messi scored twice in helping Barcelona defeat Alavés 3–0 in their first La Liga match of the season, with his first goal, a free kick that he rolled under the jumping Alavés wall, making history in being Barcelona's 6000th goal in La Liga.[246] On 18 September, Messi scored a hat-trick in a 4–0 home win over PSV Eindhoven in Barcelona's opening Champions League group stage match of the season, setting a new record for most hat-tricks in the competition, with eight.[247] On 20 October, Messi scored and assisted in a 4–2 home win over Sevilla, but was later forced off in the 26th minute after falling awkwardly and injuring his right arm; tests later confirmed that he had fractured his radial bone, ruling him out for approximately three weeks.[248] On 8 December, Messi scored two free kicks – his ninth and tenth goals from set pieces during the calendar year – in a 4–0 away win over Derbi barceloní rivals Espanyol in La Liga; this was the first time ever that he had managed such a feat in the league. His first goal was also his 10th league goal of the season, making him the first player ever to reach double figures in La Liga for 13 consecutive seasons.[249]
",3
2471,"On 13 January 2019, Messi scored his 400th La Liga goal in his 435th league appearance in a 3–0 home win over Eibar, becoming the first player ever to manage this tally in just one of Europe's top five leagues.[250] On 2 February, Messi scored twice in a 2–2 draw against Valencia, with his first goal coming from the penalty spot, his 50th La Liga penalty goal; as such, he became only the third player in La Liga history after Cristiano Ronaldo and Hugo Sánchez to score 50 penalties in the competition.[251] Later that month, the club admitted they had begun preparations for Messi's future retirement.[252] On 23 February, Messi scored the 50th hat-trick of his career and also provided an assist for Suárez, as he helped Barcelona come from behind to achieve a 4–2 away victory over Sevilla in La Liga; the goal was also his 650th career goal for club and country at senior level.[253] On 16 April, Messi scored twice in a 3–0 home victory over Manchester United in the second leg of the Champions League quarter-finals to give Barcelona a 4–0 aggregate win, which saw Barcelona progress to the semi-finals of the competition for the first time since 2015; these were also his first goals in the Champions League quarter-finals since 2013.[254][255]
",3
2472,"On 27 April, Messi came off the bench and scored the only goal in a 1–0 home win over Levante, which allowed Barcelona to clinch the league title;[256] this was his 450th La Liga appearance, and his first league title as Barcelona's captain.[257][258] On 1 May, Messi scored twice in a 3–0 home win over Liverpool in the first leg of the Champions League semi-finals; his second goal of the match, a 35-yard free kick, was the 600th senior club goal of his career, all of which had been scored with Barcelona.[259] In the return leg six days later at Anfield, Barcelona suffered a 4–0 away defeat, which saw Liverpool advance to the final 4–3 on aggregate.[260] On 19 May, in Barcelona's final La Liga match of the season, Messi scored twice in a 2–2 away draw against Eibar (his 49th and 50th goals of the season in all competitions), which saw him capture his sixth Pichichi Trophy as the league's top scorer, with 36 goals in 34 appearances; with six titles, he equalled Zarra as the player with the most top-scorer awards in La Liga.[261] He also captured his sixth Golden Shoe award, and a record third consecutive award since the 2016–17 season.[262] On 25 May, Messi scored his final goal of the season in a 2–1 defeat to Valencia in the 2019 Copa del Rey Final.[263]
",3
2473,"On 5 August 2019, it was announced that Messi would miss Barcelona's US tour after sustaining a right calf injury.[264] On 19 August, Messi's chipped goal from the edge of the box against Real Betis was nominated for the 2019 FIFA Puskás Award.[265] Later that month, he suffered another setback following the return of his calf injury, which ruled him out of the opening game of the season;[266] as a result, he was sidelined indefinitely, and was only expected to return to action with Barcelona after the September international break.[267] On 2 September, Messi was shortlisted as one of the three finalists for both the 2019 FIFA Puskás Award and the 2019 Best FIFA Men's Player Award, with Messi winning the latter on 23 September.[268][269]
",3
2474,"Messi made his first appearance of the season on 17 September, and on 6 October he scored his first goal of the season with a free kick in a 4–0 home win over Sevilla; this was his 420th goal in La Liga, which saw him break Cristiano Ronaldo's record of 419 goals scored in Europe's top five leagues.[270] On 23 October, Messi scored his first Champions League goal of the season in a 2–1 away win over Slavia Prague, becoming the first player to score in 15 consecutive Champions League seasons (excluding qualifying rounds).[271] He also equalled Raúl and Cristiano Ronaldo's shared record of the most sides scored against in the competition (33).[272] On 29 October, Messi scored and assisted twice in a 5–1 home win over Real Valladolid in La Liga; his first goal – a set piece from 35 yards – was the 50th free-kick of his career.[273] His goals (608) also saw him overtake Cristiano Ronaldo's senior goal tally (606) at club level.[274] On 9 November, Messi scored three goals (including two free kicks) in a 4–1 home win against Celta Vigo. This was his 34th hat-trick in La Liga, equalling Cristiano Ronaldo's Spanish top-flight record.[275] On 27 November, in what was his 700th appearance for Barcelona, Messi scored one goal and assisted two more in a 3–1 home win over Borussia Dortmund in the UEFA Champions League. Borussia Dortmund was the 34th team he had scored against in the competition, breaking the previous record of 33 held by Cristiano Ronaldo and Raúl.[276] On 2 December, Messi was awarded a record-breaking sixth Ballon d'Or.[277] On 8 December, Messi scored his record-breaking 35th hat-trick in La Liga with three goals in Barcelona's 5–2 home win over Mallorca.[278]
",3
2475,"On 22 February 2020, Messi scored four goals in a 5–0 home win over Eibar in La Liga.[279] On 14 June, in a 4–0 away win against Mallorca, Messi assisted twice and scored another, becoming the first player ever in La Liga to score 20 goals or more in 12 consecutive seasons.[280] On 30 June, he scored a panenka in a 2–2 home draw against Atlético Madrid in La Liga, to reach his 700th goal in his senior career for Barcelona and Argentina.[281] On 11 July, Messi provided his 20th assist of the league season for Arturo Vidal in a 1–0 away win over Real Valladolid, equalling Xavi's record of 20 assists in a single La Liga season from 2008 to 2009;[282][283][284] with 22 goals, he also became only the second player ever, after Thierry Henry in the 2002–03 FA Premier League season with Arsenal (24 goals and 20 assists), to record at least 20 goals and 20 assists in a single league season in one of Europe's top–five leagues.[284][285] Following his brace in a 5–0 away win against Alavés in the final match of the season on 20 May, Messi finished the season as both the top–scorer and top assist provider in La Liga, with 25 goals and 21 assists respectively, which saw him win his record seventh Pichichi trophy, overtaking Zarra; however, Barcelona missed out on the league title to Real Madrid.[286] On 9 August, in the Champions League round of 16 second leg versus Napoli at the Camp Nou, Messi scored the second goal and earned a penalty which led to a third goal and led his side to a 3–1 home victory and qualified 4–2 on aggregate for the quarter-finals against Bayern Munich.[287] On 15 August, Messi suffered his worst defeat as a player as Bayern Munich beat Barcelona 8–2 in a one-off tie in Lisbon, leading to another disappointing exit from the Champions League.[288]
",3
2476,"– Messi on reversing his decision to leave Barcelona in an interview with Goal on 4 September 2020.[289]
",3
2477,"Following growing dissatisfaction with the direction of Barcelona on and off the field,[290] Barcelona announced that Messi sent the club ""a document expressing his desire to leave"" on 25 August 2020.[291] The announcement garnered a significant media response, including from current and former teammates (who supported Messi's statement) and Catalan president Quim Torra.[292] On August 26, Barcelona's sporting director Ramon Planes iterated the club's desire to ""build a team around the most important player in the world""[293] and affirmed Messi will only be able to leave should a buyer pay his €700 million buyout clause; a reported early termination option available in Messi's contract (which would have allowed him to leave the club for free) could only be exercised if he had communicated his decision to Barcelona by 31 May 2020, although the player's representatives argued the deadline should be set to 31 August, due to the adjourned 2019–20 season.[294] On 30 August, La Liga issued a statement stating Messi's contract and buyout clause are still active.[295]
",3
2478,"On 4 September, Jorge Messi, Lionel's father and agent, released a statement in response to La Liga claiming the release clause ""is not valid when the termination of the contract is by the player's unilateral decision from the end of the 2019–20 season"", as stated in Messi's contract with Barcelona;[296] moments later, La Liga issued a response reiterating their statement published on 30 August.[297] Later that evening, Messi announced in an interview with Goal that he would continue at Barcelona for the final year of his contract. In the interview, Messi claimed to have informed Barcelona of his desire to leave multiple times, and club president Josep Bartomeu said Messi could decide at the end of every season if he could stay or leave, only for Bartomeu to refer to the release clause.[298] This left Messi with two options: to stay or go to court against the club, with the player saying ""I would never go to court against the club of my life"".[299]
",3
2479,"On 27 September, Messi began the 2020–21 season by scoring a penalty in a 4–0 home win against Villarreal in La Liga.[300] Two days prior to the opening game, he again criticised the club, this time for the manner of Luis Suárez's departure, stating, ""at this stage nothing surprises me any more"".[301] On 20 October, Messi scored a penalty and assisted the fifth goal in a 5–1 home victory against Ferencváros in the Champions League, becoming the first player in history to score in 16 consecutive Champions League seasons.[302] On 25 November, Messi was nominated for the 2020 Best FIFA Men's Player award and was later shortlisted as one of the final three nominees.[303][304] On 29 November, Messi scored his side's fourth goal in their 4–0 victory over Osasuna. After scoring, he unveiled a shirt of his former side Newell's Old Boys, in tribute to Argentine compatriot Diego Maradona, who had passed away four days earlier, and raised both hands to the screen showing Maradona's face in the stadium. The shirt was a number 10 replica of the same one Maradona had worn during his stint with the club in 1993.[305] On 17 December, Messi finished third in The Best FIFA Men's Player award behind Robert Lewandowski and Cristiano Ronaldo and was included in the FIFA FIFPro World XI for the 14th consecutive year.[306]
",3
2480,"On 23 December, Messi scored his 644th goal for Barcelona against Real Valladolid in La Liga, surpassing Pelé with Santos as the player with the most goals scored for a single club.[307][308] In order to celebrate his achievement, Budweiser sent personalised bottles of beer to every goalkeeper whom Messi has scored against.[309] On 17 January 2021, he was sent off for the first time in his club career for violent conduct (swinging an arm at the head of Asier Villalibre, missed initially by the referee but reviewed via VAR) in the final minutes of extra time in the 2020–21 Supercopa de España Final which Barcelona lost 2–3 to Athletic Bilbao.[310] On 21 February, he broke Xavi's club record for most appearances in La Liga with his 506th league match for Barcelona against Cádiz, also scoring from a penalty in the 1–1 home draw.[311] On 10 March, Messi scored from 35 yards out and later had a penalty saved in a 1–1 draw against Paris Saint-Germain F.C. at the Parc des Princes in the second leg of the Champions League round of 16 as Barcelona were eliminated at this stage for the first time in 14 years by an aggregate score of 2–5 after having lost 1–4 at home on 16 February.[312]
",3
2481,"As a dual Argentine-Spanish national, Messi was eligible to play for the national team of both countries.[313] Selectors for Spain's Under-17 squad began pursuing him in 2003 after Barcelona's director of football, Carles Rexach, alerted the Royal Spanish Football Federation to their young player. Messi declined the offer, having aspired to represent La Albiceleste since childhood. To further prevent Spain from taking him, the Argentine Football Association organised two under-20 friendlies in June 2004, against Paraguay and Uruguay, with the purpose of finalising his status as an Argentina player in FIFA. Five days after his 17th birthday, on 29 June, he made his debut for his country against Paraguay, scoring once and providing two assists in their 8–0 victory. He was subsequently included in the squad for the South American Youth Championship, held in Colombia in February 2005. As he lacked the stamina of his teammates, the result of his former growth hormone deficiency, he was used as a substitute in six of the nine games. After being named man of the match against Venezuela, he scored the winning 2–1 goal in the crucial last match against Brazil, thereby securing their third-place qualification for the FIFA World Youth Championship.[314]
",3
2482,"Aware of his physical limitations, Messi employed a personal trainer to increase his muscle mass, returning to the squad in an improved condition in time for the World Youth Championship, hosted by the Netherlands in June 2005. After he was left out of the starting line-up in their first match against the United States, a 1–0 defeat, the squad's senior players asked manager Francisco Ferraro to let Messi start, as they considered him their best player. After helping the team defeat Egypt and Germany to progress past the group stage, Messi proved decisive in the knockout phase as he scored their equaliser against Colombia, provided a goal and an assist against title favourites Spain, and scored their opening goal against reigning champions Brazil. Ahead of the final, he was awarded the Golden Ball as the best player of the tournament. He scored two penalties in their 2–1 victory over Nigeria, clinching Argentina's fifth championship and finishing the tournament as top scorer with 6 goals.[315][316] His performances drew comparisons with compatriot Diego Maradona, who had led Argentina to the title in 1979.[316]
",3
2483,"In recognition of his achievements with the under-20 side, senior manager José Pékerman gave Messi his first call-up for a friendly against Hungary on 17 August 2005. Aged 18, Messi made his senior debut for Argentina in the Ferenc Puskás Stadium when he came on in the 63rd minute, only to be sent off after two minutes for a perceived foul against Vilmos Vanczák, who had grabbed his shirt; Messi had struck the defender with his arm while trying to shake him off, which the referee interpreted as an intentional elbowing, a contentious decision.[317] Messi was reportedly found weeping in the dressing room after his sending-off.[318] He returned to the team on 3 September in their World Cup qualifier defeat to Paraguay, which he had declared his ""re-debut"" ahead of the match.[319] Messi started his first game in the next qualifying match against Peru, in which he was able to win a crucial penalty that secured their victory. After the match, Pékerman described him as ""a jewel"".[320] He subsequently made regular appearances for the team ahead of Argentina's participation in the 2006 FIFA World Cup, scoring his first goal in a friendly against Croatia on 1 March 2006.[321] A hamstring injury sustained a week later jeopardised his presence in the World Cup, but he was nevertheless selected for Pékerman's squad and regained fitness in time for the start of the tournament.[322]
",3
2484,"During the World Cup in Germany, Messi witnessed their opening match victory against the Ivory Coast from the substitutes' bench. In the next match, against Serbia and Montenegro, he became the youngest player to represent Argentina at a FIFA World Cup when he came on as a substitute in the 74th minute. He assisted their fourth strike within minutes and scored the final goal in their 6–0 victory, making him the youngest scorer in the tournament and the sixth-youngest goalscorer in the history of the World Cup.[323] As their progression to the knockout phase was secured, several starters were rested during the last group match. Messi consequently started the game against the Netherlands, a 0–0 draw, as they won their group on goal differential.[324][325] In the round of 16 match against Mexico, played on his 19th birthday, Messi came on in the 84th minute, with the score tied at 1–1. He appeared to score a goal, but it was contentiously ruled offside, with the team needing a late goal in extra time to proceed.[326][327] He did not play in the quarter-final against Germany, during which Argentina were eliminated 4–2 in a penalty shootout.[328] Back home, Pékerman's decision to leave him on the bench against Germany led to widespread criticism from those who believed Messi could have changed the outcome of the match in Argentina's favour.[329][330]
",3
2485,"As Messi evolved into one of the best players in the world, he secured a place in Alfio Basile's starting line-up, as part of a team considered favourites to win the 2007 Copa América, held in Venezuela.[62][331] He set up the game-winning goal of their 4–1 victory over the United States in the opening match, before winning a penalty that led to the game-tying first strike of their 4–2 win in the next match against Colombia.[332][333] As they had secured their place in the knockout phase, Messi started the next game on the bench, coming on in the last 25 minutes with the score at 0–0 to help his team defeat Paraguay by assisting their only goal. At the quarter-final stage, where the group winners faced Peru, he scored the second goal of a 4–0 victory that saw them through to the semi-final, during which he chipped the ball over Mexico's goalkeeper to ensure another 3–0 win.[331] In a surprise defeat, Argentina lost the final 3–0 to a Brazil squad that lacked several of the nation's best players.[334] Their unexpected loss was followed by much criticism in Argentina, though Messi was mostly exempt due to his young age and secondary status to star player Juan Román Riquelme.[331] He was named the best young player of the tournament by CONMEBOL.[335]
",3
2486,"Ahead of the 2008 Summer Olympics, Barcelona legally barred Messi from representing Argentina at the tournament as it coincided with their Champions League qualifying matches.[336] After interference from newly appointed Barcelona manager Pep Guardiola, who had won the tournament in 1992, Messi was permitted to join Sergio Batista's under-23 squad in Beijing.[337] During the first match, he scored the opening goal and assisted another in their 2–1 victory over the Ivory Coast. Following a 1–0 win in the next group match against Australia, ensuring their quarter-final qualification, Messi was rested during the game against Serbia, while his side won the match to finish first in their group. Against the Netherlands, he again scored the first goal and assisted a second strike to help his team to a 2–1 win in extra time. After a 3–0 semi-final victory over Brazil, Messi assisted the only goal in the final as Argentina defeated Nigeria to claim Olympic gold medals.[338] Along with Riquelme, Messi was singled out by FIFA as the stand-out player from the tournament's best team.[339]
",3
2487,"From late 2008, the national team experienced a three-year period marked by poor performances.[331] Under manager Diego Maradona, who had led Argentina to World Cup victory as a player, the team struggled to qualify for the 2010 World Cup, securing their place in the tournament only after defeating Uruguay 1–0 in their last qualifying match. Maradona was criticised for his strategic decisions, which included playing Messi out of his usual position. In eight qualifying matches under Maradona's stewardship, Messi scored only one goal, netting the opening goal in the first such match, a 4–0 victory over Venezuela.[321][340] During that game, played on 28 March 2009, he wore Argentina's number 10 shirt for the first time, following the international retirement of Riquelme.[341] Overall, Messi scored four goals in 18 appearances during the qualifying process.[321] Ahead of the tournament, Maradona visited Messi in Barcelona to request his tactical input; Messi then outlined a 4–3–1–2 formation with himself playing behind the two strikers, a playmaking position known as the enganche in Argentine football, which had been his preferred position since childhood.[342]
",3
2488,"Despite their poor qualifying campaign, Argentina were considered title contenders at the World Cup in South Africa. At the start of the tournament, the new formation proved effective; Messi managed at least four attempts on goal during their opening match but was repeatedly denied by Nigeria's goalkeeper, resulting in a 1–0 win. During the next match, against South Korea, he excelled in his playmaking role, participating in all four goals of his side's 4–1 victory. As their place in the knockout phase was guaranteed, most of the starters were rested during the last group match, but Messi reportedly refused to be benched.[340] He wore the captain's armband for the first time in their 2–0 win against Greece; as the focal point of their play, he helped create their second goal to see Argentina finish as group winners.[343] In the round of 16, they defeated Mexico 3–1, with Messi assisting their first goal, a controversial strike that stood despite being offside.[344]
",3
2489,"Argentina were eliminated in the quarter-final against Germany, at the same stage of the tournament and by the same opponent as four years earlier. Their 4–0 loss was their worst margin of defeat at a World Cup since 1974.[344] FIFA subsequently identified Messi as one of the tournament's 10 best players, citing his ""outstanding"" pace and creativity and ""spectacular and efficient"" dribbling, shooting and passing.[345] Back home, however, Messi was the subject of harsher judgement. As the perceived best player in the world, he had been expected to lead an average team to the title, as Maradona arguably did in 1986, but he had failed to replicate his performances at Barcelona with the national team, leading to the accusation that he cared less about his country than his club.[346]
",3
2490,"Maradona was replaced by Sergio Batista, who had orchestrated Argentina's Olympic victory. Batista publicly stated that he intended to build the team around Messi, employing him as a false nine within a 4–3–3 system, as used to much success by Barcelona.[346][347] Although Messi scored a record 53 goals during the 2010–11 club season, he had not scored for Argentina in an official match since March 2009.[115][321] Despite the tactical change, his goal drought continued during the 2011 Copa América, hosted by Argentina. Their first two matches, against Bolivia and Colombia, ended in draws. Media and fans noted that he did not combine well with striker Carlos Tevez, who enjoyed greater popularity among the Argentine public; Messi was consequently booed by his own team's supporters for the first time in his career. During the crucial next match, with Tevez on the bench, he gave a well-received performance, assisting two goals in their 3–0 victory over Costa Rica. After the quarter-final against Uruguay ended in a 1–1 draw following extra time, with Messi having assisted their equaliser, Argentina were eliminated 4–5 in the penalty shootout by the eventual champions.[346]
",3
2491,"After Argentina's unsuccessful performance in the Copa América, Batista was replaced by Alejandro Sabella. Upon his appointment in August 2011, Sabella awarded the 24-year-old Messi the captaincy of the squad, in accord with then-captain Javier Mascherano. Reserved by nature, Messi went on to lead his squad by example as their best player, while Mascherano continued to fulfil the role of the team's on-field leader and motivator.[348][349] In a further redesign of the team, Sabella dismissed Tevez and brought in players with whom Messi had won the World Youth Championship and Olympic Games. Now playing in a free role in an improving team, Messi ended his goal drought by scoring during their first World Cup qualifying match against Chile on 7 October, his first official goal for Argentina in two-and-a-half years.[321][348]
",3
2492,"Under Sabella, Messi's goalscoring rate drastically increased; where he had scored only 17 goals in 61 matches under his previous managers, he scored 25 times in 32 appearances during the following three years.[321][348] He netted a total of 12 goals in 9 games for Argentina in 2012, equalling the record held by Gabriel Batistuta for the most goals scored in a calendar year for their country.[350] His first hat-trick with the Albicelestes came in a friendly against Switzerland on 29 February 2012, followed by two more hat-tricks over the next year-and-a-half in friendlies against Brazil and Guatemala. Messi then helped the team secure their place in the 2014 World Cup with a 5–2 victory over Paraguay on 10 September 2013; in addition to providing an assist, he scored twice from a penalty kick, taking his international tally to 37 goals to become Argentina's second-highest goalscorer behind Batistuta. Overall, he had scored a total of 10 goals in 14 matches during the qualifying campaign.[321][351] Concurrently with his bettered performances, his relationship with his compatriots improved, as he gradually began to be perceived more favourably in Argentina.[348]
",3
2493,"Ahead of the World Cup in Brazil, doubts persisted over Messi's form, as he finished an unsuccessful and injury-plagued season with Barcelona. At the start of the tournament, however, he gave strong performances, being elected man of the match in their first four matches.[352] In his first World Cup match as captain, he led them to a 2–1 victory over Bosnia and Herzegovina; he helped create Sead Kolašinac's own goal and scored their second strike after a dribble past three players, his first World Cup goal since his debut in the tournament eight years earlier.[353] During the second match against Iran, he scored an injury-time goal from 25 yards out to end the game in a 1–0 win, securing their qualification for the knockout phase.[354] He scored twice in the last group match, a 3–2 victory over Nigeria, his second goal from a free kick, as they finished first in their group.[355] Messi assisted a late goal in extra time to ensure a 1–0 win against Switzerland in the round of 16, before starting the play that led to their match-winning 1–0 goal in the quarter-final against Belgium, helping Argentina progress to the semi-final of the World Cup for the first time since 1990.[356][357] Following a 0–0 draw in extra time, they eliminated the Netherlands 4–2 in a penalty shootout to reach the final, with Messi scoring his team's first penalty.[358]
",3
2494,"Billed as Messi versus Germany, the world's best player against the best team, the final was a repeat of the 1990 final featuring Diego Maradona.[359] Within the first half-hour, Messi had started the play that led to a goal, but it was ruled offside. He missed several opportunities to open the scoring throughout the match, in particular at the start of the second half when his breakaway effort went wide of the far post. Substitute Mario Götze finally scored in the 113th minute, followed in the last minute of extra time by a free kick that Messi sent over the net, as Germany won the match 1–0 to claim the World Cup.[360] At the conclusion of the final, Messi was awarded the Golden Ball as the best player of the tournament. In addition to being the joint third-highest goalscorer, with four goals and an assist, he created the most chances, completed the most dribbling runs, made the most deliveries into the penalty area and produced the most throughballs in the competition.[352][361] However, his selection drew criticism due to his lack of goals in the knockout round; FIFA President Sepp Blatter expressed his surprise, while Maradona suggested that Messi had undeservedly been chosen for marketing purposes.[362]
",3
2495,"Another final appearance, the third of Messi's senior international career, followed in the 2015 Copa América, held in Chile. Under the stewardship of former Barcelona manager Gerardo Martino, Argentina entered the tournament as title contenders due to their second-place achievement at the World Cup.[363][364] During the opening match against Paraguay, they were ahead two goals by half-time but lost their lead to end the match in a 2–2 draw; Messi had scored from a penalty kick, netting his only goal in the tournament.[365] Following a 1–0 win against defending champions Uruguay, Messi earned his 100th cap for his country in the final group match, a 1–0 win over Jamaica, becoming only the fifth Argentine to achieve this milestone.[366] In his 100 appearances, he had scored a total of 46 goals for Argentina, 22 of which came in official competitive matches.[321][366]
",3
2496,"As Messi evolved from the team's symbolic captain into a genuine leader, he led Argentina to the knockout stage as group winners.[367] In the quarter-final, they created numerous chances, including a rebound header by Messi, but were repeatedly denied by Colombia's goalkeeper, and ultimately ended the match scoreless, leading to a 5–4 penalty shootout in their favour, with Messi netting his team's first spot kick.[368] At the semi-final stage, Messi excelled as playmaker as he provided three assists and helped create three more goals in his side's 6–1 victory over Paraguay, receiving applause from the initially hostile crowd.[367] Argentina started the final as the odds-on title favourites, but were defeated by Chile 4–1 in a penalty shootout after an 0–0 extra-time draw. Faced with aggression from opposing players, including taking a boot to the midriff, Messi played below his standards, though he was the only Argentine to successfully convert his penalty.[369] At the close of the tournament, he was reportedly selected to receive the Most Valuable Player award but rejected the honour.[370] As Argentina continued a trophy drought that began in 1993, the World Cup and Copa América defeats again brought intense criticism for Messi from Argentine media and fans.[371]
",3
2497,"Messi's place in Argentina's Copa América Centenario squad was initially put in jeopardy when he sustained a back injury in a 1–0 friendly win over Honduras in a pre-Copa América warm-up match on 27 May 2016.[372] It was later reported that he had suffered a deep bruise in his lumbar region. He was later left on the bench in Argentina's 2–1 opening win over defending champions Chile on 6 June due to concerns regarding his fitness.[373] Although Messi was declared match-fit for his nation's second group match against Panama on 10 June, Martino left him on the bench once again; he replaced Augusto Fernández in the 61st minute and subsequently scored a hat-trick in 19 minutes, also starting the play which led to Sergio Agüero's goal, as the match ended in a 5–0 victory, sealing Argentina's place in the quarter-finals of the competition;[374] he was elected man of the match for his performance.[375]
",3
2498,"– Gabriel Batistuta on the consolation of Messi breaking his record.[376]
",3
2499,"On 18 June 2016, in the quarter-final of the Copa América against Venezuela, Messi produced another man of the match performance,[377] assisting two goals and scoring another in a 4–1 victory, which enabled him to equal Gabriel Batistuta's national record of 54 goals in official international matches.[378] This record was broken three days later when Messi scored a free kick in a 4–0 semi-final win against hosts the United States; he also assisted two goals during the match as Argentina sealed a place in the final of the competition for a second consecutive year,[379] and was named man of the match once again.[380]
",3
2500,"During a repeat of the previous year's final on 26 June, Argentina once again lost to Chile on penalties after a 0–0 deadlock, resulting in Messi's third consecutive defeat in a major tournament final with Argentina, and his fourth overall. After the match, Messi, who had missed his penalty in the shootout, announced his retirement from international football.[381] He stated, ""I tried my hardest. The team has ended for me, a decision made.""[382] Chile coach Juan Antonio Pizzi said after the match, ""My generation can't compare him to Maradona that's for my generation, because of what Maradona did for Argentine football. But I think the best player ever played today here in the United States.""[383] Messi finished the tournament as the second highest scorer, behind Eduardo Vargas, with five goals, and was the highest assist provider with four assists, also winning more Man of the Match awards than any other player in the tournament (3);[384] he was named to the team of the tournament for his performances, but missed out on the Golden Ball Award for best player, which went to Alexis Sánchez.[385]
",3
2501,"Following his announcement, a campaign began in Argentina for Messi to change his mind about retiring.[386] He was greeted by fans with signs like ""Don't go, Leo"" when the team landed in Buenos Aires. President of Argentina Mauricio Macri urged Messi not to quit, stating, ""We are lucky, it is one of life's pleasures, it is a gift from God to have the best player in the world in a footballing country like ours... Lionel Messi is the greatest thing we have in Argentina and we must take care of him.""[387] Mayor of Buenos Aires Horacio Rodríguez Larreta unveiled a statue of Messi in the capital to convince him to reconsider retirement.[388] On social networks, NoTeVayasLeo became a global trending topic, and even a playlist on Spotify.[389] The campaign also continued in the streets and avenues of the Argentine capital, with about 50,000 supporters going to the Obelisco de Buenos Aires on 2 July, using the same slogan.[390]
",3
2502,"– Messi reversing his decision from retiring on 12 August 2016[391]
",3
2503,"Just a week after Messi announced his international retirement, Argentine newspaper La Nación reported that he was reconsidering playing for Argentina at the 2018 FIFA World Cup qualifiers in September.[392] On 12 August, it was confirmed that Messi had reversed his decision to retire from international football, and he was included in the squad for the national team's upcoming 2018 World Cup qualifiers.[393] On 1 September 2016, in his first game back, he scored in a 1–0 home win over Uruguay in a 2018 World Cup qualifier.[394]
",3
2504,"On 28 March 2017, Messi was suspended for four international games for insulting an assistant referee in a game against Chile on 23 March 2017. He was also fined CHF 10,000.[395][396] On 5 May 2017, Messi's four match ban as well as his 10,000 CHF fine was lifted by FIFA after Argentina Football Association appealed against his suspension, which meant he could now play Argentina's remaining World Cup Qualifiers.[397] Argentina's place in the 2018 World Cup was in jeopardy going into their final qualifying match as they were sixth in their group, outside the five possible CONMEBOL World Cup qualifying spots, meaning they risked failing to qualify for the World Cup for the first time since 1970. On 10 October 2017, Messi led his country to World Cup qualification in scoring a hat-trick as Argentina came from behind to defeat Ecuador 3–1 away; Argentina had not defeated Ecuador in Quito since 2001.[398] Messi's three goals saw him become the joint all-time leading scorer in CONMEBOL World Cup qualifiers with 21 goals, alongside Uruguay's Luis Suárez, overtaking the previous record which was held by compatriot Hernán Crespo.[398]
",3
2505,"– Former Argentine player Osvaldo Ardiles on the decline in quality of Argentina being masked by Messi.[399]
",3
2506,"Following on from their poor qualification campaign, salvaged by Messi, expectations were not high going into the 2018 World Cup, with the team, without an injured Messi, losing 6–1 to Spain in March 2018.[400][401] Prior to Argentina's opener, there was speculation in the media over whether this would be Messi's final World Cup.[402] In the team's opening group match against Iceland on 16 June, Messi missed a potential match-winning penalty in an eventual 1–1 draw.[403] In Argentina's second game of the 2018 World Cup on 21 June, the team lost 3–0 to Croatia. Post match the Argentina coach Jorge Sampaoli spoke of the lack of quality in the team surrounding Messi, ""the reality of the Argentina squad clouds his [Messi's] brilliance"".[404] Messi had just 49 touches of the ball and only two inside the Croatia penalty area.[405] Sampaoli stated, ""we quite simply couldn't pass to him to help him generate the situations he is used to. We worked to give him the ball but the opponent also worked hard to prevent him from getting the ball. We lost that battle.""[404] Croatia midfielder Luka Modrić also stated post match, ""Messi is an incredible player but he can't do everything alone.""[405]
",3
2507,"In Argentina's final group match against Nigeria at the Krestovsky Stadium, Saint Petersburg on 26 June, Messi scored the opening goal in an eventual 2–1 victory, becoming the third Argentine after Diego Maradona and Gabriel Batistuta to score in three different World Cups; he also became the first player to score in the World Cup in his teens, twenties, and his thirties.[406] A goal of the tournament contender, Messi received a long pass from midfield and controlled the ball on the run with two touches before striking it across goal into the net with his weaker right foot.[407][408] Argentina progressed to the second round as group runners-up behind Croatia.[409] In the round of 16 match against eventual champions France on 30 June, Messi set up Gabriel Mercado's and Sergio Agüero's goals in a 4–3 defeat, which saw Argentina eliminated from the World Cup.[410] With his two assists in his team's second round fixture, Messi became the first player to provide an assist in the last four World Cups, and also became the first player to provide two assists in a match for Argentina since Diego Maradona had managed the same feat against South Korea in 1986.[411][412]
",3
2508,"Following the tournament, Messi stated that he would not participate in Argentina's friendlies against Guatemala and Colombia in September 2018, and commented that it would be unlikely that he would represent his nation for the remainder of the calendar year. Messi's absence from the national team and his continued failure to win a title with Argentina prompted speculation in the media that Messi might retire from international football once again.[413] In March 2019, however, he was called up to the Argentina squad once again for the team's friendlies against Venezuela and Morocco later that month.[414] He made his international return on 22 March, in a 3–1 friendly defeat to Venezuela, in Madrid.[415]
",3
2509,"On 21 May 2019, Messi was included in Lionel Scaloni's final 23-man Argentina squad for the 2019 Copa América.[416] In Argentina's second group match of the tournament on 19 June, Messi scored the equalising goal from the penalty spot in a 1–1 draw against Paraguay.[417] After coming under criticism in the media over his performance following Argentina's 2–0 victory over Venezuela in the quarter-finals at the Maracanã Stadium on 28 June, Messi commented that it had not been his best Copa América, while also criticising the poor quality of the pitches.[418] Following Argentina's 2–0 defeat to hosts Brazil in the semi-finals on 2 July, Messi was critical of the refereeing during the match.[419] In the third-place match against Chile on 6 July, Messi set-up Agüero's opening goal from a free kick in an eventual 2–1 win, to help Argentina capture the bronze medal; however, he was sent off along with Gary Medel in the 37th minute of play, after being involved in an altercation with the Chilean.[420] Following the match, Messi refused to collect his medal, and implied in a post-match interview that his comments following the semi-final led to his sending off.[421] Messi later issued an apology for his comments, but was fined $1,500 and was handed a one-match ban by CONMEBOL, which ruled him out of Argentina's next World Cup qualifier.[422] On 2 August, Messi was banned for three months from international football and was fined $50,000 by CONMEBOL for his comments against the referee's decisions; this ban meant he would miss Argentina's friendly matches against Chile, Mexico and Germany in September and October.[423]
",3
2510,"On 10 September 2020, Argentina FA announced that Messi's one match suspension was lifted and he would be available to play the qualifiers next month.[424] On 18 September, Messi was called up to the Argentina squad for the World Cup qualifiers against Ecuador and Bolivia in October.[425]
",3
2511,"Due to his short stature, Messi has a lower centre of gravity than taller players, which gives him greater agility, allowing him to change direction more quickly and evade opposing tackles;[426][427] this has led the Spanish media to dub him La Pulga Atómica (""The Atomic Flea"").[428][429][430] Despite being physically unimposing, he possesses significant upper-body strength, which, combined with his low centre of gravity and resulting balance, aids him in withstanding physical challenges from opponents; he has consequently been noted for his lack of diving in a sport rife with playacting.[18][427][431] His short, strong legs allow him to excel in short bursts of acceleration while his quick feet enable him to retain control of the ball when dribbling at speed.[432] His former Barcelona manager Pep Guardiola once stated, ""Messi is the only player that runs faster with the ball than he does without it.""[47] Although he has improved his ability with his weaker foot since his mid-20s, Messi is predominantly a left-footed player; with the outside of his left foot, he usually begins dribbling runs, while he uses the inside of his foot to finish and provide passes and assists.[433][434]
",3
2512,"A prolific goalscorer, Messi is known for his finishing, positioning, quick reactions, and ability to make attacking runs to beat the defensive line. He also functions in a playmaking  role, courtesy of his vision and range of passing. He has often been described as a conjurer, creating goals and opportunities where seemingly none exist.[435][436][437] Moreover, he is an accurate free kick and penalty kick taker.[427][438] With his conversion rate from his bending free kicks increasing over time Messi has developed into one of the best free kick exponents in the world.[439]
",3
2513,"Messi's pace and technical ability enable him to undertake individual dribbling runs towards goal, in particular during counterattacks, usually starting from the halfway line or the right side of the pitch.[426][431][438][440] Widely considered to be the best dribbler in the world,[441] and one of the greatest of all time,[442] with regard to this ability, his former Argentina manager Diego Maradona has said of him, ""The ball stays glued to his foot; I've seen great players in my career, but I've never seen anyone with Messi's ball control.""[434] Beyond his individual qualities, he is also a well-rounded, hard-working team player, known for his creative combinations, in particular with former Barcelona midfielders Xavi and Andrés Iniesta.[426][427]
",3
2514,"Tactically, Messi plays in a free attacking role; a versatile player, he is capable of attacking on either wing or through the centre of the pitch. His favoured position in childhood was the playmaker behind two strikers, known as the enganche in Argentine football, but he began his career in Spain as a left-winger or left-sided forward.[342] Upon his first-team debut, he was moved onto the right wing by manager Frank Rijkaard; from this position, he could more easily cut through the defence into the middle of the pitch and curl shots on goal with his left foot, rather than predominantly cross balls for teammates.[47] Under Guardiola and subsequent managers, he most often played in a false nine role; positioned as a centre-forward or lone striker, he would roam the centre, often moving deep into midfield and drawing defenders with him, in order to create and exploit spaces for passes, other teammates' attacking runs off the ball, Messi's own dribbling runs, or combinations with Xavi and Iniesta.[25] Under the stewardship of Luis Enrique, Messi initially returned to playing in the right-sided position that characterised much of his early career in the manager's 4–3–3 formation,[175][443] while he was increasingly deployed in a deeper, free playmaking role in later seasons.[444][445] Under manager Ernesto Valverde, Messi played in a variety of roles. While he occasionally continued to be deployed in a deeper role, from which he could make runs from behind into the box,[446] or even on the right wing[447] or as a false nine,[448][449] he was also used in a more offensive, central role in a 4–2–3–1,[445] or as a second striker in a 4–4–2 formation, where he was once again given the licence to drop deep, link-up with midfielders, orchestrate his teams attacking plays, and create chances for his attacking partner Suárez.[450][451]
",3
2515,"As his career advanced, and his tendency to dribble diminished slightly with age, Messi began to dictate play in deeper areas of the pitch, and developed into one of the best passers and playmakers in football history.[452][453][454] His work-rate off the ball and defensive responsibilities also decreased as his career progressed; by covering less ground on the pitch, and instead conserving his energy for short bursts of speed, he was able to improve his efficiency, movement, and positional play, and was also able to avoid muscular injuries, despite often playing a large number of matches throughout a particular season on a consistent basis. Indeed, while he was injury-prone in his early career, he was later able to improve his injury record by running less off the ball, and by adopting a stricter diet, training regime, and sleep schedule.[455] With the Argentina national team, Messi has similarly played anywhere along the frontline; under various managers, he has been employed on the right wing, as a false nine, as an out-and-out striker, in a supporting role alongside another forward, or in a deeper, free creative role as a classic number 10 playmaker or attacking midfielder behind the strikers.[347][456]
",3
2516,"– Diego Maradona hailing the 18-year-old Messi as his successor in February 2006[69]
",3
2517,"A prodigious talent as a teenager, Messi established himself among the world's best players before age 20.[62] Diego Maradona considered the 18-year-old Messi the best player in the world alongside Ronaldinho, while the Brazilian himself, shortly after winning the Ballon d'Or, commented, ""I'm not even the best at Barça"", in reference to his protégé.[457][458] Four years later, after Messi had won his first Ballon d'Or by a record margin,[76] the public debate regarding his qualities as a player moved beyond his status in contemporary football to the possibility that he was one of the greatest players in history.[14][431][459] An early proponent was his then-manager Pep Guardiola, who, as early as August 2009, declared Messi to be the best player he had ever seen.[460] In the following years, this opinion gained greater acceptance among pundits, managers, former and current players,[117][461] and by the end of Barça's second treble-winning season, Messi's superiority, ahead of Maradona and Pelé, had become the apparent view among many fans and pundits in continental Europe.[462][463] A frequent dismissal, however, has centred on the fact that Messi has not won the FIFA World Cup or any other major trophy with Argentina, leading the majority in the sport to instead cite him as arguably the best club player in history.[464]
.mw-parser-output .tmulti .thumbinner{display:flex;flex-direction:column}.mw-parser-output .tmulti .trow{display:flex;flex-direction:row;clear:left;flex-wrap:wrap;width:100%;box-sizing:border-box}.mw-parser-output .tmulti .tsingle{margin:1px;float:left}.mw-parser-output .tmulti .theader{clear:both;font-weight:bold;text-align:center;align-self:center;background-color:transparent;width:100%}.mw-parser-output .tmulti .thumbcaption{background-color:transparent}.mw-parser-output .tmulti .text-align-left{text-align:left}.mw-parser-output .tmulti .text-align-right{text-align:right}.mw-parser-output .tmulti .text-align-center{text-align:center}@media all and (max-width:720px){.mw-parser-output .tmulti .thumbinner{width:100%!important;box-sizing:border-box;max-width:none!important;align-items:center}.mw-parser-output .tmulti .trow{justify-content:center}.mw-parser-output .tmulti .tsingle{float:none!important;max-width:100%!important;box-sizing:border-box;text-align:center}.mw-parser-output .tmulti .tsingle .thumbcaption{text-align:left}.mw-parser-output .tmulti .trow>.thumbcaption{text-align:center}}",3
2518,"Throughout his career, Messi has been compared with his late compatriot Diego Maradona, due to their similar playing styles as diminutive, left-footed dribblers. Initially, he was merely one of many young Argentine players, including his boyhood idol Pablo Aimar, to receive the ""New Maradona"" moniker, but as his career progressed, Messi proved his similarity beyond all previous contenders, establishing himself as the greatest player Argentina had produced since Maradona.[22][340] Jorge Valdano, who won the 1986 World Cup alongside Maradona, said in October 2013, ""Messi is Maradona every day. For the last five years, Messi has been the Maradona of the World Cup in Mexico.""[465] César Menotti, who as manager orchestrated their 1978 World Cup victory, echoed this sentiment when he opined that Messi plays ""at the level of the best Maradona"".[466] Other notable Argentines in the sport, such as Osvaldo Ardiles, Javier Zanetti, and Diego Simeone, have expressed their belief that Messi has overtaken Maradona as the best player in history.[467][468][469]
",3
2519,"In Argentine society, Messi is generally held in lesser esteem than Maradona, a consequence of not only his perceived uneven performances with the national team, but also of differences in class, personality, and background. Messi is in some ways the antithesis of his predecessor: where Maradona was an extroverted, controversial character who rose to greatness from the slums, Messi is reserved and unassuming, an unremarkable man outside of football.[313][470][471] An enduring mark against him is the fact that, through no fault of his own, he never proved himself in the Argentine Primera División as an upcoming player, achieving stardom overseas from a young age,[18][313] while his lack of outward passion for the Albiceleste shirt (he does not sing the national anthem and is disinclined to emotional displays) have in the past led to the false perception that he felt Catalan rather than truly Argentine.[346] Despite having lived in Spain since age 13, Messi has said: ""Argentina is my country, my family, my way of expressing myself. I would change all my records to make the people in my country happy.""[472] Moreover, several pundits and footballing figures, including Maradona, have also questioned Messi's leadership with Argentina at times, despite his playing ability.[473][474][475]
",3
2520,"Among his contemporary peers, Messi is most often compared and contrasted with Portuguese forward Cristiano Ronaldo, as part of an ongoing rivalry that has been compared to past sports rivalries like the Muhammad Ali–Joe Frazier rivalry in boxing, the Björn Borg–John McEnroe rivalry in tennis, and the Ayrton Senna–Alain Prost rivalry from Formula One motor racing.[476][477]
",3
2521,"Although Messi has at times denied any rivalry,[478][479] they are widely believed to push one another in their aim to be the best player in the world:[163] since 2008, Messi has won six Ballons d'Or to Ronaldo's five,[480] six FIFA World's Best Player awards to Ronaldo's five, and six European Golden Shoes to Ronaldo's four.[481] Pundits and fans regularly argue the individual merits of both players;[163][482] beyond their playing styles, the debate also revolves around their differing physiques – Ronaldo is 1.87 m (6 ft 1 1⁄2 in) with a muscular build – and contrasting public personalities, with Ronaldo's self-confidence and theatrics a foil to Messi's humility.[483][484][485] From 2009–10 to 2017–18, Messi faced Ronaldo at least twice every season in El Clásico, which ranks among the world's most viewed annual sports events.[486] Off the pitch, Ronaldo is his direct competitor in terms of salary, sponsorships, and social media fanbase.[486]
",3
2522,"According to France Football, Messi was the world's highest-paid footballer for five years out of six between 2009 and 2014; he was the first player to exceed the €40 million benchmark, with earnings of €41 million in 2013, and the €50–€60 million points, with income of €65 million in 2014.[168][487] Messi was second on Forbes list of the world's highest-paid athletes (after Cristiano Ronaldo) with income of $81.4 million from his salary and endorsements in 2015–16.[488] In 2018 he was the first player to exceed the €100m benchmark for a calendar year, with earnings of €126m ($154m) in combined income from salaries, bonuses and endorsements.[489] Forbes ranked him the world's highest-paid athlete in 2019.[490] Since 2008, he has been Barcelona's highest-paid player, receiving a salary that increased incrementally from €7.8 million to €13 million over the next five years.[82][83][149] Signing a new Barcelona contract in 2017, he earns $667,000 per week in wages, and Barcelona also paid him $59.6 million as a signing on bonus.[491] His buyout clause is set at $835 million (€700 million).[491] In 2020, Messi became the second footballer (and second athlete in a team sport), after Cristiano Ronaldo, to surpass $1 billion in earnings during their careers.[11]
",3
2523,"In addition to his salary and bonuses, much of his income derives from endorsements; SportsPro has consequently cited him as one of the world's most marketable athletes every year since their research began in 2010.[492] His main sponsor since 2006 is the sportswear company Adidas. As Barcelona's leading youth prospect, he had been signed with Nike since age 14, but transferred to Adidas after they successfully challenged their rival's claim to his image rights in court.[493] Over time, Messi established himself as their leading brand endorser;[486] from 2008, he had a long-running signature collection of Adidas F50 boots, and in 2015, he became the first footballer to receive his own sub-brand of Adidas boots, the Adidas Messi.[494][495] Since 2017, Messi has worn the latest version of the Adidas Nemeziz.[496] In 2015, a Barcelona jersey with Messi's name and number (Messi, 10) was the best-selling replica jersey worldwide.[497]
",3
2524,"As a commercial entity, Messi's marketing brand has been based exclusively on his talents and achievements as a player, in contrast to arguably more glamorous players like Cristiano Ronaldo and David Beckham. At the start of his career, he thus mainly held sponsorship contracts with companies that employ sports-oriented marketing, such as Adidas, Pepsi, and Konami.[499][500] From 2010 onwards, concurrently with his increased achievements as a player, his marketing appeal widened, leading to long-term endorsement deals with luxury brands Dolce & Gabbana and Audemars Piguet.[499][501] Messi is also a global brand ambassador for Gillette, Turkish Airlines, Ooredoo, and Tata Motors, among other companies.[502][503][504][505] Additionally, Messi was the face of Konami's video game series Pro Evolution Soccer, appearing on the covers of PES 2009, PES 2010, PES 2011 and PES 2020. He subsequently signed with rival company EA Sports to become the face of their series FIFA and has since appeared on four consecutive covers from FIFA 13 to FIFA 16.[506][507]
",3
2525,"Messi's global popularity and influence are well documented. He was among the Time 100, an annual list of the world's most influential people as published by Time, in 2011 and 2012.[508][509] His fanbase on the social media website Facebook is among the largest of all public figures: within seven hours of its launch in April 2011, Messi's Facebook page had nearly seven million followers, and by August 2020 he had over 101 million followers, the second highest for a sportsperson after Cristiano Ronaldo.[510][511] He has over 175 million Instagram followers, the second highest for a sportsperson after Cristiano Ronaldo.[512] According to a 2014 survey by sports research firm Repucom in 15 international markets, Messi was familiar to 87% of respondents around the world, of whom 78% perceived him favourably, making him the second-most recognised player globally, behind Ronaldo, and the most likable of all contemporary players.[513][514]
",3
2526,"Other events have illustrated Messi's presence in popular culture. A solid gold replica of his left foot, weighing 25 kg (55 lb) and valued at $5.25 million, went on sale in Japan in March 2013 to raise funds for victims of the 2011 Tōhoku earthquake and tsunami.[515] A 2013 Turkish Airlines advertisement starring Messi, in which he engages in a selfie competition with then-Los Angeles Lakers star Kobe Bryant, was the most-watched ad on YouTube in the year of its release, receiving 137 million views, and was subsequently voted the best advertisement of the 2005–15 decade to commemorate YouTube's founding.[516][517] World Press Photo selected ""The Final Game"", a photograph of Messi facing the World Cup trophy after Argentina's final defeat to Germany, as the best sports image of 2014.[518] Messi, a documentary about his life by filmmaker Álex de la Iglesia, premiered at the Venice Film Festival in August 2014.[519] Born in a zoo at Saransk, Mordovia, Russia in late 2015, Messi, a pet cougar who became popular on social media, was named after the player.[520]
",3
2527,"Since 2008, Messi has been in a relationship with Antonella Roccuzzo, a fellow native of Rosario.[521] He has known Roccuzzo since he was five years old, as she is the cousin of his best friend since childhood, Lucas Scaglia, who is also a football player.[522] After keeping their relationship private for a year, Messi first confirmed their romance in an interview in January 2009, before going public a month later during a carnival in Sitges after the Barcelona–Espanyol derby.
",3
2528,"– Endocrinologist Dr. Diego Schwarzstein addressed Messi's growth hormone deficiency from 1997 to 2001. According to Bleacher Report's Richard Fitzpatrick, ""Schwarzstein and Messi built up a close relationship during more than four years of treatment.""[523]
",3
2529,"Messi and Roccuzzo have three sons: Thiago (born 2012), Mateo (born 2015) and Ciro (born 2018). To celebrate his partner's first pregnancy, Messi placed the ball under his shirt after scoring in Argentina's 4–0 win against Ecuador on 2 June 2012, before confirming the pregnancy in an interview two weeks later.[524] Thiago was born in Barcelona on 2 November 2012, with Messi attending the birth after being given permission by Barcelona to miss training. He announced his son's arrival on his Facebook page, writing, ""Today I am the happiest man in the world, my son was born and thanks to God for this gift!""[525] Thiago's name and handprints are tattooed on his left calf.[152] In April 2015, Messi confirmed on Facebook that they were expecting another child.[526] He missed training ahead of a match against Atlético Madrid to attend the birth of his second son, Mateo, on 11 September 2015 in Barcelona.[527] On 30 June 2017, he married Roccuzzo at a luxury hotel named Hotel City Center in Rosario with about 260 guests attending his wedding.[528] On 15 October 2017, his wife announced they were expecting their third child in an Instagram post, with the words ""Family of 5"".[529][530] On 10 March 2018, Messi skipped the match against Málaga after Ciro was born.[531]
",3
2530,"Messi enjoys a close relationship with his immediate family members, particularly his mother, Celia, whose face he has tattooed on his left shoulder. His professional affairs are largely run as a family business: his father, Jorge, has been his agent since he was 14, and his oldest brother, Rodrigo, handles his daily schedule and publicity. His mother and other brother, Matías, manage his charitable organisation, the Leo Messi Foundation, and take care of personal and professional matters in Rosario.[532]
",3
2531,"Since leaving for Spain at age 13, Messi has maintained close ties to his hometown of Rosario, even preserving his distinct Rosarino accent. He has kept ownership of his family's old house, although it has long stood empty; he maintains a penthouse apartment in an exclusive residential building for his mother, as well as a family compound just outside the city. Once when he was in training with the national team in Buenos Aires, he made a three-hour trip by car to Rosario immediately after practice to have dinner with his family, spent the night with them, and returned to Buenos Aires the next day in time for practice. Messi keeps in daily contact via phone and text with a small group of confidants in Rosario, most of whom were fellow members of ""The Machine of '87"" at Newell's Old Boys. He currently lives in Castelldefels, a village near Barcelona. Although considered a one-club man, he has long planned to return to Rosario to end his playing career at Newell's. He was on bad terms with the club after his transfer to Barcelona, but by 2012 their public feud had ended, with Newell's embracing their ties with Messi, even issuing a club membership card to his newborn son.[18][533][534]
",3
2532,"According to a genealogical research conducted by Diari Segre in 2011, Messi is a fourth cousin of former teammate Bojan Krkić.[535] The finding had a very significant coverage in Spanish media: it was reported by all four major sports newspapers[536][537][538][539] and by some of the largest general-interest newspapers, including ABC and La Vanguardia.[540][541][542]
",3
2533,"Throughout his career, Messi has been involved in charitable efforts aimed at vulnerable children, a commitment that stems in part from the medical difficulties he faced in his own childhood. Since 2004, he has contributed his time and finances to the United Nations Children's Fund (UNICEF), an organisation with which Barcelona also have a strong association.[543][544] Messi has served as a UNICEF goodwill ambassador since his appointment in March 2010, completing his first field mission for the organisation four months later as he travelled to Haiti to bring public awareness to the plight of the country's children in the wake of the recent earthquake. He has since participated in UNICEF campaigns targeting HIV prevention, education, and the social inclusion of disabled children.[545] To celebrate his son's first birthday, in November 2013, Messi and Thiago were part of a publicity campaign to raise awareness of mortality rates among disadvantaged children.[546]
",3
2534,"In addition to his work with UNICEF, Messi founded his own charitable organisation, the Leo Messi Foundation, which supports access to health care, education, and sport for children.[547] It was established in 2007 following a visit Messi paid to a hospital for terminally ill children in Boston, an experience that resonated with him to the point that he decided to reinvest part of his earnings into society.[533] Through his foundation, Messi has awarded research grants, financed medical training, and invested in the development of medical centres and projects in Argentina, Spain, and elsewhere in the world.[533][548] In addition to his own fundraising activities, such as his global ""Messi and Friends"" football matches, his foundation receives financial support from various companies to which he has assigned his name in endorsement agreements, with Adidas as their main sponsor.[549][550]
",3
2535,"Messi has also invested in youth football in Argentina: he financially supports Sarmiento, a football club based in the Rosario neighbourhood where he was born, committing in 2013 to the refurbishment of their facilities and the installation of all-weather pitches, and funds the management of several youth players at Newell's Old Boys and rival club Rosario Central, as well as at River Plate and Boca Juniors in Buenos Aires.[533] At Newell's Old Boys, his boyhood club, he funded the 2012 construction of a new gymnasium and a dormitory inside the club's stadium for their youth academy. His former youth coach at Newell's, Ernesto Vecchio, is employed by the Leo Messi Foundation as a talent scout for young players.[18] On 7 June 2016, Messi won a libel case against La Razón newspaper and was awarded €65,000 in damages, which he donated to the charity Médecins Sans Frontières.[551] Messi made a donation worth €1 million ($1.1 million) to fight the spread of coronavirus.[552] This was split between Clinic Barcelona hospital in Barcelona, Spain and his native Argentina.[553] In addition to this, Messi along with his fellow FC Barcelona teammates announced he will be taking a 70% cut in salaries during the coronavirus emergency, and contribute further to the club to provide fully to salaries of all the clubs employees.[554]
",3
2536,"In November 2016, with the Argentine Football Association being run by a FIFA committee for emergency due to an economic crisis, it was reported that three of the national team's security staff told Messi that they had not received their salaries for six months. He stepped in and paid the salaries of the three members.[555][556] In February 2021, Messi donated his Adidas shoes to the Museu Nacional d'Art de Catalunya which he wore when he scored his 644th goal for Barcelona and broke Pelé's record for most goals scored for a single club, with the shoes being later auctioned off in April by the museum for charity to help children with cancer.[557]
",3
2537,"Messi's financial affairs came under investigation in 2013 for suspected tax evasion. Offshore companies in tax havens Uruguay and Belize were used to evade €4.1 million in taxes related to sponsorship earnings between 2007 and 2009. An unrelated shell company in Panama set up in 2012 was subsequently identified as belonging to the Messis in the Panama Papers data leak. Messi, who pleaded ignorance of the alleged scheme, voluntarily paid arrears of €5.1 million in August 2013. On 6 July 2016, Messi and his father were both found guilty of tax fraud and were handed suspended 21-month prison sentences and respectively ordered to pay €1.7 million and €1.4 million in fines.[558] Facing the judge, he said, ""I just played football. I signed the contracts because I trusted my dad and the lawyers and we had decided that they would take charge of those things.""[559]
",3
2538,"Barcelona[569]
",3
2539,"Argentina U20
",3
2540,"Argentina Olympic team
",3
2541,"Bibliography
",3
2542,"
",3
2543,"
",3
2544,"
",3
2545,"Portuguese professional footballer
",3
2546,"Eponyms
",3
2547,"Films
",3
2548,"Cristiano Ronaldo dos Santos Aveiro GOIH ComM (Portuguese pronunciation: [kɾiʃˈtjɐnu ʁɔˈnaɫdu]; born 5 February 1985) is a Portuguese professional footballer who plays as a forward for Serie A club Juventus and captains the Portugal national team. Often considered the best player in the world and  widely regarded as one of the greatest players of all time, Ronaldo has won five Ballon d'Or awards[note 3] and four European Golden Shoes, both of which are records for a European player, and was named to the Ballon d'Or Dream Team in 2020. He has won 31 major trophies in his career, including seven league titles, five UEFA Champions Leagues, one UEFA European Championship, and one UEFA Nations League title. Ronaldo holds the records for the most goals (134) and assists (42) in the history of the UEFA Champions League.[10] He is one of the few recorded players to have made over 1,000 professional career appearances and has scored over 780 senior career goals for club and country.[11] He is also the second male to score 100 international goals and the first European one to achieve the feat.[12]
",3
2549,"Born and raised in Madeira, Ronaldo began his senior club career playing for Sporting CP, before signing with Manchester United in 2003, aged 18. After winning the FA Cup in his first season, he helped United win three successive Premier League titles, the UEFA Champions League, and the FIFA Club World Cup; at age 23, he won his first Ballon d'Or. In 2009, Ronaldo was the subject of the then-most expensive association football transfer when signed for Real Madrid in a transfer worth €94 million (£80 million). There, he won 15 trophies, including two La Liga titles, two Copas del Rey, and four UEFA Champions League titles, and became the club's all-time top goalscorer. After joining Madrid, Ronaldo finished runner-up for the Ballon d'Or three times, behind Lionel Messi – his perceived career rival – before winning back-to-back Ballons d'Or from 2013–2014 and again from 2016–2017. After winning a third consecutive Champions League title in 2018, Ronaldo became the first player to win the trophy five times.[13] In 2018, he signed for Juventus in a transfer worth an initial €100 million (£88 million), the highest fee ever paid by an Italian club and the highest ever paid for a player over 30 years old. He won the Serie A title in his first two seasons with the club.
",3
2550,"Ronaldo made his senior international debut for Portugal in 2003 at age 18, and has since earned 170 caps, including appearing and scoring in ten major tournaments, becoming Portugal's most capped player and his country's all-time top goalscorer. He scored his first international goal at Euro 2004 where he helped Portugal reach the final and assumed full captaincy of the national team in July 2008. In 2015 Ronaldo was named the best Portuguese player of all time by the Portuguese Football Federation. The following year he led Portugal to their first triumph in a major tournament by winning Euro 2016, and received the Silver Boot as the second-highest goalscorer of the tournament.
",3
2551,"One of the most marketable and famous athletes in the world, Ronaldo was ranked the world's highest-paid athlete by Forbes in 2016 and 2017 and the world's most famous athlete by ESPN from 2016 to 2019. Time included him on their list of the 100 most influential people in the world in 2014.[14] Ronaldo is the first footballer, as well as only the third sportsman, to earn $1 billion in their career.[15]
",3
2552,"Cristiano Ronaldo dos Santos Aveiro was born in São Pedro, Funchal, on the Portuguese island of Madeira, and grew up in Santo António, Funchal.[16][17] He is the fourth and youngest child of Maria Dolores dos Santos Viveiros da Aveiro, a cook, and José Dinis Aveiro, a municipal gardener and part-time kit man.[18] His great-grandmother on his father's side, Isabel da Piedade, was from the island of São Vicente, Cape Verde.[19] He has one older brother, Hugo, and two older sisters, Elma and Liliana Cátia ""Katia"".[20] His mother revealed that she wanted to abort him due to poverty, his father's alcoholism and having too many children already, but her doctor refused to perform the procedure.[21] Ronaldo grew up in a Catholic and impoverished home, sharing a room with all his siblings.[22]
",3
2553,"As a child, Ronaldo played for Andorinha from 1992 to 1995,[23] where his father was the kit man,[18] and later spent two years with Nacional. In 1997, aged 12, he went on a three-day trial with Sporting CP, who signed him for a fee of £1,500.[24] He subsequently moved from Madeira to Alcochete, near Lisbon, to join Sporting youth football academy.[24] By age 14, Ronaldo believed he had the ability to play semi-professionally, and agreed with his mother to cease his education in order to focus entirely on football.[25] While popular with other students at school, he had been expelled after throwing a chair at his teacher, who he said had ""disrespected"" him.[25] However, one year later, he was diagnosed with a racing heart, a condition that could have forced him to give up playing football.[26] Ronaldo underwent heart surgery where a laser was used to cauterise multiple cardiac pathways into one, altering his resting heart rate.[27] He was discharged from the hospital hours after the procedure and resumed training a few days later.[28][29]
",3
2554,"At age 16, Ronaldo was promoted from Sporting's youth team by first-team manager László Bölöni, who was impressed with his dribbling.[30] He subsequently became the first player to play for the club's under-16, under-17 and under-18 teams, the B team, and the first team, all within a single season.[24] A year later, on 7 October 2002, Ronaldo made his debut in the Primeira Liga, against Moreirense, and scored two goals in their 3–0 win.[31] Over the course of the 2002–03 season, his representatives suggested the player to Liverpool manager Gérard Houllier and Barcelona president Joan Laporta.[32] Manager Arsène Wenger, who was interested in signing the winger, met with him at Arsenal's grounds in November to discuss a possible transfer.[33]
",3
2555,"Manchester United manager Alex Ferguson, however, was determined to acquire Ronaldo on a permanent move urgently, after Sporting defeated United 3–1 at the inauguration of the Estádio José Alvalade in August 2003. Initially, United had just planned to sign Ronaldo and then loan him back to Sporting for a year.[34] Having been impressed by him, however, the Manchester United players urged Ferguson to sign him. After the game, Ferguson agreed to pay Sporting £12.24 million[34] for what he considered to be ""one of the most exciting young players"" he had ever seen.[35] A decade after his departure from the club, in April 2013, Sporting honoured Ronaldo by selecting him to become their 100,000th member.[36]
",3
2556,"—Former Manchester United player George Best hails the 18-year-old Cristiano Ronaldo in 2003.[37]
",3
2557,"Ronaldo became Manchester United's first Portuguese player when he signed before the 2003–04 season.[38] His transfer fee of £12.24 million made him, at the time, the most expensive teenager in English football history.[39] Although he requested the number 28, his number at Sporting, he received the number 7 shirt, which had previously been worn by such United players as George Best, Eric Cantona and David Beckham.[40] Wearing the number 7 became an extra source of motivation for Ronaldo.[41] A key element in his development during his time in England proved to be his manager, Alex Ferguson, of whom he later said, ""He's been my father in sport, one of the most important and influential factors in my career.""[42]
",3
2558,"Ronaldo made his debut in the Premier League in a 4–0 home victory over Bolton Wanderers on 16 August 2003, receiving a standing ovation when he came on as a substitute.[43] His performance earned praise from George Best, who hailed it as ""undoubtedly the most exciting debut"" he had ever seen.[37] Ronaldo scored his first goal for Manchester United with a free-kick in a 3–0 win over Portsmouth on 1 November.[44] Three other league goals followed in the second half of the campaign,[45] the last of which came against Aston Villa on the final day of the season, a match in which he also received his first red card.[46] Ronaldo ended his first season in English football by scoring the opening goal in United's 3–0 victory over Millwall in the FA Cup final, earning his first trophy.[47] BBC pundit Alan Hansen described him as the star of the final.[48] The British press had been critical of Ronaldo during the season for his ""elaborate"" step-overs in trying to beat a man,[49] but teammate Gary Neville said he was ""not a show pony, but the real thing"", and predicted he would become a world class player.[50]
",3
2559,"—Former BBC pundit Alan Hansen critiquing Ronaldo after his first season.[48]
",3
2560,"At the start of 2005, Ronaldo played two of his best matches of the 2004–05 season, producing a goal and an assist against Aston Villa and scoring twice against rivals Arsenal.[51][52] He played the full 120 minutes of the decisive match against Arsenal in the FA Cup final, which ended in a goalless draw, and scored his attempt in the lost penalty shoot-out.[53] He scored Manchester United's 1000th Premier League goal on 29 October, their only strike in a 4–1 loss to Middlesbrough.[54] Midway through the season, in November, he signed a new contract which extended his previous deal by two years to 2010.[55] Ronaldo won his second trophy in English football, the Football League Cup, after scoring the third goal in United's 4–0 final victory over Wigan Athletic.[56]
",3
2561,"During his third season in England, Ronaldo was involved in several incidents. He had a one-match ban imposed on him by UEFA for a ""one-fingered gesture"" towards Benfica fans,[57] and was sent off in the Manchester derby (a 3–1 defeat) for kicking Manchester City's former United player Andy Cole.[58] Ronaldo clashed with a teammate, striker Ruud van Nistelrooy, who took offence at the winger's showboating style of play.[59] Following the 2006 FIFA World Cup, in which he was involved in an incident where club teammate Wayne Rooney was sent off,[60] Ronaldo publicly asked for a transfer, lamenting the lack of support he felt he had received from the club over the incident.[61] United, however, denied the possibility of him leaving the club.[62]
",3
2562,"Although his World Cup altercation with Rooney resulted in Ronaldo being booed throughout the 2006–07 season,[63] it proved to be his breakout year, as he broke the 20-goal barrier for the first time and won his first Premier League title. An important factor in this success was his one-to-one training by first-team coach René Meulensteen, who taught him to make himself more unpredictable, improve his teamwork, call for the ball, and capitalise on goalscoring opportunities rather than waiting for the chance to score the aesthetically pleasing goals for which he was already known.[64] He scored three consecutive braces at the end of December, against Aston Villa (a victory that put United on top of the league), Wigan Athletic and Reading.[65][66][67] Ronaldo was named the Premier League Player of the Month in November and December, becoming only the third player to receive consecutive honours.[68][69]
",3
2563,"At the quarter-final stage of the 2006–07 UEFA Champions League, Ronaldo scored his first goals in his 30th match in the competition,[70] finding the net twice in a 7–1 victory over Roma.[71] He subsequently scored four minutes into the first semi-final leg against Milan, which ended in a 3–2 win,[72] but was marked out of the second leg as United lost 3–0 at the San Siro.[73] He also helped United reach the FA Cup final, but the decisive match against Chelsea ended in a 1–0 defeat.[74] Ronaldo scored the only goal in the Manchester derby on 5 May 2007 (his 50th goal for the club), as Manchester United claimed their first Premier League title in four years.[75] As a result of his performances, he amassed a host of personal awards for the season. He won the Professional Footballers' Association's Player's Player, Fans' Player, and Young Player of the Year awards, as well as the Football Writers' Association's Footballer of the Year award,[76][77] becoming the first player to win all four main PFA and FWA honours.[78] His club wages were concurrently upgraded to £120,000 a week (£31 million total) as part of a five-year contract extension with United.[79] At the end of 2007, Ronaldo was named runner-up to Kaká for the Ballon d'Or,[80] and came third, behind Kaká and Lionel Messi, in the running for the FIFA World Player of the Year award.[81]
",3
2564,"Ronaldo scored his first and only hat-trick for Manchester United in a 6–0 win against Newcastle United on 12 January 2008, bringing United up to the top of the Premier League table.[82] A month later, on 19 March, he captained United for the first time in a home win over Bolton, and scored both goals of the match.[83] His second goal was his 33rd of the campaign, which bettered George Best's total of 32 goals in the 1967–68 season, thus setting the club's new single-season record by a midfielder.[84] His 31 league goals earned him the Premier League Golden Boot,[85] as well as the European Golden Shoe, which made him the first winger to win the latter award.[86] He additionally received the PFA Players' Player of the Year and FWA Footballer of the Year awards for the second consecutive season.[87][88]
",3
2565,"In the knockout stage of the Champions League, Ronaldo scored the decisive goal against Lyon, which helped United advance to the quarter-finals 2–1 on aggregate,[89] and, while playing as a striker, scored with a header in the 3–0 aggregate victory over Roma.[90] United advanced to the final against Chelsea in Moscow, where, despite his opening goal being negated by an equaliser and his penalty being saved in the shoot-out,[91] Manchester United emerged victorious.[92] As the Champions League top scorer, Ronaldo was named the UEFA Club Footballer of the Year.[93]
",3
2566,"Ronaldo scored a total of 42 goals in all competitions during the 2007–08 season, his most prolific campaign during his time in England. He missed three matches after headbutting a Portsmouth player at the start of the season, an experience he said taught him not to let opponents provoke him.[94] As rumours circulated of Ronaldo's interest in moving to Real Madrid, United filed a tampering complaint with governing body FIFA over Madrid's alleged pursuit of their player, but they declined to take action.[95] FIFA president Sepp Blatter asserted that the player should be allowed to leave his club, describing the situation as ""modern slavery"".[96] Despite Ronaldo publicly agreeing with Blatter,[97] he remained at United for another year.[98]
",3
2567,"Ahead of the 2008–09 season, on 7 July, Ronaldo underwent ankle surgery,[99] which kept him out of action for 10 weeks.[100] Following his return, he scored his 100th goal in all competitions for United with the first of two free kicks in a 5–0 win against Stoke City on 15 November,[101] which meant he had now scored against all 19 opposition teams in the Premier League at the time.[102] At the close of 2008, Ronaldo helped United win the FIFA Club World Cup in Japan,[103] assisting the final-winning goal against Liga de Quito and winning the Silver Ball in the process.[104] He subsequently became United's first Ballon d'Or winner since George Best in 1968,[105] and the first Premier League player to be named the FIFA World Player of the Year.[106]
",3
2568,"His match-winning goal in the second leg against Porto, a 40-yard strike, earned him the inaugural FIFA Puskás Award, presented by FIFA in recognition of the best goal of the year;[107] he later called it the best goal he had ever scored.[108] United advanced to the final in Rome,[109] where he made little impact in United's 2–0 defeat to Barcelona.[110] Ronaldo ended his time in England with nine trophies, as United claimed their third successive Premier League title and a Football League Cup.[111][112] He finished the campaign with 26 goals in all competitions, 16 goals fewer than the previous season, in four more appearances.[113] His final goal for Manchester United came on 10 May 2009 with a free kick in the Manchester derby at Old Trafford.[114]
",3
2569,"Ahead of the 2009–10 season, Ronaldo joined Real Madrid for a world record transfer fee at the time, of £80 million (€94 million).[115] His contract, which ran until 2015, was worth €11 million per year and contained a €1 billion buy-out clause.[116] At least 80,000 fans attended his presentation at the Santiago Bernabéu, surpassing the 25-year record of 75,000 fans who had welcomed Diego Maradona at Napoli.[117] Since club captain Raúl already wore the number 7 (the number Ronaldo wore at Manchester United), Ronaldo received the number 9 shirt,[118] which was presented to him by former Madrid player Alfredo Di Stéfano.[119]
",3
2570,"Ronaldo made his debut in La Liga on 29 August 2009, against Deportivo La Coruña, and scored from the penalty spot in Madrid's 3–2 home win.[120] He scored in each of his first four league fixtures with the club, the first Madrid player to do so.[121] His first Champions League goals for the club followed with two free kicks in the first group match against Zürich.[122] His strong start to the season, however, was interrupted when he suffered an ankle injury in October while on international duty, which kept him sidelined for seven weeks.[123][124] A week after his return, he received his first red card in Spain in a match against Almería.[125] Midway through the season, Ronaldo placed second in the running for the Ballon d'Or and the FIFA World Player of the Year award, behind Lionel Messi of Barcelona, Madrid's historic rivals. He finished the campaign with 33 goals in all competitions, including a hat-trick in a 4–1 win against Mallorca on 5 May 2010, his first in the Spanish competition.[126][127] His first season at Real Madrid ended trophyless.[128]
",3
2571,"Following Raúl's departure, Ronaldo was handed the number 7 shirt for Real Madrid before the 2010–11 season.[129] His subsequent return to his Ballon d'Or-winning form was epitomised when, for the first time in his career, he scored four goals in a single match during a 6–1 rout against Racing Santander on 23 October.[130] His haul concluded a goalscoring run of six consecutive matches (three in La Liga, one in the Champions League, and two for Portugal) totalling 11 goals, the most he had scored in a single month. Ronaldo subsequently scored further hat-tricks against Athletic Bilbao, Levante, Villarreal, and Málaga.[131][132][133] Despite his performance, he did not make the podium for the inaugural FIFA Ballon d'Or at the end of 2010.[134]
",3
2572,"During a historical series of four Clásicos against rivals Barcelona in April 2011, Ronaldo scored twice to equal his personal record of 42 goals in all competitions in a single season. Although he failed to find the net during Madrid's eventual elimination in the Champions League semi-finals, he equalised from the penalty spot in the return league game and scored the match-winning goal in the 103rd minute of the Copa del Rey final, winning his first trophy in Spain.[135][136] His two goals in the last match of the season, against Almería, made him the first player in La Liga to score 40 goals.[137] In addition to the Pichichi Trophy, Ronaldo consequently won the European Golden Shoe for a second time, becoming the first player to win the award in two different leagues.[138]
",3
2573,"During the following campaign, the 2011–12 season, Ronaldo surpassed his previous goalscoring feats to achieve a new personal best of 60 goals across all competitions.[139]  He regained a place on the FIFA Ballon d'Or podium, as runner-up to Messi, after scoring hat-tricks against Real Zaragoza, Rayo Vallecano, Málaga, Osasuna, and Sevilla, the last of which put Madrid on top of the league by the season's midway point.[140][141][142]
",3
2574,"Ronaldo found greater team success in the league, as he helped Real Madrid win their first La Liga title in four years, with a record 100 points. Following a hat-trick against Levante, further increasing Madrid's lead over Barcelona,[143] he scored his 100th league goal for Madrid in a 5–1 win over Real Sociedad on 24 March 2012, a milestone he reached in just 92 matches across three seasons, breaking the previous club record held by Ferenc Puskás.[144] Another hat-trick in the Madrid derby against Atlético Madrid brought his total to 40 league goals, equalling his record of the previous season.[145] His final league goal of the campaign, against Mallorca, took his total to 46 goals, four short of the new record set by Messi,[146] and earned him the distinction of being the first player to score against all 19 opposition teams in a single season in La Liga.[147]
",3
2575,"Ronaldo began the 2012–13 season by lifting the Supercopa de España, his third trophy in Spain. With a goal in each leg by the Portuguese, Madrid won the Spanish Super Cup on away goals following a 4–4 aggregate draw against Barcelona.[148] Although Ronaldo publicly commented that he was unhappy with a ""professional issue"" within the club, prompted by his refusal to celebrate his 150th goal for Madrid,[149] his goalscoring rate did not suffer. After netting a hat-trick, including two penalties, against Deportivo La Coruña, he scored his first hat-trick in the Champions League in a 4–1 victory over Ajax.[150] Four days later, he became the first player to score in six successive Clásicos when he hit a brace in a 2–2 draw at Camp Nou.[151] His performances in 2012 again saw Ronaldo voted second in the running for the FIFA Ballon d'Or, finishing runner-up to four-time winner Messi.[152]
",3
2576,"Following the 2012–13 winter break, Ronaldo captained Real Madrid for the first time in an official match, scoring a brace to lift 10-man Madrid to a 4–3 victory over Real Sociedad on 6 January.[153] He subsequently became the first non-Spanish player in 60 years to captain Madrid in El Clásico on 30 January, a match which also marked his 500th club appearance.[154] Three days prior, he had scored his 300th club goal as part of a perfect hat-trick against Getafe.[155] He scored his 200th goal for Real Madrid on 8 May in a 6–2 win against Málaga, reaching the landmark in 197 games.[156] He helped Madrid reach the Copa del Rey final by scoring twice in El Clásico, which marked the sixth successive match at Camp Nou in which he had scored,[157] a Real Madrid record.[148] In the final, he headed the opening goal of an eventual 2–1 defeat to Atlético Madrid, but was shown a red card for violent conduct.[158] In the first knockout round of the Champions League, Ronaldo faced his former club Manchester United for the first time. After scoring the equaliser in a 1–1 draw at the Santiago Bernabéu,[159] he scored the match-winning goal in a 2–1 victory at Old Trafford, his first return to his former home ground.[160] He did not celebrate scoring against his former club as a mark of respect.[161] After scoring three goals against Galatasaray in the quarters, he scored Madrid's only goal in the 4–1 away defeat to Borussia Dortmund in the semi-finals, but failed to increase his side's 2–0 victory in the second leg, as they were eliminated at the semi-final stage for the third consecutive year.[162]
",3
2577,"At the start of the 2013–14 season, Ronaldo signed a new contract that extended his stay by three years to 2018, with a salary of €17 million net, making him briefly the highest-paid player in football.[163] He was joined at the club by winger Gareth Bale, whose world record transfer fee of €100 million surpassed the fee Madrid had paid for Ronaldo four years prior.[164] Together with striker Karim Benzema, they formed an attacking trio popularly dubbed ""BBC"", an acronym of Bale, Benzema, and Cristiano, and a play off the name of the public service broadcaster.[165] By late November, Ronaldo had scored 32 goals from 22 matches for both club and country, including hat-tricks against Galatasaray, Sevilla, Real Sociedad, Northern Ireland, and Sweden.[166][167][168] He ended 2013 with 69 goals in 59 appearances, his highest year-end goal tally.[169] He received the FIFA Ballon d'Or, an amalgamation of the Ballon d'Or and the FIFA World Player of the Year award, for the first time in his career.[170]
",3
2578,"Concurrently with his individual achievements, Ronaldo enjoyed his greatest team success in Spain to date, as he helped Real Madrid win La Décima, their tenth European Cup. His goal in a 3–0 home win over Borussia Dortmund (his 100th Champions League match) took his total for the season to 14 goals, equalling the record Messi had set two years before.[171] After hitting a brace in a 4–0 defeat of Bayern Munich at the Allianz Arena,[172] he scored from the penalty spot in the 120th minute of the 4–1 final victory over Atlético Madrid, becoming the first player to score in two European Cup finals for two different winning teams.[173] His overall performance in the final was subdued as a result of patellar tendinitis and related hamstring problems, which had plagued him in the last months of the campaign. Ronaldo played the final against medical advice, later commenting: ""In your life you do not win without sacrifices and you must take risks.""[174] As the Champions League top goalscorer for the third time, with a record 17 goals,[175] he was named the UEFA Best Player in Europe.[176]
",3
2579,"In the Copa del Rey, Ronaldo helped Madrid reach the final by scoring two penalties against Atlético Madrid at the Vicente Calderón,[177] the first of which meant he had now scored in every single minute of a 90-minute football match.[178] His continued issues with his knee and thigh caused him to miss the final, where Real Madrid defeated Barcelona 2–1 to claim the trophy.[179] Ronaldo scored 31 goals in 30 league games, which earned him the Pichichi and the European Golden Shoe, receiving the latter award jointly with Liverpool striker Luis Suárez.[180] Among his haul was his 400th career goal, in 653 appearances for club and country, which came with a brace against Celta Vigo on 6 January; he dedicated his goals to compatriot Eusébio, who had died two days before.[181] A last-minute, back-heeled volley scored against Valencia on 4 May (his 50th goal in all competitions) was recognised as the best goal of the season by the Liga de Fútbol Profesional,[182] which additionally named Ronaldo the Best Player in La Liga.[183]
",3
2580,"During the next campaign, the 2014–15 season, Ronaldo set a new personal best of 61 goals in all competitions, starting with both goals in Real Madrid's 2–0 victory over Sevilla in the UEFA Super Cup.[184] He subsequently achieved his best-ever goalscoring start to a league campaign, with a record 15 goals in the first eight rounds of La Liga.[185] His record 23rd hat-trick in La Liga, scored against Celta Vigo on 6 December, made him the fastest player to reach 200 goals in the Spanish league, as he reached the milestone in only his 178th game.[185][186] After lifting the FIFA Club World Cup with Madrid in Morocco, and becoming the joint-top assist provider of the competition alongside Toni Kroos,[187] Ronaldo received a second successive FIFA Ballon d'Or,[188] joining Johan Cruyff, Michel Platini, and Marco van Basten as a three-time Ballon d'Or winner.[189]
",3
2581,"Madrid finished in second-place in La Liga in the 2014–15 season and exited at the semi-final stage in the Champions League.[190] In the latter competition, Ronaldo extended his run of scoring away to a record 12 matches with his strike in a 2–0 win against Schalke 04.[191] He scored both of his side's goals in the semi-finals against Juventus, where Madrid were eliminated 2–3 on aggregate.[192] With 10 goals, he finished the campaign as top scorer for a third consecutive season, alongside Messi and Neymar.[193] In La Liga, for the first time in his career he scored five goals in one game, including an eight-minute hat-trick, in a 9–1 rout of Granada on 5 April.[194] His 300th goal for his club followed three days later in a 2–0 win against Rayo Vallecano.[195] Subsequent hat-tricks against Sevilla, Espanyol, and Getafe took his number of hat-tricks for Real Madrid to 31, surpassing Di Stéfano's club record of 28.[184] He finished the season with 48 goals, winning a second consecutive Pichichi and the European Golden Shoe for a record fourth time.[184]
",3
2582,"At the start of his seventh season at Real Madrid, the 2015–16 campaign, Ronaldo became the club's all-time top scorer, first in the league and then in all competitions. His five-goal haul in a 6–0 away win over Espanyol on 12 September took his tally in La Liga to 230 goals in 203 games, surpassing the club's previous recordholder, Raúl.[196] A month later, on 17 October, he again surpassed Raúl when he scored the second goal in a 3–0 defeat of Levante at the Bernabéu to take his overall total for the club to 324 goals.[note 4] Ronaldo also became the all-time top scorer in the Champions League with a hat-trick in the first group match against Shakhtar Donetsk, having finished the previous season level with Messi on 77 goals.[198] Two goals against Malmö FF in a 2–0 away win on 30 September saw him reach the milestone of 500 career goals for both club and country.[199] He subsequently became the first player to score double figures in the competition's group stage, setting the record at 11 goals, including another four-goal haul against Malmö.[200]
",3
2583,"Ronaldo's four goals in a 7–1 home win over Celta de Vigo on 5 March 2016 took his total to 252 goals in La Liga, becoming the competition's second-highest scorer in history behind Messi.[201] He scored a hat-trick against VfL Wolfsburg to send his club into the Champions League semi-finals.[202] The treble took his tally in the competition to 16 goals, making him the top scorer for the fourth consecutive season, and the fifth overall.[203] Suffering apparent fitness issues, Ronaldo gave a poorly-received performance in the final against Atlético Madrid, in a repeat of the 2014 final, though his penalty in the subsequent shoot-out secured La Undécima, Madrid's 11th victory.[204] For the sixth successive year, he ended the season having scored more than 50 goals across all competitions.[204] For his efforts during the season, he received the UEFA Best Player in Europe Award for a second time.[205]
",3
2584,"Ronaldo missed Real Madrid's first three matches of the 2016–17 season, including the 2016 UEFA Super Cup against Sevilla, as he continued to rehabilitate the knee injury he suffered against France in the final of Euro 2016.[206] On 15 September, he did not celebrate his late free kick equaliser against Sporting CP in the Champions League, with Ronaldo stating post match, ""they made me who I am.""[207] On 7 November, his contract was updated for the second time and extended by three years to 2021.[208] On 19 November, he scored a hat-trick in a 3–0 away win against Atlético Madrid, making him the all-time top scorer in the Madrid derby with 18 goals.[209] On 15 December, Ronaldo scored his 500th club career goal in the 2–0 victory over Club América in the semi-finals of the FIFA Club World Cup.[210] He then scored a hat-trick in the 4–2 win over Japanese club Kashima Antlers in the final.[211] Ronaldo finished the tournament as top scorer with four goals and was also named player of the tournament.[212] He won the Ballon d'Or for a fourth time and the inaugural Best FIFA Men's Player, a revival of the former FIFA World Player of the Year, largely owing to his success with Portugal in winning Euro 2016.[213]
",3
2585,"In the 2016–17 UEFA Champions League quarter-final against Bayern Munich in April, Ronaldo scored both goals in a 2–1 away win which saw him make history in becoming the first player to reach 100 goals in UEFA club competition.[214] In the second leg of the quarter-finals, Ronaldo scored a 'perfect' hat-trick and reached his 100th UEFA Champions League goal, becoming the first player to do so as Real Madrid again defeated Bayern 4–2 after extra-time.[215] On 2 May, Ronaldo scored another hat-trick as Real Madrid defeated Atlético Madrid 3–0 in the Champions League semi-final first leg. On 17 May, Ronaldo overtook Jimmy Greaves as the all-time top scorer in the top five European leagues, scoring twice against Celta de Vigo.[216] He finished the season with 42 goals in all competitions as he helped Madrid to win their first La Liga title since 2012.[217] In the 2017 Champions League final, Ronaldo scored two goals in the victory against Juventus and became the top goalscorer for the fifth-straight season, and sixth overall, with 12 goals, while also becoming the first player to score in three finals in the Champions League era as well as reaching his 600th senior career goal.[218] Madrid also became the first team to win back-to-back finals in the Champions League era.[219]
",3
2586,"At the start of the 2017–18 season, Ronaldo scored Madrid's second goal in a 3–1 Supercopa de España first-leg victory over Barcelona at Camp Nou.[220] On 23 October, his performances in the first half of 2017 saw him claim his fifth FIFA Player of the Year award by receiving The Best FIFA Men's Player award for the second consecutive year.[221] On 6 December, he became the first player to score in all six Champions League group stage matches with a curling strike at home to Borussia Dortmund.[222] A day later, Ronaldo won the Ballon d'Or for a fifth time, receiving the award on the Eiffel Tower in Paris.[223] On 16 December he scored a free kick winner as Madrid won their second FIFA Club World Cup title in a row by beating Gremio in the final.[224] On 3 March 2018, he scored two goals in a 3–1 home win over Getafe, his first being his 300th La Liga goal in his 286th La Liga appearance, making him the fastest player to reach this landmark and only the second player to do so after Messi.[225] On 18 March, he reached his 50th career hat-trick, scoring four goals in a 6–3 win against Girona.[226]
",3
2587,"On 3 April, Ronaldo scored the first two goals in a 3–0 away win against Juventus in the quarter-finals of the 2017–18 UEFA Champions League, with his second goal being an acrobatic bicycle kick.[227] Described as a ""PlayStation goal"" by Juventus defender Andrea Barzagli, with Ronaldo's foot approximately 7 ft 7 in (2.31 m) off the ground, it garnered him a standing ovation from the opposing fans in the stadium, as well as a plethora of plaudits from peers, pundits and coaches.[228][229] On 11 April, he scored the goal Real Madrid needed to advance to the semi-final, in the second leg of the Champions League quarter-final at home to Juventus, from a 98th-minute injury time penalty in a 3–1 defeat, with an overall 4–3 aggregate win.[230] It was also his tenth goal against Juventus, a Champions League record against a single club.[231] In the final of the tournament, on 26 May, Real Madrid defeated Liverpool 3–1, winning Ronaldo his fifth Champions League title as he became the first player to win the trophy five times.[232] He finished as the top scorer of the tournament for the sixth consecutive season, ending the campaign with 15 goals.[233] After the final, Ronaldo referred to his time with the Champions League winners in the past tense, sparking speculation that he could leave Real Madrid.[234]
",3
2588,"Despite months of negotiation to sign a new Real Madrid contract,[235] on 10 July 2018, Ronaldo signed a four-year contract with Italian club Juventus after completing a €100 million transfer, which included an additional €12 million in other fees,[236] and solidarity contributions to Ronaldo's youth clubs. The transfer was the highest ever for a player over 30 years old,[237] and the highest paid by an Italian club.[238] Upon signing, Ronaldo cited his need for a new challenge as his rationale for departing Madrid,[239] but later attributed the transfer to the lack of support he felt was shown by club president Florentino Pérez.[240]
",3
2589,"On 16 September, Ronaldo scored his first goals for Juventus in his fourth appearance for the club in a 2–1 home win over Sassuolo in Serie A. His second was the 400th league goal of his career.[241] On 19 September, in his first Champions League match for Juventus, he was sent off in the 29th minute for ""violent conduct"", his first red card in 154 Champions League appearances.[242] Ronaldo became the first player in history to win 100 Champions League matches, setting up Mario Mandžukić's winner in a 1–0 home victory over Valencia, which sealed Juventus's passage to the knock-out stages of the competition.[243] In December, he scored his tenth Serie A goal of the season, from the penalty spot, netting the final goal in a 3–0 away win over rivals Fiorentina; with this goal, Ronaldo became the first Juventus player since John Charles in 1957 to score 10 goals in his first 14 league games for the club.[244] After placing second in both the UEFA Men's Player of the Year and The Best FIFA Men's Player for the first time in three years, behind Luka Modrić, Ronaldo performances in 2018 also saw him voted runner-up for the 2018 Ballon d'Or, finishing once again behind his former Real Madrid teammate.[245]
",3
2590,"Ronaldo won his first trophy with the club in January 2019, the 2018 Supercoppa Italiana, after he scored the game-winning and only goal from a header against A.C. Milan.[246] On 10 February, Ronaldo scored in a 3–0 away win over Sassuolo; the ninth consecutive away game in which he had scored for Juventus in the league, which enabled him to equal Giuseppe Signori's single season Serie A record of most consecutive away games with at least one goal.[247] On 12 March, Ronaldo scored a hat-trick in a 3–0 home win against Atlético Madrid in the second leg of the Champions League round of 16, helping Juventus overcome a two-goal deficit to reach the quarter-finals.[248] The following month, Ronaldo scored his 125th goal in the competition, opening the scoring in a 1–1 away draw in the first leg of Juventus' quarter-final against Ajax, on 10 April.[249] In the second leg in Turin on 16 April, he scored the opening goal of the match in the first half, but Juventus eventually lost the match 2–1, and were eliminated from the competition.[250] On 20 April, Ronaldo played in the Scudetto clinching game against rivals Fiorentina as Juventus won their eighth successive Serie A title after a 2–1 home win, thereby becoming the first player to win league titles in England, Spain and Italy.[251] On 27 April, he scored his 600th club goal, the equaliser in a 1–1 away draw against rivals Inter.[252] Finishing his first Serie A campaign with 21 goals and 8 assists, Ronaldo won the inaugural Serie A Award for Most Valuable Player.[253]
",3
2591,"Ronaldo scored his first goal of the 2019–20 season for Juventus in a 4–3 home win over Napoli in Serie A on 31 August 2019.[254] On 23 September, he came in 3rd place for the 2019 Best FIFA Men's Player Award.[255] On 1 October, he reached several milestones in Juventus's 3–0 group stage win over Bayer Leverkusen in the Champions League: his goal during the match saw him score for the 14th consecutive Champions League season, equalling Raúl and Messi's record; he also broke Iker Casillas' record for most Champions League wins of all time, and equalled Raúl's record of scoring against 33 different Champions League opponents.[256] On 6 November, in a 2–1 away win against Lokomotiv Moscow in the Champions League group stage, he equalled Paolo Maldini as the second-most capped player in UEFA club competitions with 174 appearances.[257] On 18 December, Ronaldo performed an athletic feet, in leaping to a height of 8.39 ft (2.56m) – higher than the crossbar (8 ft) – before heading the winning goal in a 2–1 away win for Juventus against Sampdoria in Serie A.[258]
",3
2592,"Ronaldo scored his first Serie A hat-trick on 6 January 2020, in a 4–0 home win against Cagliari. His 56th career hat-trick, he became only the second player after Alexis Sánchez to score hat-tricks in the Premier League, La Liga and Serie A.[259] On 2 February, he scored twice from the penalty spot in a 3–0 home win over Fiorentina, equalling David Trezeguet's club record of nine consecutive appearances in Serie A with at least one goal.[260] He broke the club record six days later, when he scored in his tenth consecutive league game, a 2–1 away defeat to Hellas Verona.[261] On 22 February, Ronaldo scored for a record-equalling 11th consecutive Serie A game (a record shared with Gabriel Batistuta and Fabio Quagliarella), in what was his 1,000th senior professional game, in a 2–1 away win for Juventus against SPAL.[262]
",3
2593,"On 22 June, he scored a penalty in a 2–0 away win over Bologna, overtaking Rui Costa to become the highest scoring Portuguese player in Serie A history.[263] On 4 July, he assisted Juan Cuadrado's goal and later scored his 25th league goal of the season from a free kick in a 4–1 home win over rivals Torino, becoming the first Juventus player to achieve this milestone since Omar Sívori in 1961; the goal was also his first from a free kick with the club, after 43 attempts.[264]
",3
2594,"On 20 July, Ronaldo scored twice in a 2–1 home win over Lazio; his first goal was his 50th in Serie A. He became the second fastest player to reach this landmark, after Gunnar Nordahl, and the first player in history to reach 50 goals in the Premier League, La Liga, and Serie A. With his brace, he also reached 30 league goals for the season, becoming just the third player in Juventus's history to reach that milestone in a single season,[265][266] after Felice Borel in 1933–34 and John Hansen in 1951–52. Moreover, he became the oldest player, at the age of 35 years and 166 days, to score more than 30 goals in one of the five top European leagues since Ronnie Rooke with Arsenal in 1948.[267] On 26 July, he scored the opening goal in a 2–0 home win over Sampdoria, which saw Juventus crowned Serie A champions for a ninth consecutive time.[268] He finished his second Serie A campaign with a total of 31 goals and 6 assists, which made him the second–highest goalscorer in the league behind only European Golden Shoe winner Ciro Immobile, with 36 goals, who also equaled Gonzalo Higuaín's record for most goals in a single Serie A season.[269][270] On 7 August, Ronaldo scored a brace in a 2–1 home win against Lyon in the second leg of the Champions League round of 16, which saw him finish the season with 37 goals in all competitions; the tally allowed him to break Felice Borel's club record of 36 goals in a single season, which he had set in 1933–34.[271] However, despite the victory, Juventus tied with Lyon 2–2 on aggregate, and were eliminated from the competition on the away goals rule.[272]
",3
2595,"On 20 September 2020, Ronaldo scored in Juventus's opening match of the season, a 3–0 home win over Sampdoria in Serie A.[273] On 1 November, after Ronaldo took nearly three weeks to recover from COVID-19, he returned to action against Spezia where he came off the bench in the second half and scored within the first three minutes. He later scored a second goal from the penalty spot in an eventual 4–1 away win.[274] On 2 December, he scored a goal against Dynamo Kyiv in a Champions League group stage match to reach his 750th senior career goal.[275] Ronaldo played his 100th match in all competitions for Juventus on 13 December, scoring two penalties in a 3–1 away win to Genoa in the league, and bringing his goal tally to 79.[276] On 2 March 2021, he scored a goal in a 3–0 win over Spezia in his 600th league match, to become the first player to score at least 20 goals in each of the past 12 consecutive seasons in the top five leagues of Europe.[277] On 9 March, Juventus were knocked out from the Champions League round of 16 by Porto on away goals rule (4–4 on aggregate).[278] On 14 March, he scored his 57th career hat-trick in a 3–1 away win over Cagliari.[279]
",3
2596,"Ronaldo began his international career with Portugal under-15 in 2001. During his international youth career, Ronaldo would represent the under-15, under-17, under-20, under-21, and under-23 national sides, amassing 34 youth caps and scoring 18 goals overall.[8]
",3
2597,"At age 18, Ronaldo made his first senior appearance for Portugal in a 1–0 victory over Kazakhstan on 20 August 2003.[280] He was subsequently called up for UEFA Euro 2004, held in his home country, and scored his first international goal in a 2–1 group stage loss to eventual champions Greece.[281] After converting his penalty in a shoot-out against England in the quarter-finals,[282] he helped Portugal reach the final by scoring the opening goal in a 2–1 win over the Netherlands.[283] He was featured in the team of the tournament, having provided two assists in addition to his two goals.[284]
",3
2598,"Ronaldo was Portugal's second-highest scorer in their qualification group for the 2006 FIFA World Cup with seven goals.[285] During the tournament, he scored his first World Cup goal against Iran with a penalty kick in Portugal's second match of the group stage.[286] In Portugal's round of 16 match against the Netherlands, an infamously dirty game, Ronaldo was forced off injured in the first half, following a tackle from Dutch defender Khalid Boulahrouz. Following Portugal's 1–0 victory in the match, Ronaldo accused Boulahrouz of intentionally trying to injure him, although he was able to recover in time to participate in the next round.[287] In Portugal's quarter-final against England, Ronaldo's Manchester United teammate Wayne Rooney was sent off for stamping on Portugal defender Ricardo Carvalho. Although the referee later clarified that the red card was only due to Rooney's infraction,[288] the English media speculated that Ronaldo had influenced his decision by aggressively complaining, after which he was seen in replays winking at Portugal's bench following Rooney's dismissal.[289] Ronaldo went on to score the vital winning penalty during the shoot-out which sent Portugal into the semi-finals.[290] Ronaldo was subsequently booed during their 1–0 semi-final defeat to France.[291] FIFA's Technical Study Group overlooked him for the tournament's Best Young Player award and handed it to Germany's Lukas Podolski, citing his behaviour as a factor in the decision.[292] Following the 2006 World Cup, Ronaldo would go on to represent Portugal in four qualifying games for Euro 2008, scoring two goals in the process.[293][294]
",3
2599,"One day after his 22nd birthday, Ronaldo captained Portugal for the first time in a friendly game against Brazil on 6 February 2007,[295] as requested by Portuguese Football Federation president Carlos Silva, who had died two days earlier.[296] Ahead of Euro 2008, he was given the number 7 shirt for the first time.[297] While he scored eight goals in the qualification,[298] the second-highest tally, he scored just one goal in the tournament, netting the second goal of their 3–1 win in the group stage match against the Czech Republic; in the same game, he also set-up Portugal's third goal in injury time, which was scored by Quaresma, and was named man of the match for his performance.[299][300] Portugal were eliminated in the quarter-finals with a 3–2 loss against eventual finalists Germany.[301]
",3
2600,"After Portugal's unsuccessful performance in the European Championship, Luiz Felipe Scolari was replaced as coach by Carlos Queiroz, formerly the assistant manager at United.[302] Queiroz made Ronaldo the squad's permanent captain in July 2008.[303] Ronaldo failed to score a single goal in the qualification for the 2010 World Cup, as Portugal narrowly avoided a premature elimination from the tournament with a play-off victory over Bosnia and Herzegovina.[304] In the group stage of the World Cup, he was named man of the match in all three matches against Ivory Coast, North Korea, and Brazil.[305][306][307] His only goal of the tournament came in their 7–0 rout of North Korea, which marked his first international goal in 16 months.[308] Portugal's World Cup ended with a 1–0 loss against eventual champions Spain in the round of 16.[309]
",3
2601,"Ronaldo scored seven goals in the qualification for Euro 2012, including two strikes against Bosnia and Herzegovina in the play-offs, to send Portugal into the tournament, where they were drawn in a ""group of death"".[310] In the last group stage game against the Netherlands, Ronaldo scored twice to secure a 2–1 victory.[311] He scored a header in the quarter-final against the Czech Republic to give his team a 1–0 win.[312] In both games against the Netherlands and the Czech Republic he was named man of the match.[313][314] After the semi-finals against Spain ended scoreless, with Ronaldo having sent three shots over the bar,[315] Portugal were eliminated in the penalty shoot-out. Ronaldo did not take a penalty as he had been slated to take the unused fifth slot,[316] a decision that was questioned by the media[317] and later criticized by Frank Wagner and Beau Bourne of Bleacher Report, Graham MacAree of SB Nation and by Yahoo Sports' Martin Rogers.[318][319][320][321] Ronaldo's own teammate, Nani, said that Ronaldo ""demanded"" to take the last penalty.[322] As the joint top scorer with three goals, alongside five other players, he was again included in the team of the tournament.[323]
",3
2602,"During the qualification for the 2014 World Cup, Ronaldo scored a total of eight goals. A qualifying match on 17 October 2012, a 1–1 draw against Northern Ireland, earned him his 100th cap.[324] His first international hat-trick also came against Northern Ireland, when he found the net three times in a 15-minute spell of a 4–2 qualifying victory on 6 September 2013.[325] After Portugal failed to qualify during the regular campaign, Ronaldo scored all four of the team's goals in the play-offs against Sweden – billed as a battle between Ronaldo and Zlatan Ibrahimović – which ensured their place at the tournament.[326] His hat-trick in the second leg took his international tally to 47 goals, equaling Pauleta's record.[327] Ronaldo subsequently scored twice in a 5–1 friendly win over Cameroon on 5 March 2014 to become his country's all-time top scorer.[328]
",3
2603,"Ronaldo took part in the tournament despite suffering from patellar tendinitis and a related thigh injury,[329][330] potentially risking his career.[331] Ronaldo later commented: ""If we had two or three Cristiano Ronaldos in the team I would feel more comfortable. But we don't.""[332] Despite ongoing doubts over his fitness, being forced to abort practice twice,[333] Ronaldo played the full 90 minutes of the opening match against Germany, though he was unable to prevent a 4–0 defeat.[334] After assisting an injury-time 2–2 equaliser against the United States,[335] he scored a late match-winning goal in a 2–1 victory over Ghana.[336] His 50th international goal made him the first Portuguese to play and score in three World Cups.[337] Portugal were eliminated from the tournament at the close of the group stage on goal difference.[336]
",3
2604,"Ronaldo scored five goals, including a hat-trick against Armenia, in the qualification for Euro 2016.[338] With the only goal in another victory over Armenia on 14 November 2014, he reached 23 goals in the European Championship, including qualifying matches, to become the competition's all-time leading goalscorer.[339] At the start of the tournament, however, Ronaldo failed to convert his chances in Portugal's draws against Iceland and Austria, despite taking a total of 20 shots on goal. In the latter match, he overtook Luís Figo as his nation's most capped player with his 128th international appearance, which ended scoreless after he missed a penalty in the second half.[340] With two goals and an assist in the last match of the group stage, a 3–3 draw against Hungary, Ronaldo became the first player to score in four European Championships, having made a record 17 appearances in the tournament.[341][342] Though placed third in their group behind Hungary and Iceland, his team qualified for the knockout round as a result of the competition's newly expanded format.[343]
",3
2605,"In Portugal's first knockout match, Ronaldo's only attempt on goal was parried by Croatia's goalkeeper into the path of Ricardo Quaresma, whose finish then secured a 1–0 victory late in extra time.[344] After his team progressed past Poland on penalties,[345] Ronaldo became the first player to participate in three European Championship semi-finals;[346] he scored the opening goal and assisted a second in a 2–0 win against Wales, equaling Michel Platini as the competition's all-time top scorer with nine goals.[347] In the final against hosts France, Ronaldo was forced off after just 25 minutes following a challenge from Dimitri Payet. After multiple treatments and attempts to play on, he was stretchered off the pitch and replaced by Quaresma. During extra time, substitute Eder scored in the 109th minute to earn Portugal a 1–0 victory.[348] As team captain, Ronaldo later lifted the trophy in celebration of his country's first triumph in a major tournament. He was awarded the Silver Boot as the joint second-highest goalscorer, with three goals and three assists, and was named to the team of the tournament for the third time in his career.[349][350]
",3
2606,"Following the Euro 2016 success, Ronaldo played his first professional match on his home island of Madeira on 28 March 2017 at age 32, opening a 2–3 friendly defeat to Sweden at the Estádio dos Barreiros. With the goal, he tied with Miroslav Klose on 71 goals as the third-highest scoring European in international football.[351]
",3
2607,"In Portugal's opening match of the 2017 FIFA Confederations Cup against Mexico on 17 June, Cristiano Ronaldo set-up Quaresma's opening goal in a 2–2 draw.[352] Three days later, he scored in a 1–0 win over hosts Russia.[353] On 24 June, he scored from a penalty in a 4–0 win over New Zealand, which saw Portugal top their group and advance to the semi-finals of the competition. With his 75th international goal, Ronaldo also equalled Sándor Kocsis as the second-highest European international goalscorer of all-time, behind only Ferenc Puskás.[354][355] He was named man of the match in all three of Portugal's group stage matches.[356] Ronaldo left the competition early: after Chile defeated Portugal 3–0 on penalties in the semi-finals, he was allowed to return home to be with his newborn children.[357] Therefore, he missed Portugal's third-place play-off match in which Portugal defeated Mexico 2–1 after extra time.[358]
",3
2608,"On 31 August 2017, Ronaldo scored a hat-trick in a 5–1 win in a World Cup qualifier over the Faroe Islands, which saw him overtake Pelé and equal Hussein Saeed as the joint-fifth-highest goalscorer in international football with 78 goals.[359] These goals brought his tally in the 2018 World Cup qualifiers to 14, equalling Predrag Mijatović's record for most goals in a single UEFA senior men's qualifying campaign, and also saw him break the record for the most goals scored in a single European qualifying group, overtaking the previous record of 13 goals set by David Healy and Robert Lewandowski. Ronaldo's hat-trick took his World Cup qualifying goals total to 29, making him the highest scorer in European World Cup qualifiers, ahead of Andriy Shevchenko, and the highest goalscorer in World Cup qualifying and finals matches combined, with 32 goals, ahead of Miroslav Klose.[360] Ronaldo later added to this tally by scoring a goal against Andorra in a 2–0 victory.[361]
",3
2609,"On 15 June 2018, Ronaldo became the oldest player to score a hat-trick in a World Cup match, helping Portugal secure a 3–3 draw against Spain (his third goal a 30-yard curling free kick with two minutes remaining) in their opening match. In doing so, he also became the first Portuguese player to score a goal in four World Cups and one of four players to do so in total.[362] On 20 June, Ronaldo scored the only goal in a 1–0 victory against Morocco, breaking Ferenc Puskás’ record as the highest European goalscorer of all-time, with 85 international goals.[363] In the final group match against Iran on 25 June, Ronaldo missed a penalty in an eventual 1–1 draw which saw Portugal progress to the second round as group runners-up behind Spain.[364] On 30 June, Portugal were eliminated following a 2–1 defeat to Uruguay in the last 16.[365] For his performances in the tournament, Ronaldo was later named to the 2018 FIFA World Cup Dream Team.[366]
",3
2610,"After the 2018 FIFA World Cup, Ronaldo missed six international matches, including the entire league phase of the 2018–19 UEFA Nations League. Ronaldo played for hosts Portugal in the inaugural Nations League Finals in June 2019. In the semi-finals on 5 June, he scored a hat-trick against Switzerland to secure a spot in the final. Upon netting the match's opening goal, he became the first player to score in 10 consecutive international competitions, breaking the record of nine he previously shared with Ghana's Asamoah Gyan.[367] In the final of the tournament four days later, Portugal defeated Netherlands 1–0.[368]
",3
2611,"On 10 September 2019, Ronaldo scored four goals in a 5–1 away win over Lithuania in a Euro 2020 qualifying match;[369] in the process, he overtook Robbie Keane (23 goals) as the player with most goals in the UEFA European Championship qualifiers, setting a new record with 25 goals.[370] On that occasion, Ronaldo also set a new record as the player who scored against the most national teams, 40,[371] while also completing his eighth international hat-trick.[372] On 14 October, he scored his 700th senior career goal for club and country from the penalty spot, in his 974th senior career appearance, a 2–1 away loss to Ukraine in a Euro 2020 qualifier.[373] On 17 November, Ronaldo scored his 99th international goal in a 2–0 win over Luxembourg, leading Portugal to qualify for Euro 2020.[374] On 8 September 2020, Ronaldo scored his 100th and 101st international goals in a 2–0 away win over Sweden in a 2020–21 UEFA Nations League match, becoming only the second male player ever, after Ali Daei of Iran – and the first in Europe – to achieve this milestone.[375][376] On 13 October 2020, the Portuguese Football Federation announced that Ronaldo tested positive for COVID-19 while being asymptomatic.[377][378] By 30 October, Ronaldo had recovered.[379]
",3
2612,"A versatile attacker, Ronaldo is capable of playing on either wing as well as through the centre of the pitch,[380] and, while ostensibly right-footed, is very strong with both feet.[381] He ranks among the world's fastest footballers, both with and without the ball.[382] Tactically, Ronaldo has undergone several evolutions throughout his career. While at Sporting and during his first season at Manchester United, he was typically deployed as a traditional winger on the right side of midfield, where he regularly looked to deliver crosses into the penalty area. In this position, he was able to use his pace and acceleration, agility, and technical skills to take on opponents in one-on-one situations. Ronaldo became noted for his dribbling and flair, often displaying an array of tricks and feints,[382][383] such as the step overs and so-called 'chops' that became his trademark;[384] he has also been known to use the flip–flap.[385]
",3
2613,"As Ronaldo matured, he underwent a major physical transformation, developing a muscular body type that allowed him to retain possession of the ball under pressure, and strong legs that enabled an outstanding jumping ability.[387] His strength and jumping ability, combined with his elevation, heading accuracy, and height of 1.87 m (6 ft 1 1⁄2 in), give him an edge in winning aerial duels. These attributes allow him to function as a target-man and make him an aerial goal threat in the penalty area; consequently, many of his goals have been headers.[388][389][390] Allied with his increased stamina and work-rate, his goalscoring ability improved drastically on the left wing where he was given the positional freedom to move into the centre to finish attacks. He has also increasingly played a creative role for his team, often dropping deep to pick up the ball, participate in the build-up of plays, and create chances for his teammates, courtesy of his vision and passing ability.[382][388]
",3
2614,"In his final seasons at United, Ronaldo played an even more attacking and central role, functioning both as a striker and as a supporting forward, or even as an attacking midfielder on occasion.[391] He developed into a prolific goalscorer, capable of finishing well both inside the penalty area and from distance with an accurate and powerful shot, courtesy of his striking ability.[388][391][392] An accurate penalty kick taker,[393] he also became a set piece specialist, renowned for his powerful, bending free kicks.[394] When taking free kicks, Ronaldo is known for using the knuckleball technique – which was developed by Juninho Pernambucano.[395] He also adopts a trademark stance before striking the ball, which involves him standing with his legs far apart.[396] Regarding Cristiano Ronaldo's unique style of taking free kicks, former Manchester United assistant manager Mike Phelan has commented: ""People used to put the ball down, walk away, run up and hit it. He brought in a more dynamic showmanship. He places the ball down, the concentration level is high, he takes his certain amount of steps back so that his standing foot is in the perfect place to hit the ball in the sweet spot. He is the ultimate showman. He has that slight arrogance. When he pulls those shorts up and shows his thighs, he is saying 'All eyes on me' and this is going in. He understands the marketing side of it. The way he struts up and places it; the world is watching him.""[397]
",3
2615,"At Real Madrid, Ronaldo continued to play a more offensive role, while his creative and defensive duties became more limited, although not entirely diminished.[391] Initially deployed as a centre forward by managers Manuel Pellegrini and José Mourinho, he was later moved back onto the left wing, though in a free tactical role; this position allowed him to drift into the centre at will to get onto the end of crosses and score, or draw out defenders with his movement off the ball and leave space for teammates to exploit.[399][400][401] Madrid's counter-attacking style of play also allowed him to become a more efficient and consistent player, as evidenced by his record-breaking goalscoring feats. However, while he mainly drew praise in the media for his prolific goalscoring, he also demonstrated his ability as an effective creator in this role.[402][403][404] This unique role has been described by pundits as that of a ""false,"" ""attacking,"" or ""goalscoring winger,"" as Ronaldo effectively almost functioned as a striker at times with his central runs into the penalty area, despite actually playing on the left flank.[399][405] From 2013 onwards, under manager Carlo Ancelotti, he effectively adapted his style to the physical effects of ageing with increasingly reduced off the ball movement and general involvement, completing fewer dribbles and passes per game, and instead focusing on short-distance creating and goalscoring.[400][406][407] Since 2017, Ronaldo has adapted his style of play yet again to become more of a free-roaming centre forward under manager Zinedine Zidane, a role in which he continued to excel and maintain a prolific goalscoring record; in this position, he earned praise in the media for his intelligent movement both on and off the ball, positional sense, link-up play and finishing, as well as his ability to lose or anticipate his markers, find space in the box, and score from few touches or opportunities.[408][409][410]
",3
2616,"In his first season at Juventus, Ronaldo continued to play in a variety of different attacking roles under manager Massimiliano Allegri, depending on whom he was partnered with. While he had occupied an increasingly offensive role in his final years at Real Madrid, at times he functioned in a free role at Juventus, either as a lone striker or in his trademark role on the left wing, in a 4–2–3–1 or 4–3–3 formation, in which he often switched positions with Mario Mandžukić. In this role, he was also given licence to drop deep or even out wide onto the right flank in order to receive the ball, and be more involved in the build-up of plays; as such, aside from scoring goals himself, he began to take on opponents and create chances for other players with greater frequency than he had in his final seasons with Real Madrid. Off the ball, he was also capable of creating space for teammates with his movement and attacking runs into the box, or finishing off chances with his head or feet by getting onto the end of his teammates' crosses.[411][412] On occasion he also played in an attacking partnership alongside Mandžukić in a 4–3–1–2, 4–4–2, or 3–5–2 formation.[413][414][415] He continued to play a similar role in his second season with the club under manager Maurizio Sarri.[412]
",3
2617,"– Former manager Alex Ferguson, January 2013[416]
",3
2618,"Ronaldo is widely regarded as one of the two best players of his generation, alongside Lionel Messi.[note 5] Winning his first Ballon d'Or in 2008 by a record-high vote count at age 23, over the next decade Ronaldo has often featured in debates concerning who is the greatest player in history.[417] Acclaimed for his prolific and consistent goal-scoring,[note 6] he is considered a decisive player who is also a game changer,[418] especially in important and high-pressured situations.[note 7]
",3
2619,"Ronaldo is noted for his work ethic, elite body conditioning, and dedication to improvement on the training pitch, as well being regarded as a natural leader.[419][420] Writing of his ""extraordinary commitment to physical preparation"", Adam Bate of Sky Sports adds, ""Dedication is a huge part of staying at the top and Ronaldo's focus is perhaps unparalleled within the game.""[398] His drive and determination to succeed are fuelled by a desire to be talked about alongside Pelé and Diego Maradona once retiring.[421] He has at times, however, been criticised for simulating when tackled.[note 8] In addition to this, he was occasionally criticised early in his career by manager Alex Ferguson, teammates, and the media for being a selfish or overly flamboyant player.[422][423]
",3
2620,"During his career, Ronaldo has also been described as having an ""arrogant image"" on the pitch,[424] with Ronaldo stating that he had become a ""victim"" because of how he was portrayed in the media.[425] He is often seen moaning, gesticulating and scowling while trying to inspire his team to victory,[424] with Ronaldo insisting that his competitive nature should not be mistaken for arrogance.[425] His managers, teammates and various journalists have commented that this reputation has caused an unfair image of him.[426][427][428] In 2014, Ronaldo told France Football that he had made a ""mistake"" when he said in 2011, ""People are jealous of me as I am rich, handsome and a great player"", adding that he had matured since then and fans understood him better.[429]
",3
2621,"Ronaldo has adopted several goalscoring celebrations throughout his career, including one particular celebration which gained widespread coverage in the media, when he squatted and stared directly into a camera on the sidelines of the pitch with his hand on his chin.[430][431][432] However, after scoring a goal, he usually celebrates with a ""storming jump"" and ""turn"", before ""landing in spread-eagled fashion""[431] into his ""signature power stance"",[432] while usually simultaneously exclaiming ""Sí"" (Spanish and Italian for ""yes"");[430][433] as such, this trademark celebration has been dubbed the ""Sii!"" in the media.[430][431][434]
",3
2622,"Both players have scored in at least two UEFA Champions League finals and have regularly broken the 50-goal barrier in a single season. Sports journalists and pundits regularly weigh the individual merits of both players in an attempt to argue who they believe is the best player in modern football or in the history of the game.[435] It has been compared to sports rivalries such as the Muhammad Ali–Joe Frazier rivalry in boxing, the Borg–McEnroe rivalry in tennis, and the Ayrton Senna–Alain Prost rivalry from Formula One motor racing.[436][437]
",3
2623,"Some commentators choose to analyse the differing physiques and playing styles of the two,[438] while part of the debate revolves around the contrasting personalities of the two players: Ronaldo is sometimes depicted as an arrogant and theatrical showoff, while Messi is portrayed as a shy, humble character.[439][440][441][442]
",3
2624,"– Cristiano Ronaldo commenting on his rivalry with Messi.[443]
",3
2625,"In a 2012 interview, Ronaldo commented on the rivalry, saying ""I think we push each other sometimes in the competition, this is why the competition is so high"",[444] while Ronaldo's manager during his time at Manchester United, Alex Ferguson, opined that ""I don't think the rivalry against each other bothers them. I think they have their own personal pride in terms of wanting to be the best"".[445] Messi himself denied any rivalry, saying that it was ""only the media, the press, who wants us to be at loggerheads but I've never fought with Cristiano"".[446] Responding to the claims that he and Messi do not get on well on a personal level, Ronaldo commented, ""We don't have a relationship outside the world of football, just as we don't with a lot of other players"", before adding that in years to come he hopes they can laugh about it together, stating; ""We have to look on this rivalry with a positive spirit, because it's a good thing.""[443] Representing archrivals Barcelona and Real Madrid, the two players faced each other at least twice every season in the world's biggest club game, El Clásico, which is among the world's most viewed annual sporting events.[447]
",3
2626,"In a debate at Oxford Union in October 2013, when asked whether FIFA president Sepp Blatter preferred Messi or Ronaldo, Blatter paid tribute to the work ethic of the Argentine before taking a swipe at Ronaldo, claiming ""one of them has more expenses for the hairdresser than the other"". Real Madrid demanded – and promptly received – a full apology, and the Portuguese issued his own riposte with a mock-salute celebration after scoring a penalty against Sevilla, after Blatter had described him as a ""commander"" on the pitch.[448] In August 2019, Ronaldo and Messi were interviewed while sat next to each other prior to the announcement of the UEFA Men's Player of the Year, with Ronaldo stating, ""Of course, we have a good relationship. We haven't had dinner together yet, but I hope in the future. I pushed him and he pushed me as well. So it's good to be part of the history of football.""[449]
",3
2627,"As his reputation grew from his time at Manchester United, Ronaldo has signed many sponsorship deals for consumer products, including sportswear, football boots (since November 2012 Ronaldo has worn the Nike Mercurial Vapor personalized CR7 edition),[450] soft drinks, clothing, automotive lubricants, financial services, electronics, and computer video games.[451][452][453][454] Ronaldo was featured as the cover athlete of EA Sports' FIFA video game FIFA 18 and was heavily involved in the game's promotion.[455] His 'Siiii' goal celebration features in the FIFA series, accompanied with his own voiceover.[430] He was also the face of Pro Evolution Soccer, appearing on the cover in 2008, 2012, and 2013.[456]
",3
2628,"With earnings of €720 million (£615 million) from 2010 to 2019, Ronaldo was ranked second in Forbes list of The Highest-Paid Athletes Of The Decade, with only boxer Floyd Mayweather, Jr. earning more.[457] Forbes has twice ranked Ronaldo first on its list of the world's highest-paid football players; his combined income from salaries, bonuses, and endorsements was $73 million in 2013–14 and $79 million in 2014–15.[458][459] The latter earnings saw him listed behind only Mayweather on the magazine's list of The World's Highest-Paid Athletes.[460] In 2016, he became the first footballer to top the Forbes list of highest-earning athletes, with a total income of $88 million from his salary and endorsements in 2015–16.[461] He topped the list for the second straight year with earnings of $93 million in 2016–17.[462] Ronaldo is one of the world's most marketable athletes: SportsPro rated him the fifth most marketable athlete in 2012[463] and eighth most marketable athlete in 2013, with Brazilian footballer Neymar topping both lists.[463][464] Sports market research company Repucom named Ronaldo the most marketable and most recognised football player in the world in May 2014.[465] He was additionally named in the 2014 Time 100, Time's annual list of the most influential people in the world.[466] ESPN named Ronaldo the world's most famous athlete in 2016, 2017, 2018, and 2019.[467][468][469][470]
",3
2629,"Ronaldo has established a strong online presence. The most popular sportsperson on social media, he counted over 500 million total followers across Facebook, Twitter, and Instagram by February 2021, making him the first person to pass half a billion followers.[472] The most followed person on Facebook (150 million) and Instagram (264 million), and the most followed sportsman on Twitter (91 million), his sponsors earned $936 million in media value across his social media accounts between June 2016 to June 2017.[462] Ronaldo has released two mobile apps: in December 2011, he launched an iPhone game called Heads Up with Cristiano, created by developer RockLive,[473] and in December 2013, he launched Viva Ronaldo, a dedicated social networking website and mobile app.[474] Computer security company McAfee produced a 2012 report ranking footballers by the probability of an internet search for their name leading to an unsafe website, with Ronaldo's name first on the list.[475]
",3
2630,"Ronaldo's life and person have been the subject of several works. His autobiography, titled Moments, was published in December 2007.[476] His sponsor Castrol produced the television film Ronaldo: Tested to the Limit, in which he is physically and mentally tested in several areas; his physical performance was consequently subject to scrutiny by world media upon the film's release in September 2011.[477] Cristiano Ronaldo: The World at His Feet, a documentary narrated by the actor Benedict Cumberbatch, was released via Vimeo in June 2014.[478] A documentary film about his life and career, titled Ronaldo, was released worldwide on 9 November 2015.[479] Directed by BAFTA-winner Anthony Wonke, the film is produced and distributed by Universal Pictures, while Asif Kapadia is the executive producer.[480]
",3
2631,"Demand for a replica Ronaldo jersey has been high throughout his career. In 2008, Ronaldo's number 7 Manchester United jersey was the best-selling sports product under the auspices of the Premier League.[481] In 2015, Ronaldo's number 7 Real Madrid jersey was the second best-selling jersey worldwide, after Messi's number 10 Barcelona jersey.[482] In 2018, within 24 hours of his number 7 Juventus jersey being released, over 520,000 had been sold, with $62.4 million generated in one day.[483]
",3
2632,"Ronaldo opened his first fashion boutique under the name CR7 (his initials and shirt number) on the island of Madeira, Portugal, in 2006. Ronaldo expanded his business with a second clothes boutique in Lisbon in 2008.[484] In partnership with Scandinavian manufacturer JBS Textile Group and the New York fashion designer Richard Chai, Ronaldo co-designed a range of underwear and sock line, released in November 2013.[485] He later expanded his CR7 fashion brand by launching a line of premium shirts[486] and shoes by July 2014.[487] In September 2015, Ronaldo released his own fragrance, ""Legacy"", in a partnership with Eden Parfums.[488]
",3
2633,"In 2007, C.D. Nacional renamed its youth campus Cristiano Ronaldo Campus Futebol (Cristiano Ronaldo Football Campus).[489] In December 2013, Ronaldo opened a museum, Museu CR7, in his hometown of Funchal, Madeira, to house trophies and memorabilia of his life and playing career;[490] the museum is an official sponsor of the local football team União da Madeira.[491][492] At a ceremony held at the Belém Palace in January 2014, President of Portugal Aníbal Cavaco Silva raised Ronaldo to the rank of Grand Officer of the Order of Prince Henry, ""to distinguish an athlete of world renown who has been a symbol of Portugal globally, contributing to the international projection of the country and setting an example of tenacity for future generations"".[493] A bronze statue of Ronaldo, designed by artist Ricardo Madeira Veloso, was unveiled in Funchal on 21 December 2014.[494]
",3
2634,"In June 2010, during the build-up to the World Cup, Ronaldo became the fourth footballer – after Steven Gerrard, Pelé and David Beckham – to be represented as a waxwork at Madame Tussauds London.[495] Another waxwork of him was presented at the Madrid Wax Museum in December 2013.[496] In June 2015, astronomers led by David Sobral from Lisbon and Leiden discovered a galaxy which they named Cosmos Redshift 7 (CR7) in tribute to Ronaldo.[497][498]
",3
2635,"On 23 July 2016, following Portugal's triumph at Euro 2016, Madeira Airport in Funchal was renamed as Cristiano Ronaldo International Airport.[499] The unveiling of the rebranded terminal took place on 29 March 2017, which included a bust of his head being presented.[500] The bust and the name change were controversial, with the lack of the bust's likeness to Ronaldo being ridiculed by comedians, including Saturday Night Live,[501] while the name change was subject to much debate locally by some politicians and citizens, who even started a petition against the move, an action criticised by President of Madeira Miguel Albuquerque.[502][500] A year later, sports website Bleacher Report commissioned sculptor Emanuel Santos to create another bust.[503] However, this bust was never used; instead, a new one was made by a Spanish sculptor, shown to the public on 15 June 2018.[504]
",3
2636,"In February 2020, the United Arab Emirates awarded a golden visa to Ronaldo, under the Dubai Sports Council initiative to connect global players, and to encourage them to live and invest in the UAE.[505]
",3
2637,"Ronaldo has four children. He first became a father to a son, Cristiano Jr., born on 17 June 2010 in the United States.[506] He stated that he has full custody of the child and would not be publicly revealing the identity of the mother as per agreement with her.[507][508] In January 2015, Ronaldo announced his five-year relationship with Russian model Irina Shayk had ended.[509]
",3
2638,"Ronaldo then became father to twins, daughter Eva and son Mateo, born on 8 June 2017 in the United States via surrogacy.[510] He is in a relationship with Spanish model Georgina Rodríguez, a former shop assistant,[511] who gave birth to their daughter Alana Martina, on 12 November 2017.[512]
",3
2639,"Ronaldo's father, José, died of an alcoholism-related liver condition at age 52 in September 2005 when Ronaldo was 20.[513][514] Ronaldo has said that he does not drink alcohol,[515] and he received libel damages over a Daily Telegraph article that reported him drinking heavily in a nightclub while recovering from an injury in July 2008.[516] He also does not have any tattoos as he regularly donates blood and bone marrow.[517] His mother, Dolores, was diagnosed with breast cancer in 2007, but eventually recovered.[518]
",3
2640,"Ronaldo has made contributions to various charitable causes throughout his career. Television footage of the 2004 Indian Ocean earthquake and tsunami showed an eight-year-old boy survivor named Martunis wearing a Portuguese football shirt who was stranded for 19 days after his family was killed. Following this, Ronaldo visited Aceh, Indonesia, to raise funds for rehabilitation and reconstruction.[519][520] After accepting undisclosed damages from a libel case against The Sun newspaper in 2008, Ronaldo donated the damages to a charity in Madeira.[521] In 2009, Ronaldo donated £100,000 to the hospital that saved his mother's life in Madeira following her battle with cancer, so that they could build a cancer centre on the island.[522] In support of the victims of the 2010 Madeira flood, Ronaldo pledged to play in a charity match in Madeira between Primeira Liga club Porto and players from Madeiran-based clubs Marítimo and Nacional.[523]
",3
2641,"In 2012, Ronaldo and his agent paid for specialist treatment for a nine-year-old Canarian boy with apparently terminal cancer.[524] In December 2012, Ronaldo joined FIFA's ""11 for Health"" programme to raise awareness amongst kids of how to steer clear of conditions including drug addiction, HIV, malaria and obesity.[525] In January 2013, Ronaldo became Save the Children's new Global Artist Ambassador, in which he hopes to help fight child hunger and obesity.[526] In March, Ronaldo agreed to be the ambassador for The Mangrove Care Forum in Indonesia, an organisation aiming to raise awareness of mangrove conservation.[527]
",3
2642,"Ronaldo was named the world's most charitable sportsperson in 2015 after donating £5 million to the relief effort after the earthquake in Nepal which killed over 8,000 people.[528] In June 2016, Ronaldo donated the entirety of his €600,000 Champions League bonus after Real Madrid won the 2015–16 UEFA Champions League.[528] In August 2016, Ronaldo launched CR7Selfie, a selfie app for charity to help Save the Children that lets participants take a selfie with him in one of several different outfits and poses.[529] In the app, fans can select from among 68 photos of Ronaldo in different outfits and poses, and scroll through 39 filters to apply to their selfies.[530]
",3
2643,"In July 2017, Ronaldo was charged with fraudulently evading almost €15 million in tax between 2011 and 2014, a claim he denied at the time.[531] In June 2018, Ronaldo was given a two-year suspended jail sentence and fined €18.8 million, later reduced to €16.8 million after reaching a deal with Spanish authorities. The sentence can be served under probation, without any jail time, so long as he does not re-offend.[532]
",3
2644,"Ronaldo and another man were investigated by the British Crown Prosecution Service after a 2005 rape allegation was brought forward by two women. Within days, the two women withdrew their allegation and Scotland Yard later issued a statement declaring there was not enough evidence for a prosecution.[533] In April 2017, it was reported that Ronaldo was being investigated for a rape allegation by the Las Vegas Police Department originating in 2009.[534][535] Documents, confirmed by Ronaldo's lawyers, state that Ronaldo paid a woman US$375,000 in a non-disclosure settlement.[534][536] Ronaldo and his lawyers issued a lengthy statement denying all accusations, describing them as an ""intentional defamation campaign"" with parts significantly ""altered and/or completely fabricated"",[537][538] a claim which Der Spiegel categorically denied.[539] In July 2019, Las Vegas prosecutors said they would not charge Ronaldo over allegations of rape; the statement added: ""Based upon a review of information at this time, the allegations of sexual assault against Cristiano Ronaldo cannot be proven beyond a reasonable doubt.""[540]
",3
2645,"Notes
",3
2646,"Notes
",3
2647,"Sporting CP[549]
",3
2648,"Manchester United[550][551]
",3
2649,"Real Madrid[551]
",3
2650,"Juventus[542]
",3
2651,"Portugal
",3
2652,"Individual
",3
2653,"Orders
",3
2654,"Notes
",3
2655,"Citations
",3
2656,"Biographies
",3
2657,"
",3
2658,"Argentine professional footballer
",3
2659,"Eponym
",3
2660,"Films
",3
2661,"Family
",3
2662,"Related
",3
2663,"Diego Armando Maradona (Spanish: [ˈdjeɣo maɾaˈðona]; 30 October 1960 – 25 November 2020) was an Argentine professional football player and manager. Widely regarded as one of the greatest players in the history of the sport, he was one of the two joint winners of the FIFA Player of the 20th Century award.[3][4] Maradona's vision, passing, ball control, and dribbling skills were combined with his small stature, which gave him a low centre of gravity allowing him to manoeuvre better than most other players. His presence and leadership on the field had a great effect on his team's general performance, while he would often be singled out by the opposition. In addition to his creative abilities, he possessed an eye for goal and was known to be a free kick specialist. A precocious talent, Maradona was given the nickname ""El Pibe de Oro"" (""The Golden Boy""), a name that stuck with him throughout his career.[5] He also had a troubled off-field life and was banned in both 1991 and 1994 for abusing drugs.[6]
",3
2664,"An advanced playmaker who operated in the classic number 10 position, Maradona was the first player to set the world record transfer fee twice: in 1982 when he transferred to Barcelona for £5 million, and in 1984 when he moved to Napoli for a fee of £6.9 million.[7] He played for Argentinos Juniors, Boca Juniors, Barcelona, Napoli, Sevilla, and Newell's Old Boys during his club career, and is most famous for his time at Napoli and Barcelona, where he won numerous accolades.
",3
2665,"In his international career with Argentina, he earned 91 caps and scored 34 goals. Maradona played in four FIFA World Cups, including the 1986 World Cup in Mexico, where he captained Argentina and led them to victory over West Germany in the final, and won the Golden Ball as the tournament's best player. In the 1986 World Cup quarter final, he scored both goals in a 2–1 victory over England that entered football history for two different reasons. The first goal was an unpenalized handling foul known as the ""Hand of God"", while the second goal followed a 60 m (66 yd) dribble past five England players, voted ""Goal of the Century"" by FIFA.com voters in 2002.[8]
",3
2666,"Maradona became the coach of Argentina's national football team in November 2008. He was in charge of the team at the 2010 World Cup in South Africa before leaving at the end of the tournament. He then coached Dubai-based club Al Wasl in the UAE Pro-League for the 2011–12 season. In 2017, Maradona became the coach of Fujairah before leaving at the end of the season.[9] In May 2018, Maradona was announced as the new chairman of Belarusian club Dynamo Brest.[10] He arrived in Brest and was presented by the club to start his duties in July.[11] From September 2018 to June 2019, Maradona was coach of Mexican club Dorados.[12] He was the coach of Argentine Primera División club Gimnasia de La Plata from September 2019 until his death in November 2020.[13]
",3
2667,"Diego Armando Maradona was born on 30 October 1960, at the Policlínico (Polyclinic) Evita Hospital in Lanús, Buenos Aires Province to a poor family that had moved from Corrientes Province; he was raised in Villa Fiorito, a shantytown on the southern outskirts of Buenos Aires, Argentina.[14] He was the first son after four daughters. He has two younger brothers, Hugo (el Turco) and Raúl (Lalo), both of whom were also professional football players. 
",3
2668,"Maradona's father, Don Diego Maradona ""Chitoro"" (1927–2015) did not know his father, taking his maternal surname Maradona, through which he is known to be the descendant of Francisco Fernández de Maradona, an immigrant from Ribadeo in the Galician province of Lugo in north western Spain. Maradona's ancestor embarked to the New World in 1748 where he married Francisca Ángela Arias de Molina of Andalusian heritage and born in the Argentine city of San Juan.[15] Diego Maradona's mother, Dalma Salvadora Franco, ""Doña Tota"" (1930–2011), was of  partial Croatian descent, being the daughter of Mateo Kariolić born in the city of Bakar and who was married to Argentine-born Atanasio Ramón Franco.[16][17][18][19]
",3
2669,"When Diego came to Argentinos Juniors for trials, I was really struck by his talent and couldn't believe he was only eight years old. In fact, we asked him for his ID card so we could check it, but he told us he didn't have it on him. We were sure he was having us on because, although he had the physique of a child, he played like an adult. When we discovered he'd been telling us the truth, we decided to devote ourselves purely to him.",3
2670,"Maradona's parents were both born and brought up in the town of Esquina in the north-east province of Corrientes, living only two hundred metres from each other on the banks of the Corriente River. In 1950, they left Esquina and settled in Buenos Aires. Maradona received his first football as a gift at age three and quickly became devoted to the game.[21] At age eight, Maradona was spotted by a talent scout while he was playing in his neighbourhood club Estrella Roja. He became a staple of Los Cebollitas (The Little Onions), the junior team of Buenos Aires's Argentinos Juniors. As a 12-year-old ball boy, he amused spectators by showing his wizardry with the ball during the halftime intermissions of first division games.[22] He named Brazilian playmaker Rivellino and Manchester United winger George Best among his inspirations growing up.[23][24]
",3
2671,"On 20 October 1976, Maradona made his professional debut for Argentinos Juniors, 10 days before his 16th birthday,[25] vs. Talleres de Córdoba. He entered to the pitch wearing the number 16 jersey, and became the youngest player in the history of the Argentine Primera División. A few minutes after debuting, Maradona kicked the ball through Juan Domingo Cabrera's legs, making a nutmeg that would become legendary.[26] After the game, Maradona said, ""That day I felt I had held the sky in my hands.""[27] Thirty years later, Cabrera remembered Maradona's debut: ""I was on the right side of the field and went to press him, but he didn't give me a chance. He made the nutmeg and when I turned around, he was far away from me"".[28] Maradona scored his first goal in the Primera División against Marplatense team San Lorenzo on 14 November 1976, two weeks after turning 16.[29]
",3
2672,"Maradona spent five years at Argentinos Juniors, from 1976 to 1981, scoring 115 goals in 167 appearances before his US$ 4 million transfer to Boca Juniors.[30] Maradona received offers to join other clubs, including River Plate who offered to make him the club's best paid player.[31] Nevertheless, Maradona expressed his will to be transferred to Boca Juniors, the team he always wanted to play for.[32]
",3
2673,"Maradona signed a contract with Boca Juniors on 20 February 1981. He made his debut two days later against Talleres de Córdoba, scoring twice in the club's 4–1 win. On 10 April, Maradona played his first Superclásico against River Plate at La Bombonera stadium. Boca defeated River 3–0 with Maradona scoring a goal after dribbling past Alberto Tarantini and Fillol.[33] Despite the distrustful relationship between Maradona and Boca Juniors manager, Silvio Marzolini,[34] Boca had a successful season, winning the league title after securing a point against Racing Club.[35] That would be the only title won by Maradona in the Argentine domestic league.[36]
",3
2674,"—Barcelona teammate Lobo Carrasco[37]
",3
2675,"After the 1982 World Cup, in June, Maradona was transferred to Barcelona in Spain for a then world record fee of £5 million ($7.6 million).[38] In 1983, under coach César Luis Menotti, Barcelona and Maradona won the Copa del Rey (Spain's annual national cup competition), beating Real Madrid, and the Spanish Super Cup, beating Athletic Bilbao. On 26 June 1983, Barcelona won away to Real Madrid in one of the world's biggest club games, El Clásico, a match where Maradona scored and became the first Barcelona player to be applauded by arch-rival Real Madrid fans.[39] Maradona dribbled past Madrid goalkeeper Agustín, and as he approached the empty goal, he stopped just as Madrid defender Juan José came sliding in an attempt to block the shot. José ended up crashing into the post, before Maradona slotted the ball into the net.[40] With the manner in which the goal was scored resulting in applause from opposition fans, only Ronaldinho (in November 2005) and Andrés Iniesta (in November 2015) have since been granted such an ovation as Barcelona players from Madrid fans at the Santiago Bernabéu.[39][41]
",3
2676,"Due to illness and injury as well as controversial incidents on the field, Maradona had a difficult tenure in Barcelona.[42] First a bout of hepatitis, then a broken ankle in a La Liga game at the Camp Nou in September 1983 caused by a reckless tackle by Athletic Bilbao's Andoni Goikoetxea—nicknamed ""the Butcher of Bilbao""—threatened to jeopardize Maradona's career, but with treatment and rehabilitation, it was possible for him to return to the pitch after a three-month recovery period.[25][43]
",3
2677,"Maradona was directly involved in a violent and chaotic fight  at the 1984 Copa del Rey Final at the Santiago Bernabéu stadium in Madrid against Athletic Bilbao.[44] After receiving another hard tackle by Goikoetxea, as well as being taunted with racist insults related to his father's Native American ancestry throughout the match by Bilbao fans, and being provoked by Bilbao's Miguel Sola at full time after Barcelona lost 1–0, Maradona snapped.[44] He aggressively got up, stood inches from Sola's face and the two exchanged words. This started a chain reaction of emotional reactions from both teams. Using expletives, Sola mimicked a gesture from the crowd towards Maradona by using a xenophobic term.[45] Maradona then headbutted Sola, elbowed another Bilbao player in the face and kneed another player in the head, knocking him out cold.[44] The Bilbao squad surrounded Maradona to exact some retribution, with Goikoetxea connecting with a high kick to his chest, before the rest of the Barcelona squad joined in to help Maradona. From this point, Barcelona and Bilbao players brawled on the field with Maradona in the centre of the action, kicking and punching anyone in a Bilbao shirt.[44]
",3
2678,"The mass brawl was played out in front of the Spanish King Juan Carlos and an audience of 100,000 fans inside the stadium, and more than half of Spain watching on television.[46] After fans began throwing solid objects on the field at the players, coaches and even photographers, sixty people were injured, with the incident effectively sealing Maradona's transfer out of the club in what was his last game in a Barcelona shirt.[45] One Barcelona executive stated, ""When I saw those scenes of Maradona fighting and the chaos that followed I realized we couldn't go any further with him.""[46] Maradona got into frequent disputes with FC Barcelona executives, particularly club president Josep Lluís Núñez, culminating with a demand to be transferred out of Camp Nou in 1984. During his two injury-hit seasons at Barcelona, Maradona scored 38 goals in 58 games.[47] Maradona transferred to Napoli in Italy's Serie A for another world record fee, £6.9 million ($10.48 million).[7]
",3
2679,"Maradona arrived in Naples and was presented to the world media as a Napoli player on 5 July 1984, where he was welcomed by 75,000 fans at his presentation at the Stadio San Paolo.[48] Sports writer David Goldblatt commented, ""They [the fans] were convinced that the saviour had arrived.""[49] A local newspaper stated that despite the lack of a ""mayor, houses, schools, buses, employment and sanitation, none of this matters because we have Maradona"".[49] Prior to Maradona's arrival, Italian football was dominated by teams from the north and centre of the country, such as A.C. Milan, Juventus, Inter Milan, and Roma, and no team in the south of the Italian Peninsula had ever won a league title.[49][50]
",3
2680,"At Napoli, Maradona reached the peak of his professional career: he soon inherited the captain's armband from Napoli veteran defender Giuseppe Bruscolotti[51] and quickly became an adored star among the club's fans; in his time there he elevated the team to the most successful era in its history.[49] Maradona played for Napoli at a period when north–south tensions in Italy were at a peak due to a variety of issues, notably the economic differences between the two.[49] Led by Maradona, Napoli won their first ever Serie A Italian Championship in 1986–87.[49] Goldblatt wrote, ""The celebrations were tumultuous. A rolling series of impromptu street parties and festivities broke out contagiously across the city in a round-the-clock carnival which ran for over a week. The world was turned upside down. The Neapolitans held mock funerals for Juventus and Milan, burning their coffins, their death notices announcing 'May 1987, the other Italy has been defeated. A new empire is born.'""[49] Murals of Maradona were painted on the city's ancient buildings, and newborn children were named in his honour.[49] The following season, the team's prolific attacking trio, formed by Maradona, Bruno Giordano, and Careca, was later dubbed the ""Ma-Gi-Ca"" (magical) front-line.[52]
",3
2681,"Napoli would win their second league title in 1989–90, and finish runners up in the league twice, in 1987–88 and 1988–89.[49] Other honours during the Maradona era at Napoli included the Coppa Italia in 1987 (as well as a second-place finish in the Coppa Italia in 1989), the UEFA Cup in 1989, and the Italian Supercup in 1990.[49] During the 1989 UEFA Cup Final against Stuttgart, Maradona scored from a penalty in a 2–1 home victory in the first leg, later assisting Careca's match–winning goal,[53][54] while in the second leg on 17 May – a 3–3 away draw –, he assisted Ciro Ferrara's goal with a header.[55][56] Despite primarily playing in a creative role as an attacking midfielder, Maradona was the top scorer in Serie A in 1987–88 with 15 goals, and was the all-time leading goalscorer for Napoli, with 115 goals,[57] until his record was broken by Marek Hamšík in 2017.[36][58][59] When asked who was the toughest player he ever faced, A.C. Milan central defender Franco Baresi stated it was Maradona, a view shared by his Milan teammate Paolo Maldini.[60][61]
",3
2682,"Although Maradona was successful on the field during his time in Italy, his personal problems increased. His cocaine use continued, and he received US$70,000 in fines from his club for missing games and practices, ostensibly because of ""stress"".[62] He faced a scandal there regarding an illegitimate son, and he was also the object of some suspicion over an alleged friendship with the Camorra.[63][64][65][66] In 2000, the number 10 jersey of Napoli was officially retired.[67] On 4 December 2020, nine days after Maradona's death, Napoli's home stadium was renamed Stadio Diego Armando Maradona.[68]
",3
2683,"After serving a 15-month ban for failing a drug test for cocaine, Maradona left Napoli in disgrace in 1992. Despite interest from Real Madrid and Marseille, he signed for Sevilla, where he stayed for one year.[69] In 1993, he played for Newell's Old Boys and in 1995 returned to Boca Juniors for a two-year stint.[25] Maradona also appeared for Tottenham Hotspur in a testimonial match for Osvaldo Ardiles against Internazionale, shortly before the 1986 World Cup.[70] In 1996, he played in a friendly match alongside his brother Raul for Toronto Italia against the Canadian National Soccer League All-Stars.[71] Maradona was himself given a testimonial match in November 2001, played between an all-star World XI and the Argentina national team.[72]
",3
2684,"During his time with the Argentina national team, Maradona scored 34 goals in 91 appearances. He made his full international debut at age 16, against Hungary, on 27 February 1977. Maradona was left off the Argentine squad for the 1978 World Cup on home soil by coach César Luis Menotti who felt he was too young at age 17.[73] At age 18, Maradona played the 1979 FIFA World Youth Championship in Japan and emerged as the star of the tournament, shining in Argentina's 3–1 final win over the Soviet Union, scoring a total of six goals in six appearances in the tournament.[74] On 2 June 1979, Maradona scored his first senior international goal in a 3–1 win against Scotland at Hampden Park.[75] He went on to play for Argentina in two 1979 Copa América ties during August 1979, a 2–1 loss against Brazil and a 3–0 win over Bolivia in which he scored his side's third goal.[76]
",3
2685,"Speaking thirty years later on the impact of Maradona's performances in 1979, FIFA President Sepp Blatter stated, ""Everyone has an opinion on Diego Armando Maradona, and that’s been the case since his playing days. My most vivid recollection is of this incredibly gifted kid at the second FIFA U-20 World Cup in Japan in 1979. He left everyone open-mouthed every time he got on the ball.""[77] Maradona and his compatriot Lionel Messi are the only players to win the Golden Ball at both the FIFA U-20 World Cup and FIFA World Cup. Maradona did so in 1979 and 1986, which Messi emulated in 2005 and 2014.[78]
",3
2686,"Maradona played his first World Cup tournament in 1982 in his new country of residence, Spain. Argentina played Belgium in the opening game of the 1982 Cup at the Camp Nou in Barcelona. The Catalan crowd was eager to see their new world-record signing Maradona in action, but he did not perform to expectations,[79] as Argentina, the defending champions, lost 1–0. Although the team convincingly beat both Hungary and El Salvador in Alicante to progress to the second round, there were internal tensions within the team, with the younger, less experienced players at odds with the older, more experienced players. With a team that also included such players as Mario Kempes, Osvaldo Ardiles, Ramón Díaz, Daniel Bertoni, Alberto Tarantini, Ubaldo Fillol, and Daniel Passarella, the Argentine side was defeated in the second round by Brazil and by eventual winners Italy. The Italian match is renowned for Maradona being aggressively man-marked by Claudio Gentile, as Italy beat Argentina at the Sarrià Stadium in Barcelona, 2–1.[80]
",3
2687,"Maradona played in all five matches without being substituted, scoring twice against Hungary. He was fouled repeatedly in all five games and particularly in the last one against Brazil at the Sarrià, a game that was blighted by poor officiating and violent fouls. With Argentina already down 3–0 to Brazil, Maradona's temper eventually got the better of him and he was sent off with five minutes remaining for a serious retaliatory foul against Batista.[81]
",3
2688,"Maradona captained the Argentine national team to victory in the 1986 World Cup in Mexico, winning the final in Mexico City against West Germany.[82] Throughout the tournament, Maradona asserted his dominance and was the most dynamic player of the competition. He played every minute of every Argentina game, scoring five goals and making five assists, three of those in the opening match against South Korea at the Olímpico Universitario Stadium in Mexico City. His first goal of the tournament came against Italy in the second group game in Puebla.[83] Argentina eliminated Uruguay in the first knockout round in Puebla, setting up a match against England at the Azteca Stadium, also in Mexico City. After scoring two contrasting goals in the 2–1 quarter-final win against England, his legend was cemented.[43] The majesty of his second goal and the notoriety of his first led to the French newspaper L'Équipe describing Maradona as ""half-angel, half-devil"".[84] This match was played with the background of the Falklands War between Argentina and the United Kingdom.[85] Replays showed that the first goal was scored by striking the ball with his hand. Maradona was coyly evasive, describing it as ""a little with the head of Maradona and a little with the hand of God"".[82] It became known as the ""Hand of God"". Ultimately, on 22 August 2005, Maradona acknowledged on his television show that he had hit the ball with his hand purposely, and no contact with his head was made, and that he immediately knew the goal was illegitimate. This became known as an international fiasco in World Cup history. The goal stood, much to the wrath of the English players.[86]
",3
2689,"—Bryon Butler's BBC Radio commentary on Maradona's second goal against England[87]
",3
2690,"Maradona's second goal, just four minutes after the hotly disputed hand-goal, was later voted by FIFA as the greatest goal in the history of the World Cup. He received the ball in his own half, swivelled around and with 11 touches ran more than half the length of the field, dribbling past five English outfield players (Peter Beardsley, Steve Hodge, Peter Reid, Terry Butcher, and Terry Fenwick) before he left goalkeeper Peter Shilton on his backside with a feint, and slotted the ball into the net.[88] This goal was voted ""Goal of the Century"" in a 2002 online poll conducted by FIFA.[8] A 2002 Channel 4 poll in the UK saw his performance ranked number 6 in the list of the 100 Greatest Sporting Moments.[89]
",3
2691,"Maradona followed this with two more goals in a semi-final match against Belgium at the Azteca, including another virtuoso dribbling display for the second goal. In the final match, West Germany attempted to contain him by double-marking, but he nevertheless found the space past the West German player Lothar Matthäus to give the final pass to Jorge Burruchaga for the winning goal. Argentina beat West Germany 3–2 in front of 115,000 fans at the Azteca with Maradona lifting the World Cup as captain.[84][90]
",3
2692,"During the tournament, Maradona attempted or created more than half of Argentina's shots, attempted a tournament-best 90 dribbles – three times more than any other player – and was fouled a record 53 times, winning his team twice as many free kicks as any player.[91][92] Maradona scored or assisted 10 of Argentina's 14 goals (71%), including the assist for the winning goal in the final, ensuring that he would be remembered as one of the greatest names in football history.[92][93] By the end of the World Cup, Maradona went on to win the Golden Ball as the best player of the tournament by unanimous vote and was widely regarded to have won the World Cup virtually single-handedly, something that he later stated he did not entirely agree with.[92][94][95][96] Zinedine Zidane, watching the 1986 World Cup as a 14-year-old, stated Maradona ""was on another level"".[97] In a tribute to him, Azteca Stadium authorities built a statue of him scoring the ""Goal of the Century"" and placed it at the entrance of the stadium.[98]
",3
2693,"Regarding Maradona's performance at the 1986 World Cup in Mexico, in 2014, Roger Bennett of ESPN FC described it as ""the most virtuoso performance a World Cup has ever witnessed,""[99] while Kevin Baxter of the Los Angeles Times called it ""one of the greatest individual performances in tournament history,""[100] with Steven Goff of The Washington Post dubbing his performance as ""one of the finest in tournament annals.""[101] In 2002, Russell Thomas of The Guardian described Maradona's second goal against England in the 1986 World Cup quarter-finals as ""arguably the greatest individual goal ever.""[102] In a 2009 article for CBC Sports, John Molinaro described the goal as ""the greatest ever scored in the tournament – and, maybe, in soccer.""[103] In a 2018 article for Sportsnet, he added: ""No other player, not even Pel[é] in 1958 nor Paolo Rossi in 1982, had dominated a single competition the way Maradona did in Mexico."" He also went on to say of Maradona's performance: ""The brilliant Argentine artist single-handedly delivered his country its second World Cup."" Regarding his two memorable goals against England in the quarter-finals, he commented: ""Yes, it was Maradona’s hand, and not God’s, that was responsible for the first goal against England. But while the 'Hand of God' goal remains one of the most contentious moments in World Cup history, there can be no disputing that his second goal against England ranks as the greatest ever scored in the tournament. It transcended mere sports – his goal was pure art.""[104]
",3
2694,"Maradona captained Argentina again in the 1990 World Cup in Italy to yet another World Cup final. An ankle injury affected his overall performance, and he was much less dominant than four years earlier. After losing their opening game to Cameroon at the San Siro in Milan, Argentina were almost eliminated in the first round, only qualifying in third position from their group. In the round of 16 match against Brazil in Turin, Claudio Caniggia scored the only goal after being set up by Maradona.[105]
",3
2695,"In the quarter-final, Argentina faced Yugoslavia in Florence; the match ended 0–0 after 120 minutes, with Argentina advancing in a penalty shootout even though Maradona's kick, a weak shot to the goalkeeper's right, was saved. The semi-final against the host nation Italy at Maradona's club stadium in Naples, the Stadio San Paolo, was also resolved on penalties after a 1–1 draw. This time, however, Maradona was successful with his effort, daringly rolling the ball into the net with an almost exact replica of his unsuccessful kick in the previous round. At the final in Rome, Argentina lost 1–0 to West Germany, the only goal being a controversial penalty scored by Andreas Brehme in the 85th minute, after Rudi Völler was adjudged to be fouled.[105]
",3
2696,"At the 1994 World Cup in the United States, Maradona played in only two games (both at the Foxboro Stadium near Boston), scoring one goal against Greece, before being sent home after failing a drug test for ephedrine doping.[106] After scoring against Greece, Maradona had one of the most remarkable World Cup goal celebrations as he ran towards one of the sideline cameras shouting with a distorted face and bulging eyes.[107] This turned out to be Maradona's last international goal for Argentina.[107] In the second game, a 2–1 victory over Nigeria which was to be his last game for Argentina, he set up both of his team's goals on free kicks, the second an assist to Caniggia.[108]
",3
2697,"In his autobiography, Maradona argued that the test result was due to his personal trainer giving him the power drink Rip Fuel. His claim was that the U.S. version, unlike the Argentine one, contained the chemical and that, having run out of his Argentine dosage, his trainer unwittingly bought the U.S. formula. FIFA expelled him from USA '94, and Argentina were subsequently eliminated in the round of 16 by Romania in Los Angeles. Maradona also separately claimed that he had an agreement with FIFA, on which the organization reneged, to allow him to use the drug for weight loss before the competition in order to be able to play.[109] His failed drug test at the 1994 World Cup signalled the end of his international career, which lasted 17 years and yielded 34 goals from 91 games, including one winner's medal and one runners-up medal in the World Cup.[110]
",3
2698,"Outwith official internationals, Maradona also played and scored for an Argentina XI against the World XI in 1978 to mark the first anniversary of their first World Cup win,[111][112] scored for The Americas against the World in a UNICEF fundraiser a short time after the 1986 triumph,[111][112] a year after that captained the 'Rest of the World' against the English Football League XI to celebrate the organisation's centenary (after reportedly securing a £100,000 appearance fee)[113][114] and was on the scoresheet for the Argentina XI once more in his own 'farewell match' in 2001.[115]
",3
2699,"—Michel Platini, former French midfielder, on Maradona's ball control[20]
",3
2700,"Described as a ""classic number 10"" in the media,[116] Maradona was a traditional playmaker who usually played in a free role, either as an attacking midfielder behind the forwards, or as a second striker in a front–two,[117][118][119] although he was also deployed as an offensive–minded central midfielder in a 4–4–2 formation on occasion.[120][121][122][123] Maradona was renowned for his dribbling ability, vision, close ball control, passing, and creativity, and is considered to have been one of the most skilful players in the sport.[96][124][125] He had a compact physique, and with his strong legs, low center of gravity, and resulting balance, he could withstand physical pressure well while running with the ball, despite his small stature,[99][126][127] while his acceleration, quick feet, and agility, combined with his dribbling skills and close control at speed, allowed him to change direction quickly, making him difficult for opponents to defend against.[128][129][130][131]
",3
2701,"Maradona is regarded as one of the greatest dribblers in the history of the game.[99][126][132][133] Former Dutch player Johan Cruyff saw similarities between Maradona and Lionel Messi with the ball seemingly attached to their body when dribbling.[134] His physical strengths were illustrated by his two goals against Belgium in the 1986 World Cup. Although he was known for his penchant for undertaking individual runs with the ball,[135] he was also a strategist and an intelligent team player, with excellent spatial awareness, as well as being highly technical with the ball. He could manage himself effectively in limited spaces, and would attract defenders only to quickly dash out of the melee (as in the second goal against England in 1986),[136][137][138][139] or give an assist to a free teammate. Being short, but strong, he could hold the ball long enough with a defender on his back to wait for a teammate making a run or to find a gap for a quick shot. He showed leadership qualities on the field and captained Argentina in their World Cup campaigns of 1986, 1990, and 1994.[140][141] While he was primarily a creative playmaker, Maradona was also known for his finishing and goalscoring ability.[96][142] Former Milan manager Arrigo Sacchi also praised Maradona for his defensive work-rate off the ball in a 2010 interview with Il Corriere dello Sport.[143]
",3
2702,"The team leader on and off the field – he would speak up on a range of issues on behalf of the players – Maradona's ability as a player and his overpowering personality had a major positive effect on his team, with his 1986 World Cup teammate Jorge Valdano stating:
",3
2703,"Maradona was a technical leader: a guy who resolved all difficulties that may come up on the pitch. Firstly, he was in charge of making the miracles happen, that's something that gives team-mates a lot of confidence. Secondly, the scope of his celebrity was such that he absorbed all the pressures on behalf of his team-mates. What I mean is: one slept soundly the night before a game not just because you knew you were playing next to Diego and Diego did things no other player in the world could do, but also because unconsciously we knew that if it was the case that we lost then Maradona would shoulder more of the burden, would be blamed more, than the rest of us. That was the kind of influence he exercised on the team.[144]",3
2704," Lauding the ""charisma"" of Maradona, another of his Argentina teammates, prolific striker Gabriel Batistuta, stated, ""Diego could command a stadium, have everyone watch him. I played with him and I can tell you how technically decisive he was for the team"".[145] Napoli's former president – Corrado Ferlaino – commented on Maradona's leadership qualities during his time with the club in 2008, describing him as ""a coach on the pitch.""[146]
",3
2705,"—Lionel Messi, the player most closely identified with the ""New Maradona"" label[77]
",3
2706,"One of Maradona's trademark moves was dribbling full-speed on the right wing, and on reaching the opponent's goal line, delivering accurate passes to his teammates. Another trademark was the rabona, a reverse-cross pass shot behind the leg that holds all the weight.[147] This manoeuvre led to several assists, such as the cross for Ramón Díaz's header against Switzerland in 1980.[148] He was also a dangerous free kick and penalty kick taker, who was renowned for his ability to bend the ball from corners and direct set pieces.[149][150][151] Regarded as one of the best dead-ball specialists of all time,[152][153][154][155] his free kick technique, which often saw him raise his knee at a high angle when striking the ball, thus enabling him to lift it high over the wall, allowed him to score free kicks even from close range, within 22 to 17 yards (20 to 16 metres) from the goal, or even just outside the penalty area.[156] His style of taking free kicks influenced several other specialists, including Gianfranco Zola,[154] Andrea Pirlo,[157] and Lionel Messi.[158]
",3
2707,"Maradona was famous for his cunning personality.[159] Some critics view his controversial ""Hand of God"" goal at the 1986 World Cup as a clever manoeuvre, with one of the opposition players, Glenn Hoddle, admitting that Maradona had disguised it by flicking his head at the same time as palming the ball.[160] The goal itself has been viewed as an embodiment of the Buenos Aires shanty town Maradona was brought up in and its concept of viveza criolla—""cunning of the criollos"".[161] Although critical of the illegitimate first goal, England striker Gary Lineker conceded, ""When Diego scored that second goal against us, I felt like applauding. I'd never felt like that before, but it's true... and not just because it was such an important game. It was impossible to score such a beautiful goal. He's the greatest player of all time, by a long way. A genuine phenomenon.""[20] Maradona used his hand in the 1990 World Cup, again without punishment, and this time on his own goal line, to prevent the Soviet Union from scoring.[162] A number of publications have referred to Maradona as the Artful Dodger, the urchin pickpocket from Charles Dickens' Oliver Twist.[163][164][165][166]
",3
2708,"Maradona was dominantly left-footed, often using his left foot even when the ball was positioned more suitably for a right-footed connection.[167] His first goal against Belgium in the 1986 World Cup semi-final is a worthy indicator of such; he had run into the inside right channel to receive a pass but let the ball travel across to his left foot, requiring more technical ability. During his run past several England players in the previous round for the ""Goal of the Century"" he did not use his right foot once, despite spending the whole movement on the right-hand side of the pitch. In the 1990 World Cup second-round tie against Brazil, he used his right foot to set up the winning goal for Claudio Caniggia due to two Brazilian markers forcing him into a position that made use of his left foot less practical.[168]
",3
2709,"Pelé scored more goals. Lionel Messi has won more trophies. Both have lived more stable lives than the overweight former cocaine addict who tops this list, whose relationship with football became increasingly strained the longer his career continued. If you've seen Diego Maradona with a football at his feet, you'll understand.",3
2710,"Maradona is widely regarded as the best player of his generation.[137] He is considered one of the greatest players of all time by pundits, players, and managers,[4][77][170] and by some as the best player ever.[169][171][172][173] Known as one of the most skilful players in the game, he is regarded as one the greatest dribblers[99][126][132][133] and free kick takers in history.[152][153][154][155] 
Though he's also listed as one of the most overrated players ever in other lists.[174] 
A precocious talent in his youth,[5] in addition to his playing ability, Maradona also drew praise from his former manager Menotti for his dedication, determination, and the work-ethic he demonstrated in order to improve the technical aspect of his game in training, despite his natural gifts, with the manager noting: ""I'm always cautious about using the word 'genius'. I find it hard to apply that even to Mozart. The beauty of Diego's game has a hereditary element – his natural ease with the ball – but it also owes a lot to his ability to learn: a lot of those brushstrokes, those strokes of 'genius', are in fact a product of his hard work. Diego worked very hard to be the best.""[175] Maradona's former Napoli manager – Ottavio Bianchi – also praised his discipline in training, commenting: ""Diego is different to the one that they depict. When you got him on his own he was a very good kid. It was beautiful to watch him and coach him. They all speak of the fact that he did not train, but it was not true because Diego was the last person to leave the pitch, it was necessary to send him away because otherwise he would stay for hours to invent free kicks.""[176] However, although, as Bianchi noted, Maradona was known for making ""great plays"" and doing ""unimaginable"" and ""incredible things"" with the ball during training sessions,[177][178][179] and would even go through periods of rigorous exercise, he was equally known for his limited work-rate in training without the ball, and even gained a degree of infamy during his time in Italy for missing training sessions with Napoli, while he often trained independently instead of with his team.[177][180][181][182]
",3
2711,"In a 2019 documentary film on his life, Diego Maradona, Maradona confessed that his weekly regime consisted of ""playing a game on Sunday, going out until Wednesday, then hitting the gym on Thursday."" Regarding his inconsistent training regimen, the film's director, Asif Kapadia, commented in 2020: ""He had a metabolism. He would look so incredibly out of shape, but then he’d train like crazy and sweat it off by the time matchday came along. His body shape just didn’t look like a footballer, but then he had this ability and this balance. He had a way of being, and that idea of talking to him honestly about how a typical week transpired was pretty amazing."" He also revealed that Maradona was ahead of his time in the fact that he had a personal fitness coach – Fernando Signorini – who trained him in a variety of areas, in addition to looking after his physical conditioning, adding: ""While he [Maradona] was in a football team he had his own regime. How many players would do that? How many players would even know to think like that? 'I’m different to anyone else so I need to train at what I’m good at and what I’m weak at.' Signorini is very well read and very intelligent. He would literally say, 'This is the way I’m going to train you, read this book.' He would help him psychologically, talk to him about philosophy, and things like that.""[183][184] Moreover, Maradona was notorious for his poor diet and extreme lifestyle off the pitch, including his use of illicit drugs and alcohol abuse, which along with personal issues, his metabolism, medication that he was prescribed, and periods of inactivity due to injuries and suspensions, led to his significant weight–gain and physical decline as his career progressed; his lack of discipline and difficulties in his turbulent personal life are thought by some in the sport to have negatively impacted his performances and longevity in the later years of his playing career.[175][185][186]
",3
2712,"A controversial figure in the sport, while he earned critical acclaim from players, pundits, and managers over his playing style, he also drew criticism in the media for his temper and confrontational behaviour, both on and off the pitch.[187][188][189] However, in 2005, Paolo Maldini, described Maradona both as the greatest player he ever faced, and also as the most honest, stating: ""He was a model of good behaviour on the pitch – he was respectful of everyone, from the great players down to the ordinary team member. He was always getting kicked around and he never complained – not like some of today's strikers.""[190] His former club and international teammate, Franco Baresi, stated when he was asked who was his greatest opponent: ""Maradona; when he was on form, there was almost no way of stopping him,""[60] while fellow former Italy defender Giuseppe Bergomi described Maradona as the greatest player of all time in 2018.[191] Zlatan Ibrahimović said his off-field antics do not matter, and he should only be judged for the impact he made on the field. ""For me Maradona is more than football. What he did as a footballer, in my opinion, he will be remembered forever. When you see number 10 who do you think about? Maradona. It is a symbol, even today there are those who choose that number for him.""[192]
",3
2713,"Today his skills would afford him greater protection. Back then they merely served as the red rag of provocation that would guarantee he would be the victim of brutal challenges wherever he played. The rules changed as a direct result of some of the injuries Maradona received. When I interviewed him a few years ago, he told me he thought players such as Lionel Messi owed him a great deal because some of the tackles he had endured would never be allowed today.",3
2714,"In 1999, Maradona was placed second behind Pelé by World Soccer in the magazine's list of the ""100 Greatest Players of the 20th Century"".[193] Along with Pelé, Maradona was one of the two joint winners of the ""FIFA Player of the Century"" award in 2000,[3] and also placed fifth in ""IFFHS' Century Elections"".[194] In a 2014 FIFA poll, Maradona was voted the second-greatest number 10 of all-time, behind only Pelé,[195] and later that year, was ranked second in The Guardian's list of the 100 greatest World Cup players of all-time, ahead of the 2014 World Cup in Brazil, once again behind Pelé.[196] In 2017, FourFourTwo ranked him in first place in their list of ""100 greatest players,""[169] while in 2018, he was ranked in first place by the same magazine in their list of the ""Greatest Football Players in World Cup History"";[197] in March 2020, he was also ranked first by Jack Gallagher of 90min.com in their list of ""Top 50 Greatest Players of All Time"".[198] In May 2020, Sky Sports ranked Maradona as the best player never to have won the UEFA Champions League or European Cup.[199]
",3
2715,"Hounded for years by the press, Maradona once fired a compressed-air rifle at reporters whom he claimed were invading his privacy. This quote from former teammate Jorge Valdano summarizes the feelings of many:
",3
2716,"He is someone many people want to emulate, a controversial figure, loved, hated, who stirs great upheaval, especially in Argentina... Stressing his personal life is a mistake. Maradona has no peers inside the pitch, but he has turned his life into a show, and is now living a personal ordeal that should not be imitated.[200]",3
2717,"In 1990, the Konex Foundation from Argentina granted him the Diamond Konex Award, one of the most prestigious culture awards in Argentina, as the most important personality in Sports in the last decade in his country. In April 1996, Maradona had a three-round exhibition boxing match with Santos Laciar for charity.[201] In 2000, Maradona published his autobiography Yo Soy El Diego (""I am The Diego""), which became a best-seller in Argentina.[202] Two years later, Maradona donated the Cuban royalties of his book to ""the Cuban people and Fidel"".[203]
",3
2718,"In 2000, he won FIFA Player of the Century award which was to be decided by votes on their official website, their official magazine and a grand jury. Maradona won the Internet-based poll, garnering 53.6% of the votes against 18.53% for Pelé.[204] In spite of this, and shortly before the ceremony, FIFA added a second award and appointed a ""Football Family"" committee composed of football journalists that also gave to Pelé the title of best player of the century to make it a draw. Maradona also came fifth in the vote of the IFFHS (International Federation of Football History and Statistics).[194] In 2001, the Argentine Football Association (AFA) asked FIFA for authorization to retire the jersey number 10 for Maradona. FIFA did not grant the request, even though Argentine officials have maintained that FIFA hinted that it would.[205]
",3
2719,"Maradona has topped a number of fan polls, including a 2002 FIFA poll in which his second goal against England was chosen as the best goal ever scored in a World Cup; he also won the most votes in a poll to determine the All-Time Ultimate World Cup Team. On 22 March 2010, Maradona was chosen number 1 in 'The Greatest 10 World Cup Players of All Time' by the London-based newspaper The Times.[206] Argentinos Juniors named its stadium after Maradona on 26 December 2003. In 2003, Maradona was employed by the Libyan footballer Al-Saadi Gaddafi, the third son of Colonel Muammar Gaddafi, as a ""technical consultant"", while Al-Saadi was playing for the Italian club, Perugia, which was playing in Serie A at the time.[207]
",3
2720,"On 22 June 2005, it was announced that Maradona would return to former club Boca Juniors as a sports vice-president in charge of managing the First Division roster (after a disappointing 2004–05 season, which coincided with Boca's centenary).[209] His contract began 1 August 2005, and one of his first recommendations proved to be very effective: advising the club to hire Alfio Basile as the new coach. With Maradona fostering a close relationship with the players, Boca won the 2005 Apertura, the 2006 Clausura, the 2005 Copa Sudamericana, and the 2005 Recopa Sudamericana.
",3
2721,"On 15 August 2005, Maradona made his debut as host of a talk-variety show on Argentine television, La Noche del 10 (""The Night of the no. 10""). His main guest on opening night was Pelé; the two had a friendly chat, showing no signs of past differences. However, the show also included a cartoon villain with a clear physical resemblance to Pelé. In subsequent evenings, he led the ratings on all occasions but one. Most guests were drawn from the worlds of football and show business, including Ronaldo and Zinedine Zidane, but also included interviews with other notable friends and personalities such as Cuban leader Fidel Castro and boxers Roberto Durán and Mike Tyson.[210] Maradona gave each of his guests a signed Argentina jersey, which Tyson wore when he arrived in Brazil, Argentina's biggest rivals.[211] In November 2005, however, Maradona rejected an offer to work with Argentina's national football team.[212]
",3
2722,"In May 2006, Maradona agreed to take part in UK's Soccer Aid (a program to raise money for UNICEF).[213] In September 2006, Maradona, in his famous blue and white number 10, was the captain for Argentina in a three-day World Cup of Indoor Football tournament in Spain. On 26 August 2006, it was announced that Maradona was quitting his position in the club Boca Juniors because of disagreements with the AFA, who selected Alfio Basile to be the new coach of the Argentina national team.[214] In 2008, Serbian filmmaker Emir Kusturica made Maradona, a documentary about Maradona's life.[215]
",3
2723,"On 1 September 2014, Maradona, along with many current and former footballing stars, took part in the ""Match for Peace"", which was played at the Stadio Olimpico in Rome, with the proceeds being donated entirely to charity.[216] Maradona set up a goal for Roberto Baggio during the first half of the match, with a chipped through-ball over the defence with the outside of his left foot.[217] Unusually, both Baggio and Maradona wore the number 10 shirt, despite playing on the same team.[217] On 17 August 2015, Maradona visited Ali Bin Nasser, the Tunisian referee of the Argentina–England quarter-final match at the 1986 World Cup where Maradona scored his Hand of God, and paid tribute to him by giving him a signed Argentine jersey.[218][219]
",3
2724,"Maradona began his managerial career alongside former Argentinos Juniors midfield teammate Carlos Fren. The pair led Mandiyú of Corrientes in 1994 and Racing Club in 1995, with little success. In May 2011 he became manager of Dubai club Al Wasl FC in the United Arab Emirates. Maradona was sacked on 10 July 2012.[220][221] In August 2013, Maradona moved on to become mental coach at Argentine club Deportivo Riestra. Maradona departed this role in 2017 to become the head coach of Fujairah, in the UAE second division, before leaving at the end of the season upon failure to secure promotion at the club.[9] In September 2018 he was appointed manager of Mexican second division side Dorados.[12] He made his debut with Dorados on 17 September 2018 with a 4–1 victory over Cafetaleros de Tapachula.[222] On 13 June 2019, after Dorados failed to clinch promotion to the Mexican top flight, Maradona's lawyer announced that he would be stepping down from the role, citing health reasons.[223]
",3
2725,"On 5 September 2019, Maradona was unveiled as the new head coach of Gimnasia de La Plata, signing a contract until the end of the season.[13] After two months in charge he left the club on 19 November.[224] However, two days later, Maradona rejoined the club as manager saying that ""we finally achieved political unity in the club"".[225] Maradona insisted that Gabriel Pellegrino remain club president if he were to stay with Gimnasia de La Plata.[226][227] However it was still not clear if Pellegrino, who declined to run for re-election,[226][227] would stay on as club President.[226][227] Originally scheduled to be held on 23 November 2019,[226] the election was delayed 15 days.[227] On 15 December 2019, Pellegrino, who was encouraged by Maradona to seek re-election, was re-elected to a three-year term.[228] Despite having a bad record during the 2019–20 season, Gimnasia renewed Maradona's contract on 3 June 2020 through the 2020–21 season.[229]
",3
2726,"After the resignation of Argentina national team coach Alfio Basile in 2008, Maradona immediately proposed his candidacy for the vacant role. According to several press sources, his major challengers included; Diego Simeone, Carlos Bianchi, Miguel Ángel Russo, and Sergio Batista. On 29 October 2008, AFA chairman Julio Grondona confirmed that Maradona would be the head coach of the national team. On 19 November 2008, Maradona managed Argentina for the first time when they played against Scotland at Hampden Park in Glasgow, which Argentina won 1–0.[230]
",3
2727,"After winning his first three matches as the coach of the national team, he oversaw a 6–1 defeat to Bolivia, equalling the team's worst ever margin of defeat. With two matches remaining in the qualification tournament for the 2010 World Cup, Argentina was in fifth place and faced the possibility of failing to qualify, but victory in the last two matches secured qualification for the finals.[231][232] After Argentina's qualification, Maradona used abusive language at the live post-game press conference, telling members of the media to ""suck it and keep on sucking it"".[233] FIFA responded with a two-month ban on all footballing activity, which expired on 15 January 2010, and a CHF 25,000 fine, with a warning as to his future conduct.[234] The friendly match scheduled to take place at home to the Czech Republic on 15 December, during the period of the ban, was cancelled. The only match Argentina played during Maradona's ban was a friendly away to Catalonia, which they lost 4–2.
",3
2728,"At the World Cup finals in June 2010, Argentina started by winning 1–0 against Nigeria, followed by a 4–1 victory over South Korea on the strength of a Gonzalo Higuaín hat-trick.[235][236] In the final match of the group stage, Argentina won 2–0 against Greece to win the group and advance to a second round, meeting Mexico.[237] After defeating Mexico 3–1, however, Argentina was routed by Germany 4–0 in the quarter-finals to go out of the competition.[238] Argentina was ranked fifth in the tournament. After the defeat to Germany, Maradona admitted that he was reconsidering his future as Argentina's coach, stating, ""I may leave tomorrow.""[239] On 15 July 2010, the AFA said that he would be offered a new four-year deal that would keep him in charge through to the summer of 2014 when Brazil staged the World Cup.[240] On 27 July, however, the AFA announced that its board had unanimously decided not to renew his contract, and instead awarded the job to 1978 World Cup winning captain and his 1986 teammate, Daniel Passarella.[241] Afterwards, on 29 July, Maradona claimed that AFA president Julio Grondona and director of national teams (as well as his former Argentine national team and Sevilla coach) Carlos Bilardo had ""lied to"", ""betrayed"", and effectively sacked him from the role. He said, ""They wanted me to continue, but seven of my staff should not go on, if he told me that, it meant he did not want me to keep working.""[242]
",3
2729,"Born to a Roman Catholic family, his parents were Diego Maradona Senior and Dalma Salvadora Franco. Maradona married long-time fiancée Claudia Villafañe on 7 November 1989 in Buenos Aires,[243] and they had two daughters, Dalma Nerea (born 2 April 1987) and Giannina Dinorah (born 16 May 1989), by whom he became a grandfather in 2009 after she married Sergio Aguero (now divorced).[244]
",3
2730,"Maradona and Villafañe divorced in 2004. Daughter Dalma has since asserted that the divorce was the best solution for all, as her parents remained on friendly terms. They travelled together to Naples for a series of homages in June 2005 and were seen together on other occasions, including the Argentina games during 2006 World Cup.[245]
",3
2731,"During the divorce proceedings, Maradona admitted that he was the father of Diego Sinagra (born in Naples on 20 September 1986). The Italian courts had already ruled so in 1993, after Maradona refused to undergo DNA tests to prove or disprove his paternity. Diego Junior met Maradona for the first time in May 2003 after tricking his way onto a golf course in Italy where Maradona was playing.[246] Sinagra is now a footballer playing in Italy.[247]
",3
2732,"After the divorce, Claudia embarked on a career as a theatre producer, and Dalma sought an acting career; she previously had expressed her desire to attend the Actors Studio in Los Angeles.[248][249]
",3
2733,"Maradona's relationship with his immediate family was a close one, and in a 1990 interview with Sports Illustrated he showed phone bills where he had spent a minimum of 15,000 US dollars per month calling his parents and siblings.[250] Maradona's mother, Dalma, died on 19 November 2011. He was in Dubai at the time, and desperately tried to fly back in time to see her, but was too late. She was 81 years old. His father, ""Don"" Diego, died on 25 June 2015 at age 87.[251]
",3
2734,"In 2014 Maradona was accused of assaulting his girlfriend, Rocío Oliva, allegations which he denied.[252][253]
",3
2735,"Maradona's great-nephew Hernán López is also a professional footballer.[254]
",3
2736,"From the mid-1980s until 2004, Maradona was addicted to cocaine. He allegedly began using the drug in Barcelona in 1983.[256] By the time he was playing for Napoli, he had a full-blown addiction, which interfered with his ability to play football.[257] In the midst of his drug crisis in 1991, Maradona was asked by journalists if the hit song ""Mi enfermedad"" (lit. ""My Disease"") was dedicated to him.[258]
",3
2737,"Maradona had a tendency to put on weight and suffered increasingly from obesity, at one point weighing 280 lb (130 kg). He was obese from the end of his playing career until undergoing gastric bypass surgery in a clinic in Cartagena de Indias, Colombia, on 6 March 2005. His surgeon said that Maradona would follow a liquid diet for three months in order to return to his normal weight.[259] When Maradona resumed public appearances shortly thereafter, he displayed a notably thinner figure.[260]
",3
2738,"On 29 March 2007, Maradona was readmitted to a hospital in Buenos Aires. He was treated for hepatitis and effects of alcohol abuse and was released on 11 April, but readmitted two days later.[261] In the following days, there were constant rumours about his health, including three false claims of his death within a month.[262] After being transferred to a psychiatric clinic specializing in alcohol-related problems, Maradona was discharged on 7 May.[263] On 8 May 2007, Maradona appeared on Argentine television and stated that he had quit drinking and had not used drugs in two and a half years.[264] During the 2018 World Cup match between Argentina and Nigeria, Maradona was shown on television cameras behaving extremely erratically, with an abundance of white residue visible on the glass in front of his seat in the stands. The smudges could have been fingerprints, and he later blamed his behaviour on consuming lots of wine.[265]  In January 2019, Maradona underwent surgery after a hernia caused internal bleeding in his stomach.[266]
",3
2739,"Maradona showed sympathy to left-wing ideologies.[267] He supported the establishment of an independent Palestinian state and condemned Israel's military strikes on Gaza during the 2014 Israel–Gaza conflict, saying: ""What Israel is doing to the Palestinians is shameful.""[268] He became friends with Cuban leader Fidel Castro while receiving treatment on the island, with Castro stating, ""Diego is a great friend and very noble, too. There's also no question he’s a wonderful athlete and has maintained a friendship with Cuba to no material gain of his own.""[77] Maradona had a portrait of Castro tattooed on his left leg and one of Fidel's second in command, fellow Argentine Che Guevara on his right arm.[269] In his autobiography, El Diego, he dedicated the book to various people, including Castro. He wrote, ""To Fidel Castro and, through him, all the Cuban people.""[270]
",3
2740,"Maradona voiced support for Bolivia's ousted president Evo Morales[271] and was also a supporter of former Venezuelan President Hugo Chávez. In 2005, he came to Venezuela to meet Chávez, who received him in the Miraflores Palace. After the meeting, Maradona said that he had come to meet a ""great man"" (un grande, which can also mean ""a big man"", in Spanish), but had instead met a gigantic man (un gigante). He also stated, ""I believe in Chávez, I am a Chavista. Everything Fidel does, everything Chávez does, for me is the best.""[272] Maradona was Chávez's guest of honour at the opening game of the 2007 Copa América held in Venezuela.[273]
",3
2741,"In 2004, he participated in a protest against the U.S.-led war in Iraq.[267] Maradona declared his opposition to what he identified as imperialism, particularly during the 2005 Summit of the Americas in Mar del Plata, Argentina. There he protested George W. Bush's presence in Argentina, wearing a T-shirt labelled "".mw-parser-output .monospaced{font-family:monospace,monospace}STOP BUSH"" (with the ""s"" in ""Bush"" being replaced with a swastika) and referring to Bush as ""human garbage"".[274][275] In August 2007, Maradona went further, making an appearance on Chávez's weekly television show Aló Presidente and saying, ""I hate everything that comes from the United States. I hate it with all my strength.""[276] By December 2008, however, Maradona had adopted a more pro-U.S. attitude and expressed admiration for Bush's successor, then-President-elect Barack Obama, for whom he had great expectations.[208]
",3
2742,"—Emir Kusturica, film director[77]
",3
2743,"With his poor shanty town (villa miseria) upbringing, Maradona cultivated a man-of-the-people persona.[277] During a meeting with Pope John Paul II at the Vatican in 1987, they clashed on the issue of wealth disparity, with Maradona stating, ""I argued with him because I was in the Vatican and I saw all these golden ceilings and afterwards I heard the Pope say the Church was worried about the welfare of poor kids. Sell your ceiling then, amigo, do something!""[277] In September 2014, Maradona met with Pope Francis in Rome, crediting Francis for inspiring him to return to religion after many years away; he stated, ""We should all imitate Pope Francis. If each one of us gives something to someone else, no one in the world would be starving.""[278]
",3
2744,"In December 2007, Maradona presented a signed shirt with a message of support to the people of Iran: it is displayed in the Iranian Ministry of Foreign Affairs' museum.[279] In April 2013, Maradona visited the tomb of Hugo Chávez and urged Venezuelans to elect the late leader's designated successor, Nicolás Maduro, to continue the socialist leader's legacy; ""Continue the struggle,"" Maradona said on television.[280] Maradona attended Maduro's final campaign rally in Caracas, signing footballs and kicking them to the crowd, and presented Maduro with an Argentina jersey.[280] Having visited Chávez's tomb with Maradona, Maduro said, ""Speaking with Diego was very emotional because comandante Chávez also loved him very much.""[280] Maradona participated and danced at the electoral campaign rally during the 2018 presidential elections in Venezuela.[281][282] During the 2019 Venezuelan presidential crisis, the Mexican Football Federation fined him for violating their code of ethics and dedicating a team victory to Nicolás Maduro.[283]
",3
2745,"Maradona in his 2000 autobiography Yo Soy El Diego linked the ""Hand of God"" goal against England at the 1986 World Cup to the Falklands War: ""Although we had said before the game that football had nothing to do with the Malvinas [Falklands] War, we knew they had killed a lot of Argentine boys there, killed them like little birds. And this was revenge.""[284] In October 2015, Maradona thanked Queen Elizabeth II and the Houses of Parliament in London for giving him the chance to provide ""true justice"" as head of an organization designed to help young children.[285] In a video released on his official Facebook page, Maradona confirmed he would accept their nomination for him to become Latin American director for the non-governmental organization Football for Unity.[285]
",3
2746,"In March 2009, Italian officials announced that Maradona still owed the Italian government €37 million in local taxes, €23.5 million of which was accrued interest on his original debt. They reported that at that point, Maradona had paid only €42,000, two luxury watches and a set of earrings.[286][287]
",3
2747,"On 2 November 2020, Maradona was admitted to a hospital in La Plata, supposedly for psychological reasons. A representative of the ex-footballer said his condition was not serious.[288] A day later, he underwent emergency brain surgery to treat a subdural hematoma.[289] He was released on 12 November after successful surgery and was supervised by doctors as an outpatient.[290] On 25 November 2020, at the age of 60, Maradona suffered a heart attack and died at his home in Dique Luján, Buenos Aires Province, Argentina.[291][292] Maradona's coffin – draped in Argentina's national flag and three Maradona number 10 jerseys (Argentinos Juniors, Boca Juniors and Argentina) – was lying in state at the Presidential Palace, the Casa Rosada, with mourners filing past his coffin.[293] On 26 November, Maradona's wake, which was attended by tens of thousands of people, was cut short by his family as his coffin was relocated from the rotunda of the Presidential Palace after fans took over an inner courtyard and also clashed with police.[294][295] The same day, a private funeral service was held and Maradona was buried next to his parents at the Jardín de Bella Vista cemetery in Bella Vista, Buenos Aires.[296]
",3
2748,"— Pelé paying tribute following Maradona's death[297]
",3
2749,"In a statement on social media, the Argentine Football Association expressed ""its deepest sorrow for the death of our legend"", adding: ""You will always be in our hearts.""[298] President Alberto Fernández announced three days of national mourning.[299] UEFA and CONMEBOL announced that every match in the Champions League, Europa League, Copa Libertadores, and Copa Sudamericana would hold a moment of silence prior to kickoff.[300][301] Boca Juniors' game was postponed in respect to Maradona.[302] Subsequently, other confederations around the world followed suit, with every fixture observing a minute of silence, starting with the 2020 AFC Champions League's fixtures.[303] In addition to the minute of silence in Italy's Serie A an image of Maradona was projected on stadium screens in the 10th minute of play.[304]
",3
2750,"In Naples, the Stadio San Paolo—officially renamed Stadio Diego Armando Maradona on 4 December 2020—was illuminated at night in honour of Maradona, with numerous fans gathering outside the stadium placing murals and paintings as a tribute. Both Napoli owner Aurelio De Laurentiis and the mayor of Naples Luigi de Magistris expressed their desire to rename their stadium after Maradona, which was unanimously approved by Naples City Council.[68] Prior to Napoli's Europa League match against Rijeka the day after Maradona's passing, all of the Napoli players wore shirts with ""Maradona 10"" on the back of them, before observing a minute of silence.[305] Figures in the sport from every continent around the world also paid tribute to him.[297][306][307] Celebrities and other sports people outside football also paid tribute to Maradona.[308][309][310][311][312]
",3
2751,"On 27 November 2020, the Aditya School of Sports in Barasat, Kolkata, India named their cricket stadium after Maradona.[313] Three years earlier Maradona had conducted a workshop with 100 kids in the stadium and played a charity match at the same venue with former Indian cricket captain, Sourav Ganguly.[313] The AFA announced that the 2020 Copa de la Liga Profesional, which is the debut season of Copa de la Liga Profesional, would be renamed Copa Diego Armando Maradona.[314] On 28 November, Pakistan Football Federation's main cup PFF National Challenge Cup honoured Maradona along with Wali Mohammad.[315][316] In a rugby test match between Argentina and New Zealand on 28 November, as the New Zealand team lined up to perform the haka their captain Sam Cane presented a black jersey with Maradona's name and his number 10.[317] On 29 November, compatriot Lionel Messi scored in Barcelona's 4–0 home win over Osasuna in La Liga, dedicating his goal to Maradona by revealing a Newell's Old Boys shirt worn by the latter under his own, and subsequently pointing to the sky.[318]
",3
2752,"On 30 November, after Boca Juniors opened the scoring against Newell's Old Boys at La Bombonera, the club's players paid an emotional tribute by laying a Maradona jersey in front of his private suite where his daughter Dalma was present.[319]
",3
2753,"The American newspaper Houston Chronicle wrote of Maradona:
",3
2754,"To understand the gargantuan shadow Maradona casts over his football-mad homeland, one has to conjure up the athleticism of Michael Jordan, the power of Babe Ruth – and the human fallibility of Mike Tyson. Lump them together in a single barrel-chested man with shaggy black hair and you have El Diego, idol to the millions who call him D10S, a mashup of his playing number and the Spanish word for God.[320]",3
2755,"In Argentina, Maradona is considered an icon. Concerning the idolatry that exists in his country, former teammate Jorge Valdano said, ""At the time that Maradona retired from active football, he left Argentina traumatized. Maradona was more than just a great footballer. He was a special compensation factor for a country that in a few years lived through several military dictatorships and social frustrations of all kinds."" Valdano added that ""Maradona offered to Argentines a way out of their collective frustration, and that's why people there love him as a divine figure.""[321] In leading his nation to the 1986 World Cup, and in particular his performance and two goals in the quarter-final against England, Guillem Balagué writes: ""That Sunday in Mexico City, the world saw one man single-handedly – in more than one sense of the phrase – lift the mood of a depressed and downtrodden nation into the stratosphere. With two goals in the space of four minutes, he allowed them to dare to dream that they, like him, could be the best in the world. He did it first by nefarious and then spellbindingly brilliant means. In those moments, he went from star player to legend.""[43]
",3
2756,"Since 1986, it has been common for Argentines abroad to hear Maradona's name as a token of recognition, even in remote places.[42] The Tartan Army sing a version of the Hokey Cokey in honour of the Hand of God goal against England.[322] In Argentina, Maradona is often talked about in terms reserved for legends. In the Argentine film El hijo de la novia (""Son of the Bride""), somebody who impersonates a Catholic priest says to a bar patron, ""They idolized him and then crucified him."" When a friend scolds him for taking the prank too far, the fake priest retorts, ""But I was talking about Maradona."" He is the subject of the film El camino de San Diego, though he himself only appears in archive footage.[323]
",3
2757,"Maradona was included in many cameos in the Argentine comic book El Cazador de Aventuras. After the closing of it, the authors started a new short-lived comic book titled El Die, using Maradona as the main character. Maradona has had several online Flash games that are entirely dedicated to his legacy.[324] In Rosario, Argentina, locals organized the parody religion of the ""Church of Maradona"". The organization reformulates many elements from Christian tradition, such as Christmas or prayers, reflecting instead details from Maradona. It had 200 founding members, and tens of thousands more have become members via the church's official web site.[325]
",3
2758,"Many Argentine artists performed songs in tribute to Diego, such as ""La Mano de Dios"" by El Potro Rodrigo, ""Maradona"" by Andrés Calamaro, ""Para siempre Diego"" (Diego Forever) by Los Ratones Paranoicos, ""Francotirador"" (Sniper) by Attaque 77, ""Maradona Blues"" by Charly García, ""Santa Maradona"" (Saint Maradona) by Mano Negra, and ""La Vida Tómbola"" by Manu Chao, among others. There are also other films, such as: Maradona, La Mano de Dios (Maradona, the Hand of God), Amando a Maradona (Loving Maradona), and Maradona by Kusturica.[215]
",3
2759,"By 1982, Maradona had become one of the biggest sports stars in the world and had endorsements with many companies, including Puma and Coca-Cola, earning him an additional $1.5 million per year on top of his club salary.[326] In 1982, he featured in a World Cup commercial for Coca-Cola, and a Japanese commercial for Puma.[326] In 2010 he appeared in a commercial for French fashion house Louis Vuitton, indulging in a game of table football with fellow World Cup winners Pelé and Zinedine Zidane.[327] Maradona featured in the music video to the 2010 World Cup song ""Waka Waka"" by Shakira, with footage shown of him celebrating Argentina winning the 1986 World Cup.[328]
",3
2760,"A 2006 television commercial for Brazilian soft drink Guaraná Antarctica portrayed Maradona as a member of the Brazil national team, including wearing the yellow jersey and singing the Brazilian national anthem with Brazilian players Ronaldo and Kaká.[329] Later on in the commercial he wakes up realizing it was a nightmare after having too much of the drink. This generated some controversy in the Argentine media after its release (although the commercial was not supposed to air for the Argentine market, fans could see it online). Maradona replied that he had no problem in wearing the Brazilian national squad jersey despite Argentina and Brazil having a tense rivalry in football, but that he would refuse to wear the shirt of River Plate, Boca Juniors' traditional rival.[330] There is a documented phenomenon of Brazilians being named in honour of Maradona,[331] an example being footballer Diego Costa.[332]
",3
2761,"In 2017, Maradona featured as a legendary player in the football video games FIFA 18 and Pro Evolution Soccer 2018.[333] In 2019, a documentary film titled Diego Maradona was released by Academy Award and BAFTA Award winning filmmaker Asif Kapadia, director of Amy (on singer Amy Winehouse) and Senna (on motor racing driver Ayrton Senna). Kapadia stated that ""
...Maradona is the third part of a trilogy about child geniuses and fame.""[334] He added, ""...I was fascinated by his journey, wherever he went there were moments of incredible brilliance and drama. He was a leader, taking his teams to the very top, but also many lows in his career. He was always the little guy fighting against the system... and he was willing to do anything, to use all of his cunning and intelligence to win.""[335]
",3
2762,"Maradona made 694 appearances and scored 354 goals for club and country combined, with a goalscoring average of 0.51.
",3
2763,"Notes
",3
2764,"Notes
",3
2765,"Boca Juniors[339]
",3
2766,"Barcelona[339]
",3
2767,"Napoli[339]
",3
2768,"Argentina Youth[339]
",3
2769,"Argentina[339][340]
",3
2770,"
",3
2771,"Emanuel ""Manu"" David Ginóbili (English: /ˈmænuː dʒɪˈnoʊbli/,[2]; born 28 July 1977) is an Argentine former professional basketball player. Over a 23-season professional career, he became one of only two players (along with Bill Bradley) to have won a EuroLeague title, an NBA championship, and an Olympic gold medal.[3] A four-time NBA champion, Ginóbili was a member of the San Antonio Spurs for his entire NBA career. Along with Spurs teammates Tim Duncan and Tony Parker, he was known as one of the ""Big Three"".
",3
2772,"Ginóbili comes from a family of professional basketball players. He spent the early part of his career in Argentina and Italy, winning several individual and team honors. His stint with Italian club Kinder Bologna was particularly successful; he won two Italian League MVP awards, the EuroLeague Finals MVP, and the 2001 EuroLeague championship and Triple Crown.
",3
2773,"Selected as the 57th overall pick in the 1999 NBA draft, Ginóbili joined the Spurs in 2002 and soon became a key player for the team. In addition to his four NBA championships, Ginóbili was named an All-Star in 2005 and 2011 and was selected twice for the All-NBA Third Team. In 2007–08, he was named the NBA Sixth Man of the Year. Ginóbili announced his retirement from the NBA on 27 August 2018.
",3
2774,"Ginóbili comes from a family of basketball players. His oldest brother, Leandro, retired in 2003 after seven years in the Argentine basketball league, while brother Sebastián has played in both the Argentine local league and in the Spanish 2nd-tier level Liga Española de Baloncesto. Their father Jorge was a coach at a club in Bahía Blanca, Argentina, where Ginóbili learned to play the game.[4] Given the proliferation of basketball clubs in Bahía Blanca and his idolization of Michael Jordan, Ginóbili's love for basketball grew rapidly.[5]
",3
2775,"Ginóbili has dual citizenship in Argentina and Italy[6] thanks to his Marchesan descent.[7] As a result of his travels, he can speak Spanish, Italian and English fluently. In his free time, Ginóbili enjoys listening to Latin music, watching movies and traveling.[8] In 2004, he married fellow Argentine Marianela Oroño.[9] On 16 May 2010, his wife gave birth to twin boys, Dante and Nicola.[10] On 21 April 2014, his wife gave birth to their third son, Luca.[11][12]
",3
2776,"Ginóbili made his professional debut in the Argentine basketball league for the Andino Sport Club of La Rioja in the 1995–96 season, and was traded to Estudiantes de Bahía Blanca the next year.[8] He played with his hometown team until 1998.
",3
2777,"He moved to Europe to spend the 1998–99 and 1999–2000 seasons with Italian team Basket Viola Reggio Calabria.[8] In 1999, he teamed with Brent Scott, Brian Oliver and Sydney Johnson to earn promotion from the Italian 2nd Division to the Italian 1st Division.[13]
",3
2778,"Ginóbili then entered the 1999 NBA draft and the San Antonio Spurs selected him late in the second round with the 57th overall pick.[14] However, he did not sign with the Spurs at this point. Instead, he returned to Italy to play for Kinder Bologna, which he helped win the 2001 Italian League Championship, the 2001 and 2002 Italian Cups, and the 2001 EuroLeague, where he was named the 2001 EuroLeague's Finals MVP.[8] He was also named the Italian League MVP in 2000–01 and 2001–02, and made the Italian League's All-Star Game three times during this period.[8]
",3
2779,"While playing with Argentina's national team at the 2002 FIBA World Championship in Indianapolis, Ginóbili made the All-Tournament Team, alongside future NBA star Yao Ming and established NBA stars Dirk Nowitzki and Peja Stojaković,[15] and helped lead Argentina to a second-place finish.[8]
",3
2780,"Ginóbili joined the Spurs for the 2002–03 NBA season, where he played backup for veteran guard Steve Smith.[5] He spent much of the early season injured, and found it hard to adjust to the NBA's style of play. As his injury improved, so did Ginóbili, winning the Western Conference Rookie of the Month in March, and being named to the All-Rookie Second Team at the end of the season.[8] Still, he only started in five games as the Spurs chalked up a 60–22 regular season win–loss record.[16][17] The Spurs then entered the playoffs eager to upend the defending champions Los Angeles Lakers, at which point Ginóbili rose to prominence.
",3
2781,"Gregg Popovich[18]
",3
2782,"In contrast to his regular season, Ginóbili became an integral part of Gregg Popovich's rotation in the playoffs, playing in every game.[8] The Spurs eliminated Phoenix and Los Angeles[19] and in those games his scoring threat took opponents by surprise, giving them one more thing to cope with against the now highly favored Spurs. He helped guide them past the Dallas Mavericks in the Western Conference Finals and then the Brooklyn Nets in the Finals,[19] securing San Antonio's second championship. After the win, Ginóbili won his first Olimpia de Oro (""Golden Olympia"") as Argentina's sportsperson of the year,[20] and met Argentine president Néstor Kirchner.[5] A gym in Bahía Blanca was dedicated in Ginóbili's honor as well.[5]
",3
2783,"In the 2003–04 season, the Spurs began featuring Ginóbili more prominently, starting him in half of the 77 regular season games in which he played.[16] His statistics improved in all major categories, as he averaged 12.8 points, 4.5 rebounds, 3.8 assists and 1.8 steals per game.[16] During the 2004 playoffs, the Spurs lost again to the Los Angeles Lakers in the Western Conference Semifinals. Following Game 5 where Derek Fisher scored a buzzer-beating jump shot,[21] the Spurs lost Game 6 and the series 4–2.[22] While Ginóbili did not start in a single playoff game as he did in 2003, his playoff statistics improved significantly, with 13.0 points, 5.3 rebounds and 3.1 assists per game.[16]
",3
2784,"After some initial issues with San Antonio over his contract, Ginóbili re-signed with the Spurs and started every game during the 2004–05 season.[16] This was his best season yet as he was selected as a reserve by NBA coaches to the 2005 Western Conference All-Star team, marking his debut in the elite mid-season showcase.[8] During the playoffs, Ginóbili's play was pivotal to winning San Antonio's third championship. The Spurs first defeated Phoenix 4–1 in the Conference Finals,[23] before prevailing in a very defensive oriented seven-game series against the Detroit Pistons.[24] Ginóbili recorded career-highs in his playoff numbers, most notably 20.8 ppg and 5.8 rpg,[16] and had the third highest point total in the entire playoffs.[8] In the NBA Finals MVP Award voting, the shooting guard was a candidate but was edged out by teammate and captain Tim Duncan.[25][5] The former finished the 2004–05 season as the second leading scorer on the team.[8] During the season, he became only the fourth person to win consecutive Olimpias de Oro, this time sharing the award with soccer star Carlos Tevez.[20]
",3
2785,"The 2005–06 season was an injury-plagued one for Ginóbili, who suffered foot and ankle injuries that hindered his ability to play. He managed 65 games in the regular season, but saw a dip in major statistics as compared to the previous season.[16] During the playoffs, he returned to form, but was unable to prevent the Spurs from being eliminated by the Dallas Mavericks in the Conference Semifinals.[26]
",3
2786,"In the 2006–07 season, the Spurs lacked energy from their reserves. Ginóbili came off the bench for most of the second half of the season, helping the Spurs attain the league's best record during that portion of the season. Ginóbili produced numbers closely identical to his successful 2004–05 campaign despite starting in only 36 of 75 games, his second lowest number of starts since arriving at San Antonio.[16] The 2007 NBA Playoffs saw him help the Spurs to defeat the Denver Nuggets, Phoenix Suns and Utah Jazz; the team then swept the Cleveland Cavaliers for Ginobili's third and San Antonio's fourth championship.[27]
",3
2787,"Ginóbili was to play an even bigger role for the Spurs the following season, reaching career high averages in points, rebounds, assists, and three-point field goal percentage.[16] On 11 February 2008, Ginóbili scored 34 points and recorded 15 rebounds in a 93–88 win over the Toronto Raptors, becoming the first guard in Spurs' history to have at least 15 points and 15 rebounds in a game.[28][29] On 21 April 2008, the NBA announced that Ginóbili had won the 2008 Sixth Man Award, winning 123 out of the 124 first place votes.[30] (self.nba)[31] Ginobili had a statline of 19.5 points, 4.5 assists, and 4.8 rebounds on .460 shooting averaging 31.1 minutes. Only a couple of weeks later, the Argentine was also named to the All-NBA Third Team.[32] In the playoffs, the Spurs defeated the Suns 4–1 in the first round,[33] Ginóbili was moved to the starting lineup in the second round against the New Orleans Hornets after the Spurs lost the first two road games. San Antonio eventually prevailed in seven games, the Argentine played another strong series, leading the Spurs in points and assists per game (21.3 and 6.0 respectively).[34] However, San Antonio lost to arch-rivals Los Angeles Lakers in the Conference Finals in five games, and once again failed to capture back-to-back NBA championships.[35]
",3
2788,"The following season, Ginóbili was injured for most of the campaign, managing only 44 regular season games and missing the 2009 NBA Playoffs entirely. San Antonio qualified for the playoffs as the third seed with a 54–28 record,[36][37] but with an aging supporting cast (Bowen, Michael Finley and Kurt Thomas were all in their late 30s), the Spurs were only considered fringe contenders for the championship.[37] As it turned out, the strong play of Duncan and Tony Parker were not enough to help the Spurs avoid a 4–1 defeat by Dallas, and the Spurs were eliminated in the first round of the playoffs for the first time since 2000.[38]
",3
2789,"On 31 October 2009, in a game against the Sacramento Kings, a bat descended onto the court at the AT&T Center, causing a stoppage of play. As the bat flew past, Ginóbili swatted the bat to the ground with his hand. He then carried the creature off the court, earning the applause of the crowd.[39] On 9 April 2010, the Spurs and Ginóbili agreed to a three-year, $39 million contract extension through the 2012–13 season.[40]
",3
2790,"In 2010–11, Ginobili was regarded as the key player on his team,[41][42][43] and he finished eighth on the NBA MVP ballot following the season.[41] Ginobili was injured in the last game of the regular season. Despite the injury, Manu averaged 20.6 points and 4.2 assists during the team's first-round series against Memphis Grizzlies; however, the Spurs lost the series in six games. Ginóbili was named an NBA All-Star for the second time in his career and also was named to the All-NBA third team.[44]
",3
2791,"In the lockout-shortened 2011–12 season, Ginóbili helped the Spurs go 50–16. The team advanced to the Western Conference Finals, where they were defeated 4–2 by the Oklahoma City Thunder. In Game Five of the series, Ginóbili scored 34 points.
",3
2792,"In 2012–13, the Spurs advanced to the NBA Finals, where they faced the Miami Heat. In the Spurs' Game Five win, Ginóbili scored a season-high 24 points and helped his team take a 3-2 series lead. However, the Spurs went on to lose Games Six and Seven.
",3
2793,"On 11 July 2013, Ginóbili re-signed with the Spurs on a two-year deal.[45] In 2013–14, the Spurs had a league-best 62–20 record. Ginóbili finished third in the voting for Sixth Man of the Year.[46] In game 1 of the Western Conference Finals against the Thunder, the Big Three of Duncan, Parker and Ginóbili notched their 110th career playoff win, matching the number of playoff wins attained by Magic Johnson, Kareem Abdul-Jabbar and Michael Cooper of the Los Angeles Lakers. The Spurs reached the NBA Finals again, where they faced the Heat for the second year in a row. This time, they dominated the series, winning 4–1 to claim that franchise's fifth championship; Ginóbili won his fourth championship as a Spur.[citation needed]
",3
2794,"On 20 July 2015, Ginóbili re-signed with the Spurs.[47] On 14 January 2016, in a win over the Cleveland Cavaliers, Ginóbili played his 900th NBA game, all with the Spurs.[48] On 4 February, he underwent surgery after suffering a testicular injury in the Spurs' win over the New Orleans Pelicans the previous night. He was subsequently sidelined for one month.[49] He returned to the action on 5 March after missing 12 games with the injury, scoring 22 points in 15 minutes against the Sacramento Kings.[50]
",3
2795,"On 14 July 2016, Ginóbili re-signed with the Spurs.[51] On 9 November 2016, in a loss to the Houston Rockets, Ginóbili became the 15th second-rounder to reach 13,000 points and joined Rashard Lewis as the only second round draft picks in NBA history with 13,000 career points and at least 1,300 three-pointers.[52]
",3
2796,"In game 5 of the 2017 Western Conference Semifinals against Houston, Ginóbili blocked James Harden's shot in the closing seconds to help San Antonio to a 110-107 victory.[53] In game 3 of the Western Conference Finals against Golden State Warriors, Ginóbili became the first player at the age of 39 to score 20 or more points off the bench in a playoff game since the NBA began recording starts in the 1970–71 NBA season.[54]
",3
2797,"On 24 August 2017, Ginóbili re-signed with the Spurs.[55] In January 2018, he became the only player in NBA history to have multiple 20-point games off the bench at age 40 or older.[56] He also became the first player in his 40s to score 15-plus points in back-to-back games since Michael Jordan in 2002–03.[56] On 28 January against the Sacramento Kings, Ginóbili and Vince Carter scored 21 and 15 points respectively; it was the first game in NBA history where two players over the age of 40 scored more than 15 points.[57] On 29 March 2018, in a 103–99 win over the Thunder, Ginobili became the Spurs' career leader in steals, passing David Robinson (1,388) for the franchise record.[58] In game 4 of the Spurs' first round playoff series against the Warriors, Ginóbili played in his 217th playoff game, breaking a tie with Shaquille O'Neal for sixth in league history. Ginóbili also passed Reggie Miller for third in career 3-pointers in playoff history.[59] The Spurs lost to the Warriors in five games.
",3
2798,"On 27 August 2018, Ginóbili announced his retirement from professional basketball,[60] making him the second player that season to complete a career with one team, after Nick Collison of the Oklahoma City Thunder.[61] On 28 March 2019, the Spurs retired Ginóbili's No. 20 jersey,[62] right next to the No. 21 jersey of Tim Duncan.
",3
2799,"Source: Basketball Reference.[63]
",3
2800,"Ginóbili was a core member of a hugely successful Argentine national basketball team, which is sometimes referred to as the Golden Generation.
",3
2801,"Ginóbili played with the junior Argentine national team at the 1997 FIBA Under-21 World Championship, where his team finished in 4th place.[64] Ginóbili was a member of the senior Argentine national basketball team, and made his senior debut during the 1998 FIBA World Championship in Athens.[8] He also played at the 2002 FIBA World Championship, where he won a silver medal. His best accomplishment as a member of the national team came at the 2004 Athens Summer Olympics when Argentina became the first team other than Team USA to win the gold medal in 16 years. The highlight of the tournament was his game-winning buzzer beater with 0.7 seconds remaining, on the opening day of the Olympics, in a game versus Serbia and Montenegro.[65] Ginóbili led the team in both scoring (19.3 points per game) and assists (3.3 assists per game).[66]
",3
2802,"He played with Argentina at the 2006 FIBA World Championship, where his team finished in 4th place. Ginóbili was the flag bearer for Argentina at the opening ceremony of the 2008 Summer Olympics, which was held in Beijing, China. At the 2008 Beijing Summer Olympics basketball tournament, Ginóbili's Argentina defeated Lithuania to win the bronze medal game, although the shooting guard did not play in that match, after sustaining an injury in the tournament's semifinals.[67] In April 2010, Ginóbili announced that he would not participate in the 2010 FIBA World Championship, due to family reasons.[68] He did however compete for the team at the 2012 London Summer Olympics, where Argentina narrowly missed out on winning the bronze medal, in the bronze medal game versus Russia.[69] He played his last international games at the 2016 Rio Summer Olympics, where Argentina finished in 8th place.
",3
2803,"Ginóbili was listed as 6 ft 6 in (1.98 m) in shoes, weighed 205 lb (93 kg) and played left-handed. He established himself as a star shooting guard[8] and became known as one of the greatest sixth men in NBA history.[70][71][72] He was a relatively late bloomer, entering the NBA at age 25 in a period when entering the NBA as a teenager was very common.  He was known as a reliable and versatile backcourt player.[5]
",3
2804,"Apart from his up-tempo and aggressive style, Ginóbili was known for his clutch play.[4][73] Ginóbili's go-to move was either a 3-pointer or a fierce drive to the basket. He often lowered his head when driving to the basket to collapse defenses and create shots or passes to his teammates. Ginobili popularized the Euro step in the NBA, although he was not the first to use the move in the league.[74]
",3
2805,"Ginobili was known as a team player. He accepted the Spurs coaches' decision to bring him off the bench for most of his career.[18] He was also known for his difficult-to-defend passes, including the no-look pass.[18] Ginobili was also willing to draw charges on defense.[4] In 2007, he was listed by ESPN writer Thomas Neumann at No. 6 on the list of greatest floppers in NBA history.[75] Five years later, Ian Thomsen, a Sports Illustrated columnist, grouped Ginóbili with fellow European league players Anderson Varejão and Vlade Divac as the players who ""made [flopping] famous"", by exaggerating contact on the court in a manner analogous to diving in soccer games.[76]
",3
2806,"Gregg Popovich, after the 2005 NBA Playoffs[4]
",3
2807,"Having traversed the major basketball continents during his career, Ginóbili is one of the few players who enjoyed success under both the physical, one-on-one play of the NBA and the more technical, jump-shooting rule set of FIBA. He is one of only two players in basketball history (along with Bill Bradley) to win the EuroLeague,[77] an Olympic gold medal, and an NBA championship ring.[14][78] He is also the first non-U.S. player to win both the NBA championship ring and the Olympic gold medal, and the second Latin American to be selected to play in an NBA All-Star game (after Panama's Rolando Blackman).[78] The Spurs made the NBA playoffs in each of Ginobili's 16 NBA seasons.[79]
",3
2808,"In 2007, ESPN sportswriter John Hollinger ranked Ginóbili as the sixth-best international player then active in the NBA, describing Ginobili as ""one of the great draft heists of all time"" and attributing the trend of NBA teams drafting developing European players to the success of the Argentine.[6] The following year, Ginóbili was named by ESPN as one of the best EuroLeague players to have graced the NBA.[80]
",3
2809,"Awards
",3
2810,"
",3
2811,"
",3
2812,"
",3
2813,"
",3
2814,"Shaquille Rashaun ""Shaq"" O'Neal (/ʃəˈkiːl/ shə-KEEL; /ʃæk/ SHAK; born March 6, 1972) is an American former professional basketball player and sports analyst on the television program Inside the NBA on TNT. He played for six teams over his 19-year career in the National Basketball Association (NBA). At 7 ft 1 in (2.16 m) tall and 325 pounds (147 kg), O'Neal is regarded as one of the greatest basketball players of all time.[1][2][3]
",3
2815,"After playing college basketball for the LSU Tigers, O'Neal was drafted by the Orlando Magic with the first overall pick in the 1992 NBA draft. He quickly became one of the best centers in the league, winning Rookie of the Year in 1992–93 and leading his team to the 1995 NBA Finals. After four years with the Magic, O'Neal signed as a free agent with the Los Angeles Lakers. They won three consecutive championships in 2000, 2001, and 2002. Amid tension between O'Neal and Kobe Bryant, O'Neal was traded to the Miami Heat in 2004, and his fourth NBA championship followed in 2006. Midway through the 2007–2008 season he was traded to the Phoenix Suns. After a season-and-a-half with the Suns, O'Neal was traded to the Cleveland Cavaliers in the 2009–10 season.[4] O'Neal played for the Boston Celtics in the 2010–11 season before retiring.[5]
",3
2816,"O'Neal's individual accolades include the 1999–2000 Most Valuable Player (MVP) Award, the 1992–93 NBA Rookie of the Year award, 15 All-Star Game selections, three All-Star Game MVP awards, three Finals MVP awards, two scoring titles, 14 All-NBA team selections, and three NBA All-Defensive Team selections. He is one of only three players to win NBA MVP, All-Star Game MVP and Finals MVP awards in the same year (2000); the other players are Willis Reed in 1970 and Michael Jordan in 1996 and 1998. He ranks 8th all time in points scored, 6th in field goals, 15th in rebounds, and 8th in blocks. Due to his ability to dunk the basketball and score from close range, O'Neal also ranks third all time in field goal percentage (58.2%).[6] O'Neal was elected into the Naismith Memorial Basketball Hall of Fame in 2016.[7] He was elected to the FIBA Hall of Fame in 2017.[8]
",3
2817,"In addition to his basketball career, O'Neal has released four rap albums, with his first, Shaq Diesel, going platinum. O'Neal is also an electronic music producer, and touring DJ, known as DIESEL.[9] He has appeared in numerous films and has starred in his own reality shows, Shaq's Big Challenge and Shaq Vs.. He hosts The Big Podcast with Shaq.[10] He is also the general manager of Kings Guard Gaming of the NBA 2K League.[11]
",3
2818,"O'Neal was born on March 6, 1972, in Newark, New Jersey, to Lucille O'Neal and Joe Toney, who played high school basketball (he was an All-State guard) and was offered a basketball scholarship to play at Seton Hall. Toney struggled with drug addiction and was imprisoned for drug possession when O'Neal was an infant. Upon his release, he did not resume a place in O'Neal's life and instead agreed to relinquish his parental rights to O'Neal's Jamaican stepfather, Phillip A. Harrison, a career Army sergeant.[12][13][14] O'Neal remained estranged from his biological father for decades; O'Neal had not spoken with Toney or expressed an interest in establishing a relationship.[14] On his 1994 rap album, Shaq Fu: The Return, O'Neal voiced his feelings of disdain for Toney in the song ""Biological Didn't Bother"", dismissing him with the line ""Phil is my father."" However, O'Neal's feelings toward Toney mellowed in the years following Harrison's death in 2013, and the two met for the first time in March 2016, with O'Neal telling him, ""I don't hate you. I had a good life. I had Phil.""[15]
",3
2819,"O'Neal came from a tall family—his biological father stood 6 ft 1 in (1.85 m) and his mother was 6 ft 2 in (1.88 m) tall—and by age 13 O'Neal was already 6 ft 6 in (1.98 m) tall. O'Neal credits the Boys & Girls Clubs of America in Newark with giving him a safe place to play and keeping him off the streets. ""It gave me something to do,"" he said. ""I'd just go there to shoot. I didn't even play on a team.""[16] Because of his stepfather's career in the military, the family left Newark, moving to military bases in Germany and Texas.[17]
",3
2820,"After returning from Germany, O'Neal's family settled in San Antonio, Texas. By age 16, O'Neal had grown to 6 ft 10 in (2.08 m), and he began playing basketball at Robert G. Cole High School. O'Neal led his team to a 68–1 record over two years and helped the team win the state championship during his senior year.[18] His 791 rebounds during the 1989 season remains a state record for a player in any classification.[19] O'Neal's tendency to make hook shots earned comparisons to Kareem Abdul-Jabbar, inspiring him to wear the same jersey number as Abdul-Jabbar, No. 33. However, his high school team did not have a 33 jersey, so O'Neal chose to wear No. 32 before college.[20]
",3
2821,"After graduating from high school, O'Neal studied business at Louisiana State University (LSU). He had first met Tigers coach Dale Brown years earlier in Europe when O'Neal's stepfather was stationed on a U.S. Army base at Wildflecken, West Germany. While playing for Brown at LSU, O'Neal was a two-time All-American, two-time SEC Player of the Year, and received the Adolph Rupp Trophy as NCAA men's basketball player of the year in 1991; he was also named college player of the year by AP and UPI. O'Neal left LSU early to pursue his NBA career, but continued his education even after becoming a professional player.[21] He was later inducted into the LSU Hall of Fame.[22] A 900-pound bronze statue of O'Neal is located in front of the LSU Basketball Practice Facility.[23]
",3
2822,"The Orlando Magic drafted O'Neal with the 1st overall pick in the 1992 NBA draft. In the summer before moving to Orlando, he spent time in Los Angeles under the tutelage of Hall of Famer Magic Johnson.[24] O'Neal wore number 32 because Terry Catledge refused to relinquish the 33 jersey.[20] O'Neal was named the Player of the Week in his first week in the NBA, the first player to do so.[25] During his rookie season, O'Neal averaged 23.4 points on 56.2% shooting, 13.9 rebounds, and 3.5 blocks per game for the season. He was named the 1993 NBA Rookie of the Year and was the first rookie to be voted an All-Star starter since Michael Jordan in 1985.[26] The Magic finished 41–41, winning 20 more games than the previous season, but missed the playoffs by virtue of a tie-breaker with the Indiana Pacers. On more than one occasion during the year, Sports Illustrated writer Jack McCallum overheard O'Neal saying, ""We've got to get [head coach] Matty [Guokas] out of here and bring in [assistant] Brian [Hill].""[27]
",3
2823,"In 1993–1994, O'Neal's second season, Hill was the coach and Guokas was reassigned to the front office.[28] O'Neal improved his scoring average to 29.4 points (second in the league to David Robinson) while leading the NBA in field goal percentage at 60%. On November 20, 1993, against the New Jersey Nets, O'Neal registered the first triple-double of his career, recording 24 points to go along with career highs of 28 rebounds and 15 blocks.[29] He was voted into the All-Star game and also made the All-NBA 3rd Team. Teamed with newly drafted Anfernee ""Penny"" Hardaway, the Magic finished with a record of 50–32 and made the playoffs for the first time in franchise history. In his first playoff series, O'Neal averaged 20.7 points and 13.3 rebounds as the Pacers swept the Magic.
",3
2824,"In O'Neal's third season, 1994–95, he led the NBA in scoring with a 29.3 point average, while finishing second in MVP voting to David Robinson and entering his third straight All-Star Game along with Hardaway. They formed one of the league's top duos and helped Orlando to a 57–25 record and the Atlantic Division crown. The Magic won their first ever playoff series against the Boston Celtics in the 1995 NBA Playoffs. They then defeated the Chicago Bulls in the conference semifinals. After beating Reggie Miller's Indiana Pacers, the Magic reached the NBA Finals, facing the defending NBA champion Houston Rockets. O'Neal played well in his first Finals appearance, averaging 28 points on 59.5% shooting, 12.5 rebounds, and 6.3 assists. Despite this, the Rockets, led by future Hall-of-Famers Hakeem Olajuwon and Clyde Drexler, swept the series in four games.[30]
",3
2825,"O'Neal was injured for a great deal of the 1995–96 season, missing 28 games. He averaged 26.6 points and 11 rebounds per game, made the All-NBA 3rd Team, and played in his 4th All-Star Game. Despite O'Neal's injuries, the Magic finished with a regular season record of 60–22, second in the Eastern conference to the Chicago Bulls, who finished with an NBA record 72 wins. Orlando easily defeated the Detroit Pistons and the Atlanta Hawks in the first two rounds of the 1996 NBA Playoffs; however, they were no match for Jordan's Bulls, who swept them in the Eastern Conference Finals.
",3
2826,"O'Neal became a free agent after the 1995–96 NBA season. In the summer of 1996, O'Neal was named to the United States Olympic basketball team, and was later part of the gold medal-winning team at the 1996 Olympics in Atlanta. While the Olympic basketball team was training in Orlando, the Orlando Sentinel published a poll that asked whether the Magic should fire Hill if that were one of O'Neal's conditions for returning.[31][32] 82% answered ""no"".[31] O'Neal had a power struggle while playing under Hill.[33][34] He said the team ""just didn't respect [Hill].""[35] Another question in the poll asked, ""Is Shaq worth $115 million?"" in reference to the amount of the Magic's offer. 91.3% of the response was ""no"".[32][33] O'Neal's Olympic teammates teased him over the poll.[32][34] He was also upset that the Orlando media implied O'Neal was not a good role model for having a child with his longtime girlfriend with no immediate plans to marry.[31] O'Neal compared his lack of privacy in Orlando to ""feeling like a big fish in a dried-up pond.""[36] O'Neal also learned that Hardaway considered himself the leader of the Magic and did not want O'Neal making more money than him.[37]
",3
2827,"On the team's first full day at the Olympics in Atlanta, the media announced that O'Neal would join the Los Angeles Lakers on a seven-year, $121 million contract.[38][39] He insisted he did not choose Los Angeles for the money. ""I'm tired of hearing about money, money, money, money, money"", O'Neal said after the signing. ""I just want to play the game, drink Pepsi, wear Reebok,"" he added, referring to a couple of his product endorsements.[40][41] The Lakers won 56 games during the 1996–97 season. O'Neal averaged 26.2 points and 12.5 rebounds in his first season with Los Angeles; however, he again missed over 30 games due to injury. The Lakers made the playoffs, but were eliminated in the second round by the Utah Jazz in five games.[42] In his first playoff game for the Lakers, O'Neal scored 46 points against the Portland Trail Blazers, the most for the Lakers in a playoff game since Jerry West had 53 in 1969. On December 17, 1996, O'Neal shoved Dennis Rodman of the Chicago Bulls; Rodman's teammates Scottie Pippen and Michael Jordan restrained Rodman and prevented further conflict. The Los Angeles Daily News reported that O'Neal was willing to be suspended for fighting Rodman, and O'Neal said: ""It's one thing to talk tough and one thing to be tough.""[43]
",3
2828,"The following season, O'Neal averaged 28.3 points and 11.4 rebounds. He led the league with a 58.4 field goal percentage, the first of five consecutive seasons in which he did so. The Lakers finished the season 61–21, first in the Pacific Division, and were the second seed in the western conference during the 1998 NBA Playoffs. After defeating the Portland Trail Blazers and Seattle SuperSonics in the first two rounds, the Lakers again fell to the Jazz, this time in a 4–0 sweep.[44]
",3
2829,"With the tandem of O'Neal and teenage superstar Kobe Bryant, expectations for the Lakers increased. However, personnel changes were a source of instability during the 1998–99 season. Long-time Laker point guard Nick Van Exel was traded to the Denver Nuggets; his former backcourt partner Eddie Jones was packaged with back-up center Elden Campbell for Glen Rice to satisfy a demand by O'Neal for a shooter. Coach Del Harris was fired, and former Lakers forward Kurt Rambis finished the season as head coach. The Lakers finished with a 31–19 record during the lockout-shortened season. Although they made the playoffs, they were swept by the San Antonio Spurs, led by Tim Duncan and David Robinson in the second round of the Western Conference playoffs. The Spurs would go on to win their first NBA title in 1999.
",3
2830,"In 1999, prior to the 1999–2000 season, the Lakers hired Phil Jackson as head coach, and the team's fortunes soon changed. Jackson immediately challenged O'Neal, telling him ""the [NBA's] MVP trophy should be named after him when he retired.""[45]
",3
2831,"In the November 10, 1999, game against the Houston Rockets, O'Neal and Charles Barkley were ejected. After O'Neal blocked a layup by Barkley, O'Neal shoved Barkley, who then threw the ball at O'Neal.[46] On March 6, 2000, O'Neal scored a career-high 61 points to go along with 23 rebounds and 3 assists in a 123–103 win over the LA Clippers.[47]
",3
2832,"O'Neal was also voted the 1999–2000 regular season Most Valuable Player, one vote short of becoming the first unanimous MVP in NBA history. Fred Hickman, then of CNN, instead chose Allen Iverson, then of the Philadelphia 76ers who would go on to win MVP the next season. O'Neal also won the scoring title while finishing second in rebounds and third in blocked shots. Jackson's influence resulted in a newfound commitment by O'Neal to defense, resulting in his first All-Defensive Team selection (second-team) in 2000.[48]
",3
2833,"In the 2001 NBA Finals against the 76ers, O'Neal fouled out in Game 3 backing over Dikembe Mutombo, the 2000–2001 Defensive Player of the Year. ""I didn't think the best defensive player in the game would be flopping like that. It's a shame that the referees buy into that"", O'Neal said. ""I wish he'd stand up and play me like a man instead of flopping and crying every time I back him down.[49]
",3
2834,"A month before the 2001–02 season's training camp, O'Neal had corrective surgery for a claw toe deformity in the smallest toe of his left foot.[50] He opted against a more involved surgery to return quicker.[51] He was ready for the start of the 2001–02 regular season, but the toe frequently bothered him.[50]
",3
2835,"In January 2002, he was involved in a spectacular on-court brawl in a game against the Chicago Bulls. He punched center Brad Miller after an intentional foul to prevent a basket, resulting in a melee with Miller, forward Charles Oakley, and several other players.[52] O'Neal was suspended for three games without pay and fined $15,000.[53] For the season, O'Neal averaged 27.2 points and 10.7 rebounds, excellent statistics but below his career average; he was less of a defensive force during the season.[50]
",3
2836,"Matched up against the Sacramento Kings in the 2002 Western Conference finals, O'Neal said, ""There is only one way to beat us. It starts with c and ends with t."" O'Neal meant ""cheat"" in reference to the alleged flopping of Kings' center Vlade Divac. O'Neal referred to Divac as ""she"", and said he would never exaggerate contact to draw a foul. ""I'm a guy with no talent who has gotten this way with hard work.""[54] 
After the 2001–2002 season, O'Neal told friends that he did not want another season of limping and being in virtually constant pain from his big right toe. His trademark mobility and explosion had been often absent. The corrective options ranged from reconstructive surgery on the toe to rehabilitation exercises with more shoe inserts and anti-inflammation medication. O'Neal was already wary of the long-term damage his frequent consumption of these medications might have. He did not want to rush a decision with his career potentially at risk.[50]
",3
2837,"Using Jackson's triangle offense, O'Neal and Bryant enjoyed tremendous success, leading the Lakers to three consecutive titles (2000, 2001, and 2002). O'Neal was named MVP of the NBA Finals all three times and had the highest scoring average for a center in NBA Finals history.[55]
",3
2838,"O'Neal missed the first 12 games of the 2002–03 season recovering from toe surgery.[56] He was sidelined with hallux rigidus, a degenerative arthritis in his toe.[57] He waited the whole summer until just before training camp for the surgery and explained, ""I got hurt on company time, so I'll heal on company time.""[58] O'Neal debated whether to have a more invasive surgery that would have kept him out an additional three months, but he opted against the more involved procedure.[57] The Lakers started the season with a record of 11–19.[59] At the end of the season, the Lakers had fallen to the fifth seed and failed to reach the Finals in 2003.
",3
2839,"For the 2003-04 season, the team made a concerted off-season effort to improve its roster. They sought the free-agent services of forward Karl Malone and aging guard Gary Payton, but due to salary cap restrictions, could not offer either one nearly as much money as they could have made with some other teams. O'Neal assisted in the recruitment efforts and personally persuaded both men to join the squad. Ultimately, both signed, each forgoing larger salaries in favor of a chance to win an NBA championship, which neither had accomplished in their careers (and which neither would achieve with the Lakers). At the beginning of the 2003–04 season, O'Neal wanted a contract extension with a pay raise on his remaining three years for $30 million. The Lakers had hoped O'Neal would take less money due to his age, physical conditioning, and games missed due to injuries. During a preseason game, O'Neal had yelled at Lakers owner Jerry Buss, ""Pay me.""[60] There had been increasing tension between O'Neal and Bryant. The feud climaxed during training camp prior to the 2003–2004 season when Bryant, in an interview with ESPN journalist Jim Gray, criticized O'Neal for being out of shape, a poor leader, and putting his salary demands over the best interest of the Lakers.[61]
",3
2840,"The Lakers made the playoffs in 2004 and lost to the Detroit Pistons in the 2004 NBA Finals. Lakers assistant coach Tex Winter said, ""Shaq defeated himself against Detroit. He played way too passively. He had one big game ... He's always interested in being a scorer, but he hasn't had nearly enough concentration on defense and rebounding.""[62] After the series, O'Neal was angered by comments made by Lakers general manager Mitch Kupchak regarding O'Neal's future with the club, as well as by the departure of Lakers coach Phil Jackson at the request of Buss. O'Neal made comments indicating that he felt the team's decisions were centered on a desire to appease Bryant to the exclusion of all other concerns, and O'Neal promptly demanded a trade. Kupchak wanted the Dallas Mavericks' Dirk Nowitzki in return but Mavericks owner Mark Cuban refused to let his 7-footer go. However, Miami showed interest, and eventually the two clubs agreed.[63] Winter said, ""[O'Neal] left because he couldn't get what he wanted—a huge pay raise. There was no way ownership could give him what he wanted. Shaq's demands held the franchise hostage, and the way he went about it didn't please the owner too much.""[64]
",3
2841,"On July 14, 2004, O'Neal was traded to the Miami Heat for Caron Butler, Lamar Odom, Brian Grant, and a future first-round draft choice (who would turn into Jordan Farmar in the 2006 draft). O'Neal reverted from (his Lakers jersey) number 34 to number 32, which he had worn while playing for the Magic. Upon signing with the Heat, O'Neal promised the fans that he would bring a championship to Miami. He claimed one of the main reasons for wanting to be traded to Miami was because of their up-and-coming star Dwyane Wade, to whom he gave the nickname ""Flash"". With O'Neal on board, the new-look Heat surpassed expectations, claiming the best record in the Eastern Conference in 2004–05 with 59 wins. He played in 73 games, his most since 2001 season, averaged 22.9 points a game along with 10.4 rebounds and 2.3 blocks. O'Neal made his 12th consecutive All-Star Team, made the All-NBA 1st Team, and won the Eastern Conference player of the Month award for his performance in March. O'Neal also narrowly lost the 2004–05 MVP Award to Phoenix Suns guard Steve Nash in one of the closest votes in NBA history.[65]
",3
2842,"Despite being hobbled by a deep thigh bruise, O'Neal led the Heat to the Eastern Conference Finals and a Game 7 against the defending champion Detroit Pistons, losing by a narrow margin. Afterwards, O'Neal and others criticized Heat head coach Stan Van Gundy for not calling enough plays for O'Neal.[66] 
In August 2005, O'Neal signed a 5-year-extension with the Heat for $100 million. Supporters applauded O'Neal's willingness to take what amounted to a pay cut and the Heat's decision to secure O'Neal's services for the long term. They contended that O'Neal was worth more than $20 million per year, particularly given that lesser players earned almost the same amount.[67]
",3
2843,"In the second game of the 2005–06 season, O'Neal injured his right ankle and subsequently missed the following 18 games. Upon O'Neal's return, Van Gundy resigned, citing family reasons, and Pat Riley assumed head coach responsibilities.[58] O'Neal later referred to Van Gundy as a ""frontrunner"" and a ""master of panic.""[68] Many critics stated that Heat coach Riley correctly managed O'Neal during the rest of the season, limiting his minutes to a career low. Riley felt doing so would allow O'Neal to be healthier and fresher come playoff time. Although O'Neal averaged career lows (or near-lows) in points, rebounds, and blocks, he said in an interview ""Stats don't matter. I care about winning, not stats. If I score 0 points and we win I'm happy. If I score 50, 60 points, break the records, and we lose, I'm pissed off. 'Cause I knew I did something wrong. I'll have a hell of a season if I win the championship and average 20 points a game.""[69] During the 2005–06 season, the Heat recorded only a .500 record without O'Neal in the line-up.[70]
",3
2844,"On April 11, 2006, O'Neal recorded his second career triple-double against the Toronto Raptors with 15 points, 11 rebounds and a career high 10 assists.[71] O'Neal finished the 2005–06 season as the league leader in field goal percentage.[71]
",3
2845,"In the 2006 NBA Playoffs, the Heat first faced the younger Chicago Bulls, and O'Neal delivered a dominating 27 point, 16 rebound and 5 blocks performance in game 1 followed by a 22-point effort in game 2 to help Miami take a 2–0 lead in the series. Chicago would respond with two dominating performances at home to tie the series, but Miami would respond right back with a victory at home in game 5. Miami returned to Chicago and closed out the series in the 6th game, highlighted by another dominating performance by O'Neal who finished with 30 points and 20 rebounds. Miami advanced to face New Jersey, who won a surprising game 1 victory before the Heat won four straight to assure a rematch with Detroit. The Pistons had no answer for Wade throughout the series, while O'Neal delivered 21 points and 12 rebounds in game 3 followed by 27 points and 12 boards in game 4 to help Miami take a 3–2 series lead. The Pistons would win game 5 in Detroit, and Wade would once again get injured, but the Heat held on to win game 6 with O'Neal scoring 28 points with 16 rebounds and 5 blocks to help Miami reach their first ever NBA Finals.[72]
",3
2846,"In the Finals, the Heat were underdogs against the Dallas Mavericks led by Dirk Nowitzki, and the Mavericks won the first two games at home in dominating fashion. The Heat led by Wade and a balanced effort by O'Neal, Antoine Walker and Jason Williams would go on to win all three of the next games at home, before closing out the series in Dallas to deliver the first NBA title for the franchise and O'Neal's fourth title. With Wade carrying the offensive load, O'Neal did not need to have a dominating series, and finished with an average of 13.7 points and 10.2 rebounds for the series.[72]
",3
2847,"In the 2006–07 season, O'Neal missed 35 games after an injury to his left knee in November required surgery.[73][74] After one of those missed games, a Christmas Day match-up against the Lakers, he ripped Jackson, who O'Neal had once called a second father, referring to his former coach as ""Benedict Arnold"". Jackson had previously said, ""The only person I've ever [coached] that hasn't been a worker ... is probably Shaq.""[75] The Heat struggled during O'Neal's absence,[76] but with his return won seven of their next eight games. Bad luck still haunted the squad, however, as Wade dislocated his left shoulder, leaving O'Neal as the focus of the team.[76] Critics doubted that O'Neal, now in his mid-30s, could carry the team into the playoffs.[77] The Heat went on a winning streak that kept them in the race for a playoff spot, which they finally secured against the Cleveland Cavaliers on April 5.[76]
",3
2848,"In a rematch of the year before, the Heat faced the Bulls in the first round of the 2006–07 NBA playoffs. The Heat struggled against the Bulls and although O'Neal put up reasonable numbers, he was not able to dominate the series. The Bulls swept the Heat, the first time in 50 years a defending NBA champion was swept in the opening round.[78] It was the first time in 13 years that O'Neal did not advance into the second round. In the 2006–07 season O'Neal reached 25,000 career points, becoming the 14th player in NBA history to accomplish that milestone. However, it was the first season in O'Neal's career that his scoring average dropped below 20 points per game.[6]
",3
2849,"O'Neal experienced a rough start for the 2007–08 season, averaging career lows in points, rebounds, and blocks. His role in the offense diminished, as he attempted only 10 field goals per game, versus his career average of 17. In addition, O'Neal was plagued by fouls, and during one stretch fouled out of five consecutive games. O'Neal's streak of 14 straight All-Star appearances ended that season.[6] O'Neal again missed games due to injuries, and the Heat had a 15–game losing streak.[79] According to O'Neal, Riley thought he was faking the injury.[80] During a practice in February 2008, O'Neal got into an altercation with Riley over the coach ordering a tardy Jason Williams to leave practice. The two argued face-to-face, with O'Neal poking Riley in the chest and Riley slapping his finger away. Riley soon after decided to trade O'Neal.[81] O'Neal said his relationship with Wade was not ""all that good"" by the time he left Miami, but he did not express disappointment at Wade for failing to stand up for him.[82]
",3
2850,"O'Neal played 33 games for the Miami Heat in the 2007–08 season prior to being traded to the Phoenix Suns. O'Neal started all 33 games and averaged 14.2 points per game. Following the trade to Phoenix, O'Neal averaged 12.9 points while starting all 28 games with the Suns.
",3
2851,"The Phoenix Suns acquired O'Neal in February 2008 from the league-worst Miami Heat, who had a record at the time of the trade of 9-37, in exchange for Shawn Marion and Marcus Banks.[83] O'Neal made his Suns debut on February 20, 2008, against his former Lakers team, scoring 15 points and grabbing 9 rebounds in the process. The Lakers won, 130–124. O'Neal was upbeat in a post-game press conference, stating: ""I will take the blame for this loss because I wasn't in tune with the guys [...] But give me four or five days to really get in tune and I'll get it.""[84]
",3
2852,"In 28 regular-season games, O'Neal averaged 12.9 points and 10.6 rebounds,[85] good enough to make the playoffs. One of the reasons for the trade was to limit Tim Duncan in the event of a postseason matchup between the Suns and the San Antonio Spurs, especially after the Suns' six-game elimination by the Spurs in the 2007 NBA Playoffs.[86] O'Neal and the Phoenix Suns did face the Spurs in the first round of the playoffs, but they were once again eliminated, in five games. O'Neal averaged 15.2 points, 9.2 rebounds and 1.0 assists per game.[85]
",3
2853,"O'Neal preferred his new situation with the Suns over the Heat. ""I love playing for this coach and I love playing with these guys"", O'Neal said. ""We have professionals who know what to do. No one is asking me to play with [his former Heat teammates] Chris Quinn or Ricky Davis. I'm actually on a team again."" Riley felt O'Neal was wrong for maligning his former teammates. O'Neal responded with an expletive toward Riley, whom he often referred to as the ""great Pat Riley"" while playing for the Heat.[87] O'Neal credited the Suns training staff with prolonging his career.[88] They connected his arthritic toe, which would not bend, to the alteration of his jump that consequently was straining his leg. The trainers had him concentrate on building his core strength, flexibility, and balance.[89]
",3
2854,"The 2008–09 season improved for O'Neal, who averaged 18 points, 9 rebounds, and 1.6 blocks through the first half (41 games) of the season, leading the Suns to a 23–18 record and 2nd place in their division.[90] He returned to the All-Star Game in 2009 and emerged as co-MVP along with ex-teammate Kobe Bryant.
",3
2855,"On February 27, 2009, O'Neal scored 45 points and grabbed 11 rebounds, his 49th career 40-point game, beating the Toronto Raptors 133–113.
",3
2856,"In a matchup against Orlando on March 3, 2009, O'Neal was outscored by Magic center Dwight Howard, 21–19. ""I'm really too old to be trying to outscore 18-year-olds"", O'Neal said, referring to the then 23-year-old Howard. ""It's not really my role anymore."" O'Neal was double-teamed most of the night. ""I like to play people one-on-one. My whole career I had to play people one-on-one. Never once had to double or ask for a double. But it's cool"", said O'Neal. During the game, O'Neal flopped against Howard. Magic coach Stan Van Gundy, who had coached O'Neal with the Heat, was ""very disappointed cause [O'Neal] knows what it's like. Let's stand up and play like men, and I think our guy did that tonight.""[91] O'Neal responded, ""Flopping is playing like that your whole career. I was trying to take the charge, trying to get a call. It probably was a flop, but flopping is the wrong use of words. Flopping would describe his coaching.""[92] Mark Madsen, a Lakers teammate of O'Neal's for three years, found it amusing since ""everyone in the league tries to flop on Shaq and Shaq never flops back.""[93] In a 2006 interview in TIME, O'Neal said if he were NBA commissioner, he would ""Make a guy have to beat a guy—not flop and get calls and be nice to the referees and kiss ass.""[94]
",3
2857,"On March 6, O'Neal talked about the upcoming game against the Rockets and Yao Ming. ""It's not going to be man-on-man, so don't even try that,"" says O'Neal with an incredulous laugh. ""They're going to double and triple me like everybody else ... I rarely get to play [Yao] one-on-one ... But when I play him (on defense), it's just going to be me down there. So don't try to make it a Yao versus Shaq thing, when it's Shaq versus four other guys.""[95]
",3
2858,"The 2009 NBA Playoffs was also the first time since O'Neal's rookie season in 1992–93 that he did not participate in the playoffs. He was named as a member of the All-NBA Third Team. The Suns notified O'Neal he might be traded to cut costs.[96]
",3
2859,"On June 25, 2009, O'Neal was traded to the Cleveland Cavaliers for Sasha Pavlovic, Ben Wallace, $500,000, and a 2010-second round draft pick.[97] Upon arriving in Cleveland, O'Neal said, ""My motto is very simple: Win a Ring for the King"", referring to LeBron James.[98] James was the leader of the team, and O'Neal deferred to him.[99] On February 25, 2010, O'Neal suffered a severe right thumb injury while attempting to go up for a shot against Glen Davis of the Boston Celtics.[100] He had surgery on the thumb on March 1 and returned to play in time for the first round of the playoffs.[101] After defeating the Chicago Bulls in the first round, the Cavaliers went on to lose to the Boston Celtics in the second round. In September 2016, O'Neal said: ""When I was in Cleveland, we were in first place. Big Baby [Glen Davis] breaks my hand and I had to sit out five weeks late in the year. I come back finally in the first round of the playoffs, and we lost to Boston in the second round. I was upset. I know for a fact if I was healthy, we would have gotten it done that year and won a ring.""[102] O'Neal averaged career lows in almost every major statistical category during the 2009–10 season, taking on a much less significant role than in previous years.
",3
2860,"Upon hearing Bryant comment that he had more rings than O'Neal, Wyc Grousbeck, principal owner of the Celtics, saw an opportunity to acquire O'Neal.[103] Celtics coach Doc Rivers agreed to the signing on the condition that O'Neal would not receive preferential treatment, nor could he cause any locker room problems like in Los Angeles or Miami.[104] On August 4, 2010, the Celtics announced that they had signed O'Neal.[105] The contract was for two years at the veteran minimum salary for a total contract value of $2.8 million.[106] O'Neal wanted the larger mid-level exception contract, but the Celtics chose instead to give it to Jermaine O'Neal.[107] The Atlanta Hawks and the Dallas Mavericks also expressed interest but had stalled on O'Neal's salary demands.[108][109] He was introduced by the Celtics on August 10, 2010, and chose the number 36.[110]
",3
2861,"O'Neal said he didn't ""compete with little guys who run around dominating the ball, throwing up 30 shots a night—like D–Wade, Kobe."" O'Neal added that he was only competing against Duncan: ""If Tim Duncan gets five rings, then that gives some writer the chance to say 'Duncan is the best,' and I can't have that.""[111] Publicly, he insisted he did not care whether he started or substituted for the Celtics, but expected to be part of the second unit.[111] Privately, he wanted to start, but kept it to himself.[112] O'Neal missed games throughout the season due to an assortment of ailments to his right leg[113] including knee,[114] calf,[115] hip,[116] and Achilles injuries.[117] The Celtics traded away center Kendrick Perkins in February partially due to the expectation that O'Neal would return to fill Perkins' role. The Celtics were 33–10 in games Perkins had missed during the year due to injury,[113] and they were 19–3 in games that O'Neal played over 20 minutes.[118] After requesting a cortisone shot, O'Neal returned April 3 after missing 27 games due to his Achilles; he played only five minutes due to a strained right calf.[113][119] It was the last regular season game he would play that year.[120] O'Neal missed the first round of the 2011 playoffs. He insisted on more cortisone shots and returned in the second round, but he was limited to 12 minutes in two games as the Heat eliminated the Celtics from the playoffs.[121][122]
",3
2862,"On June 1, 2011, O'Neal announced his retirement via social media.[123][124] On a short video on Twitter, O'Neal tweeted, ""We did it. Nineteen years, baby. I want to thank you very much. That's why I'm telling you first. I'm about to retire. Love you. Talk to you soon."" On June 3, 2011, O'Neal held a press conference at his home in Orlando to officially announce his retirement.[125]
",3
2863,"While in college, O'Neal was considered for the Dream Team to fill the college spot, but it eventually went to future teammate Christian Laettner.[126] His national team career began in the 1994 FIBA World Championship in which he was named MVP of the Tournament. While he led the Dream Team II to the gold medal with an 8–0 record, O'Neal averaged 18 points and 8.5 rebounds and recorded two double-doubles. In four games, he scored more than 20 points. Before 2010, he was the last active American player to have a gold from the FIBA World Cup.
",3
2864,"He was one of two players (the other being Reggie Miller) from the 1994 roster to be also named to the Dream Team III. Due to more star-power, he rotated with Hakeem Olajuwon and David Robinson and started 3 games. He averaged 9.3 points and 5.3 rebounds with 8 total blocks. Again, a perfect 8–0 record landed him another gold medal at the 1996 Olympics in Atlanta. O'Neal was upset that coach Lenny Wilkens played Robinson more minutes in the final game; Wilkens previously explained to O'Neal that it would probably be Robinson's last Olympics.[127]
",3
2865,"After his 1996 experience, he declined to play in international competition. He was angered by being overlooked for the 1999 FIBA AmeriCup squad, saying it was a ""lack of respect"".[128] He forwent an opportunity to participate in the 2000 Olympics, explaining that two gold medals were enough.[129] Shaq also chose not to play in the 2002 FIBA World Championship.[130] He rejected an offer to play in the 2004 Olympics,[131] and although he was initially interested in being named for 2006–2008 US preliminary roster,[132] he eventually declined the invitation.[133]
",3
2866,"O'Neal established himself as an overpowering low post presence, putting up career averages of 23.7 points on .582 field goal accuracy, 10.9 rebounds and 2.3 blocks per game.
",3
2867,"At 7 ft 1 in (2.16 m), 330 lb (150 kg)[134] and U.S. shoe size 23,[56] he became famous for his physical stature. His physical frame gave him a power advantage over most opponents. On two occasions during his first season in the NBA, his powerful dunks broke the steel backboard supports, prompting the league to increase the brace strength and stability of the backboards for the following 1993–94 season.[135]
",3
2868,"O'Neal's ""drop step"", (called the ""Black Tornado"" by O'Neal) in which he posted up a defender, turned around and, using his elbows for leverage, powered past him for a very high-percentage slam dunk, proved an effective offensive weapon. In addition, O'Neal frequently used a right-handed jump hook shot to score near the basket. The ability to dunk contributed to his career field goal accuracy of .582, second only to Artis Gilmore as the highest field goal percentage of all time.[136] He led the NBA in field goal percentage 10 times, breaking Wilt Chamberlain's record of nine.[56]
",3
2869,"Opposing teams often used up many fouls on O'Neal, reducing the playing time of their own big men. O'Neal's imposing physical presence inside the paint caused dramatic changes in many teams' offensive and defensive strategies.[137]
",3
2870,"O'Neal's primary weakness was his free throw shooting, with a career average of 52.7%. He once missed all 11 of his free throw attempts in a game against the Seattle SuperSonics on December 8, 2000, a record.[138] O'Neal believes his free throw woes were a mental issue, as he often shot 80 percent in practice.[139] In hope of exploiting O'Neal's poor foul shooting, opponents often committed intentional fouls against him, a tactic known as ""Hack-a-Shaq"". O'Neal was the third-ranked player all-time in free throws taken,[140] having attempted 11,252 free-throws in 1,207 games up to and including the 2010–11 season. On December 25, 2008, O'Neal missed his 5,000th free throw, becoming the second player in NBA history to do so, along with Chamberlain.[141]
",3
2871,"O'Neal only made one three point shot during his entire career. He made the shot during the 1995–96 NBA season with the Orlando Magic. His career three point shot record is 1 for 22 (a 4.5% career percentage).
",3
2872,"O'Neal was a capable defender, named three times to the All-NBA Second Defensive Team. His presence intimidated opposing players shooting near the basket, and he averaged 2.3 blocked shots per game over the course of his career.[142]
",3
2873,"Phil Jackson believed O'Neal underachieved in his career, saying he ""could and should have been the MVP player for 10 consecutive seasons.""[143] The Lakers retired his No. 34 jersey on April 2, 2013.[144]
",3
2874,"On February 26, 2016, the Miami Heat announced that it would retire O'Neal's No. 32 jersey during the 2016–17 season, making O'Neal one of just 32 athletes in American professional sports history to have their jersey retired by multiple teams.[145][146] The Heat eventually retired his jersey on December 22, 2016, during halftime of a game against his former team, the Los Angeles Lakers.
",3
2875,"O'Neal called himself ""The Big Aristotle"" and ""Hobo Master"" for his composure and insights during interviews. Journalists and others gave O'Neal several nicknames including ""Shaq"", ""The Diesel"", ""Shaq Fu"", ""The Big Daddy"", ""Superman"", ""The Big Agave"", ""The Big Cactus"", ""The Big Shaqtus"", ""The Big Galactus"", ""Wilt Chamberneezy"", ""The Big Baryshnikov"", ""The Real Deal"", ""The Big Shamrock"", ""The Big Leprechaun"", ""Shaqovic"",[147][148] and ""The Big Conductor"".[149] Although he was a favorite interviewee of the press, O'Neal was sensitive and often went weeks without speaking.[150] When he did not want to speak with the press, he employed an interview technique whereby, sitting in front of his cubicle, he would murmur in his low-pitched voice.[150][151]
",3
2876,"During the 2000 Screen Actors Guild strike, O'Neal performed in a commercial for Disney. O'Neal was fined by the union for crossing the picket line.[152][153]
",3
2877,"O'Neal's humorous and sometimes incendiary comments fueled the Los Angeles Lakers' long-standing rivalry with the Sacramento Kings; O'Neal frequently referred to the Sacramento team as the ""Queens.""[154][155][156] During the 2002 victory parade, O'Neal declared that Sacramento would never be the capital of California,[157] after the Lakers beat the Kings in a tough seven-game series en route to its third championship with O'Neal.
",3
2878,"He also received media flak for mocking Chinese people when interviewed about newcomer center Yao Ming. O'Neal told a reporter, ""you tell Yao Ming, ching chong yang, wah, ah so.""[158] O'Neal later said it was locker room humor and he meant no offense. Yao believed that O'Neal was joking, but he said many Asians wouldn't see the humor.[159] Yao joked, ""Chinese is hard to learn. I had trouble with it when I was little.""[160] O'Neal later admitted that he regretted how he treated Yao early in his career.[161]
",3
2879,"During the 2005 NBA playoffs, O'Neal compared his poor play to Erick Dampier,[162] a Dallas Mavericks center who had failed to score a single point in one of their recent games. The quip inspired countless citations and references by announcers during those playoffs, though Dampier himself offered little response to the insult. The two would meet in the 2006 NBA Finals.[163]
",3
2880,"O'Neal was very vocal with the media, often making jabs at former Laker teammate Kobe Bryant. In the summer of 2005, when asked about Bryant, he responded, ""I'm sorry, who?"" and continued to pretend that he did not know who Bryant was until well into the 2005–06 season.[164]
",3
2881,"O'Neal also appeared on television on Saturday Night Live (he was initially picked to host the second episode of season 24 in 1998, but had to back down due to scheduling conflicts, being replaced by Kelsey Grammer; however, he did appear in two sketches during the episode) and in 2007 hosted Shaq's Big Challenge, a reality show on ABC in which he challenged Florida kids to lose weight and stay in shape.
",3
2882,"When the Lakers faced the Heat on January 16, 2006, O'Neal and Bryant made headlines by engaging in handshakes and hugs before the game, an event that was believed to signify the end of the so-called ""Bryant–O'Neal feud"" that had festered since the center left Los Angeles. O'Neal was quoted as saying that he accepted the advice of NBA legend Bill Russell to make peace with Bryant.[165] However, on June 22, 2008, O'Neal freestyled a diss rap about Bryant in a New York club. While rapping, O'Neal blamed Bryant for his divorce from his wife Shaunie and claims to have received a vasectomy, as part of a rhyme. He also taunted Bryant for not being able to win a championship without him. O'Neal led the audience to mockingly chant several times ""Kobe, tell me how my ass tastes.""[166] O'Neal justified his act by saying ""I was freestyling. That's all. It was all done in fun. Nothing serious whatsoever. That is what MCs do. They freestyle when called upon. I'm totally cool with Kobe. No issue at all.""[167] Although even other exponents of hip hop, such as Snoop Dogg, Nas and Cory Gunz, agreed with O'Neal,[168] Maricopa County, Arizona Sheriff Joe Arpaio expressed his intention to relieve O'Neal of his Maricopa County sheriff posse badge, due to ""use of a racially derogatory word and other foul language"". The racial quote from his song was ""it's like a white boy trying to be more nigga than me.""[169]
",3
2883,"In August 2010, O'Neal was sued by his personal IT technician, Shawn Darling, after O'Neal had allegedly attempted to plant child pornography on Darling's computer.[170][171][172][173][174] Darling claimed that O'Neal had originally tried to protect himself by hacking his mistresses voicemails and deleting relevant messages. Darling also alleged that O'Neal had used law enforcement contacts to obtain restricted information on those mistresses, and that O'Neal subsequently threw his laptop into a lake to destroy possible evidence.
",3
2884,"In April 2014, O'Neal posted a photo on Instagram that showed himself mocking Jahmel Binion who suffers from Ectodermal dysplasia.[175][176] O'Neal issued a public apology, stating that he and Binion had spoken and that he's ""made a friend today"".[175] Binion would however go on to sue O'Neal for a sum larger than $25,000.[175]
",3
2885,"O'Neal left LSU for the NBA after three years. However, he promised his mother he would eventually return to his studies and complete his bachelor's degree. He fulfilled that promise in 2000, earning his B.A. degree in general studies,[177] with a minor in political science.[178] Coach Phil Jackson let O'Neal miss a home game so he could attend graduation. At the ceremony, he told the crowd ""now I can go and get a real job"".
Subsequently, O'Neal earned an online MBA degree through the University of Phoenix in 2005. In reference to his completion of his MBA degree, he stated: ""It's just something to have on my resume for when I go back into reality. Someday I might have to put down a basketball and have a regular 9-to-5 like everybody else.""[179]
",3
2886,"Toward the end of his playing career, he began work on an educational doctorate at Barry University.[180][181] His doctoral capstone[182][183] topic was ""The Duality of Humor and Aggression in Leadership Styles"".[180][184] O'Neal received his Ed.D. degree in Human Resource Development in 2012.[185] O'Neal told a reporter for ABC News that he plans to further his education by attending law school.[186]
",3
2887,"O'Neal has also studied directing and cinematography with the New York Film Academy's Filmmaking Conservatory.[187]
",3
2888,"O'Neal maintained a high level of interest in the workings of police departments and became personally involved in law enforcement. O'Neal went through the Los Angeles County Sheriff's Reserve Academy and became a reserve officer with the Los Angeles Port Police. 
On March 2, 2005, O'Neal was given an honorary U.S. Deputy Marshal title and named the spokesman for the Safe Surfin' Foundation; he served an honorary role on the task force of the same name, which tracks down sexual predators who target children on the Internet.[188]
",3
2889,"Upon his trade to Miami, O'Neal began training to become a Miami Beach reserve officer. On December 8, 2005, he was sworn in, but elected for a private ceremony to avoid distracting attention from the other officers. He assumed a $1 per year salary in this capacity.[189] Shortly thereafter, in Miami, O'Neal witnessed a hate crime (assaulting a man while calling out homophobic slurs) and called Miami-Dade police, describing the suspect and helping police, over his cell phone, track the offender.[189] O'Neal's actions resulted in the arrest of two suspects on charges of aggravated battery, assault, and a hate crime.[190]
",3
2890,"In September 2006, O'Neal took part in a raid on a home in rural Bedford County, Virginia. O'Neal had been made an ""honorary deputy"" by the local sheriff's department. O'Neal was not qualified as a SWAT officer.[191]
",3
2891,"In June 2008, the Bedford County, Virginia and Maricopa County, Arizona sheriff departments revoked O'Neal special deputyship after a video surfaced of him rapping about Kobe Bryant and using racial slurs.[192][193]
",3
2892,"In December 2016, O'Neal was sworn in as a sheriff's deputy in Jonesboro, Georgia as part of Clayton County, Georgia Sheriff's Department. O'Neal holds the county record of Tallest Sheriff's Deputy.[194]
",3
2893,"Beginning in 1993, O'Neal began to compose rap music. He released five studio albums and 1 compilation album. Although his rapping abilities were criticized at the outset,[195][196] one critic credited him with ""progressing as a rapper in small steps, not leaps and bounds"".[197] His 1993 debut album, Shaq Diesel, received platinum certification from the RIAA.
",3
2894,"O'Neal was featured alongside Michael Jackson as a guest rapper on ""2 Bad"", a song from Jackson's 1995 album HIStory. He contributed three tracks, including the song ""We Genie"", to the Kazaam soundtrack.[198] O'Neal was also featured in Aaron Carter's 2001 hit single ""That's How I Beat Shaq"". Shaq also appears on the music video for the release.[199]
",3
2895,"Shaquille O'Neal conducted the Boston Pops Orchestra at the Boston Symphony Hall on December 20, 2010.
",3
2896,"O'Neal also started DJing in the 1980s at LSU.[200] Currently, he produces electronic music and tours the world under the stage name, DIESEL.[201] O'Neal also created his part music festival, circus and carnival, SHAQ's Fun House, alongside his two music managers.[202]
",3
2897,"In July 2017, O'Neal released a diss track aimed at LaVar Ball, the father of NBA point guard Lonzo Ball. The three minute song was released in response to Ball claiming him and his younger son LaMelo, would beat O'Neal and his son Shareef in a game of basketball.
",3
2898,"Starting with Blue Chips and Kazaam, O'Neal appeared in films that were panned by some critics.[203][204]
",3
2899,"O'Neal is one of the first African Americans to portray a major comic book superhero in a motion picture, having starred as John Henry Irons, the protagonist in the 1997 film Steel. He is preceded only by Michael Jai White, whose film Spawn was released two weeks before Steel.
",3
2900,"O'Neal appeared as himself on an episode of Curb Your Enthusiasm, bedridden after Larry David's character accidentally tripped him while stretching, and in two episodes each of My Wife and Kids and The Parkers. He appeared in cameo roles in the films Freddy Got Fingered, Jack and Jill and Scary Movie 4. O'Neal appeared in the 311 music video for the hit single ""You Wouldn't Believe"" in 2001, in P. Diddy's video for ""Bad Boy for Life"", the video for Aaron Carter's ""That's How I Beat Shaq"", the video for Owl City's ""Vanilla Twilight"" and the video for Maroon 5's ""Don't Wanna Know"". O'Neal appeared in the movie CB4 in a small ""interviewing"" scene. O'Neal appeared in a SportsCenter commercial dressed in his Miami police uniform, rescuing Mike the Tiger from a tree. O'Neal reportedly wanted a role in the film X2 (the second in the X-Men film series), but was ignored by the filmmakers.[205] O'Neal appeared as Officer Fluzoo in the comedy sequel Grown Ups 2.
",3
2901,"He voiced animated versions of himself on several occasions, including in the animated series Static Shock (2002; episode ""Static Shaq""), in Johnny Bravo (1997; episode ""Back on Shaq""), in Uncle Grandpa (2014; episode ""Perfect Kid""), and in The Lego Movie (2014). He also had a voice over role in the 2013 film The Smurfs 2.[206]
",3
2902,"O'Neal was featured on the covers of video games NBA Live 96, NBA 2K6, NBA 2K7, NBA Showtime: NBA on NBC, NBA Hoopz, and NBA Inside Drive 2004.[207][208][209][210]
O'Neal appeared in the arcade version of NBA Jam (1993), NBA Jam (2003) and NBA Live 2004 as a current player and as a 1990s All-Star. O'Neal starred in Shaq Fu, a fighting game for the Super Nintendo Entertainment System and Sega Genesis. A sequel, Shaq Fu: A Legend Reborn, was released in 2018.[211] O'Neal also appeared in Backyard Basketball in 2004, Ready 2 Rumble Boxing: Round 2 as a playable boxer, and as an unlockable character in Delta Force: Black Hawk Down. O'Neal was also an unlockable character in UFC Undisputed 2010.[212]
",3
2903,"O'Neal and his mother, Lucille Harrison, were featured in the documentary film Apple Pie, which aired on ESPN.[213][214] O'Neal had a 2005 reality series on ESPN, Shaquille,[215] and hosted a series called Shaq's Big Challenge on ABC.[216]
",3
2904,"O'Neal appeared on NBA Ballers and NBA Ballers: Phenom,[217] in the 2002 Discovery Channel special Motorcycle Mania 2 requesting an exceptionally large bike to fit his large size famed custom motorcycle builder Jesse James,[218] in the first Idol Gives Back in 2007,[219] on an episode of Fear Factor,[220] and on an episode of MTV's Jackass, where he was lifted off the ground on Wee Man's back.[221] O'Neal was a wrestling fan and made appearances at many WWE events.[222]
",3
2905,"O'Neal was pranked on the MTV show Punk'd when a crew member accused him of stealing his parking space. After O'Neal and his wife went into a restaurant, Ashton Kutcher's crew members let the air out of O'Neal's tires. O'Neal and the crew member then got into an altercation and after Kutcher told O'Neal he had been Punk'd, O'Neal made an obscene gesture at the camera.[223][224]
",3
2906,"O'Neal starred in a reality show called Shaq Vs. which premiered on August 18, 2009, on ABC.[225] The show featured O'Neal competing against other athletes at their own sports.[226]
",3
2907,"On July 14, 2011, O'Neal announced that he would join Turner Network Television (TNT) as an analyst on its NBA basketball games, joining Ernie Johnson, Kenny Smith, and Charles Barkley.[227]
",3
2908,"He hosted the show Upload with Shaquille O'Neal which aired on TruTV for one season.
",3
2909,"In September 2015 whilst promoting sportswear giant Reebok in South Korea, O'Neal joined the cast in the South Korean variety television show Off to School where he went to Seo Incheon High School. The show features various celebrities attending a selected high school as students for three days.[228] The producer of the show, Kim No-eun said, ""We've worked hard on our guest list this season, so Chu Sung Hoon will be appearing on a cable channel for the first time. Shaquille O'Neal will be on the show as well. We succeeded in casting him after a lot of effort. O'Neal will be visiting Korea for a promotion and will be visiting the school on the last day. He will have lunch with the students. We're even preparing a big match between Chu Sung Hoon and Shaquille O'Neal. We're specially preparing a uniform for Shaquille O'Neal.""[229][230][231]
",3
2910,"O'Neal has made numerous appearances in television commercials, including several Pepsi commercials, such as one from 1995 which parodied shows like I Love Lucy (the ""Job Switching"" episode), Bonanza, and Woody Woodpecker; various 1990s Reebok commercials; Nestlé Crunch commercials; Gold Bond products; The General insurance commercials; and IcyHot commercials.
",3
2911,"O'Neal began training in mixed martial arts (MMA) in 2000. At Jonathan Burke's Gracie Gym, he trained in boxing, jiu-jitsu, Muay Thai and wrestling. At the gym, he used the nickname Diesel.[232] O'Neal challenged kickboxer and mixed martial artist Choi Hong-man to a mixed martial arts rules bout in a YouTube video posted on June 17, 2009. Choi replied to an email asking him if he would like to fight O'Neal saying ""Yes, if there is a chance."" Hong-man also responded to a question asking if O'Neal had a chance of winning with a simple ""No.""[233] On August 28, 2010, at UFC 118 in Boston, O'Neal reiterated his desire to fight Choi in an interview.[234]
",3
2912,"A lifelong professional wrestling fan, O'Neal has made numerous appearances at televised events over the years for four different promotions.[235][236] His favorite wrestlers are Tony Atlas, Junkyard Dog, André the Giant, and Brock Lesnar.[237]
",3
2913,"In 1994, O'Neal made several appearances in World Championship Wrestling (WCW), including at the Bash at the Beach pay per view, where he presented the title belt to the winner of the WCW World Heavyweight Championship match between Hulk Hogan and Ric Flair.[238] In July 2009, O'Neal served as the guest host for a live broadcast of WWE's Monday Night Raw. As part of the show, O'Neal got into a physical altercation with seven-foot tall wrestler Big Show.[239] In September 2012, O'Neal made a guest appearance on Total Nonstop Action Wrestling's Impact Wrestling program, where he had a backstage segment with Hulk Hogan.[240]
",3
2914,"In April 2016, O'Neal participated in his first-ever match, when he was a surprise celebrity entry in the André the Giant Memorial Battle Royal at WrestleMania 32.[241] O'Neal eliminated Damien Sandow, and had another confrontation with Big Show before being eliminated himself by most of the other wrestlers.[242] In July at the 2016 ESPY Awards on the red carpet, Big Show and O'Neal had another brief confrontation.[243] A match was proposed for WrestleMania 33, which O'Neal accepted.[244][245] In January 2017, the two began calling each other out on social media, posting workout videos of themselves preparing for the potential match.[246][247] After weeks of discussion, the match was cancelled. According to Dave Meltzer of Wrestling Observer Newsletter, the match was canceled due to monetary reasons, as both parties could not agree on a deal.[248] Big Show later stated it was scheduling issues on O'Neal's part that caused the cancellation.[249]
",3
2915,"On the November 11, 2020 episode of AEW Dynamite, Jade Cargill interrupted Cody Rhodes and teased the arrival of O'Neal in All Elite Wrestling (AEW).[250][251] He made a cameo appearance on Being The Elite and it was later confirmed that O'Neal had been appearing backstage at recent AEW tapings, including Full Gear.[252][253][254] He appeared on the December 9 episode of AEW Dynamite and addressed AEW in a sit-down interview with Tony Schiavone and Brandi Rhodes.[255] At the end of the interview, O'Neal got water thrown on him by Brandi after telling her to get pointers from Cargill, who had broken Brandi's arm several weeks ago.[256][257] On the March 3, 2021 episode of AEW Dynamite titled The Crossroads, O'Neal teamed with Jade Cargill to defeat Cody Rhodes and Red Velvet.[258] During the match, O'Neal paid tribute to Brodie Lee with his signature gesture and powerbomb and went through two tables by Cody.[259][260]
",3
2916,"O'Neal is also an active businessman and investor. He was an active bond investor in the early 1990s but continued to wade into stocks and made investments in various companies such as General Electric, Apple, and PepsiCo. He described what has worked best for him in stock investing was where he felt a personal connection with the company.[261] He has also been an active real estate entrepreneur. O'Neal was looking to expand his business ventures with real-estate development projects aimed at assisting Orlando home owners facing foreclosure. His plans involved buying the mortgages of those who had fallen into foreclosure and then selling the homes back to them under more affordable terms. He would make a small profit in return, but wanted to make an investment in Orlando and help out homeowners.[262]
",3
2917,"In conjunction with Boraie Development, O'Neal has developed projects in his hometown of Newark, New Jersey including, CityPlex12 and One Riverview.[263][264][265][266][267]
",3
2918,"O'Neal is on the advisory board for Tout Industries, a social video service startup company based in San Francisco.[124] He received the position in return for breaking news of his NBA retirement on the service.[268]
",3
2919,"In September 2013, O'Neal became a minority owner of the Sacramento Kings.[269]
",3
2920,"In June 2015, O'Neal invested in technology startup Loyale3 Holdings Inc., a San Francisco brokerage firm whose website and mobile app enables companies to sell a piece of their IPOs directly to small investors who put up as a little as $100 and also allows investors to regularly buy small amounts of shares in already public companies.[261]
",3
2921,"O'Neal is an investor for eSports team NRG Esports.[270] He has also appeared in television commercials promoting the Counter-Strike: Global Offensive league ELeague.[271]
",3
2922,"In late 2016 O'Neal purchased the Krispy Kreme location at 295 Ponce de Leon Avenue in Atlanta. O'Neal is also the global spokesperson for the company.[272]
",3
2923,"In early 2019 O'Neal joined the Papa John's board of directors and invested in nine stores in the Atlanta area. In addition, he became the spokesperson for the company as part of the three-year contract.[273]
",3
2924,"O'Neal was raised by a Baptist mother and a Muslim stepfather.[274] Both Robin Wright in her book Rock the Casbah as well as the Los Angeles Times have identified O'Neal as a Muslim.[275][276][277] However, O'Neal has said, ""I'm Muslim, I'm Jewish, I'm Buddhist, I'm everybody 'cause I'm a people person.""[278]
",3
2925,"O'Neal married Shaunie Nelson on December 26, 2002. The couple have four children: Shareef, Amirah, Shaqir, and Me'arah. Nelson also has one son from a previous relationship, Myles. On September 4, 2007, O'Neal filed for divorce from Shaunie in a Miami-Dade Circuit court. Shaunie later said that the couple had gotten back together and that the divorce was withdrawn. However, on November 10, 2009, Shaunie filed an intent to divorce, citing irreconcilable differences.[279]
",3
2926,"In 2015, Shareef was seen in high school basketball highlights as a 6-foot-7-inch (2.01 m) freshman power forward, and had been described to have ""polar opposite playing style to his father"" due to his more athletic build and better shooting range.[280][281] Shareef, later rated as a top-30 prospect in the recruiting class of 2018, had committed to play college basketball at the University of Arizona, but rescinded the commitment in February 2018 after Arizona head coach Sean Miller was linked to potential major violations of NCAA recruiting rules.[282]
",3
2927,"O'Neal has a daughter from a previous relationship with his ex-girlfriend Arnetta Yardbourgh, Taahirah O'Neal.[283]
",3
2928,"In summer 2010, O'Neal began dating reality TV star Nicole ""Hoopz"" Alexander.[284][285] The couple resided at O'Neal's home in Sudbury, Massachusetts[286] and later split in 2012.[287]
",3
2929,"Since 2014, O'Neal has been dating Laticia Rolle, a model, originally from Gardner, Massachusetts.[288]
",3
2930,"In June 2005 when Hall of Fame center George Mikan died, O'Neal, who considered Mikan to be a major influence, extended an offer to his family to pay all of the funeral expenses, which they accepted.[289]
",3
2931,"O'Neal is a member of Omega Psi Phi fraternity.
",3
2932,"O'Neal is a 2009 inductee of the New Jersey Hall of Fame.[290] O'Neal became a Freemason in 2011, becoming a member of Widow's Son Lodge No. 28 in Boston.[291] O'Neal is a Prince Hall Freemason.[292][293][294]
",3
2933,"On January 31, 2012, O'Neal was honored as one of the 35 Greatest McDonald's All-Americans.[295]
",3
2934,"O'Neal is a fan of the National Hockey League's New Jersey Devils, who play in his hometown of Newark, and has been seen at several games over the years.[296] On January 11, 2014, O'Neal performed the ceremonial first puck and drove a Zamboni for a game between the Devils and the Florida Panthers.[297] O'Neal is also a fan of English football club Northampton Town, and has posted videos of support to their official YouTube page.[298]
",3
2935,"O'Neal endorsed Republican New Jersey governor Chris Christie in his 2013 reelection bid, appearing in a television advertisement.[299]
",3
2936,"
",3
2937,"
",3
2938,"
",3
2939,"Football is a family of team sports that involve, to varying degrees, kicking a ball to score a goal.  Unqualified, the word football normally means the form of football that is the most popular where the word is used. Sports commonly called football include association football (known as soccer in some countries); gridiron football (specifically American football or Canadian football); Australian rules football; rugby football (either rugby union or rugby league); and Gaelic football.[1][2] These various forms of football share to varying extent common origins and are known as football codes.
",3
2940,"There are a number of references to traditional, ancient, or prehistoric ball games played in many different parts of the world.[3][4][5] Contemporary codes of football can be traced back to the codification of these games at English public schools during the 19th century.[6][7] The expansion and cultural influence of the British Empire allowed these rules of football to spread to areas of British influence outside the directly controlled Empire.[8]  By the end of the 19th century, distinct regional codes were already developing: Gaelic football, for example, deliberately incorporated the rules of local traditional football games in order to maintain their heritage.[9]  In 1888, The Football League was founded in England, becoming the first of many professional football competitions. During the 20th century, several of the various kinds of football grew to become some of the most popular team sports in the world.[10]
",3
2941,"The various codes of football share certain common elements and can be grouped into two main classes of football: carrying codes like American football, Canadian football, Australian football, rugby union and rugby league, where the ball is moved about the field while being held in the hands or thrown, and kicking codes such as Association football and Gaelic football, where the ball is moved primarily with the feet, and where handling is strictly limited.[11]
",3
2942,"Common rules among the sports include:[12]
",3
2943,"In all codes, common skills include passing, tackling, evasion of tackles, catching and kicking.[11] In most codes, there are rules restricting the movement of players offside, and players scoring a goal must put the ball either under or over a crossbar between the goalposts.
",3
2944,"There are conflicting explanations of the origin of the word ""football"".  It is widely assumed that the word ""football"" (or the phrase ""foot ball"") refers to the action of the foot kicking a ball.[13]  There is an alternative explanation, which is that football originally referred to a variety of games in medieval Europe, which were played on foot. There is no conclusive evidence for either explanation.
",3
2945,"The Chinese competitive game cuju (蹴鞠), as stated by FIFA, is the earliest form of football for which there is scientific evidence and appears in a military manual dated to the second and third centuries BC.[14]  It existed during the Han dynasty and possibly the Qin dynasty, in the second and third centuries BC.[15]  The Japanese version of cuju is kemari (蹴鞠), and was developed during the Asuka period.[16] This is known to have been played within the Japanese imperial court in Kyoto from about 600 AD. In kemari several people stand in a circle and kick a ball to each other, trying not to let the ball drop to the ground (much like keepie uppie).
",3
2946,"The Ancient Greeks and Romans are known to have played many ball games, some of which involved the use of the feet. The Roman game harpastum is believed to have been adapted from a Greek team game known as ""ἐπίσκυρος"" (Episkyros)[17][18] or ""φαινίνδα"" (phaininda),[19] which is mentioned by a Greek playwright, Antiphanes (388–311 BC) and later referred to by the Christian theologian Clement of Alexandria (c. 150 – c. 215 AD). These games appear to have resembled rugby football.[20][21][22][23][24] The Roman politician Cicero (106–43 BC) describes the case of a man who was killed whilst having a shave when a ball was kicked into a barber's shop. Roman ball games already knew the air-filled ball, the follis.[25][26] Episkyros is recognised as an early form of football by FIFA.[27]
",3
2947,"There are a number of references to traditional, ancient, or prehistoric ball games, played by indigenous peoples in many different parts of the world. For example, in 1586, men from a ship commanded by an English explorer named John Davis, went ashore to play a form of football with Inuit (Eskimo) people in Greenland.[28] There are later accounts of an Inuit game played on ice, called Aqsaqtuk. Each match began with two teams facing each other in parallel lines, before attempting to kick the ball through each other team's line and then at a goal. In 1610, William Strachey, a colonist at Jamestown, Virginia recorded a game played by Native Americans, called Pahsaheman.[citation needed] Pasuckuakohowog, a game similar to modern-day association football played amongst Amerindians, was also reported as early as the 17th century.
",3
2948,"Games played in Mesoamerica with rubber balls by indigenous peoples are also well-documented as existing since before this time, but these had more similarities to basketball or volleyball, and no links have been found between such games and modern football sports. Northeastern American Indians, especially the Iroquois Confederation, played a game which made use of net racquets to throw and catch a small ball; however, although it is a ball-goal foot game, lacrosse (as its modern descendant is called) is likewise not usually classed as a form of ""football.""[citation needed]
",3
2949,"On the Australian continent several tribes of indigenous people played kicking and catching games with stuffed balls which have been generalised by historians as Marn Grook (Djab Wurrung for ""game ball""). The earliest historical account is an anecdote from the 1878 book by Robert Brough-Smyth, The Aborigines of Victoria, in which a man called Richard Thomas is quoted as saying, in about 1841 in Victoria, Australia, that he had witnessed Aboriginal people playing the game: ""Mr Thomas describes how the foremost player will drop kick a ball made from the skin of a possum and how other players leap into the air in order to catch it."" Some historians have theorised that Marn Grook was one of the origins of Australian rules football.
",3
2950,"The Māori in New Zealand played a game called Ki-o-rahi consisting of teams of seven players play on a circular field divided into zones, and score points by touching the 'pou' (boundary markers) and hitting a central 'tupu' or target.[citation needed]
",3
2951,"These games and others may well go far back into antiquity. However, the main sources of modern football codes appear to lie in western Europe, especially England.
",3
2952,"Mahmud al-Kashgari in his Dīwān Lughāt al-Turk, described a game called ""tepuk"" among Turks in Central Asia. In the game, people try to attack each other's castle by kicking a ball made of sheep leather.[29]
",3
2953,"Ancient Greek athlete balancing a ball on his thigh, Piraeus, 400-375 BC
",3
2954,"A Song dynasty painting by Su Hanchen (c. 1130-1160), depicting Chinese children playing cuju
",3
2955,"Paint of a Mesoamerican ballgame player of the Tepantitla murals in Teotihuacan
",3
2956,"A group of indigenous people playing a ball game in French Guiana
",3
2957,"An illustration from the 1850s of indigenous Australians playing marn grook
",3
2958,"A revived version of kemari being played at the Tanzan Shrine, Japan, 2006
",3
2959,"The Middle Ages saw a huge rise in popularity of annual Shrovetide football matches throughout Europe, particularly in England. An early reference to a ball game played in Britain comes from the 9th century Historia Brittonum, which describes ""a party of boys ... playing at ball"".[30] References to a ball game played in northern France known as La Soule or Choule, in which the ball was propelled by hands, feet, and sticks,[31] date from the 12th century.[32]
",3
2960,"The early forms of football played in England, sometimes referred to as ""mob football"", would be played in towns or between neighbouring villages, involving an unlimited number of players on opposing teams who would clash en masse,[33] struggling to move an item, such as inflated animal's bladder[34] to particular geographical points, such as their opponents' church, with play taking place in the open space between neighbouring parishes.[35] The game was played primarily during significant religious festivals, such as Shrovetide, Christmas, or Easter,[34] and Shrovetide games have survived into the modern era in a number of English towns (see below).
",3
2961,"The first detailed description of what was almost certainly football in England was given by William FitzStephen in about 1174–1183. He described the activities of London youths during the annual festival of Shrove Tuesday:
",3
2962,"After lunch all the youth of the city go out into the fields to take part in a ball game. The students of each school have their own ball; the workers from each city craft are also carrying their balls. Older citizens, fathers, and wealthy citizens come on horseback to watch their juniors competing, and to relive their own youth vicariously: you can see their inner passions aroused as they watch the action and get caught up in the fun being had by the carefree adolescents.[36]",3
2963,"Most of the very early references to the game speak simply of ""ball play"" or ""playing at ball"". This reinforces the idea that the games played at the time did not necessarily involve a ball being kicked.
",3
2964,"An early reference to a ball game that was probably football comes from 1280 at Ulgham, Northumberland, England:  ""Henry... while playing at ball.. ran against David"".[37]  Football was played in Ireland in 1308, with a documented reference to John McCrocan, a spectator at a ""football game"" at Newcastle, County Down being charged with accidentally stabbing a player named William Bernard.[38]  Another reference to a football game comes in 1321 at Shouldham, Norfolk, England: ""[d]uring the game at ball as he kicked the ball, a lay friend of his... ran against him and wounded himself"".[37]
",3
2965,"In 1314, Nicholas de Farndone, Lord Mayor of the City of London issued a decree banning football in the French used by the English upper classes at the time. A translation reads: ""[f]orasmuch as there is great noise in the city caused by hustling over large foot balls [rageries de grosses pelotes de pee][39] in the fields of the public from which many evils might arise which God forbid: we command and forbid on behalf of the king, on pain of imprisonment, such game to be used in the city in the future."" This is the earliest reference to football.
",3
2966,"In 1363, King Edward III of England issued a proclamation banning ""...handball, football, or hockey; coursing and cock-fighting, or other such idle games"",[40] showing that ""football"" – whatever its exact form in this case – was being differentiated from games involving other parts of the body, such as handball.
",3
2967,"A game known as ""football"" was played in Scotland as early as the 15th century: it was prohibited by the Football Act 1424 and although the law fell into disuse it was not repealed until 1906. There is evidence for schoolboys playing a ""football"" ball game in Aberdeen in 1633 (some references cite 1636) which is notable as an early allusion to what some have considered to be passing the ball. The word ""pass"" in the most recent translation is derived from ""huc percute"" (strike it here) and later ""repercute pilam"" (strike the ball again) in the original Latin. It is not certain that the ball was being struck between members of the same team. The original word translated as ""goal"" is ""metum"", literally meaning the ""pillar at each end of the circus course"" in a Roman chariot race. There is a reference to ""get hold of the ball before [another player] does"" (Praeripe illi pilam si possis agere) suggesting that handling of the ball was allowed. One sentence states in the original 1930 translation ""Throw yourself against him"" (Age, objice te illi).
",3
2968,"King Henry IV of England also presented one of the earliest documented uses of the English word ""football"", in 1409, when he issued a proclamation forbidding the levying of money for ""foteball"".[37][41]
",3
2969,"There is also an account in Latin from the end of the 15th century of football being played at Caunton, Nottinghamshire. This is the first description of a ""kicking game"" and the first description of dribbling: ""[t]he game at which they had met for common recreation is called by some the foot-ball game. It is one in which young men, in country sport, propel a huge ball not by throwing it into the air but by striking it and rolling it along the ground, and that not with their hands but with their feet... kicking in opposite directions"" The chronicler gives the earliest reference to a football pitch, stating that: ""[t]he boundaries have been marked and the game had started.[37]
",3
2970,"Other firsts in the medieval and early modern eras:
",3
2971,"In the 16th century, the city of Florence celebrated the period between Epiphany and Lent by playing a game which today is known as ""calcio storico"" (""historic kickball"") in the Piazza Santa Croce.[45] The young aristocrats of the city would dress up in fine silk costumes and embroil themselves in a violent form of football. For example, calcio players could punch, shoulder charge, and kick opponents. Blows below the belt were allowed. The game is said to have originated as a military training exercise. In 1580, Count Giovanni de' Bardi di Vernio wrote Discorso sopra 'l giuoco del Calcio Fiorentino. This is sometimes said to be the earliest code of rules for any football game. The game was not played after January 1739 (until it was revived in May 1930).
",3
2972,"There have been many attempts to ban football, from the middle ages through to the modern day. The first such law was passed in England in 1314; it was followed by more than 30 in England alone between 1314 and 1667.[46]:6 Women were banned from playing at English and Scottish Football League grounds in 1921, a ban that was only lifted in the 1970s. Female footballers still face similar problems in some parts of the world.
",3
2973,"While football continued to be played in various forms throughout Britain, its public schools (equivalent to private schools in other countries) are widely credited with four key achievements in the creation of modern football codes. First of all, the evidence suggests that they were important in taking football away from its ""mob"" form and turning it into an organised team sport. Second, many early descriptions of football and references to it were recorded by people who had studied at these schools. Third, it was teachers, students, and former students from these schools who first codified football games, to enable matches to be played between schools. Finally, it was at English public schools that the division between ""kicking"" and ""running"" (or ""carrying"") games first became clear.
",3
2974,"The earliest evidence that games resembling football were being played at English public schools – mainly attended by boys from the upper, upper-middle and professional classes – comes from the Vulgaria by William Herman in 1519. Herman had been headmaster at Eton and Winchester colleges and his Latin textbook includes a translation exercise with the phrase ""We wyll playe with a ball full of wynde"".[47]
",3
2975,"Richard Mulcaster, a student at Eton College in the early 16th century and later headmaster at other English schools, has been described as ""the greatest sixteenth Century advocate of football"".[48] Among his contributions are the earliest evidence of organised team football. Mulcaster's writings refer to teams (""sides"" and ""parties""), positions (""standings""), a referee (""judge over the parties"") and a coach ""(trayning maister)"". Mulcaster's ""footeball"" had evolved from the disordered and violent forms of traditional football:
",3
2976,"[s]ome smaller number with such overlooking, sorted into sides and standings, not meeting with their bodies so boisterously to trie their strength: nor shouldring or shuffing one an other so barbarously ... may use footeball for as much good to the body, by the chiefe use of the legges.[49]",3
2977,"In 1633, David Wedderburn, a teacher from Aberdeen, mentioned elements of modern football games in a short Latin textbook called Vocabula. Wedderburn refers to what has been translated into modern English as ""keeping goal"" and makes an allusion to passing the ball (""strike it here""). There is a reference to ""get hold of the ball"", suggesting that some handling was allowed. It is clear that the tackles allowed included the charging and holding of opposing players (""drive that man back"").[50]
",3
2978,"A more detailed description of football is given in Francis Willughby's Book of Games, written in about 1660.[51] Willughby, who had studied at Bishop Vesey's Grammar School, Sutton Coldfield, is the first to describe goals and a distinct playing field: ""a close that has a gate at either end. The gates are called Goals."" His book includes a diagram illustrating a football field. He also mentions tactics (""leaving some of their best players to guard the goal""); scoring (""they that can strike the ball through their opponents' goal first win"") and the way teams were selected (""the players being equally divided according to their strength and nimbleness""). He is the first to describe a ""law"" of football: ""they must not strike [an opponent's leg] higher than the ball"".[52][53]
",3
2979,"English public schools were the first to codify football games. In particular, they devised the first offside rules, during the late 18th century.[54] In the earliest manifestations of these rules, players were ""off their side"" if they simply stood between the ball and the goal which was their objective. Players were not allowed to pass the ball forward, either by foot or by hand. They could only dribble with their feet, or advance the ball in a scrum or similar formation. However, offside laws began to diverge and develop differently at each school, as is shown by the rules of football from Winchester, Rugby, Harrow and Cheltenham, during between 1810 and 1850.[54] The first known codes – in the sense of a set of rules – were those of Eton in 1815[55] and Aldenham in 1825.[55])
",3
2980,"During the early 19th century, most working class people in Britain had to work six days a week, often for over twelve hours a day. They had neither the time nor the inclination to engage in sport for recreation and, at the time, many children were part of the labour force. Feast day football played on the streets was in decline. Public school boys, who enjoyed some freedom from work, became the inventors of organised football games with formal codes of rules.
",3
2981,"Football was adopted by a number of public schools as a way of encouraging competitiveness and keeping youths fit. Each school drafted its own rules, which varied widely between different schools and were changed over time with each new intake of pupils. Two schools of thought developed regarding rules. Some schools favoured a game in which the ball could be carried (as at Rugby, Marlborough and Cheltenham), while others preferred a game where kicking and dribbling the ball was promoted (as at Eton, Harrow, Westminster and Charterhouse). The division into these two camps was partly the result of circumstances in which the games were played. For example, Charterhouse and Westminster at the time had restricted playing areas; the boys were confined to playing their ball game within the school cloisters, making it difficult for them to adopt rough and tumble running games.[citation needed]
",3
2982,"William Webb Ellis, a pupil at Rugby School, is said to have ""with a fine disregard for the rules of football, as played in his time [emphasis added], first took the ball in his arms and ran with it, thus creating the distinctive feature of the rugby game."" in 1823. This act is usually said to be the beginning of Rugby football, but there is little evidence that it occurred, and most sports historians believe the story to be apocryphal. The act of 'taking the ball in his arms' is often misinterpreted as 'picking the ball up' as it is widely believed that Webb Ellis' 'crime' was handling the ball, as in modern association football, however handling the ball at the time was often permitted and in some cases compulsory,[56] the rule for which Webb Ellis showed disregard was running forward with it as the rules of his time only allowed a player to retreat backwards or kick forwards.
",3
2983,"The boom in rail transport in Britain during the 1840s meant that people were able to travel further and with less inconvenience than they ever had before. Inter-school sporting competitions became possible. However, it was difficult for schools to play each other at football, as each school played by its own rules. The solution to this problem was usually that the match be divided into two halves, one half played by the rules of the host ""home"" school, and the other half by the visiting ""away"" school.
",3
2984,"The modern rules of many football codes were formulated during the mid- or late- 19th century. This also applies to other sports such as lawn bowls, lawn tennis, etc. The major impetus for this was the patenting of the world's first lawnmower in 1830. This allowed for the preparation of modern ovals, playing fields, pitches, grass courts, etc.[57]
",3
2985,"Apart from Rugby football, the public school codes have barely been played beyond the confines of each school's playing fields. However, many of them are still played at the schools which created them (see Surviving UK school games below).
",3
2986,"Public schools' dominance of sports in the UK began to wane after the Factory Act of 1850, which significantly increased the recreation time available to working class children. Before 1850, many British children had to work six days a week, for more than twelve hours a day. From 1850, they could not work before 6 a.m. (7 a.m. in winter) or after 6 p.m. on weekdays (7 p.m. in winter); on Saturdays they had to cease work at 2 p.m. These changes meant that working class children had more time for games, including various forms of football.
",3
2987,"The earliest known matches between public schools are as follows:
",3
2988,"Sports clubs dedicated to playing football began in the 18th century, for example London's Gymnastic Society which was founded in the mid-18th century and ceased playing matches in 1796.[61][59]
",3
2989,"The first documented club to bear in the title a reference to being a 'football club' were called ""The Foot-Ball Club"" who were located in Edinburgh, Scotland, during the period 1824–41.[62][63]  The club forbade tripping but allowed pushing and holding and the picking up of the ball.[63]
",3
2990,"In 1845, three boys at Rugby school were tasked with codifying the rules then being used at the school. These were the first set of written rules (or code) for any form of football.[64] This further assisted the spread of the Rugby game.
",3
2991,"The earliest known matches involving non-public school clubs or institutions are as follows:
",3
2992,"One of the longest running football fixture is the Cordner-Eggleston Cup, contested between Melbourne Grammar School and Scotch College, Melbourne every year since 1858. It is believed by many to also be the first match of Australian rules football, although it was played under experimental rules in its first year. The first football trophy tournament was the Caledonian Challenge Cup, donated by the Royal Caledonian Society of Melbourne, played in 1861 under the Melbourne Rules.[76]  The oldest football league is a rugby football competition, the United Hospitals Challenge Cup (1874), while the oldest rugby trophy is the Yorkshire Cup, contested since 1878. The South Australian Football Association (30 April 1877) is the oldest surviving Australian rules football competition. The oldest surviving soccer trophy is the Youdan Cup (1867) and the oldest national football competition is the English FA Cup (1871). The Football League (1888) is recognised as the longest running Association Football league. The first ever international football match took place between sides representing England and Scotland on 5 March 1870 at the Oval under the authority of the FA. The first Rugby international took place in 1871.
",3
2993,"In Europe, early footballs were made out of animal bladders, more specifically pig's bladders, which were inflated. Later leather coverings were introduced to allow the balls to keep their shape.[77] However, in 1851, Richard Lindon and William Gilbert, both shoemakers from the town of Rugby (near the school), exhibited both round and oval-shaped balls at the Great Exhibition in London. Richard Lindon's wife is said to have died of lung disease caused by blowing up pig's bladders.[78] Lindon also won medals for the invention of the ""Rubber inflatable Bladder"" and the ""Brass Hand Pump"".
",3
2994,"In 1855, the U.S. inventor Charles Goodyear – who had patented vulcanised rubber – exhibited a spherical football, with an exterior of vulcanised rubber panels, at the Paris Exhibition Universelle. The ball was to prove popular in early forms of football in the U.S.[79]
",3
2995,"The iconic ball with a regular pattern of hexagons and pentagons (see truncated icosahedron) did not become popular until the 1960s, and was first used in the World Cup in 1970.
",3
2996,"The earliest reference to a game of football involving players passing the ball and attempting to score past a goalkeeper was written in 1633 by David Wedderburn, a poet and teacher in Aberdeen, Scotland.[80]  Nevertheless, the original text does not state whether the allusion to passing as 'kick the ball back' ('Repercute pilam') was in a forward or backward direction or between members of the same opposing teams (as was usual at this time)[81]
",3
2997,"""Scientific"" football is first recorded in 1839 from Lancashire[82] and in the modern game in Rugby football from 1862[83] and from Sheffield FC as early as 1865.[84][85]  The first side to play a passing combination game was the Royal Engineers AFC in 1869/70[86][87] By 1869 they were ""work[ing] well together"", ""backing up"" and benefiting from ""cooperation"".[88] By 1870 the Engineers were passing the ball: ""Lieut. Creswell, who having brought the ball up the side then kicked it into the middle to another of his side, who kicked it through the posts the minute before time was called"".[89] Passing was a regular feature of their style.[90] By early 1872 the Engineers were the first football team renowned for ""play[ing] beautifully together"".[91] A double pass is first reported from Derby school against Nottingham Forest in March 1872, the first of which is irrefutably a short pass: ""Mr Absey dribbling the ball half the length of the field delivered it to Wallis, who kicking it cleverly in front of the goal, sent it to the captain who drove it at once between the Nottingham posts"".[92] The first side to have perfected the modern formation was Cambridge University AFC[93][94][95] and introduced the 2–3–5 ""pyramid"" formation.[96][97]
",3
2998,"During the nineteenth century, several codifications of the rules of football were made at the University of Cambridge, in order to enable students from different public schools to play each other.  The Cambridge Rules of 1863 influenced the decision of Football Association to ban Rugby-style carrying of the ball in its own first set of laws.[98]
",3
2999,"By the late 1850s, many football clubs had been formed throughout the English-speaking world, to play various codes of football. Sheffield Football Club, founded in 1857 in the English city of Sheffield by Nathaniel Creswick and William Prest, was later recognised as the world's oldest club playing association football.[99]
However, the club initially played its own code of football: the Sheffield rules. The code was largely independent of the public school rules, the most significant difference being the lack of an offside rule.
",3
3000,"The code was responsible for many innovations that later spread to association football. These included free kicks, corner kicks, handball, throw-ins and the crossbar.[100] By the 1870s they became the dominant code in the north and midlands of England. At this time a series of rule changes by both the London and Sheffield FAs gradually eroded the differences between the two games until the adoption of a common code in 1877.
",3
3001,"There is archival evidence of ""foot-ball"" games being played in various parts of Australia throughout the first half of the 19th century. The origins of an organised game of football known today as Australian rules football can be traced back to 1858 in Melbourne, the capital city of Victoria.
",3
3002,"In July 1858, Tom Wills, an Australian-born cricketer educated at Rugby School in England, wrote a letter to Bell's Life in Victoria & Sporting Chronicle, calling for a ""foot-ball club"" with a ""code of laws"" to keep cricketers fit during winter.[101] This is considered by historians to be a defining moment in the creation of Australian rules football. Through publicity and personal contacts Wills was able to co-ordinate football matches in Melbourne that experimented with various rules,[102] the first of which was played on 31 July 1858. One week later, Wills umpired a schoolboys match between Melbourne Grammar School and Scotch College. Following these matches, organised football in Melbourne rapidly increased in popularity.
",3
3003,"Wills and others involved in these early matches formed the Melbourne Football Club (the oldest surviving Australian football club) on 14 May 1859. Club members Wills, William Hammersley, J. B. Thompson and Thomas H. Smith met with the intention of forming a set of rules that would be widely adopted by other clubs. The committee debated rules used in English public school games; Wills pushed for various rugby football rules he learnt during his schooling. The first rules share similarities with these games, and were shaped to suit to Australian conditions. H. C. A. Harrison, a seminal figure in Australian football, recalled that his cousin Wills wanted ""a game of our own"".[103] The code was distinctive in the prevalence of the mark, free kick, tackling, lack of an offside rule and that players were specifically penalised for throwing the ball.
",3
3004,"The Melbourne football rules were widely distributed and gradually adopted by the other Victorian clubs. The rules were updated several times during the 1860s to accommodate the rules of other influential Victorian football clubs. A significant redraft in 1866 by H. C. A. Harrison's committee accommodated the Geelong Football Club's rules, making the game then known as ""Victorian Rules"" increasingly distinct from other codes. It soon adopted cricket fields and an oval ball, used specialised goal and behind posts, and featured bouncing the ball while running and spectacular high marking. The game spread quickly to other Australian colonies. Outside its heartland in southern Australia, the code experienced a significant period of decline following World War I but has since grown throughout Australia and in other parts of the world, and the Australian Football League emerged as the dominant professional competition.
",3
3005,"During the early 1860s, there were increasing attempts in England to unify and reconcile the various public school games. In 1862, J. C. Thring, who had been one of the driving forces behind the original Cambridge Rules, was a master at Uppingham School and he issued his own rules of what he called ""The Simplest Game"" (these are also known as the Uppingham Rules). In early October 1863 another new revised version of the Cambridge Rules was drawn up by a seven member committee representing former pupils from Harrow, Shrewsbury, Eton, Rugby, Marlborough and Westminster.
",3
3006,"At the Freemasons' Tavern, Great Queen Street, London on the evening of 26 October 1863, representatives of several football clubs in the London Metropolitan area met for the inaugural meeting of The Football Association (FA). The aim of the Association was to establish a single unifying code and regulate the playing of the game among its members. Following the first meeting, the public schools were invited to join the association. All of them declined, except Charterhouse and Uppingham. In total, six meetings of the FA were held between October and December 1863. After the third meeting, a draft set of rules were published. However, at the beginning of the fourth meeting, attention was drawn to the recently published Cambridge Rules of 1863. The Cambridge rules differed from the draft FA rules in two significant areas; namely running with (carrying) the ball and hacking (kicking opposing players in the shins). The two contentious FA rules were as follows:
",3
3007,"IX. A player shall be entitled to run with the ball towards his adversaries' goal if he makes a fair catch, or catches the ball on the first bound; but in case of a fair catch, if he makes his mark he shall not run.
X. If any player shall run with the ball towards his adversaries' goal, any player on the opposite side shall be at liberty to charge, hold, trip or hack him, or to wrest the ball from him, but no player shall be held and hacked at the same time.[104]",3
3008,"At the fifth meeting it was proposed that these two rules be removed. Most of the delegates supported this, but F. M. Campbell, the representative from Blackheath and the first FA treasurer, objected. He said: ""hacking is the true football"". However, the motion to ban running with the ball in hand and hacking was carried and Blackheath withdrew from the FA. After the final meeting on 8 December, the FA published the ""Laws of Football"", the first comprehensive set of rules for the game later known as Association Football. The term ""soccer"", in use since the late 19th century, derives from an Oxford University abbreviation of ""Association"".[105]
",3
3009,"The first FA rules still contained elements that are no longer part of association football, but which are still recognisable in other games (such as Australian football and rugby football): for instance, a player could make a fair catch and claim a mark, which entitled him to a free kick; and if a player touched the ball behind the opponents' goal line, his side was entitled to a free kick at goal, from 15 yards (13.5 metres) in front of the goal line.
",3
3010,"In Britain, by 1870, there were 49 clubs playing variations of the Rugby school game.[106] There were also ""rugby"" clubs in Ireland, Australia, Canada and New Zealand. However, there was no generally accepted set of rules for rugby until 1871, when 21 clubs from London came together to form the Rugby Football Union (RFU). The first official RFU rules were adopted in June 1871.[107] These rules allowed passing the ball. They also included the try, where touching the ball over the line allowed an attempt at goal, though drop-goals from marks and general play, and penalty conversions were still the main form of contest.
",3
3011,"Rugby football split into Rugby union, Rugby league, American football, and Canadian football. Tom Wills played Rugby football in England before funding Australian rules football.
",3
3012,"As was the case in Britain, by the early 19th century, North American schools and universities played their own local games, between sides made up of students. For example, students at Dartmouth College in New Hampshire played a game called Old division football, a variant of the association football codes, as early as the 1820s.[108] They remained largely ""mob football"" style games, with huge numbers of players attempting to advance the ball into a goal area, often by any means necessary. Rules were simple, violence and injury were common.[109] The violence of these mob-style games led to widespread protests and a decision to abandon them. Yale University, under pressure from the city of New Haven, banned the play of all forms of football in 1860, while Harvard University followed suit in 1861.[109] In its place, two general types of football evolved: ""kicking"" games and ""running"" (or ""carrying"") games. A hybrid of the two, known as the ""Boston game"", was played by a group known as the Oneida Football Club. The club, considered by some historians as the first formal football club in the United States, was formed in 1862 by schoolboys who played the ""Boston game"" on Boston Common.[109][110] The game began to return to American college campuses by the late 1860s. The universities of Yale, Princeton (then known as the College of New Jersey), Rutgers, and Brown all began playing ""kicking"" games during this time. In 1867, Princeton used rules based on those of the English Football Association.[109]
",3
3013,"In Canada, the first documented football match was a practice game played on 9 November 1861, at University College, University of Toronto (approximately 400 yards west of Queen's Park). One of the participants in the game involving University of Toronto students was (Sir) William Mulock, later Chancellor of the school.[112]  In 1864, at Trinity College, Toronto, F. Barlow Cumberland, Frederick A. Bethune, and Christopher Gwynn, one of the founders of Milton, Massachusetts, devised rules based on rugby football.[112] A ""running game"", resembling rugby football, was then taken up by the Montreal Football Club in Canada in 1868.[113]
",3
3014,"On 6 November 1869, Rutgers faced Princeton in a game that was played with a round ball and, like all early games, used improvised rules. It is usually regarded as the first game of American intercollegiate football.[109][114]
",3
3015,"Modern North American football grew out of a match between McGill University of Montreal and Harvard University in 1874. During the game, the two teams alternated between the rugby-based rules used by McGill and the Boston Game rules used by Harvard.[115][116][117] Within a few years, Harvard had both adopted McGill's rules and persuaded other U.S. university teams to do the same. On 23 November 1876, representatives from Harvard, Yale, Princeton, and Columbia met at the Massasoit Convention in Springfield, Massachusetts, agreeing to adopt most of the Rugby Football Union rules, with some variations.[118]
",3
3016,"In 1880, Yale coach Walter Camp, who had become a fixture at the Massasoit House conventions where the rules were debated and changed, devised a number of major innovations. Camp's two most important rule changes that diverged the American game from rugby were replacing the scrummage with the line of scrimmage and the establishment of the down-and-distance rules.[118] American football still however remained a violent sport where collisions often led to serious injuries and sometimes even death.[119] This led U.S. President Theodore Roosevelt to hold a meeting with football representatives from Harvard, Yale, and Princeton on 9 October 1905, urging them to make drastic changes.[120] One rule change introduced in 1906, devised to open up the game and reduce injury, was the introduction of the legal forward pass. Though it was underutilised for years, this proved to be one of the most important rule changes in the establishment of the modern game.[121]
",3
3017,"Over the years, Canada absorbed some of the developments in American football in an effort to distinguish it from a more rugby-oriented game. In 1903, the Ontario Rugby Football Union adopted the Burnside rules, which implemented the line of scrimmage and down-and-distance system from American football, among others.[122] Canadian football then implemented the legal forward pass in 1929.[123] American and Canadian football remain different codes, stemming from rule changes that the American side of the border adopted but the Canadian side has not.
",3
3018,"In the mid-19th century, various traditional football games, referred to collectively as caid, remained popular in Ireland, especially in County Kerry. One observer, Father W. Ferris, described two main forms of caid during this period: the ""field game"" in which the object was to put the ball through arch-like goals, formed from the boughs of two trees; and the epic ""cross-country game"" which took up most of the daylight hours of a Sunday on which it was played, and was won by one team taking the ball across a parish boundary. ""Wrestling"", ""holding"" opposing players, and carrying the ball were all allowed.
",3
3019,"By the 1870s, Rugby and Association football had started to become popular in Ireland. Trinity College Dublin was an early stronghold of Rugby (see the Developments in the 1850s section, above). The rules of the English FA were being distributed widely. Traditional forms of caid had begun to give way to a ""rough-and-tumble game"" which allowed tripping.
",3
3020,"There was no serious attempt to unify and codify Irish varieties of football, until the establishment of the Gaelic Athletic Association (GAA) in 1884. The GAA sought to promote traditional Irish sports, such as hurling and to reject imported games like Rugby and Association football. The first Gaelic football rules were drawn up by Maurice Davin and published in the United Ireland magazine on 7 February 1887.[124] Davin's rules showed the influence of games such as hurling and a desire to formalise a distinctly Irish code of football. The prime example of this differentiation was the lack of an offside rule (an attribute which, for many years, was shared only by other Irish games like hurling, and by Australian rules football).
",3
3021,"The International Rugby Football Board (IRFB) was founded in 1886,[125] but rifts were beginning to emerge in the code. Professionalism had already begun to creep into the various codes of football.
",3
3022,"In England, by the 1890s, a long-standing Rugby Football Union ban on professional players was causing regional tensions within rugby football, as many players in northern England were working class and could not afford to take time off to train, travel, play and recover from injuries. This was not very different from what had occurred ten years earlier in soccer in Northern England but the authorities reacted very differently in the RFU, attempting to alienate the working class support in Northern England. In 1895, following a dispute about a player being paid broken time payments, which replaced wages lost as a result of playing rugby, representatives of the northern clubs met in Huddersfield to form the Northern Rugby Football Union (NRFU). The new body initially permitted only various types of player wage replacements. However, within two years, NRFU players could be paid, but they were required to have a job outside sport.
",3
3023,"The demands of a professional league dictated that rugby had to become a better ""spectator"" sport. Within a few years the NRFU rules had started to diverge from the RFU, most notably with the abolition of the line-out. This was followed by the replacement of the ruck with the ""play-the-ball ruck"", which allowed a two-player ruck contest between the tackler at marker and the player tackled. Mauls were stopped once the ball carrier was held, being replaced by a play-the ball-ruck. The separate Lancashire and Yorkshire competitions of the NRFU merged in 1901, forming the Northern Rugby League, the first time the name rugby league was used officially in England.
",3
3024,"Over time, the RFU form of rugby, played by clubs which remained members of national federations affiliated to the IRFB, became known as rugby union.
",3
3025,"The need for a single body to oversee association football had become apparent by the beginning of the 20th century, with the increasing popularity of international fixtures. The English Football Association had chaired many discussions on setting up an international body, but was perceived as making no progress. It fell to associations from seven other European countries: France, Belgium, Denmark, Netherlands, Spain, Sweden, and Switzerland, to form an international association. The Fédération Internationale de Football Association (FIFA) was founded in Paris on 21 May 1904.[126] Its first president was Robert Guérin.[126] The French name and acronym has remained, even outside French-speaking countries.
",3
3026,"Rugby league rules diverged significantly from rugby union in 1906, with the reduction of the team from 15 to 13 players. In 1907, a New Zealand professional rugby team toured Australia and Britain, receiving an enthusiastic response, and professional rugby leagues were launched in Australia the following year. However, the rules of professional games varied from one country to another, and negotiations between various national bodies were required to fix the exact rules for each international match. This situation endured until 1948, when at the instigation of the French league, the Rugby League International Federation (RLIF) was formed at a meeting in Bordeaux.
",3
3027,"During the second half of the 20th century, the rules changed further. In 1966, rugby league officials borrowed the American football concept of downs: a team was allowed to retain possession of the ball for four tackles (rugby union retains the original rule that a player who is tackled and brought to the ground must release the ball immediately).  The maximum number of tackles was later increased to six (in 1971), and in rugby league this became known as the six tackle rule.
",3
3028,"With the advent of full-time professionals in the early 1990s, and the consequent speeding up of the game, the five metre off-side distance between the two teams became 10 metres, and the replacement rule was superseded by various interchange rules, among other changes.
",3
3029,"The laws of rugby union also changed during the 20th century, although less significantly than those of rugby league. In particular, goals from marks were abolished, kicks directly into touch from outside the 22 metre line were penalised, new laws were put in place to determine who had possession following an inconclusive ruck or maul, and the lifting of players in line-outs was legalised.
",3
3030,"In 1995, rugby union became an ""open"" game, that is one which allowed professional players.[127] Although the original dispute between the two codes has now disappeared – and despite the fact that officials from both forms of rugby football have sometimes mentioned the possibility of re-unification – the rules of both codes and their culture have diverged to such an extent that such an event is unlikely in the foreseeable future.
",3
3031,"The word football, when used in reference to a specific game can mean any one of those described above. Because of this, much friendly controversy has occurred over the term football, primarily because it is used in different ways in different parts of the English-speaking world. Most often, the word ""football"" is used to refer to the code of football that is considered dominant within a particular region (which is Association football in most countries). So, effectively, what the word ""football"" means usually depends on where one says it.
",3
3032,"In each of the United Kingdom, the United States, and Canada, one football code is known solely as ""football"", while the others generally require a qualifier. In New Zealand, ""football"" historically referred to rugby union, but more recently may be used unqualified to refer to association football. The sport meant by the word ""football"" in Australia is either Australian rules football or rugby league, depending on local popularity (which largely conforms to the Barassi Line). In francophone Quebec, where Canadian football is more popular, the Canadian code is known as le football while American football is known as le football américain and association football is known as le soccer.[128]
",3
3033,"Of the 45 national FIFA (Fédération Internationale de Football Association) affiliates in which English is an official or primary language, most currently use Football in their organisations' official names; the FIFA affiliates in Canada and the United States use Soccer in their names. A few FIFA affiliates have recently ""normalised"" to using ""Football"", including:
",3
3034,"Several of the football codes are the most popular team sports in the world.[10] Globally, association football is played by over 250 million players in over 200 nations,[133] and has the highest television audience in sport,[134] making it the most popular in the world.[135] American football, with 1.1 million high school football players and nearly 70,000 college football players, is the most popular sport in the United States,[136][137] with the annual Super Bowl game accounting for nine of the top ten of the most watched broadcasts in U.S. television history.[138] The NFL has the highest average attendance (67,591) of any professional sports league in the world and has the highest revenue[139] out of any single professional sports league.[140] Thus, the best association football and American football players are among the highest paid athletes in the world.[141][142][143]
",3
3035,"Australian rules football has the highest spectator attendance of all sports in Australia.[144][145] Similarly, Gaelic football is the most popular sport in Ireland in terms of match attendance,[146] and the All-Ireland Football Final is the most watched event of that nation's sporting year.[147]
",3
3036,"Rugby union is the most popular sport in New Zealand, Samoa, Tonga, and Fiji.[148] It is also the fastest growing sport in the U.S.[149][150][151][152] with college rugby being the fastest growing[clarification needed][153][154] college sport in that country.[155][dubious  – discuss]
",3
3037,"These codes have in common the prohibition of the use of hands (by all players except the goalkeeper, though outfield players can ""throw-in"" the ball when it goes out of play), unlike other codes where carrying or handling the ball by all players is allowed
",3
3038,"The hockey game bandy has rules partly based on the association football rules and is sometimes nicknamed as 'winter football'.
",3
3039,"There are also motorsport variations of the game.
",3
3040,"These codes have in common the ability of players to carry the ball with their hands, and to throw it to teammates, unlike association football where the use of hands during play is prohibited by anyone except the goal keeper.  They also feature various methods of scoring based upon whether the ball is carried into the goal area, or kicked above the goalposts.
",3
3041,"These codes have in common the absence of an offside rule, the prohibition of continuous carrying of the ball (requiring a periodic bounce or solo (toe-kick), depending on the code) while running, handpassing by punching or tapping the ball rather than throwing it, and other traditions.
",3
3042,"Games still played at UK public (independent) schools:
",3
3043,"Note: although similar to football and volleyball in some aspects, Sepak takraw has ancient origins and cannot be considered a hybrid game.
",3
3044,"
",3
3045,"
",3
3046,"Basketball is a team sport in which two teams, most commonly of five players each, opposing one another on a rectangular court, compete with the primary objective of shooting a basketball (approximately 9.4 inches (24 cm) in diameter) through the defender's hoop (a basket 18 inches (46 cm) in diameter mounted 10 feet (3.048 m) high to a backboard at each end of the court) while preventing the opposing team from shooting through their own hoop. A field goal is worth two points, unless made from behind the three-point line, when it is worth three. After a foul, timed play stops and the player fouled or designated to shoot a technical foul is given one, two or three one-point free throws. The team with the most points at the end of the game wins, but if regulation play expires with the score tied, an additional period of play (overtime) is mandated.
",3
3047,"Players advance the ball by bouncing it while walking or running (dribbling) or by passing it to a teammate, both of which require considerable skill. On offense, players may use a variety of shots—the lay-up, the jump shot, or a dunk; on defense, they may steal the ball from a dribbler, intercept passes, or block shots; either offense or defense may collect a rebound, that is, a missed shot that bounces from rim or backboard. It is a violation to lift or drag one's pivot foot without dribbling the ball, to carry it, or to hold the ball with both hands then resume dribbling.
",3
3048,"The five players on each side fall into five playing positions. The tallest player is usually the center, the second-tallest and strongest is the power forward, a slightly shorter but more agile player is the small forward, and the shortest players or the best ball handlers are the shooting guard and the point guard, who implements the coach's game plan by managing the execution of offensive and defensive plays (player positioning). Informally, players may play three-on-three, two-on-two, and one-on-one.
",3
3049,"Invented in 1891 by Canadian-American gym teacher James Naismith in Springfield, Massachusetts, United States, basketball has evolved to become one of the world's most popular and widely viewed sports.[1] The National Basketball Association (NBA) is the most significant professional basketball league in the world in terms of popularity, salaries, talent, and level of competition.[2][3] Outside North America, the top clubs from national leagues qualify to continental championships such as the EuroLeague and the Basketball Champions League Americas. The FIBA Basketball World Cup and Men's Olympic Basketball Tournament are the major international events of the sport and attract top national teams from around the world. Each continent hosts regional competitions for national teams, like EuroBasket and FIBA AmeriCup.
",3
3050,"The FIBA Women's Basketball World Cup and Women's Olympic Basketball Tournament feature top national teams from continental championships. The main North American league is the WNBA (NCAA Women's Division I Basketball Championship is also popular), whereas the strongest European clubs participate in the EuroLeague Women.
",3
3051,"In December 1891, James Naismith, a Canadian professor of physical education and instructor at the International Young Men's Christian Association Training School (now Springfield College) in Springfield, Massachusetts,[4] was trying to keep his gym class active on a rainy day.[5] He sought a vigorous indoor game to keep his students occupied and at proper levels of fitness during the long New England winters. After rejecting other ideas as either too rough or poorly suited to walled-in gymnasiums, he invented a new game in which players would pass a ball to teammates and try to score points by tossing the ball into a basket mounted on a wall. Naismith wrote the basic rules and nailed a peach basket onto an elevated track. Naismith initially set up the peach basket with its bottom intact, which meant that the ball had to be retrieved manually after each ""basket"" or point scored. This quickly proved tedious, so Naismith removed the bottom of the basket to allow the balls to be poked out with a long dowel after each scored basket.
",3
3052,"Basketball was originally played with a soccer ball. These round balls from ""association football"" were made, at the time, with a set of laces to close off the hole needed for inserting the inflatable bladder after the other sewn-together segments of the ball's cover had been flipped outside-in.[6][7] These laces could cause bounce passes and dribbling to be unpredictable.[8] Eventually a lace-free ball construction method was invented, and this change to the game was endorsed by Naismith. (Whereas in American football, the lace construction proved to be advantageous for gripping and remains to this day.) The first balls made specifically for basketball were brown, and it was only in the late 1950s that Tony Hinkle, searching for a ball that would be more visible to players and spectators alike, introduced the orange ball that is now in common use. Dribbling was not part of the original game except for the ""bounce pass"" to teammates. Passing the ball was the primary means of ball movement. Dribbling was eventually introduced but limited by the asymmetric shape of early balls.[dubious  – discuss] Dribbling was common by 1896, with a rule against the double dribble by 1898.[9]
",3
3053,"The peach baskets were used until 1906 when they were finally replaced by metal hoops with backboards. A further change was soon made, so the ball merely passed through. Whenever a person got the ball in the basket, his team would gain a point. Whichever team got the most points won the game.[10] The baskets were originally nailed to the mezzanine balcony of the playing court, but this proved impractical when spectators in the balcony began to interfere with shots. The backboard was introduced to prevent this interference; it had the additional effect of allowing rebound shots.[11] Naismith's handwritten diaries, discovered by his granddaughter in early 2006, indicate that he was nervous about the new game he had invented, which incorporated rules from a children's game called duck on a rock, as many had failed before it.
",3
3054,"Frank Mahan, one of the players from the original first game, approached Naismith after the Christmas break, in early 1892, asking him what he intended to call his new game. Naismith replied that he hadn't thought of it because he had been focused on just getting the game started. Mahan suggested that it be called ""Naismith ball"", at which he laughed, saying that a name like that would kill any game. Mahan then said, ""Why not call it basketball?"" Naismith replied, ""We have a basket and a ball, and it seems to me that would be a good name for it.""[12][13] The first official game was played in the YMCA gymnasium in Albany, New York, on January 20, 1892, with nine players. The game ended at 1–0; the shot was made from 25 feet (7.6 m), on a court just half the size of a present-day Streetball or National Basketball Association (NBA) court.
",3
3055,"At the time, football was being played with 10 to a team (which was increased to 11). When winter weather got too icy to play football, teams were taken indoors, and it was convenient to have them split in half and play basketball with five on each side. By 1897–1898 teams of five became standard.
",3
3056,"Basketball's early adherents were dispatched to YMCAs throughout the United States, and it quickly spread through the United States and Canada. By 1895, it was well established at several women's high schools. While YMCA was responsible for initially developing and spreading the game, within a decade it discouraged the new sport, as rough play and rowdy crowds began to detract from YMCA's primary mission. However, other amateur sports clubs, colleges, and professional clubs quickly filled the void. In the years before World War I, the Amateur Athletic Union and the Intercollegiate Athletic Association of the United States (forerunner of the NCAA) vied for control over the rules for the game. The first pro league, the National Basketball League, was formed in 1898 to protect players from exploitation and to promote a less rough game. This league only lasted five years.
",3
3057,"James Naismith was instrumental in establishing college basketball. His colleague C.O. Beamis fielded the first college basketball team just a year after the Springfield YMCA game at the suburban Pittsburgh Geneva College.[14] Naismith himself later coached at the University of Kansas for six years, before handing the reins to renowned coach Forrest ""Phog"" Allen. Naismith's disciple Amos Alonzo Stagg brought basketball to the University of Chicago, while Adolph Rupp, a student of Naismith's at Kansas, enjoyed great success as coach at the University of Kentucky. On February 9, 1895, the first intercollegiate 5-on-5 game was played at Hamline University between Hamline and the School of Agriculture, which was affiliated with the University of Minnesota.[15][16][17] The School of Agriculture won in a 9–3 game.
",3
3058,"In 1901, colleges, including the University of Chicago, Columbia University, Cornell University, Dartmouth College, the University of Minnesota, the U.S. Naval Academy, the University of Colorado and Yale University began sponsoring men's games. In 1905, frequent injuries on the football field prompted President Theodore Roosevelt to suggest that colleges form a governing body, resulting in the creation of the Intercollegiate Athletic Association of the United States (IAAUS). In 1910, that body changed its name to the National Collegiate Athletic Association (NCAA). The first Canadian interuniversity basketball game was played at YMCA in Kingston, Ontario on February 6, 1904, when McGill University—Naismith's alma mater—visited Queen's University. McGill won 9–7 in overtime; the score was 7–7 at the end of regulation play, and a ten-minute overtime period settled the outcome. A good turnout of spectators watched the game.[18]
",3
3059,"The first men's national championship tournament, the National Association of Intercollegiate Basketball tournament, which still exists as the National Association of Intercollegiate Athletics (NAIA) tournament, was organized in 1937. The first national championship for NCAA teams, the National Invitation Tournament (NIT) in New York, was organized in 1938; the NCAA national tournament began one year later. College basketball was rocked by gambling scandals from 1948 to 1951, when dozens of players from top teams were implicated in match fixing and point shaving. Partially spurred by an association with cheating, the NIT lost support to the NCAA tournament.
",3
3060,"Before widespread school district consolidation, most American high schools were far smaller than their present-day counterparts. During the first decades of the 20th century, basketball quickly became the ideal interscholastic sport due to its modest equipment and personnel requirements. In the days before widespread television coverage of professional and college sports, the popularity of high school basketball was unrivaled in many parts of America. Perhaps the most legendary of high school teams was Indiana's Franklin Wonder Five, which took the nation by storm during the 1920s, dominating Indiana basketball and earning national recognition.
",3
3061,"Today virtually every high school in the United States fields a basketball team in varsity competition.[19] Basketball's popularity remains high, both in rural areas where they carry the identification of the entire community, as well as at some larger schools known for their basketball teams where many players go on to participate at higher levels of competition after graduation. In the 2016–17 season, 980,673 boys and girls represented their schools in interscholastic basketball competition, according to the National Federation of State High School Associations.[20] The states of Illinois, Indiana and Kentucky are particularly well known for their residents' devotion to high school basketball, commonly called Hoosier Hysteria in Indiana; the critically acclaimed film Hoosiers shows high school basketball's depth of meaning to these communities.
",3
3062,"There is currently no tournament to determine a national high school champion. The most serious effort was the National Interscholastic Basketball Tournament at the University of Chicago from 1917 to 1930. The event was organized by Amos Alonzo Stagg and sent invitations to state champion teams. The tournament started out as a mostly Midwest affair but grew. In 1929 it had 29 state champions. Faced with opposition from the National Federation of State High School Associations and North Central Association of Colleges and Schools that bore a threat of the schools losing their accreditation the last tournament was in 1930. The organizations said they were concerned that the tournament was being used to recruit professional players from the prep ranks.[21] The tournament did not invite minority schools or private/parochial schools.
",3
3063,"The National Catholic Interscholastic Basketball Tournament ran from 1924 to 1941 at Loyola University.[22] The National Catholic Invitational Basketball Tournament from 1954 to 1978 played at a series of venues, including Catholic University, Georgetown and George Mason.[23] The National Interscholastic Basketball Tournament for Black High Schools was held from 1929 to 1942 at Hampton Institute.[24] The National Invitational Interscholastic Basketball Tournament was held from 1941 to 1967 starting out at Tuskegee Institute. Following a pause during World War II it resumed at Tennessee State College in Nashville. The basis for the champion dwindled after 1954 when Brown v. Board of Education began an integration of schools. The last tournaments were held at Alabama State College from 1964 to 1967.[25]
",3
3064,"Teams abounded throughout the 1920s. There were hundreds of men's professional basketball teams in towns and cities all over the United States, and little organization of the professional game. Players jumped from team to team and teams played in armories and smoky dance halls. Leagues came and went. Barnstorming squads such as the Original Celtics and two all-African American teams, the New York Renaissance Five (""Rens"") and the (still existing) Harlem Globetrotters played up to two hundred games a year on their national tours.
",3
3065,"In 1946, the Basketball Association of America (BAA) was formed. The first game was played in Toronto, Ontario, Canada between the Toronto Huskies and New York Knickerbockers on November 1, 1946. Three seasons later, in 1949, the BAA merged with the National Basketball League (NBL) to form the National Basketball Association (NBA). By the 1950s, basketball had become a major college sport, thus paving the way for a growth of interest in professional basketball. In 1959, a basketball hall of fame was founded in Springfield, Massachusetts, site of the first game. Its rosters include the names of great players, coaches, referees and people who have contributed significantly to the development of the game. The hall of fame has people who have accomplished many goals in their career in basketball. An upstart organization, the American Basketball Association, emerged in 1967 and briefly threatened the NBA's dominance until the ABA-NBA merger in 1976. Today the NBA is the top professional basketball league in the world in terms of popularity, salaries, talent, and level of competition.
",3
3066,"The NBA has featured many famous players, including George Mikan, the first dominating ""big man""; ball-handling wizard Bob Cousy and defensive genius Bill Russell of the Boston Celtics; charismatic center Wilt Chamberlain, who originally played for the barnstorming Harlem Globetrotters; all-around stars Oscar Robertson and Jerry West; more recent big men Kareem Abdul-Jabbar, Shaquille O'Neal, Hakeem Olajuwon and Karl Malone; playmakers John Stockton, Isiah Thomas and Steve Nash; crowd-pleasing forwards Julius Erving and Charles Barkley; European stars Dirk Nowitzki, Pau Gasol and Tony Parker; more recent superstars LeBron James, Allen Iverson and Kobe Bryant; and the three players who many credit with ushering the professional game to its highest level of popularity during the 1980s and 1990s: Larry Bird, Earvin ""Magic"" Johnson, and Michael Jordan.
",3
3067,"In 2001, the NBA formed a developmental league, the National Basketball Development League (later known as the NBA D-League and then the NBA G League after a branding deal with Gatorade). As of the 2018–19 season, the G League has 27 teams.
",3
3068,"FIBA (International Basketball Federation) was formed in 1932 by eight founding nations: Argentina, Czechoslovakia, Greece, Italy, Latvia, Portugal, Romania and Switzerland. At this time, the organization only oversaw amateur players. Its acronym, derived from the French Fédération Internationale de Basket-ball Amateur, was thus ""FIBA"". Men's basketball was first included at the Berlin 1936 Summer Olympics, although a demonstration tournament was held in 1904. The United States defeated Canada in the first final, played outdoors. This competition has usually been dominated by the United States, whose team has won all but three titles. The first of these came in a controversial final game in Munich in 1972 against the Soviet Union, in which the ending of the game was replayed three times until the Soviet Union finally came out on top.[26] In 1950 the first FIBA World Championship for men, now known as the FIBA Basketball World Cup, was held in Argentina. Three years later, the first FIBA World Championship for women, now known as the FIBA Women's Basketball World Cup, was held in Chile. Women's basketball was added to the Olympics in 1976, which were held in Montreal, Quebec, Canada with teams such as the Soviet Union, Brazil and Australia rivaling the American squads.
",3
3069,"In 1989, FIBA allowed professional NBA players to participate in the Olympics for the first time. Prior to the 1992 Summer Olympics, only European and South American teams were allowed to field professionals in the Olympics. The United States' dominance continued with the introduction of the original Dream Team. In the 2004 Athens Olympics, the United States suffered its first Olympic loss while using professional players, falling to Puerto Rico (in a 19-point loss) and Lithuania in group games, and being eliminated in the semifinals by Argentina. It eventually won the bronze medal defeating Lithuania, finishing behind Argentina and Italy. The Redeem Team, won gold at the 2008 Olympics, and the B-Team, won gold at the 2010 FIBA World Championship in Turkey despite featuring no players from the 2008 squad. The United States continued its dominance as they won gold at the 2012 Olympics, 2014 FIBA World Cup and the 2016 Olympics.
",3
3070,"Worldwide, basketball tournaments are held for boys and girls of all age levels. The global popularity of the sport is reflected in the nationalities represented in the NBA. Players from all six inhabited continents currently play in the NBA. Top international players began coming into the NBA in the mid-1990s, including Croatians Dražen Petrović and Toni Kukoč, Serbian Vlade Divac, Lithuanians Arvydas Sabonis and Šarūnas Marčiulionis, Dutchman Rik Smits and German Detlef Schrempf.
",3
3071,"In the Philippines, the Philippine Basketball Association's first game was played on April 9, 1975 at the Araneta Coliseum in Cubao, Quezon City. Philippines. It was founded as a ""rebellion"" of several teams from the now-defunct Manila Industrial and Commercial Athletic Association, which was tightly controlled by the Basketball Association of the Philippines (now defunct), the then-FIBA recognized national association. Nine teams from the MICAA participated in the league's first season that opened on April 9, 1975. The NBL is Australia's pre-eminent men's professional basketball league. The league commenced in 1979, playing a winter season (April–September) and did so until the completion of the 20th season in 1998. The 1998–99 season, which commenced only months later, was the first season after the shift to the current summer season format (October–April). This shift was an attempt to avoid competing directly against Australia's various football codes. It features 8 teams from around Australia and one in New Zealand. A few players including Luc Longley, Andrew Gaze, Shane Heal, Chris Anstey and Andrew Bogut made it big internationally, becoming poster figures for the sport in Australia. The Women's National Basketball League began in 1981.
",3
3072,"Women's basketball began in 1892 at Smith College when Senda Berenson, a physical education teacher, modified Naismith's rules for women. Shortly after she was hired at Smith, she went to Naismith to learn more about the game.[27] Fascinated by the new sport and the values it could teach, she organized the first women's collegiate basketball game on March 21, 1893, when her Smith freshmen and sophomores played against one another.[28] However, the first women's interinstitutional game was played in 1892 between the University of California and Miss Head's School.[29] Berenson's rules were first published in 1899, and two years later she became the editor of A. G. Spalding's first Women's Basketball Guide.[28] Berenson's freshmen played the sophomore class in the first women's intercollegiate basketball game at Smith College, March 21, 1893.[30] The same year, Mount Holyoke and Sophie Newcomb College (coached by Clara Gregory Baer) women began playing basketball. By 1895, the game had spread to colleges across the country, including Wellesley, Vassar, and Bryn Mawr. The first intercollegiate women's game was on April 4, 1896. Stanford women played Berkeley, 9-on-9, ending in a 2–1 Stanford victory.
",3
3073,"Women's basketball development was more structured than that for men in the early years. In 1905, the Executive Committee on Basket Ball Rules (National Women's Basketball Committee) was created by the American Physical Education Association.[31] These rules called for six to nine players per team and 11 officials. The International Women's Sports Federation (1924) included a women's basketball competition. 37 women's high school varsity basketball or state tournaments were held by 1925. And in 1926, the Amateur Athletic Union backed the first national women's basketball championship, complete with men's rules.[31] The Edmonton Grads, a touring Canadian women's team based in Edmonton, Alberta, operated between 1915 and 1940. The Grads toured all over North America, and were exceptionally successful. They posted a record of 522 wins and only 20 losses over that span, as they met any team that wanted to challenge them, funding their tours from gate receipts.[32] The Grads also shone on several exhibition trips to Europe, and won four consecutive exhibition Olympics tournaments, in 1924, 1928, 1932, and 1936; however, women's basketball was not an official Olympic sport until 1976. The Grads' players were unpaid, and had to remain single. The Grads' style focused on team play, without overly emphasizing skills of individual players. The first women's AAU All-America team was chosen in 1929.[31] Women's industrial leagues sprang up throughout the United States, producing famous athletes, including Babe Didrikson of the Golden Cyclones, and the All American Red Heads Team, which competed against men's teams, using men's rules. By 1938, the women's national championship changed from a three-court game to two-court game with six players per team.[31]
",3
3074,"The NBA-backed Women's National Basketball Association (WNBA) began in 1997. Though it had shaky attendance figures, several marquee players (Lisa Leslie, Diana Taurasi, and Candace Parker among others) have helped the league's popularity and level of competition. Other professional women's basketball leagues in the United States, such as the American Basketball League (1996–98), have folded in part because of the popularity of the WNBA. The WNBA has been looked at by many as a niche league. However, the league has recently taken steps forward. In June 2007, the WNBA signed a contract extension with ESPN. The new television deal ran from 2009 to 2016. Along with this deal, came the first ever rights fees to be paid to a women's professional sports league. Over the eight years of the contract, ""millions and millions of dollars"" were ""dispersed to the league's teams."" In a March 12, 2009 article, NBA commissioner David Stern said that in the bad economy, ""the NBA is far less profitable than the WNBA. We're losing a lot of money among a large number of teams. We're budgeting the WNBA to break even this year.""[33]
",3
3075,"Measurements and time limits discussed in this section often vary among tournaments and organizations; international and NBA rules are used in this section.
",3
3076,"The object of the game is to outscore one's opponents by throwing the ball through the opponents' basket from above while preventing the opponents from doing so on their own. An attempt to score in this way is called a shot. A successful shot is worth two points, or three points if it is taken from beyond the three-point arc 6.75 metres (22 ft 2 in) from the basket in international games[34] and 23 feet 9 inches (7.24 m) in NBA games.[35] A one-point shot can be earned when shooting from the foul line after a foul is made. After a team has scored from a field goal or free throw, play is resumed with a throw-in awarded to the non-scoring team taken from a point beyond the endline of the court where the points(s) were scored.[36]
",3
3077,"Games are played in four quarters of 10 (FIBA)[37] or 12 minutes (NBA).[38] College men's games use two 20-minute halves,[39] college women's games use 10-minute quarters,[40] and most United States high school varsity games use 8-minute quarters; however, this varies from state to state.[41][42] 15 minutes are allowed for a half-time break under FIBA, NBA, and NCAA rules[39][43][44] and 10 minutes in United States high schools.[41] Overtime periods are five minutes in length[39][45][46] except for high school, which is four minutes in length.[41] Teams exchange baskets for the second half. The time allowed is actual playing time; the clock is stopped while the play is not active. Therefore, games generally take much longer to complete than the allotted game time, typically about two hours.
",3
3078,"Five players from each team may be on the court at one time.[47][48][49][50] Substitutions are unlimited but can only be done when play is stopped. Teams also have a coach, who oversees the development and strategies of the team, and other team personnel such as assistant coaches, managers, statisticians, doctors and trainers.
",3
3079,"For both men's and women's teams, a standard uniform consists of a pair of shorts and a jersey with a clearly visible number, unique within the team, printed on both the front and back. Players wear high-top sneakers that provide extra ankle support. Typically, team names, players' names and, outside of North America, sponsors are printed on the uniforms.
",3
3080,"A limited number of time-outs, clock stoppages requested by a coach (or sometimes mandated in the NBA) for a short meeting with the players, are allowed. They generally last no longer than one minute (100 seconds in the NBA) unless, for televised games, a commercial break is needed.
",3
3081,"The game is controlled by the officials consisting of the referee (referred to as crew chief in the NBA), one or two umpires (referred to as referees in the NBA) and the table officials. For college, the NBA, and many high schools, there are a total of three referees on the court. The table officials are responsible for keeping track of each team's scoring, timekeeping, individual and team fouls, player substitutions, team possession arrow, and the shot clock.
",3
3082,"The only essential equipment in a basketball game is the ball and the court: a flat, rectangular surface with baskets at opposite ends. Competitive levels require the use of more equipment such as clocks, score sheets, scoreboard(s), alternating possession arrows, and whistle-operated stop-clock systems.
",3
3083,"A regulation basketball court in international games is 91.9 feet (28.0 meters) long and 49.2 feet (15 meters) wide. In the NBA and NCAA the court is 94 by 50 feet (29 by 15 meters).[35] Most courts have wood flooring, usually constructed from maple planks running in the same direction as the longer court dimension.[51][52] The name and logo of the home team is usually painted on or around the center circle.
",3
3084,"The basket is a steel rim 18 inches (46 cm) diameter with an attached net affixed to a backboard that measures 6 by 3.5 feet (1.8 by 1.1 meters) and one basket is at each end of the court. The white outlined box on the backboard is 18 inches (46 cm) high and 2 feet (61 cm) wide. At almost all levels of competition, the top of the rim is exactly 10 feet (3.05 meters) above the court and 4 feet (1.22 meters) inside the baseline. While variation is possible in the dimensions of the court and backboard, it is considered important for the basket to be of the correct height – a rim that is off by just a few inches can have an adverse effect on shooting.  The net must ""check the ball momentarily as it passes through the basket"" to aid the visual confirmation that the ball went through.[53]  The act of checking the ball has the further advantage of slowing down the ball so the rebound doesn't go as far.[54]
",3
3085,"The size of the basketball is also regulated. For men, the official ball is 29.5 inches (75 cm) in circumference (size 7, or a ""295 ball"") and weighs 22 oz (623.69 grams). If women are playing, the official basketball size is 28.5 inches (72 cm) in circumference (size 6, or a ""285 ball"") with a weight of 20 oz (567 grams). In 3x3, a formalized version of the halfcourt 3-on-3 game, a dedicated ball with the circumference of a size 6 ball but the weight of a size 7 ball is used in all competitions (men's, women's, and mixed teams).[55]
",3
3086,"The ball may be advanced toward the basket by being shot, passed between players, thrown, tapped, rolled or dribbled (bouncing the ball while running).
",3
3087,"The ball must stay within the court; the last team to touch the ball before it travels out of bounds forfeits possession. The ball is out of bounds if it touches a boundary line, or touches any player or object that is out of bounds.
",3
3088,"There are limits placed on the steps a player may take without dribbling, which commonly results in an infraction known as traveling. Nor may a player stop his dribble and then resume dribbling. A dribble that touches both hands is considered stopping the dribble, giving this infraction the name double dribble. Within a dribble, the player cannot carry the ball by placing his hand on the bottom of the ball; doing so is known as carrying the ball. A team, once having established ball control in the front half of their court, may not return the ball to the backcourt and be the first to touch it. A violation of these rules results in loss of possession.
",3
3089,"The ball may not be kicked, nor be struck with the fist. For the offense, a violation of these rules results in loss of possession; for the defense, most leagues reset the shot clock and the offensive team is given possession of the ball out of bounds.
",3
3090,"There are limits imposed on the time taken before progressing the ball past halfway (8 seconds in FIBA and the NBA; 10 seconds in NCAA and high school for both sexes), before attempting a shot (24 seconds in FIBA, the NBA, and U Sports (Canadian universities) play for both sexes, and 30 seconds in NCAA play for both sexes), holding the ball while closely guarded (5 seconds), and remaining in the restricted area known as the free-throw lane, (or the ""key"") (3 seconds). These rules are designed to promote more offense.
",3
3091,"There are also limits on how players may block an opponent's field goal attempt or help a teammate's field goal attempt. Goaltending is a defender's touching of a ball that is on a downward flight toward the basket, while the related violation of basket interference is the touching of a ball that is on the rim or above the basket, or by a player reaching through the basket from below. Goaltending and basket interference committed by a defender result in awarding the basket to the offense, while basket interference committed by an offensive player results in cancelling the basket if one is scored. The defense gains possession in all cases of goaltending or basket interference.
",3
3092,"An attempt to unfairly disadvantage an opponent through certain types of physical contact is illegal and is called a personal foul. These are most commonly committed by defensive players; however, they can be committed by offensive players as well. Players who are fouled either receive the ball to pass inbounds again, or receive one or more free throws if they are fouled in the act of shooting, depending on whether the shot was successful. One point is awarded for making a free throw, which is attempted from a line 15 feet (4.6 m) from the basket.
",3
3093,"The referee is responsible for judging whether contact is illegal, sometimes resulting in controversy. The calling of fouls can vary between games, leagues and referees.
",3
3094,"There is a second category of fouls called technical fouls, which may be charged for various rules violations including failure to properly record a player in the scorebook, or for unsportsmanlike conduct. These infractions result in one or two free throws, which may be taken by any of the five players on the court at the time. Repeated incidents can result in disqualification. A blatant foul involving physical contact that is either excessive or unnecessary is called an intentional foul (flagrant foul in the NBA). In FIBA and NCAA women's basketball, a foul resulting in ejection is called a disqualifying foul, while in leagues other than the NBA, such a foul is referred to as flagrant.
",3
3095,"If a team exceeds a certain limit of team fouls in a given period (quarter or half) – four for NBA, NCAA women's, and international games – the opposing team is awarded one or two free throws on all subsequent non-shooting fouls for that period, the number depending on the league. In the US college men's game and high school games for both sexes, if a team reaches 7 fouls in a half, the opposing team is awarded one free throw, along with a second shot if the first is made. This is called shooting ""one-and-one"". If a team exceeds 10 fouls in the half, the opposing team is awarded two free throws on all subsequent fouls for the half.
",3
3096,"When a team shoots foul shots, the opponents may not interfere with the shooter, nor may they try to regain possession until the last or potentially last free throw is in the air.
",3
3097,"After a team has committed a specified number of fouls, the other team is said to be ""in the bonus"". On scoreboards, this is usually signified with an indicator light reading ""Bonus"" or ""Penalty"" with an illuminated directional arrow or dot indicating that team is to receive free throws when fouled by the opposing team. (Some scoreboards also indicate the number of fouls committed.)
",3
3098,"If a team misses the first shot of a two-shot situation, the opposing team must wait for the completion of the second shot before attempting to reclaim possession of the ball and continuing play.
",3
3099,"If a player is fouled while attempting a shot and the shot is unsuccessful, the player is awarded a number of free throws equal to the value of the attempted shot. A player fouled while attempting a regular two-point shot thus receives two shots, and a player fouled while attempting a three-point shot receives three shots.
",3
3100,"If a player is fouled while attempting a shot and the shot is successful, typically the player will be awarded one additional free throw for one point. In combination with a regular shot, this is called a ""three-point play"" or ""four-point play"" (or more colloquially, an ""and one"") because of the basket made at the time of the foul (2 or 3 points) and the additional free throw (1 point).
",3
3101,"Although the rules do not specify any positions whatsoever, they have evolved as part of basketball. During the early years of basketball's evolution, two guards, two forwards, and one center were used. In more recent times specific positions evolved, but the current trend, advocated by many top coaches including Mike Krzyzewski, is towards positionless basketball, where big players are free to shoot from outside and dribble if their skill allows it.[56] Popular descriptions of positions include:
",3
3102,"Point guard (often called the ""1"") : usually the fastest player on the team, organizes the team's offense by controlling the ball and making sure that it gets to the right player at the right time.
",3
3103,"Shooting guard (the ""2"") : creates a high volume of shots on offense, mainly long-ranged; and guards the opponent's best perimeter player on defense.
",3
3104,"Small forward (the ""3"") : often primarily responsible for scoring points via cuts to the basket and dribble penetration; on defense seeks rebounds and steals, but sometimes plays more actively.
",3
3105,"Power forward (the ""4""): plays offensively often with their back to the basket; on defense, plays under the basket (in a zone defense) or against the opposing power forward (in man-to-man defense).
",3
3106,"Center (the ""5""): uses height and size to score (on offense), to protect the basket closely (on defense), or to rebound.
",3
3107,"The above descriptions are flexible. For most teams today, the shooting guard and small forward have very similar responsibilities and are often called the wings, as do the power forward and center, who are often called post players. While most teams describe two players as guards, two as forwards, and one as a center, on some occasions teams choose to call them by different designations.
",3
3108,"There are two main defensive strategies: zone defense and man-to-man defense. In a zone defense, each player is assigned to guard a specific area of the court. Zone defenses often allow the defense to double team the ball, a manoeuver known as a trap. In a man-to-man defense, each defensive player guards a specific opponent.
",3
3109,"Offensive plays are more varied, normally involving planned passes and movement by players without the ball. A quick movement by an offensive player without the ball to gain an advantageous position is known as a cut. A legal attempt by an offensive player to stop an opponent from guarding a teammate, by standing in the defender's way such that the teammate cuts next to him, is a screen or pick. The two plays are combined in the pick and roll, in which a player sets a pick and then ""rolls"" away from the pick towards the basket. Screens and cuts are very important in offensive plays; these allow the quick passes and teamwork, which can lead to a successful basket. Teams almost always have several offensive plays planned to ensure their movement is not predictable. On court, the point guard is usually responsible for indicating which play will occur.
",3
3110,"Shooting is the act of attempting to score points by throwing the ball through the basket, methods varying with players and situations.
",3
3111,"Typically, a player faces the basket with both feet facing the basket. A player will rest the ball on the fingertips of the dominant hand (the shooting arm) slightly above the head, with the other hand supporting the side of the ball. The ball is usually shot by jumping (though not always) and extending the shooting arm. The shooting arm, fully extended with the wrist fully bent, is held stationary for a moment following the release of the ball, known as a follow-through. Players often try to put a steady backspin on the ball to absorb its impact with the rim. The ideal trajectory of the shot is somewhat controversial, but generally a proper arc is recommended. Players may shoot directly into the basket or may use the backboard to redirect the ball into the basket.
",3
3112,"The two most common shots that use the above described setup are the set shot and the jump shot. Both are preceded by a crouching action which preloads the muscles and increases the power of the shot. In a set shot the shooter straightens up and throws from a standing position with neither foot leaving the floor; this is typically used for free throws. For a jump shot, the throw is taken in mid-air with the ball being released near the top of the jump. This provides much greater power and range, and it also allows the player to elevate over the defender. Failure to release the ball before the feet return to the floor is considered a traveling violation.
",3
3113,"Another common shot is called the lay-up. This shot requires the player to be in motion toward the basket, and to ""lay"" the ball ""up"" and into the basket, typically off the backboard (the backboard-free, underhand version is called a finger roll). The most crowd-pleasing and typically highest-percentage accuracy shot is the slam dunk, in which the player jumps very high and throws the ball downward, through the basket while touching it.
",3
3114,"Another shot that is less common than the lay-up, is the ""circus shot"". The circus shot is a low-percentage shot that is flipped, heaved, scooped, or flung toward the hoop while the shooter is off-balance, airborne, falling down, and/or facing away from the basket. A back-shot is a shot taken when the player is facing away from the basket, and may be shot with the dominant hand, or both; but there is a very low chance that the shot will be successful.[57]
",3
3115,"A shot that misses both the rim and the backboard completely is referred to as an air ball. A particularly bad shot, or one that only hits the backboard, is jocularly called a brick. The hang time is the length of time a player stays in the air after jumping, either to make a slam dunk, lay-up or jump shot.
",3
3116,"The objective of rebounding is to successfully gain possession of the basketball after a missed field goal or free throw, as it rebounds from the hoop or backboard. This plays a major role in the game, as most possessions end when a team misses a shot. There are two categories of rebounds: offensive rebounds, in which the ball is recovered by the offensive side and does not change possession, and defensive rebounds, in which the defending team gains possession of the loose ball. The majority of rebounds are defensive, as the team on defense tends to be in better position to recover missed shots.
",3
3117,"A pass is a method of moving the ball between players. Most passes are accompanied by a step forward to increase power and are followed through with the hands to ensure accuracy.
",3
3118,"A staple pass is the chest pass. The ball is passed directly from the passer's chest to the receiver's chest. A proper chest pass involves an outward snap of the thumbs to add velocity and leaves the defence little time to react.
",3
3119,"Another type of pass is the bounce pass. Here, the passer bounces the ball crisply about two-thirds of the way from his own chest to the receiver. The ball strikes the court and bounces up toward the receiver. The bounce pass takes longer to complete than the chest pass, but it is also harder for the opposing team to intercept (kicking the ball deliberately is a violation). Thus, players often use the bounce pass in crowded moments, or to pass around a defender.
",3
3120,"The overhead pass is used to pass the ball over a defender. The ball is released while over the passer's head.
",3
3121,"The outlet pass occurs after a team gets a defensive rebound. The next pass after the rebound is the outlet pass.
",3
3122,"The crucial aspect of any good pass is it being difficult to intercept. Good passers can pass the ball with great accuracy and they know exactly where each of their other teammates prefers to receive the ball. A special way of doing this is passing the ball without looking at the receiving teammate. This is called a no-look pass.
",3
3123,"Another advanced style of passing is the behind-the-back pass, which, as the description implies, involves throwing the ball behind the passer's back to a teammate. Although some players can perform such a pass effectively, many coaches discourage no-look or behind-the-back passes, believing them to be difficult to control and more likely to result in turnovers or violations.
",3
3124,"Dribbling is the act of bouncing the ball continuously with one hand and is a requirement for a player to take steps with the ball. To dribble, a player pushes the ball down towards the ground with the fingertips rather than patting it; this ensures greater control.
",3
3125,"When dribbling past an opponent, the dribbler should dribble with the hand farthest from the opponent, making it more difficult for the defensive player to get to the ball. It is therefore important for a player to be able to dribble competently with both hands.
",3
3126,"Good dribblers (or ""ball handlers"") tend to bounce the ball low to the ground, reducing the distance of travel of the ball from the floor to the hand, making it more difficult for the defender to ""steal"" the ball. Good ball handlers frequently dribble behind their backs, between their legs, and switch directions suddenly, making a less predictable dribbling pattern that is more difficult to defend against. This is called a crossover, which is the most effective way to move past defenders while dribbling.
",3
3127,"A skilled player can dribble without watching the ball, using the dribbling motion or peripheral vision to keep track of the ball's location. By not having to focus on the ball, a player can look for teammates or scoring opportunities, as well as avoid the danger of having someone steal the ball away from him/her.
",3
3128,"A block is performed when, after a shot is attempted, a defender succeeds in altering the shot by touching the ball. In almost all variants of play, it is illegal to touch the ball after it is in the downward path of its arc; this is known as goaltending. It is also illegal under NBA and Men's NCAA basketball to block a shot after it has touched the backboard, or when any part of the ball is directly above the rim. Under international rules it is illegal to block a shot that is in the downward path of its arc or one that has touched the backboard until the ball has hit the rim. After the ball hits the rim, it is again legal to touch it even though it is no longer considered as a block performed.
",3
3129,"To block a shot, a player has to be able to reach a point higher than where the shot is released. Thus, height can be an advantage in blocking. Players who are taller and playing the power forward or center positions generally record more blocks than players who are shorter and playing the guard positions. However, with good timing and a sufficiently high vertical leap, even shorter players can be effective shot blockers.
",3
3130,"At the professional level, most male players are above 6 feet 3 inches (1.91 m) and most women above 5 feet 7 inches (1.70 m). Guards, for whom physical coordination and ball-handling skills are crucial, tend to be the smallest players. Almost all forwards in the top men's pro leagues are 6 feet 6 inches (1.98 m) or taller. Most centers are over 6 feet 10 inches (2.08 m) tall. According to a survey given to all NBA teams,[when?] the average height of all NBA players is just under 6 feet 7 inches (2.01 m), with the average weight being close to 222 pounds (101 kg). The tallest players ever in the NBA were Manute Bol and Gheorghe Mureșan, who were both 7 feet 7 inches (2.31 m) tall. At 7 feet 2 inches (2.18 m), Margo Dydek was the tallest player in the history of the WNBA.
",3
3131,"The shortest player ever to play in the NBA is Muggsy Bogues at 5 feet 3 inches (1.60 m).[58] Other short players have thrived at the pro level. Anthony ""Spud"" Webb was just 5 feet 7 inches (1.70 m) tall, but had a 42-inch (1.1 m) vertical leap, giving him significant height when jumping. While shorter players are often at a disadvantage in certain aspects of the game, their ability to navigate quickly through crowded areas of the court and steal the ball by reaching low are strengths.
",3
3132,"Players regularly inflate their height. Many prospects exaggerate their height while in high school or college to make themselves more appealing to coaches and scouts, who prefer taller players. Charles Barkley stated; ""I've been measured at 6-5, 6-4 ​3⁄4. But I started in college at 6-6."" Sam Smith, a former writer from the Chicago Tribune, said: ""We sort of know the heights, because after camp, the sheet comes out. But you use that height, and the player gets mad. And then you hear from his agent. Or you file your story with the right height, and the copy desk changes it because they have the 'official' N.B.A. media guide, which is wrong. So you sort of go along with the joke.""[59] In the NBA, there is no standard on whether a player's listed height uses their measurement with shoes on or without. The NBA Draft Combine, which most players attend before the draft, provides both measurements. Thereafter, a player's team is solely responsible for their listed height, which can vary depending on the process selected.[60][61]
",3
3133,"Notable players who overstated their height include:
",3
3134,"On rare occasions, some players will understate their actual heights, not to be repositioned. One example is Kevin Durant, whose listed height is 6 feet 9 inches (2.06 m), while his actual height is 7 feet 0 inches (2.13 m). Durant's reasoning was, ""Really, that's the prototypical size for a small forward. Anything taller than that, and they'll start saying, 'Ah, he's a power forward.""[66]
",3
3135,"Variations of basketball are activities based on the game of basketball, using common basketball skills and equipment (primarily the ball and basket). Some variations are only superficial rules changes, while others are distinct games with varying degrees of basketball influences. Other variations include children's games, contests or activities meant to help players reinforce skills.
",3
3136,"There are principal basketball sports with variations on basketball including Wheelchair basketball, Water basketball, Beach basketball, Slamball, Streetball and Unicycle basketball. An earlier version of basketball, played primarily by women and girls, was Six-on-six basketball. Horseball is a game played on horseback where a ball is handled and points are scored by shooting it through a high net (approximately 1.5m×1.5m). The sport is like a combination of polo, rugby, and basketball. There is even a form played on donkeys known as Donkey basketball, but that version has come under attack from animal rights groups.
",3
3137,"Perhaps the single most common variation of basketball is the half-court game, played in informal settings without referees or strict rules. Only one basket is used, and the ball must be ""taken back"" or ""cleared"" – passed or dribbled outside the three-point line each time possession of the ball changes from one team to the other. Half-court games require less cardiovascular stamina, since players need not run back and forth a full court. Half-court raises the number of players that can use a court or, conversely, can be played if there is an insufficient number to form full 5-on-5 teams.
",3
3138,"Half-court basketball is usually played 1-on-1, 2-on-2 or 3-on-3. Also, streetball commonly uses the same system. The latter variation is gradually gaining official recognition as 3x3, originally known as FIBA 33. It was first tested at the 2007 Asian Indoor Games in Macau and the first official tournaments were held at the 2009 Asian Youth Games and the 2010 Youth Olympics, both in Singapore. The first FIBA 3x3 Youth World Championships[67] were held in Rimini, Italy in 2011, with the first FIBA 3x3 World Championships for senior teams following a year later in Athens. The sport is highly tipped to become an Olympic sport as early as 2016.[68] In the summer of 2017, the BIG3 basketball league, a professional 3x3 half court basketball league that features former NBA players, began. The BIG3 features several rule variants including a four-point field goal.[69]
",3
3139,"There are also other basketball sports, such as:
",3
3140,"Spin-offs from basketball that are now separate sports include:
",3
3141,"Basketball has been adopted by various social groups, which have established their own environments and sometimes their own rules. Such socialized forms of basketball include the following.
",3
3142,"Basketball is played widely casually in schools and colleges where fun, entertainment and camaraderie rule rather than winning a game.
",3
3143,"Disabled basketball is played by various disabled groups, such as the deaf and physically crippled people.
",3
3144,"Show basketball is performed by entertainment basketball show teams, the prime example being the Harlem Globetrotters. There are even specialized entertainment teams, such as teams of celebrities, people with short heights and others.
",3
3145,"Fantasy basketball was popularized during the 1990s after the advent of the Internet. Those who play this game are sometimes referred to as General Managers, who draft actual NBA players and compute their basketball statistics. The game was popularized by ESPN Fantasy Sports, NBA.com, and Yahoo! Fantasy Sports. Other sports websites provided the same format keeping the game interesting with participants actually owning specific players.
",3
3146,"
",3
3147,"Rugby league, often called simply league, is a full-contact sport played by two teams of thirteen players on a rectangular field measuring 68 metres (75 yards) wide and 112–122 metres (122 to 133 yards) long.[1] One of the two codes of rugby football, it originated in Northern England in 1895 as a split from the Rugby Football Union over the issue of payments to the players.[2] Its rules progressively changed with the aim of producing a faster, more entertaining game for spectators.[3]
",3
3148,"In rugby league, points are scored by carrying the ball and touching it to the ground beyond the opposing team's goal line; this is called a try, and is the primary method of scoring.[4] The opposing team attempts to stop the attacking side scoring points by tackling the player carrying the ball.[4] In addition to tries, points can be scored by kicking goals. Field goals can be attempted at any time, and following a successful try, the scoring team gains a free kick to try at goal with a conversion for further points.[4] Kicks at goal may also be awarded for penalties.
",3
3149,"The Super League and the National Rugby League (NRL) are the premier club competitions. Rugby league is played internationally, predominantly by European, Australasian and Pacific Island countries, and is governed by the International Rugby League (IRL). Rugby league is the national sport of Papua New Guinea,[5][6][7] and is a popular sport in countries such as England,[8] Australia,[9] New Zealand, France, Tonga, Fiji, Samoa, and Lebanon.[10]
",3
3150,"The first Rugby League World Cup was held in France in 1954; the current holders are Australia.[11]
",3
3151,"Rugby league football takes its name from the bodies that split to create a new form of rugby, distinct from that run by the Rugby Football Unions, in Britain, Australia and New Zealand between 1895 and 1908.
",3
3152,"The first of these, the Northern Rugby Football Union, was established in 1895 as a breakaway faction of England's Rugby Football Union (RFU). Both organisations played the game under the same rules at first, although the Northern Union began to modify rules almost immediately, thus creating a new simpler game that was intended to be a faster paced form of rugby football. Similar breakaway factions split from RFU-affiliated unions in Australia and New Zealand in 1907 and 1908, renaming themselves ""rugby football leagues"" and introducing Northern Union rules.[12] In 1922, the Northern Union also changed its name to the Rugby Football League[13] and thus over time the sport itself became known as ""rugby league"" football.
",3
3153,"In 1895, a schism in Rugby football resulted in the formation of the Northern Rugby Football Union (NRFU).[14] Although many factors played a part in the split, including the success of working class northern teams, the main division was caused by the RFU decision to enforce the amateur principle of the sport, preventing ""broken time payments"" to players who had taken time off work to play rugby. Northern teams typically had more working class players (coal miners, mill workers etc.) who could not afford to play without this compensation, in contrast to affluent southern teams who had other sources of income to sustain the amateur principle.[2] In 1895, a decree by the RFU banning the playing of rugby at grounds where entrance fees were charged led to twenty-two clubs (including Stockport, who negotiated by telephone) meeting at the George Hotel, Huddersfield on 29 August 1895 and forming the ""Northern Rugby Football Union"".[15] Within fifteen years of that first meeting in Huddersfield, more than 200 RFU clubs had left to join the rugby revolution.
",3
3154,"In 1897, the line-out was abolished[16] and in 1898 professionalism introduced.[17] In 1906, the Northern Union changed its rules, reducing teams from 15 to 13 a side and replacing the ruck formed after every tackle with the play the ball.[18]
",3
3155,"A similar schism to that which occurred in England took place in Sydney, Australia. There, on 8 August 1907 the New South Wales Rugby Football League was founded at Bateman's Hotel in George Street.[19] Rugby league then went on to displace rugby union as the primary football code in New South Wales and Queensland.[20]
",3
3156,"On 5 May 1954 over 100,000 (official figure 102,569) spectators watched the 1953–54 Challenge Cup Final replay at Odsal Stadium, Bradford, England, setting a new record for attendance at a rugby football match of either code.[19] Also in 1954 the Rugby League World Cup, the first for either code of rugby, was formed at the instigation of the French. In 1966, the International Board introduced a rule that a team in possession was allowed three play-the-balls and on the fourth tackle a scrum was to be formed. This was increased to six tackles in 1972 and in 1983 the scrum was replaced by a handover.[21] 1967 saw the first professional Sunday matches of rugby league played.
",3
3157,"The first sponsors, Joshua Tetley and John Player, entered the game for the 1971–72 Northern Rugby Football League season. Television had an enormous impact on the sport of rugby league in the 1990s when News Corporation paid for worldwide broadcasting rights. The media giant's ""Super League"" movement created changes for the traditional administrators of the game. In Europe, it resulted in a move from a winter sport to a summer one as the new Super League competition tried to expand its market. In Australasia, the Super League war resulted in long and costly legal battles and changing loyalties, causing significant damage to the code in an extremely competitive sporting market. In 1997 two competitions were run alongside each other in Australia, after which a peace deal in the form of the National Rugby League was formed. The NRL has since become recognised as the sport's flagship competition and since that time has set record TV ratings and crowd figures.[22]
",3
3158,"The objective in rugby league is to score more points through tries, goals and field goals (also known as drop goals) than the opposition within the 80 minutes of play. If after two-halves of play, each consisting of forty minutes, the two teams are drawing, a draw may be declared, or the game may enter extra time under the golden point rule, depending on the relevant competition's format.
",3
3159,"The try is the most common form of scoring,[23] and a team will usually attempt to score one by running and kicking the ball further upfield or passing from player-to-player in order to manoeuvre around the opposition's defence. A try involves touching the ball to the ground on or beyond the defending team's goal-line and is worth four points. A goal is worth two points and may be gained from a conversion or a penalty. A field goal, or drop goal, is only worth one point and is gained by dropping and then kicking the ball on the half volley between the uprights in open play.
",3
3160,"Field position is crucial in rugby league,[24] achieved by running with or kicking the ball. Passing in rugby league may only be in a backward or sideways direction. Teammates, therefore, have to remain on-side by not moving ahead of the player with the ball. However the ball may be kicked ahead for teammates, but again, if they are in front of the kicker when the ball is kicked, they are deemed off-side. Tackling is a key component of rugby league play. Only the player holding the ball may be tackled. A tackle is complete, for example, when the player is held by one or more opposing players
in such a manner that he can make no further progress and cannot part with the ball, or when the player is held by one or more opposing players and the ball or the hand or arm holding the ball comes into contact with the ground.[25] An attacking team gets a maximum of six tackles to progress up the field before possession is changed over. Once the tackle is completed, the ball-carrier must be allowed to get to his feet to 'play-the-ball'. Ball control is also important in rugby league, as a fumble of the ball on the ground forces a handover, unless the ball is fumbled backwards. The ball can also be turned over by going over the sideline.
",3
3161,"Rugby league and rugby union are distinct sports with many similarities and a shared origin. Both have the same fundamental rules, are played for 80 minutes and feature an oval-shaped ball and H-shaped goalposts. Both have rules that the ball cannot be passed forward, and dropping it forwards leads to a scrum. Both use tries as the central scoring method and conversion kicks, penalty goals and drop goals as additional scoring methods. However, there are differences in how many points each method is worth.
",3
3162,"One of the main differences is the rules of possession.[26] When the ball goes into touch, possession in rugby union is contested through a line-out, while in rugby league a scrum restarts play. The lesser focus on contesting possession means that play stops less frequently in rugby league,[27] with the ball typically in play for 50 out of the 80 minutes compared to around 35 minutes for professional rugby union.[28] Other differences include that there are fewer players in rugby league (13 compared to 15)[29][30] and different rules for tackling. Rugby union has more detailed rules than rugby league[31][32] and has changed less since the 1895 schism.[33]
",3
3163,"Rugby league historian Tony Collins has written that since rugby union turned professional in the mid-1990s, it has increasingly borrowed techniques and tactics from rugby league.[34][35] The inherent similarities between rugby league and rugby union have at times led to experimental hybrid games being played that use a mix of the two sports' rules.[36][37]
",3
3164,"Players on the pitch are divided into forwards and backs, although the game's rules apply to all players the same way. Each position has a designated number to identify himself from other players. These numbers help to identify which position a person is playing. The system of numbering players is different depending on which country the match is played in. In Australia and New Zealand, each player is usually given a number corresponding to their playing position on the field. However, since 1996 European teams have been able to grant players specific squad numbers, which they keep without regard to the position they play, similarly to association football.[38]
",3
3165,"Substitutes (generally referred to as ""the bench"") are allowed in the sport, and are typically used when a player gets tired or injured, although they can also be used tactically. Each team is currently allowed four substitutes, and in Australia and New Zealand, these players occupy shirt numbers 14 to 22.[39] There are no limitations on which players must occupy these interchangeable slots. Generally, twelve interchanges are allowed in any game from each team, although in the National Rugby League, this was reduced to ten prior to the 2008 season[40] and further reduced to eight prior to the 2016 season. If a team has to interchange a player due to the blood bin rule or due to injury, and this was the result of misconduct from the opposing team, the compromised team does not have to use one of its allocated interchanges to take the player in question off the field.
",3
3166,"The backs are generally smaller, faster and more agile than the forwards. They are often the most creative and evasive players on the field, relying on running, kicking and handling skills, as well as tactics and set plays, to break the defensive line, instead of brute force. Generally forwards do the majority of the work (hit-ups/tackling).
",3
3167,"Usually, the stand-off/five-eighth and scrum-half/half-back are a team's creative unit or 'playmakers'. During the interactions between a team's 'key' players (five-eighth, half-back, fullback, lock forward, and hooker), the five-eighth and half-back will usually be involved in most passing moves. These two positions are commonly called the ""halves"".
",3
3168,"The forwards' two responsibilities can be broken into ""normal play"" and ""scrum play"". For information on a forward's role in the scrum see rugby league scrummage. Forward positions are traditionally named after the player's position in the scrum yet are equal with respect to ""normal play"" with the exception of the hooker. Forward positions are traditionally assigned as follows:
",3
3169,"Rugby league is played in over 70 nations throughout the world. Seven countries – Australia, Canada, England, France, New Zealand, Papua New Guinea and Wales – have teams that play at a professional level, while the rest are semi-professional or amateur. 45 national teams are ranked by the RLIF and a further 32 are officially recognized and unranked.[41] The strongest rugby league nations are Australia, England, New Zealand and Tonga.
",3
3170,"The Rugby League World Cup is the highest form of representative rugby league. Those which have contested World Cups are; Australia, New Zealand, England, France, Fiji, Wales, Papua New Guinea, Samoa, Ireland, USA, Scotland, Italy, Tonga, Cook Islands, Lebanon, Russia and South Africa. The current World Champions are Australia, who won the 2017 Rugby League World Cup. The next Rugby League World Cup will be held in October and November 2021 and hosted by England. This will be the first time that the Men's, Women's and Wheelchair competitions will be staged together.[42] The competition currently features 16 teams.
",3
3171,"The Asia-Pacific Rugby League Confederation's purpose is to spread the sport of rugby league throughout their region along with other governing bodies such as the ARL and NZRL.[43] Since rugby league was introduced to Australia in 1908,
it has become the largest television sport and 3rd most attended sport in Australia.[44] Neighbouring Papua New Guinea is one of two countries to have rugby league as its national sport (with Cook Islands).[6][7] Australia's elite club competition also features a team from Auckland, New Zealand's biggest city. Rugby league is the dominant winter sport in the eastern Australian states of New South Wales and Queensland.[45] The game is also among the predominant sports of Tonga[46] and is played in other Pacific nations such as Samoa and Fiji. Researchers have found that rugby league has been able to help with improving development in the islands.[47] In Australia, and indeed the rest of the region, the annual State of Origin series ranks among the most popular sporting events.[48][49]
",3
3172,"The Rugby League European Federation are responsible for developing rugby league in Europe and the Northern Hemisphere.[50]
",3
3173,"In England, rugby league has traditionally been associated with the northern counties of Yorkshire, Lancashire and Cumberland where the game originated, especially in towns along the M62 corridor.[8] Its popularity has also increased elsewhere.[51][52][53]  As of 2020[update], only one of the twelve Super League teams are based outside of these traditional counties: Catalans Dragons (Perpignan, France). One other team from outside the United Kingdom, the Toulouse Olympique, competes in the English Rugby League system, although not at the highest tier Super League level, but rather in the Rugby League Championship.
",3
3174,"Super League average attendances are in the 8,000 to 9,500 range. The average Super League match attendance in 2014 was 8,365.[54] In 2018 average Super League match attendance was 8,547.[55] Ranked the eighth most popular sport in the UK overall,[56] rugby league is the 27th most popular participation sport in England according to figures released by Sport England; the total number of rugby league participants in England aged 16 and over was 44,900 in 2017.[57] This is a 39% drop from 10 years ago.[57] While the sport is largely concentrated in the north of England there have been complaints about its lack of profile in the British media. On the eve of the 2017 Rugby League World Cup Final where England would face Australia, English amateur rugby league coach Ben Dawson stated, ""we’re in the final of a World Cup. First time in more than 30 years and there's no coverage anywhere"".[58]
",3
3175,"France first played rugby league as late as 1934, where in the five years prior to the Second World War, the sport's popularity increased as Frenchmen became disenchanted with the state of French rugby union in the 1930s.[59] However, after the Allied Forces were defeated by Germany in June 1940, the Vichy regime in the south seized assets belonging to rugby league authorities and clubs and banned the sport for its association with the left-wing Popular Front government that had governed France before the war.[59] The sport was unbanned after the Liberation of Paris in August 1944 and the collapse of the Vichy regime, although it was still actively marginalised by the French authorities until the 1990s.[59] Despite this, the national side appeared in the finals of the 1954 and 1968 World Cups, and the country hosted the 1954 event.[60][61] In 1996, a French team, Paris Saint-Germain was one of eleven teams which formed the new Super League, although the club was dissolved in 1997.[62] In 2006, the Super League admitted the Catalans Dragons, a team from Perpignan in the southern Languedoc-Roussillon region.[63] They have subsequently reached the 2007 Challenge Cup Final and made the playoffs of the 2008 Super League XIII season. The success of the Dragons in Super League has initiated a renaissance in French rugby league, with new-found enthusiasm for the sport in the south of the country where most of the Elite One Championship teams are based. In other parts of Europe, the game is played at semi-professional and amateur level.
",3
3176,"The Toronto Wolfpack are currently North America's only active professional Rugby League team, competing in the English Rugby League system. The Wolfpack won the 2017 Kingstone Press League 1 in their inaugural season and earned promotion to the 2018 Rugby League Championship. In 2019 The Wolfpack won promotion to the Super League. The Wolfpack play their home games at Lamport Stadium in Toronto.[64] Beginning in 2020, the English Hemel Stags will be relocated to Ottawa as the Ottawa Aces, where their home field will be TD Place Stadium.[65]
",3
3177,"The early 21st century has seen other countries take up the game and compete in international rugby league with the Rugby League European Federation and Asia-Pacific Rugby League Confederation expanding the game to new areas such as Chile, Canada, Ghana, Philippines, Czech Republic, Germany, Sweden, Norway, Spain, Hungary, Turkey, Thailand and Brazil to name a few.[66][67][68]
",3
3178,"The two most prominent full-time professional leagues are the Australian National Rugby League and the British Super League and to a lesser extent the semi professional French Elite One Championship and Elite Two Championship. 
",3
3179,"Domestic leagues, with some full-time exceptions, exist at a semi-professional level below the NRL and Super League, in Australia the Queensland Cup (which includes a team from Papua New Guinea) and NSW Cup, which provides players to various NRL teams.
",3
3180,"In the United Kingdom, below the Super League, are the Championship and League 1. The UK professional system includes two French teams and one Canadian team. The NRL contains one team from New Zealand.
",3
3181,"The Papua New Guinea National Rugby League operates as a semi-professional competition and enjoys nationwide media coverage, being the national sport of the country.
",3
3182,"The top five attendances for rugby league test matches (International) are:
",3
3183,"The top five attendances for domestic based rugby league matches are:
",3
3184,"* NRL double header played to open Round 1 of the 1999 NRL season. Figure shown is the total attendance which is officially counted for both games.[69][70]** The official attendance of the 1954 Challenge Cup Final replay was 102,569. Unofficial estimates put the attendance as high as 150,000, Bradford Police confirming 120,000.
",3
3185," Quotations related to Rugby league at Wikiquote
 The dictionary definition of Rugby league at Wiktionary
 Media related to Rugby league at Wikimedia Commons
",3
3186,"
",3
3187,"
",3
3188,"Tennis is a racket sport that can be played individually against a single opponent (singles) or between two teams of two players each (doubles). Each player uses a tennis racket that is strung with cord to strike a hollow rubber ball covered with felt over or around a net and into the opponent's court. The object of the game is to maneuver the ball in such a way that the opponent is not able to play a valid return. The player who is unable to return the ball will not gain a point, while the opposite player will.
",3
3189,"Tennis is an Olympic sport and is played at all levels of society and at all ages. The sport can be played by anyone who can hold a racket, including wheelchair users. The modern game of tennis originated in Birmingham, England, in the late 19th century as lawn tennis.[1] It had close connections both to various field (lawn) games such as croquet and bowls as well as to the older racket sport today called real tennis. During most of the 19th century, in fact, the term tennis referred to real tennis, not lawn tennis.
",3
3190,"The rules of modern tennis have changed little since the 1890s. Two exceptions are that from 1908 to 1961 the server had to keep one foot on the ground at all times, and the adoption of the tiebreak in the 1970s. A recent addition to professional tennis has been the adoption of electronic review technology coupled with a point-challenge system, which allows a player to contest the line call of a point, a system known as Hawk-Eye.
",3
3191,"Tennis is played by millions of recreational players and is also a popular worldwide spectator sport. The four Grand Slam tournaments (also referred to as the Majors) are especially popular: the Australian Open played on hard courts, the French Open played on red clay courts, Wimbledon played on grass courts, and the US Open also played on hard courts.
",3
3192,"Historians believe that the game's ancient origin lay in 12th century northern France, where a ball was struck with the palm of the hand.[2] Louis X of France was a keen player of jeu de paume (""game of the palm""), which evolved into real tennis, and became notable as the first person to construct indoor tennis courts in the modern style. Louis was unhappy with playing tennis outdoors and accordingly had indoor, enclosed courts made in Paris ""around the end of the 13th century"".[3] In due course this design spread across royal palaces all over Europe.[3] In June 1316 at Vincennes, Val-de-Marne and following a particularly exhausting game, Louis drank a large quantity of cooled wine and subsequently died of either pneumonia or pleurisy, although there was also suspicion of poisoning.[4] Because of the contemporary accounts of his death, Louis X is history's first tennis player known by name.[4] Another of the early enthusiasts of the game was King Charles V of France, who had a court set up at the Louvre Palace.[5]
",3
3193,"It was not until the 16th century that rackets came into use and the game began to be called ""tennis"", from the French term tenez, which can be translated as ""hold!"", ""receive!"" or ""take!"", an interjection used as a call from the server to his opponent.[6] It was popular in England and France, although the game was only played indoors where the ball could be hit off the wall. Henry VIII of England was a big fan of this game, which is now known as real tennis.[7] During the 18th and early 19th centuries, as real tennis declined, new racket sports emerged in England.[8]
",3
3194,"The invention of the first lawn mower in 1830, in Britain, is believed to have been a catalyst, for the preparation of modern-style grass courts, sporting ovals, playing fields, pitches, greens, etc. This in turn led to the codification of modern rules for many sports, including lawn tennis, most football codes, lawn bowls and others.[9]
",3
3195,"Between 1859 and 1865 Harry Gem, a solicitor and his friend Augurio Perera developed a game that combined elements of racquets and the Basque ball game pelota, which they played on Perera's croquet lawn in Birmingham in England.[10][11] In 1872, along with two local doctors, they founded the world's first tennis club on Avenue Road, Leamington Spa.[12] This is where ""lawn tennis"" was used as a name of activity by a club for the first time. After Leamington, the second club to take up the game of lawn tennis appears to have been the Edgbaston Archery and Croquet Society, also in Birmingham.
",3
3196,"In Tennis: A Cultural History, Heiner Gillmeister reveals that on 8 December 1874, British army officer Walter Clopton Wingfield wrote to Harry Gem, commenting that he (Wingfield) had been experimenting with his version of lawn tennis “for a year and a half”.[13] In December 1873, Wingfield designed and patented a game which he called sphairistikè (Greek: σφαιριστική, meaning ""ball-playing""), and was soon known simply as ""sticky"" – for the amusement of guests at a garden party on his friend's estate of Nantclwyd Hall, in Llanelidan, Wales.[14] According to R. D. C. Evans, turfgrass agronomist, ""Sports historians all agree that [Wingfield] deserves much of the credit for the development of modern tennis.""[8][15] According to Honor Godfrey, museum curator at Wimbledon, Wingfield ""popularized this game enormously. He produced a boxed set which included a net, poles, rackets, balls for playing the game – and most importantly you had his rules. He was absolutely terrific at marketing and he sent his game all over the world. He had very good connections with the clergy, the law profession, and the aristocracy and he sent thousands of sets out in the first year or so, in 1874.""[16] The world's oldest annual tennis tournament took place at Leamington Lawn Tennis Club in Birmingham in 1874.[17] This was three years before the All England Lawn Tennis and Croquet Club would hold its first championships at Wimbledon, in 1877. The first Championships culminated in a significant debate on how to standardise the rules.[16]
",3
3197,"In the U.S. in 1874 Mary Ewing Outerbridge, a young socialite, returned from Bermuda with a sphairistikè set. She became fascinated by the game of tennis after watching British army officers play.[18] She laid out a tennis court at the Staten Island Cricket Club at Camp Washington, Tompkinsville, Staten Island, New York. The first American National championship was played there in September 1880. An Englishman named O.E. Woodhouse won the singles title, and a silver cup worth $100, by defeating Canadian I. F. Hellmuth.[19] There was also a doubles match which was won by a local pair. There were different rules at each club. The ball in Boston was larger than the one normally used in New York.
",3
3198,"On 21 May 1881, the oldest nationwide tennis organization in the world[20] was formed, the United States National Lawn Tennis Association (now the United States Tennis Association) in order to standardize the rules and organize competitions.[21] The U.S. National Men's Singles Championship, now the US Open, was first held in 1881 at the Newport Casino, Newport, Rhode Island.[22] The U.S. National Women's Singles Championships were first held in 1887 in Philadelphia.[23]
",3
3199,"Tennis also became popular in France, where the French Championships dates to 1891 although until 1925 it was open only to tennis players who were members of French clubs.[24] Thus, Wimbledon, the US Open, the French Open, and the Australian Open (dating to 1905) became and have remained the most prestigious events in tennis.[25][26] Together these four events are called the Majors or Slams (a term borrowed from bridge rather than baseball).[27]
",3
3200,"In 1913, the International Lawn Tennis Federation (ILTF), now the International Tennis Federation (ITF), was founded and established three official tournaments as the major championships of the day. The World Grass Court Championships were awarded to Great Britain.  The World Hard Court Championships were awarded to France; the term ""hard court"" was used for clay courts at the time. Some tournaments were held in Belgium instead. And the World Covered Court Championships for indoor courts was awarded annually; Sweden, France, Great Britain, Denmark, Switzerland and Spain each hosted the tournament.[28] At a meeting held on 16 March 1923 in Paris, the title 'World Championship' was dropped and a new category of Official Championship was created for events in Great Britain, France, the United States, and Australia – today's Grand Slam events.[28][29] The impact on the four recipient nations to replace the ‘world championships’ with ‘official championships’ was simple in a general sense: each became a major nation of the federation with enhanced voting power and each now operated a major event.[28]
",3
3201,"The comprehensive rules promulgated in 1924 by the ILTF, have remained largely stable in the ensuing eighty years, the one major change being the addition of the tiebreak system designed by Jimmy Van Alen.[30] That same year, tennis withdrew from the Olympics after the 1924 Games but returned 60 years later as a 21-and-under demonstration event in 1984. This reinstatement was credited by the efforts by the then ITF President Philippe Chatrier, ITF General Secretary David Gray and ITF Vice President Pablo Llorens, and support from IOC President Juan Antonio Samaranch. The success of the event was overwhelming and the IOC decided to reintroduce tennis as a full medal sport at Seoul in 1988.[31][32]
",3
3202,"The Davis Cup, an annual competition between men's national teams, dates to 1900.[33] The analogous competition for women's national teams, the Fed Cup, was founded as the Federation Cup in 1963 to celebrate the 50th anniversary of the founding of the ITF.[34]
",3
3203,"In 1926, promoter C. C. Pyle established the first professional tennis tour with a group of American and French tennis players playing exhibition matches to paying audiences.[26][35] The most notable of these early professionals were the American Vinnie Richards and the Frenchwoman Suzanne Lenglen.[26][36] Once a player turned pro he or she was no longer permitted to compete in the major (amateur) tournaments.[26]
",3
3204,"In 1968, commercial pressures and rumors of some amateurs taking money under the table led to the abandonment of this distinction, inaugurating the Open Era, in which all players could compete in all tournaments, and top players were able to make their living from tennis. With the beginning of the Open Era, the establishment of an international professional tennis circuit, and revenues from the sale of television rights, tennis's popularity has spread worldwide, and the sport has shed its middle-class English-speaking image[37] (although it is acknowledged that this stereotype still exists).[37][38]
",3
3205,"In 1954, Van Alen founded the International Tennis Hall of Fame, a non-profit museum in Newport, Rhode Island.[39] The building contains a large collection of tennis memorabilia as well as a hall of fame honouring prominent members and tennis players from all over the world. Each year, a grass court tournament and an induction ceremony honoring new Hall of Fame members are hosted on its grounds.
",3
3206,"Part of the appeal of tennis stems from the simplicity of equipment required for play. Beginners need only a racket and balls.
",3
3207,"The components of a tennis racket include a handle, known as the grip, connected to a neck which joins a roughly elliptical frame that holds a matrix of tightly pulled strings. For the first 100 years of the modern game, rackets were made of wood and of standard size, and strings were of animal gut. Laminated wood construction yielded more strength in rackets used through most of the 20th century until first metal and then composites of carbon graphite, ceramics, and lighter metals such as titanium were introduced. These stronger materials enabled the production of oversized rackets that yielded yet more power. Meanwhile, technology led to the use of synthetic strings that match the feel of gut yet with added durability.
",3
3208,"Under modern rules of tennis, the rackets must adhere to the following guidelines;[40]
",3
3209,"The rules regarding rackets have changed over time, as material and engineering advances have been made. For example, the maximum length of the frame had been 32 inches (81 cm) until 1997, when it was shortened to 29 inches (74 cm).[41]
",3
3210,"Many companies manufacture and distribute tennis rackets. Wilson, Head and Babolat are three of the most commonly used brands; however, many more companies exist.[42] The same companies sponsor players to use these rackets in the hopes that the company name will become more well known by the public.
",3
3211,"Tennis balls were originally made of cloth strips stitched together with thread and stuffed with feathers.[43] Modern tennis balls are made of hollow vulcanized rubber with a felt coating. Traditionally white, the predominant colour was gradually changed to optic yellow in the latter part of the 20th century to allow for improved visibility. Tennis balls must conform to certain criteria for size, weight, deformation, and bounce to be approved for regulation play. The International Tennis Federation (ITF) defines the official diameter as 65.41–68.58 mm (2.575–2.700 in). Balls must weigh between 56.0 and 59.4 g (1.98 and 2.10 oz).[44] Tennis balls were traditionally manufactured in the United States and Europe. Although the process of producing the balls has remained virtually unchanged for the past 100 years, the majority of manufacturing now takes place in the Far East. The relocation is due to cheaper labour costs and materials in the region.[45] Tournaments that are played under the ITF Rules of Tennis must use balls that are approved by the International Tennis Federation (ITF) and be named on the official ITF list of approved tennis balls.[46]
",3
3212,"Advanced players improve their performance through a number of accoutrements. Vibration dampeners may be interlaced in the proximal part of the string array for improved feel. Racket handles may be customized with absorbent or rubber-like materials to improve the players' grip. Players often use sweat bands on their wrists to keep their hands dry and head bands or bandanas to keep the sweat out of their eyes as well. Finally, although the game can be played in a variety of shoes, specialized tennis shoes have wide, flat soles for stability and a built-up front structure to avoid excess wear.
",3
3213,"Tennis is played on a rectangular, flat surface. The court is 78 feet (23.77 m) long, and 27 feet (8.2 m) wide for singles matches and 36 ft (11 m) for doubles matches.[47] Additional clear space around the court is required in order for players to reach overrun balls. A net is stretched across the full width of the court, parallel with the baselines, dividing it into two equal ends. It is held up by either a cord or metal cable of diameter no greater than 0.8 cm (1⁄3 in).[48] The net is 3 feet 6 inches (1.07 m) high at the posts and 3 feet (0.91 m) high in the center.[47] The net posts are 3 feet (0.91 m) outside the doubles court on each side or, for a singles net, 3 feet (0.91 m) outside the singles court on each side.
",3
3214,"The modern tennis court owes its design to Major Walter Clopton Wingfield. In 1873, Wingfield patented a court much the same as the current one for his stické tennis (sphairistike). This template was modified in 1875 to the court design that exists today, with markings similar to Wingfield's version, but with the hourglass shape of his court changed to a rectangle.[49]
",3
3215,"Tennis is unusual in that it is played on a variety of surfaces.[50] Grass, clay, and hardcourts of concrete or asphalt topped with acrylic are the most common. Occasionally carpet is used for indoor play, with hardwood flooring having been historically used. Artificial turf courts can also be found.
",3
3216,"The lines that delineate the width of the court are called the baseline (farthest back) and the service line (middle of the court). The short mark in the center of each baseline is referred to as either the hash mark or the center mark. The outermost lines that make up the length are called the doubles sidelines; they are the boundaries for doubles matches. The lines to the inside of the doubles sidelines are the singles sidelines, and are the boundaries in singles play. The area between a doubles sideline and the nearest singles sideline is called the doubles alley, playable in doubles play. The line that runs across the center of a player's side of the court is called the service line because the serve must be delivered into the area between the service line and the net on the receiving side. Despite its name, this is not where a player legally stands when making a serve.[51]
",3
3217,"The line dividing the service line in two is called the center line or center service line. The boxes this center line creates are called the service boxes; depending on a player's position, they have to hit the ball into one of these when serving.[52] A ball is out only if none of it has hit the area inside the lines, or the line, upon its first bounce. All lines are required to be between 1 and 2 inches (25 and 51 mm) in width, with the exception of the baseline which can be up to 4 inches (100 mm) wide, although in practice it is often the same width as the others.[51]
",3
3218,"The players or teams start on opposite sides of the net. One player is designated the server, and the opposing player is the receiver. The choice to be server or receiver in the first game and the choice of ends is decided by a coin toss before the warm-up starts. Service alternates game by game between the two players or teams. For each point, the server starts behind the baseline, between the center mark and the sideline. The receiver may start anywhere on their side of the net. When the receiver is ready, the server will serve, although the receiver must play to the pace of the server.
",3
3219,"For a service to be legal, the ball must travel over the net without touching it into the diagonally opposite service box. If the ball hits the net but lands in the service box, this is a let or net service, which is void, and the server retakes that serve. The player can serve any number of let services in a point and they are always treated as voids and not as faults. A fault is a serve that falls long or wide of the service box, or does not clear the net. There is also a ""foot fault"" when a player's foot touches the baseline or an extension of the center mark before the ball is hit. If the second service, after a fault, is also a fault, the server double faults, and the receiver wins the point. However, if the serve is in, it is considered a legal service.
",3
3220,"A legal service starts a rally, in which the players alternate hitting the ball across the net. A legal return consists of a player hitting the ball so that it falls in the server's court, before it has bounced twice or hit any fixtures except the net. A player or team cannot hit the ball twice in a row. The ball must travel over or round the net into the other players' court. A ball that hits the net during a rally is considered a legal return as long as it crosses into the opposite side of the court. The first player or team to fail to make a legal return loses the point. The server then moves to the other side of the service line at the start of a new point.[53]
",3
3221,"A game consists of a sequence of points played with the same player serving. A game is won by the first player to have won at least four points in total and at least two points more than the opponent. The running score of each game is described in a manner peculiar to tennis: scores from zero to three points are described as ""love"", ""15"", ""30"", and ""40"", respectively. If at least three points have been scored by each player, making the player's scores equal at 40 apiece, the score is not called out as ""40–40"", but rather as ""deuce"". If at least three points have been scored by each side and a player has one more point than his opponent, the score of the game is ""advantage"" for the player in the lead. During informal games, ""advantage"" can also be called ""ad in"" or ""van in"" when the serving player is ahead, and ""ad out"" or ""van out"" when the receiving player is ahead; alternatively, either player may simply call out ""my ad"" or ""your ad"" during informal play.
",3
3222,"The score of a tennis game during play is always read with the serving player's score first. In tournament play, the chair umpire calls the point count (e.g., ""15-love"") after each point. At the end of a game, the chair umpire also announces the winner of the game and the overall score.
",3
3223,"A set consists of a sequence of games played with service alternating between games, ending when the count of games won meets certain criteria. Typically, a player wins a set by winning at least six games and at least two games more than the opponent. If one player has won six games and the opponent five, an additional game is played. If the leading player wins that game, the player wins the set 7–5. If the trailing player wins the game (tying the set 6–6) a tie-break is played. A tie-break, played under a separate set of rules, allows one player to win one more game and thus the set, to give a final set score of 7–6. A ""love"" set means that the loser of the set won zero games, colloquially termed a 'jam donut' in the US.[54] In tournament play, the chair umpire announces the winner of the set and the overall score. The final score in sets is always read with the winning player's score first, e.g. ""6–2, 4–6, 6–0, 7–5"".
",3
3224,"A match consists of a sequence of sets. The outcome is determined through a best of three or five sets system. On the professional circuit, men play best-of-five-set matches at all four Grand Slam tournaments, Davis Cup, and the final of the Olympic Games and best-of-three-set matches at all other tournaments, while women play best-of-three-set matches at all tournaments. The first player to win two sets in a best-of-three, or three sets in a best-of-five, wins the match.[55] Only in the final sets of matches at the French Open, the Olympic Games, and Fed Cup are tie-breaks not played. In these cases, sets are played indefinitely until one player has a two-game lead, occasionally leading to some remarkably long matches.
",3
3225,"In tournament play, the chair umpire announces the end of the match with the well-known phrase ""Game, set, match"" followed by the winning person's or team's name.
",3
3226,"A game point occurs in tennis whenever the player who is in the lead in the game needs only one more point to win the game. The terminology is extended to sets (set point), matches (match point), and even championships (championship point). For example, if the player who is serving has a score of 40-love, the player has a triple game point (triple set point, etc.) as the player has three consecutive chances to win the game. Game points, set points, and match points are not part of official scoring and are not announced by the chair umpire in tournament play.
",3
3227,"A break point occurs if the receiver, not the server, has a chance to win the game with the next point. Break points are of particular importance because serving is generally considered advantageous, with servers being expected to win games in which they are serving. A receiver who has one (score of 30–40 or advantage), two (score of 15–40) or three (score of love-40) consecutive chances to win the game has break point, double break point or triple break point, respectively. If the receiver does, in fact, win their break point, the game is awarded to the receiver, and the receiver is said to have converted their break point. If the receiver fails to win their break point it is called a failure to convert. Winning break points, and thus the game, is also referred to as breaking serve, as the receiver has disrupted, or broken the natural advantage of the server. If in the following game the previous server also wins a break point it is referred to as breaking back. Except where tie-breaks apply, at least one break of serve is required to win a set (otherwise a two-game lead would never occur).
",3
3228,"Another, however informal, tennis format is called Canadian doubles. This involves three players, with one person playing against a doubles team. The single player gets to utilize the alleys normally reserved only for a doubles team. Conversely, the doubles team does not use the alleys when executing a shot. The scoring is the same as for a regular game. This format is not sanctioned by any official body.
",3
3229,"""Australian doubles"", another informal and unsanctioned form of tennis, is played with similar rules to the Canadian doubles style, only in this version, players rotate court position after each game, each player taking a turn at playing alone against the other two. As such, each player plays doubles and singles over the course of a match, with the singles player always serving. Scoring styles vary, but one popular method is to assign a value of 2 points to each game, with the server taking both points if he or she holds serve and the doubles team each taking one if they break serve.
",3
3230,"Wheelchair tennis can be played by able-bodied players as well as people who require a wheelchair for mobility. An extra bounce is permitted. This rule makes it possible to have mixed wheelchair and able-bodied matches. It is possible for a doubles team to consist of a wheelchair player and an able-bodied player (referred to as ""one-up, one-down""), or for a wheelchair player to play against an able-bodied player. In such cases, the extra bounce is permitted for the wheelchair users only.
",3
3231,"In most professional play and some amateur competition, there is an officiating head judge or chair umpire (usually referred to simply as the umpire), who sits in a raised chair to one side of the court. The umpire has absolute authority to make factual determinations. The umpire may be assisted by line judges, who determine whether the ball has landed within the required part of the court and who also call foot faults. There also may be a net judge who determines whether the ball has touched the net during service. The umpire has the right to overrule a line judge or a net judge if the umpire is sure that a clear mistake has been made.[58]
",3
3232,"In past tournaments, line judges tasked with calling the serve were sometimes assisted by electronic sensors that beeped to indicate an out-of-bounds serve; one such system was called ""Cyclops"".[59] Cyclops has since largely been replaced by the Hawk-Eye system.[60][61] In professional tournaments using this system, players are allowed three unsuccessful appeals per set, plus one additional appeal in the tie-break to challenge close line calls by means of an electronic review. The US Open, Miami Masters, US Open Series, and World Team Tennis started using this challenge system in 2006 and the Australian Open and Wimbledon introduced the system in 2007.[62] In clay-court matches, such as at the French Open, a call may be questioned by reference to the mark left by the ball's impact on the court surface.
",3
3233,"The referee, who is usually located off the court, is the final authority about tennis rules. When called to the court by a player or team captain, the referee may overrule the umpire's decision if the tennis rules were violated (question of law) but may not change the umpire's decision on a question of fact. If, however, the referee is on the court during play, the referee may overrule the umpire's decision. (This would only happen in Davis Cup or Fed Cup matches, not at the World Group level, when a chair umpire from a non-neutral country is in the chair).[58]
",3
3234,"Ball boys and girls may be employed to retrieve balls, pass them to the players, and hand players their towels. They have no adjudicative role. In rare events (e.g., if they are hurt or if they have caused a hindrance), the umpire may ask them for a statement of what actually happened. The umpire may consider their statements when making a decision. In some leagues, especially junior leagues, players make their own calls, trusting each other to be honest. This is the case for many school and university level matches. The referee or referee's assistant, however, can be called on court at a player's request, and the referee or assistant may change a player's call. In unofficiated matches, a ball is out only if the player entitled to make the call is sure that the ball is out.
",3
3235,"In tennis, a junior is a player under 18 who is still legally protected by a parent or guardian. Players on the main adult tour who are under 18 must have documents signed by a parent or guardian. These players, however, are still eligible to play in junior tournaments.
",3
3236,"The International Tennis Federation (ITF) conducts a junior tour that allows juniors to establish a world ranking and an Association of Tennis Professionals (ATP) or Women's Tennis Association (WTA) ranking. Most juniors who enter the international circuit do so by progressing through ITF, Satellite, Future, and Challenger tournaments before entering the main circuit. The latter three circuits also have adults competing in them. Some juniors, however, such as Australian Lleyton Hewitt and Frenchman Gaël Monfils, have catapulted directly from the junior tour to the ATP tour by dominating the junior scene or by taking advantage of opportunities given to them to participate in professional tournaments.
",3
3237,"In 2004, the ITF implemented a new rankings scheme to encourage greater participation in doubles, by combining two rankings (singles and doubles) into one combined tally.[63] Junior tournaments do not offer prize money except for the Grand Slam tournaments, which are the most prestigious junior events. Juniors may earn income from tennis by participating in the Future, Satellite, or Challenger tours. Tournaments are broken up into different tiers offering different amounts of ranking points, culminating with Grade A.
",3
3238,"Leading juniors are allowed to participate for their nation in the Junior Fed Cup and Davis Cup competitions. To succeed in tennis often means having to begin playing at a young age. To facilitate and nurture a junior's growth in tennis, almost all tennis playing nations have developed a junior development system. Juniors develop their play through a range of tournaments on all surfaces, accommodating all different standards of play. Talented juniors may also receive sponsorships from governing bodies or private institutions.
",3
3239,"A tennis match is intended to be continuous.[64] Because stamina is a relevant factor, arbitrary delays are not permitted. In most cases, service is required to occur no more than 20 seconds after the end of the previous point.[64] This is increased to 90 seconds when the players change ends (after every odd-numbered game), and a 2-minute break is permitted between sets.[64] Other than this, breaks are permitted only when forced by events beyond the players' control, such as rain, damaged footwear, damaged racket, or the need to retrieve an errant ball. Should a player be deemed to be stalling repeatedly, the chair umpire may initially give a warning followed by subsequent penalties of ""point"", ""game"", and default of the match for the player who is consistently taking longer than the allowed time limit.[65]
",3
3240,"In the event of a rain delay, darkness or other external conditions halting play, the match is resumed at a later time, with the same score as at the time of the delay, and each player at the same end of the court as when rain halted play, or as close to the same relative compass point if play is resumed on a different court.
",3
3241,"Balls wear out quickly in serious play and, therefore, in ATP and WTA tournaments, they are changed after every nine games with the first change occurring after only seven games, because the first set of balls is also used for the pre-match warm-up.[44] In ITF tournaments like Fed Cup, the balls are changed after every eleven games (rather than nine) with the first change occurring after only nine games (instead of seven). An exception is that a ball change may not take place at the beginning of a tiebreaker, in which case the ball change is delayed until the beginning of the second game of the next set.[48] As a courtesy to the receiver, the server will often signal to the receiver before the first serve of the game in which new balls are used as a reminder that they are using new balls. Continuity of the balls' condition is considered part of the game, so if a re-warm-up is required after an extended break in play (usually due to rain), then the re-warm-up is done using a separate set of balls, and use of the match balls is resumed only when play resumes.
",3
3242,"A recent rule change is to allow coaching on court on a limited basis during a match.[66][67][68][69] This has been introduced in women's tennis for WTA Tour events in 2009 and allows the player to request her coach once per set.[70]
",3
3243,"Stance refers to the way a player prepares themselves in order to best be able to return a shot. Essentially, it enables them to move quickly in order to achieve a particular stroke. There are four main stances in modern tennis: open, semi-open, closed, and neutral. All four stances involve the player crouching in some manner: as well as being a more efficient striking posture, it allows them to isometrically preload their muscles in order to play the stroke more dynamically. What stance is selected is strongly influenced by shot selection. A player may quickly alter their stance depending on the circumstances and the type of shot they intend to play. Any given stance also alters dramatically based upon the actual playing of the shot with dynamic movements and shifts of body weight occurring.[71][72]
",3
3244,"This is the most common stance in tennis. The player's feet are placed parallel to the net. They may be pointing sideways, directly at the net or diagonally towards it. This stance allows for a high degree of torso rotation which can add significant power to the stroke. This process is sometimes likened to the coiling and uncoiling of a spring. i.e. the torso is rotated as a means of preloading the muscular system in preparation for playing the stroke: this is the coiling phase. When the stroke is played the torso rotates to face forwards again, called uncoiling, and adds significant power to the stroke. A disadvantage of this stance is that it does not always allow ‘for proper weight transfer and maintenance of balance’[71] when making powerful strokes. It is commonly used for forehand strokes; double-handed backhands can also be made effectively from it.
",3
3245,"This stance is somewhere between open and closed and is a very flexible stance. The feet are aligned diagonally towards the net. It allows for a lot of shoulder rotation and the torso can be coiled, before being uncoiled into the shot in order to increase the power of the shot. It is commonly used in modern tennis especially by ‘top professional players on the forehand’.[73] Two-handed backhands can also be employed from this stance.
",3
3246,"The closed stance is the least commonly used of the three main stances. One foot is placed further towards the net with the other foot further from it; there is a diagonal alignment between the feet.  It allows for effective torso rotation in order to increase the power of the shot. It is usually used to play backhand shots and it is rare to see forehand shots played from it. A stroke from this stance may entail the rear foot coming completely off the floor with bodyweight being transferred entirely to the front foot.[71]
[72]
",3
3247,"This is sometimes also referred to as the square stance. One foot is positioned closer to the net and ahead of the other which is  behind and in line with it. Both feet are aligned at a 90 degree angle to the net. The neutral stance is often taught early because ‘It allows beginners to learn about shifting weight and rotation of the body.’[72] Forehands and backhands may be made from it.[74]
",3
3248,"A competent tennis player has eight basic shots in his or her repertoire: the serve, forehand, backhand, volley, half-volley, overhead smash, drop shot, and lob.
",3
3249,"A grip is a way of holding the racket in order to hit shots during a match. The grip affects the angle of the racket face when it hits the ball and influences the pace, spin, and placement of the shot. Players use various grips during play, including the Continental (The ""Handshake Grip""), Eastern (Can be either semi-eastern or full eastern. Usually used for backhands.), and Western (semi-western or full western, usually for forehand grips) grips. Most players change grips during a match depending on what shot they are hitting; for example, slice shots and serves call for a Continental grip.[75]
",3
3250,"A serve (or, more formally, a ""service"") in tennis is a shot to start a point. The serve is initiated by tossing the ball into the air and hitting it (usually near the apex of its trajectory) into the diagonally opposite service box without touching the net. The serve may be hit under- or overhand although underhand serving remains a rarity.[76] If the ball hits the net on the first serve and bounces over into the correct diagonal box then it is called a ""let"" and the server gets two more additional serves to get it in. There can also be a let if the server serves the ball and the receiver isn't prepared.[48] If the server misses his or her first serve and gets a let on the second serve, then they get one more try to get the serve in the box.
",3
3251,"Experienced players strive to master the conventional overhand serve to maximize its power and placement. The server may employ different types of serve including flat serve, topspin serve, slice serve, and kick (American twist) serve. A reverse type of spin serve is hit in a manner that spins the ball opposite the natural spin of the server, the spin direction depending upon right- or left-handedness. If the ball is spinning counterclockwise, it will curve right from the hitter's point of view and curve left if spinning clockwise.[77]
",3
3252,"Some servers are content to use the serve simply to initiate the point; however, advanced players often try to hit a winning shot with their serve. A winning serve that is not touched by the opponent is called an ""ace"".
",3
3253,"For a right-handed player, the forehand is a stroke that begins on the right side of the body, continues across the body as contact is made with the ball, and ends on the left side of the body. There are various grips for executing the forehand, and their popularity has fluctuated over the years. The most important ones are the continental, the eastern, the semi-western, and the western. For a number of years, the small, frail 1920s player Bill Johnston was considered by many to have had the best forehand of all time, a stroke that he hit shoulder-high using a western grip. Few top players used the western grip after the 1920s, but in the latter part of the 20th century, as shot-making techniques and equipment changed radically, the western forehand made a strong comeback and is now used by many modern players. No matter which grip is used, most forehands are generally executed with one hand holding the racket, but there have been fine players with two-handed forehands. In the 1940s and 50s, the Ecuadorian/American player Pancho Segura used a two-handed forehand to achieve a devastating effect against larger, more powerful players. Players such as Monica Seles or France's Fabrice Santoro and Marion Bartoli are also notable players known for their two-handed forehands.[78]
",3
3254,"For right-handed players, the backhand is a stroke that begins on the left side of their body, continues across their body as contact is made with the ball, and ends on the right side of their body. It can be executed with either one hand or with both and is generally considered more difficult to master than the forehand. For most of the 20th century, the backhand was performed with one hand, using either an eastern or a continental grip. The first notable players to use two hands were the 1930s Australians Vivian McGrath and John Bromwich, but they were lonely exceptions. The two-handed grip gained popularity in the 1970s as Björn Borg, Chris Evert, Jimmy Connors, and later Mats Wilander and Marat Safin used it to great effect, and it is now used by a large number of the world's best players, including Rafael Nadal and Serena Williams.[79]
",3
3255,"Two hands give the player more control, while one hand can generate a slice shot, applying backspin on the ball to produce a low trajectory bounce. Reach is also limited with the two-handed shot. The player long considered to have had the best backhand of all time, Don Budge, had a powerful one-handed stroke in the 1930s and 1940s that imparted topspin onto the ball. Ken Rosewall, another player noted for his one-handed backhand, used a very accurate slice backhand through the 1950s and 1960s. A small number of players, notably Monica Seles, use two hands on both the backhand and forehand sides.
",3
3256,"A volley is a shot returned to the opponent in mid-air before the ball bounces, generally performed near the net, and is usually made with a stiff-wristed punching motion to hit the ball into an open area of the opponent's court. The half volley is made by hitting the ball on the rise just after it has bounced, also generally in the vicinity of the net, and played with the racket close to the ground.[80] The swinging volley is hit out of the air as the player approaches the net. It is an offensive shot used to take preparation time away from the opponent, as it returns the ball into the opponent's court much faster than a standard volley.
",3
3257,"From a poor defensive position on the baseline, the lob can be used as either an offensive or defensive weapon, hitting the ball high and deep into the opponent's court to either enable the lobber to get into better defensive position or to win the point outright by hitting it over the opponent's head. If the lob is not hit deeply enough into the other court, however, an opponent near the net may then hit an overhead smash, a hard, serve-like shot, to try to end the point.
",3
3258,"A difficult shot in tennis is the return of an attempted lob over the backhand side of a player. When the contact point is higher than the reach of a two-handed backhand, most players will try to execute a high slice (under the ball or sideways). Fewer players attempt the backhand sky-hook or smash. Rarely, a player will go for a high topspin backhand, while themselves in the air. A successful execution of any of these alternatives requires balance and timing, with less margin of error than the lower contact point backhands, since this shot is a break in the regular pattern of play.
",3
3259,"If their opponent is deep in their court, a player may suddenly employ an unexpected drop shot, by softly tapping the ball just over the net so that the opponent is unable to run in fast enough to retrieve it. Advanced players will often apply back spin to a drop shot, causing the ball to ""skid"" upon landing and bounce sideways, with less forward momentum toward their opponent, or even backwards towards the net, thus making it even more difficult to return.
",3
3260,"Muscle strain is one of the most common injuries in tennis.[81] When an isolated large-energy appears during the muscle contraction and at the same time body weight apply huge amount of pressure to the lengthened muscle, muscle strain can occur.[82] Inflammation and bleeding are triggered when muscle strain occurs, which can result in redness, pain and swelling.[82] Overuse is also common in tennis players of all levels. Muscle, cartilage, nerves, bursae, ligaments and tendons may be damaged from overuse. The repetitive use of a particular muscle without time for repair and recovery is the most common cause of injury.[82]
",3
3261,"Tournaments are often organized by gender and number of players. Common tournament configurations include men's singles, women's singles, and doubles, where two players play on each side of the net. Tournaments may be organized for specific age groups, with upper age limits for youth and lower age limits for senior players. Example of this include the Orange Bowl and Les Petits As junior tournaments. There are also tournaments for players with disabilities, such as wheelchair tennis and deaf tennis.[83] In the four Grand Slam tournaments, the singles draws are limited to 128 players for each gender.
",3
3262,"Most large tournaments seed players, but players may also be matched by their skill level. According to how well a person does in sanctioned play, a player is given a rating that is adjusted periodically to maintain competitive matches. For example, the United States Tennis Association administers the National Tennis Rating Program (NTRP), which rates players between 1.0 and 7.0 in 1/2 point increments. Average club players under this system would rate 3.0–4.5 while world class players would be 7.0 on this scale.
",3
3263,"The four Grand Slam tournaments are considered to be the most prestigious tennis events in the world. They are held annually and comprise, in chronological order, the Australian Open, the French Open, Wimbledon, and the US Open. Apart from the Olympic Games, Davis Cup, Fed Cup, and Hopman Cup, they are the only tournaments regulated by the International Tennis Federation (ITF).[84] The ITF's national associations, Tennis Australia (Australian Open), the Fédération Française de Tennis (French Open), the Lawn Tennis Association (Wimbledon) and the United States Tennis Association (US Open) are delegated the responsibility to organize these events.[84]
",3
3264,"Aside from the historical significance of these events, they also carry larger prize funds than any other tour event and are worth double the number of ranking points to the champion than in the next echelon of tournaments, the Masters 1000 (men) and Premier events (women).[85][86] Another distinguishing feature is the number of players in the singles draw. There are 128, more than any other professional tennis tournament. This draw is composed of 32 seeded players, other players ranked in the world's top 100, qualifiers, and players who receive invitations through wild cards. Grand Slam men's tournaments have best-of-five set matches while the women play best-of-three. Grand Slam tournaments are among the small number of events that last two weeks, the others being the Indian Wells Masters and the Miami Masters.
",3
3265,"Currently, the Grand Slam tournaments are the only tour events that have mixed doubles contests. Grand Slam tournaments are held in conjunction with wheelchair tennis tournaments and junior tennis competitions. These tournaments also contain their own idiosyncrasies. For example, players at Wimbledon are required to wear predominantly white. Andre Agassi chose to skip Wimbledon from 1988 through 1990 citing the event's traditionalism, particularly its ""predominantly white"" dress code.[87] Wimbledon has its own particular methods for disseminating tickets, often leading tennis fans to follow complex procedures to obtain tickets.[88]
",3
3266,"* The international tournament began in 1925
",3
3267,"The ATP World Tour Masters 1000 is a group of nine tournaments that form the second-highest echelon in men's tennis. Each event is held annually, and a win at one of these events is worth 1000 ranking points. When the ATP, led by Hamilton Jordan, began running the men's tour in 1990, the directors designated the top nine tournaments, outside of the Grand Slam events, as ""Super 9"" events.[89] In 2000 this became the Tennis Masters Series and in 2004 the ATP Masters Series. In November at the end of the tennis year, the world's top eight players compete in the ATP World Tour Finals, a tournament with a rotating locale. It is currently held in London, England.[90]
",3
3268,"In August 2007 the ATP announced major changes to the tour that were introduced in 2009. The Masters Series was renamed to the ""Masters 1000"", the addition of the number 1000 referring to the number of ranking points earned by the winner of each tournament. Contrary to earlier plans, the number of tournaments was not reduced from nine to eight and the Monte Carlo Masters remains part of the series although, unlike the other events, it does not have a mandatory player commitment. The Hamburg Masters has been downgraded to a 500-point event. The Madrid Masters moved to May and onto clay courts, and a new tournament in Shanghai took over Madrid's former indoor October slot. As of 2011 six of the nine ""1000"" level tournaments are combined ATP and WTA events.[91]
",3
3269,"The third and fourth tier of men's tennis tournaments are formed by the ATP World Tour 500 series, consisting of 11 tournaments, and the ATP World Tour 250 series with 40 tournaments.[92] Like the ATP World Tour Masters 1000, these events offer various amounts of prize money and the numbers refer to the amount of ranking points earned by the winner of a tournament.[85] The Dubai Tennis Championships offer the largest financial incentive to players, with total prize money of US$2,313,975 (2012).[93] These series have various draws of 28, 32, 48 and 56 for singles and 16 and 24 for doubles. It is mandatory for leading players to enter at least four 500 events, including at least one after the US Open.
",3
3270,"The Challenger Tour for men is the lowest level of tournament administered by the ATP. It is composed of about 150 events and, as a result, features a more diverse range of countries hosting events.[94] The majority of players use the Challenger Series at the beginning of their career to work their way up the rankings. Andre Agassi, between winning Grand Slam tournaments, plummeted to World No. 141 and used Challenger Series events for match experience and to progress back up the rankings.[95] The Challenger Series offers prize funds of between US$25,000 and US$150,000.
",3
3271,"Below the Challenger Tour are the Futures tournaments, events on the ITF Men's Circuit. These tournaments also contribute towards a player's ATP rankings points. Futures Tournaments offer prize funds of between US$10,000 and US$15,000.[96] Approximately 530 Futures Tournaments are played each year.
",3
3272,"Premier events for women form the most prestigious level of events on the Women's Tennis Association Tour after the Grand Slam tournaments. These events offer the largest rewards in terms of points and prize money. Within the Premier category are Premier Mandatory, Premier 5, and Premier tournaments. The Premier events were introduced in 2009 replacing the previous Tier I and II tournament categories. Currently four tournaments are Premier Mandatory, five tournaments are Premier 5, and twelve tournaments are Premier. The first tiering system in women's tennis was introduced in 1988. At the time of its creation, only two tournaments, the Lipton International Players Championships in Florida and the German Open in Berlin, comprised the Tier I category.
",3
3273,"International tournaments are the second main tier of the WTA tour and consist of 31 tournaments, with a prize money for every event at U.S.$220,000, except for the year-ending Commonwealth Bank Tournament of Champions in Bali, which has prize money of U.S.$600,000.
",3
3274,"Professional tennis players enjoy the same relative perks as most top sports personalities: clothing, equipment and endorsements. Like players of other individual sports such as golf, they are not salaried, but must play and finish highly in tournaments to obtain prize money.
",3
3275,"In recent years, some controversy has surrounded the involuntary or deliberate noise caused by players' grunting.[citation needed]
",3
3276,"While players are gradually less competitive in singles by their late 20s and early 30s, they can still continue competitively in doubles (as instanced by Martina Navratilova and John McEnroe, who won doubles titles in their 40s).
",3
3277,"In the Open Era, several female players such as Martina Navratilova, Margaret Court, Martina Hingis, Serena Williams, and Venus Williams (the latter two sisters playing together) have been prolific at both singles and doubles events throughout their careers. John McEnroe is one of the very few professional male players to be top ranked in both singles and doubles at the same time,[97][98][99] and Yevgeny Kafelnikov is the most recent male player to win multiple Grand Slams in both singles and doubles during the same period of his career.
",3
3278,"In terms of public attention and earnings (see below), singles champions have far surpassed their doubles counterparts. The Open Era, particularly the men's side, has seen many top-ranked singles players that only sparingly compete in doubles, while having ""doubles specialists"" who are typically being eliminated early in the singles draw but do well in the doubles portion of a tournament. Notable doubles pairings include The Woodies (Todd Woodbridge and Mark Woodforde) and the Bryan Brothers (identical twin brothers Robert Charles ""Bob"" Bryan and Michael Carl ""Mike"" Bryan). Woodbridge has disliked the term ""doubles ‘specialists’"", saying that he and Woodforde ""set a singles schedule and doubles fitted in around that"", although later in Woodbridge's career he focused exclusively on doubles as his singles ranking fell too low that it was no longer financially viable to recover at that age. Woodbridge noted that while top singles players earn enough that they don't need to nor want to play doubles, he suggested that lower-ranked singles players outside the Top Ten should play doubles to earn more playing time and money.[100][101]
",3
3279,"The Olympics doubles tennis tournament necessitates that both members of a doubles pairing be from the same country, hence several top professional pairs such as Jamie Murray and Bruno Soares cannot compete in the Olympics. Top-ranked singles players that are usually rivals on the professional circuit, such as Boris Becker and Michael Stich, and Roger Federer and Stan Wawrinka have formed a rare doubles partnership for the Olympics. Unlike professional tennis tournaments (see below) where singles players receive much more prize money than doubles players, an Olympic medal for both singles and doubles has similar prestige. The Olympics is more of a priority for doubles champions while singles champions often skip the tournament.[100][101] While the ATP has voted for Olympic results to count towards player ranking points, WTA players voted against it.[102]
",3
3280,"For the 2000 Olympics, Lisa Raymond was passed over for Team USA in favor of Serena Williams by captain Billie Jean King, even though Raymond was the top-ranked doubles player in the world at the time, and Raymond unsuccessfully challenged the selection.[102]
",3
3281,"In professional tennis tournaments such as Wimbledon, the singles competition receives the most prize money and coverage, followed by doubles, and then mixed doubles usually receive the lowest monetary awards.[103] For instance in the US Open as of 2018, the men's and women's singles prize money (US$40,912,000) accounts for 80.9 percent of total player base compensation, while men's and women's doubles (US$6,140,840), men's and women's singles qualifying (US$3,008,000), and mixed doubles (US$505,000) account for 12.1 percent, 5.9 percent, and 1.0 percent, respectively. The singles winner receives US$3,800,000, while the doubles winning pair receives $700,000 and the mixed doubles winning pair receives US$155,000.[104]
",3
3282,"The following players have won at least five singles titles at Grand Slam tournaments:
",3
3283,"
",3
3284,"
",3
3285,"
",3
3286,"A frequent topic of discussion among tennis fans and commentators is who was the greatest male singles player of all time. By a large margin, an Associated Press poll in 1950 named Bill Tilden as the greatest player of the first half of the 20th century.[105] From 1920 to 1930, Tilden won singles titles at Wimbledon three times and the U.S. Championships seven times. In 1938, however, Donald Budge became the first person to win all four major singles titles during the same calendar year, the Grand Slam, and won six consecutive major titles in 1937 and 1938. Tilden called Budge ""the finest player 365 days a year that ever lived.""[106] In his 1979 autobiography, Jack Kramer said that, based on consistent play, Budge was the greatest player ever.[107] Some observers, however, also felt that Kramer deserved consideration for the title. Kramer was among the few who dominated amateur and professional tennis during the late 1940s and early 1950s. Tony Trabert has said that of the players he saw before the start of the Open Era, Kramer was the best male champion.[108]
",3
3287,"By the 1960s, Budge and others had added Pancho Gonzales and Lew Hoad to the list of contenders. Budge reportedly believed that Gonzales was the greatest player ever.[109] Gonzales said about Hoad, ""When Lew's game was at its peak nobody could touch him. ... I think his game was the best game ever. Better than mine. He was capable of making more shots than anybody. His two volleys were great. His overhead was enormous. He had the most natural tennis mind with the most natural tennis physique.""[110]
",3
3288,"Before and during the Open Era, Rod Laver remains the only male player in history to have won the calendar year Grand Slam twice in 1962 and 1969 [111] and also the calendar year Professional Grand Slam in 1967.[112]
",3
3289,"Jimmy Connors, Björn Borg, and John McEnroe had a fierce rivalry in late 1970s and early 1980s that propelled ""the men's game to new heights of popularity"".[113]  Connors had a long and prolific career and holds the Open Era men's singles records of 109 titles including eight Grand Slams, 1,557 matches played, and 1,274 match wins.  Borg was regarded by his contemporaries as among the greatest ever, having a calm court demeanor and unrivalled physical conditioning, winning six French Opens and five straight Wimbledon titles, retiring at age 26 when he was still in his prime.  McEnroe attained the No. 1 ranking in both singles and doubles, finishing his career with 77 singles and 78 doubles titles; this remains the highest men's combined total of the Open Era. [114]
",3
3290,"The Agassi–Sampras rivalry was the best rivalry of the 1990s. Andre Agassi, the first of two male players in history to have achieved a Career Golden Slam in singles tennis (followed by Rafael Nadal), has been called the best service returner in the history of the game.[115][116][117][118] Agassi was the first man to win grand slams on all modern surfaces (previous holders of all grand slam tournaments played in an era of grass and clay only), and is regarded by a number of critics and fellow players to be among the greatest players of all time.[115][119][120] Both Rod Laver and Ken Rosewall also won major Pro Slam tournaments on all three surfaces (grass, clay, hard court) Rosewall in 1963 and Laver in 1967.[121] Pete Sampras had a precise and powerful serve, set the record of six year-end No.1 finishes (matched by Novak Djokovic, albeit Sampras did so consecutively), and was the first player to break Roy Emerson's record of twelve Grand Slams. Sampras retired with a then-Open era record of fourteen Grand Slam titles which was by far the most among his contemporaries, as the second-most Slams held at the time by another active player was Agassi with seven. 
",3
3291,"By the early twenty-first century, the ""Big Three"" of Roger Federer, Rafael Nadal and Novak Djokovic had dominated.[122][123]
Roger Federer is considered by many observers to have the most ""complete"" game in modern tennis. He has won 20 grand slam titles and 6 World Tour Finals, the most for any male player. Many experts of tennis, former tennis players and his own tennis peers believe Federer is the greatest player in the history of the game.[124][125][126][127][128][129] Federer's biggest rival Rafael Nadal is regarded as the greatest competitor in tennis history by some former players and is regarded to have the potential to be the greatest of all time.[130][131] Nadal is regarded as the greatest clay court player of all time.[132] Novak Djokovic is also considered to be one of the greatest tennis players of all time and the most dominant of the 2010s decade, being the first male player since Rod Laver in 1969 to hold all four major titles at once, the only player to achieve the Career Golden Masters, and amassing a superior head-to-head record against Federer and Nadal.[133]
",3
3292,"As with the men there are frequent discussions about who is the greatest female singles player of all time with Steffi Graf, Martina Navratilova and Serena Williams being the three players most often nominated.
",3
3293,"In March 2012 the TennisChannel published a combined list of the 100 greatest men and women tennis players of all time.[134] It ranked Steffi Graf as the greatest female player (in 3rd place overall), followed by Martina Navratilova (4th place) and Margaret Court (8th place). The rankings were determined by an international panel.
",3
3294,"Sportswriter John Wertheim of Sports Illustrated stated in an article in July 2010 that Serena Williams is the greatest female tennis player ever with the argument that ""Head-to-head, on a neutral surface (i.e. hard courts), everyone at their best, I can't help feeling that she crushes the other legends."".[135] In a reaction to this article Yahoo sports blog Busted Racket published a list of the top-10 women's tennis players of all time placing Martina Navratilova in first spot.[136] This top-10 list was similar to the one published in June 2008 by the Bleacher Report who also ranked Martina Navratilova as the top female player of all time.[137]
",3
3295,"Steffi Graf is considered by some to be the greatest female player. Billie Jean King said in 1999, ""Steffi is definitely the greatest women's tennis player of all time.""[138] Martina Navratilova has included Graf on her list of great players.[138] In December 1999, Graf was named the greatest female tennis player of the 20th century by a panel of experts assembled by the Associated Press.[139] Tennis writer Steve Flink, in his book The Greatest Tennis Matches of the Twentieth Century, named her as the best female player of the 20th century, directly followed by Martina Navratilova.[140]
",3
3296,"Tennis magazine selected Martina Navratilova as the greatest female tennis player for the years 1965 through 2005.[141][142] Tennis historian and journalist Bud Collins has called Navratilova ""arguably, the greatest player of all time.""[143] Billie Jean King said about Navratilova in 2006, ""She's the greatest singles, doubles and mixed doubles player who's ever lived.""[144]
",3
3297,"
",3
3298,"
",3
3299,"Roger Federer (German pronunciation: [ˈrɔdʒər ˈfeːdərər]; born 8 August 1981) is a Swiss professional tennis player. He is ranked No. 6 in the world by the Association of Tennis Professionals (ATP). He has won 20 Grand Slam men's singles titles, an all-time record shared with Rafael Nadal. Federer has been world No. 1 in the ATP rankings a total of 310 weeks – including a record 237 consecutive weeks – and has finished as the year-end No. 1 five times. Federer has won 103 ATP singles titles, the second-most of all-time behind Jimmy Connors and including a record six ATP Finals.
",3
3300,"Federer has played in an era where he dominated men's tennis together with Nadal and Novak Djokovic, who have been collectively referred to as the Big Three and are widely considered three of the greatest male tennis players of all-time.[c] A Wimbledon junior champion in 1998, Federer won his first Grand Slam singles title at Wimbledon in 2003 at age 21. In 2004, he established himself as the best player in men's tennis by winning three out of four major singles titles and the ATP Finals,[d] a feat he repeated in 2006 and 2007. From 2005 to 2010, Federer made 18 out of 19 major singles finals. During this span, he won his fifth consecutive titles at both Wimbledon and the US Open. He completed the career Grand Slam at the 2009 French Open after three previous runner-ups to Nadal, his main rival up until 2010. At age 27, he also surpassed Pete Sampras's then-record of 14 Grand Slam men's singles titles at Wimbledon in 2009.
",3
3301,"Although Federer remained in the top 3 through most of the 2010s, the success of Djokovic and Nadal in particular ended his dominance over grass and hard courts. From mid-2010 through the end of 2016, he only won one major title. During this period, Federer and Stan Wawrinka led the Switzerland Davis Cup team to their first title in 2014, adding to the gold medal they won together in doubles at the 2008 Beijing Olympics. Federer also has a silver medal in singles from the 2012 London Olympics, where he finished runner-up to Andy Murray. After taking half a year off in late 2016 to recover from knee surgery, Federer had a renaissance at the majors. He won three more Grand Slam singles titles over the next two years, including the 2017 Australian Open over Nadal and a men's singles record eighth Wimbledon title in 2017 later that year. He also became the oldest ATP world No. 1 in 2018 at age 36.
",3
3302,"A versatile all-court player, Federer's perceived effortlessness has made him highly popular among tennis fans. Originally lacking self-control as a junior, Federer transformed his on-court demeanor to become well-liked for his general graciousness, winning the Stefan Edberg Sportsmanship Award 13 times. He has also won the Laureus World Sportsman of the Year award a record five times. Outside of competing, he played an instrumental role in the creation of the Laver Cup team competition. Federer is also an active philanthropist. He established the Roger Federer Foundation, which targets impoverished children in southern Africa, and has raised funds in part through the Match for Africa exhibition series. Federer is routinely one of the highest-paid athletes in any sport, and ranked first among all athletes with $100 million in endorsement income in 2020.
",3
3303,"Federer was born in Basel, Switzerland.[3] His Swiss father, Robert Federer, is from Berneck in the Canton of St. Gallen, and his  Afrikaner mother, Lynette Federer (née Durand), is from Kempton Park, Gauteng, in South Africa. Federer has one sibling, his older sister, Diana,[4] who is the mother of a set of twins.[5] Since his mother is South African, he holds both Swiss and South African citizenship.[6] He grew up in nearby Birsfelden, Riehen, and then Münchenstein, close to the French and German borders, and he speaks Swiss German, Standard German, English, and French fluently, as well as functional Italian and Swedish; Swiss German is his native language.[3][7][8][9] Federer served as a ball boy at his hometown Basel tournament, the Swiss Indoors, in 1992 and 1993.[7][10]
",3
3304,"Like all male Swiss citizens, Federer was subject to compulsory military service in the Swiss Armed Forces. However, in 2003 he was ruled ""unsuitable"" and was subsequently not required to fulfill his military obligation.[11] Instead, he served in the civil protection force and was required to pay 3% of his taxable income as an alternative.[12] He grew up supporting FC Basel and the Swiss national football team.[13] Federer also credits his hand-eye coordination to the wide range of sports he played as a child, including badminton and basketball.[14]
",3
3305,"Federer is married to former Women's Tennis Association player Miroslava Federer (née Vavrinec), whom he met while they were both competing for Switzerland at the 2000 Sydney Olympics. Usually called Mirka, she retired from the tour in 2002 because of a foot injury.[15] They were married at Wenkenhof Villa in Riehen near Basel on 11 April 2009, surrounded by a small group of close friends and family.[16] In 2009, Mirka gave birth to identical twin girls.[17] The Federers had another pair of identical twins in 2014, this time boys.[18][19]
",3
3306,"Federer's main accomplishments as a junior player came at Wimbledon in 1998, where he won both the boys' singles final over Irakli Labadze,[20] and in doubles teamed with Olivier Rochus, defeating the team of Michaël Llodra and Andy Ram.[21] In addition, Federer reached the US Open Junior final in 1998, losing to David Nalbandian. He won four ITF junior singles tournaments in his career, including the prestigious Orange Bowl, where he defeated Guillermo Coria in the final.[22] He ended 1998 with the No. 1 junior world ranking, was awarded ITF junior World Champion, and entered his first tournament as a professional during 1998 in Gstaad, where he lost to Lucas Arnold Ker in the first round.[23]
",3
3307,"Federer entered the top 100 ranking for the first time on 20 September 1999 and started at the 1999 Marseille Open defeating the reigning champion of the 1998 French Open, Spaniard Carlos Moyá. His first final came at the Marseille Open in 2000, where he lost to fellow Swiss Marc Rosset.[24] Federer won the 2001 Hopman Cup representing Switzerland, along with world No. 1 Martina Hingis.[25][26][27] The duo defeated the American pair of Monica Seles and Jan-Michael Gambill in the finals. Federer later said that his experience with Hingis ""definitely helped me to become the player I am today.""[28]
",3
3308,"Federer's first singles win was at the 2001 Milan Indoor tournament, where he defeated Julien Boutter in the final.[24][29] Although he won his first title already in 1999 on the Challenger tour, winning the doubles event in Segovia, Spain with Dutchman Sander Groen, the final was played on Federer's 18th birthday. In 2001, Federer made his first Grand Slam quarterfinal at the French Open, losing to former world No. 2 and eventual finalist Alex Corretja. His run to the French quarterfinals launched him into the top 15 for the first time in his career.[30][31]
",3
3309,"His international breakthrough came at the 2001 Wimbledon Championships, where the 19-year-old Federer faced the four-time defending champion and all-time Grand Slam leader Pete Sampras. Federer beat the No. 1 seed in a five-set match to reach the quarterfinals.[32] In the quarters he faced Englishman Tim Henman, eventually losing in a fourth-set tiebreaker.[33]
",3
3310,"The first final he reached at the Masters level came at the 2002 Miami Masters event, where he lost to former and future No. 1 Andre Agassi on hard court.[34][35] Federer won his first Master Series event at the 2002 Hamburg Masters on clay, over Marat Safin; the victory put him in top 10 for the first time.[34][36] Federer made 10 singles finals between 1998 and 2002, of which he won four and lost six.[24][34][37][38][30] He also made six finals in doubles. He finished 2001 with an ATP ranking of No. 13, and 2002 was the first year he was ranked within the top 10, finishing at No. 6.[36]
",3
3311,"In 2003, Federer won his first Grand Slam singles title at Wimbledon, beating Andy Roddick in the semifinals and Mark Philippoussis in the final.[39] In August he had a chance to take over the No. 1 ranking for the first time from Andre Agassi if he made it to the Montreal final. However, he fell in the semifinals to Roddick, in a final-set tiebreaker, leaving him 120 points behind Agassi.[2] This, coupled with early losses to David Nalbandian at Cincinnati and the US Open, denied Federer the chance to become No. 1 for the duration of the season.[40]
",3
3312,"Federer won his first and to date only doubles Masters Series 1000 event in Miami with Max Mirnyi[41] and made it to one singles Masters Series 1000 event in Rome on clay, which he lost.[42][43] Federer made it to nine finals on the ATP Tour and won seven of them, including the 500 series events at Dubai and Vienna.[42] Lastly, Federer won the year-end championships over Andre Agassi, finishing the year as world No. 2, narrowly behind Andy Roddick by only 160 points.[42][44]
",3
3313,"During 2004, Federer won three Grand Slam singles titles for the first time in his career and became the first person to do so since Mats Wilander in 1988. His first major hard-court title came at the Australian Open over Marat Safin, thereby becoming the world No. 1 for the first time.[45] He then won his second Wimbledon crown over Andy Roddick.[46] Federer defeated the 2001 US Open champion, Lleyton Hewitt, at the US Open for his first title there.[47]
",3
3314,"Federer won three ATP Masters Series 1000 events, one was on clay in Hamburg, and the other two were on hard surfaces at Indian Wells and in Canada.[47] Federer took the ATP 500 series event at Dubai and wrapped up the year by winning the year-end championships for the second time.[47] He also won his first tournament on home soil by capturing the Swiss Open in Gstaad. His 11 singles titles were the most of any player in two decades, and his record of 74–6 was the best since Ivan Lendl in 1986.[48] He reached the year-end No. 1 ranking for the first time.[49]
",3
3315,"In 2005, Federer failed to reach the finals of the first two Grand Slam tournaments, losing the Australian Open semifinal to eventual champion Safin after holding match points, and the French Open semifinal to eventual champion Rafael Nadal.[50] However, Federer quickly reestablished his dominance on grass, winning the Wimbledon Championships over Andy Roddick.[51] At the US Open, Federer defeated Andre Agassi in the latter's last major final.[52][53]
",3
3316,"Federer also took four ATP Masters Series 1000 wins: Indian Wells, Miami and Cincinnati on hard court, and Hamburg on clay.[52] The win in Miami was particularly noteworthy as it was the first final contested between Federer and Nadal. Federer recovered from two sets and a break down to take the final in five sets. Furthermore, Federer won two ATP 500 series events at Rotterdam and Dubai.[52] Federer lost the year-end championships to David Nalbandian in five sets while playing through a foot injury that sidelined him for almost the rest of the season after September.[54] He maintained his position as No. 1 for the entire season.[52]
",3
3317,"Federer won 11 singles titles, which ties his 2004 season. Federer's 81 match victories were the most since Pete Sampras in 1993, and his record of 81–4 (95.2%) remains the third-best winning percentage in the Open Era behind John McEnroe's 1984 and Jimmy Connors's 1974.[48]
",3
3318,"The 2006 season was statistically the best season of Federer's career. In November 2011, Stephen Tignor, chief editorial writer for Tennis.com, ranked Federer's 2006 season as statistically the second-best season of all time during the Open Era, behind Rod Laver's Grand Slam year of 1969.[55]
",3
3319,"Federer won 12 singles titles (the most of any player since Thomas Muster in 1995 and John McEnroe in 1984) and had a match record of 92–5 (the most wins since Ivan Lendl in 1982). Federer reached the finals in an astounding 16 of the 17 tournaments he entered during the season.[56]
",3
3320,"In 2006, Federer won three Grand Slam singles titles and reached the final of the other, with the only loss coming against Nadal in the French Open.[56] This was Federer and Nadal's first meeting in a Grand Slam final. He was the first man to reach all four finals in a calendar year since Rod Laver in 1969. Federer defeated Nadal in the Wimbledon Championships final. In the Australian Open, Federer defeated Marcos Baghdatis,[57] and at the US Open, Federer defeated Roddick (2003 champion).[56] In addition, Federer made it to six ATP Masters Series 1000 finals, winning four on hard surfaces and losing two on clay to Nadal. Federer, however, consistently pushed Nadal to the limit on clay throughout the season taking him to fourth-set tiebreakers in Monte-Carlo and Paris, and a thrilling match in Rome that went to a deciding fifth-set tiebreaker.[58]
",3
3321,"Federer won one ATP 500 series event in Tokyo and captured the year-end championships for the third time in his career, again finishing the year as world No. 1.[57] Federer only lost to two players during 2006, to Nadal four times in finals, and to 19-year-old Andy Murray in the second round of the 2006 Cincinnati Masters, in what was Federer's only defeat before reaching the final of a tournament that year.[59] Federer finished the season on a 29-match winning streak, as well as winning 48 of his last 49 matches after the French Open.[60]
",3
3322,"Near the end of the season he won his hometown tournament, the Swiss Indoors in Basel, Switzerland for the first time, having finished runner up in 2000 and 2001, and missing the tournament in 2004 and 2005 due to injuries.[61]
",3
3323,"In 2007, Federer reached all four Grand Slam singles finals, winning three of them again. He won the Australian Open without dropping a set, beating Fernando González in the final. This made him the first man in the 21st century to accomplish the feat, as Björn Borg at the 1980 French Open was the last to win a Grand Slam tournament without the loss of a set.[62] Federer had entered the year on a huge winning streak and after capturing his fourth Dubai crown Federer's winning streak stood at 41 matches, the longest of his career and only five shy of the record. Federer entered Indian Wells as the three-time defending champion, but his streak ended in controversy. He was defeated by an Argentine, Guillermo Cañas, who had failed a drug test for illegal doping.[63]
",3
3324,"This surprising first-round defeat marked the first time since August 2006 he suffered defeat, a period spanning over seven months.[64]
",3
3325,"During the clay season, Federer's victory in the Hamburg Masters final was particularly impressive, as it snapped Nadal's 81-match winning streak on clay, an Open-era record. Federer turned the match around from a set down to sweep 12 of the final 14 games, including a final set bagel.[65] At the French Open, some anticipated that Federer could become the first man in almost 40 years to hold all four majors simultaneously, having just resoundingly defeated young rival Nadal on clay entering the tournament. However, in a repeat of the previous year Federer played a tough four-set final against Nadal, but was undone by going 1/17 on break-point chances.[66]
",3
3326,"At Wimbledon, Federer entered the tournament not only as the four-time defending champion, but also riding a 48-match winning streak on grass. Once again, he defeated Rafael Nadal for a second consecutive year in the final, this time in a thrilling five-set encounter that many analysts hailed as the greatest Wimbledon final since 1980. Victory at Wimbledon equaled him with Björn Borg for the record of five consecutive championships at the All England Club.[67]
",3
3327,"Federer reached the final in Montreal before playing a young and relatively unknown Serbian named Novak Djokovic. Djokovic proved his potential by beating the world No. 1 in a final-set tiebreaker upset. Federer rebounded in Cincinnati to capture his fifth title of the year. Federer entered the US Open as the three-time defending champion and faced Djokovic in the final. This time, Federer prevailed in a close straight-set match.[68] Victory in New York moved him ahead of Laver and Borg for third on the all-time list of major championship victories. Throughout the tournament, the American press labelled him Darth Federer for his all-black attire (which included tuxedo-striped shorts) and the tournament played The Imperial March from Star Wars when he was announced onto the court for each of his matches.[69] He closed out the year with victories in Basel and the Year End Championships in Shanghai.[70]
",3
3328,"He finished the season as the year-end No. 1 for the fourth year in a row, demonstrating his dominance, and during these four years he won 11 Grand Slam singles titles. After his phenomenal triple Grand Slam season yet again, Federer became the only player in history to win three majors in a year for three years (2004, 2006, 2007).[71][72][73][74] It was the third consecutive season that Federer held the No. 1 ranking for all 52 weeks of the year.[49]
",3
3329,"Federer's success in 2008 was severely hampered by a lingering bout of mononucleosis, which he suffered during the first half of the year.[75] At the end of the year he suffered a back injury.[76]
",3
3330,"In 2008, Federer captured one Grand Slam, a singles title at the US Open over Andy Murray.[77] Federer was defeated by Nadal in two Grand Slam finals, the French Open and Wimbledon, which was regarded as the best match of tennis history by many, when he was going for six straight wins to break Björn Borg's record. He came back from two sets down to force a fifth set, where he fell just two points from the title.[77] At the Australian Open, Federer lost in the semifinals to eventual winner Djokovic, which ended his record of 10 consecutive finals.[77] He lost twice in Masters Series 1000 finals on clay to Nadal, at Monte Carlo and Hamburg.[77] Federer captured three titles in 250-level events at Estoril, Halle, and Basel.[78][79][80]
",3
3331,"At the Olympic Games, Federer and Stan Wawrinka won the gold medal in doubles, after beating the Bryan brothers American team in the semifinals and the Swedish duo of Simon Aspelin and Thomas Johansson in the final.[81] However, Federer could reach only the quarterfinals in the singles draw, bowing out to then No. 8 James Blake, ceding his No. 1 ranking to Nadal after being at the top for a record 237 consecutive weeks.[82] He ended the year ranked No. 2.[83]
",3
3332,"Federer entered the 2009 season with 13 Grand Slams, only one behind Pete Sampras' all-time record. The season began with a loss to Nadal in the final of the Australian Open in a hotly contested five-set match.[84] Federer struggled following the defeat in Melbourne and entered the clay season without a title.[85]
",3
3333,"Federer's season turned around in the final masters event of the clay season when he defeated Nadal on clay for only the second time to capture the Madrid Masters.[86] Federer entered the French Open with few predicting him to win the elusive Parisian title having lost to Nadal in the final weekend for the past four seasons. After Nadal's unexpected defeat to Robin Söderling, Federer became the overwhelming favorite. In his next match, he came from two sets and break point down in the third set to defeat Tommy Haas in five sets.[87] He also fought back from a two-sets-to-one deficit against a young Juan Martín del Potro to win a five setter in the semifinals.[88] In the final, he faced Söderling, and with straight sets victory, he finally captured the Coupe des Mousquetaires and career Grand Slam.[89] This victory also tied him with Pete Sampras for the most Grand Slam singles titles.[90][89]
",3
3334,"Federer turned his sights to the grass courts of Wimbledon, where he breezed his way up to the final.[91] In the championship match he faced long-time rival Andy Roddick in what was their eighth and final meeting at a Grand Slam. Roddick pushed Federer into a record-setting fifth set, which Federer claimed 16–14 to win his 15th Grand Slam singles title, breaking the all-time record of Pete Sampras.[92][93]
",3
3335,"Federer continued his summer run by winning his third title on the lightning-fast courts of the Cincinnati Masters, defeating Novak Djokovic in the final.[94] At the US Open he defeated Söderling in the quarters and Djokovic, for the third consecutive year, in the semifinals. On the penultimate point of the Djokovic match he hit what many consider to be the greatest shot of his career, a tweener winner, to set up match points.[95] Federer was defeated by del Potro in the final despite leading two sets to one and falling just two points from the title in the fourth set.[94]
",3
3336,"The 2009 season was perhaps the most historically relevant of Federer's career as he completed a career Grand Slam by winning his first French Open title and won a men's record fifteenth Grand Slam singles title at Wimbledon, surpassing Pete Sampras's mark of fourteen.[94] The Wimbledon final was also historic for being the longest Grand Slam final in terms of games played with Federer prevailing 16–14 in the fifth set.[93]
",3
3337,"Federer finished the season as the year-end No. 1 for the fifth time in his career.[96]
",3
3338,"Federer started the year with a win at the Australian Open,[97] where he defeated Andy Murray in the final, extending the Grand Slam singles record to sixteen titles and matching Andre Agassi's record of four Australian Open titles.[77] Since Wimbledon 2005 Federer had made 18 out of 19 finals in Grand Slam tournaments, a period of sustained excellence unparalleled in the Open Era. This tournament, however, marked the end of his dominance at the majors.[98]
",3
3339,"At the French Open, Federer won his 700th tour match and 150th tour match on clay.[97][99] However, he failed to reach a Grand Slam semifinal for the first time since the 2004 French Open,[100] losing to Söderling in the last 8 and relinquishing his No. 1 ranking,[97] having been just one week away from equalling Pete Sampras's record of 286 weeks as world No. 1. In a huge upset at Wimbledon, Federer lost in the last 8 again to Tomáš Berdych and fell to No. 3 in the rankings for the first time in 6 years and 8 months.[97][101][102]
",3
3340,"Towards the middle of July, Federer hired Pete Sampras' old coach Paul Annacone on a trial basis to put his tennis game and career back on track.[103] At the 2010 US Open, Federer reached the semifinals, where he lost a five-set match to Novak Djokovic after holding two match points.[97] Federer made it to four Masters 1000 finals, prevailing at the Cincinnati Masters against Mardy Fish.[104]
",3
3341,"Federer finished the year in strong form, winning indoor titles at the Stockholm Open, Swiss Indoors, and the ATP World Tour Finals in London, which brought his tally to 66 career titles. Federer won the year-end championships in London by beating rival Rafael Nadal for his fifth title at the event.[105] He beat all contenders except Nadal in straight sets. It remains the only tournament in his career where Federer defeated all fellow members of the Big Four.[106] In 2010 Federer finished in the top two for the eighth consecutive season.[107]
",3
3342,"The year 2011 was a lean year for Federer, although great by most player's standards. He was defeated in straight sets in the semifinals of the 2011 Australian Open by eventual champion Novak Djokovic,[108] marking the first time since July 2003 that he did not hold any of the four major titles. In the French Open semifinals, Federer ended Djokovic's undefeated streak of 43 consecutive wins with a four-set victory.[109] Federer then lost in the final to Rafael Nadal.[110] At Wimbledon, Federer advanced to his 29th consecutive Grand Slam quarterfinal, losing to Jo-Wilfried Tsonga. It marked the first time in his career that he had lost a Grand Slam tournament match after winning the first two sets.[111]
",3
3343,"At the US Open, Federer lost in the semifinals to Novak Djokovic in five sets. In a repeat of previous year's semifinal event, Federer again squandered two match points on his own serve before losing after winning first two sets for second consecutive time in the year. The loss meant that it was the first time since 2002 that Federer had not won any of the four grand slam titles.[112]
",3
3344,"In September 2011, in a South African poll, Federer was voted the second most trusted and respected person in the world, next to Nelson Mandela.[113][114]
",3
3345,"Federer finished the season successfully in the indoor season, winning his last three tournaments of the year at the Swiss Indoors, Paris Masters, and ATP World Tour Finals, forming a 16 match winning streak. Federer finished the year ranked No. 3.[115]
",3
3346,"The 2012 season for Federer had his most match wins since 2006 and his highest winning percentage and number of titles won since 2007.[116]
",3
3347,"Federer reached the semifinal of the 2012 Australian Open, setting up a 27th career meeting with Nadal, a match he lost in four sets.[117]
He then won the Rotterdam Open for the first time since 2005, defeating Juan Martín del Potro.[118] Federer played in the 2012 Dubai Tennis Championships, where he defeated Andy Murray in the final and won the championship title for the fifth time in his career.[119] Federer then moved on to the Indian Wells Masters, where he defeated Rafael Nadal in the semifinals, and John Isner in the final. Federer won the title for a record fourth time, and, in doing so, equalled Nadal's record of 19 ATP Masters 1000 titles.[120]
",3
3348,"Federer went on to compete at the Madrid Masters on the new blue clay surface, where he beat Tomáš Berdych in the final, thus regaining the No. 2 ranking from Rafael Nadal. In the French Open, Federer made the semifinals before losing to Djokovic in straight sets, in a rematch of previous year's semifinal.[121][122]
",3
3349,"At Wimbledon, Federer had a five-set match in the third round against Julien Benneteau on his way to the winning the tournament. Federer defeated Andy Murray in four sets in the 2012 Wimbledon final,[123] regaining the No. 1 ranking in the process.[124] ""It's amazing. It equals me with Pete Sampras, who's my hero. It just feels amazing"", Federer said of winning his seventh Wimbledon championship, tying Sampras' Open Era record.[125] By defeating top-ranked Djokovic in the semifinals and winning in the finals, Federer returned to the top spot in the world rankings and, in doing so, broke Sampras' record of 286 weeks atop the list.[126]
",3
3350,"In the 2012 Summer Olympics, Federer played a 4-hour 26-minute semifinal against del Potro where Federer won 19–17 in the third and final set.[127] In a lopsided match, he lost to Murray in straight sets in the final, winning a silver medal for his country.[128]
",3
3351,"Federer won the Cincinnati open in August, beating Novak Djokovic in the final.[129] In the US Open, five-time champ Federer was defeated by Tomáš Berdych in the quarterfinals.[130]
",3
3352,"At the Shanghai Masters, after defeating Wawrinka in the third round, Federer confirmed his 300th week at No. 1. Federer made it to the finals of the ATP Finals, where he lost to Djokovic in two sets.[131][132]
",3
3353,"Federer developed back injuries in March and July and his ranking dropped from No. 2 to No. 6.[133][134] Federer's first and only title of 2013 came at the Gerry Weber Open (defeating Mikhail Youzhny), where he also played doubles with good friend Tommy Haas. With the victory in Halle, he tied John McEnroe for the third-most ATP titles won by a male player in the Open Era.[135] Federer, however, was unable to maintain his form into Wimbledon, suffering his worst Grand Slam tournament defeat since 2003 in the second round against Sergiy Stakhovsky. Not only did the loss end Federer's record streak of 36 consecutive quarterfinals at Grand Slam tournaments,[136] it meant he would drop out of the top 4 for the first time since July 2003.[137]
",3
3354,"During the summer, he experimented with various different racquets and played the German Open with a blacked-out 98-inch Wilson racquet, instead of his regular Pro Staff 6.1 90 BLX racquet with the smaller 90-inch hitting area. He returned to his regular racquet for the second half of the season.[138][139] After Wimbledon, Federer continued to be upset early in tournaments in Hamburg and Gstaad because of a serious back injury through October, when he announced that he was parting ways with Paul Annacone, his coach for the last three years.[140] Federer made the final in Basel, succumbing to Juan Martín del Potro in three sets, and indicated it was a mistake to have played certain tournaments while suffering from a back injury.[141]
",3
3355,"On 27 December 2013, Federer announced that Stefan Edberg was joining his team as co-coach with Severin Lüthi.[142]
",3
3356,"Federer began the season by changing rackets for the first time in his career, from his longtime frame of 90 square inches to one measured at 97 square inches. He had long been at a comparative disadvantage in equipment as almost the entire tour, including his top rivals Nadal and Djokovic, used more powerful frames of between 95 and 100 square inches.[138][143] At the Australian Open, Federer defeated Jo-Wilfried Tsonga and Andy Murray to reach his 11th consecutive semifinal in Melbourne, before losing to Rafael Nadal in straight sets.[144]
",3
3357,"At the Dubai Tennis Championships, he defeated Novak Djokovic in the semifinals, and then defeated Tomáš Berdych in the final to win his sixth Dubai crown and his first title since Halle in 2013.[145] Federer made the final at the Indian Wells Masters, but lost to Novak Djokovic in a final-set tiebreaker.[146] At the Davis Cup quarterfinals, Federer won both of his singles rubbers against Kazakhstan, the second of which was the first live deciding rubber of his Davis Cup career.[147] Federer then took a wild card into the Monte-Carlo Masters defeating Novak Djokovic on his way to the finals, but lost to compatriot Stan Wawrinka in a tight final.[148]
",3
3358,"In June, Federer announced that after the end of his third term, he would resign as President of the ATP Players Council, a position he had held since 2008.[149][150][151] At the Halle Open, Federer reached both the singles and the doubles finals and won his seventh Halle singles title, beating Alejandro Falla in the final.[152] At Wimbledon, Federer reached a record ninth final, but he was defeated by Djokovic in an epic five-set match.[153][154]
",3
3359,"Federer made the final of the Canadian Open but was defeated by Jo-Wilfried Tsonga.[155] Federer defeated Spain's David Ferrer in three sets to capture his sixth Cincinnati crown and 22nd ATP World Tour Masters 1000 title, his first in Cincinnati since 2012.[156] He then reached the semifinals at the US Open but lost in straight sets to eventual champion Marin Čilić.[157] At the Davis Cup semifinals, Federer won both his singles matches against Italy in straight sets and led Switzerland to the final for the first time since 1992.[158]
",3
3360,"Federer then played in the Shanghai Masters. He beat Novak Djokovic in the semifinals, ending the Serb's 28-match unbeaten run on Chinese soil. He battled Frenchman Gilles Simon in his second Shanghai final, defeating him in two tiebreak sets and collected the 23rd Masters 1000 title of his career.[159] The victory saw Federer return to the No. 2 ranking for the first time since May 2013. Federer then played the Swiss Indoors in October, where he won a record sixth title and his 82nd ATP men's singles title overall. Federer also reached the finals of the 2014 ATP World Tour Finals to face Djokovic again, but withdrew from the final because of another back injury from his semifinal match against Stan Wawrinka.[160]
",3
3361,"Despite his injury, Federer finished the season on a high by defeating Richard Gasquet to clinch the Davis Cup for Switzerland for the first time in its history.[161] The final was held at the Stade Pierre-Mauroy in Lille, France attracting over 27,000 spectators per match; this broke attendance record for the highest ever officially sanctioned competition tennis match.[162]
",3
3362,"Federer started his season at the Brisbane International. He defeated Milos Raonic in the final, thereby becoming only the third man in the Open Era to have 1,000 or more wins, joining Jimmy Connors and Ivan Lendl, as well as the first man in the Open Era to win at least one title in each of 15 consecutive years.[163] In Dubai, Federer successfully defended his title with a straight-set victory over Novak Djokovic in the final, marking his seventh title at the tournament and, after Wimbledon and Halle, was the third time he had won seven or more titles in a tournament.[164] Additionally, Federer became the fourth person since 1991 to surpass 9,000 career aces.[165] In March, he reached the final of the Indian Wells, but lost in three sets to defending champion Djokovic.[166]
",3
3363,"Federer won his third title of the season at the inaugural Istanbul Open clay-court tournament, ending a title drought on red clay since the 2009 French Open. Federer made it to the final of the Italian Open in May, but was unable to win his first title there, losing to Djokovic in the final.[167] In the French Open he made it through the first rounds losing just one set, to Gaël Monfils in the 4th. In the quarterfinals, he was eventually beaten in straight sets by the later champion Stan Wawrinka.[168]
",3
3364,"As the new expanded grass season began, Federer won his record eighth Gerry Weber Open and become only the third man in the Open Era to win a title eight times.[169]
Federer entered Wimbledon as the second seed. He played a flawless match to defeat Andy Murray in straight sets in the semifinals and advance to his 10th Wimbledon final in a repeat against Novak Djokovic. Federer lost the match in four sets.[170]
",3
3365,"He defeated Andy Murray and Novak Djokovic in straight sets to win the Cincinnati Masters for the seventh time. This marked the first time that Federer had beaten the top two players in the world at the same tournament.[171] At the US Open, he advanced to his first final there since 2009 without dropping a set, including a win over Stan Wawrinka in the semifinals.[172] In the final, he was once again defeated by top seed Djokovic in four sets.[173] At the Swiss Indoors tournament in Basel, Federer won his sixth singles title of the year, and his 88th ATP title, defeating his old rival Rafael Nadal in the final.[174] It was the seventh time he had captured his hometown tournament.[175]
",3
3366,"In December, Federer announced that he would enter the 2016 ATP World Tour season with a new-look coaching team, having additionally announced that Stefan Edberg would not be travelling with him next year. While countryman Severin Lüthi remained Federer's head coach, joining the team in 2016 was Croatian former world No. 3 player Ivan Ljubicic. Federer revealed that Edberg originally signed on to the coaching team for one season only in 2014, but agreed to stay on in 2015.[176]
",3
3367,"Federer started his season in the Brisbane International as the defending champion, despite having a virus when the tournament started. However, in a rematch of the previous year's final, he lost in the final to Milos Raonic in straight sets.[177] Federer then participated at the 2016 Australian Open and rebounded from his third round defeat by Andreas Seppi in 2015 by reaching the semifinals but lost to eventual champion Novak Djokovic in four sets.[178] The day after his loss to Djokovic, Federer sustained a knee injury and in early February, he underwent arthroscopic surgery to repair a torn meniscus in his knee and missed the tournaments in Rotterdam, Dubai and Indian Wells in February and March. He was scheduled to return to action in Miami.[179] Due to a stomach virus he had to withdraw from Miami thus prolonging his time on the sidelines.[180]
",3
3368,"Federer made his comeback at the Monte-Carlo Masters, losing in the quarterfinals to Jo-Wilfried Tsonga in three sets. In Madrid, he suffered a back injury during practice and withdrew shortly after arriving. He then participated in the Internazionali BNL d'Italia where he lost in the third round to Dominic Thiem. His withdrawal from the French Open broke a record run of 65 consecutive participations in the main draw of Grand Slam tournaments, stretching back to the 2000 Australian Open.[181]
",3
3369,"Still suffering from recurring knee pain during the grass season he lost in the semifinals of Stuttgart and Halle. On 6 July, he came back from two sets down to defeat Marin Čilić in five sets in the 2016 Wimbledon quarterfinals, equalling Jimmy Connors' all-time records of eleven Wimbledon semifinals and 84 match wins.[182] He suffered his first defeat in a Wimbledon semifinal two days later in a five-set loss to Raonic, re-injuring his knee in the fifth set.[183]
",3
3370,"On 26 July, Federer announced that he would miss the 2016 Summer Olympics and the remainder of the 2016 season to fully recover from his knee injury.[184] The sudden withdrawal not only implied that 2016 was his first season since 2000 that Federer failed to win a title, but it also meant that he would have to drop out of top ten for the first time in fourteen years. This, combined with a grand slam drought spanning over four years, led to many analysts believing that his outstanding career was finally coming to an end and he would never win any major titles again.[185][186]
",3
3371,"Federer's 2017 season marked a return to Grand Slam wins since 2012, the most titles since 2007, and the highest win percentage since 2006. Statistically, this season was his best since 2007.[187][188]
Federer played in the Hopman Cup and Australian Open in January 2017.[189] His withdrawal from most of the injury affected 2016 season lead his ranking slip to No. 17 at the start of Australian Open, his lowest in over fifteen years. At the Australian Open, he beat top-10 players Tomáš Berdych and Kei Nishikori on his way to semifinals, making Federer the oldest man to compete in a grand slam semi-final since Jimmy Connors in 1991.[190] In the semi-finals, he defeated Stanislas Wawrinka in five sets, making him the oldest player to compete in a Grand Slam final since Ken Rosewall in 1974.[191][192] Coming back from a break down in the fifth set, Federer defeated Rafael Nadal to win the Australian Open, which also marked Federer's 100th match at the Australian Open; it was the first time Federer had won a match against Nadal in a Grand Slam event since the 2007 Wimbledon final, and also marked Federer's first ever Grand Slam victory over Nadal outside the grass courts of Wimbledon. With this victory, he re-entered the top ten.[193][194][195]
",3
3372,"In March, Federer won his 25th Masters title at Indian Wells, defeating Wawrinka in the final and gaining another victory over Nadal in the 4th round. This was also Federer's 90th career title and he climbed to No. 6 in the ATP rankings.[196] Federer collected his 26th Masters title by defeating Nadal in the final of the Miami Masters in straight sets and climbed to No. 4 in the ATP rankings. This marked the third time Federer had won in Indian Wells and Miami back-to-back, colloquially referred to as the Sunshine Double (2005, 2006 and 2017).[197]
",3
3373,"Due to concerns about his longevity, Federer decided that he would skip the entire clay-court season.[198] He returned to the tour at the beginning of the grass-court season in Stuttgart, where he suffered a shock defeat to Tommy Haas in the second round despite holding match points, the lowest-ranked player (No. 302) to beat him since No. 407 Bjoern Phau in 1999.[199] He rebounded the following week by winning a record-extending ninth title at the Gerry Weber Open in Halle, doing so without the loss of a set.[200] In the 2017 Wimbledon Championships, Federer made it to the final without dropping a set, defeating Milos Raonic in the quarterfinals and Tomáš Berdych in the semifinals. In the final, Federer defeated a physically and mentally out of sorts Marin Čilić in straight sets to win a record-breaking eighth Wimbledon gentlemen's singles title and his record-extending 19th major title overall, becoming the oldest male player to win Wimbledon in the Open era.[201] Federer became the second man in the Open era to win Wimbledon without dropping a set after Björn Borg in 1976.[202] It marked the second time in his career that he had won a grand slam tournament without losing a set, matching his performance at the 2007 Australian Open.[203] Federer moved up to become No. 3 in the ATP Rankings after the event and qualified for the ATP Finals for a record 15th time.[204]
",3
3374,"At the opening of the summer hard court swing Federer was defeated in the final of the Montreal Masters by Alexander Zverev after injuring his back during the match.[205] Due to the injury, he opted to withdraw from the Cincinnati Masters to be fit for the US Open. However, Federer lost to del Potro in the quarterfinals at the US Open, in a tournament characterized by inconsistent play from Federer, unlike the major portion of the season.[206]
",3
3375,"Federer's next participation was in September in the inaugural Laver Cup, representing team Europe. Federer won both his singles matches against Sam Querrey and Nick Kyrgios, with the latter win sealing the cup for Europe.[207] The tournament was also notable for Federer playing doubles teaming with longtime rival Nadal for the first time. The two legends emerged victorious against world duo of Sam Querrey and Jack Sock.[208]
",3
3376,"At the Shanghai Masters, Federer captured his third Masters title of the season, defeating No. 1 Rafael Nadal in the final. This was Federer's fifth straight victory over Nadal in their rivalry and his 94th career title, drawing him level with 2nd-placed Ivan Lendl.[209] During the indoor season, Federer defeated Juan Martin Del Potro in the final of his hometown tournament, the Swiss Indoors in Basel, earning a record eighth championship there and winning his 95th career title, surpassing Ivan Lendl in number of career titles.[210] Federer qualified for the 2017 ATP Finals, but was beaten by David Goffin in the semifinals in three sets.[211]
",3
3377,"Federer started his season winning the Hopman Cup partnering with Belinda Bencic. This was his second Hopman Cup title, having won previously in 2001 with Martina Hingis.[212] At the 2018 Australian Open, Federer reached the final without dropping a set, and successfully defended his title beating Marin Čilić in a five-set final. This was Federer's sixth title at the Australian Open, equaling the then record held by Roy Emerson and Novak Djokovic, which was surpassed by Djokovic in 2019. He also became the first man to win twenty Grand Slam titles. It was also the first time since the 2008 US Open that Federer successfully defended a major title.[213]
",3
3378,"In mid-February, Federer won his third Rotterdam Open title to return to No. 1 in the ATP rankings, clinching the spot with a quarterfinal victory over Robin Haase.[214] He beat Grigor Dimitrov in straight sets in the final. At 36 years and 195 days of age, he became the oldest ATP world No. 1 by more than three years. He also broke the ATP record for the longest span between a player's first and last weeks to attain the No. 1 ranking at 14 years and 17 days apart, as well as the most time between two successive reigns at No. 1 at 5 years and 106 days.[215]
",3
3379,"In March, Federer entered the Indian Wells Masters as the defending champion. He defeated Chung Hyeon in the quarterfinals, ensuring that he retained the world No. 1 ranking, and Borna Ćorić in the semifinals, solidifying a career-best start to a season at 17–0. His previous best season start had been 16–0 during the 2006 season.[216] Despite holding three championship points, Federer was defeated by Juan Martin Del Potro in a close three-set final. At the Miami Open, Federer received a first-round bye, but lost in the second round to Thanasi Kokkinakis. With this early exit from the tournament, Federer lost his No. 1 ranking to Nadal on 2 April. He announced that he would miss the clay court season, including the French Open, for the second consecutive season.[217] Nevertheless, he regained the No. 1 ranking in May after Nadal failed to defend one of his Masters titles at the Madrid Open.[218] He then lost the top spot the following week after Nadal won the title at the Italian Open.[219]
",3
3380,"In June, Federer regained the No. 1 ranking after defeating Nick Kyrgios in the semifinals at the Stuttgart Open.[220] He then won the tournament, defeating Milos Raonic in the final in straight sets.[221] However, he lost his No.1 ranking the following week when he failed to defend his Halle Open title, losing in the final to Borna Ćorić in three sets.[222] At Wimbledon, Federer was looking to defend his 2017 title and was seeded first at a Grand Slam for the first time since the 2012 US Open but lost in the quarter finals against South African Kevin Anderson in five sets, despite winning the first two sets and having a match point in the third set.[223] This was only his second Wimbledon defeat after winning the first two sets since his defeat to Jo-Wilfried Tsonga at the 2011 Wimbledon Championships.[224]
",3
3381,"Federer next played in Cincinnati where he lost in the final to Novak Djokovic, who won a record Career Golden Masters, in straight sets.[225] The loss ended Federer's run of 100 consecutive service holds and 14 match winning streak in Cincinnati. Federer entered the US Open as the second seed but was upset by John Millman in the 4th round, citing extreme conditions of heat and humidity that took a toll on his body.[226] Federer then played at the Laver Cup where he successfully helped Team Europe defend their title, winning both his singles matches against Nick Kyrgios and John Isner.[227] He also paired up with Djokovic for the first time in doubles, losing their match against Jack Sock and Kevin Anderson in three sets.[228] Federer then played at the 2018 Shanghai Masters as the defending champion but lost in the semifinals to Borna Ćorić in straight sets.[229]
",3
3382,"At the Swiss Indoors in October, Federer shared that he had sustained a hand injury in training prior to the grass season that had caused severe pain up his forearm. He stated that this injury significantly hindered his play, particularly his forehand, since the Stuttgart Open.[230][231] Federer went on to defend his title with a straight-sets win over Marius Copil in the final, winning his ninth title at the event and his 99th career singles title.[232] Federer entered the Paris Masters, continuing his good run of form defeating Fabio Fognini and Kei Nishikori in straight sets. In the semi-finals, he played a very close match with Novak Djokovic, but ultimately lost to him in three sets. At the Nitto ATP Finals, Federer lost in straight sets to Alexander Zverev in the semifinal.[233]
",3
3383,"Federer opened his campaign by retaining the Hopman Cup alongside Belinda Bencic, becoming the first player to win the mixed-gender event three times.[234]
",3
3384,"Federer was seeded third at the 2019 Australian Open, entering as the two-time defending champion. He defeated Denis Istomin, Dan Evans, and Taylor Fritz to reach the fourth round, where he faced 14th seed Stefanos Tsitsipas. In a stunning upset, Tsitsipas defeated Federer in four close sets. Critically, Federer was unable to convert any of the twelve break points he held throughout the match, including four set points in the second set. After the match Federer announced he would play the clay court season for the first time since 2016.[235][236]
",3
3385,"At the Dubai Tennis Championships, Federer won his 100th Career Singles Title, beating Tsitsipas in straight sets in the final. It was his eighth title in Dubai and he became only the second man after Jimmy Connors to reach the three figure mark in the Open Era.[237] Federer then reached the final of the 2019 Indian Wells Masters where he lost to Dominic Thiem in three sets.[238] On 31 March, Federer defeated John Isner at the 2019 Miami Open in straights sets to win his 4th Miami Open title and 28th Masters 1000 title.[239] Federer then played his first clay court tournament in three years at the 2019 Madrid Open and secured his 1200th career win, beating Gael Monfils in the third round. In the quarterfinals he lost to Dominic Thiem again in three sets, despite having two match points in the second set.[240]
Federer then played at the Italian Open and reached the quarterfinals but was forced to withdraw from his quarterfinal match against Stefanos Tsitsipas due to a right leg injury.[241]
",3
3386,"Federer next played at the French Open for the first time in 4 years and seeded 3rd in the draw. Federer achieved comfortable straight-set victories against Lorenzo Sonego, Oscar Otte, Casper Ruud and Leonardo Mayer to reach the quarterfinals, where he faced good friend and compatriot Stan Wawrinka. Federer managed to avenge his loss to Wawrinka at the same stage of the tournament 4 years ago, winning in 4 sets after 3 hours and 35 minutes. With the victory Federer returned to the semifinals of the French Open for the first time since 2012, where he lost to defending and 11-time champion Rafael Nadal in straight sets.[242]
",3
3387,"Federer then began his grass court season at the Halle Open where he won his tenth title at the event, defeating David Goffin in the final in straight sets. This marked the first time Federer had won a singles tournament ten times or more.[243] At Wimbledon, Roger Federer reached his record 12th final at the tournament after ousting his nemesis Rafael Nadal in four sets in the semifinal, thus exacting revenge for his earlier defeat to him at the French Open. This was also the first time Federer played Nadal at Wimbledon since the 2008 Wimbledon final, a match regarded by some as the greatest match in the history of tennis.[244] Federer then faced Novak Djokovic in the final, against whom he lost in a five set thriller lasting four hours and fifty seven minutes, despite having two championship points on serve in the fifth set. The match also marked the first time a fifth set tiebreaker was played at 12 games all in the men's singles and was the longest men's final in Wimbledon history.[245]
",3
3388,"Federer next played at the 2019 Cincinnati Masters and reached the third round where he lost in straight sets to Andrey Rublev. This was his quickest defeat in 16 years, taking just 62 minutes.[246] At the 2019 US Open, he was seeded third. He dropped the first set against both Sumit Nagal and Damir Džumhur in the first two rounds, but pulled out convincing straight sets wins over Dan Evans and David Goffin in the third and fourth. In the quarterfinals, he faced Grigor Dimitrov, who was ranked No. 78 going into the tournament. Despite taking a two sets to one lead, Federer ultimately lost the match in five sets.[247][248] At the 2019 Shanghai Masters, Federer defeated David Goffin in straight sets to reach the quarterfinal.[249] However, he lost the quarterfinal to Alexander Zverev in three sets.[250]
",3
3389,"Federer advanced to the Swiss Indoors as the two-time defending champion. His first round match, against Peter Gojowczyk, was remarkable for being the 1500th match of his career. In the final, he defeated Alex de Minaur in straight sets for a record-extending tenth Swiss Indoors title.[251] Federer then played in the Björn Borg group at the 2019 ATP Finals where in the round robin, he lost his opening match to Dominic Thiem in straight sets but beat Matteo Berrettini and Djokovic (his first win over Djokovic since 2015) in straight sets to qualify for the semifinals.[252] He then lost the semifinal to Stefanos Tsitsipas in straight sets.[253]
",3
3390,"Federer began his 2020 season at the 2020 Australian Open. He reached the semifinals after straight sets wins over Steve Johnson and Filip Krajinović, a five-set win over John Millman and a four-set win over Márton Fucsovics. Federer saved seven match points in his five-set quarterfinal win over Tennys Sandgren.[254] Federer then lost his semifinal match to Djokovic in straight sets, having sustained a groin injury earlier in the tournamant.[255] In February, Federer underwent arthroscopic surgery for a right knee injury and subsequently withdrew from Dubai, Indian Wells, Miami and the French Open to give time for his knee to recover, announcing that he would return in the grass season.[256] On June 10, due to a setback from his initial rehabilitation from the knee injury suffered earlier in the year, Federer announced that he had to have an additional arthroscopic procedure on his right knee. Therefore, he officially shut down his season to take the necessary time to recover, vowing to return in 2021. This is only the second year in Roger Federer's career since he won his first title that he finished without a title.[257]
",3
3391,"In January, Federer withdrew from the 2021 Australian Open due to still recovering from his knee surgery and strict COVID-19 quarantine measures in Australia.[258][259] On 8 March, Novak Djokovic moved past him for the highest number of career weeks spent as the ATP number 1 ranked player.[260]. On 10 March, he made his return to the ATP Tour at the Qatar Open. He won his first ATP match in 14 months against Dan Evans, but lost to Nikoloz Basilashvili in the next round.[261]
",3
3392,"An 18-year-old Federer made his Olympic debut at Sydney in 2000, where he entered the singles competition. He surprised many by reaching the semifinals but lost to Tommy Haas in the semifinals and then to Arnaud Di Pasquale in the bronze medal match, causing Federer to leave Sydney empty handed.[262][263]
",3
3393,"At the 2004 Summer Olympics in Athens, Federer was the clear favorite after claiming the world No. 1 ranking earlier in the year and capturing the Australian Open and Wimbledon titles. However, he lost in the second round to 18-year-old Tomáš Berdych. In doubles, he and compatriot Yves Allegro lost in the second round.[264]
",3
3394,"At the 2008 Summer Olympics in Beijing, Federer was again the top seed and favorite, but lost in the quarterfinals to James Blake.[265] However, he found more success on the doubles court, capturing the gold medal in men's doubles with compatriot Stan Wawrinka, defeating Simon Aspelin and Thomas Johansson of Sweden.[266] At both the Athens and Beijing Olympic Games, Federer was the flagbearer for Switzerland in the opening ceremony.[267]
",3
3395,"At London 2012, Federer won his first singles medal, losing to Andy Murray in the final to claim the silver. He and Wawrinka were unable to defend their gold medal in doubles, losing in the second round to Jonathan Erlich and Andy Ram of Israel.[268][269]
",3
3396,"Federer did not compete in the 2016 Rio Olympics after taking the rest of the season off after Wimbledon to recover from a knee injury.[270]
",3
3397,"Federer made his Davis Cup for Switzerland debut in the World Group 1st Round against Italy in 1999 at 17 years of age. In his first match he defeated Davide Sanguinetti in four sets and recorded a second singles victory in a dead rubber two days later as Switzerland advanced to the World Group Quarterfinals.[271] In the Quarterfinals Federer, who was still 17 years old, suffered his first Davis Cup loss when he was defeated by Belgian Christophe Van Garsse in five sets. The Swiss team went on to lose the rubber 3–2. A year later, Federer competed in his first Davis Cup doubles rubber where he teamed with countryman Lorenzo Manta to defeat Australians Wayne Arthurs and Sandon Stolle in four sets. Despite the doubles victory, Federer lost both singles rubbers to Mark Philippoussis and Lleyton Hewitt which saw Switzerland sent to the World Group Playoffs for the first time in Federer's career. He returned for the playoffs in July 2000 and led Switzerland to a 5–0 win over Belarus by recording wins in singles and doubles.[272]
",3
3398,"His first Davis Cup highlight came in 2003 as the newly crowned Wimbledon champion led his country to an historic semifinal run. After recording five wins in ties against the Netherlands and France, the Swiss team traveled to Melbourne to play the highly rated Australians.[273] Federer once again defeated Wimbledon runner-up Mark Philippoussis in the second rubber but allowed the Australians to lead the tie 2–1 going into Day 3 after dropping the doubles rubber in five sets. Federer then played Lleyton Hewitt in a sudden death situation for Switzerland and despite leading two sets to love, succumbed to a fast finishing Hewitt in five sets.[274] Australia went on to claim the Davis Cup title months later[275] as Federer's interest in Davis Cup began to wane and his focus shifted to his personal career. He skipped many ties over the years but often competed in the World Group Playoffs in order for Switzerland to maintain their place in the top division.[276][277][278]
",3
3399,"The emergence of countryman Stanislas Wawrinka as a Grand Slam singles champion in 2014 renewed hope for Federer in his Davis Cup quest, and the pair both committed to playing each tie that year. Their commitment paid off as wins over Serbia, Kazakhstan and Italy allowed the Swiss team to advance to the 2014 Davis Cup Final. Leading into the final, Federer was suffering from a back injury[279] that threw serious doubt over Switzerland's chance to claim the title, and a second rubber straight sets loss to Gaël Monfils seemingly spelled the worst for Switzerland. However, a rejuvenated Federer returned the next day to help claim the doubles rubber, which set up a fourth rubber singles tie between Federer and Richard Gasquet. Federer defeated Gasquet in straight sets and in doing so handed Switzerland its first (and only to date) Davis Cup title.[280][281]
",3
3400,"Federer holds many Davis Cup records for Switzerland that includes most total wins, most singles wins and most years played.[282]
",3
3401,"Federer won the 2001 Hopman Cup representing Switzerland, along with Martina Hingis. The duo defeated the American pair of Monica Seles and Jan-Michael Gambill in the finals.[283]
He also played the next year, along with his current wife Mirka Vavrinec, but they lost in the round robin stage.[284]
",3
3402,"Federer played again at the Hopman Cup in 2017, along with Belinda Bencic. They won all of their ties except the last one, and as a result they couldn't make the final.[285][286]
",3
3403,"In 2018, Federer won his second Hopman Cup title and third overall for Switzerland. His partner was Belinda Bencic again. The Swiss team won all the ties and Federer won all his singles and mixed doubles matches. They defeated the German pair, Alexander Zverev and Angelique Kerber, in the final 2–1.[287]
",3
3404,"Federer won his third and second consecutive Hopman Cup title in 2019 alongside Belinda Bencic. They again defeated Alexander Zverev and Angelique Kerber of Germany in the final, and won the final tie 2–1 by winning a tiebreak in the final set of the mixed doubles (5–4). Federer again won all of his singles matches. The Swiss team only lost one tie to Greece (1–2).[288]
",3
3405,"Roger Federer has won three Hopman Cup titles, which is more than any other individual.[288]
",3
3406,"Federer founded the Laver Cup, which pits Europe against the rest of the world. The tournament is named in honor of Rod Laver and the inaugural edition was played in 2017.[289]
",3
3407,"Europe won the inaugural Laver Cup in 2017. Federer played his first singles match on day two, when he dispatched Sam Querrey in straight sets. Later on day two, he partnered with his rival Nadal in doubles, where they defeated the Team World duo of Sam Querrey and Jack Sock in the match tie breaker, which took place at one set all. This was the first time Federer and Nadal competed on the same side of a doubles match. On day three, Federer competed in the final match of the tournament, where he sealed victory for Team Europe by defeating Nick Kyrgios in the champion's tiebreak (saving a match point). With three wins and seven points, Federer was the most accomplished player of the tournament.[290][291]
",3
3408,"The second edition was played in 2018. The European team led by Federer retained the title after defeating Team World, 13–8. Federer won both his singles matches, against Nick Kyrgios and John Isner, but lost both his doubles matches.[292]
",3
3409,"In 2019 the ATP announced that the Laver Cup would be an official event on the ATP Tour, with match wins and losses to be counted as official on every player's career record in singles and doubles.
",3
3410,"The third edition was held in Geneva, Switzerland. Federer and the European team captured their third consecutive title. Team World was closer than ever to win their first title, losing 11–13 after having led during the final day. Like in 2018, Federer won singles matches against Kyrgios and Isner. He went 1–1 in doubles.
",3
3411,"Federer and Rafael Nadal have played 40 times, with Federer trailing 16–24. Federer has a winning record on grass 3–1 and hard courts 11–9, while Nadal leads on clay 14–2.[293] Because tournament seedings are based on rankings, 24 of their matches have been in tournament finals which have included an all-time record nine Grand Slam finals.[294] Federer and Nadal have been playing each other since 2004, and their rivalry is a significant part of both men's careers.[295][296][297][298][299] The latest encounter was at the 2019 Wimbledon Championships, where Federer won to reach the final.
",3
3412,"They held the top two rankings on the ATP Tour from July 2005 until 17 August 2009, when Nadal fell to No. 3 (Andy Murray became the new No. 2),[300] and again from 11 September 2017 until 15 October 2018 (Novak Djokovic became the new No. 2). They are the only pair of men to have ever finished six consecutive calendar years at the top. Federer was ranked No. 1 for a record 237 consecutive weeks beginning in February 2004. Nadal, who is five years younger, ascended to No. 2 in July 2005 and held this spot for 160 consecutive weeks, before surpassing Federer in August 2008.[301]
",3
3413,"From 2006 to 2008, they played in every French Open and Wimbledon final. They then met in the 2009 Australian Open final, the 2011 French Open final, and the 2017 Australian Open final. Nadal won six of the nine, losing the first two Wimbledon finals and the second Australian Open final. Four of these finals were five set-matches (2007 and 2008 Wimbledon, 2009 and 2017 Australian Open), with the 2008 Wimbledon final being lauded as the greatest match ever by many long-time tennis analysts.[302][303][304][305] Of their 40 meetings, 13 have reached a deciding set. They have also played in 12 Masters Series finals, including their lone five-hour match at the 2006 Rome Masters which Nadal won in a fifth-set tie-break, having saved two match points.
",3
3414,"Federer and Novak Djokovic have played 50 times, with Federer trailing 23–27.[306][307] They are tied 4–4 on clay while Federer trails 18–20 on hard-courts and 1–3 on grass. The Federer–Djokovic rivalry is the largest rivalry in men's Grand Slam tournament history with a record 17 matches played against each other. Djokovic is the only player besides Nadal to defeat Federer in consecutive Grand Slam tournaments (2010 US Open and 2011 Australian Open, also 2015 Wimbledon, US Open and 2016 Australian Open), and the only player besides Nadal and Murray who has double-figure career wins over Federer. Djokovic is one of two players (the other again being Nadal) on tour to have defeated Federer in straight sets at a Grand Slam event multiple times (2008 Australian Open, 2011 Australian Open, 2012 French Open, 2020 Australian Open), but Djokovic alone has done so four times.
",3
3415,"Federer and Djokovic first played in a Grand Slam final at the 2007 US Open where the three-time reigning champion and No. 1 Federer emerged victorious in straight sets. Federer ended Djokovic's perfect 41–0 start to the 2011 season in the semifinals of the French Open, but Djokovic was able to avenge this loss at the 2011 US Open in five sets after saving two match points against Federer for the second straight year.[308] In the semifinals of Wimbledon 2012, Federer beat defending champion and No. 1 Djokovic in four sets.[309] The two met again during the finals of the 2014 Wimbledon Championships with Djokovic emerging victorious after five sets.[310] Federer also ended Djokovic's 28 straight wins in China at 2014 Shanghai Open. Federer and Djokovic rematched in the 2015 Wimbledon Championships with Djokovic once again claiming victory in four sets.[311] The pair met once more for the final major of the season, the 2015 US Open and once more Djokovic prevailed in four sets.[312] At the 2019 Wimbledon Championships, Djokovic bested Federer in an almost 5 hour match whose final set went to a tiebreak. This was the fifth consecutive time that Djokovic defeated Federer in Grand Slam matches. Some experts have included the rivalry between Federer and Djokovic as one of the best rivalries in the Open Era.[313]
",3
3416,"Federer and Andy Murray have played 25 times, with Federer leading 14–11. Federer leads 12–10 on hard courts, and 2–1 on grass. They have never met on clay. After Federer won the first professional match they played, Murray dominated the first half of the rivalry, leading 8–5 in 2010, while the second half of the rivalry has been dominated by Federer, who leads 9–3 since 2011.[314] The two have met six times at the Grand Slam tournament level, with Federer leading 5–1. Their first three Grand Slam matches were finals, with Federer winning all three of these matches; at the 2008 US Open[315] and the 2010 Australian Open,[316] both of which he won in straight sets, and at the 2012 Wimbledon Championships in which Murray took the opening set, but went on to lose in four sets. However, Murray won their encounter in the semifinals of the 2013 Australian Open, defeating Federer for the first time at a Grand slam tournament in five sets. At the 2014 Australian Open, Federer reversed that result, defeating Murray in four sets in the quarterfinals. The most recent meeting between the two in a major was in the semifinals of the 2015 Wimbledon Championships, where a dominant Federer triumphed in straight sets.
",3
3417,"They met in the final of the 2012 Summer Olympics, in which Murray defeated Federer in straight sets, denying Federer a career Golden Slam. Murray also leads 6–3 in ATP 1000 tournaments, 2–0 in finals. They have also met five times at the ATP World Tour Finals, with Murray winning in Shanghai in 2008,[317] and Federer in London in 2009, 2010, 2012, and 2014.[318] Murray is one of only three players to have recorded ten or more victories over Federer (the other two being Nadal and Novak Djokovic).
",3
3418,"Federer and Andy Roddick played 24 times, and Federer leads their head-to-head 21–3. Roddick lost his No. 1 ranking to Federer after Federer won his first Australian Open in 2004. Their rivalry includes four Grand Slam event finals, three at Wimbledon and one at the US Open, all won by Federer.[319] Roddick himself said it was not much of a rivalry, being so one-sided.[320]
",3
3419,"In the 2009 Wimbledon final, Roddick lost to Federer in five sets. The match included a 30-game fifth set (a Grand Slam final record) and lasted over four hours. In the final game of the deciding set, Roddick's serve was broken for the first time in the match. With that victory, Federer broke Pete Sampras' record of 14 Grand Slam singles titles, and Roddick apologised to Sampras (who was in attendance) for not being able to stop Federer.
",3
3420,"Federer and Lleyton Hewitt played 27 times, with Federer leading 18–9.[321] Early in their careers, Hewitt dominated Federer, winning seven of their first nine meetings, including a victory from two sets down in the 2003 Davis Cup semifinal which allowed Australia to defeat Switzerland. This marked a turning point in the rivalry, as Federer won 16 of the next 18 meetings from 2004 onwards. This is Hewitt's longest rivalry as these two first played each other as juniors in 1996. They met in one Grand Slam tournament final, the 2004 US Open final, where Federer won his first US Open title in a lopsided encounter in which Federer scored a bagel on both sides of a second-set tiebreak. Federer met Hewitt at six of the Grand Slam tournaments in which he lifted the trophy, including all five of his triumphs between 2004 and 2005. Their last meeting was at the 2014 Brisbane International, where Hewitt triumphed over Federer in three sets for his first title since 2010, when he also beat Federer to the Halle title.
",3
3421,"Hewitt and Federer teamed up in the men's doubles at Wimbledon in 1999. They lost in the third round to Jonas Björkman and Pat Rafter.[322]
",3
3422,"Federer and David Nalbandian played 19 times, with Federer leading 11–8.[323] David Nalbandian was Federer's biggest rival in his early career. Nalbandian dominated early on, winning their first five matches from 2002 to 2003. Federer reversed this trend at the 2003 Masters Cup, where he recorded his first victory, and went on to win 11 of their last 14 meetings. Federer leads 6–5 on hard courts, 1–0 on grass, and 3–1 on clay courts, while Nalbandian leads 2–1 on carpet. Notable meetings include Nalbandian's win in a fifth-set tiebreaker to win the 2005 Masters Cup, and Federer's win in the 2006 French Open semifinals. They met each other six times in Grand Slam tournaments, with Federer leading 4–2.
",3
3423,"Marat Safin and Federer played 12 times, with Federer leading 10–2.[324] Federer and Safin turned pro within one year of each other, with Safin turning pro in 1997 and Federer in 1998. Federer leads 4–1 on hard courts, 3–0 on grass, and 3–0 on clay courts, while Safin leads 1–0 on carpet. Notable meetings include Federer's defeating Safin at the 2002 Hamburg Masters to win the first Masters 1000 title of his career, as well as Federer's emerging victorious in the semifinals of the 2004 Tennis Masters Cup, after winning a tiebreak 20–18 on his eighth match point. Federer also defeated Safin in the finals of the 2004 Australian Open to capture his first Australian Open and second Grand Slam tournament title. However, Safin defeated Federer in the 2005 Australian Open semifinals, having saved one match point in the fourth-set tiebreak, to end a 26-match winning streak by Federer.[325] They met each other five times in Grand Slam tournaments, with Federer leading 4–1.
",3
3424,"Federer and Andre Agassi played 11 times, and Federer leads their head-to-head 8–3.[326] This was Federer's most significant rivalry with a dominant player of the previous generation. They first met in only the third tournament of Federer's career at the 1998 Swiss Indoors in Federer's hometown, with Andre Agassi prevailing over the 17-year-old. Agassi also defeated Federer at the 2001 US Open and the finals of the Miami Masters in 2002. Federer began to turn the tide at the Masters Cup in 2003, when he defeated Agassi in both the round robin and the final. They played a memorable quarterfinal match at the 2004 US Open that spanned over two days, with Federer eventually prevailing in five sets. At the 2005 Dubai Championships, Federer and Agassi attracted worldwide headlines with a publicity stunt that saw the two men play on a helipad almost 220 meters above sea level at the hotel Burj al-Arab. Their final match was at one of the most prestigious platforms in the sport, when they played in the finals of the 2005 US Open. Federer was victorious in four sets, claiming the 6th Grand Slam tournament of his career and denying Agassi his 9th.
",3
3425,"Federer and his fellow Swiss player Stan Wawrinka have played each other 26 times, with Federer leading 23–3. Federer leads 7–1 in Grand Slam tournaments, 17–0 on hard courts, 1–0 on grass courts and 5–3 on clay courts. The pair are 1–1 in finals. Their first meeting in a final came at 2014 Monte-Carlo Rolex Masters where Wawrinka defeated Federer in three sets to win his first Masters 1000 title before Federer avenged his loss at the 2017 BNP Paribas Open by beating him in the final.[327] While the rivalry is one-sided in Federer's favour, the two have contested some close matches. Wawrinka defeated Federer in straight sets during the 2015 French Open quarterfinals en route to winning his first French Open title, although Federer then won a straight-sets victory in the 2015 US Open semifinals. Other close matches include the 2012 Shanghai Masters and the 2013 Indian Wells Masters, both of which Federer won in three sets, the 2014 Wimbledon quarterfinal, which Federer won in four sets, the 2014 ATP World Tour Final semifinal, which Federer won in three sets after saving four match points, and the 2017 Australian Open semifinal, which Federer won in five sets. Despite their on-court rivalry, they are friends off court,[328] and they have played doubles together on numerous occasions,[329] most notably when they won the doubles Olympic Gold at the 2008 Beijing Olympics and when winning the 2014 Davis Cup.
",3
3426,"Juan Martín del Potro and Roger Federer have played 25 times, with Federer leading 18–7.[330] They have met seven times in Grand Slam tournaments, with Federer leading 5–2. Their two most famous Grand Slam tournament meetings came in 2009. The first was in the French Open semifinals, when Federer survived a five-set clash when he was on his way to the only French title of his career. The second was in the final of the US Open, where del Potro beat five-time defending champion Federer in five sets, ending his 20-match winning streak at Grand Slams. Another high-profile match was in the semifinals of the 2012 London Olympics, where Federer prevailed 19–17 in the final set to secure the Olympic silver medal. They also met in the finals of the Swiss Indoors in 2012, 2013 and 2017, with del Potro prevailing on first two occasions, and Federer on last one of them in tight three-set matches.
",3
3427,"In the 2017 U.S. Open quarterfinals, in a rematch of the 2009 US Open final, Del Potro again beat Federer in four sets to end his unbeaten streak in grand slams that year. With this win, Del Potro also denied the first Federer-Nadal match at US Open, as in 2009 where he beat Nadal in straight sets in the semifinals. Federer, however avenged this loss at the Shanghai Masters semifinals, where he beat del Potro in three sets after coming from a set down. In the final at the 2018 BNP Paribas Open del Potro beat Federer in three close sets, after facing match points in the third set. With this win del Potro won his first Masters 1000 title of his career.[331]
",3
3428,"Tomáš Berdych and Federer played 26 times, with Federer leading 20–6.[332] Federer leads 12–5 on hard courts, 3–1 on grass courts, 4–0 on clay courts, and 1–0 on carpet. Berdych won their first professional match, notably upsetting then-No. 1 Federer at the 2004 Summer Olympics. Federer then went on to win their next eight meetings, before Berdych ended the losing streak in 2010. Between 2010 and 2013, Berdych won 5 of 8 meetings. Federer again dominated the matchup after 2014, leading 9–0 since then. They met ten times in Grand Slam tournaments, with Federer leading 8–2, and Berdych is one of five players, along with Arnaud Clément, Álex Corretja, David Nalbandian, and Jo-Wilfried Tsonga, to defeat Federer multiple times in majors before the semifinal stage. Their most notable Grand Slam matches took place in the 2009 Australian Open, when Federer prevailed in five sets after dropping the first two sets, the 2010 Wimbledon Championships and the 2012 US Open, both of which Berdych won in four sets. Berdych went on to reach the only Grand Slam final of his career after the Wimbledon quarterfinal victory, ending Federer's run of seven consecutive finals at Wimbledon dating back to 2003.[333]
",3
3429,"Jo-Wilfried Tsonga and Federer have played 18 times, with Federer leading 12–6. Federer leads 5–3 on outdoor hard courts and 4–0 on indoor hard. They are 1–1 on grass and 2–2 on clay courts.[334] The pair have met six times in Grand Slam tournaments, including their five-set matches in the quarterfinals of 2011 Wimbledon and 2013 Australian Open. They have also one Grand Slam semifinal meeting in the 2010 Australian Open, with Federer winning in straight sets. Federer and Tsonga have played in the 2011 ATP World Tour Finals final, with Federer winning his record-sixth Year-End Championship in three sets. The pair have also met in two ATP World Tour Masters 1000 finals. The first was in the 2011 BNP Paribas Masters, with Federer winning his first title in Bercy, and the second was in the 2014 Rogers Cup, with Tsonga winning his second Masters 1000 title.
",3
3430,"Federer and Marin Čilić have played 10 times, with Federer leading 9–1.[335] Čilić's only victory came in the 2014 US Open semifinals, after which he went on to win the Grand Slam title. Their first encounter was in the 3rd round in the 2008 Paris Masters, which Federer won in straight sets. They have played five Grand Slam matches, two in Wimbledon, two in the US Open, and one at the 2018 Australian Open; Federer leads these matches 4–1. Two of these have been Grand Slam finals – the 2017 Wimbledon final, which Federer won in straight sets, and the 2018 Australian Open final, which Federer won in five sets.
",3
3431,"Federer and Rafael Nadal have won more Grand Slam tournament titles (20) than any other men's singles players.[336][337] He is the first men's singles player to have reached ten consecutive Grand Slam tournament finals and a total of 31 Grand Slam finals.[338][339] He has earned a men's doubles gold medal, and a men's single silver medal at the Olympics in 2008 and 2012, respectively.[340] He has spent the second-most time at the top of the ATP Rankings (310 weeks). He also holds the record for the most titles (6) at the year-end tournament, where only the year-end eight highest-ranked players participate. Federer was ranked among the top eight players in the world continuously for 14 years and two weeks—from 14 October 2002 until 31 October 2016, when injuries forced him to skip much of the 2016 season.[341]
",3
3432,"Federer has won the ATP Player of the Year five times (2004–07, 2009), and has become ITF World Champion five times (2004–07, 2009). He has won the ATPWorldTour.com Fans' Favourite Award a record 18 times consecutively (2003–20), and has won the Stefan Edberg Sportsmanship Award (voted for by the players) a record 13 times (2004–09, 2011–17),[342] both being awards indicative of respect and popularity. He also won the Arthur Ashe Humanitarian of the Year Award twice (2006, 2013), the Laureus World Sportsman of the Year five times (2005–08, 2018), and the Laureus World Comeback of the Year once, following his 2017 renaissance.[343]
",3
3433,"Federer is one of the founders, via his management company TEAM8, of the Laver Cup; the annual team tennis tournament which pits Europe against the rest of the world. He co-founded the tournament in honor of tennis legend Rod Laver and the inaugural edition was played in 2017.
",3
3434,"In 2018, Federer returned to the Australian Open to defend his 2017 title and won his 20th Grand Slam tournament. Rafael Nadal, with his 2020 Roland Garros win, equalled Federer reaching his 20th Grand Slam.
",3
3435,"Roger Federer has huge popularity in the world of sport, and because of his achievements, Federer is widely considered to be one of the greatest tennis players of all time, with many players and analysts considering him to be the greatest player ever.[e] He has also been called the greatest athlete of his generation.[358][359] Tennis.com listed him as the greatest male player of the open era.[360] Federer himself has downplayed these claims, stating in 2012 that it is impossible to compare tennis players from different eras and that past champions are needed to pave the way for future champions.[361]
",3
3436,"Until 2020, no other male tennis player had won 20 major singles titles (the record has since been tied by Rafael Nadal). Federer has also been in a record 31 major finals, including a record 10 in a row. He has held the world No. 1 spot in the ATP rankings for longer than any other male player. He was ranked No. 1 at the age of 36 and has won a record eight Wimbledon titles. He won five consecutive US Open titles, which is the most in the Open Era.
",3
3437,"He has been voted by his peers to receive the tour Sportsmanship Award a record thirteen times and voted by tennis fans to receive the ATP Fans' Favorite award for seventeen consecutive years.[362] Federer has been named the Swiss Sports Personality of the Year a record seven times. He has been named the ATP Player of the Year and ITF World Champion five times, and he has won the Laureus World Sportsman of the Year award a record five times, including four consecutive awards from 2005 to 2008. He is also the only individual to have won the BBC Overseas Sports Personality of the Year award four times.
",3
3438,"Federer helped to lead a revival in tennis known by many as the Golden Age. This led to increased interest in the sport, which in turn led to higher revenues for many venues across tennis. During this period rising revenues led to exploding prize money; when Federer first won the Australian Open in 2004 he earned $985,000, compared to when he won in 2018 and the prize had increased to AUD 4 million.[363]
",3
3439,"Upon winning the 2009 French Open and completing the career Grand Slam, Federer became the first individual male tennis player to grace the cover of Sports Illustrated since Andre Agassi in 1999.[364] He was also the first non-American player to appear on the cover of the magazine since Stefan Edberg in 1992.[365] Federer again made the cover of Sports Illustrated following his record-breaking 8th Wimbledon title and second Grand Slam of 2017, becoming the first male tennis player to be featured on the cover since himself in 2009.[365]
",3
3440,"Federer is nicknamed the ""Federer Express"" (shortened to ""Fed Express"" or ""FedEx""),[366][367][368] and the ""Swiss Maestro.""[369][370] He has also been referred to as ""King Roger"" on occasion.[371]
",3
3441,"In 2003, he established the Roger Federer Foundation to help disadvantaged children and to promote their access to education and sport.[372][373][374]
",3
3442,"Since May 2004, citing his close ties with South Africa (his mother is South African) he has been supporting the South Africa-Swiss charity IMBEWU, which helps children better connect to sports as well as social and health awareness. In 2005, Federer visited South Africa to meet the children that had benefited from his support.[375][376][377] Also in 2005, he auctioned his racquet from his US Open championship to aid victims of Hurricane Katrina.[378]
",3
3443,"At the 2005 Pacific Life Open in Indian Wells, Federer arranged an exhibition involving several top players from the ATP and WTA tour called Rally for Relief. The proceeds went to the victims of the tsunami caused by the 2004 Indian Ocean earthquake. In December 2006, he visited Tamil Nadu, one of the areas in India most affected by the tsunami.[379] He was appointed a Goodwill Ambassador by UNICEF in April 2006 and has appeared in UNICEF public messages to raise public awareness of AIDS.[380][381]
",3
3444,"In response to the 2010 Haiti earthquake, Federer arranged a collaboration with fellow top tennis players for a special charity event during the 2010 Australian Open called 'Hit for Haiti', in which proceeds went to Haiti earthquake victims.[382][383] He participated in a follow-up charity exhibition during the 2010 Indian Wells Masters, which raised $1 million.[384]
",3
3445,"The Nadal vs. Federer ""Match for Africa"" in 2010 in Zurich and Madrid raised more than $4 million for the Roger Federer Foundation and Fundación Rafa Nadal. In January 2011, Federer took part in an exhibition, Rally for Relief, to raise money for the victims of the Queensland floods.[385][386] In 2014, the ""Match for Africa 2"" between Federer and Stan Wawrinka, again in Zurich, raised £850,000 for education projects in Southern Africa.[387]
",3
3446,"In 2007, the Swiss Post in Basel released a special edition stamp for Federer. Three years later, in 2010, Federer awarded a special edition stamp by Austria's Postal Service.[388][389]
",3
3447,"In 2011, on the Reputation Institute's study of the World's most respected, admired and trusted personalities, Federer ranked No. 2 just behind Nelson Mandela but ahead of Bill Gates, Steve Jobs, Oprah Winfrey and Bono.[390]
",3
3448,"In 2012, the city of Halle, in Germany, unveiled ""Roger-Federer-Allee"" in recognition of Federer's success on the grass at the Gerry Weber Open.[391] In 2016, the city of Biel, Switzerland, location of the national centre for Swiss Tennis where Federer trained as a junior, named the street in his honour as ""1 Allée Roger Federer"".[392]
",3
3449,"In July 2016, Roger Federer ranked No. 1 in the list for the most recognizable people in Switzerland, surpassing personalities such as Albert Einstein and William Tell. In a poll of more than 9,000 people from 15 countries, the Swiss legend topped the list of most recognizable Swiss with 600 more votes than the country's second national hero, William Tell, who came up second. Federer got 916 votes, Tell got 316 and Einstein ranked third with 204. The other three in the first six were Henry Dunant, Jean-Jacques Rousseau and novel character Heidi.[393]
",3
3450,"In January 2017, Federer named the Most Marketable Sports Person for 2016 by researchers of London School of Marketing. Federer earned £49.2 million in endorsements and sponsorships.[394]
",3
3451,"On 24 November 2017, Federer received an honorary doctorate awarded to him by his home university, the University of Basel. He received the title in recognition for his role in increasing the international reputation of Basel and Switzerland, and also his engagement for children in Africa through his charitable foundation.[395]
",3
3452,"In December 2019, Federer became the first living person to be celebrated on Swiss coins. His face will be on the 20-franc coin and in May 2020, Swissmint issued a Federer 50-franc gold coin featuring a different design.[396]
",3
3453,"In December 2019 Roger Federer was voted by the readers as the Most Stylish Man of the Decade (2010–2019) in GQ. He was first in the list, ahead of Timothée Chalamet, LeBron James, Harry Styles, David Beckham, Justin Bieber, Kanye West, Ryan Gosling and others.[397]
",3
3454,"On 29 May 2020 Federer topped Forbes' 2020 List of the World's Highest Paid Athletes with $106.3 million in total earnings from salary, winnings and endorsements. Federer appears every year on this list, inside the top-10 or top-5, but never on the top spot before. This year is the first time Roger Federer has ranked atop Forbes's annual list. He surpassed sports legends like, 2.Cristiano Ronaldo (football - $105m), 3. Lionel Messi (football - $104m), 4. Neymar (football - $95.5m), 5. LeBron James (basketball - $88.2m), 6. Stephen Curry (basketball - $74.4m), 7. Kevin Durant (basketball - $63.9m), 8. Tiger Woods (golf - $62.3m), 9. Kirk Cousins (american football - $60.5m), 10. Carson Wentz (american football - $59.1m), and many more great sports persons.[398]
",3
3455,"On 20 July 2020 Federer was featured by Swiss National Museum in a 100-part chronicle of Swiss history and culture.[399][400]
",3
3456,"Federer's versatility has been described by Jimmy Connors: ""In an era of specialists, you're either a clay court specialist, a grass court specialist, or a hard court specialist... or you're Roger Federer.""[401]
",3
3457,"An elite athlete, Federer is an all-court, all-around player known for his speed, fluid style of play, and exceptional shot making. Federer mainly plays from the baseline but is also comfortable at the net, being one of the best volleyers in the game.[402] He has a powerful, accurate smash and very effectively performs rare elements of professional tennis, such as the backhand smash and skyhook, half-volley, jump smash (slam dunk) and an aggressive serve return known affectionately as SABR (Sneak Attack By Roger, a half-volley attack on an opponent's second serve). David Foster Wallace compared the brute force of Federer's forehand motion with that of ""a great liquid whip"",[403] while John McEnroe has referred to Federer's forehand as ""the greatest shot in our sport.""[404] Federer is also known for his efficient, deceptively effortless movement around the court and excellent footwork, which enables him to run around shots directed to his backhand, usually considered his weaker wing, and instead hit a powerful and penetrating inside-out or inside-in forehand, one of his best shots. He also has great variety with his forehand, able to hit with topspin or pace (or both), thus opening up the court and going in to the forecourt for aggressive volleys.
",3
3458,"Federer plays with a single-handed backhand, which gives him great variety. He employs the slice, occasionally using it to lure his opponent to the net and deliver a passing shot. Federer can also fire topspin winners and possesses a 'flick' backhand with which he can generate pace with his wrist; this is usually used to pass the opponent at the net.[403] He has averaged 90% of service games won throughout his career, oftentimes coming up victorious in clutch or pressure service games. His serve is difficult to read because he always uses a similar ball toss, regardless of what type of serve he is going to hit and where he aims to hit it, and turns his back to his opponents during his motion. He is often able to produce big serves on key points during a match. His first serve is typically around 200 km/h (125 mph);[405][406][407] however, he is capable of serving at 220 km/h (137 mph).[405][406] Federer is also accomplished at serve and volleying,[408] and employed this tactic frequently in his early career.[409][410]
",3
3459,"Later in his career, Federer added the drop shot to his arsenal and can perform a well-disguised one off both wings. He sometimes uses a between-the-legs shot, which is colloquially referred to as a ""tweener"" or ""hotdog"". His most notable use of the tweener was in the semifinals of the 2009 US Open against Novak Djokovic, bringing him triple match point.[411] Federer is one of the top players who employ successfully the ""squash shot"", when he gets pushed deep and wide on his forehand wing. Since Stefan Edberg joined his coaching team at the start of the 2014 season, Federer has played a more offensive game, attacking the net more often, and improved his volley shots.[412][413] In the lead-up to the 2015 US Open, Federer successfully added a new unique shot to his arsenal called SABR (Sneak Attack by Roger), in which he charges forward to receive the second serve and hits a return on the service line. The SABR is a unique shot that Federer owns, in the way that he manages to add enough power and placement into the shot, which makes it very difficult, or close to impossible for the opponent to reach it.[414]
With the switch to a bigger 97 inch racket from 90 inches, Federer has gained easy power while relinquishing some control on his shots. The bigger racket has enabled easier serving and better defense on both wings with fewer shanks. However this has diminished control and power on his forehand, slice backhand and dropshot.[415] Since his comeback in 2017, Federer is noted for his improved backhand both down the line and cross court which was cited as the reason for his win against Nadal in the 2017 Australian Open Final and Indian Wells 4th round.
",3
3460,"
Federer is also noted for his cool demeanour and emotional control on the court. In contrast to his early career, most of his professional game has been characterised by lack of outbursts or emotional frustration at errors, which gives him an advantage over less controlled opponents.[416][417][418] Federer declared: .mw-parser-output .templatequote{overflow:hidden;margin:1em 0;padding:0 40px}.mw-parser-output .templatequote .templatequotecite{line-height:1.5em;text-align:left;padding-left:1.6em;margin-top:0}",3
3461,"I don't get the anxiety during a match so much anymore. You know, to throw racquets, to toss balls out of the court, scream and stuff. I almost laugh [on the inside] about it a little bit today when an opponent does it. But that's something for me that's not a problem any more.[419]",3
3462,"Federer plays with his signature Wilson Pro Staff RF97 Autograph racquet. It has a 97 square inch head, 16x19 string pattern, 366 gram strung weight, 340 gram swing weight, 68 RA stiffness, and 9 point head light balance.[420] Federer strings his racquets using Wilson Natural Gut 16 gauge for his main strings and Luxilon ALU Power Rough 17 gauge (polyester) for his cross strings. In an interview in November 2017, Federer stated his favorite stringing tension is 26.5 kilograms (58.4 lb) mains & 25 kilograms (55.1 lb) crosses.[421]
",3
3463,"As a junior player, Federer played with a Wilson Pro Staff 6.0 85 square inch head racquet. He switched to a bigger custom-built Wilson 90 square inch head racquet in 2003.[422][423] His grip size was ​4.mw-parser-output .sr-only{border:0;clip:rect(0,0,0,0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px;white-space:nowrap} 3⁄8 inches (L3).[424] When asked about string tensions, Federer stated ""this depends on how warm the days are and with what kind of balls I play and against who I play. So you can see – it depends on several factors and not just the surface; the feeling I have is most important.""[425]
",3
3464,"Federer first signed with Nike footwear and apparel in 1994.[426] For the 2006 championships at Wimbledon, Nike designed a jacket emblazoned with a crest of three tennis racquets, symbolising the three Wimbledon Championships he had previously won, and which was updated the next year with four racquets after he won the Championship in 2006.[427] At Wimbledon 2008, and again in 2009, Nike continued this trend by making him a personalised cardigan that also had his own logo, an R and an F joined together,[428][429] which was originally designed by his wife, Mirka.[430]
",3
3465,"Federer's contract with Nike expired in March 2018, and he later signed a deal with Uniqlo.[431] It was reported that Uniqlo signed Federer for roughly $300 million for 10 years ($30 million per year), as opposed to Nike's previous deal with Federer, which was for roughly $10 million per year.[432] However, Federer does not have a shoe deal and chooses to wear Nike trainers.[433]
",3
3466,"In May 2020 Federer became the first tennis player to reach the top of the Forbes ""World's Highest Paid Athletes"" list.[434][435] He is endorsed by Japanese clothing company Uniqlo[431] and Swiss companies Nationale Suisse, Credit Suisse, Rolex, Lindt, Sunrise, and Jura Elektroapparate.[436] In 2010, his endorsement by Mercedes-Benz China was extended into a global partnership deal.[437] His other sponsors include Gillette, Wilson, Barilla, and Moët & Chandon.[434][438][439] Previously, he was an ambassador for Nike, NetJets, Emmi AG,[440] and for Maurice Lacroix.[441]
",3
3467,"Current through the 2021 Qatar Open.
",3
3468,"Note:
Federer received fourth-round walkovers at the US Open (2004 and 2012) and the Wimbledon Championships (2007), and a second-round walkover at the Australian Open (2012); these are not counted as wins
",3
3469,"As of 2019 Federer holds the third highest number of Guinness World Records within one discipline, a total of 30, which include 18 performance based records.[454]
",3
3470,"
",3
3471,"
",3
3472,"Table tennis, also known as ping-pong and whiff-whaff, is a sport in which two or four players hit a lightweight ball, also known as the ping-pong ball, back and forth across a table using small rackets. The game takes place on a hard table divided by a net. Except for the initial serve, the rules are generally as follows: players must allow a ball played toward them to bounce one time on their side of the table and must return it so that it bounces on the opposite side at least once. A point is scored when a player fails to return the ball within the rules. Play is fast and demands quick reactions. Spinning the ball alters its trajectory and limits an opponent's options, giving the hitter a great advantage.
",3
3473,"Table tennis is governed by the worldwide organization International Table Tennis Federation (ITTF), founded in 1926. ITTF currently includes 226 member associations.[3] The table tennis official rules are specified in the ITTF handbook.[4] Table tennis has been an Olympic sport since 1988,[5] with several event categories. From 1988 until 2004, these were men's singles, women's singles, men's doubles and women's doubles. Since 2008, a team event has been played instead of the doubles.
",3
3474,"The sport originated in Victorian England, where it was played among the upper-class as an after-dinner parlour game.[1][2] It has been suggested that makeshift versions of the game were developed by British military officers in India around the 1860s or 1870s, who brought it back with them.[6] A row of books stood up along the center of the table as a net, two more books served as rackets and were used to continuously hit a golf-ball.[7][8]
",3
3475,"The name ""ping-pong"" was in wide use before British manufacturer J. Jaques & Son Ltd trademarked it in 1901. The name ""ping-pong"" then came to describe the game played using the rather expensive Jaques's equipment, with other manufacturers calling it table tennis. A similar situation arose in the United States, where Jaques sold the rights to the ""ping-pong"" name to Parker Brothers. Parker Brothers then enforced its trademark for the term in the 1920s making the various associations change their names to ""table tennis"" instead of the more common, but trademarked, term.[9]
",3
3476,"The next major innovation was by James W. Gibb, a British enthusiast of table tennis, who discovered novelty celluloid balls on a trip to the US in 1901 and found them to be ideal for the game. This was followed by E.C. Goode who, in 1901, invented the modern version of the racket by fixing a sheet of pimpled, or stippled, rubber to the wooden blade. Table tennis was growing in popularity by 1901 to the extent that tournaments were being organized, books being written on the subject,[7] and an unofficial world championship was held in 1902. In those early days, the scoring system was the same as in lawn tennis.[10]
",3
3477,"Although both a ""Table Tennis Association"" and a ""Ping Pong Association"" existed by 1910,[10] a new Table Tennis Association was founded in 1921, and in 1926 renamed the English Table Tennis Association.[11] The International Table Tennis Federation (ITTF) followed in 1926.[1][12] London hosted the first official World Championships in 1926. In 1933, the United States Table Tennis Association, now called USA Table Tennis, was formed.[1][13]
",3
3478,"In the 1930s, Edgar Snow commented in Red Star Over China that the Communist forces in the Chinese Civil War had a ""passion for the English game of table tennis"" which he found ""bizarre"".[14] On the other hand, the popularity of the sport waned in 1930s Soviet Union, partly because of the promotion of team and military sports, and partly because of a theory that the game had adverse health effects.[15]
",3
3479,"In the 1950s, paddles that used a rubber sheet combined with an underlying sponge layer changed the game dramatically,[1] introducing greater spin and speed.[16] These were introduced to Britain by sports goods manufacturer S.W. Hancock Ltd. The use of speed glue beginning in the mid 1980s increased the spin and speed even further, resulting in changes to the equipment to ""slow the game down"". Table tennis was introduced as an Olympic sport at the Olympics in 1988.[17]
",3
3480,"After the 2000 Olympics in Sydney, the ITTF instituted several rule changes that were aimed at making table tennis more viable as a televised spectator sport.[18][19] First, the older 38 mm (1.50 in) balls were officially replaced by 40 mm (1.57 in) balls in October 2000.[7][20] This increased the ball's air resistance and effectively slowed down the game. By that time, players had begun increasing the thickness of the fast sponge layer on their paddles, which made the game excessively fast and difficult to watch on television. A few months later, the ITTF changed from a 21-point to an 11-point scoring system (and the serve rotation was reduced from five points to two), effective in September 2001.[7] This was intended to make games more fast-paced and exciting. The ITTF also changed the rules on service to prevent a player from hiding the ball during service, in order to increase the average length of rallies and to reduce the server's advantage, effective in 2002.[21]
For the opponent to have time to realize a serve is taking place, the ball must be tossed a minimum of 16 centimetres (6.3 in) in the air. The ITTF states that all events after July 2014 are played with a new poly material ball.[22]
[23]
",3
3481,"The international rules specify that the game is played with a sphere having a mass of 2.7 grams (0.095 oz) and a diameter of 40 millimetres (1.57 in).[24] The rules say that the ball shall bounce up 24–26 cm (9.4–10.2 in) when dropped from a height of 30.5 cm (12.0 in) onto a standard steel block thereby having a coefficient of restitution of 0.89 to 0.92. Balls are now made of a polymer instead of celluloid as of 2015, colored white or orange, with a matte finish. The choice of ball color is made according to the table color and its surroundings. For example, a white ball is easier to see on a green or blue table than it is on a grey table. Manufacturers often indicate the quality of the ball with a star rating system, usually from one to three, three being the highest grade. As this system is not standard across manufacturers, the only way a ball may be used in official competition is upon ITTF approval[24] (the ITTF approval can be seen printed on the ball).
",3
3482,"The 40 mm ball was introduced after the end of the 2000 Summer Olympics; previously a 38 mm ball was standard.[20] This created some controversies. Then World No 1 table tennis professional Vladimir Samsonov threatened to pull out of the World Cup, which was scheduled to debut the new regulation ball on October 12, 2000.[25]
",3
3483,"The table is 2.74 m (9.0 ft) long, 1.525 m (5.0 ft) wide, and 76 cm (2.5 ft) high with any continuous material so long as the table yields a uniform bounce of about 23 cm (9.1 in) when a standard ball is dropped onto it from a height of 30 cm (11.8 in), or about 77%.[26][27] The table or playing surface is uniformly dark coloured and matte, divided into two halves by a net at 15.25 cm (6.0 in) in height. The ITTF approves only wooden tables or their derivates. Concrete tables with a steel net or a solid concrete partition are sometimes available in outside public spaces, such as parks.[28]
",3
3484,"Players are equipped with a laminated wooden racket covered with rubber on one or two sides depending on the grip of the player. The ITTF uses the term ""racket"",[30] though ""bat"" is common in Britain, and ""paddle"" in the U.S. and Canada.
",3
3485,"The wooden portion of the racket, often referred to as the ""blade"", commonly features anywhere between one and seven plies of wood, though cork, glass fiber, carbon fiber, aluminum fiber, and Kevlar are sometimes used. According to the ITTF regulations, at least 85% of the blade by thickness shall be of natural wood.[31] Common wood types include balsa, limba, and cypress or ""hinoki"", which is popular in Japan. The average size of the blade is about 17 centimetres (6.7 in) long and 15 centimetres (5.9 in) wide, although the official restrictions only focus on the flatness and rigidity of the blade itself, these dimensions are optimal for most play styles.
",3
3486,"Table tennis regulations allow different rubber surfaces on each side of the racket.[32] Various types of surfaces provide various levels of spin or speed, and in some cases they nullify spin. For example, a player may have a rubber that provides much spin on one side of their racket, and one that provides no spin on the other. By flipping the racket in play, different types of returns are possible. To help a player distinguish between the rubber used by his opposing player, international rules specify that one side must be red while the other side must be black.[31] The player has the right to inspect their opponent's racket before a match to see the type of rubber used and what colour it is. Despite high speed play and rapid exchanges, a player can see clearly what side of the racket was used to hit the ball. Current rules state that, unless damaged in play, the racket cannot be exchanged for another racket at any time during a match.[33]
",3
3487,"According to ITTF rule 2.13.1, the first service is decided by lot,[34] normally a coin toss.[35] It is also common for one player (or the umpire/scorer) to hide the ball in one or the other hand, usually hidden under the table, allowing the other player to guess which hand the ball is in. The correct or incorrect guess gives the ""winner"" the option to choose to serve, receive, or to choose which side of the table to use. (A common but non-sanctioned method is for the players to play the ball back and forth three times and then play out the point. This is commonly referred to as ""serve to play"", ""rally to serve"", ""play for serve"", or ""volley for serve"".)
",3
3488,"In game play, the player serving the ball commences a play.[36] The server first stands with the ball held on the open palm of the hand not carrying the paddle, called the freehand, and tosses the ball directly upward without spin, at least 16 cm (6.3 in) high.[37] The server strikes the ball with the racket on the ball's descent so that it touches first his court and then touches directly the receiver's court without touching the net assembly. In casual games, many players do not toss the ball upward; however, this is technically illegal and can give the serving player an unfair advantage.
",3
3489,"The ball must remain behind the endline and above the upper surface of the table, known as the playing surface, at all times during the service. The server cannot use his/her body or clothing to obstruct sight of the ball; the opponent and the umpire must have a clear view of the ball at all times. If the umpire is doubtful of the legality of a service they may first interrupt play and give a warning to the server. If the serve is a clear failure or is doubted again by the umpire after the warning, the receiver scores a point.
",3
3490,"If the service is ""good"", then the receiver must make a ""good"" return by hitting the ball back before it bounces a second time on receiver's side of the table so that the ball passes the net and touches the opponent's court, either directly or after touching the net assembly.[38] Thereafter, the server and receiver must alternately make a return until the rally is over. Returning the serve is one of the most difficult parts of the game, as the server's first move is often the least predictable and thus most advantageous shot due to the numerous spin and speed choices at his or her disposal.
",3
3491,"A Let is a rally of which the result is not scored, and is called in the following circumstances:[39]
",3
3492,"A let is also called foul service, if the ball hits the server's side of the table, if the ball does not pass further than the edge and if the ball hits the table edge and hits the net.
",3
3493,"A point is scored by the player for any of several results of the rally:[40]
",3
3494,"A game shall be won by the player first scoring 11 points unless both players score 10 points, when the game shall be won by the first player subsequently gaining a lead of 2 points. A match shall consist of the best of any odd number of games.[43] In competition play, matches are typically best of five or seven games.
",3
3495,"Service alternates between opponents every two points (regardless of winner of the rally) until the end of the game, unless both players score ten points or the expedite system is operated, when the sequences of serving and receiving stay the same but each player serves for only one point in turn (Deuce).[44] The player serving first in a game receives first in the next game of the match.
",3
3496,"After each game, players switch sides of the table. In the last possible game of a match, for example the seventh game in a best of seven matches, players change ends when the first player scores five points, regardless of whose turn it is to serve. If the sequence of serving and receiving is out of turn or the ends are not changed, points scored in the wrong situation are still calculated and the game shall be resumed with the order at the score that has been reached.
",3
3497,"In addition to games between individual players, pairs may also play table tennis. Singles and doubles are both played in international competition, including the Olympic Games since 1988 and the Commonwealth Games since 2002.[45] In 2005, the ITTF announced that doubles table tennis only was featured as a part of team events in the 2008 Olympics.
",3
3498,"In doubles, all the rules of single play are applied except for the following.
",3
3499,"Service
",3
3500,"Order of play, serving and receiving
",3
3501,"If a game is unfinished after 10 minutes' play and fewer than 18 points have been scored, the expedite system is initiated.[41] The umpire interrupts the game, and the game resumes with players serving for one point in turn. If the expedite system is introduced while the ball is not in play, the previous receiver shall serve first. Under the expedite system, the server must win the point before the opponent makes 13 consecutive returns or the point goes to the opponent. The system can also be initiated at any time at the request of both players or pairs. Once introduced, the expedite system remains in force until the end of the match. A rule to shorten the time of a match, it is mainly seen in defensive players' games.
",3
3502,"Though table tennis players grip their rackets in various ways, their grips can be classified into two major families of styles, penhold and shakehand.[47] The rules of table tennis do not prescribe the manner in which one must grip the racket, and numerous grips are employed.
",3
3503,"The penhold grip is so-named because one grips the racket similarly to the way one holds a writing instrument.[48] The style of play among penhold players can vary greatly from player to player. The most popular style, usually referred to as the Chinese penhold style, involves curling the middle, ring, and fourth finger on the back of the blade with the three fingers always touching one another.[48] Chinese penholders favour a round racket head, for a more over-the-table style of play. In contrast, another style, sometimes referred to as the Japanese/Korean penhold grip, involves splaying those three fingers out across the back of the racket, usually with all three fingers touching the back of the racket, rather than stacked upon one another.[48] Sometimes a combination of the two styles occurs, wherein the middle, ring and fourth fingers are straight, but still stacked, or where all fingers may be touching the back of the racket, but are also in contact with one another. Japanese and Korean penholders will often use a square-headed racket for an away-from-the-table style of play. Traditionally these square-headed rackets feature a block of cork on top of the handle, as well as a thin layer of cork on the back of the racket, for increased grip and comfort. Penhold styles are popular among players originating from East Asian countries such as China, Japan, South Korea, and Taiwan.
",3
3504,"Traditionally, penhold players use only one side of the racket to hit the ball during normal play, and the side which is in contact with the last three fingers is generally not used. This configuration is sometimes referred to as ""traditional penhold"" and is more commonly found in square-headed racket styles. However, the Chinese developed a technique in the 1990s in which a penholder uses both sides of the racket to hit the ball, where the player produces a backhand stroke (most often topspin) known as a reverse penhold backhand by turning the traditional side of the racket to face one's self, and striking the ball with the opposite side of the racket. This stroke has greatly improved and strengthened the penhold style both physically and psychologically, as it eliminates the strategic weakness of the traditional penhold backhand.
",3
3505,"The shakehand grip is so-named because the racket is grasped as if one is performing a handshake.[49] Though it is sometimes referred to as the ""tennis"" or ""Western"" grip, it bears no relation to the Western tennis grip, which was popularized on the West Coast of the United States in which the racket is rotated 90°, and played with the wrist turned so that on impact the knuckles face the target.  In table tennis, ""Western"" refers to Western nations, for this is the grip that players native to Europe and the Americas have almost exclusively employed.
",3
3506,"The shakehand grip's simplicity and versatility, coupled with the acceptance among top-level Chinese trainers that the European style of play should be emulated and trained against, has established it as a common grip even in China.[50] Many world class European and East Asian players currently use the shakehand grip, and it is generally accepted that shakehands is easier to learn than penholder, allowing a broader range of playing styles both offensive and defensive.[49]
",3
3507,"The Seemiller grip is named after the American table tennis champion Danny Seemiller, who used it. It is achieved by placing the thumb and index finger on either side of the bottom of the racquet head and holding the handle with the rest of the fingers. Since only one side of the racquet is used to hit the ball, two contrasting rubber types can be applied to the blade, offering the advantage of ""twiddling"" the racket to fool the opponent. Seemiller paired inverted rubber with anti-spin rubber. Many players today combine inverted and long-pipped rubber. The grip is considered exceptional for blocking, especially on the backhand side, and for forehand loops of backspin balls.[51]
The Seemiller grip's popularity reached its apex in 1985 when four (Danny Seemiller, Ricky Seemiller, Eric Boggan and Brian Masters) of the United States' five participants in the World Championships used it.[51]
",3
3508,'A good ready position will enable you to move quickly into position and to stay balanced whilst playing powerful strokes.'[52],3
3509,"The stance in table tennis is also known as the 'ready position'. It is the position every player initially adopts when receiving and returns to after playing a shot in order to be prepared to make the next shot. It involves the feet being spaced wider than shoulder width and a partial crouch being adopted; the crouch is an efficient posture for moving quickly from and also preloads the muscles enabling a more dynamic movement. The upper torso is positioned slightly forward and the player is looking forwards. The racket is held at the ready with a bent arm. The position should feel balanced and provide a solid base for striking and quick lateral movement. Players may tailor their stance based upon their personal preferences, and alter it during the game based upon the specific circumstances.[53]
",3
3510,"Table tennis strokes generally break down into offensive and defensive categories.
",3
3511,"Also known as speed drive, a direct hit on the ball propelling it forward back to the opponent. This stroke differs from speed drives in other racket sports like tennis because the racket is primarily perpendicular to the direction of the stroke and most of the energy applied to the ball results in speed rather than spin, creating a shot that does not arc much, but is fast enough that it can be difficult to return. A speed drive is used mostly for keeping the ball in play, applying pressure on the opponent, and potentially opening up an opportunity for a more powerful attack.
",3
3512,"Perfected during the 1960s,[1][54] the loop is essentially the reverse of the chop. The racket is parallel to the direction of the stroke (""closed"") and the racket thus grazes the ball, resulting in a large amount of topspin. A good loop drive will arc quite a bit, and once striking the opponent's side of the table will jump forward, much like a kick serve in tennis. Most professional players nowadays, such as Ding Ning, Timo Boll and Zhang Jike, primarily use loop for offense.
",3
3513,"The counter-hit is usually a counterattack against drives, normally high loop drives. The racket is held closed and near to the ball, which is hit with a short movement ""off the bounce"" (immediately after hitting the table) so that the ball travels faster to the other side. Kenta Matsudaira is known for primarily using counter-hit for offense.
",3
3514,"When a player tries to attack a ball that has not bounced beyond the edge of the table, the player does not have the room to wind up in a backswing. The ball may still be attacked, however, and the resulting shot is called a flip because the backswing is compressed into a quick wrist action. A flip is not a single stroke and can resemble either a loop drive or a loop in its characteristics. What identifies the stroke is that the backswing is compressed into a short wrist flick.
",3
3515,"A player will typically execute a smash when the opponent has returned a ball that bounces too high or too close to the net. It is nearly always done with a forehand stroke. Smashing use rapid acceleration to impart as much speed on the ball as possible so that the opponent cannot react in time. The racket is generally perpendicular to the direction of the stroke. Because the speed is the main aim of this shot, the spin on the ball is often minimal, although it can be applied as well. An offensive table tennis player will think of a rally as a build-up to a winning smash. Smash is used more often with penhold grip.
",3
3516,"The push (or ""slice"" in Asia) is usually used for keeping the point alive and creating offensive opportunities. A push resembles a tennis slice: the racket cuts underneath the ball, imparting backspin and causing the ball to float slowly to the other side of the table. A push can be difficult to attack because the backspin on the ball causes it to drop toward the table upon striking the opponent's racket. In order to attack a push, a player must usually loop (if the push is long) or flip (if the push is short) the ball back over the net. Often, the best option for beginners is to simply push the ball back again, resulting in pushing rallies. Against good players, it may be the worst option because the opponent will counter with a loop, putting the first player in a defensive position. Pushing can have advantages in some circumstances, such as when the opponent makes easy mistakes.
",3
3517,"A chop is the defensive, backspin counterpart to the offensive loop drive.[55] A chop is essentially a bigger, heavier push, taken well back from the table. The racket face points primarily horizontally, perhaps a little bit upward, and the direction of the stroke is straight down. The object of a defensive chop is to match the topspin of the opponent's shot with backspin. A good chop will float nearly horizontally back to the table, in some cases having so much backspin that the ball actually rises. Such a chop can be extremely difficult to return due to its enormous amount of backspin. Some defensive players can also impart no-spin or sidespin variations of the chop. Some famous choppers include Joo Sae-hyuk and Wu Yang.
",3
3518,"A block is executed by simply placing the racket in front of the ball right after the ball bounces; thus, the ball rebounds back toward the opponent with nearly as much energy as it came in with. This requires precision, since the ball's spin, speed, and location all influence the correct angle of a block. It is very possible for an opponent to execute a perfect loop, drive, or smash, only to have the blocked shot come back just as fast. Due to the power involved in offensive strokes, often an opponent simply cannot recover quickly enough to return the blocked shot, especially if the block is aimed at an unexpected side of the table. Blocks almost always produce the same spin as was received, many times topspin.
",3
3519,"The defensive lob propels the ball about five metres in height, only to land on the opponent's side of the table with great amounts of spin.[56] The stroke itself consists of lifting the ball to an enormous height before it falls back to the opponent's side of the table. A lob can have nearly any kind of spin. Though the opponent may smash the ball hard and fast, a good defensive lob could be more difficult to return due to the unpredictability and heavy amounts of the spin on the ball.[56] Thus, though backed off the table by tens of feet and running to reach the ball, a good defensive player can still win the point using good lobs. Lob is used less frequently by professional players. A notable exception is Michael Maze.
",3
3520,"Adding spin onto the ball causes major changes in table tennis gameplay. Although nearly every stroke or serve creates some kind of spin, understanding the individual types of spin allows players to defend against and use different spins effectively.[57]
",3
3521,"Backspin is where the bottom half of the ball is rotating away from the player, and is imparted by striking the base of the ball with a downward movement.[57] At the professional level, backspin is usually used defensively in order to keep the ball low.[58] Backspin is commonly employed in service because it is harder to produce an offensive return, though at the professional level most people serve sidespin with either backspin or topspin.  Due to the initial lift of the ball, there is a limit on how much speed with which one can hit the ball without missing the opponent's side of the table. However, backspin also makes it harder for the opponent to return the ball with great speed because of the required angular precision of the return. Alterations are frequently made to regulations regarding equipment in an effort to maintain a balance between defensive and offensive spin choices.[citation needed] It is actually possible to smash with backspin offensively, but only on high balls that are close to the net.
",3
3522,"The topspin stroke has a smaller influence on the first part of the ball-curve. Like the backspin stroke, however, the axis of spin remains roughly perpendicular to the trajectory of the ball thus allowing for the Magnus effect to dictate the subsequent curvature. After the apex of the curve, the ball dips downwards as it approaches the opposing side, before bouncing. On the bounce, the topspin will accelerate the ball, much in the same way that a wheel which is already spinning would accelerate upon making contact with the ground. When the opponent attempts to return the ball, the topspin causes the ball to jump upwards and the opponent is forced to compensate for the topspin by adjusting the angle of his or her racket. This is known as ""closing the racket"".
",3
3523,"The speed limitation of the topspin stroke is minor compared to the backspin stroke. This stroke is the predominant technique used in professional competition because it gives the opponent less time to respond. In table tennis topspin is regarded as an offensive technique due to increased ball speed, lower bio-mechanical efficiency and the pressure that it puts on the opponent by reducing reaction time. (It is possible to play defensive topspin-lobs from far behind the table, but only highly skilled players use this stroke with any tactical efficiency.) Topspin is the least common type of spin to be found in service at the professional level, simply because it is much easier to attack a top-spin ball that is not moving at high speed.
",3
3524,"This type of spin is predominantly employed during service, wherein the contact angle of the racket can be more easily varied. Unlike the two aforementioned techniques, sidespin causes the ball to spin on an axis which is vertical, rather than horizontal. The axis of rotation is still roughly perpendicular to the trajectory of the ball. In this circumstance, the Magnus effect will still dictate the curvature of the ball to some degree. Another difference is that unlike backspin and topspin, sidespin will have relatively very little effect on the bounce of the ball, much in the same way that a spinning top would not travel left or right if its axis of rotation were exactly vertical. This makes sidespin a useful weapon in service, because it is less easily recognized when bouncing, and the ball ""loses"" less spin on the bounce. Sidespin can also be employed in offensive rally strokes, often from a greater distance, as an adjunct to topspin or backspin. This stroke is sometimes referred to as a ""hook"". The hook can even be used in some extreme cases to circumvent the net when away from the table.
",3
3525,"Players employ this type of spin almost exclusively when serving, but at the professional level, it is also used from time to time in the lob. Unlike any of the techniques mentioned above, corkspin (or ""drill-spin"") has the axis of spin relatively parallel to the ball's trajectory, so that the Magnus effect has little or no effect on the trajectory of a cork-spun ball: upon bouncing, the ball will dart right or left (according to the direction of the spin), severely complicating the return. In theory this type of spin produces the most obnoxious effects, but it is less strategically practical than sidespin or backspin, because of the limitations that it imposes upon the opponent during their return. Aside from the initial direction change when bouncing, unless it goes out of reach, the opponent can counter with either topspin or backspin. A backspin stroke is similar in the fact that the corkspin stroke has a lower maximum velocity, simply due to the contact angle of the racket when producing the stroke. To impart a spin on the ball which is parallel to its trajectory, the racket must be swung more or less perpendicular to the trajectory of the ball, greatly limiting the forward momentum that the racket transfers to the ball. Corkspin is almost always mixed with another variety of spin, since alone, it is not only less effective but also harder to produce.
",3
3526,"Competitive table tennis is popular in East Asia and Europe, and has been[vague] gaining attention in the United States.[59] The most important international competitions are the World Table Tennis Championships, the Table Tennis World Cup, the Olympics and the ITTF World Tour. Continental competitions include the following: 
",3
3527,"Chinese players have won 60% of the men's World Championships since 1959;[60] in the women's competition for the Corbillin Cup, Chinese players have won all but three of the World Championships since 1971.[61] Other strong teams come from East Asia and Europe, including countries such as Austria, Belarus, Germany, Hong Kong, Portugal, Japan, South Korea, Singapore, Sweden, and Taiwan.[62]
",3
3528,"There are professional competitions at the clubs level; the respective leagues of Austria, Belgium, China (China Table Tennis Super League), Japan (T.League), France, Germany (Bundesliga), and Russia are examples of the highest level. There are also some important international club teams competitions such as the European Champions League and its former competitor,[vague] the European Club Cup, where the top club teams from European countries compete.
",3
3529,"According to the New York Times, 31% of the table tennis players at the 2016 Summer Olympics were naturalized. The rate was twice as high as the next sport, basketball, which featured 15% of naturalized players.[63]
",3
3530,"In particular, Chinese-born players representing Singapore have won three Olympic medals, more than native Singaporeans have ever won in all sports. However, these successes have been very controversial in Singapore.[64] In 2014, Singapore Table Tennis Association's president Lee Bee Wah quit over this issue;[65] however, her successor Ellen Lee has basically continued on this path.[66]
",3
3531,"The rate of naturalization accelerated after the ITTF's 2009 decision (one year after China won every possible Olympic medal in the sport) to reduce the number of entries per association in both the Olympics and the World Table Tennis Championships.[citation needed]
",3
3532,"In 2019, the ITTF adopted new regulations which state that players who acquired a new nationality may not represent their new association before:[67]
",3
3533,"An official hall of fame exists at the ITTF Museum.[72] A Grand Slam is earned by a player who wins singles crowns at the Olympic Games, World Championships, and World Cup.[73] Jan-Ove Waldner of Sweden first completed the grand slam at 1992 Olympic Games. Deng Yaping of China is the first female recorded at the inaugural Women's World Cup in 1996. The following table presents an exhaustive list of all players to have completed a grand slam.
",3
3534,"Jean-Philippe Gatien (France) and Wang Hao (China) won both the World Championships and the World Cup, but lost in the gold medal matches at the Olympics. Jörgen Persson (Sweden) also won the titles except the Olympic Games. Persson is one of the three table tennis players to have competed at seven Olympic Games. Ma Lin (China) won both the Olympic gold and the World Cup, but lost (three times, in 1999, 2005, and 2007) in the finals of the World Championships.
",3
3535,"Founded in 1926, the International Table Tennis Federation (ITTF) is the worldwide governing body for table tennis, which maintains an international ranking system in addition to organizing events like the World Table Tennis Championships.[13]  In 2007, the governance for table tennis for persons with a disability was transferred from the International Paralympic Committee to the ITTF.[83]
",3
3536,"On many continents, there is a governing body responsible for table tennis on that continent. For example, the European Table Tennis Union (ETTU) is the governing body responsible for table tennis in Europe.[84] There are also national bodies and other local authorities responsible for the sport, such as USA Table Tennis (USATT), which is the national governing body for table tennis in the United States.[13]
",3
3537,"Hardbat table tennis uses rackets with short outward ""pips"" and no sponge, resulting in decreased speeds and reduced spin. World Championship of Ping Pong uses old-fashioned wooden paddles covered with sandpaper.
",3
3538,"
",3
3539,"
",3
3540,"Golf is a club-and-ball sport in which players use various clubs to hit balls into a series of holes on a course in as few strokes as possible.
",3
3541,"Golf, unlike most ball games, cannot and does not utilize a standardized playing area, and coping with the varied terrains encountered on different courses is a key part of the game. The game at the usual level is played on a course with an arranged progression of 18 holes, though recreational courses can be smaller, often having nine holes. Each hole on the course must contain a teeing ground to start from, and a putting green containing the actual hole or cup 4 1⁄4 inches (11 cm) in diameter. There are other standard forms of terrain in between, such as the fairway, rough (long grass), bunkers (or ""sand traps""), and various hazards (water, rocks) but each hole on a course is unique in its specific layout and arrangement.
",3
3542,"Golf is played for the lowest number of strokes by an individual, known as stroke play, or the lowest score on the most individual holes in a complete round by an individual or team, known as match play. Stroke play is the most commonly seen format at all levels, but most especially at the elite level.
",3
3543,"The modern game of golf originated in 15th century Scotland. The 18-hole round was created at the Old Course at St Andrews in 1764. Golf's first major, and the world's oldest tournament in existence, is The Open Championship, also known as the British Open, which was first played in 1860 at the Prestwick Golf Club in Ayrshire, Scotland. This is one of the four major championships in men's professional golf, the other three being played in the United States: The Masters, the U.S. Open, and the PGA Championship.
",3
3544,"While the modern game of golf originated in 15th-century Scotland, the game's ancient origins are unclear and much debated.
",3
3545,"Some historians[3] trace the sport back to the Roman game of paganica, in which participants used a bent stick to hit a stuffed leather ball. One theory asserts that paganica spread throughout Europe as the Romans conquered most of the continent, during the first century BC, and eventually evolved into the modern game.[4]
",3
3546,"Others cite chuiwan (捶丸; ""chui"" means striking and ""wan"" means small ball)[5] as the progenitor, a Chinese game played between the eighth and fourteenth centuries.[6] A Ming Dynasty scroll by the artist Youqiu dating back to 1368 entitled ""The Autumn Banquet"" shows a member of the Chinese Imperial court swinging what appears to be a golf club at a small ball with the aim of sinking it into a hole.[5] The game is thought to have been introduced into Europe during the Middle Ages.[7]
",3
3547,"Another early game that resembled modern golf was known as cambuca in England and chambot in France.[7] The Persian game chowkan is another possible ancient origin, albeit being more polo-like. In addition, kolven (a game involving a ball and curved bats) was played annually in Loenen, Netherlands, beginning in 1297, to commemorate the capture of the assassin of Floris V, a year earlier.
",3
3548,"The modern game originated in Scotland, where the first written record of golf is James II's banning of the game in 1457, as an unwelcome distraction to learning archery.[8] James IV lifted the ban in 1502 when he became a golfer himself, with golf clubs first recorded in 1503–1504: ""For golf clubbes and balles to the King that he playit with"".[9] To many golfers, the Old Course at St Andrews, a links course dating to before 1574, is considered to be a site of pilgrimage.[10] In 1764, the standard 18-hole golf course was created at St Andrews when members modified the course from 22 to 18 holes.[11] Golf is documented as being played on Musselburgh Links, East Lothian, Scotland as early as 2 March 1672, which is certified as the oldest golf course in the world by Guinness World Records.[12][13] The oldest surviving rules of golf were compiled in March 1744 for the Company of Gentlemen Golfers, later renamed The Honourable Company of Edinburgh Golfers, which was played at Leith, Scotland.[14] The world's oldest golf tournament in existence, and golf's first major, is The Open Championship, which was first played on 17 October 1860 at Prestwick Golf Club, in Ayrshire, Scotland, with Scottish golfers winning the earliest majors.[15] Two Scotsmen from Dunfermline, John Reid and Robert Lockhart, first demonstrated golf in the U.S. by setting up a hole in an orchard in 1888, with Reid setting up America's first golf club the same year, Saint Andrew's Golf Club in Yonkers, New York.[16]
",3
3549,"A golf course consists of either 9 or 18 holes, each with a teeing ground that is set off by two markers showing the bounds of the legal tee area, fairway, rough and other hazards, and the putting green surrounded by the fringe with the pin (normally a flagstick) and cup.
",3
3550,"The levels of grass are varied to increase difficulty, or to allow for putting in the case of the green. While many holes are designed with a direct line-of-sight from the teeing area to the green, some holes may bend either to the left or to the right. This is commonly called a ""dogleg"", in reference to a dog's knee. The hole is called a ""dogleg left"" if the hole angles leftwards and ""dogleg right"" if it bends right. Sometimes, a hole's direction may bend twice; this is called a ""double dogleg"".
",3
3551,"A regular golf course consists of 18 holes, but nine-hole courses are common and can be played twice through for a full round of 18 holes.[17][18]
",3
3552,"Early Scottish golf courses were primarily laid out on links land, soil-covered sand dunes directly inland from beaches.[19] This gave rise to the term ""golf links"", particularly applied to seaside courses and those built on naturally sandy soil inland.[20]
",3
3553,"The first 18-hole golf course in the United States was on a sheep farm in Downers Grove, Illinois, in 1892. The course is still there today.[21]
",3
3554,"Every round of golf is based on playing a number of holes in a given order. A ""round"" typically consists of 18 holes that are played in the order determined by the course layout. Each hole is played once in the round on a standard course of 18 holes. The game can be played by any number of people, although a typical group playing will have 1-4 people playing the round. The typical amount of time required for pace of play for a 9-hole round is two hours and four hours for an 18-hole round.
",3
3555,"Playing a hole on a golf course is initiated by putting a ball into play by striking it with a club on the teeing ground (also called the tee box, or simply the tee). For this first shot on each hole, it is allowed but not required for the golfer to place the ball on a tee prior to striking it. A tee is a small peg that can be used to elevate the ball slightly above the ground up to a few centimetres high. Tees are commonly made of wood but may be constructed of any material, including plastic. Traditionally, golfers used mounds of sand to elevate the ball, and containers of sand were provided for the purpose. A few courses still require sand to be used instead of peg tees, to reduce litter and reduce damage to the teeing ground. Tees help reduce the interference of the ground or grass on the movement of the club making the ball easier to hit, and also places the ball in the very centre of the striking face of the club (the ""sweet spot"") for better distance.
",3
3556,"When the initial shot on a hole is intended to move the ball a long distance, typically more than 225 yards (210 m), the shot is commonly called a ""drive"" and is generally made with a long-shafted, large-headed wood club called a ""driver"". Shorter holes may be initiated with other clubs, such as higher-numbered woods or irons. Once the ball comes to rest, the golfer strikes it again as many times as necessary using shots that are variously known as a ""lay-up"", an ""approach"", a ""pitch"", or a ""chip"", until the ball reaches the green, where he or she then ""putts"" the ball into the hole (commonly called ""sinking the putt"" or ""holing out""). The goal of getting the ball into the hole (""holing"" the ball) in as few strokes as possible may be impeded by obstacles such as areas of longer grass called ""rough"" (usually found alongside fairways), which both slows any ball that contacts it and makes it harder to advance a ball that has stopped on it; ""doglegs"", which are changes in the direction of the fairway that often require shorter shots to play around them; bunkers (or sand traps); and water hazards such as ponds or streams.[17]
",3
3557,"In stroke play competitions played according to strict rules, each player plays his or her ball until it is holed no matter how many strokes that may take. In match play it is acceptable to simply pick up one's ball and ""surrender the hole"" after enough strokes have been made by a player that it is mathematically impossible for the player to win the hole. It is also acceptable in informal stroke play to surrender the hole after hitting three strokes more than the ""par"" rating of the hole (a ""triple bogey"" - see below); while technically a violation of Rule 3–2, this practice speeds play as a courtesy to others, and avoids ""runaway scores"", excessive frustration and injuries caused by overexertion.
",3
3558,"The total distance from the first teeing ground to the 18th green can be quite long; total yardages ""through the green"" can be in excess of 7,000 yards (6.4 km), and when adding in the travel distance between the green of one hole and the tee of the next, even skilled players may easily travel five miles (8 km) or more during a round. At some courses, electric golf carts are used to travel between shots, which can speed-up play and allows participation by individuals unable to walk a whole round. On other courses players generally walk the course, either carrying their bag using a shoulder strap or using a ""golf trolley"" for their bag. These trolleys may or may not be battery assisted. At many amateur tournaments including U.S. high school and college play, players are required to walk and to carry their own bags, but at the professional and top amateur level, as well as at high-level private clubs, players may be accompanied by caddies, who carry and manage the players' equipment and who are allowed by the rules to give advice on the play of the course.[22] A caddie's advice can only be given to the player or players for whom the caddie is working, and not to other competing players.
",3
3559,"The rules of golf are internationally standardised and are jointly governed by The R&A, spun off in 2004 from The Royal and Ancient Golf Club of St Andrews (founded 1754), and the United States Golf Association (USGA).[23][24] With the aim of simplifying the rules, in 2017 the USGA and R&A undertook a complete rewrite.[25] The new rule book came into effect in January 2019.[26]
",3
3560,"The underlying principle of the rules is fairness. As stated on the back cover of the official rule book:
",3
3561,"There are strict regulations regarding the amateur status of golfers.[27] Essentially, anybody who has ever received payment or compensation for giving instruction, or played golf for money, is not considered an amateur and may not participate in competitions limited solely to amateurs. However, amateur golfers may receive expenses that comply with strict guidelines and they may accept non-cash prizes within the limits established by the Rules of Amateur Status.
",3
3562,"In addition to the officially printed rules, golfers also abide by a set of guidelines called golf etiquette. Etiquette guidelines cover matters such as safety, fairness, pace of play, and a player's obligation to contribute to the care of the course. Though there are no penalties for breach of etiquette rules, players generally follow the rules of golf etiquette in an effort to improve everyone's playing experience.
",3
3563,"Penalty strokes are incurred in certain situations and are counted towards a player's score as if there were extra swing(s) at the ball. Either one or two strokes are added for most rule infractions or for taking relief from various situations, with the ""general penalty"" defined as two-strokes, and disqualification for severe or repeated rule breaches. Examples include:
",3
3564,"Golf clubs are used to hit the golf ball. Each club is composed of a shaft with a lance (or ""grip"") on the top end and a club head on the bottom. Long clubs, which have a lower amount of degree loft, are those meant to propel the ball a comparatively longer distance, and short clubs a higher degree of loft and a comparatively shorter distance. The actual physical length of each club is longer or shorter, depending on the distance the club is intended to propel the ball.
",3
3565,"Golf clubs have traditionally been arranged into three basic types. Woods are large-headed, long-shafted clubs meant to propel the ball a long distance from relatively ""open"" lies, such as the teeing ground and fairway. Of particular importance is the driver or ""1-wood"", which is the lowest lofted wood club, and in modern times has become highly specialized for making extremely long-distance tee shots, up to 300 yards (270 m), or more, in a professional golfer's hands. Traditionally these clubs had heads made of a hardwood, hence the name, but virtually all modern woods are now made of metal such as titanium, or of composite materials. Irons are shorter-shafted clubs with a metal head primarily consisting of a flat, angled striking face. Traditionally the clubhead was forged from iron; modern iron clubheads are investment-cast from a steel alloy. Irons of varying loft are used for a variety of shots from virtually anywhere on the course, but most often for shorter-distance shots approaching the green, or to get the ball out of tricky lies such as sand traps. The third class is the putter, which evolved from the irons to create a low-lofted, balanced club designed to roll the ball along the green and into the hole. Putters are virtually always used on the green or in the surrounding rough/fringe. A fourth class, called hybrids, evolved as a cross between woods and irons, and are typically seen replacing the low-lofted irons with a club that provides similar distance, but a higher launch angle and a more forgiving nature.
",3
3566,"A maximum of 14 clubs is allowed in a player's bag at one time during a stipulated round. The choice of clubs is at the golfer's discretion, although every club must be constructed in accordance with parameters outlined in the rules. (Clubs that meet these parameters are usually called ""conforming"".) Violation of these rules can result in disqualification.
",3
3567,"The exact shot hit at any given time on a golf course, and which club is used to accomplish the shot, are always completely at the discretion of the golfer; in other words, there is no restriction whatsoever on which club a golfer may or may not use at any time for any shot.
",3
3568,"Golf balls are spherical, usually white (although other colours are allowed), and minutely pock-marked by dimples that decrease aerodynamic drag by increasing air turbulence around the ball in motion, which delays ""boundary layer"" separation and reduces the drag-inducing ""wake"" behind the ball,
thereby allowing the ball to fly farther.[29] The combination of a soft ""boundary layer"" and a hard ""core"" enables both distance and spin.
",3
3569,"A tee is allowed only for the first stroke on each hole, unless the player must hit a provisional tee shot or replay his or her first shot from the tee.
",3
3570,"Many golfers wear golf shoes with metal or plastic spikes designed to increase traction, thus allowing for longer and more accurate shots.
",3
3571,"A golf bag is used to transport golf clubs and the player's other or personal equipment. Golf bags have several pockets designed for carrying equipment and supplies such as tees, balls, and gloves. Golf bags can be carried, pulled on a trolley or harnessed to a motorized golf cart during play. Golf bags usually have both a hand strap and shoulder strap for carrying, others may be carried over both shoulders like a backpack, and often bags have retractable legs that allow the bag to stand upright when at rest.
",3
3572,"The golf swing is outwardly similar to many other motions involving swinging a tool or playing implement, such as an axe or a baseball bat. However, unlike many of these motions, the result of the swing is highly dependent on several sub-motions being properly aligned and timed. These ensure that the club travels up to the ball in line with the desired path; that the clubface is in line with the swing path; and that the ball hits the centre or ""sweet spot"" of the clubface. The ability to do this consistently, across a complete set of clubs with a wide range of shaft lengths and clubface areas, is a key skill for any golfer, and takes a significant effort to achieve.
",3
3573,"Stance refers to how the golfer positions themselves in order to play a stroke; it is fundamentally important in being able to play a stroke effectively. The stance adopted is determined by what stroke is being played. All stances involve a slight crouch. This allows for a more efficient striking posture whilst also isometrically preloading the muscles of the legs and core; this allows the stroke to be played more dynamically and with a greater level of overall control. When adopting their stance golfers start with the non-dominant side of the body facing the target (for a right-hander, the target is to their left). Setting the stance in regard to the position of the ball, and placing the clubhead behind the ball, is known as being at address; when in this position the player's body and the centerline of the club face are positioned parallel to the desired line of travel, with the feet either perpendicular to that line or slightly splayed outward. The feet are commonly shoulder-width apart for middle irons and putters, narrower for short irons and wider for long irons and woods. The ball is typically positioned more to the ""front"" of the player's stance (closer to the leading foot) for lower-lofted clubs, with the usual ball position for a drive being just behind the arch of the leading foot. The ball is placed further ""back"" in the player's stance (toward the trailing foot) as the loft of the club to be used increases. Most iron shots and putts are made with the ball roughly centered in the stance, while a few mid- and short-iron shots are made with the ball slightly behind the centre of the stance to ensure consistent contact between the ball and clubface, so the ball is on its way before the club continues down into the turf.
",3
3574,"The golfer chooses a golf club, grip, and stroke appropriate to the distance:
",3
3575,"Having chosen a club and stroke to produce the desired distance, the player addresses the ball by taking their stance to the side of it and (except when the ball lies in a hazard) grounding the club behind the ball. The golfer then takes their backswing, rotating the club, their arms and their upper body away from the ball, and then begins their swing, bringing the clubhead back down and around to hit the ball. A proper golf swing is a complex combination of motions, and slight variations in posture or positioning can make a great deal of difference in how well the ball is hit and how straight it travels. The general goal of a player making a full swing is to propel the clubhead as fast as possible while maintaining a single ""plane"" of motion of the club and clubhead, to send the clubhead into the ball along the desired path of travel and with the clubhead also pointing that direction.
",3
3576,"Accuracy and consistency are typically stressed over pure distance. A player with a straight drive that travels only 220 yards (200 m) will nevertheless be able to accurately place the ball into a favourable lie on the fairway, and can make up for the lesser distance of any given club by simply using ""more club"" (a lower loft) on their tee shot or on subsequent fairway and approach shots. However, a golfer with a drive that may go 280 yards (260 m) but often does not fly straight will be less able to position their ball advantageously; the ball may ""hook"", ""pull"", ""draw"", ""fade"", ""push"" or ""slice"" off the intended line and land out of bounds or in the rough or hazards, and thus the player will require many more strokes to hole out.
",3
3577,"A golf stroke uses the muscles of the core (especially erector spinae muscles and latissimus dorsi muscle when turning), hamstring, shoulder, and wrist. Stronger muscles in the wrist can prevent them from being twisted during swings, whilst stronger shoulders increase the turning force. Weak wrists can also transmit the force to elbows and even neck and lead to injury. (When a muscle contracts, it pulls equally from both ends and, to have movement at only one end of the muscle, other muscles must come into play to stabilize the bone to which the other end of the muscle is attached.) Golf is a unilateral exercise that can break body balances, requiring exercises to keep the balance in muscles.[30][31]
",3
3578,"Putting is considered to be the most important component of the game of golf. As the game of golf has evolved, there have been many different putting techniques and grips that have been devised to give golfers the best chance to make putts. When the game originated, golfers would putt with their dominant hand on the bottom of the grip and their weak hand on top of the grip. This grip and putting style is known as ""conventional"". There are many variations of conventional including overlap, where the golfer overlaps the off hand index finger onto off the dominant pinky; interlock, where the offhand index finger interlocks with the dominant pinky and ring finger; double or triple overlap and so on.[32] Recently, ""cross handed"" putting has become a popular trend amongst professional golfers and amateurs. Cross handed putting is the idea that the dominant hand is on top of the grip where the weak hand is on the bottom. This grip restricts the motion in your dominant hand and eliminates the possibility of wrist breakdowns through the putting stroke.[33]
",3
3579,"Other notable putting styles include ""the claw"", a style that has the grip directly in between the thumb and index finger of the dominant hand while the palm faces the target.[34] The weak hand placed normally on the putter. Anchored putting, a style that requires a longer putter shaft that can be anchored into the player's stomach or below the chin; the idea is to stabilize one end of the putter thus creating a more consistent pendulum stroke. This style has been banned on professional circuits since 2016.[35]
",3
3580,"A hole is classified by its par, which gives an indication of the number of strokes a skilled golfer may be expected to need to complete play of the hole.[17] The primary factor for classifying the par of a relatively straight, hazard-free hole is the distance from the tee to the green, and calculates the number of strokes a skilled golfer is expected to require to reach the green with an additional allowance of 2 putts. As such, the minimum par of any hole is 3; one stroke for the tee shot and two putts. Par 3, 4 and 5 holes are commonplace on golf courses; far more rarely, courses may feature par-6 and even par-7 holes.
",3
3581,"For men, a typical par-3 hole is less than 250 yards (230 m) in length, with a par-4 hole ranging between 251–450 yards (230–411 m), and a par-5 hole being longer than 450 yards (410 m); for women these boundaries are lower, and for professionals they are much increased. The rare par-6s can stretch well over 650 yards (590 m). These distances are based on the typical scratch golfer's drive distance of between 240 and 280 yards (220 and 260 m). Although length is the primary factor in calculating par, other factors are taken into account; however the number of strokes a scratch golfer should take to make the green remains foremost. Factors affecting the calculation include altitude, gradient of the land from the tee to green, and forced ""lay-ups"" due to dog-legs (sharp bends) or obstacles (e.g. bunkers, water hazards).[36]
",3
3582,"Getting the ball onto the green in two strokes less than par, and hence meeting the par calculation criteria, is called making ""green in regulation"" or GIR.[37] Missing a GIR does not necessarily mean a golfer will not make par, but it does make doing so more difficult as it reduces the number of putts available; conversely, making a GIR does not guarantee a par, as the player might require three or more putts to ""hole out"". Professional golfers typically make between 60% and 70% of greens in regulation.[38]
",3
3583,"Eighteen-hole courses typically total to an overall par score of 70 to 72 for a complete round; with most holes having a par of 4, and a smaller number of par-3 and par-5 holes. Additionally, courses may be classified according to their play difficulty, which may be used to calculate a golfer's handicap.[39] The two primary difficulty ratings in the U.S. are the Course Rating, which is the expected score for a zero-handicap ""scratch golfer"", and the Slope Rating, which is a measure of how much worse a ""bogey golfer"" (handicap around 20) would be expected to play than a ""scratch golfer"" relative to their handicap.
",3
3584,"The goal is to play as few strokes per round as possible. A golfer's number of strokes in a hole, course, or tournament is compared to its respective par score, and is then reported either as the number that the golfer was ""under-"" or ""over-par"", or if it was ""equal to par"". A hole in one (or an ""ace"") occurs when a golfer sinks their ball into the cup with their first stroke from the tee. Common scores for a hole also have specific terms.[17]
",3
3585,"In a typical professional tournament or among ""scratch"" amateur players, ""birdie-bogey"" play is common; a player will ""lose"" a stroke by bogeying a hole, then ""gain"" one by scoring a birdie. Eagles are uncommon but not rare; however, only 18 players have scored an albatross in a men's major championship. One of the rarest feats in golf is the condor, which has never occurred in a professional tournament. Only five condors have been verified to have ever occurred, although none of the courses involved were professionally accredited.[40]
",3
3586,"There are two basic forms of golf play, match play and stroke play. Stroke play is more popular.
",3
3587,"Two players (or two teams) play each hole as a separate contest against each other in what is called match play. The party with the lower score wins that hole, or if the scores of both players or teams are equal the hole is ""halved"" (or tied). The game is won by the party that wins more holes than the other. In the case that one team or player has taken a lead that cannot be overcome in the number of holes remaining to be played, the match is deemed to be won by the party in the lead, and the remainder of the holes are not played. For example, if one party already has a lead of six holes, and only five holes remain to be played on the course, the match is over and the winning party is deemed to have won ""6 & 5"". At any given point, if the lead is equal to the number of holes remaining, the party leading the match is said to be ""dormie"", and the match is continued until the party increases the lead by one hole or ties any of the remaining holes, thereby winning the match, or until the match ends in a tie with the lead player's opponent winning all remaining holes. When the game is tied after the predetermined number of holes have been played, it may be continued until one side takes a one-hole lead.[17]
",3
3588,"The score achieved for each and every hole of the round or tournament is added to produce the total score, and the player with the lowest score wins in stroke play. Stroke play is the game most commonly played by professional golfers. If there is a tie after the regulation number of holes in a professional tournament, a playoff takes place between all tied players. Playoffs either are sudden death or employ a pre-determined number of holes, anywhere from three to a full 18. In sudden death, a player who scores lower on a hole than all of his opponents wins the match. If at least two players remain tied after such a playoff using a pre-determined number of holes, then play continues in sudden death format, where the first player to win a hole wins the tournament.
",3
3589,"There are many variations in scoring and playing formats in the game of golf, some officially defined in the Rules of Golf. Variations include the popular Stableford scoring system, and various team formats. Some common and popular examples are listed below.
",3
3590,"There are also variations on the usual starting procedure where everyone begins from the first tee and plays all holes in order, though to the eighteenth. In large field tournaments, especially on professional tours, a two tee start is commonplace, where the field will be split between starting on the first tee and the tenth tee (sometimes the eighth or eleventh depending on proximity to the clubhouse). Shotgun starts are mainly used for amateur tournament or society play. In this variant, each of the groups playing starts their game on a different hole, allowing for all players to start and end their round at roughly the same time. For example, a group starting on hole 5 will play through to the 18th hole and continue with hole 1, ending their round on hole 4.
",3
3591,"A bogey or par competition is a scoring format sometimes seen in informal tournaments. Its scoring is similar to match play, except each player compares their hole score to the hole's par rating instead of the score of another player. The player ""wins"" the hole if they score a birdie or better, they ""lose"" the hole if they score a bogey or worse, and they ""halve"" the hole by scoring par. By recording only this simple win-loss-halve score on the sheet, a player can shrug off a very poorly-played hole with a simple ""-"" mark and move on. As used in competitions, the player or pair with the best win-loss ""differential"" wins the competition.
",3
3592,"The Stableford system is a simplification of stroke play that awards players points based on their score relative to the hole's par; the score for a hole is calculated by taking the par score, adding 2, then subtracting the player's hole score, making the result zero if negative. Alternately stated, a double bogey or worse is zero points, a bogey is worth one point, par is two, a birdie three, an eagle four, and so on. The advantages of this system over stroke play are a more natural ""higher is better"" scoring, the ability to compare Stableford scores between plays on courses with different total par scores (scoring an ""even"" in stroke play will always give a Stableford score of 36), discouraging the tendency to abandon the entire game after playing a particularly bad hole (a novice playing by strict rules may score as high as an 8 or 10 on a single difficult hole; their Stableford score for the hole would be zero, which puts them only two points behind par no matter how badly they played), and the ability to simply pick up one's ball once it is impossible to score any points for the hole, which speeds play.
",3
3593,"The USGA and R&A sanction a ""Modified Stableford"" system for scratch players, which makes par worth zero, a birdie worth 2, eagle 5 and double-eagle 8, while a bogey is a penalty of −1 and a double-bogey or worse −3. As with the original system, the highest score wins the game, and terrible scores on one or two holes will not ruin a player's overall score, but this system rewards ""bogey-birdie"" play more than the original, encouraging golfers to try to make riskier birdie putt or eagle chipshots instead of simply parring each hole.[17]
",3
3594,"A handicap is a numerical measure of a golfer's potential scoring ability over 18 holes. It is used to enable players of widely varying abilities to compete against one another. Better players are those with the lowest handicaps, and someone with a handicap of 0 or less is often referred to as a scratch golfer. Handicap systems vary throughout the world and use different methods to assess courses and calculate handicaps. In order to address difficulties in translating between these systems the USGA and The R&A, working with the various existing handicapping authorities, devised a new World Handicap System which is set to be introduced globally starting in 2020.[46]
",3
3595,"Golf courses are assessed and rated according to the average good score of a scratch golfer, taking into account a multitude of factors affecting play, such as length, obstacles, undulations, etc. A player's handicap gives an indication of the number of strokes above this course rating that the player will make over the course of an ""average best"" round of golf, i.e. scoring near their potential, above average.[47] Lower handicap players are generally the most consistent, so can be expected to play to this standard or better more often than higher handicappers. Some handicap systems also account for differences in scoring difficulty between low and high handicap golfer. They do this by means of assessing and rating courses according to the average good score of a ""bogey golfer"", a player with a handicap of around 20. This is used with the course rating to calculate a slope rating, which is used to adjust golfer's handicap to produce a playing handicap for the course and set of tees being used.[48]
",3
3596,"Handicap systems have potential for abuse by players who may intentionally play badly to increase their handicap (sandbagging) before playing to their potential at an important event with a valuable prize. For this reason, handicaps are not used in professional golf, but they can still be calculated and used along with other criteria to determine the relative strengths of various professional players. Touring professionals, being the best of the best, have negative handicaps; they can be expected, more often than not, to score lower than the Course Rating on any course.
",3
3597,"In 2005 Golf Digest calculated that the countries with most golf courses per capita, in order, were: Scotland, New Zealand, Australia, Ireland, Canada, Wales, United States, Sweden, and England (countries with fewer than 500,000 people were excluded).
",3
3598,"The number of courses in other territories has increased, an example of this being the expansion of golf in China. The first golf course in China opened in 1984, but by the end of 2009 there were roughly 600 in the country. For much of the 21st century, development of new golf courses in China has been officially banned (with the exception of the island province of Hainan), but the number of courses had nonetheless tripled from 2004 to 2009; the ""ban"" has been evaded with the government's tacit approval simply by not mentioning golf in any development plans.[49]
",3
3599,"In the United States, the number of people who play golf twenty-five times or more per year decreased from 6.9 million in 2000 to 4.6 million in 2005,[50] according to the National Golf Foundation. The NGF reported that the number who played golf at all decreased from 30 to 26 million over the same period.[50]
",3
3600,"In February 1971, astronaut Alan Shepard became the first person to golf anywhere other than Earth. He smuggled a golf club and two golf balls on board Apollo 14 with the intent to golf on the Moon. He attempted two drives. He shanked the first attempt, but it is estimated his second went more than 200 yards (180 m).[51]
",3
3601,"Number of golf courses by country in 2015. Below are the top 18 countries that have the most golf courses.[52]
",3
3602,"The majority of professional golfers work as club or teaching professionals (""pros""), and only compete in local competitions. A small elite of professional golfers are ""tournament pros"" who compete full-time on international ""tours"". Many club and teaching professionals working in the golf industry start as caddies or with a general interest in the game, finding employment at golf courses and eventually moving on to certifications in their chosen profession. These programs include independent institutions and universities, and those that eventually lead to a Class A golf professional certification. Touring professionals typically start as amateur players, who attain their ""pro"" status after success in major tournaments that win them either prize money and/or notice from corporate sponsors. Jack Nicklaus, for example, gained widespread notice by finishing second in the 1960 U.S. Open to champion Arnold Palmer, with a 72-hole score of 282 (the best score to date in that tournament by an amateur). He played one more amateur year in 1961, winning that year's U.S. Amateur Championship, before turning pro in 1962.
",3
3603,"Golf instruction involves the teaching and learning of the game of golf. Proficiency in teaching golf instruction requires not only technical and physical ability but also knowledge of the rules and etiquette of the game. In some countries, golf instruction is best performed by teachers certified by the Professional Golfers Association. Some top instructors who work with professional golfers have become quite well known in their own right. Professional golf instructors can use physical conditioning, mental visualization, classroom sessions, club fitting, driving range instruction, on-course play under real conditions, and review of videotaped swings in slow motion to teach golf to prepare the golfer for the course.
",3
3604,"There are at least twenty professional golf tours, each run by a PGA or an independent tour organization, which is responsible for arranging events, finding sponsors, and regulating the tour. Typically a tour has ""members"" who are entitled to compete in most of its events, and also invites non-members to compete in some of them. Gaining membership of an elite tour is highly competitive, and most professional golfers never achieve it.
",3
3605,"Perhaps the most widely known tour is the PGA Tour, which tends to attract the strongest fields, outside the four Majors and the four World Golf Championships events. This is due mostly to the fact that most PGA Tour events have a first prize of at least 800,000 USD. The European Tour, which attracts a substantial number of top golfers from outside North America, ranks second to the PGA Tour in worldwide prestige. Some top professionals from outside North America play enough tournaments to maintain membership on both the PGA Tour and European Tour. Since 2010, both tours' money titles have been claimed by the same individual three times, with Luke Donald doing so in 2011 and Rory McIlroy in 2012 and 2014. In 2013, Henrik Stenson won the FedEx Cup points race on the PGA Tour and the European Tour money title, but did not top the PGA Tour money list (that honour going to Tiger Woods).
",3
3606,"The other leading men's tours include the Japan Golf Tour, the Asian Tour (Asia outside Japan), the PGA Tour of Australasia, and the Sunshine Tour (for southern Africa, primarily South Africa). The Japan, Australasian, Sunshine, PGA, and European Tours are the charter members of the trade body of the world's main tours, the International Federation of PGA Tours, founded in 1996. The Asian Tour became a full member in 1999. The Canadian Tour became an associate member of the Federation in 2000, and the Tour de las Américas (Latin America) became an associate member of the Federation in 2007. The Federation underwent a major expansion in 2009 that saw eleven new tours become full members – the Canadian Tour, Tour de las Américas, China Golf Association, the Korea Professional Golfers' Association, Professional Golf Tour of India, and the operators of all six major women's tours worldwide. The OneAsia Tour, founded in 2009, is not a member of the Federation, but was founded as a joint venture of the Australasia, China, Japan, and Korean tours. In 2011, the Tour de las Américas was effectively taken over by the PGA Tour, and in 2012 was folded into the new PGA Tour Latinoamérica. Also in 2012, the Canadian Tour was renamed PGA Tour Canada after it agreed to be taken over by the PGA Tour. All men's tours that are Federation members, except the India tour, offer points in the Official World Golf Ranking (OWGR) to players who place sufficiently high in their events. The OneAsia Tour also offers ranking points.
",3
3607,"Golf is unique in having lucrative competition for older players. There are several senior tours for men aged fifty and over, arguably the best known of which is the U.S.-based PGA Tour Champions.
",3
3608,"There are six principal tours for women, each based in a different country or continent. The most prestigious of these is the United States-based LPGA Tour. All of the principal tours offer points in the Women's World Golf Rankings for high finishers in their events.
",3
3609,"All of the leading professional tours for under-50 players have an official developmental tour, in which the leading players at the end of the season will earn a tour card on the main tour for the following season. Examples include the Web.com Tour, which feeds to the PGA Tour, and the Challenge Tour, which is the developmental tour of the European Tour. The Web.com and Challenge Tours also offer OWGR points.
",3
3610,"The major championships are the four most prestigious men's tournaments of the year. In chronological order they are: The Masters, the U.S. Open, The Open Championship (referred to in North America as the British Open) and the PGA Championship.[53]
",3
3611,"The fields for these events include the top several dozen golfers from all over the world. The Masters has been played at Augusta National Golf Club in Augusta, Georgia, since its inception in 1934. It is the only major championship that is played at the same course each year.[54] The U.S. Open and PGA Championship are played at courses around the United States, while the Open Championship is played at courses around the United Kingdom.[55]
",3
3612,"Prior to the advent of the PGA Championship and The Masters, the four Majors were the U.S. Open, the U.S. Amateur, the Open Championship, and the British Amateur.
",3
3613,"Women's golf does not have a globally agreed set of majors. The list of majors recognised by the dominant women's tour, the LPGA Tour in the U.S., has changed several times over the years, with the most recent changes occurring in 2001 and 2013. Like the PGA Tour, the (U.S.) LPGA[56] tour long had four majors, but now has five: the ANA Inspiration (previously known by several other names, most recently the Kraft Nabisco Championship), the Women's PGA Championship (previously known as the LPGA Championship),[57] the U.S. Women's Open, the Women's British Open (which replaced the du Maurier Classic as a major in 2001) and The Evian Championship (added as the fifth major in 2013). Only the last two are also recognised as majors by the Ladies European Tour. However, the significance of this is limited, as the LPGA is far more dominant in women's golf than the PGA Tour is in mainstream men's golf. For example, the BBC has been known to use the U.S. definition of ""women's majors"" without qualifying it. Also, the Ladies' Golf Union, the governing body for women's golf in Great Britain and Ireland, stated on its official website that the Women's British Open was ""the only Women's Major to be played outside the U.S.""[58] (this was before the elevation of The Evian Championship to major status). For many years, the Ladies European Tour tacitly acknowledged the dominance of the LPGA Tour by not scheduling any of its own events to conflict with the three LPGA majors played in the U.S., but that changed beginning in 2008, when the LET scheduled an event opposite the LPGA Championship. The second-richest women's tour, the LPGA of Japan Tour, does not recognise any of the U.S. LPGA or European majors as it has its own set of majors (historically three, since 2008 four). However, these events attract little notice outside Japan.
",3
3614,"Senior (aged fifty and over) men's golf does not have a globally agreed set of majors. The list of senior majors on the U.S.-based PGA Tour Champions has changed over the years, but always by expansion. PGA Tour Champions now recognises five majors: the Senior PGA Championship, The Tradition, the Senior Players Championship, the United States Senior Open, and The Senior (British) Open Championship.
",3
3615,"Of the five events, the Senior PGA is by far the oldest, having been founded in 1937. The other events all date from the 1980s, when senior golf became a commercial success as the first golf stars of the television era, such as Arnold Palmer and Gary Player, reached the relevant age. The Senior Open Championship was not recognised as a major by PGA Tour Champions until 2003. The European Senior Tour recognises only the Senior PGA and the two Senior Opens as majors. However, PGA Tour Champions is arguably more dominant in global senior golf than the U.S. LPGA is in global women's golf.
",3
3616,"After a 112-year absence from the Olympic Games, golf returned for the 2016 Rio Games.[59] 41 different countries were represented by 120 athletes.[60]
",3
3617,"It was not until 1552 that the first woman golfer played the game. Mary Queen of Scots commissioned St. Andrew's Links.[61] However, it was not until the 20th century that women were taken seriously and eventually broke the ""Gentlemen Only, Ladies Forbidden"" rule. Many men saw women as unfit to play the sport due to their supposed lack of strength and ability.
",3
3618,"In 1891 the newly built Shinnecock Hills nine-hole course in Southampton, New York became the first club to offer membership to women golfers. Four years later, in 1895, The U.S. Golf Association held the first Women's Amateur Championship tournament.[61][62]
",3
3619,"Just like professional golfer Bobby Jones, Joyce Wethered was considered to be a star in the 1920s.[63] Jones praised Wethered in 1930 after they had played an exhibition against each other. He doubted that there had ever been a better golfer, man or woman.[64] However, Bobby Jones' comment was not enough for others to change their views on women golfers.
",3
3620,"The Royal Liverpool's club refused entry of Sir Henry Cotton's wife into the clubhouse in the late 1940s. The secretary of the club released a statement saying, ""No woman ever has entered the clubhouse and, praise God, no woman ever will.""[63] However, American golfer and all-around athlete Babe Zaharias did not have to enter the clubhouse. She was able to prove herself on the course, going on to become the first American to win the British Women's Amateur title in 1947. The following year she became the first woman to attempt to qualify for the U.S. Open, but her application was rejected by the USGA. They stated that the event was intended to be open to men only.[65]
",3
3621,"The Ladies Professional Golf Association was formed in 1950 as a way to popularize the sport and provide competitive opportunities for golfers.[63] The competitions were not the same for the men and women. It was not until 1972 that U.S. Congress passed the Title IX of the Education Amendments. ""No person in the United States shall, on the basis of sex, be excluded from participation in, be denied the benefits of, or be subject to discrimination under any education program or activities receiving Federal financial assistance.""[66] American Renee Powell moved to the UK in the 1970s to further her career, and became the first woman to play in a British men's tournament in 1977.[67]
",3
3622,"Today, women golfers are still fighting to have the same opportunities as men golfers. There is still a big pay gap in the USGA. The USGA has a long history of writing bigger checks to winners of the men's U.S. Open than the U.S. Women's Open.[68]
",3
3623,"
",3
3624,"Eldrick Tont ""Tiger"" Woods (born December 30, 1975) is an American professional golfer. He is tied for first in PGA Tour wins, ranks second in men's major championships, and holds numerous golf records.[5] Woods is widely regarded as one of the greatest golfers of all time and one of the most famous athletes of all time. He has been elected to the World Golf Hall of Fame.[6]
",3
3625,"Following an outstanding junior, college, and amateur golf career, Woods turned professional in 1996 at the age of 20. By the end of April 1997, he had won three PGA Tour events in addition to his first major, the 1997 Masters, which he won by 12 strokes in a record-breaking performance. He reached number one in the world rankings for the first time in June 1997, less than a year after turning pro. Throughout the first decade of the 21st century, Woods was the dominant force in golf. He was the top-ranked golfer in the world from August 1999 to September 2004 (264 consecutive weeks) and again from June 2005 to October 2010 (281 consecutive weeks). During this time, he won 13 of golf's major championships.
",3
3626,"The next decade of Woods's career was marked by comebacks from personal problems and injuries. He took a self-imposed hiatus from professional golf from December 2009 to early April 2010 in an attempt to resolve marital issues with his wife at the time, Elin. Woods admitted to multiple infidelities, and the couple eventually divorced.[7] Woods fell to number 58 in the world rankings in November 2011 before ascending again to the number-one ranking between March 2013 and May 2014.[8][9] However, injuries led him to undergo four back surgeries between 2014 and 2017.[10] Woods competed in only one tournament between August 2015 and January 2018, and he dropped off the list of the world's top 1,000 golfers.[11][12]  On his return to regular competition, Woods made steady progress to the top of the game, winning his first tournament in five years at the Tour Championship in September 2018 and his first major in 11 years at the 2019 Masters.
",3
3627,"Woods has held numerous golf records. He has been the number one player in the world for the most consecutive weeks and for the greatest total number of weeks of any golfer in history. He has been awarded PGA Player of the Year a record 11 times[13] and has won the Byron Nelson Award for lowest adjusted scoring average a record eight times. Woods has the record of leading the money list in ten different seasons. He has won 15 professional major golf championships (trailing only Jack Nicklaus, who leads with 18) and 82 PGA Tour events (tied for first all time with Sam Snead).[14] Woods leads all active golfers in career major wins and career PGA Tour wins. He is the youngest player to achieve the career Grand Slam only four men before him have won career grand slam (Gene Sarazen, Ben Hogan, Gary Player and Jack Nicklaus), and the second golfer (after Nicklaus) to have achieved a career Grand Slam three times. Woods has won 18 World Golf Championships. He was also part of the American winning team for the 1999 Ryder Cup. In May 2019, Woods was awarded the Presidential Medal of Freedom, the fourth golfer to receive the honor.[15]
",3
3628,"On February 23, 2021, Woods was hospitalized in serious but stable condition after a single-car collision and underwent emergency surgery to repair compound fractures sustained in each leg in addition to a shattered ankle.[16]
",3
3629,"Woods was born in 1975 in Cypress, California,[17] to Earl[18] and Kultida ""Tida"" Woods.[19] He is their only child and has two half-brothers, Earl Jr. and Kevin, and a half-sister, Royce, from his father's first marriage.[20]
",3
3630,"Earl was a retired U.S. Army officer, and Vietnam War veteran; he was born to African American parents, and was also said to have had European, Native American, and possibly Chinese, ancestry.[21][22] Kultida (née Punsawad) is originally from Thailand, where Earl had met her when he was on a tour of duty there in 1968. She is of mixed Thai, Chinese, and Dutch ancestry.[23] Tiger has described his ethnic make-up as ""Cablinasian"" (a syllabic abbreviation he coined from Caucasian, Black, American Indian, and Asian).[24]
",3
3631,"Woods's first name, Eldrick, was chosen by his mother because it began with ""E"" (for Earl) and ended with ""K"" (for Kultida). His middle name Tont is a traditional Thai name. He was nicknamed Tiger in honor of his father's friend Col. Vuong Dang Phong, who had also been known as Tiger.[25]
",3
3632,"Woods has a niece, Cheyenne Woods, who played for the Wake Forest University golf team and turned professional in 2012 when she made her pro debut in the LPGA Championship.[26]
",3
3633,"Woods grew up in Orange County, California. He was a child prodigy who was introduced to golf before the age of two by his athletic father, Earl Woods. Earl was a single-digit handicap amateur golfer who also was one of the earliest African-American college baseball players at Kansas State University.[27] Tiger's father was a member of the military and had playing privileges at the Navy golf course beside the Joint Forces Training Base in Los Alamitos, which allowed Tiger to play there. Tiger also played at the par 3 Heartwell golf course in Long Beach, as well as some of the municipals in Long Beach.[28]
",3
3634,"In 1978, Tiger putted against comedian Bob Hope in a television appearance on The Mike Douglas Show. At age three, he shot a 48 over nine holes at the Navy course. At age five, he appeared in Golf Digest and on ABC's That's Incredible![29] Before turning seven, Tiger won the Under Age 10 section of the Drive, Pitch, and Putt competition, held at the Navy Golf Course in Cypress, California.[30] In 1984 at the age of eight, he won the 9–10 boys' event, the youngest age group available, at the Junior World Golf Championships.[31] He first broke 80 at age eight.[32] He went on to win the Junior World Championships six times, including four consecutive wins from 1988 to 1991.[33][34][35][36][37]
",3
3635,"Woods's father Earl wrote that Tiger first defeated him at the age of 11 years, with Earl trying his best. Earl lost to Tiger every time from then on.[38] Woods first broke 70 on a regulation golf course at age 12.[39]
",3
3636,"When Woods was 13 years old, he played in the 1989 Big I, which was his first major national junior tournament. In the final round, he was paired with pro John Daly, who was then relatively unknown. The event's format placed a professional with each group of juniors who had qualified. Daly birdied three of the last four holes to beat Woods by only one stroke.[40] As a young teenager, Woods first met Jack Nicklaus in Los Angeles at the Bel-Air Country Club, when Nicklaus was performing a clinic for the club's members. Woods was part of the show, and he impressed Nicklaus and the crowd with his skills and potential.[41] Earl Woods had researched in detail the career accomplishments of Nicklaus and had set his young son the goals of breaking those records.[39]
",3
3637,"Woods was 15 years old and a student at Western High School in Anaheim when he became the youngest U.S. Junior Amateur champion; this was a record that stood until it was broken by Jim Liu in 2010.[42] He was named 1991's Southern California Amateur Player of the Year (for the second consecutive year) and Golf Digest Junior Amateur Player of the Year. In 1992, he defended his title at the U.S. Junior Amateur Championship, becoming the tournament's first two-time winner. He also competed in his first PGA Tour event, the Nissan Los Angeles Open (he missed the 36-hole cut), and was named Golf Digest Amateur Player of the Year, Golf World Player of the Year, and Golfweek National Amateur of the Year.[43][44]
",3
3638,"The following year, Woods won his third consecutive U.S. Junior Amateur Championship; he remains the event's only three-time winner.[45] In 1994, at the TPC at Sawgrass in Florida, he became the youngest winner of the U.S. Amateur Championship, a record he held until 2008 when it was broken by Danny Lee.[46] He was a member of the American team at the 1994 Eisenhower Trophy World Amateur Golf Team Championships (winning), and the 1995 Walker Cup (losing).[47][48]
",3
3639,"Woods graduated from Western High School at age 18 in 1994 and was voted ""Most Likely to Succeed"" among the graduating class. He had starred for the high school's golf team under coach Don Crosby.[49]
",3
3640,"Woods learned to manage his stuttering as a boy.[50] This was not known until he wrote a letter to a boy who contemplated suicide. Woods wrote, ""I know what it's like to be different and to sometimes not fit in. I also stuttered as a child and I would talk to my dog and he would sit there and listen until he fell asleep. I also took a class for two years to help me, and I finally learned to stop.""[51]
",3
3641,"Woods was heavily recruited by college golf powers. He chose Stanford University, the 1994 NCAA champions. He enrolled at Stanford in the fall of 1994 under a golf scholarship and won his first collegiate event, the 40th Annual William H. Tucker Invitational, that September.[52] He selected a major in economics and was nicknamed ""Urkel"" by college teammate Notah Begay III.[53] In 1995, he successfully defended his U.S. Amateur title at the Newport Country Club in Rhode Island[46] and was voted Pac-10 Player of the Year, NCAA First Team All-American, and Stanford's Male Freshman of the Year (an award that encompasses all sports).[54][55]
",3
3642,"At age 19, Woods participated in his first PGA Tour major, the 1995 Masters, and tied for 41st as the only amateur to make the cut; two years later, he won the tournament by 12 strokes. At age 20 in 1996, he became the first golfer to win three consecutive U.S. Amateur titles[56] and won the NCAA individual golf championship.[57] In winning the silver medal as leading amateur at The Open Championship, he tied the record for an amateur aggregate score of 281.[58] He left college after two years in order to turn professional in the golf industry. In 1996, Woods moved out of California, stating in 2013 that it was due to the state's high tax rate.[59]
",3
3643,"Woods turned pro at age 20 in August 1996 and immediately signed advertising deals with Nike, Inc. and Titleist that ranked as the most lucrative endorsement contracts in golf history at that time.[60][61] Woods was named Sports Illustrated's 1996 Sportsman of the Year and PGA Tour Rookie of the Year.[62] On April 13, 1997, he won his first major, the Masters, in record-breaking fashion and became the tournament's youngest winner at age 21.[63] Two months later, he set the record for the fastest ascent to No. 1 in the Official World Golf Rankings.[64] After a lackluster 1998, Woods finished the 1999 season with eight wins, including the PGA Championship, a feat not achieved since Johnny Miller did it in 1974.[65][66]
",3
3644,"Woods was severely myopic; his eyesight had a rating of 11 diopters. In order to correct this problem, he underwent successful laser eye surgery in 1999,[67] and he immediately resumed winning tour events. In 2007, his vision again began to deteriorate, and he underwent laser eye surgery a second time.[68]
",3
3645,"In 2000, Woods won six consecutive events on the PGA Tour, which was the longest winning streak since Ben Hogan did it in 1948. One of these was the U.S. Open, where he broke or tied nine tournament records in what Sports Illustrated called ""the greatest performance in golf history"", in which Woods won the tournament by a record 15-stroke margin and earned a check for $800,000.[69] At age 24, he became the youngest golfer to achieve the Career Grand Slam.[70] At the end of 2000, Woods had won nine of the twenty PGA Tour events he entered and had broken the record for lowest scoring average in tour history. He was named the Sports Illustrated Sportsman of the Year, the only athlete to be honored twice, and was ranked by Golf Digest magazine as the twelfth-best golfer of all time.[71]
",3
3646,"When Woods won the 2001 Masters, he became the only player to win four consecutive major professional golf titles, although not in the same calendar year. This achievement came to be known as the ""Tiger Slam.""[72] Following a stellar 2001 and 2002 in which he continued to dominate the tour, Woods's career hit a slump.[65][73] He did not win a major in 2003 or 2004. In September 2004, Vijay Singh overtook Woods in the Official World Golf Rankings, ending Woods's record streak of 264 weeks at No. 1.[74]
",3
3647,"Woods rebounded in 2005, winning six PGA Tour events and reclaiming the top spot in July after swapping it back and forth with Singh over the first half of the year.[75]
",3
3648,"Woods began dominantly in 2006, winning his first two PGA tournaments but failing to capture his fifth Masters championship in April.[76] Following the death of his father in May, Woods took some time off from the tour and appeared rusty upon his return at the U.S. Open at Winged Foot, where he missed the cut.[77] However, he quickly returned to form and ended the year by winning six consecutive tour events. At the season's close, Woods had 54 total wins that included 12 majors; he had broken the tour records for both total wins and total majors wins over eleven seasons.[78]
",3
3649,"Woods continued to excel in 2007 and the first part of 2008. In April 2008, he underwent knee surgery and missed the next two months on the tour.[79] Woods returned for the 2008 U.S. Open, where he struggled the first day but ultimately claimed a dramatic sudden death victory over Rocco Mediate that followed an 18-hole playoff, after which Mediate said, ""This guy does things that are just not normal by any stretch of the imagination,"" and Kenny Perry added, ""He beat everybody on one leg.""[80] Two days later, Woods announced that he would miss the remainder of the season due to additional knee surgery, and that his knee was more severely damaged than previously revealed, prompting even greater praise for his U.S. Open performance. Woods called it ""my greatest ever championship.""[81] In Woods's absence, television ratings for the remainder of the season suffered a huge decline from 2007.[82]
",3
3650,"Woods had a much anticipated return to golf in 2009, when he performed well. His comeback included a spectacular performance at the 2009 Presidents Cup, but he failed to win a major, the first year since 2004 that he had not done so.[83] After his marital infidelities came to light and received massive media coverage at the end of 2009 (see further details below), Woods announced in December that he would be taking an indefinite break from competitive golf.[7] In February 2010, he delivered a televised apology for his behavior, saying ""I was wrong and I was foolish.""[84] During this period, several companies ended their endorsement deals with Woods.[85]
",3
3651,"Woods returned to competition in April at the 2010 Masters, where he finished tied for fourth place.[86] He followed the Masters with poor showings at the Quail Hollow Championship and the Players Championship, where he withdrew in the fourth round, citing injury.[87] Shortly afterward, Hank Haney, Woods's coach since 2003, resigned the position. In August, Woods hired Sean Foley as Haney's replacement. The rest of the season went badly for Woods, who failed to win a single event for the first time since turning professional, while nevertheless finishing the season ranked No. 2 in the world.
",3
3652,"In 2011, Woods's performance continued to suffer; this took its toll on his ranking. After falling to No. 7 in March, he rebounded to No. 5 with a strong showing at the 2011 Masters, where he tied for fourth place.[88] Due to leg injuries incurred at the Masters, he missed several summer stops on the PGA Tour. In July, he fired his longtime caddy Steve Williams (who was shocked by the dismissal), and replaced him on an interim basis with friend Bryon Bell until he hired Joe LaCava.[89] After returning to tournament play in August, Woods continued to falter, and his ranking gradually fell to a low of #58.[9] He rose to No. 50 in mid-November after a third-place finish at the Emirates Australian Open, and broke his winless streak with a victory at December's Chevron World Challenge.[9][90][full citation needed]
",3
3653,"Woods began his 2012 season with two tournaments (the Abu Dhabi HSBC Golf Championship and the AT&T Pebble Beach National Pro-Am) where he started off well but struggled on the final rounds. Following the WGC-Accenture Match Play Championship, where he was knocked out in the second round by missing a 5-foot putt,[91] Woods revised his putting technique and tied for second at the Honda Classic, with the lowest final round score in his PGA Tour career. After a short time off due to another leg injury, Woods won the Arnold Palmer Invitational, his first win on the PGA Tour since the BMW Championship in September 2009. Following several dismal performances, Woods notched his 73rd PGA Tour win at the Memorial Tournament in June, tying Jack Nicklaus in second place for most PGA Tour victories;[92] a month later, Woods surpassed Nicklaus with a win at the AT&T National, to trail only Sam Snead, who accumulated 82 PGA tour wins.[93]
",3
3654,"The year 2013 brought a return of Woods's dominating play. In January, he won the Farmers Insurance Open by four shots for his 75th PGA Tour win. It was the seventh time he had won the event.[94] In March, he won the WGC-Cadillac Championship, also for the seventh time, giving him his 17th WGC title and first since 2009.[95] Two weeks later, he won the Arnold Palmer Invitational, winning the event for a record-tying 8th time. The win moved him back to the top of the world rankings.[96] To commemorate that achievement, Nike was quick to launch an ad with the tagline ""winning takes care of everything"".[97]
",3
3655,"During the 2013 Masters, Woods faced disqualification after unwittingly admitting in a post-round interview with ESPN that he had taken an illegal drop on the par-5 15th hole when his third shot had bounced off the pin and into the water. After further review of television footage, Woods was assessed a two-stroke penalty for the drop but was not disqualified.[98] He finished tied for fourth in the event. Woods won The Players Championship in May 2013, his second career win at the event, notching his fourth win of the 2013 season. It was the quickest he had gotten to four wins in any season in his professional career.
",3
3656,"Woods had a poor showing at the 2013 U.S. Open as a result of an elbow injury that he sustained at The Players Championship. In finishing at 13-over-par, he recorded his worst score as a professional and finished 12 strokes behind winner Justin Rose. After a prolonged break because of the injury, during which he missed the Greenbrier Classic and his own AT&T National, he returned at the Open Championship at Muirfield. Despite being in contention all week and beginning the final round only two strokes behind Lee Westwood, he struggled with the speed of the greens and could only manage a 3-over-par 74 that left him tied for 6th place, five strokes behind eventual winner Phil Mickelson. Two weeks later, Woods returned to form at the WGC-Bridgestone Invitational, recording his 5th win of the season and 8th win at the event in its 15-year history. His second round 61 matched his record score on the PGA Tour and could easily have been a 59 were it not for some short missed birdie putts on the closing holes. This gave him a seven-stroke lead that he held onto for the rest of the tournament. But at the PGA Championship at Oak Hill Country Club, Woods never was in contention, making 2013 his fifth full season where he did not win a major; he was in contention in only two of the four majors in 2013.
",3
3657,"After a slow start to 2014, Woods sustained an injury during the final round of the Honda Classic and was unable to finish the tournament. He withdrew after the 13th hole, citing back pain.[99] He subsequently competed in the WGC-Cadillac Championship but was visibly in pain during much of the last round. He was forced to skip the Arnold Palmer Invitational at the end of March 2014,[100] and after undergoing back surgery, he announced on April 1 that he would miss the Masters for the first time since 1994.[101] Woods returned at the Quicken Loans National in June, however he said that his expectations for the week were low. He struggled with nearly every aspect of his game and missed the cut. He next played at The Open Championship, contested at Hoylake, where Woods had won eight years prior. Woods fired a brilliant 69 in the first round to put himself in contention, but shot 77 on Friday and eventually finished 69th. Despite his back pain, he played at the 2014 PGA Championship where he failed to make the cut. On August 25, 2014, Woods and his swing coach Sean Foley parted ways. In the four years under Foley, he won eight times but no majors. He had previously won eight majors with Harmon and six with Haney. Woods said there was currently no timetable to find a replacement swing coach.[102]
",3
3658,"On February 5, 2015, Woods withdrew from the Farmers Insurance Open after another back injury.[103] Woods stated on his website that it was unrelated to his previous surgery and he would take a break from golf until his back healed.[104] He returned for the Masters, finishing in a tie for 17th. In the final round, Woods injured his wrist after his club hit a tree root. He later stated that a bone popped out of his wrist, but he adjusted it back into place and finished the round.[105] Woods then missed the cut at the 2015 U.S. Open and Open Championship, the first time Woods missed the cut at consecutive majors, finishing near the bottom of the leaderboard both times.[106] He finished tied for 18th at the Quicken Loans National on August 2.[107] In late August 2015, Woods played quite well at the Wyndham Championship finishing the tournament at 13-under, only four strokes behind the winner, and tied for 10th place.[108] Woods offered only a brief comment on the speculation that he was still recovering from back surgery, saying it was ""just my hip"" but offering no specifics.[109]
",3
3659,"Woods had back surgery on September 16, 2015. In late March 2016, he announced that he would miss the Masters while he recovered from the surgery;[110] he had also missed the 2014 Masters due to a back problem.[111] ""I'm absolutely making progress, and I'm really happy with how far I've come,"" he explained in a statement. ""But I still have no timetable to return to competitive golf.""[112] However, he did attend the Masters Champions Dinner on April 5, 2016.[113] For the first time in his career, he missed all four majors in one year due to problems with his back. In October 2016, he told Charlie Rose on PBS that he still wanted to break Jack Nicklaus's record of 18 major titles.[114] Woods underwent back surgery in December 2016 and spent the next 15 months off the Tour. He made his return to competitive golf in the Hero World Challenge.[115]
",3
3660,"Woods's back problems continued to hinder him in 2017. He missed the cut at the Farmers Insurance Open in January and pulled out of a European Tour event in Dubai on February 3. On March 31, Woods announced on his website that he would not be playing in the 2017 Masters Tournament despite being cleared to play by his doctors. Woods said that although he was happy with his rehabilitation, he did not feel ""tournament ready.""[116][117] Woods subsequently told friends, ""I'm done"".[118] On April 20, Woods announced that he had undergone his fourth back surgery since 2014 to alleviate back and leg pain. Recovery time required up to six months, meaning that Woods would spend the rest of the year without playing any professional golf.[119] Woods returned to competitive golf at the Hero World Challenge in the Bahamas. He shot rounds of 69-68-75-68 and finished tied for 9th place. His world ranking went from 1,199th to 668th, which was the biggest jump in the world rankings in his career.
",3
3661,"On March 11, 2018, he finished one-shot back and tied for second at the Valspar Championship in Florida, his first top-five finish on the PGA Tour since 2013.[120] He then tied for sixth with a score of five under par at the 2018 Open Championship.[121] At the last major of the year, the 2018 PGA Championship, Woods finished second, two shots behind the winner Brooks Koepka. It was his best result in a major since 2009 (second at the 2009 PGA Championship) and moved him up to 26th in the world rankings. His final round of 64 was his best ever final round in a major.[122][12]
",3
3662,"Woods returned to the winner's circle for the 80th time in his PGA Tour career on September 23, 2018, when he won the season-ending Tour Championship at East Lake Golf Club for the second time and that tournament for the third time. He shot rounds of 65-68-65-71 to win by two strokes over Billy Horschel.[123]
",3
3663,"On April 14, 2019, Woods won the Masters, which was his first major championship win in eleven years and his 15th major overall. He finished 13 under par to win by one stroke over Dustin Johnson, Xander Schauffele and Brooks Koepka.[124] At age 43, he became the second oldest golfer ever to win the Masters, after Jack Nicklaus who was 46 when he triumphed in 1986.[125] In August 2019, Woods announced via social media that he underwent a knee surgery to repair minor cartilage damage and that he had an arthroscopic procedure during the Tour Championship. In his statement, Woods also confirmed that he was walking and intends on traveling and playing in Japan in October.[126]
",3
3664,"Woods played in his first 2020 PGA Tour event at the Zozo Championship in October 2019, which was the first-ever PGA Tour event played in Japan. Woods, who played a highly publicized skins game earlier in the week at the same course as the Championship, held at least a share of the lead after every round of the rain-delayed tournament, giving him a three stroke victory over Hideki Matsuyama.[127] The win was Woods's 82nd on Tour, tying him with Sam Snead for the most victories all time on the PGA Tour.[128][129]
",3
3665,"On December 23, 2020, Woods had microdiscectomy surgery on his back for the fifth time.[130] The operation was to remove a pressurized disc fragment that was pinching his nerve and causing him pain during the PNC Championship.
",3
3666,"On August 20, 2007, California Governor Arnold Schwarzenegger and his wife Maria Shriver announced that Woods would be inducted into the California Hall of Fame. He was inducted December 5, 2007 at The California Museum for History, Women and the Arts in Sacramento.[131]
",3
3667,"In December 2009, Woods was named ""Athlete of the Decade"" by the Associated Press.[132] He was named Associated Press Male Athlete of the Year[133] a record-tying four times, and is one of only two people to be named Sports Illustrated's Sportsman of the Year more than once.
",3
3668,"Since his record-breaking win at the 1997 Masters, Woods has been the biggest name in golf and his presence in tournaments has drawn a huge fan following. Some sources have credited him for dramatically increasing prize money in golf, generating interest in new PGA tournament audiences, and for drawing the largest TV ratings in golf history.[62][134]
",3
3669,"In May 2019, following his 2019 Masters Tournament win, Woods was awarded the Presidential Medal of Freedom by President Donald Trump.[135]
",3
3670,"During the first decade of his professional career, Woods was the world's most marketable athlete.[136] Shortly after his 21st birthday in 1996, he signed endorsement deals with numerous companies, including General Motors, Titleist, General Mills, American Express, Accenture, and Nike In 2000, he signed a 5-year, $105 million contract extension with Nike, which was the largest endorsement package signed by a professional athlete at that time.[137] Woods's endorsement has been credited with playing a significant role in taking the Nike Golf brand from a ""start-up"" golf company earlier in the previous decade to becoming the leading golf apparel company in the world and a major player in the equipment and golf ball market.[136][138] Nike Golf is one of the fastest growing brands in the sport, with an estimated $600 million in sales.[139] Woods has been described as the ""ultimate endorser"" for Nike Golf,[139] frequently seen wearing Nike gear during tournaments, and even in advertisements for other products.[137] Woods receives a percentage from the sales of Nike Golf apparel, footwear, golf equipment, golf balls,[136] and has a building named after him at Nike's headquarters campus in Beaverton, Oregon.[140]
",3
3671,"In 2002, Woods was involved in every aspect of the launch of Buick's Rendezvous SUV. A company spokesman stated that Buick was happy with the value of Woods's endorsement, pointing out that more than 130,000 Rendezvous vehicles were sold in 2002 and 2003. ""That exceeded our forecasts,"" he was quoted as saying, ""It has to be in recognition of Tiger."" In February 2004, Buick renewed Woods's endorsement contract for another five years, in a deal reportedly worth $40 million.[137]
",3
3672,"Woods collaborated closely with TAG Heuer to develop the world's first professional golf watch, which was released in April 2005.[141] The lightweight, titanium-construction watch, designed to be worn while playing the game, incorporates numerous innovative design features to accommodate golf play. It is capable of absorbing up to 5,000 Gs of shock, far in excess of the forces generated by a normal golf swing.[141] In 2006, the TAG Heuer Professional Golf Watch won the prestigious iF product design award in the Leisure/Lifestyle category.[142]
",3
3673,"Woods also endorsed the Tiger Woods PGA Tour series of video games; he has done so since 1999.[143] In 2006, he signed a six-year contract with Electronic Arts, the series' publisher.[144]
",3
3674,"In February 2007, Woods, Roger Federer and Thierry Henry became ambassadors for the ""Gillette Champions"" marketing campaign. Gillette did not disclose financial terms, though an expert estimated the deal could total between $10 million and $20 million.[145]
",3
3675,"In October 2007, Gatorade announced that Woods would have his own brand of sports drink starting in March 2008. ""Gatorade Tiger"" was his first U.S. deal with a beverage company and his first licensing agreement. Although no figures were officially disclosed, Golfweek magazine reported that it was for five years and could pay him as much as $100 million.[146] The company decided in early fall 2009 to discontinue the drink due to weak sales.[147]
",3
3676,"In October 2012, it was announced that Woods had signed an exclusive endorsement deal with Fuse Science, Inc, a sports nutrition firm.[148]
",3
3677,"In 1997, Woods and fellow golfer Arnold Palmer initiated a civil case against Bruce Matthews (the owner of Gotta Have It Golf, Inc.) and others in the effort to stop the unauthorized sale of their images and alleged signatures in the memorabilia market. Matthews and associated parties counterclaimed that Woods and his company, ETW Corporation, committed several acts including breach of contract, breach of implied duty of good faith, and violations of Florida's Deceptive and Unfair Trade Practices Act.[149] Palmer also was named in the counter-suit, accused of violating the same licensing agreement in conjunction with his company Arnold Palmer Enterprises.
",3
3678,"On March 12, 2014, a Florida jury ruled in favor of Gotta Have It on its breach of contract and other related claims, rejected ETW's counterclaims, and awarded Gotta Have It $668,346 in damages.[150] The award may end up exceeding $1 million once interest has been factored in, though the ruling may be appealed.
",3
3679,"In August 2016, Woods announced that he would be seeking a new golf equipment partner[151] after the news of Nike's exit from the equipment industry.[152] It was announced on January 25, 2017, that he would be signing a new club deal with TaylorMade.[153] He added the 2016 M2 driver along with the 2017 M1 fairway woods, with irons to be custom made at a later date. He also added his Scotty Cameron Newport 2 GSS, a club he used to win 13 of his 15 majors.[154] Also, in late 2016, he would add Monster Energy as his primary bag sponsor, replacing MusclePharm.[155]
",3
3680,"Woods has appeared on Forbes' list of the world's highest-paid athletes.[156][157] According to Golf Digest, Woods made $769,440,709 from 1996 to 2007,[158] and the magazine predicted that Woods would pass a billion dollars in earnings by 2010.[159] In 2009, Forbes confirmed that Woods was indeed the world's first professional athlete to earn over a billion dollars in his career, after accounting for the $10 million bonus Woods received for the FedEx Cup title.[160] The same year, Forbes estimated his net worth to be $600 million, making him the second richest person of color in the United States, behind only Oprah Winfrey.[161] In 2015, Woods ranked ninth in Forbes' list of world's highest-paid athletes, being the top among Asian Americans or the fourth among African Americans.[162] As of 2017, Woods was considered to be the highest-paid golfer in the world.[163]
",3
3681,"Early in Woods's career, a small number of golf industry analysts expressed concern about his impact on the competitiveness of the game and the public appeal of professional golf. Sportswriter Bill Lyon of Knight Ridder asked in a column, ""Isn't Tiger Woods actually bad for golf?"" (though Lyon ultimately concluded that he was not).[164] At first, some pundits feared that Woods would drive the spirit of competition out of the game of golf by making existing courses obsolete and relegating opponents to simply competing for second place each week.
",3
3682,"A related effect was measured by University of California economist Jennifer Brown, who found that other golfers scored worse when competing against Woods than when he was not in the tournament. The scores of highly skilled golfers are nearly one stroke higher when playing against Woods. This effect was larger when he was on winning streaks and disappeared during his well-publicized slump in 2003–04. Brown explains the results by noting that competitors of similar skill can hope to win by increasing their level of effort, but that, when facing a ""superstar"" competitor, extra exertion does not significantly raise one's level of winning while increasing risk of injury or exhaustion, leading to reduced effort.[165]
",3
3683,"Many courses in the PGA Tour rotation (including major championship sites like Augusta National) have added yardage to their tees in an effort to reduce the advantage of long hitters like Woods, in a strategy that became known as ""Tiger-proofing"".[166] Woods said he welcomed the change, in that adding yardage to courses did not affect his ability to win.[167]
",3
3684,"Woods has won 82 official PGA Tour events, including 15 majors. He is 14–1 when going into the final round of a major with at least a share of the lead. Multiple golf experts have heralded Woods as ""the greatest closer in history"".[168] He owns the lowest career scoring average and the most career earnings of any player in PGA Tour history.
",3
3685,"Woods's victory at the 2013 Players Championship also marked a win in his 300th PGA Tour start.[169] He also won golf tournaments in his 100th (in 2000) and 200th (in 2006) tour starts.[170]
",3
3686,"Woods has spent the most consecutive and cumulative weeks atop the world rankings. He is one of five players (along with Gene Sarazen, Ben Hogan, Gary Player, and Jack Nicklaus) to have won all four major championships in his career, known as the Career Grand Slam, and was the youngest to do so.[171] Woods is the only player to have consecutively won all four major championships open to professionals, accomplishing the feat in the 2000–2001 seasons.
",3
3687,"1Defeated May in three-hole playoff by 1 stroke: Woods (3-4-5=12), May (4-4-5=13) 
2Defeated DiMarco in a sudden-death playoff: Woods (3), DiMarco (4).
3Defeated Mediate with a par on 1st sudden death hole after 18-hole playoff was tied at even par. This was the final time an 18-hole playoff was used in competition.
",3
3688,"Results not in chronological order in 2020.
",3
3689,"LA = Low amateur
CUT = missed the half-way cut
WD = withdrew
""T"" indicates a tie for a place
NT = No tournament due to COVID-19 pandemic
",3
3690,"WD = withdrew
""T"" indicates a tie for a place.
",3
3691,"Results not in chronological order before 2015.
",3
3692,"1Cancelled due to 9/11
",3
3693,"QF, R16, R32, R64 = Round in which player lost in match play
WD = withdrew 
NT = No tournament
""T"" = tied
Note that the HSBC Champions did not become a WGC event until 2009.
",3
3694,"*As of the 2020 season
",3
3695,"When Woods first joined the PGA Tour in 1996, his long drives had a large impact on the world of golf,[173] but he did not upgrade his equipment in the following years. He insisted upon the use of True Temper Dynamic Gold steel-shafted clubs and smaller steel clubheads that promoted accuracy over distance.[174] Many opponents caught up to him, and Phil Mickelson even made a joke in 2003 about Woods using ""inferior equipment"", which did not sit well with Nike, Titleist or Woods.[175] During 2004, Woods finally upgraded his driver technology to a larger clubhead and graphite shaft, which, coupled with his clubhead speed, again made him one of the tour's longest players off the tee.
",3
3696,"Despite his power advantage, Woods has always focused on developing an excellent all-around game. Although in recent years[when?] he has typically been near the bottom of the Tour rankings in driving accuracy, his iron play is generally accurate, his recovery and bunker play is very strong, and his putting (especially under pressure) is possibly his greatest asset. He is largely responsible for a shift to higher standards of athleticism amongst professional golfers, and is known for utilizing more hours of practice than most.[176][177][178]
",3
3697,"From mid-1993 (while he was still an amateur) until 2004, Woods worked almost exclusively with leading swing coach Butch Harmon. From mid-1997, Harmon and Woods fashioned a major redevelopment of Woods's full swing, achieving greater consistency, better distance control, and better kinesiology. The changes began to pay off in 1999.[179] Woods and Harmon eventually parted ways. From March 2004 to 2010, Woods was coached by Hank Haney, who worked on flattening his swing plane. Woods continued to win tournaments with Haney, but his driving accuracy dropped significantly. Haney resigned under questionable circumstances in May 2010[180] and was replaced by Sean Foley.[181]
",3
3698,"Fluff Cowan served as Woods's caddie from the start of his professional career until Woods dismissed him in March 1999.[182] He was replaced by Steve Williams, who became a close friend of Woods and is often credited with helping him with key shots and putts.[183] In June 2011, Woods dismissed Williams after he caddied for Adam Scott in the U.S. Open[184] and replaced him with friend Bryon Bell on an interim basis. Joe LaCava, a former caddie of both Fred Couples and Dustin Johnson, was hired by Woods shortly after[185] and has remained Woods's caddie since then.
",3
3699,"The TGR Foundation was established in 1996 by Woods and his father Earl as the Tiger Woods Foundation, with the primary goal of promoting golf among inner-city children.[186] The foundation has conducted junior golf clinics across the country, and sponsors the Tiger Woods Foundation National Junior Golf Team in the Junior World Golf Championships.[187][188] As of December 2010, TWF employed approximately 55 people.[189][190]
",3
3700,"The foundation operates the Tiger Woods Learning Center, a $50-million, 35,000-square-foot (3,300 m2) facility in Anaheim, California, providing college-access programs for underserved youth.[187][189][191] The TWLC opened in 2006 and features seven classrooms, extensive multi-media facilities and an outdoor golf teaching area.[187] The center has since expanded to four additional campuses: two in Washington, D.C.; one in Philadelphia; and one in Stuart, Florida.[191]
",3
3701,"The foundation benefits from the annual Chevron World Challenge and AT&T National golf tournaments hosted by Woods.[189] In October 2011, the foundation hosted the first Tiger Woods Invitational at Pebble Beach.[192] Other annual fundraisers have included the concert events Block Party, last held in 2009 in Anaheim, and Tiger Jam, last held in 2011 in Las Vegas after a one-year hiatus.[189][193]
",3
3702,"In November 2006, Woods announced his intention to begin designing golf courses around the world through a new company, Tiger Woods Design.[194] A month later, he announced that the company's first course would be in Dubai as part of a 25.3-million-square-foot development, The Tiger Woods Dubai.[195] The Al Ruwaya Golf Course was initially expected to finish construction in 2009.[195] As of February 2010, only seven holes had been completed; in April 2011, The New York Times reported that the project had been shelved permanently.[196][197] In 2013, the partnership between Tiger Woods Design and Dubai Holding was dissolved.[198]
",3
3703,"Tiger Woods Design has taken on two other courses, neither of which has materialized. In August 2007, Woods announced The Cliffs at High Carolina, a private course in the Blue Ridge Mountains near Asheville, North Carolina.[199] After a groundbreaking in November 2008, the project suffered cash flow problems and suspended construction.[197] A third course, in Punta Brava, Mexico, was announced in October 2008, but incurred delays due to issues with permits and an environmental impact study.[197][200] Construction on the Punta Brava course has not yet begun.[197]
",3
3704,"These projects have encountered problems that have been attributed to factors that include overly optimistic estimates of their value, declines throughout the global economy (particularly the U.S. crash in home prices), and the decreased appeal and marketability of Woods following his 2009 infidelity scandal.[197]
",3
3705,"Woods wrote a golf instruction column for Golf Digest magazine from 1997 to February 2011.[201] In 2001 he wrote a best-selling golf instruction book, How I Play Golf, which had the largest print run of any golf book for its first edition, 1.5 million copies.[202] In March 2017, he published a memoir, The 1997 Masters: My Story, co-authored by Lorne Rubenstein, which focuses on his first Masters win.[203] In October 2019, Woods announced he would be writing a memoir book titled Back.[204]
",3
3706,"In November 2003, Woods became engaged to Elin Nordegren, a Swedish former model and daughter of former minister of migration Barbro Holmberg and radio journalist Thomas Nordegren.[205] They were introduced during The Open Championship in 2001 by Swedish golfer Jesper Parnevik, who had employed her as an au pair. They married on October 5, 2004, at the Sandy Lane resort in Barbados, and lived at Isleworth, a community in Windermere, a suburb of Orlando, Florida.[206][207] In 2006, they purchased a $39-million estate in Jupiter Island, Florida, and began constructing a 10,000-square-foot home; Woods moved there in 2010 following the couple's divorce.[156][207]
",3
3707,"Woods and Nordegren's first child was a daughter born in 2007, whom they named Sam Alexis Woods. Woods chose the name because his own father had always called him Sam.[208] Their son, Charlie Axel Woods, was born in 2009.[209]
",3
3708,"On March 18, 2013, Woods announced that he and Olympic gold medal skier Lindsey Vonn were dating.[210] They split up in May 2015.[211] From November 2016 to August 2017, Woods was rumored in a relationship with stylist Kristin Smith.[212] Woods announced in November 2017 that he was in a relationship with restaurant manager Erica Herman, following speculation about their relationship that began the month prior.[citation needed]
",3
3709,"
",3
3710,"In November 2009, the National Enquirer published a story claiming that Woods had had an extramarital affair with New York City nightclub manager Rachel Uchitel, who denied the claim.[213] Two days later, around 2:30 a.m. on November 27, Woods was driving from his Florida mansion in his Cadillac Escalade SUV when he collided with a fire hydrant, a tree, and several hedges near his home.[214] He was treated for minor facial lacerations and received a ticket for careless driving.[214][215] Following intense media speculation about the cause of the accident, Woods released a statement on his website and took sole responsibility for the accident, calling it a ""private matter"" and crediting his wife for helping him from the car.[216] On November 30, Woods announced that he would not be appearing at his own charity golf tournament (the Chevron World Challenge) or any other tournaments in 2009 due to his injuries.[217]
",3
3711,"On December 2, following Us Weekly magazine's previous day reporting of a purported mistress and subsequent release of a voicemail message allegedly left by Woods for the woman,[218] Woods released a further statement. He admitted transgressions and apologized to ""all of those who have supported [him] over the years"", while reiterating his and his family's right to privacy.[213][219] Over the next few days, more than a dozen women claimed in various media outlets to have had affairs with Woods.[7] On December 11, he released a third statement admitting to infidelity and he apologized again. He also announced that he would be taking ""an indefinite break from professional golf.""[7]
",3
3712,"In the days and months following Woods's admission of multiple infidelities, several companies re-evaluated their relationships with him. Accenture, AT&T, Gatorade and General Motors completely ended their sponsorship deals, while Gillette suspended advertising featuring Woods.[85][220] TAG Heuer dropped Woods from advertising in December 2009 and officially ended their deal when his contract expired in August 2011.[85] Golf Digest magazine suspended Woods's monthly column beginning with the February 2010 issue.[221] In contrast, Nike continued to support Woods, as did Electronic Arts, which was working with Woods on the game Tiger Woods PGA Tour Online.[222] A December 2009 study estimated the shareholder loss caused by Woods's affairs to be between $5 billion and $12 billion.[223]
",3
3713,"On February 19, 2010, Woods gave a televised statement in which he said he had undertaken a 45-day therapy program that began at the end of December. He again apologized for his actions. ""I thought I could get away with whatever I wanted to,"" he said. ""I felt that I had worked hard my entire life and deserved to enjoy all the temptations around me. I felt I was entitled. Thanks to money and fame, I didn't have to go far to find them. I was wrong. I was foolish."" He said he did not know yet when he would be returning to golf.[84][224] On March 16, he announced that he would play in the 2010 Masters.[225]
",3
3714,"After six years of marriage, Woods and Elin divorced on August 23, 2010.[226]
",3
3715,"On May 29, 2017, Woods was arrested near his Jupiter Island, Florida, home by the Jupiter Police Department at about 3:00 am. EDT for driving under the influence of alcohol or drugs. He was asleep in his car, which was stationary in a traffic lane with its engine running. He later stated that he had taken prescription drugs and did not realize how they might interact together.[227] On July 3, 2017, Woods tweeted that he had completed an out-of-state intensive program to tackle an unspecified issue.[228] At his August 9, 2017 arraignment, Woods had his attorney Douglas Duncan submit a not guilty plea for him and agreed to take part in a first-time DUI offender program and attend another arraignment on October 25.[229][230]
",3
3716,"At a hearing on October 27, 2017, Woods pleaded guilty to reckless driving. He received a year of probation, was fined $250, and ordered to undergo 50 hours of community service along with regular drug tests. He was not allowed to drink alcohol during the probation, and if he violated the probation he would be sentenced to 90 days in jail with an additional $500 fine.[231]
",3
3717,"Woods was raised as a Buddhist, and he actively practiced his faith from childhood until well into his adult, professional golf career.[232] In a 2000 article, Woods was quoted as saying that he ""believes in Buddhism... not every aspect, but most of it.""[233] He has attributed his deviations and infidelity to his losing track of Buddhism. He said, ""Buddhism teaches me to stop following every impulse and to learn restraint. Obviously I lost track of what I was taught.""[234]
",3
3718,"Woods is registered as an independent voter.[235] In January 2009, Woods delivered a speech commemorating the military at the We Are One: The Obama Inaugural Celebration at the Lincoln Memorial.[236] In April 2009, Woods visited the White House while promoting the golf tournament he hosts, the AT&T National.[237] In December 2016 and again in November 2017, Woods played golf with President Donald Trump at the Trump International Golf Club in West Palm Beach.[238]
",3
3719,"On February 23, 2021, Woods was involved in a serious rollover car accident in Rancho Palos Verdes, California.[239] The wreck was a single-vehicle collision and Woods was the sole occupant of the vehicle, which was traveling north along Hawthorne Boulevard.[240][241][242] The front of the Genesis GV80 SUV was destroyed but the interior remained intact; the safety features possibly saved his life, leaving him with less traumatic injuries, according to the Los Angeles Sheriff.[243]
",3
3720,"He was taken to the Harbor–UCLA Medical Center by ambulance.[244][239] The incident is under investigation by the Los Angeles County Sheriff's Department, which said the car ""sustained major damage."" No charges are anticipated.[239][245][246] Woods's agent later said that he sustained multiple leg injuries and had undergone surgery for non-life-threatening injuries.[239][241][245] It was reported that he had sustained broken bones in both of his legs and ""compound fractures"".[247] The sheriff involved in the incident said that Woods had ""no recollection"" of the crash during questioning at the hospital.[248]
",3
3721,"Player in italics denotes current number one
",3
3722,"
",3
3723,"
",3
3724,"Boxing is a combat sport in which two people, usually wearing protective gloves and other protective equipment such as hand wraps and mouthguards, throw punches at each other for a predetermined amount of time in a boxing ring.
",3
3725,"Amateur boxing is both an Olympic and Commonwealth Games sport and is a standard fixture in most international games—it also has its own World Championships. Boxing is overseen by a referee over a series of one-to-three-minute intervals called rounds.
",3
3726,"A winner can be resolved before the completion of the rounds when a referee deems an opponent incapable of continuing, disqualification of an opponent, or resignation of an opponent.  When the fight reaches the end of its final round with both opponents still standing, the judges' scorecards determine the victor. In the event that both fighters gain equal scores from the judges, professional bouts are considered a draw. In Olympic boxing, because a winner must be declared, judges award the contest to one fighter on technical criteria.
",3
3727,"While humans have fought in hand-to-hand combat since the dawn of human history, the earliest evidence of fist-fighting sporting contests date back to the ancient Near East in the 3rd and 2nd millennia BC.[2] The earliest evidence of boxing rules date back to Ancient Greece, where boxing was established as an Olympic game in 688 BC.[2] Boxing evolved from 16th- and 18th-century prizefights, largely in Great Britain, to the forerunner of modern boxing in the mid-19th century with the 1867 introduction of the Marquess of Queensberry Rules.
",3
3728,"The earliest known depiction of boxing comes from a Sumerian relief in Iraq from the 3rd millennium BC.[2] A relief sculpture from Egyptian Thebes (c. 1350 BC) shows both boxers and spectators.[2] These early Middle-Eastern and Egyptian depictions showed contests where fighters were either bare-fisted or had a band supporting the wrist.[2] The earliest evidence of fist fighting with the use of gloves can be found on Minoan Crete (c. 1500–1400 BC).[2]
",3
3729,"Various types of boxing existed in ancient India. The earliest references to musti-yuddha come from classical Vedic epics such as the Ramayana and Rig Veda. The Mahabharata describes two combatants boxing with clenched fists and fighting with kicks, finger strikes, knee strikes and headbutts.[3] Duels (niyuddham) were often fought to the death.[citation needed] During the period of the Western Satraps, the ruler Rudradaman—in addition to being well-versed in ""the great sciences"" which included Indian classical music, Sanskrit grammar, and logic—was said to be an excellent horseman, charioteer, elephant rider, swordsman and boxer.[4] The Gurbilas Shemi, an 18th-century Sikh text, gives numerous references to musti-yuddha.
",3
3730,"In Ancient Greece boxing was a well developed sport and enjoyed consistent popularity. In Olympic terms, it was first introduced in the 23rd Olympiad, 688 BC. The boxers would wind leather thongs around their hands in order to protect them. There were no rounds and boxers fought until one of them acknowledged defeat or could not continue. Weight categories were not used, which meant heavyweights had a tendency to dominate. The style of boxing practiced typically featured an advanced left leg stance, with the left arm semi-extended as a guard, in addition to being used for striking, and with the right arm drawn back ready to strike. It was the head of the opponent which was primarily targeted, and there is little evidence to suggest that targeting the body was common.[5]
",3
3731,"Boxing was a popular spectator sport in Ancient Rome.[6] Fighters protected their knuckles with leather thongs wrapped around their fists. Eventually harder leather was used and the thong became a weapon. Metal studs were introduced to the thongs to make the cestus. Fighting events were held at Roman amphitheatres.
",3
3732,"Records of Classical boxing activity disappeared after the fall of the Western Roman Empire when the wearing of weapons became common once again and interest in fighting with the fists waned. However, there are detailed records of various fist-fighting sports that were maintained in different cities and provinces of Italy between the 12th and 17th centuries. There was also a sport in ancient Rus called Kulachniy Boy or ""Fist Fighting"".
",3
3733,"As the wearing of swords became less common, there was renewed interest in fencing with the fists. The sport would later resurface in England during the early 16th century in the form of bare-knuckle boxing sometimes referred to as prizefighting. The first documented account of a bare-knuckle fight in England appeared in 1681 in the London Protestant Mercury, and the first English bare-knuckle champion was James Figg in 1719.[7] This is also the time when the word ""boxing"" first came to be used. This earliest form of modern boxing was very different. Contests in Mr. Figg's time, in addition to fist fighting, also contained fencing and cudgeling. On 6 January 1681, the first recorded boxing match took place in Britain when Christopher Monck, 2nd Duke of Albemarle (and later Lieutenant Governor of Jamaica) engineered a bout between his butler and his butcher with the latter winning the prize.
",3
3734,"Early fighting had no written rules. There were no weight divisions or round limits, and no referee. In general, it was extremely chaotic. An early article on boxing was published in Nottingham, 1713, by Sir Thomas Parkyns, a successful Wrestler from Bunny, Nottinghamshire, who had practised the techniques he described. The article, a single page in his manual of wrestling and fencing, Progymnasmata: The inn-play, or Cornish-hugg wrestler, described a system of headbutting, punching, eye-gouging, chokes, and hard throws, not recognized in boxing today.[8]
",3
3735,"The first boxing rules, called the Broughton's rules, were introduced by champion Jack Broughton in 1743 to protect fighters in the ring where deaths sometimes occurred.[9] Under these rules, if a man went down and could not continue after a count of 30 seconds, the fight was over. Hitting a downed fighter and grasping below the waist were prohibited. Broughton encouraged the use of 'mufflers', a form of padded bandage or mitten, to be used in 'jousting' or sparring sessions in training, and in exhibition matches.
",3
3736,"These rules did allow the fighters an advantage not enjoyed by today's boxers; they permitted the fighter to drop to one knee to end the round and begin the 30-second count at any time. Thus a fighter realizing he was in trouble had an opportunity to recover. However, this was considered ""unmanly""[10] and was frequently disallowed by additional rules negotiated by the Seconds of the Boxers.[11] In modern boxing, there is a three-minute limit to rounds (unlike the downed fighter ends the round rule). Intentionally going down in modern boxing will cause the recovering fighter to lose points in the scoring system. Furthermore, as the contestants did not have heavy leather gloves and wristwraps to protect their hands, they used different punching technique to preserve their hands because the head was a common target to hit full out.[dubious  – discuss][citation needed] Almost all period manuals have powerful straight punches with the whole body behind them to the face (including forehead) as the basic blows.[12][13][unreliable source?]
",3
3737,"The London Prize Ring Rules introduced measures that remain in effect for professional boxing to this day, such as outlawing butting, gouging, scratching, kicking, hitting a man while down, holding the ropes, and using resin, stones or hard objects in the hands, and biting.[14]
",3
3738,"In 1867, the Marquess of Queensberry rules were drafted by John Chambers for amateur championships held at Lillie Bridge in London for Lightweights, Middleweights and Heavyweights. The rules were published under the patronage of the Marquess of Queensberry, whose name has always been associated with them.
",3
3739,"There were twelve rules in all, and they specified that fights should be ""a fair stand-up boxing match"" in a 24-foot-square or similar ring. Rounds were three minutes with one-minute rest intervals between rounds. Each fighter was given a ten-second count if he was knocked down, and wrestling was banned.
The introduction of gloves of ""fair-size"" also changed the nature of the bouts. An average pair of boxing gloves resembles a bloated pair of mittens and are laced up around the wrists.[16]
The gloves can be used to block an opponent's blows. As a result of their introduction, bouts became longer and more strategic with greater importance attached to defensive maneuvers such as slipping, bobbing, countering and angling. Because less defensive emphasis was placed on the use of the forearms and more on the gloves, the classical forearms outwards, torso leaning back stance of the bare knuckle boxer was modified to a more modern stance in which the torso is tilted forward and the hands are held closer to the face.
",3
3740,"Through the late nineteenth century, the martial art of boxing or prizefighting was primarily a sport of dubious legitimacy. Outlawed in England and much of the United States, prizefights were often held at gambling venues and broken up by police.[17] Brawling and wrestling tactics continued, and riots at prizefights were common occurrences. Still, throughout this period, there arose some notable bare knuckle champions who developed fairly sophisticated fighting tactics.
",3
3741,"The English case of R v. Coney in 1882 found that a bare-knuckle fight was an assault occasioning actual bodily harm, despite the consent of the participants. This marked the end of widespread public bare-knuckle contests in England.
",3
3742,"The first world heavyweight champion under the Queensberry Rules was ""Gentleman Jim"" Corbett, who defeated John L. Sullivan in 1892 at the Pelican Athletic Club in New Orleans.[18]
",3
3743,"The first instance of film censorship in the United States occurred in 1897 when several states banned the showing of prize fighting films from the state of Nevada,[19] where it was legal at the time.
",3
3744,"Throughout the early twentieth century, boxers struggled to achieve legitimacy.[20] They were aided by the influence of promoters like Tex Rickard and the popularity of great champions such as John L. Sullivan.
",3
3745,"The modern sport arose from illegal venues and outlawed prizefighting and has become a multibillion-dollar commercial enterprise. A majority of young talent still comes from poverty-stricken areas around the world.[citation needed] Places like Mexico, Africa, South America, and Eastern Europe prove to be filled with young aspiring athletes who wish to become the future of boxing. Even in the U.S., places like the inner cities of New York, and Chicago have given rise to promising young talent. According to Rubin, ""boxing lost its appeal with the American middle class, and most of who boxes in modern America come from the streets and are street fighters"".[21]
",3
3746,"The Marquess of Queensberry rules have been the general rules governing modern boxing since their publication in 1867.[22]
",3
3747,"A boxing match typically consists of a determined number of three-minute rounds, a total of up to 9 to 12 rounds. A minute is typically spent between each round with the fighters in their assigned corners receiving advice and attention from their coach and staff. The fight is controlled by a referee who works within the ring to judge and control the conduct of the fighters, rule on their ability to fight safely, count knocked-down fighters, and rule on fouls.
",3
3748,"Up to three judges are typically present at ringside to score the bout and assign points to the boxers, based on punches and elbows that connect, defense, knockdowns, hugging and other, more subjective, measures. Because of the open-ended style of boxing judging, many fights have controversial results, in which one or both fighters believe they have been ""robbed"" or unfairly denied a victory. Each fighter has an assigned corner of the ring, where his or her coach, as well as one or more ""seconds"" may administer to the fighter at the beginning of the fight and between rounds. Each boxer enters into the ring from their assigned corners at the beginning of each round and must cease fighting and return to their corner at the signalled end of each round.
",3
3749,"A bout in which the predetermined number of rounds passes is decided by the judges, and is said to ""go the distance"". The fighter with the higher score at the end of the fight is ruled the winner. With three judges, unanimous and split decisions are possible, as are draws. A boxer may win the bout before a decision is reached through a knock-out; such bouts are said to have ended ""inside the distance"". If a fighter is knocked down during the fight, determined by whether the boxer touches the canvas floor of the ring with any part of their body other than the feet as a result of the opponent's punch and not a slip, as determined by the referee, the referee begins counting until the fighter returns to his or her feet and can continue. Some jurisdictions require the referee to count to eight regardless of if the fighter gets up before.
",3
3750,"Should the referee count to ten, then the knocked-down boxer is ruled ""knocked out"" (whether unconscious or not) and the other boxer is ruled the winner by knockout (KO). A ""technical knock-out"" (TKO) is possible as well, and is ruled by the referee, fight doctor, or a fighter's corner if a fighter is unable to safely continue to fight, based upon injuries or being judged unable to effectively defend themselves. Many jurisdictions and sanctioning agencies also have a ""three-knockdown rule"", in which three knockdowns in a given round result in a TKO. A TKO is considered a knockout in a fighter's record. A ""standing eight"" count rule may also be in effect. This gives the referee the right to step in and administer a count of eight to a fighter that he or she feels may be in danger, even if no knockdown has taken place. After counting the referee will observe the fighter, and decide if he or she is fit to continue. For scoring purposes, a standing eight count is treated as a knockdown.
",3
3751,"In general, boxers are prohibited from hitting below the belt, holding, tripping, pushing, biting, or spitting. The boxer's shorts are raised so the opponent is not allowed to hit to the groin area with intent to cause pain or injury. Failure to abide by the former may result in a foul. They also are prohibited from kicking, head-butting, or hitting with any part of the arm other than the knuckles of a closed fist (including hitting with the elbow, shoulder or forearm, as well as with open gloves, the wrist, the inside, back or side of the hand). They are prohibited as well from hitting the back, back of the head or neck (called a ""rabbit-punch"") or the kidneys. They are prohibited from holding the ropes for support when punching, holding an opponent while punching, or ducking below the belt of their opponent (dropping below the waist of your opponent, no matter the distance between).
",3
3752,"If a ""clinch"" – a defensive move in which a boxer wraps his or her opponents arms and holds on to create a pause – is broken by the referee, each fighter must take a full step back before punching again (alternatively, the referee may direct the fighters to ""punch out"" of the clinch). When a boxer is knocked down, the other boxer must immediately cease fighting and move to the furthest neutral corner of the ring until the referee has either ruled a knockout or called for the fight to continue.
",3
3753,"Violations of these rules may be ruled ""fouls"" by the referee, who may issue warnings, deduct points, or disqualify an offending boxer, causing an automatic loss, depending on the seriousness and intentionality of the foul. An intentional foul that causes injury that prevents a fight from continuing usually causes the boxer who committed it to be disqualified. A fighter who suffers an accidental low-blow may be given up to five minutes to recover, after which they may be ruled knocked out if they are unable to continue. Accidental fouls that cause injury ending a bout may lead to a ""no contest"" result, or else cause the fight to go to a decision if enough rounds (typically four or more, or at least three in a four-round fight) have passed.
",3
3754,"Unheard of in the modern era, but common during the early 20th Century in North America, a ""newspaper decision (NWS)"" might be made after a no decision bout had ended. A ""no decision"" bout occurred when, by law or by pre-arrangement of the fighters, if both boxers were still standing at the fight's conclusion and there was no knockout, no official decision was rendered and neither boxer was declared the winner. But this did not prevent the pool of ringside newspaper reporters from declaring a consensus result among themselves and printing a newspaper decision in their publications. Officially, however, a ""no decision"" bout resulted in neither boxer winning or losing. Boxing historians sometimes use these unofficial newspaper decisions in compiling fight records for illustrative purposes only. Often, media outlets covering a match will personally score the match, and post their scores as an independent sentence in their report.
",3
3755,"Throughout the 17th to 19th centuries, boxing bouts were motivated by money, as the fighters competed for prize money, promoters controlled the gate, and spectators bet on the result.
",3
3756,"The modern Olympic movement revived interest in amateur sports, and amateur boxing became an Olympic sport in 1908. In their current form, Olympic and other amateur bouts are typically limited to three or four rounds, scoring is computed by points based on the number of clean blows landed, regardless of impact, and fighters wear protective headgear, reducing the number of injuries, knockdowns, and knockouts.[23] Currently scoring blows in amateur boxing are subjectively counted by ringside judges, but the Australian Institute for Sport has demonstrated a prototype of an Automated Boxing Scoring System, which introduces scoring objectivity, improves safety, and arguably makes the sport more interesting to spectators. Professional boxing remains by far the most popular form of the sport globally, though amateur boxing is dominant in Cuba and some former Soviet republics. For most fighters, an amateur career, especially at the Olympics, serves to develop skills and gain experience in preparation for a professional career. Western boxers typically participate in one Olympics and then turn pro, Cubans and other socialist countries have an opportunity to collect multiple medals.[24] In 2016, professional boxers were admitted in the Olympic Games and other tournaments sanctioned by AIBA.[25] This was done in part to level the playing field and give all of the athletes the same opportunities government-sponsored boxers from socialist countries and post-Soviet republics have.[26] However, professional organizations strongly opposed that decision.[27][28]
",3
3757,"Amateur boxing may be found at the collegiate level, at the Olympic Games, Commonwealth Games, Asian Games, etc. In many other venues sanctioned by amateur boxing associations. Amateur boxing has a point scoring system that measures the number of clean blows landed rather than physical damage. Bouts consist of three rounds of three minutes in the Olympic and Commonwealth Games, and three rounds of three minutes in a national ABA (Amateur Boxing Association) bout, each with a one-minute interval between rounds.
",3
3758,"Competitors wear protective headgear and gloves with a white strip or circle across the knuckle. There are cases however, where white ended gloves are not required but any solid color may be worn. The white end is just a way to make it easier for judges to score clean hits. Each competitor must have their hands properly wrapped, pre-fight, for added protection on their hands and for added cushion under the gloves. Gloves worn by the fighters must be twelve ounces in weight unless the fighters weigh under 165 pounds (75 kg), thus allowing them to wear ten ounce gloves. A punch is considered a scoring punch only when the boxers connect with the white portion of the gloves. Each punch that lands cleanly on the head or torso with sufficient force is awarded a point. A referee monitors the fight to ensure that competitors use only legal blows. A belt worn over the torso represents the lower limit of punches – any boxer repeatedly landing low blows below the belt is disqualified. Referees also ensure that the boxers don't use holding tactics to prevent the opponent from swinging. If this occurs, the referee separates the opponents and orders them to continue boxing. Repeated holding can result in a boxer being penalized or ultimately disqualified. Referees will stop the bout if a boxer is seriously injured, if one boxer is significantly dominating the other or if the score is severely imbalanced.[29] Amateur bouts which end this way may be noted as ""RSC"" (referee stopped contest) with notations for an outclassed opponent (RSCO), outscored opponent (RSCOS), injury (RSCI) or head injury (RSCH).
",3
3759,"Professional bouts are usually much longer than amateur bouts, typically ranging from ten to twelve rounds, though four-round fights are common for less experienced fighters or club fighters. There are also some two- and three-round professional bouts, especially in Australia. Through the early 20th century, it was common for fights to have unlimited rounds, ending only when one fighter quit, benefiting high-energy fighters like Jack Dempsey. Fifteen rounds remained the internationally recognized limit for championship fights for most of the 20th century until the early 1980s, when the death of boxer Kim Duk-koo eventually prompted the World Boxing Council and other organizations sanctioning professional boxing to reduce the limit to twelve rounds.
",3
3760,"Headgear is not permitted in professional bouts, and boxers are generally allowed to take much more damage before a fight is halted. At any time, the referee may stop the contest if he believes that one participant cannot defend himself due to injury. In that case, the other participant is awarded a technical knockout win. A technical knockout would also be awarded if a fighter lands a punch that opens a cut on the opponent, and the opponent is later deemed not fit to continue by a doctor because of the cut. For this reason, fighters often employ cutmen, whose job is to treat cuts between rounds so that the boxer is able to continue despite the cut. If a boxer simply quits fighting, or if his corner stops the fight, then the winning boxer is also awarded a technical knockout victory. In contrast with amateur boxing, professional male boxers have to be bare-chested.[30]
",3
3761,"""Style"" is often defined as the strategic approach a fighter takes during a bout. No two fighters' styles are alike, as each is determined by that individual's physical and mental attributes. Three main styles exist in boxing: outside fighter (""boxer""), brawler (or ""slugger""), and Inside fighter (""swarmer""). These styles may be divided into several special subgroups, such as counter puncher, etc. The main philosophy of the styles is, that each style has an advantage over one, but disadvantage over the other one. It follows the rock paper scissors scenario - boxer beats brawler, brawler beats swarmer, and swarmer beats boxer.[31]
",3
3762,"A classic ""boxer"" or stylist (also known as an ""out-fighter"") seeks to maintain distance between himself and his opponent, fighting with faster, longer range punches, most notably the jab, and gradually wearing his opponent down. Due to this reliance on weaker punches, out-fighters tend to win by point decisions rather than by knockout, though some out-fighters have notable knockout records. They are often regarded as the best boxing strategists due to their ability to control the pace of the fight and lead their opponent, methodically wearing him down and exhibiting more skill and finesse than a brawler.[32] Out-fighters need reach, hand speed, reflexes, and footwork.
",3
3763,"Notable out-fighters include Muhammad Ali, Larry Holmes, Joe Calzaghe, Wilfredo Gómez, Salvador Sánchez, Cecilia Brækhus, Gene Tunney,[33] Ezzard Charles,[34] Willie Pep,[35] Meldrick Taylor, Ricardo ""Finito"" López, Floyd Mayweather Jr., Roy Jones Jr., Sugar Ray Leonard, Miguel Vázquez, Sergio ""Maravilla"" Martínez, Vitali Klitschko, Wladimir Klitschko and Guillermo Rigondeaux. This style was also used by fictional boxer Apollo Creed.
",3
3764,"A boxer-puncher is a well-rounded boxer who is able to fight at close range with a combination of technique and power, often with the ability to knock opponents out with a combination and in some instances a single shot. Their movement and tactics are similar to that of an out-fighter (although they are generally not as mobile as an out-fighter),[36] but instead of winning by decision, they tend to wear their opponents down using combinations and then move in to score the knockout. A boxer must be well rounded to be effective using this style.
",3
3765,"Notable boxer-punchers include Muhammad Ali, Canelo Álvarez, Sugar Ray Leonard, Roy Jones Jr., Wladimir Klitschko, Vasyl Lomachenko, Lennox Lewis, Joe Louis,[37] Wilfredo Gómez, Oscar De La Hoya, Archie Moore, Miguel Cotto, Nonito Donaire, Sam Langford,[38] Henry Armstrong,[39] Sugar Ray Robinson,[40] Tony Zale, Carlos Monzón,[41] Alexis Argüello, Érik Morales, Terry Norris, Marco Antonio Barrera, Naseem Hamed, Thomas Hearns, Julian Jackson and Gennady Golovkin.
",3
3766,"Counter punchers are slippery, defensive style fighters who often rely on their opponent's mistakes in order to gain the advantage, whether it be on the score cards or more preferably a knockout. They use their well-rounded defense to avoid or block shots and then immediately catch the opponent off guard with a well placed and timed punch. A fight with a skilled counter-puncher can turn into a war of attrition, where each shot landed is a battle in itself. Thus, fighting against counter punchers requires constant feinting and the ability to avoid telegraphing one's attacks. To be truly successful using this style they must have good reflexes, a high level of prediction and awareness, pinpoint accuracy and speed, both in striking and in footwork.
",3
3767,"Notable counter punchers include Muhammad Ali, Joe Calzaghe, Vitali Klitschko, Evander Holyfield, Max Schmeling, Chris Byrd, Jim Corbett, Jack Johnson, Bernard Hopkins, Laszlo Papp, Jerry Quarry, Anselmo Moreno, James Toney, Marvin Hagler, Juan Manuel Márquez, Humberto Soto, Floyd Mayweather Jr., Roger Mayweather, Pernell Whitaker, Sergio Gabriel Martinez and Guillermo Rigondeaux. This style of boxing is also used by fictional boxer Little Mac.
",3
3768,"Counter punchers usually wear their opponents down by causing them to miss their punches. The more the opponent misses, the faster they tire, and the psychological effects of being unable to land a hit will start to sink in. The counter puncher often tries to outplay their opponent entirely, not just in a physical sense, but also in a mental and emotional sense. This style can be incredibly difficult, especially against seasoned fighters, but winning a fight without getting hit is often worth the pay-off. They usually try to stay away from the center of the ring, in order to outmaneuver and chip away at their opponents. A large advantage in counter-hitting is the forward momentum of the attacker, which drives them further into your return strike. As such, knockouts are more common than one would expect from a defensive style.
",3
3769,"A brawler is a fighter who generally lacks finesse and footwork in the ring, but makes up for it through sheer punching power. Many brawlers tend to lack mobility, preferring a less mobile, more stable platform and have difficulty pursuing fighters who are fast on their feet. They may also have a tendency to ignore combination punching in favor of continuous beat-downs with one hand and by throwing slower, more powerful single punches (such as hooks and uppercuts). Their slowness and predictable punching pattern (single punches with obvious leads) often leaves them open to counter punches, so successful brawlers must be able to absorb substantial amounts of punishment. However, not all brawler/slugger fighters are not mobile; some can move around and switch styles if needed but still have the brawler/slugger style such as Wilfredo Gómez, Prince Naseem Hamed and Danny García.
",3
3770,"A brawler's most important assets are power and chin (the ability to absorb punishment while remaining able to continue boxing). Examples of this style include George Foreman, Rocky Marciano, Julio César Chávez, Roberto Durán, Danny García, Wilfredo Gómez, Sonny Liston, John L. Sullivan, Max Baer, Prince Naseem Hamed, Ray Mancini, David Tua, Arturo Gatti, Micky Ward, Brandon Ríos, Ruslan Provodnikov, Michael Katsidis, James Kirkland, Marcos Maidana, Jake LaMotta, Manny Pacquiao, and Ireland's John Duddy. This style of boxing was also used by fictional boxers Rocky Balboa and James ""Clubber"" Lang.
",3
3771,"Brawlers tend to be more predictable and easy to hit but usually fare well enough against other fighting styles because they train to take punches very well. They often have a higher chance than other fighting styles to score a knockout against their opponents because they focus on landing big, powerful hits, instead of smaller, faster attacks. Oftentimes they place focus on training on their upper body instead of their entire body, to increase power and endurance. They also aim to intimidate their opponents because of their power, stature and ability to take a punch.
",3
3772,"In-fighters/swarmers (sometimes called ""pressure fighters"") attempt to stay close to an opponent, throwing intense flurries and combinations of hooks and uppercuts. Mainly Mexican, Irish, Irish-American, Puerto Rican, and Mexican-American boxers popularized this style. A successful in-fighter often needs a good ""chin"" because swarming usually involves being hit with many jabs before they can maneuver inside where they are more effective. In-fighters operate best at close range because they are generally shorter and have less reach than their opponents and thus are more effective at a short distance where the longer arms of their opponents make punching awkward. However, several fighters tall for their division have been relatively adept at in-fighting as well as out-fighting.
",3
3773,"The essence of a swarmer is non-stop aggression. Many short in-fighters use their stature to their advantage, employing a bob-and-weave defense by bending at the waist to slip underneath or to the sides of incoming punches. Unlike blocking, causing an opponent to miss a punch disrupts his balance, this permits forward movement past the opponent's extended arm and keeps the hands free to counter. A distinct advantage that in-fighters have is when throwing uppercuts, they can channel their entire bodyweight behind the punch; Mike Tyson was famous for throwing devastating uppercuts. Marvin Hagler was known for his hard ""chin"", punching power, body attack and the stalking of his opponents. Some in-fighters, like Mike Tyson, have been known for being notoriously hard to hit. The key to a swarmer is aggression, endurance, chin, and bobbing-and-weaving.
",3
3774,"Notable in-fighters include Henry Armstrong, Aaron Pryor, Julio César Chávez, Jack Dempsey, Shawn Porter, Miguel Cotto, Joe Frazier, Danny García, Mike Tyson, Manny Pacquiao, Rocky Marciano,[42] Wayne McCullough, James Braddock, Gerry Penalosa, Harry Greb,[43][44] David Tua, James Toney and Ricky Hatton. This style was also used by the Street Fighter character Balrog.
",3
3775,"All fighters have primary skills with which they feel most comfortable, but truly elite fighters are often able to incorporate auxiliary styles when presented with a particular challenge. For example, an out-fighter will sometimes plant his feet and counter punch, or a slugger may have the stamina to pressure fight with his power punches.
",3
3776,"Old history of the development of boxing and its prevalence contribute to fusion of various types of martial arts and the emergence of new ones that are based on them. For example, a combination of boxing and sportive sambo techniques gave rise to a combat sambo.
",3
3777,"There is a generally accepted rule of thumb about the success each of these boxing styles has against the others. In general, an in-fighter has an advantage over an out-fighter, an out-fighter has an advantage over a brawler, and a brawler has an advantage over an in-fighter; these form a cycle with each style being stronger relative to one, and weaker relative to another, with none dominating, as in rock paper scissors. Naturally, many other factors, such as the skill level and training of the combatants, determine the outcome of a fight, but the widely held belief in this relationship among the styles is embodied in the cliché amongst boxing fans and writers that ""styles make fights.""
",3
3778,"Brawlers tend to overcome swarmers or in-fighters because, in trying to get close to the slugger, the in-fighter will invariably have to walk straight into the guns of the much harder-hitting brawler, so, unless the former has a very good chin and the latter's stamina is poor, the brawler's superior power will carry the day. A famous example of this type of match-up advantage would be George Foreman's knockout victory over Joe Frazier in their original bout ""The Sunshine Showdown"".
",3
3779,"Although in-fighters struggle against heavy sluggers, they typically enjoy more success against out-fighters or boxers. Out-fighters prefer a slower fight, with some distance between themselves and the opponent. The in-fighter tries to close that gap and unleash furious flurries. On the inside, the out-fighter loses a lot of his combat effectiveness, because he cannot throw the hard punches. The in-fighter is generally successful in this case, due to his intensity in advancing on his opponent and his good agility, which makes him difficult to evade. For example, the swarming Joe Frazier, though easily dominated by the slugger George Foreman, was able to create many more problems for the boxer Muhammad Ali in their three fights. Joe Louis, after retirement, admitted that he hated being crowded, and that swarmers like untied/undefeated champ Rocky Marciano would have caused him style problems even in his prime.
",3
3780,"The boxer or out-fighter tends to be most successful against a brawler, whose slow speed (both hand and foot) and poor technique makes him an easy target to hit for the faster out-fighter. The out-fighter's main concern is to stay alert, as the brawler only needs to land one good punch to finish the fight. If the out-fighter can avoid those power punches, he can often wear the brawler down with fast jabs, tiring him out. If he is successful enough, he may even apply extra pressure in the later rounds in an attempt to achieve a knockout. Most classic boxers, such as Muhammad Ali, enjoyed their best successes against sluggers.
",3
3781,"An example of a style matchup was the historical fight of Julio César Chávez, a swarmer or in-fighter, against Meldrick Taylor, the boxer or out-fighter (see Julio César Chávez vs. Meldrick Taylor). The match was nicknamed ""Thunder Meets Lightning"" as an allusion to punching power of Chávez and blinding speed of Taylor. Chávez was the epitome of the ""Mexican"" style of boxing. Taylor's hand and foot speed and boxing abilities gave him the early advantage, allowing him to begin building a large lead on points. Chávez remained relentless in his pursuit of Taylor and due to his greater punching power Chávez slowly punished Taylor. Coming into the later rounds, Taylor was bleeding from the mouth, his entire face was swollen, the bones around his eye socket had been broken, he had swallowed a considerable amount of his own blood, and as he grew tired, Taylor was increasingly forced into exchanging blows with Chávez, which only gave Chávez a greater chance to cause damage. While there was little doubt that Taylor had solidly won the first three quarters of the fight, the question at hand was whether he would survive the final quarter. Going into the final round, Taylor held a secure lead on the scorecards of two of the three judges. Chávez would have to knock Taylor out to claim a victory, whereas Taylor merely needed to stay away from the Mexican legend. However, Taylor did not stay away, but continued to trade blows with Chávez. As he did so, Taylor showed signs of extreme exhaustion, and every tick of the clock brought Taylor closer to victory unless Chávez could knock him out.
With about a minute left in the round, Chávez hit Taylor squarely with several hard punches and stayed on the attack, continuing to hit Taylor with well-placed shots. Finally, with about 25 seconds to go, Chávez landed a hard right hand that caused Taylor to stagger forward towards a corner, forcing Chávez back ahead of him. Suddenly Chávez stepped around Taylor, positioning him so that Taylor was trapped in the corner, with no way to escape from Chávez' desperate final flurry. Chávez then nailed Taylor with a tremendous right hand that dropped the younger man. By using the ring ropes to pull himself up, Taylor managed to return to his feet and was given the mandatory 8-count. Referee Richard Steele asked Taylor twice if he was able to continue fighting, but Taylor failed to answer. Steele then concluded that Taylor was unfit to continue and signaled that he was ending the fight, resulting in a TKO victory for Chávez with only two seconds to go in the bout.
",3
3782,"Since boxing involves forceful, repetitive punching, precautions must be taken to prevent damage to bones in the hand. Most trainers do not allow boxers to train and spar without wrist wraps and boxing gloves. Hand wraps are used to secure the bones in the hand, and the gloves are used to protect the hands from blunt injury, allowing boxers to throw punches with more force than if they did not use them. Gloves have been required in competition since the late nineteenth century, though modern boxing gloves are much heavier than those worn by early twentieth-century fighters. Prior to a bout, both boxers agree upon the weight of gloves to be used in the bout, with the understanding that lighter gloves allow heavy punchers to inflict more damage. The brand of gloves can also affect the impact of punches, so this too is usually stipulated before a bout. Both sides are allowed to inspect the wraps and gloves of the opponent to help ensure both are within agreed upon specifications and no tampering has taken place.
",3
3783,"A mouthguard is important to protect the teeth[45][46] and gums from injury, and to cushion the jaw, resulting in a decreased chance of knockout. Both fighters must wear soft soled shoes to reduce the damage from accidental (or intentional) stepping on feet. While older boxing boots more commonly resembled those of a professional wrestler, modern boxing shoes and boots tend to be quite similar to their amateur wrestling counterparts.
",3
3784,"Boxers practice their skills on several types of punching bags. A small, tear-drop-shaped ""speed bag"" is used to hone reflexes and repetitive punching skills, while a large cylindrical ""heavy bag"" filled with sand, a synthetic substitute, or water is used to practice power punching and body blows. The double-end bag is usually connected by elastic on the top and bottom and moves randomly upon getting struck and helps the fighter work on accuracy and reflexes. In addition to these distinctive pieces of equipment, boxers also use sport-nonspecific training equipment to build strength, speed, agility, and stamina. Common training equipment includes free weights, rowing machines, jump rope, and medicine balls.
",3
3785,"Boxers also use punch/focus mitts in which a trainer calls out certain combinations and the fighter strikes the mitts accordingly. This is a great exercise for stamina as the boxer isn't allowed to go at his own pace but that of the trainer, typically forcing the fighter to endure a higher output and volume than usual. In addition, they also allow trainers to make boxers utilize footwork and distances more accurately.
",3
3786,"Boxing matches typically take place in a boxing ring, a raised platform surrounded by ropes attached to posts rising in each corner. The term ""ring"" has come to be used as a metaphor for many aspects of prize fighting in general.
",3
3787,"The modern boxing stance differs substantially from the typical boxing stances of the 19th and early 20th centuries. The modern stance has a more upright vertical-armed guard, as opposed to the more horizontal, knuckles-facing-forward guard adopted by early 20th century hook users such as Jack Johnson.
",3
3788,"Upright stance
",3
3789,"Semi-crouch
",3
3790,"Full crouch
",3
3791,"In a fully upright stance, the boxer stands with the legs shoulder-width apart and the rear foot a half-step in front of the lead man. Right-handed or orthodox boxers lead with the left foot and fist (for most penetration power). Both feet are parallel, and the right heel is off the ground. The lead (left) fist is held vertically about six inches in front of the face at eye level. The rear (right) fist is held beside the chin and the elbow tucked against the ribcage to protect the body. The chin is tucked into the chest to avoid punches to the jaw which commonly cause knock-outs and is often kept slightly off-center. Wrists are slightly bent to avoid damage when punching and the elbows are kept tucked in to protect the ribcage. Some boxers fight from a crouch, leaning forward and keeping their feet closer together. The stance described is considered the ""textbook"" stance and fighters are encouraged to change it around once it's been mastered as a base. Case in point, many fast fighters have their hands down and have almost exaggerated footwork, while brawlers or bully fighters tend to slowly stalk their opponents. In order to retain their stance boxers take 'the first step in any direction with the foot already leading in that direction.'[47]
",3
3792,"Different stances allow for bodyweight to be differently positioned and emphasised; this may in turn alter how powerfully and explosively a type of punch can be delivered. For instance, a crouched stance allows for the bodyweight to be positioned further forward over the lead left leg. If a lead left hook is thrown from this position, it will produce a powerful springing action in the lead leg and produce a more explosive punch. This springing action could not be generated effectively, for this punch, if an upright stance was used or if the bodyweight was positioned predominantly over the back leg.[48] Mike Tyson was a keen practitioner of a crouched stance and this style of power punching. The preparatory positioning of the bodyweight over the bent lead leg is also known as an isometric preload.
",3
3793,"Left-handed or southpaw fighters use a mirror image of the orthodox stance, which can create problems for orthodox fighters unaccustomed to receiving jabs, hooks, or crosses from the opposite side. The southpaw stance, conversely, is vulnerable to a straight right hand.
",3
3794,"North American fighters tend to favor a more balanced stance, facing the opponent almost squarely, while many European fighters stand with their torso turned more to the side. The positioning of the hands may also vary, as some fighters prefer to have both hands raised in front of the face, risking exposure to body shots.
",3
3795,"There are four basic punches in boxing: the jab, cross, hook and uppercut. Any punch other than a jab is considered a power punch. If a boxer is right-handed (orthodox), his left hand is the lead hand and his right hand is the rear hand. For a left-handed boxer or southpaw, the hand positions are reversed. For clarity, the following discussion will assume a right-handed boxer.
",3
3796,"Jab
",3
3797,"Cross  - in counter-punch with a looping
",3
3798,"Hook
",3
3799,"Uppercut
",3
3800,"These different punch types can be thrown in rapid succession to form combinations or ""combos."" The most common is the jab and cross combination, nicknamed the ""one-two combo."" This is usually an effective combination, because the jab blocks the opponent's view of the cross, making it easier to land cleanly and forcefully.
",3
3801,"A large, swinging circular punch starting from a cocked-back position with the arm at a longer extension than the hook and all of the fighter's weight behind it is sometimes referred to as a ""roundhouse,"" ""haymaker,"" ""overhand,"" or sucker-punch. Relying on body weight and centripetal force within a wide arc, the roundhouse can be a powerful blow, but it is often a wild and uncontrolled punch that leaves the fighter delivering it off balance and with an open guard.
",3
3802,"Wide, looping punches have the further disadvantage of taking more time to deliver, giving the opponent ample warning to react and counter. For this reason, the haymaker or roundhouse is not a conventional punch, and is regarded by trainers as a mark of poor technique or desperation. Sometimes it has been used, because of its immense potential power, to finish off an already staggering opponent who seems unable or unlikely to take advantage of the poor position it leaves the puncher in.
",3
3803,"Another unconventional punch is the rarely used bolo punch, in which the opponent swings an arm out several times in a wide arc, usually as a distraction, before delivering with either that or the other arm.
",3
3804,"An illegal punch to the back of the head or neck is known as a rabbit punch.
",3
3805,"Both the hook and uppercut may be thrown with both hands, resulting in differing footwork and positioning from that described above if thrown by the other hand. Generally the analogous opposite is true of the footwork and torso movement.
",3
3806,"There are several basic maneuvers a boxer can use in order to evade or block punches, depicted and discussed below.
",3
3807,"Slipping
",3
3808,"Bobbing
",3
3809,"Blocking (with the arms)
",3
3810,"Cover-Up (with the gloves)
",3
3811,"Clinching
",3
3812,"Footwork
",3
3813,"Pulling away
",3
3814,"Bolo punch
",3
3815,"Overhand (overcut)
",3
3816,"In boxing, each fighter is given a corner of the ring where he rests in between rounds for 1 minute and where his trainers stand. Typically, three men stand in the corner besides the boxer himself; these are the trainer, the assistant trainer and the cutman. The trainer and assistant typically give advice to the boxer on what he is doing wrong as well as encouraging him if he is losing. The cutman is a cutaneous doctor responsible for keeping the boxer's face and eyes free of cuts, blood and excessive swelling. This is of particular importance because many fights are stopped because of cuts or swelling that threaten the boxer's eyes.
",3
3817,"In addition, the corner is responsible for stopping the fight if they feel their fighter is in grave danger of permanent injury. The corner will occasionally throw in a white towel to signify a boxer's surrender (the idiomatic phrase ""to throw in the towel"", meaning to give up, derives from this practice).[53] This can be seen in the fight between Diego Corrales and Floyd Mayweather. In that fight, Corrales' corner surrendered despite Corrales' steadfast refusal.
",3
3818,"Knocking a person unconscious or even causing a concussion may cause permanent brain damage.[54] There is no clear division between the force required to knock a person out and the force likely to kill a person.[55] From 1980 to 2007, more than 200 amateur boxers, professional boxers and Toughman fighters died due to ring or training injuries.[56] In 1983, editorials in the Journal of the American Medical Association called for a ban on boxing.[57] The editor, Dr. George Lundberg, called boxing an ""obscenity"" that ""should not be sanctioned by any civilized society.""[58] Since then, the British,[59] Canadian[60] and Australian[61] Medical Associations have called for bans on boxing.
",3
3819,"Supporters of the ban state that boxing is the only sport where hurting the other athlete is the goal. Dr. Bill O'Neill, boxing spokesman for the British Medical Association, has supported the BMA's proposed ban on boxing: ""It is the only sport where the intention is to inflict serious injury on your opponent, and we feel that we must have a total ban on boxing.""[62] Opponents respond that such a position is misguided opinion, stating that amateur boxing is scored solely according to total connecting blows with no award for ""injury"". They observe that many skilled professional boxers have had rewarding careers without inflicting injury on opponents by accumulating scoring blows and avoiding punches winning rounds scored 10-9 by the 10-point must system, and they note that there are many other sports where concussions are much more prevalent.[63]
",3
3820,"In 2007, one study of amateur boxers showed that protective headgear did not prevent brain damage,[64] and another found that amateur boxers faced a high risk of brain damage.[65] The Gothenburg study analyzed temporary levels of neurofilament light in cerebral spinal fluid which they conclude is evidence of damage, even though the levels soon subside. More comprehensive studies of neurological function on larger samples performed by Johns Hopkins University in 1994 and accident rates analyzed by National Safety Council in 2017 show amateur boxing is a comparatively safe sport.[66][67]
",3
3821,"In 1997, the American Association of Professional Ringside Physicians was established to create medical protocols through research and education to prevent injuries in boxing.[68][69]
",3
3822,"Professional boxing is forbidden in Iceland,[70] Iran, Saudi Arabia and North Korea. It was banned in Sweden until 2007 when the ban was lifted but strict restrictions, including four three-minute rounds for fights, were imposed.[71] Boxing was banned in Albania from 1965 until the fall of Communism in 1991. Norway legalized professional boxing in December 2014.[72]
",3
3823,"As active and dynamic sports, boxing provides the following benefits:
",3
3824,"With a careful and thoughtful approach, boxing can be quite beneficial to health. For example, Gemma Ruegg, a two-weight regional champion from Bournemouth in Dorset, boxed throughout her pregnancy and returned to the ring three weeks after giving birth to her daughter. Earlier, boxing helped her to get rid of alcohol addiction and depression.[73]
",3
3825,"The sport of boxing has two internationally recognized boxing halls of fame; the International Boxing Hall of Fame (IBHOF).[74] In 2013, The Boxing Hall of Fame Las Vegas opened in Las Vegas, NV founded by Steve Lott, former assistant manager for Mike Tyson.[75]
",3
3826,"The International Boxing Hall of Fame opened in Canastota in 1989. The first inductees in 1990 included Jack Johnson, Benny Leonard, Jack Dempsey, Henry Armstrong, Sugar Ray Robinson, Archie Moore, and Muhammad Ali. Other world-class figures[76] include Salvador Sanchez, Jose Napoles, Roberto ""Manos de Piedra"" Durán, Ricardo Lopez, Gabriel ""Flash"" Elorde, Vicente Saldivar, Ismael Laguna, Eusebio Pedroza, Carlos Monzón, Azumah Nelson, Rocky Marciano, Pipino Cuevas and Ken Buchanan. The Hall of Fame's induction ceremony is held every June as part of a four-day event. The fans who come to Canastota for the Induction Weekend are treated to a number of events, including scheduled autograph sessions, boxing exhibitions, a parade featuring past and present inductees, and the induction ceremony itself.
",3
3827,"The Boxing Hall of Fame Las Vegas features the $75 million ESPN Classic Sports fight film and tape library and radio broadcast collection. The collection includes the fights of all the great champions including: Muhammad Ali, Mike Tyson, George Foreman, Roberto Durán, Marvin Hagler, Jack Dempsey, Joe Louis, Joe Frazier, Rocky Marciano and Sugar Ray Robinson. It is this exclusive fight film library that will separate the Boxing Hall of Fame Las Vegas from the other halls of fame which do not have rights to any video of their sports. The inaugural inductees included Muhammad Ali, Henry Armstrong, Tony Canzoneri, Ezzard Charles, Julio César Chávez Sr., Jack Dempsey, Roberto Durán, Joe Louis, and Sugar Ray Robinson[77]
",3
3828,"There are various organization and websites, that rank boxers in both weight class and pound-for-pound manner.
",3
3829,"
",3
3830,"Handball (also known as team handball, European handball or Olympic handball)[3] is a team sport in which two teams of seven players each (six outcourt players and a goalkeeper) pass a ball using their hands with the aim of throwing it into the goal of the other team. A standard match consists of two periods of 30 minutes, and the team that scores more goals wins.
",3
3831,"Modern handball is played on a court of 40 by 20 metres (131 by 66 ft), with a goal in the middle of each end. The goals are surrounded by a 6-meter (20 ft) zone where only the defending goalkeeper is allowed; goals must be scored by throwing the ball from outside the zone or while ""diving"" into it. The sport is usually played indoors, but outdoor variants exist in the forms of field handball, Czech handball (which were more common in the past) and beach handball. The game is fast and high-scoring: professional teams now typically score between 20 and 35 goals each, though lower scores were not uncommon until a few decades ago. Players may score hat tricks. Body contact is permitted for the defenders trying to stop the attackers from approaching the goal. No protective equipment is mandated, but players may wear soft protective bands, pads and mouth guards.[4]
",3
3832,"The game was codified at the end of the 19th century in Denmark. The modern set of rules was published on 29 October 1917 in Berlin, which is seen as the date of birth of the sport,[1][5] and had several revisions since. The first official handball match was played in the same year in Germany.[1] The first international games were played under these rules for men in 1925 and for women in 1930. Men's handball was first played at the 1936 Summer Olympics in Berlin as outdoors, and the next time at the 1972 Summer Olympics in Munich as indoors, and has been an Olympic sport since. Women's team handball was added at the 1976 Summer Olympics.
",3
3833,"The International Handball Federation was formed in 1946 and, as of 2016[update], has 197 member federations.[6] The sport is most popular in Europe, and European countries have won all medals but one in the men's world championships since 1938. In the women's world championships, only two non-European countries have won the title: South Korea and Brazil. The game also enjoys popularity in East Asia, North Africa and parts of South America.
",3
3834,"Games similar to handball were played in Ancient Greece and are represented on amphorae and stone carvings. Although detailed textual reference is rare, there are numerous descriptions of ball games being played where players throw the ball to one another; sometimes this is done in order to avoid interception by a player on the opposing team. Such games were played widely and served as both a form of exercise and a social event.[7]
",3
3835,"There is evidence of ancient Roman women playing a version of handball called expulsim luderecode: lat promoted to code: la .[8] There are records of handball-like games in medieval France, and among the Inuit in Greenland, in the Middle Ages. By the 19th century, there existed similar games of håndbold from Denmark, házená in the Czech Republic, handbol in Ukraine, and torball in Germany.[9]
",3
3836,"The team handball game of today was codified at the end of the 19th century in northern Europe: primarily in Denmark, Germany, Norway and Sweden. The first written set of team handball rules was published in 1906 by the Danish gym teacher, lieutenant and Olympic medalist Holger Nielsen from Ordrup grammar school, north of Copenhagen. The modern set of rules was published on 29 October 1917 by Max Heiser, Karl Schelenz, and Erich Konigh from Berlin, Germany; this day is therefore seen as the ""date of birth"" of the sport.[1][5] The first ever official handball match was played on 2 December 1917 in Berlin.[1] After 1919 the rules were improved by Karl Schelenz. The first international games were played under these rules, between Germany and Austria by men in 1925 and between Germany and Austria by women in 1930.
",3
3837,"In 1926, the Congress of the International Amateur Athletics Federation nominated a committee to draw up international rules for field handball. The International Amateur Handball Federation was formed in 1928 and later the International Handball Federation was formed in 1946.
",3
3838,"Men's field handball was played at the 1936 Summer Olympics in Berlin. During the next several decades, indoor handball flourished and evolved in the Scandinavian countries. The sport re-emerged onto the world stage as team handball for the 1972 Summer Olympics in Munich. Women's team handball was added at the 1976 Summer Olympics in Montreal. Due to its popularity in the region, the Eastern European countries that refined the event became the dominant force in the sport when it was reintroduced.
",3
3839,"The International Handball Federation organised the men's world championship in 1938 and every four (sometimes three) years from World War II to 1995. Since the 1995 world championship in Iceland, the competition has been held every two years. The women's world championship has been held since 1957. The IHF also organizes women's and men's junior world championships. By July 2009, the IHF listed 166 member federations - approximately 795,000 teams and 19 million players.
",3
3840,"The rules are laid out in the IHF's set of rules.[10]
",3
3841,"Two teams of seven players (six court players plus one goalkeeper) take the court and attempt to score points by putting the game ball into the opposing team's goal. In handling the ball, players are subject to the following restrictions:
",3
3842,"Notable scoring opportunities can occur when attacking players jump into the goal area. For example, an attacking player may catch a pass while launching inside the goal area, and then shoot or pass before touching the floor. Doubling occurs when a diving attacking player passes to another diving teammate.
",3
3843,"Handball is played on a court 40 by 20 metres (131 ft 2.80 in × 65 ft 7.40 in), with a goal in the centre of each end. The goals are surrounded by a near-semicircular area, called the zone or the crease, defined by a line six meters from the goal. A dashed near-semicircular line nine metres from the goal marks the free-throw line. Each line on the court is part of the area it encompasses. This implies that the middle line belongs to both halves at the same time.
",3
3844,"The goals are two meters high and three meters wide. They must be securely bolted either to the floor or the wall behind.
",3
3845,"The goal posts and the crossbar must be made out of the same material (e.g., wood or aluminium) and feature a quadratic cross section with sides of 8 cm (3 in). The three sides of the beams visible from the playing field must be painted alternatingly in two contrasting colors which both have to contrast against the background. The colors on both goals must be the same.
",3
3846,"Each goal must feature a net. This must be fastened in such a way that a ball thrown into the goal does not leave or pass the goal under normal circumstances. If necessary, a second net may be clasped to the back of the net on the inside.
",3
3847,"The goals are surrounded by the crease, also called the zone. This area is delineated by two quarter circles with a radius of six metres around the far corners of each goal post and a connecting line parallel to the goal line. Only the defending goalkeeper is allowed inside this zone. However, court players may catch and touch the ball in the air within it as long as the player starts their jump outside the zone and releases the ball before they land (landing inside the perimeter is allowed in this case as long as the ball has been released).
",3
3848,"If a player without the ball contacts the ground inside the goal perimeter, or the line surrounding the perimeter, they must take the most direct path out of it. However, should a player cross the zone in an attempt to gain an advantage (e.g., better position) their team cedes the ball. Similarly, violation of the zone by a defending player is penalized only if they do so in order to gain an advantage in defending.
",3
3849,"Outside of one long edge of the court to both sides of the middle line are the substitution areas for each team. Team officials, substitutes, and suspended players must wait within this area. A team's area is the same side as the goal the team is defending; during halftime, substitution areas are swapped. Any player entering or leaving the play must cross the substitution line which is part of the side line and extends 4.5 metres (15 ft) from the middle line to the team's side.
",3
3850," A standard match has two 30-minute halves with a 10- or 15-minute (major Championships/Olympics) halftime intermission. At half-time, teams switch sides of the court as well as benches. For youths, the length of the halves is reduced—25 minutes at ages 12 to 15, and 20 minutes at ages 8 to 11; though national federations of some countries may differ in their implementation from the official guidelines.[11]
",3
3851,"If a decision must be reached in a particular match (e.g., in a tournament) and it ends in a draw after regular time, there are at maximum two overtimes, each consisting of two straight 5-minute periods with a one-minute break in between. Should these not decide the game either, the winning team is determined in a penalty shootout (best-of-five rounds; if still tied, extra rounds are added until one team wins).
",3
3852,"The referees may call timeout according to their sole discretion; typical reasons are injuries, suspensions, or court cleaning. Penalty throws should trigger a timeout only for lengthy delays, such as a change of the goalkeeper.
",3
3853,"Since 2012, teams can call 3 team timeouts per game (up to two per half), which last one minute each. This right may only be invoked by the team in possession of the ball. Team representatives must show a green card marked with a black T on the timekeeper's desk. The timekeeper then immediately interrupts the game by sounding an acoustic signal to stop the clock. Before 2012, teams were allowed only one timeout per half. For the purpose of calling timeouts, overtime and shootouts are extensions of the second half.
",3
3854,"A handball match is adjudicated by two equal referees. Some national bodies allow games with only a single referee in special cases like illness on short notice. Should the referees disagree on any occasion, a decision is made on mutual agreement during a short timeout; or, in case of punishments, the more severe of the two comes into effect. The referees are obliged to make their decisions ""on the basis of their observations of facts"".[12] Their judgements are final and can be appealed against only if not in compliance with the rules.
",3
3855,"The referees position themselves in such a way that the team players are confined between them. They stand diagonally aligned so that each can observe one side line. Depending on their positions, one is called field referee and the other goal referee. These positions automatically switch on ball turnover. They physically exchange their positions approximately every 10 minutes (long exchange), and change sides every five minutes (short exchange).
",3
3856,"The IHF defines 18 hand signals for quick visual communication with players and officials. The signal for warning is accompanied by a yellow card.[13] A disqualification for the game is indicated by a red card,[14] followed by a blue card if the disqualification will be accompanied by a report.[15] The referees also use whistle blows to indicate infractions or to restart the play.
",3
3857,"The referees are supported by a scorekeeper and a timekeeper who attend to formal things such as keeping track of goals and suspensions, or starting and stopping the clock, respectively. They also keep an eye on the benches and notify the referees on substitution errors. Their desk is located between the two substitution areas.
",3
3858,"Each team consists of seven players on court and seven substitute players on the bench. One player on the court must be the designated goalkeeper, differing in his clothing from the rest of the field players. Substitution of players can be done in any number and at any time during game play. An exchange takes place over the substitution line. A prior notification of the referees is not necessary.
",3
3859,"Some national bodies, such as the Deutsche Handball Bund (DHB, ""German Handball Federation""), allow substitution in junior teams only when in ball possession or during timeouts. This restriction is intended to prevent early specialization of players to offence or defence.
",3
3860,"Field players are allowed to touch the ball with any part of their bodies above and including the knee. As in several other team sports, a distinction is made between catching and dribbling. A player who is in possession of the ball may stand stationary for only three seconds, and may take only three steps. They must then either shoot, pass, or dribble the ball. Taking more than three steps at any time is considered travelling, and results in a turnover. A player may dribble as many times as they want (though, since passing is faster, it is the preferred method of attack), as long as during each dribble the hand contacts only the top of the ball. Therefore, carrying is completely prohibited, and results in a turnover. After the dribble is picked up, the player has the right to another three seconds or three steps. The ball must then be passed or shot, as further holding or dribbling will result in a double dribble turnover and a free throw for the other team. Other offensive infractions that result in a turnover include charging and setting an illegal screen. Carrying the ball into the six-meter zone results either in ball possession by the goalkeeper (by attacker) or turnover (by defender).
",3
3861,"Only the goalkeepers are allowed to move freely within the goal perimeter, although they may not cross the goal perimeter line while carrying or dribbling the ball. Within the zone, they are allowed to touch the ball with all parts of their bodies, including their feet, with a defensive aim (for other actions, they are subject to the same restrictions as the field players). The goalkeepers may participate in the normal play of their teammates. They may be substituted by a regular field player if their team elects to use this scheme in order to outnumber the defending players. Earlier, this field player become the designated goalkeeper on the court; and had to wear some vest or bib to be identified as such. That shirt had to be equal in colour and form to the goalkeeper's shirt, to avoid confusion. A rule change meant to make the game more offensive now allows any player to substitute with the goalkeeper. The new rule resembles the one used in ice hockey. This rule was first used in the women's world championship in December 2015 and has since been used by the men's European championship in January 2016 and by both genders in the Olympic tournament in Rio in 2016.
",3
3862,"If either goalkeeper deflects the ball over the outer goal line, their team stays in possession of the ball, in contrast to other sports like football. The goalkeeper resumes the play with a throw from within the zone (""goalkeeper throw""). Passing to one's own goalkeeper results in a turnover. In a penalty shot, throwing the ball against the head of a goalkeeper who is not moving risks a direct disqualification (""red card"").
",3
3863,"Outside of own D-zone, the goalkeeper is treated as a current field player, and has to follow field players' rules; holding or tackling an opponent player outside the area risks a direct disqualification.[clarification needed] The goalkeeper may not return to the area with the ball.
",3
3864,"Each team is allowed to have a maximum of four team officials seated on the benches. An official is anybody who is neither player nor substitute. One official must be the designated representative who is usually the team manager. Since 2012, representatives can call up to 3 team timeouts (up to twice per half), and may address the scorekeeper, timekeeper, and referees (before that, it was once per half); overtime and shootouts are considered extensions of the second half. Other officials typically include physicians or managers. Neither official is allowed to enter the playing court without the permission of the referees.
",3
3865," The ball is spherical and must be made either of leather or a synthetic material. It is not allowed to have a shiny or slippery surface. As the ball is intended to be operated by a single hand, its official sizes vary depending on age and gender of the participating teams.
",3
3866,"The referees may award a special throw to a team. This usually happens after certain events such as scored goals, off-court balls, turnovers and timeouts. All of these special throws require the thrower to obtain a certain position, and pose restrictions on the positions of all other players. Sometimes the execution must wait for a whistle blow by the referee.
",3
3867,"Penalties are given to players, in progressive format, for fouls that require more punishment than just a free-throw. Actions directed mainly at the opponent and not the ball (such as reaching around, holding, pushing, tripping, and jumping into opponent) as well as contact from the side, from behind a player or impeding the opponent's counterattack are all considered illegal and are subject to penalty. Any infraction that prevents a clear scoring opportunity will result in a seven-meter penalty shot.
",3
3868,"Typically the referee will give a warning yellow card for an illegal action; but, if the contact was particularly dangerous, like striking the opponent in the head, neck or throat, the referee can forego the warning for an immediate two-minute suspension. Players are warned once before given a yellow card; they risk being red-carded if they draw three yellows.
",3
3869,"A red card results in an ejection from the game and a two-minute penalty for the team. A player may receive a red card directly for particularly rough penalties. For instance, any contact from behind during a fast break is now being treated with a red card; as does any deliberate intent to injure opponents. A red-carded player has to leave the playing area completely. A player who is disqualified may be substituted with another player after the two-minute penalty is served. A coach or official can also be penalized progressively. Any coach or official who receives a two-minute suspension will have to pull out one of their players for two minutes; however, the player is not the one punished, and can be substituted in again, as the penalty consists of the team playing with one fewer player than the opposing team.
",3
3870,"After referees award the ball to the opponents for whatever reason, the player currently in possession of the ball has to lay it down quickly, or risk a two-minute suspension. Also, gesticulating or verbally questioning the referee's order, as well as arguing with the officials' decisions, will normally risk a yellow card. If the suspended player protests further, does not walk straight off the field to the bench, or if the referee deems the tempo deliberately slow, that player risks a double yellow card. Illegal substitution (outside of the dedicated area, or if the replacement player enters too early) is prohibited; if they do, they risk a yellow card.
",3
3871,"Players are typically referred to by the positions they are playing. The positions are always denoted from the view of the respective goalkeeper, so that a defender on the right opposes an attacker on the left. However, not all of the following positions may be occupied depending on the formation or potential suspensions.
",3
3872,"Sometimes, the offense uses formations with two pivot players.
",3
3873,"There are many variations in defensive formations. Usually, they are described as n:m formations, where n is the number of players defending at the goal line and m the number of players defending more offensive. Exceptions are the 3:2:1 defense and n+m formation (e.g. 5+1), where m players defend some offensive player in man coverage (instead of the usual zone coverage).
",3
3874,"Attacks are played with all field players on the side of the defenders. Depending on the speed of the attack, one distinguishes between three attack waves with a decreasing chance of success:
",3
3875,"The third wave evolves into the normal offensive play when all defenders not only reach the zone, but gain their accustomed positions. Some teams then substitute specialised offence players. However, this implies that these players must play in the defence should the opposing team be able to switch quickly to offence. The latter is another benefit for fast playing teams.
",3
3876,"If the attacking team does not make sufficient progress (eventually releasing a shot on goal), the referees can call passive play (since about 1995, the referee gives a passive warning some time before the actual call by holding one hand up in the air, signalling that the attacking team should release a shot soon), turning control over to the other team. A shot on goal or an infringement leading to a yellow card or two-minute penalty will mark the start of a new attack, causing the hand to be taken down; but a shot blocked by the defense or a normal free throw will not. If it were not for this rule, it would be easy for an attacking team to stall the game indefinitely, as it is difficult to intercept a pass without at the same time conceding dangerous openings towards the goal.
",3
3877,"The usual formations of the defense are 6–0, when all the defense players line up between the 6-metre (20 ft) and 9-metre (30 ft) lines to form a wall; the 5–1, when one of the players cruises outside the 9-metre (30 ft) perimeter, usually targeting the center forwards while the other 5 line up on the 6-metre (20 ft) line; and the less common 4–2 when there are two such defenders out front. Very fast teams will also try a 3–3 formation which is close to a switching man-to-man style. The formations vary greatly from country to country, and reflect each country's style of play. 6–0 is sometimes known as ""flat defense"", and all other formations are usually called ""offensive defense"".
",3
3878,"Handball teams are usually organised as clubs. On a national level, the clubs are associated in federations which organize matches in leagues and tournaments.
",3
3879,"The International Handball Federation (IHF) is the administrative and controlling body for international handball. Handball is an Olympic sport played during the Summer Olympics.[16]
",3
3880,"The IHF organizes world championships, held in odd-numbered years, with separate competitions for men and women.[17]
The IHF World Men's Handball Championship 2019 title holders are Denmark.[18] The IHF World Women's Handball Championship 2019 title holders are Netherlands.[19]
",3
3881,"The IHF is composed of five continental federations: Asian Handball Federation, African Handball Confederation, Pan-American Team Handball Federation, European Handball Federation and Oceania Handball Federation. These federations organize continental championships held every other second year. Handball is played during the Pan American Games,[20] All-Africa Games,[21] and Asian Games.[16] It is also played at the Mediterranean Games. In addition to continental competitions between national teams, the federations arrange international tournaments between club teams.[22]
",3
3882,"The current worldwide attendance record for seven-a-side handball was set on 6 September 2014, during a neutral venue German league game between HSV Hamburg and the Mannheim-based Rhein-Neckar Lions.[23] The matchup drew 44,189 spectators to Commerzbank Arena in Frankfurt, exceeding the previous record of 36,651 set at Copenhagen's Parken Stadium during the 2011 Danish Cup final.[23]
",3
3883,"Handball events have been selected as a main motif in numerous collectors' coins. One of the recent samples is the €10 Greek Handball commemorative coin, minted in 2003 to commemorate the 2004 Summer Olympics. On the coin, the modern athlete directs the ball in his hands towards his target, while in the background the ancient athlete is just about to throw a ball, in a game known as cheirosphaira, in a representation taken from a black-figure pottery vase of the Archaic period.[24]
",3
3884,"The most recent commemorative coin featuring handball is the British 50 pence coin, part of the series of coins commemorating the London 2012 Olympic Games.[25]
",3
3885,"Notes
",3
3886," Media related to Handball at Wikimedia Commons
",3
3887,"
",4
3888,"An economy (from Greek οίκος – ""household"" and νέμoμαι – ""manage"") is an area of the production, distribution and trade, as well as consumption of goods and services by different agents. In general, it is defined  'as a social domain that emphasize the practices, discourses, and material expressions associated with the production, use, and management of resources'.[1] A given economy is the result of a set of processes that involves its culture, values, education, technological evolution, history, social organization, political structure and legal systems, as well as its geography, natural resource endowment, and ecology, as main factors. These factors give context, content, and set the conditions and parameters in which an economy functions. In other words, the economic domain is a social domain of interrelated human practices and transactions that does not stand alone.
",4
3889,"Economic agents can be individuals, businesses, organizations, or governments. Economic transactions occur when two groups or parties agree to the value or price of the transacted good or service, commonly expressed in a certain currency. However, monetary transactions only account for a small part of the economic domain. 
",4
3890,"Economic activity is spurred by production which uses natural resources, labor and capital. It has changed over time due to technology, innovation (new products, services, processes, expanding markets, diversification of markets, niche markets, increases revenue functions) such as, that which produces intellectual property and changes in industrial relations (most notably child labor being replaced in some parts of the world with universal access to education). 
",4
3891,"A market-based economy is one where goods and services are produced and exchanged according to demand and supply between participants (economic agents) by barter or a medium of exchange with a credit or debit value accepted within the network, such as a unit of currency. A command-based economy is one where political agents directly control what is produced and how it is sold and distributed. A green economy is low-carbon, resource efficient and socially inclusive. In a green economy, growth in income and employment is driven by public and private investments that reduce carbon emissions and pollution, enhance energy and resource efficiency, and prevent the loss of biodiversity and ecosystem services.[2] A gig economy is one in which short-term jobs are assigned or chosen via online platforms.[3] New economy is a term that referred to the whole emerging ecosystem where new standards and practices were introduced, usually as a result of technological innovations. The global economy refers to humanity's economic system or systems overall.
",4
3892,"Today the range of fields of study examining the economy revolves around the social science of economics, but may include sociology (economic sociology), history (economic history), anthropology (economic anthropology), and geography (economic geography). Practical fields directly related to the human activities involving production, distribution, exchange, and consumption of goods and services as a whole are engineering, management, business administration, applied science, and finance.
",4
3893,"All professions, occupations, economic agents or economic activities, contribute to the economy. Consumption, saving, and investment are variable components in the economy that determine macroeconomic equilibrium. There are three main sectors of economic activity: primary, secondary, and tertiary.
",4
3894,"Due to the growing importance of the financial sector in modern times,[4] the term real economy is used by analysts[5][6] as well as politicians[7] to denote the part of the economy that is concerned with the actual production of goods and services,[8] as ostensibly  contrasted with the paper economy, or the financial side of the economy,[9] which is concerned with buying and selling on the financial markets. Alternate and long-standing terminology distinguishes measures of an economy expressed in real values (adjusted for inflation), such as real GDP, or in nominal values (unadjusted for inflation).[10]
",4
3895,"The English words ""economy"" and ""economics"" can be traced back to the Greek word οἰκονόμος (i.e. ""household management""), a composite word derived from οἶκος (""house;household;home"") and νέμω (""manage; distribute;to deal out;dispense"") by way of οἰκονομία (""household management"").
",4
3896,"The first recorded sense of the word ""economy"" is in the phrase ""the management of œconomic affairs"", found in a work possibly composed in a monastery in 1440.[citation needed] ""Economy"" is later recorded in more general senses, including ""thrift"" and ""administration"".
",4
3897,"The most frequently used current sense, denoting ""the economic system of a country or an area"", seems not to have developed until the 1650s.[11]
",4
3898,"As long as someone has been making, supplying and distributing goods or services, there has been some sort of economy; economies grew larger as societies grew and became more complex. Sumer developed a large-scale economy based on commodity money, while the Babylonians and their neighboring city states later developed the earliest system of economics as we think of, in terms of rules/laws on debt, legal contracts and law codes relating to business practices, and private property.[12]
",4
3899,"The Babylonians and their city state neighbors developed forms of economics comparable to currently used civil society (law) concepts.[13] They developed the first known codified legal and administrative systems, complete with courts, jails, and government records.
",4
3900,"The ancient economy was mainly based on subsistence farming. The Shekel referred to an ancient unit of weight and currency. The first usage of the term came from Mesopotamia circa 3000 BC. and referred to a specific mass of barley which related other values in a metric such as silver, bronze, copper etc. A barley/shekel was originally both a unit of currency and a unit of weight, just as the British Pound was originally a unit denominating a one-pound mass of silver.
",4
3901,"For most people, the exchange of goods occurred through social relationships. There were also traders who bartered in the marketplaces. In Ancient Greece, where the present English word 'economy' originated, many people were bond slaves of the freeholders. The economic discussion was driven by scarcity.
",4
3902,"In Medieval times, what we now call economy was not far from the subsistence level. Most exchange occurred within social groups. On top of this, the great conquerors raised what we now call venture capital (from ventura, ital.; risk) to finance their captures. The capital should be refunded by the goods they would bring up in the New World. The discoveries of Marco Polo (1254–1324), Christopher Columbus (1451–1506) and Vasco da Gama (1469–1524) led to a first global economy. The first enterprises were trading establishments. In 1513, the first stock exchange was founded in Antwerpen. Economy at the time meant primarily trade.
",4
3903,"The European captures became branches of the European states, the so-called colonies. The rising nation-states Spain, Portugal, France, Great Britain and the Netherlands tried to control the trade through custom duties and (from mercator, lat.: merchant) was a first approach to intermediate between private wealth and public interest.
The secularization in Europe allowed states to use the immense property of the church for the development of towns. The influence of the nobles decreased. The first Secretaries of State for economy started their work. Bankers like Amschel Mayer Rothschild (1773–1855) started to finance national projects such as wars and infrastructure. Economy from then on meant national economy as a topic for the economic activities of the citizens of a state.
",4
3904,"The first economist in the true modern meaning of the word was the Scotsman Adam Smith (1723–1790) who was inspired partly by the ideas of  physiocracy,  a reaction to mercantilism and also later Economics student, Adam Mari.[15] He defined the elements of a national economy: products are offered at a natural price generated by the use of competition - supply and demand - and the division of labor. He maintained that the basic motive for free trade is human self-interest. The so-called self-interest hypothesis became the anthropological basis for economics. Thomas Malthus (1766–1834) transferred the idea of supply and demand to the problem of overpopulation.
",4
3905,"The Industrial Revolution was a period from the 18th to the 19th century where major changes in agriculture, manufacturing, mining, and transport had a profound effect on the socioeconomic and cultural conditions starting in the United Kingdom, then subsequently spreading throughout Europe, North America, and eventually the world. The onset of the Industrial Revolution marked a major turning point in human history; almost every aspect of daily life was eventually influenced in some way.
In Europe wild capitalism started to replace the system of mercantilism (today: protectionism) and led to economic growth. The period today is called industrial revolution because the system of Production, production and division of labor enabled the mass production of goods.
",4
3906,"The contemporary concept of ""the economy"" wasn't popularly known until the American Great Depression in the 1930s.[16]
",4
3907,"After the chaos of two World Wars and the devastating Great Depression, policymakers searched for new ways of controlling the course of the economy. This was explored and discussed by Friedrich August von Hayek (1899–1992) and Milton Friedman (1912–2006) who pleaded for a global free trade and are supposed to be the fathers of the so-called neoliberalism. However, the prevailing view was that held by John Maynard Keynes (1883–1946), who argued for a stronger control of the markets by the state. The theory that the state can alleviate economic problems and instigate economic growth through state manipulation of aggregate demand is called Keynesianism in his honor. In the late 1950s, the economic growth in America and Europe—often called Wirtschaftswunder (ger: economic miracle) —brought up a new form of economy: mass consumption economy. In 1958, John Kenneth Galbraith (1908–2006) was the first to speak of an affluent society. In most of the countries the economic system is called a social market economy.
",4
3908,"With the fall of the Iron Curtain and the transition of the countries of the Eastern Bloc towards democratic government and market economies, the idea of the post-industrial society is brought into importance as its role is to mark together the significance that the service sector receives instead of industrialization. Some attribute the first use of this term to Daniel Bell's 1973 book, The Coming of Post-Industrial Society, while others attribute it to social philosopher Ivan Illich's book, Tools for Conviviality. The term is also applied in philosophy to designate the fading of postmodernism in the late 90s and especially in the beginning of the 21st century.
",4
3909,"With the spread of Internet as a mass media and communication medium especially after 2000-2001, the idea for the Internet and information economy is given place because of the growing importance of e-commerce and electronic businesses, also the term for a global information society as understanding of a new type of ""all-connected"" society is created. In the late 2000s, the new type of economies and economic expansions of countries like China, Brazil, and India bring attention and interest to different from the usually dominating Western type economies and economic models.
",4
3910,"The economy may be considered as having developed through the following phases or degrees of precedence.[according to whom?]
",4
3911,"In modern economies, these phase precedences are somewhat differently expressed by the three-sector theory.[citation needed]
",4
3912,"Other sectors of the developed community include :
",4
3913,"The main indicators used to monitor the performance of an economy are:
",4
3914,"The GDP (gross domestic product) of a country is a measure of the size of its economy. The most conventional economic analysis of a country relies heavily on economic indicators like the GDP and GDP per capita. While often useful, GDP only includes economic activity for which money is exchanged.
",4
3915,"An informal economy is the set of economic activities operating as to partially avoid being taxed or regulated, in contrast to a formal economy. The informal economy is thus not included in that government's gross national product (GNP). Although the informal economy is often associated with developing countries, all economic systems contain an informal economy in some proportion.
",4
3916,"Informal economic activity is a dynamic process that includes many aspects of economic and social theory including exchange, regulation, and enforcement. By its nature, it is necessarily difficult to observe, study, define, and measure. No single source readily or authoritatively defines informal economy as a unit of study.
",4
3917,"The terms ""underground"", ""under the table"" and ""off the books"" typically refer to this type of economy. The term black market refers to a specific subset of the informal economy. The term ""informal sector"" was used in many earlier studies, and has been mostly replaced in more recent studies which use the newer term.
",4
3918,"The informal sector makes up a significant portion of the economies in developing countries but it is often stigmatized as troublesome and unmanageable. However, the informal sector provides critical economic opportunities for the poor and has been expanding rapidly since the 1960s. As such, integrating the informal economy into the formal sector is an important policy challenge.
",4
3919,"Economic research is conducted in fields as different as Agricultural, Development, Econometrics, Environmental, Game theory, Industrial Organization, International, Labor, Macroeconomics, Mathematical, Monetary, Public, Regional and Urban, Education, and Economics History.
",4
3920,"
",4
3921,"
",4
3922,"
",4
3923,"Adam Smith FRSA (c. 16 June [O.S. c. 5 June] 1723[1] – 17 July 1790) was a Scottish[a] economist, philosopher as well as a moral philosopher, a pioneer of political economy, and a key figure during the Scottish Enlightenment,[6] also known as ''The Father of Economics''[7] or ''The Father of Capitalism''.[8] Smith wrote two classic works, The Theory of Moral Sentiments (1759) and An Inquiry into the Nature and Causes of the Wealth of Nations (1776). The latter, often abbreviated as The Wealth of Nations, is considered his magnum opus and the first modern work of economics. In his work, Adam Smith introduced his theory of absolute advantage.[9]
",4
3924,"Smith studied social philosophy at the University of Glasgow and at Balliol College, Oxford, where he was one of the first students to benefit from scholarships set up by fellow Scot John Snell. After graduating, he delivered a successful series of public lectures at the University of Edinburgh,[10] leading him to collaborate with David Hume during the Scottish Enlightenment. Smith obtained a professorship at Glasgow, teaching moral philosophy and during this time, wrote and published The Theory of Moral Sentiments. In his later life, he took a tutoring position that allowed him to travel throughout Europe, where he met other intellectual leaders of his day.
",4
3925,"Smith laid the foundations of classical free market economic theory. The Wealth of Nations was a precursor to the modern academic discipline of economics. In this and other works, he developed the concept of division of labour and expounded upon how rational self-interest and competition can lead to economic prosperity. Smith was controversial in his own day and his general approach and writing style were often satirised by writers such as Horace Walpole.[11]
",4
3926,"Smith was born in Kirkcaldy, in Fife, Scotland. His father, also Adam Smith, was a Scottish Writer to the Signet (senior solicitor), advocate and prosecutor (judge advocate) and also served as comptroller of the customs in Kirkcaldy.[12] Smith's mother was born Margaret Douglas, daughter of the landed Robert Douglas of Strathendry, also in Fife; she married Smith's father in 1720. Two months before Smith was born, his father died, leaving his mother a widow.[13] The date of Smith's baptism into the Church of Scotland at Kirkcaldy was 5 June 1723[14] and this has often been treated as if it were also his date of birth,[12] which is unknown.
",4
3927,"Although few events in Smith's early childhood are known, the Scottish journalist John Rae, Smith's biographer, recorded that Smith was abducted by Romani at the age of three and released when others went to rescue him.[b][16] Smith was close to his mother, who probably encouraged him to pursue his scholarly ambitions.[17] He attended the Burgh School of Kirkcaldy—characterised by Rae as ""one of the best secondary schools of Scotland at that period""[15]—from 1729 to 1737, he learned Latin, mathematics, history, and writing.[17]
",4
3928,"Smith entered the University of Glasgow when he was 14 and studied moral philosophy under Francis Hutcheson.[17] Here, he developed his passion for liberty, reason, and free speech. In 1740, he was the graduate scholar presented to undertake postgraduate studies at Balliol College, Oxford, under the Snell Exhibition.[18]
",4
3929,"Smith considered the teaching at Glasgow to be far superior to that at Oxford, which he found intellectually stifling.[19] In Book V, Chapter II of The Wealth of Nations, he wrote: ""In the University of Oxford, the greater part of the public professors have, for these many years, given up altogether even the pretence of teaching.""
Smith is also reported to have complained to friends that Oxford officials once discovered him reading a copy of David Hume's A Treatise of Human Nature, and they subsequently confiscated his book and punished him severely for reading it.[15][20][21] According to William Robert Scott, ""The Oxford of [Smith's] time gave little if any help towards what was to be his lifework.""[22] Nevertheless, he took the opportunity while at Oxford to teach himself several subjects by reading many books from the shelves of the large Bodleian Library.[23] When Smith was not studying on his own, his time at Oxford was not a happy one, according to his letters.[24] Near the end of his time there, he began suffering from shaking fits, probably the symptoms of a nervous breakdown.[25] He left Oxford University in 1746, before his scholarship ended.[25][26]
",4
3930,"In Book V of The Wealth of Nations, Smith comments on the low quality of instruction and the meager intellectual activity at English universities, when compared to their Scottish counterparts. He attributes this both to the rich endowments of the colleges at Oxford and Cambridge, which made the income of professors independent of their ability to attract students, and to the fact that distinguished men of letters could make an even more comfortable living as ministers of the Church of England.[21]
",4
3931,"Smith's discontent at Oxford might be in part due to the absence of his beloved teacher in Glasgow, Francis Hutcheson, who was well regarded as one of the most prominent lecturers at the University of Glasgow in his day and earned the approbation of students, colleagues, and even ordinary residents with the fervor and earnestness of his orations (which he sometimes opened to the public). His lectures endeavoured not merely to teach philosophy, but also to make his students embody that philosophy in their lives, appropriately acquiring the epithet, the preacher of philosophy. Unlike Smith, Hutcheson was not a system builder; rather, his magnetic personality and method of lecturing so influenced his students and caused the greatest of those to reverentially refer to him as ""the never to be forgotten Hutcheson""—a title that Smith in all his correspondence used to describe only two people, his good friend David Hume and influential mentor Francis Hutcheson.[27]
",4
3932,"Smith began delivering public lectures in 1748 at the University of Edinburgh,[28] sponsored by the Philosophical Society of Edinburgh under the patronage of Lord Kames.[29] His lecture topics included rhetoric and belles-lettres,[30] and later the subject of ""the progress of opulence"". On this latter topic, he first expounded his economic philosophy of ""the obvious and simple system of natural liberty"". While Smith was not adept at public speaking, his lectures met with success.[31]
",4
3933,"In 1750, Smith met the philosopher David Hume, who was his senior by more than a decade. In their writings covering history, politics, philosophy, economics, and religion, Smith and Hume shared closer intellectual and personal bonds than with other important figures of the Scottish Enlightenment.[32]
",4
3934,"In 1751, Smith earned a professorship at Glasgow University teaching logic courses, and in 1752, he was elected a member of the Philosophical Society of Edinburgh, having been introduced to the society by Lord Kames. When the head of Moral Philosophy in Glasgow died the next year, Smith took over the position.[31] He worked as an academic for the next 13 years, which he characterised as ""by far the most useful and therefore by far the happiest and most honorable period [of his life]"".[33]
",4
3935,"Smith published The Theory of Moral Sentiments in 1759, embodying some of his Glasgow lectures. This work was concerned with how human morality depends on sympathy between agent and spectator, or the individual and other members of society. Smith defined ""mutual sympathy"" as the basis of moral sentiments. He based his explanation, not on a special ""moral sense"" as the Third Lord Shaftesbury and Hutcheson had done, nor on utility as Hume did, but on mutual sympathy, a term best captured in modern parlance by the 20th-century concept of empathy, the capacity to recognise feelings that are being experienced by another being.
",4
3936,"Following the publication of The Theory of Moral Sentiments, Smith became so popular that many wealthy students left their schools in other countries to enroll at Glasgow to learn under Smith.[34] After the publication of The Theory of Moral Sentiments, Smith began to give more attention to jurisprudence and economics in his lectures and less to his theories of morals.[35] For example, Smith lectured that the cause of increase in national wealth is labour, rather than the nation's quantity of gold or silver, which is the basis for mercantilism, the economic theory that dominated Western European economic policies at the time.[36]
",4
3937,"In 1762, the University of Glasgow conferred on Smith the title of Doctor of Laws (LL.D.).[37] At the end of 1763, he obtained an offer from Charles Townshend—who had been introduced to Smith by David Hume—to tutor his stepson, Henry Scott, the young Duke of Buccleuch. Smith resigned from his professorship in 1764 to take the tutoring position. He subsequently attempted to return the fees he had collected from his students because he had resigned partway through the term, but his students refused.[38]
",4
3938,"Smith's tutoring job entailed touring Europe with Scott, during which time he educated Scott on a variety of subjects, such as etiquette and manners. He was paid £300 per year (plus expenses) along with a £300 per year pension; roughly twice his former income as a teacher.[38] Smith first travelled as a tutor to Toulouse, France, where he stayed for a year and a half. According to his own account, he found Toulouse to be somewhat boring, having written to Hume that he ""had begun to write a book to pass away the time"".[38] After touring the south of France, the group moved to Geneva, where Smith met with the philosopher Voltaire.[39]
",4
3939,"From Geneva, the party moved to Paris. Here, Smith met Benjamin Franklin, and discovered the Physiocracy school founded by François Quesnay.[40] Physiocrats were opposed to mercantilism, the dominating economic theory of the time, illustrated in their motto Laissez faire et laissez passer, le monde va de lui même! (Let do and let pass, the world goes on by itself!).
",4
3940,"The wealth of France had been virtually depleted by Louis XIV[c] and Louis XV in ruinous wars,[d] and was further exhausted in aiding the American insurgents against the British. The excessive consumption of goods and services deemed to have no economic contribution was considered a source of unproductive labour, with France's agriculture the only economic sector maintaining the wealth of the nation.[citation needed] Given that the English economy of the day yielded an income distribution that stood in contrast to that which existed in France, Smith concluded that ""with all its imperfections, [the Physiocratic school] is perhaps the nearest approximation to the truth that has yet been published upon the subject of political economy.""[41] The distinction between productive versus unproductive labour—the physiocratic classe steril—was a predominant issue in the development and understanding of what would become classical economic theory.
",4
3941,"In 1766, Henry Scott's younger brother died in Paris, and Smith's tour as a tutor ended shortly thereafter.[42] Smith returned home that year to Kirkcaldy, and he devoted much of the next decade to writing his magnum opus.[43] There, he befriended Henry Moyes, a young blind man who showed precocious aptitude.  Smith secured the patronage of David Hume and Thomas Reid in the young man's education.[44] In May 1773, Smith was elected fellow of the Royal Society of London,[45] and was elected a member of the Literary Club in 1775. The Wealth of Nations was published in 1776 and was an instant success, selling out its first edition in only six months.[46]
",4
3942,"In 1778, Smith was appointed to a post as commissioner of customs in Scotland and went to live with his mother (who died in 1784)[47] in Panmure House in Edinburgh's Canongate.[48] Five years later, as a member of the Philosophical Society of Edinburgh when it received its royal charter, he automatically became one of the founding members of the Royal Society of Edinburgh.[49] From 1787 to 1789, he occupied the honorary position of Lord Rector of the University of Glasgow.[50]
",4
3943,"Smith died in the northern wing of Panmure House in Edinburgh on 17 July 1790 after a painful illness. His body was buried in the Canongate Kirkyard.[51] On his deathbed, Smith expressed disappointment that he had not achieved more.[52]
",4
3944,"Smith's literary executors were two friends from the Scottish academic world: the physicist and chemist Joseph Black and the pioneering geologist James Hutton.[53] Smith left behind many notes and some unpublished material, but gave instructions to destroy anything that was not fit for publication.[54] He mentioned an early unpublished History of Astronomy as probably suitable, and it duly appeared in 1795, along with other material such as Essays on Philosophical Subjects.[53]
",4
3945,"Smith's library went by his will to David Douglas, Lord Reston (son of his cousin Colonel Robert Douglas of Strathendry, Fife), who lived with Smith.[55] It was eventually divided between his two surviving children, Cecilia Margaret (Mrs. Cunningham) and David Anne (Mrs. Bannerman). On the death in 1878 of her husband, the Reverend W. B. Cunningham of Prestonpans, Mrs. Cunningham sold some of the books. The remainder passed to her son, Professor Robert Oliver Cunningham of Queen's College, Belfast, who presented a part to the library of Queen's College. After his death, the remaining books were sold. On the death of Mrs. Bannerman in 1879, her portion of the library went intact to the New College (of the Free Church) in Edinburgh and the collection was transferred to the University of Edinburgh Main Library in 1972.
",4
3946,"Not much is known about Smith's personal views beyond what can be deduced from his published articles. His personal papers were destroyed after his death at his request.[54] He never married,[57] and seems to have maintained a close relationship with his mother, with whom he lived after his return from France and who died six years before him.[58]
",4
3947,"Smith was described by several of his contemporaries and biographers as comically absent-minded, with peculiar habits of speech and gait, and a smile of ""inexpressible benignity"".[59] He was known to talk to himself,[52] a habit that began during his childhood when he would smile in rapt conversation with invisible companions.[60] He also had occasional spells of imaginary illness,[52] and he is reported to have had books and papers placed in tall stacks in his study.[60] According to one story, Smith took Charles Townshend on a tour of a tanning factory, and while discussing free trade, Smith walked into a huge tanning pit from which he needed help to escape.[61] He is also said to have put bread and butter into a teapot, drunk the concoction, and declared it to be the worst cup of tea he ever had. According to another account, Smith distractedly went out walking in his nightgown and ended up 15 miles (24 km) outside of town, before nearby church bells brought him back to reality.[60][61]
",4
3948,"James Boswell, who was a student of Smith's at Glasgow University, and later knew him at the Literary Club, says that Smith thought that speaking about his ideas in conversation might reduce the sale of his books, so his conversation was unimpressive. According to Boswell, he once told Sir Joshua Reynolds, that ""he made it a rule when in company never to talk of what he understood"".[62]
",4
3949,"Smith has been alternatively described as someone who ""had a large nose, bulging eyes, a protruding lower lip, a nervous twitch, and a speech impediment"" and one whose ""countenance was manly and agreeable"".[21][63] Smith is said to have acknowledged his looks at one point, saying, ""I am a beau in nothing but my books.""[21] Smith rarely sat for portraits,[64] so almost all depictions of him created during his lifetime were drawn from memory. The best-known portraits of Smith are the profile by James Tassie and two etchings by John Kay.[65] The line engravings produced for the covers of 19th-century reprints of The Wealth of Nations were based largely on Tassie's medallion.[66]
",4
3950,"Considerable scholarly debate has occurred about the nature of Smith's religious views. Smith's father had shown a strong interest in Christianity and belonged to the moderate wing of the Church of Scotland.[67] The fact that Adam Smith received the Snell Exhibition suggests that he may have gone to Oxford with the intention of pursuing a career in the Church of England.[68]
",4
3951,"Anglo-American economist Ronald Coase has challenged the view that Smith was a deist, based on the fact that Smith's writings never explicitly invoke God as an explanation of the harmonies of the natural or the human worlds.[69] According to Coase, though Smith does sometimes refer to the ""Great Architect of the Universe"", later scholars such as Jacob Viner have ""very much exaggerated the extent to which Adam Smith was committed to a belief in a personal God"",[70] a belief for which Coase finds little evidence in passages such as the one in the Wealth of Nations in which Smith writes that the curiosity of mankind about the ""great phenomena of nature"", such as ""the generation, the life, growth, and dissolution of plants and animals"", has led men to ""enquire into their causes"", and that ""superstition first attempted to satisfy this curiosity, by referring all those wonderful appearances to the immediate agency of the gods. Philosophy afterwards endeavoured to account for them, from more familiar causes, or from such as mankind were better acquainted with than the agency of the gods"".[70]
",4
3952,"Some other authors argue that Smith's social and economic philosophy is inherently theological and that his entire model of social order is logically dependent on the notion of God's action in nature.[71]
",4
3953,"Smith was also a close friend of David Hume, who was commonly characterised in his own time as an atheist.[72] The publication in 1777 of Smith's letter to William Strahan, in which he described Hume's courage in the face of death in spite of his irreligiosity, attracted considerable controversy.[73]
",4
3954,"In 1759, Smith published his first work, The Theory of Moral Sentiments, sold by co-publishers Andrew Millar of London and Alexander Kincaid of Edinburgh.[74] Smith continued making extensive revisions to the book until his death.[e] Although The Wealth of Nations is widely regarded as Smith's most influential work, Smith himself is believed to have considered The Theory of Moral Sentiments to be a superior work.[76]
",4
3955,"In the work, Smith critically examines the moral thinking of his time, and suggests that conscience arises from dynamic and interactive social relationships through which people seek ""mutual sympathy of sentiments.""[77] His goal in writing the work was to explain the source of mankind's ability to form moral judgment, given that people begin life with no moral sentiments at all. Smith proposes a theory of sympathy, in which the act of observing others and seeing the judgments they form of both others and oneself makes people aware of themselves and how others perceive their behaviour. The feedback we receive from perceiving (or imagining) others' judgment creates an incentive to achieve ""mutual sympathy of sentiments"" with them and leads people to develop habits, and then principles, of behaviour, which come to constitute one's conscience.[78]
",4
3956,"Some scholars have perceived a conflict between The Theory of Moral Sentiments and The Wealth of Nations; the former emphasises sympathy for others, while the latter focuses on the role of self-interest.[79] In recent years, however, some scholars[80][81][82] of Smith's work have argued that no contradiction exists. They claim that in The Theory of Moral Sentiments, Smith develops a theory of psychology in which individuals seek the approval of the ""impartial spectator"" as a result of a natural desire to have outside observers sympathise with their sentiments. Rather than viewing The Theory of Moral Sentiments and The Wealth of Nations as presenting incompatible views of human nature, some Smith scholars regard the works as emphasising different aspects of human nature that vary depending on the situation. Otteson argues that both books are Newtonian in their methodology and deploy a similar ""market model"" for explaining the creation and development of large-scale human social orders, including morality, economics, as well as language.[83] Ekelund and Hebert offer a differing view, observing that self-interest is present in both works and that ""in the former, sympathy is the moral faculty that holds self-interest in check, whereas in the latter, competition is the economic faculty that restrains self-interest.""[84]
",4
3957,"Disagreement exists between classical and neoclassical economists about the central message of Smith's most influential work: An Inquiry into the Nature and Causes of the Wealth of Nations (1776). Neoclassical economists emphasise Smith's invisible hand,[85] a concept mentioned in the middle of his work – Book IV, Chapter II – and classical economists believe that Smith stated his programme for promoting the ""wealth of nations"" in the first sentences, which attributes the growth of wealth and prosperity to the division of labour.
",4
3958,"Smith used the term ""the invisible hand"" in ""History of Astronomy""[86] referring to ""the invisible hand of Jupiter"", and once in each of his The Theory of Moral Sentiments[87] (1759) and The Wealth of Nations[88] (1776). This last statement about ""an invisible hand"" has been interpreted in numerous ways.
",4
3959,"As every individual, therefore, endeavours as much as he can both to employ his capital in the support of domestic industry, and so to direct that industry that its produce may be of the greatest value; every individual necessarily labours to render the annual revenue of the society as great as he can. He generally, indeed, neither intends to promote the public interest, nor knows how much he is promoting it. By preferring the support of domestic to that of foreign industry, he intends only his own security; and by directing that industry in such a manner as its produce may be of the greatest value, he intends only his own gain, and he is in this, as in many other cases, led by an invisible hand to promote an end which was no part of his intention. Nor is it always the worse for the society that it was no part of it. By pursuing his own interest he frequently promotes that of the society more effectually than when he really intends to promote it. I have never known much good done by those who affected to trade for the public good. It is an affectation, indeed, not very common among merchants, and very few words need be employed in dissuading them from it.",4
3960,"Those who regard that statement as Smith's central message also quote frequently Smith's dictum:[89]
",4
3961,"It is not from the benevolence of the butcher, the brewer, or the baker, that we expect our dinner, but from their regard to their own interest. We address ourselves, not to their humanity but to their self-love, and never talk to them of our own necessities but of their advantages.",4
3962,"However, in The Theory of Moral Sentiments he had a more sceptical approach to self-interest as driver of behaviour:",4
3963,"How selfish soever man may be supposed, there are evidently some principles in his nature, which interest him in the fortune of others, and render their happiness necessary to him, though he derives nothing from it except the pleasure of seeing it.",4
3964,"Smith's statement about the benefits of ""an invisible hand"" may be meant to answer[citation needed] Mandeville's contention that ""Private Vices ... may be turned into Public Benefits"".[90] It shows Smith's belief that when an individual pursues his self-interest under conditions of justice, he unintentionally promotes the good of society. Self-interested competition in the free market, he argued, would tend to benefit society as a whole by keeping prices low, while still building in an incentive for a wide variety of goods and services. Nevertheless, he was wary of businessmen and warned of their ""conspiracy against the public or in some other contrivance to raise prices"".[91] Again and again, Smith warned of the collusive nature of business interests, which may form cabals or monopolies, fixing the highest price ""which can be squeezed out of the buyers"".[92] Smith also warned that a business-dominated political system would allow a conspiracy of businesses and industry against consumers, with the former scheming to influence politics and legislation. Smith states that the interest of manufacturers and merchants ""in any particular branch of trade or manufactures, is always in some respects different from, and even opposite to, that of the public ... The proposal of any new law or regulation of commerce which comes from this order, ought always to be listened to with great precaution, and ought never be adopted till after having been long and carefully examined, not only with the most scrupulous, but with the most suspicious attention.""[93] Thus Smith's chief worry seems to be when business is given special protections or privileges from government; by contrast, in the absence of such special political favours, he believed that business activities were generally beneficial to the whole society:
",4
3965,"It is the great multiplication of the production of all the different arts, in consequence of the division of labour, which occasions, in a well-governed society, that universal opulence which extends itself to the lowest ranks of the people. Every workman has a great quantity of his own work to dispose of beyond what he himself has occasion for; and every other workman being exactly in the same situation, he is enabled to exchange a great quantity of his own goods for a great quantity, or, what comes to the same thing, for the price of a great quantity of theirs. He supplies them abundantly with what they have occasion for, and they accommodate him as amply with what he has occasion for, and a general plenty diffuses itself through all the different ranks of society. (The Wealth of Nations, I.i.10)",4
3966,"The neoclassical interest in Smith's statement about ""an invisible hand"" originates in the possibility of seeing it as a precursor of neoclassical economics and its concept of general equilibrium – Samuelson's ""Economics"" refers six times to Smith's ""invisible hand"". To emphasise this connection, Samuelson[94] quotes Smith's ""invisible hand"" statement substituting ""general interest"" for ""public interest"". Samuelson[95] concludes: ""Smith was unable to prove the essence of his invisible-hand doctrine. Indeed, until the 1940s, no one knew how to prove, even to state properly, the kernel of truth in this proposition about perfectly competitive market.""
",4
3967,"Very differently, classical economists see in Smith's first sentences his programme to promote ""The Wealth of Nations"". Using the physiocratical concept of the economy as a circular process, to secure growth the inputs of Period 2 must exceed the inputs of Period 1. Therefore, those outputs of Period 1 which are not used or usable as inputs of Period 2 are regarded as unproductive labour, as they do not contribute to growth. This is what Smith had heard in France from, among others, François Quesnay, whose ideas Smith was so impressed by that he might have dedicated The Wealth of Nations to him had he not died beforehand.[96][97] To this French insight that unproductive labour should be reduced to use labour more productively, Smith added his own proposal, that productive labour should be made even more productive by deepening the division of labour. Smith argued that deepening the division of labour under competition leads to greater productivity, which leads to lower prices and thus an increasing standard of living—""general plenty"" and ""universal opulence""—for all. Extended markets and increased production lead to the continuous reorganisation of production and the invention of new ways of producing, which in turn lead to further increased production, lower prices, and improved standards of living. Smith's central message is, therefore, that under dynamic competition, a growth machine secures ""The Wealth of Nations"". Smith's argument predicted Britain's evolution as the workshop of the world, underselling and outproducing all its competitors. The opening sentences of the ""Wealth of Nations"" summarise this policy:
",4
3968,"The annual labour of every nation is the fund which originally supplies it with all the necessaries and conveniences of life which it annually consumes ... . [T]his produce ... bears a greater or smaller proportion to the number of those who are to consume it ... .[B]ut this proportion must in every nation be regulated by two different circumstances;
",4
3969,"However, Smith added that the ""abundance or scantiness of this supply too seems to depend more upon the former of those two circumstances than upon the latter.""[99]
",4
3970,"Shortly before his death, Smith had nearly all his manuscripts destroyed. In his last years, he seemed to have been planning two major treatises, one on the theory and history of law and one on the sciences and arts. The posthumously published Essays on Philosophical Subjects, a history of astronomy down to Smith's own era, plus some thoughts on ancient physics and metaphysics, probably contain parts of what would have been the latter treatise. Lectures on Jurisprudence were notes taken from Smith's early lectures, plus an early draft of The Wealth of Nations, published as part of the 1976 Glasgow Edition of the works and correspondence of Smith. Other works, including some published posthumously, include Lectures on Justice, Police, Revenue, and Arms (1763) (first published in 1896); and Essays on Philosophical Subjects (1795).[100]
",4
3971,"The Wealth of Nations was a precursor to the modern academic discipline of economics. In this and other works, Smith expounded how rational self-interest and competition can lead to economic prosperity. Smith was controversial in his own day and his general approach and writing style were often satirised by Tory writers in the moralising tradition of Hogarth and Swift, as a discussion at the University of Winchester suggests.[101] In 2005, The Wealth of Nations was named among the 100 Best Scottish Books of all time.[102]
",4
3972,"In light of the arguments put forward by Smith and other economic theorists in Britain, academic belief in mercantilism began to decline in Britain in the late 18th century. During the Industrial Revolution, Britain embraced free trade and Smith's laissez-faire economics, and via the British Empire, used its power to spread a broadly liberal economic model around the world, characterised by open markets, and relatively barrier-free domestic and international trade.[103]
",4
3973,"George Stigler attributes to Smith ""the most important substantive proposition in all of economics"". It is that, under competition, owners of resources (for example labour, land, and capital) will use them most profitably, resulting in an equal rate of return in equilibrium for all uses, adjusted for apparent differences arising from such factors as training, trust, hardship, and unemployment.[104]
",4
3974,"Paul Samuelson finds in Smith's pluralist use of supply and demand as applied to wages, rents, and profit a valid and valuable anticipation of the general equilibrium modelling of Walras a century later. Smith's allowance for wage increases in the short and intermediate term from capital accumulation and invention contrasted with Malthus, Ricardo, and Karl Marx in their propounding a rigid subsistence–wage theory of labour supply.[105]
",4
3975,"Joseph Schumpeter criticised Smith for a lack of technical rigour, yet he argued that this enabled Smith's writings to appeal to wider audiences: ""His very limitation made for success. Had he been more brilliant, he would not have been taken so seriously. Had he dug more deeply, had he unearthed more recondite truth, had he used more difficult and ingenious methods, he would not have been understood. But he had no such ambitions; in fact he disliked whatever went beyond plain common sense. He never moved above the heads of even the dullest readers. He led them on gently, encouraging them by trivialities and homely observations, making them feel comfortable all along.""[106]
",4
3976,"Classical economists presented competing theories of those of Smith, termed the ""labour theory of value"". Later Marxian economics descending from classical economics also use Smith's labour theories, in part. The first volume of Karl Marx's major work, Das Kapital, was published in German in 1867. In it, Marx focused on the labour theory of value and what he considered to be the exploitation of labour by capital.[107][108] The labour theory of value held that the value of a thing was determined by the labour that went into its production. This contrasts with the modern contention of neoclassical economics, that the value of a thing is determined by what one is willing to give up to obtain the thing.
",4
3977,"The body of theory later termed ""neoclassical economics"" or ""marginalism"" formed from about 1870 to 1910. The term ""economics"" was popularised by such neoclassical economists as Alfred Marshall as a concise synonym for ""economic science"" and a substitute for the earlier, broader term ""political economy"" used by Smith.[109][110] This corresponded to the influence on the subject of mathematical methods used in the natural sciences.[111] Neoclassical economics systematised supply and demand as joint determinants of price and quantity in market equilibrium, affecting both the allocation of output and the distribution of income. It dispensed with the labour theory of value of which Smith was most famously identified with in classical economics, in favour of a marginal utility theory of value on the demand side and a more general theory of costs on the supply side.[112]
",4
3978,"The bicentennial anniversary of the publication of The Wealth of Nations was celebrated in 1976, resulting in increased interest for The Theory of Moral Sentiments and his other works throughout academia. After 1976, Smith was more likely to be represented as the author of both The Wealth of Nations and The Theory of Moral Sentiments, and thereby as the founder of a moral philosophy and the science of economics. His homo economicus or ""economic man"" was also more often represented as a moral person. Additionally, economists David Levy and Sandra Peart in ""The Secret History of the Dismal Science"" point to his opposition to hierarchy and beliefs in inequality, including racial inequality, and provide additional support for those who point to Smith's opposition to slavery, colonialism, and empire. They show the caricatures of Smith drawn by the opponents of views on hierarchy and inequality in this online article. Emphasised also are Smith's statements of the need for high wages for the poor, and the efforts to keep wages low. In The ""Vanity of the Philosopher: From Equality to Hierarchy in Postclassical Economics"", Peart and Levy also cite Smith's view that a common street porter was not intellectually inferior to a philosopher,[113] and point to the need for greater appreciation of the public views in discussions of science and other subjects now considered to be technical. They also cite Smith's opposition to the often expressed view that science is superior to common sense.[114]
",4
3979,"Smith also explained the relationship between growth of private property and civil government:
",4
3980,"Men may live together in society with some tolerable degree of security, though there is no civil magistrate to protect them from the injustice of those passions. But avarice and ambition in the rich, in the poor the hatred of labour and the love of present ease and enjoyment, are the passions which prompt to invade property, passions much more steady in their operation, and much more universal in their influence. Wherever there is great property there is great inequality. For one very rich man there must be at least five hundred poor, and the affluence of the few supposes the indigence of the many. The affluence of the rich excites the indignation of the poor, who are often both driven by want, and prompted by envy, to invade his possessions. It is only under the shelter of the civil magistrate that the owner of that valuable property, which is acquired by the labour of many years, or perhaps of many successive generations, can sleep a single night in security. He is at all times surrounded by unknown enemies, whom, though he never provoked, he can never appease, and from whose injustice he can be protected only by the powerful arm of the civil magistrate continually held up to chastise it. The acquisition of valuable and extensive property, therefore, necessarily requires the establishment of civil government. Where there is no property, or at least none that exceeds the value of two or three days' labour, civil government is not so necessary. Civil government supposes a certain subordination. But as the necessity of civil government gradually grows up with the acquisition of valuable property, so the principal causes which naturally introduce subordination gradually grow up with the growth of that valuable property. (...) Men of inferior wealth combine to defend those of superior wealth in the possession of their property, in order that men of superior wealth may combine to defend them in the possession of theirs. All the inferior shepherds and herdsmen feel that the security of their own herds and flocks depends upon the security of those of the great shepherd or herdsman; that the maintenance of their lesser authority depends upon that of his greater authority, and that upon their subordination to him depends his power of keeping their inferiors in subordination to them. They constitute a sort of little nobility, who feel themselves interested to defend the property and to support the authority of their own little sovereign in order that he may be able to defend their property and to support their authority. Civil government, so far as it is instituted for the security of property, is in reality instituted for the defence of the rich against the poor, or of those who have some property against those who have none at all. (Source: The Wealth of Nations, Book 5, Chapter 1, Part 2)",4
3981,"Smith's chapter on colonies, in turn, would help shape British imperial debates from the mid-19th century onward. The Wealth of Nations would become an ambiguous text regarding the imperial question. In his chapter on colonies, Smith pondered how to solve the crisis developing across the Atlantic among the empire's 13 American colonies. He offered two different proposals for easing tensions. The first proposal called for giving the colonies their independence, and by thus parting on a friendly basis, Britain would be able to develop and maintain a free-trade relationship with them, and possibly even an informal military alliance. Smith's second proposal called for a theoretical imperial federation that would bring the colonies and the metropole closer together through an imperial parliamentary system and imperial free trade.[115]
",4
3982,"Smith's most prominent disciple in 19th-century Britain, peace advocate Richard Cobden, preferred the first proposal. Cobden would lead the Anti-Corn Law League in overturning the Corn Laws in 1846, shifting Britain to a policy of free trade and empire ""on the cheap"" for decades to come. This hands-off approach toward the British Empire would become known as Cobdenism or the Manchester School.[116] By the turn of the century, however, advocates of Smith's second proposal such as Joseph Shield Nicholson would become ever more vocal in opposing Cobdenism, calling instead for imperial federation.[117] As Marc-William Palen notes: ""On the one hand, Adam Smith’s late nineteenth and early twentieth-century Cobdenite adherents used his theories to argue for gradual imperial devolution and empire 'on the cheap'. On the other, various proponents of imperial federation throughout the British World sought to use Smith's theories to overturn the predominant Cobdenite hands-off imperial approach and instead, with a firm grip, bring the empire closer than ever before.""[118] Smith's ideas thus played an important part in subsequent debates over the British Empire.
",4
3983,"Smith has been commemorated in the UK on banknotes printed by two different banks; his portrait has appeared since 1981 on the £50 notes issued by the Clydesdale Bank in Scotland,[119][120] and in March 2007 Smith's image also appeared on the new series of £20 notes issued by the Bank of England, making him the first Scotsman to feature on an English banknote.[121]
",4
3984,"A large-scale memorial of Smith by Alexander Stoddart was unveiled on 4 July 2008 in Edinburgh. It is a 10-foot (3.0 m)-tall bronze sculpture and it stands above the Royal Mile outside St Giles' Cathedral in Parliament Square, near the Mercat cross.[122] 20th-century sculptor Jim Sanborn (best known for the Kryptos sculpture at the United States Central Intelligence Agency) has created multiple pieces which feature Smith's work. At Central Connecticut State University is Circulating Capital, a tall cylinder which features an extract from The Wealth of Nations on the lower half, and on the upper half, some of the same text, but represented in binary code.[123] At the University of North Carolina at Charlotte, outside the Belk College of Business Administration, is Adam Smith's Spinning Top.[124][125] Another Smith sculpture is at Cleveland State University.[126] He also appears as the narrator in the 2013 play The Low Road, centred on a proponent on laissez-faire economics in the late 18th century, but dealing obliquely with the financial crisis of 2007–2008 and the recession which followed; in the premiere production, he was portrayed by Bill Paterson.
",4
3985,"A bust of Smith is in the Hall of Heroes of the National Wallace Monument in Stirling.
",4
3986,"Adam Smith resided at Panmure House from 1778 to 1790. This residence has now been purchased by the Edinburgh Business School at Heriot-Watt University and fundraising has begun to restore it.[127][128] Part of the Northern end of the original building appears to have been demolished in the 19th century to make way for an iron foundry.
",4
3987,"Smith has been celebrated by advocates of free-market policies as the founder of free-market economics, a view reflected in the naming of bodies such as the Adam Smith Institute in London, multiple entities known as the ""Adam Smith Society"", including an historical Italian organization,[129] and the U.S.-based Adam Smith Society,[130][131] and the Australian Adam Smith Club,[132] and in terms such as the Adam Smith necktie.[133]
",4
3988,"Alan Greenspan argues that, while Smith did not coin the term laissez-faire, ""it was left to Adam Smith to identify the more-general set of principles that brought conceptual clarity to the seeming chaos of market transactions"". Greenspan continues that The Wealth of Nations was ""one of the great achievements in human intellectual history"".[134] P.J. O'Rourke describes Smith as the ""founder of free market economics"".[135]
",4
3989,"Other writers have argued that Smith's support for laissez-faire (which in French means leave alone) has been overstated. Herbert Stein wrote that the people who ""wear an Adam Smith necktie"" do it to ""make a statement of their devotion to the idea of free markets and limited government"", and that this misrepresents Smith's ideas. Stein writes that Smith ""was not pure or doctrinaire about this idea. He viewed government intervention in the market with great skepticism...yet he was prepared to accept or propose qualifications to that policy in the specific cases where he judged that their net effect would be beneficial and would not undermine the basically free character of the system. He did not wear the Adam Smith necktie."" In Stein's reading, The Wealth of Nations could justify the Food and Drug Administration, the Consumer Product Safety Commission, mandatory employer health benefits, environmentalism, and ""discriminatory taxation to deter improper or luxurious behavior"".[136]
",4
3990,"Similarly, Vivienne Brown stated in The Economic Journal that in the 20th-century United States, Reaganomics supporters, The Wall Street Journal, and other similar sources have spread among the general public a partial and misleading vision of Smith, portraying him as an ""extreme dogmatic defender of laissez-faire capitalism and supply-side economics"".[137] In fact, The Wealth of Nations includes the following statement on the payment of taxes:
",4
3991,"The subjects of every state ought to contribute towards the support of the government, as nearly as possible, in proportion to their respective abilities; that is, in proportion to the revenue which they respectively enjoy under the protection of the state.[138]",4
3992,"Some commentators have argued that Smith's works show support for a progressive, not flat, income tax and that he specifically named taxes that he thought should be required by the state, among them luxury-goods taxes and tax on rent.[139] Yet Smith argued for the ""impossibility of taxing the people, in proportion to their economic revenue, by any capitation"" (The Wealth of Nations, V.ii.k.1). Smith argued that taxes should principally go toward protecting ""justice"" and ""certain publick institutions"" that were necessary for the benefit of all of society, but that could not be provided by private enterprise (The Wealth of Nations, IV.ix.51).
",4
3993,"Additionally, Smith outlined the proper expenses of the government in The Wealth of Nations, Book V, Ch. I. Included in his requirements of a government is to enforce contracts and provide justice system, grant patents and copy rights, provide public goods such as infrastructure, provide national defence, and regulate banking. The role of the government was to provide goods ""of such a nature that the profit could never repay the expense to any individual"" such as roads, bridges, canals, and harbours. He also encouraged invention and new ideas through his patent enforcement and support of infant industry monopolies. He supported partial public subsidies for elementary education, and he believed that competition among religious institutions would provide general benefit to the society. In such cases, however, Smith argued for local rather than centralised control: ""Even those publick works which are of such a nature that they cannot afford any revenue for maintaining themselves ... are always better maintained by a local or provincial revenue, under the management of a local and provincial administration, than by the general revenue of the state"" (Wealth of Nations, V.i.d.18). Finally, he outlined how the government should support the dignity of the monarch or chief magistrate, such that they are equal or above the public in fashion. He even states that monarchs should be provided for in a greater fashion than magistrates of a republic because ""we naturally expect more splendor in the court of a king than in the mansion-house of a doge"".[140] In addition, he allowed that in some specific circumstances, retaliatory tariffs may be beneficial:
",4
3994,The recovery of a great foreign market will generally more than compensate the transitory inconvenience of paying dearer during a short time for some sorts of goods.[141],4
3995,"However, he added that in general, a retaliatory tariff ""seems a bad method of compensating the injury done to certain classes of our people, to do another injury ourselves, not only to those classes, but to almost all the other classes of them"" (The Wealth of Nations, IV.ii.39).
",4
3996,"Economic historians such as Jacob Viner regard Smith as a strong advocate of free markets and limited government (what Smith called ""natural liberty""), but not as a dogmatic supporter of laissez-faire.[142]
",4
3997,"Economist Daniel Klein believes using the term ""free-market economics"" or ""free-market economist"" to identify the ideas of Smith is too general and slightly misleading. Klein offers six characteristics central to the identity of Smith's economic thought and argues that a new name is needed to give a more accurate depiction of the ""Smithian"" identity.[143][144] Economist David Ricardo set straight some of the misunderstandings about Smith's thoughts on free market. Most people still fall victim to the thinking that Smith was a free-market economist without exception, though he was not. Ricardo pointed out that Smith was in support of helping infant industries. Smith believed that the government should subsidise newly formed industry, but he did fear that when the infant industry grew into adulthood, it would be unwilling to surrender the government help.[145] Smith also supported tariffs on imported goods to counteract an internal tax on the same good. Smith also fell to pressure in supporting some tariffs in support for national defence.[145]
",4
3998,"Some have also claimed, Emma Rothschild among them, that Smith would have supported a minimum wage,[146] although no direct textual evidence supports the claim. Indeed, Smith wrote:
",4
3999,"The price of labour, it must be observed, cannot be ascertained very accurately anywhere, different prices being often paid at the same place and for the same sort of labour, not only according to the different abilities of the workmen, but according to the easiness or hardness of the masters. Where wages are not regulated by law, all that we can pretend to determine is what are the most usual; and experience seems to show that law can never regulate them properly, though it has often pretended to do so. (The Wealth of Nations, Book 1, Chapter 8)",4
4000,"However, Smith also noted, to the contrary, the existence of an imbalanced, inequality of bargaining power:[147]
",4
4001,"A landlord, a farmer, a master manufacturer, a merchant, though they did not employ a single workman, could generally live a year or two upon the stocks which they have already acquired. Many workmen could not subsist a week, few could subsist a month, and scarce any a year without employment. In the long run, the workman may be as necessary to his master as his master is to him, but the necessity is not so immediate.",4
4002,"Alfred Marshall criticised Smith's definition of the economy on several points. He argued that man should be equally important as money, services are as important as goods, and that there must be an emphasis on human welfare, instead of just wealth. The ""invisible hand"" only works well when both production and consumption operates in free markets, with small (""atomistic"") producers and consumers allowing supply and demand to fluctuate and equilibrate. In conditions of monopoly and oligopoly, the ""invisible hand"" fails.
",4
4003,"Nobel Prize-winning economist Joseph E. Stiglitz says, on the topic of one of Smith's better-known ideas: ""the reason that the invisible hand often seems invisible is that it is often not there.""[148]
",4
4004,"
",4
4005,"Heterodox
",4
4006,"John Maynard Keynes, 1st Baron Keynes[2] CB FBA (/keɪnz/ KAYNZ; 5 June 1883 – 21 April 1946) was an English economist, whose ideas fundamentally changed the theory and practice of macroeconomics and the economic policies of governments. Originally trained in mathematics, he built on and greatly refined earlier work on the causes of business cycles.[3] One of the most influential economists of the 20th century,[4] his ideas are the basis for the school of thought known as Keynesian economics, and its various offshoots.[5]
",4
4007,"During the Great Depression of the 1930s, Keynes spearheaded a revolution in economic thinking, challenging the ideas of neoclassical economics that held that free markets would, in the short to medium term, automatically provide full employment, as long as workers were flexible in their wage demands. He argued that aggregate demand (total spending in the economy) determined the overall level of economic activity, and that inadequate aggregate demand could lead to prolonged periods of high unemployment. Keynes advocated the use of fiscal and monetary policies to mitigate the adverse effects of economic recessions and depressions. He detailed these ideas in his magnum opus, The General Theory of Employment, Interest and Money, published in 1936. By the late 1930s, leading Western economies had begun adopting Keynes's policy recommendations. Almost all capitalist governments had done so by the end of the two decades following Keynes's death in 1946. As a leader of the British delegation, Keynes participated in the design of the international economic institutions established after the end of World War II but was overruled by the American delegation on several aspects.
",4
4008,"Keynes's influence started to wane in the 1970s, partly as a result of the stagflation that plagued the Anglo-American economies during that decade, and partly because of criticism of Keynesian policies by Milton Friedman and other monetarists,[6] who disputed the ability of government to favourably regulate the business cycle with fiscal policy.[7] However, the advent of the global financial crisis of 2007–2008 sparked a resurgence in Keynesian thought. Keynesian economics provided the theoretical underpinning for economic policies undertaken in response to the financial crisis of 2007–2008 by President Barack Obama of the United States, Prime Minister Gordon Brown of the United Kingdom, and other heads of governments.[8]
",4
4009,"When Time magazine included Keynes among its Most Important People of the Century in 1999, it stated that ""his radical idea that governments should spend money they don't have may have saved capitalism.""[9] The Economist has described Keynes as ""Britain's most famous 20th-century economist.""[10] In addition to being an economist, Keynes was also a civil servant, a director of the Bank of England, and a part of the Bloomsbury Group of intellectuals.[11]
",4
4010,"John Maynard Keynes was born in Cambridge, Cambridgeshire, England, to an upper-middle-class family. His father, John Neville Keynes, was an economist and a lecturer in moral sciences at the University of Cambridge and his mother Florence Ada Keynes a local social reformer. Keynes was the first born, and was followed by two more children – Margaret Neville Keynes in 1885 and Geoffrey Keynes in 1887. Geoffrey became a surgeon and Margaret married the Nobel Prize-winning physiologist Archibald Hill, although she had many affairs with women, notably Eglantyne Jebb.[12]
",4
4011,"According to the economic historian and biographer Robert Skidelsky, Keynes's parents were loving and attentive. They remained in the same house throughout their lives, where the children were always welcome to return. Keynes would receive considerable support from his father, including expert coaching to help him pass his scholarship exams and financial help both as a young man and when his assets were nearly wiped out at the onset of Great Depression in 1929. Keynes's mother made her children's interests her own, and according to Skidelsky, ""because she could grow up with her children, they never outgrew home"".[13]
",4
4012,"In January 1889 at the age of five and a half, Keynes started at the kindergarten of the Perse School for Girls for five mornings a week. He quickly showed a talent for arithmetic, but his health was poor leading to several long absences. He was tutored at home by a governess, Beatrice Mackintosh, and his mother. In January 1892, at eight and a half, he started as a day pupil at St Faith's preparatory school. By 1894, Keynes was top of his class and excelling at mathematics. In 1896, St Faith's headmaster, Ralph Goodchild, wrote that Keynes was ""head and shoulders above all the other boys in the school"" and was confident that Keynes could get a scholarship to Eton.[14][15]
",4
4013,"In 1897, Keynes won a scholarship to Eton College, where he displayed talent in a wide range of subjects, particularly mathematics, classics and history. At Eton, Keynes experienced the first ""love of his life"" in Dan Macmillan, older brother of the future Prime Minister Harold Macmillan.[16] Despite his middle-class background, Keynes mixed easily with upper-class pupils.
",4
4014,"In 1902 Keynes left Eton for King's College, Cambridge, after receiving a scholarship for this also to read mathematics. Alfred Marshall begged Keynes to become an economist,[17]
although Keynes's own inclinations drew him towards philosophy – especially the ethical system of G. E. Moore. Keynes was elected to the University Pitt Club[18] and was an active member of the semi-secretive Cambridge Apostles society, a debating club largely reserved for the brightest students. Like many members, Keynes retained a bond to the club after graduating and continued to attend occasional meetings throughout his life. Before leaving Cambridge, Keynes became the President of the Cambridge Union Society and Cambridge University Liberal Club. He was said to be an atheist.[19][20]
",4
4015,"In May 1904, he received a first-class BA in mathematics. Aside from a few months spent on holidays with family and friends, Keynes continued to involve himself with the university over the next two years. He took part in debates, further studied philosophy and attended economics lectures informally as a graduate student for one term, which constituted his only formal education in the subject. He took civil service exams in 1906.
",4
4016,"The economist Harry Johnson wrote that the optimism imparted by Keynes's early life is a key to understanding his later thinking.[21]
Keynes was always confident he could find a solution to whatever problem he turned his attention to and retained a lasting faith in the ability of government officials to do good.[22]
Keynes's optimism was also cultural, in two senses: he was of the last generation raised by an empire still at the height of its power and was also of the last generation who felt entitled to govern by culture, rather than by expertise. According to Skidelsky, the sense of cultural unity current in Britain from the 19th century to the end of World War I provided a framework with which the well-educated could set various spheres of knowledge in relation to each other and life, enabling them to confidently draw from different fields when addressing practical problems.[13]
",4
4017,"In October 1908 Keynes's Civil Service career began as a clerk in the India Office.[23] He enjoyed his work at first, but by 1908 had become bored and resigned his position to return to Cambridge and work on probability theory, at first privately funded only by two dons at the university – his father and the economist Arthur Pigou.
",4
4018,"By 1909 Keynes had published his first professional economics article in The Economic Journal, about the effect of a recent global economic downturn on India.[24] He founded the Political Economy Club, a weekly discussion group. Also in 1909, Keynes accepted a lectureship in economics funded personally by Alfred Marshall. Keynes's earnings rose further as he began to take on pupils for private tuition.
",4
4019,"In 1911 Keynes was made the editor of The Economic Journal. By 1913 he had published his first book, Indian Currency and Finance.[25] He was then appointed to the Royal Commission on Indian Currency and Finance[26] – the same topic as his book – where Keynes showed considerable talent at applying economic theory to practical problems. His written work was published under the name ""J M Keynes"", though to his family and friends he was known as Maynard. (His father, John Neville Keynes, was also always known by his middle name).[27]
",4
4020,"The British Government called on Keynes's expertise during the First World War. While he did not formally re-join the civil service in 1914, Keynes traveled to London at the government's request a few days before hostilities started. Bankers had been pushing for the suspension of specie payments – the convertibility of banknotes into gold – but with Keynes's help the Chancellor of the Exchequer (then Lloyd George) was persuaded that this would be a bad idea, as it would hurt the future reputation of the city if payments were suspended before it was necessary.
",4
4021,"In January 1915 Keynes took up an official government position at the Treasury. Among his responsibilities were the design of terms of credit between Britain and its continental allies during the war and the acquisition of scarce currencies. According to economist Robert Lekachman, Keynes's ""nerve and mastery became legendary"" because of his performance of these duties, as in the case where he managed to assemble – with difficulty – a small supply of Spanish pesetas.
",4
4022,"The secretary of the Treasury was delighted to hear Keynes had amassed enough to provide a temporary solution for the British Government. But Keynes did not hand the pesetas over, choosing instead to sell them all to break the market: his boldness paid off, as pesetas then became much less scarce and expensive.[28]
",4
4023,"On the introduction of military conscription in 1916, he applied for exemption as a conscientious objector, which was effectively granted conditional upon continuing his government work.
",4
4024,"In the 1917 King's Birthday Honours, Keynes was appointed Companion of the Order of the Bath for his wartime work,[29] and his success led to the appointment that had a huge effect on Keynes's life and career; Keynes was appointed financial representative for the Treasury to the 1919 Versailles peace conference. He was also appointed Officer of the Belgian Order of Leopold.[30]
",4
4025,"Keynes's experience at Versailles was influential in shaping his future outlook, yet it was not a successful one. Keynes's main interest had been in trying to prevent Germany's compensation payments being set so high it would traumatize innocent German people, damage the nation's ability to pay and sharply limit her ability to buy exports from other countries – thus hurting not just Germany's economy but that of the wider world.
",4
4026,"Unfortunately for Keynes, conservative powers in the coalition that emerged from the 1918 coupon election were able to ensure that both Keynes himself and the Treasury were largely excluded from formal high-level talks concerning reparations. Their place was taken by the Heavenly Twins – the judge Lord Sumner and the banker Lord Cunliffe whose nickname derived from the ""astronomically"" high war compensation they wanted to demand from Germany. Keynes was forced to try to exert influence mostly from behind the scenes.
",4
4027,"The three principal players at Versailles were Britain's Lloyd George, France's Clemenceau and America's President Wilson.[31]
It was only Lloyd George to whom Keynes had much direct access; until the 1918 election he had some sympathy with Keynes's view but while campaigning had found his speeches were only well received by the public if he promised to harshly punish Germany, and had therefore committed his delegation to extracting high payments.
",4
4028,"Lloyd George did, however, win some loyalty from Keynes with his actions at the Paris conference by intervening against the French to ensure the dispatch of much-needed food supplies to German civilians. Clemenceau also pushed for substantial reparations, though not as high as those proposed by the British, while on security grounds, France argued for an even more severe settlement than Britain.
",4
4029,"Wilson initially favoured relatively lenient treatment of Germany – he feared too harsh conditions could foment the rise of extremism and wanted Germany to be left sufficient capital to pay for imports. To Keynes's dismay, Lloyd George and Clemenceau were able to pressure Wilson to agree to include pensions in the reparations bill.
",4
4030,"Towards the end of the conference, Keynes came up with a plan that he argued would not only help Germany and other impoverished central European powers but also be good for the world economy as a whole. It involved the radical writing down of war debts, which would have had the possible effect of increasing international trade all round, but at the same time thrown the entire cost of European reconstruction on the United States.
",4
4031,"Lloyd George agreed it might be acceptable to the British electorate. However, America was against the plan; the US was then the largest creditor, and by this time Wilson had started to believe in the merits of a harsh peace and thought that his country had already made excessive sacrifices. Hence despite his best efforts, the result of the conference was a treaty which disgusted Keynes both on moral and economic grounds and led to his resignation from the Treasury.[32]
",4
4032,"In June 1919 he turned down an offer to become chairman of the British Bank of Northern Commerce, a job that promised a salary of £2000 in return for a morning per week of work.
",4
4033,"Keynes's analysis on the predicted damaging effects of the treaty appeared in the highly influential book, The Economic Consequences of the Peace, published in 1919.[33] This work has been described as Keynes's best book, where he was able to bring all his gifts to bear – his passion as well as his skill as an economist. In addition to economic analysis, the book contained pleas to the reader's sense of compassion:
",4
4034,"I cannot leave this subject as though its just treatment wholly depended either on our pledges or on economic facts. The policy of reducing Germany to servitude for a generation, of degrading the lives of millions of human beings, and of depriving a whole nation of happiness should be abhorrent and detestable, – abhorrent and detestable, even if it was possible, even if it enriched ourselves, even if it did not sow the decay of the whole civilized life of Europe.",4
4035,"Also present was striking imagery such as ""year by year Germany must be kept impoverished and her children starved and crippled"" along with bold predictions which were later justified by events:
",4
4036,"If we aim deliberately at the impoverishment of Central Europe, vengeance, I dare predict, will not limp. Nothing can then delay for very long that final war between the forces of Reaction and the despairing convulsions of Revolution, before which the horrors of the late German war will fade into nothing.",4
4037,"Keynes's followers assert that his predictions of disaster were borne out when the German economy suffered the hyperinflation of 1923, and again by the collapse of the Weimar Republic and the outbreak of the Second World War. However, historian Ruth Henig claims that ""most historians of the Paris peace conference now take the view that, in economic terms, the treaty was not unduly harsh on Germany and that, while obligations and damages were inevitably much stressed in the debates at Paris to satisfy electors reading the daily newspapers, the intention was quietly to give Germany substantial help towards paying her bills, and to meet many of the German objections by amendments to the way the reparations schedule was in practice carried out"".[34][35]
",4
4038,"Only a small fraction of reparations was ever paid. In fact, historian Stephen A. Schuker demonstrates in American 'Reparations' to Germany, 1919–33, that the capital inflow from American loans substantially exceeded German out payments so that, on a net basis, Germany received support equal to four times the amount of the post-Second World War Marshall Plan.
",4
4039,"Schuker also shows that, in the years after Versailles, Keynes became an informal reparations adviser to the German government, wrote one of the major German reparation notes, and supported the hyperinflation on political grounds.  Nevertheless, The Economic Consequences of the Peace gained Keynes international fame, even though it also caused him to be regarded as anti-establishment – it was not until after the outbreak of the Second World War that Keynes was offered a directorship of a major British Bank, or an acceptable offer to return to government with a formal job. However, Keynes was still able to influence government policy making through his network of contacts, his published works and by serving on government committees; this included attending high-level policy meetings as a consultant.[32]
",4
4040,"Keynes had completed his A Treatise on Probability before the war but published it in 1921.[32] The work was a notable contribution to the philosophical and mathematical underpinnings of probability theory, championing the important view that probabilities were no more or less than truth values intermediate between simple truth and falsity. Keynes developed the first upper-lower probabilistic interval approach to probability in chapters 15 and 17 of this book, as well as having developed the first decision weight approach with his conventional coefficient of risk and weight, c, in chapter 26. In addition to his academic work, the 1920s saw Keynes active as a journalist selling his work internationally and working in London as a financial consultant. In 1924 Keynes wrote an obituary for his former tutor
Alfred Marshall which Joseph Schumpeter called ""the most brilliant life of a man of science I have ever read.""[36]
Marshall's widow was ""entranced"" by the memorial, while Lytton Strachey rated it as one of Keynes's ""best works"".[32]
",4
4041,"In 1922 Keynes continued to advocate reduction of German reparations with A Revision of the Treaty.[32] He attacked the post-World War I deflation policies with A Tract on Monetary Reform in 1923[32] – a trenchant argument that countries should target stability of domestic prices, avoiding deflation even at the cost of allowing their currency to depreciate. Britain suffered from high unemployment through most of the 1920s, leading Keynes to recommend the depreciation of sterling to boost jobs by making British exports more affordable. From 1924 he was also advocating a fiscal response, where the government could create jobs by spending on public works.[32] During the 1920s Keynes's pro stimulus views had only limited effect on policy makers and mainstream academic opinion – according to Hyman Minsky one reason was that at this time his theoretical justification was ""muddled"".[24] The Tract had also called for an end to the gold standard. Keynes advised it was no longer a net benefit for countries such as Britain to participate in the gold standard, as it ran counter to the need for domestic policy autonomy. It could force countries to pursue deflationary policies at exactly the time when expansionary measures were called for to address rising unemployment. The Treasury and Bank of England were still in favour of the gold standard and in 1925 they were able to convince the then Chancellor Winston Churchill to re-establish it, which had a depressing effect on British industry. Keynes responded by writing The Economic Consequences of Mr. Churchill and continued to argue against the gold standard until Britain finally abandoned it in 1931.[32]
",4
4042,"Keynes had begun a theoretical work to examine the relationship between unemployment, money, and prices back in the 1920s.[37] The work, Treatise on Money, was published in 1930 in two volumes. A central idea of the work was that if the amount of money being saved exceeds the amount being invested – which can happen if interest rates are too high – then unemployment will rise. This is in part a result of people not wanting to spend too high a proportion of what employers pay out, making it difficult, in aggregate, for employers to make a profit. Another key theme of the book is the unreliability of financial indices for representing an accurate – or indeed meaningful – indication of general shifts in purchasing power of currencies over time. In particular, he criticized the justification of Britain's return to the gold standard in 1925 at pre-war valuation by reference to the wholesale price index. He argued that the index understated the effects of changes in the costs of services and labor.
",4
4043,"Keynes was deeply critical of the British government's austerity measures during the Great Depression. He believed that budget deficits during recessions were a good thing and a natural product of an economic slump. He wrote, ""For Government borrowing of one kind or another is nature's remedy, so to speak, for preventing business losses from being, in so severe a slump as the present one, so great as to bring production altogether to a standstill.""[38]
",4
4044,"At the height of the Great Depression, in 1933, Keynes published The Means to Prosperity, which contained specific policy recommendations for tackling unemployment in a global recession, chiefly counter-cyclical public spending. The Means to Prosperity contains one of the first mentions of the multiplier effect. While it was addressed chiefly to the British Government, it also contained advice for other nations affected by the global recession. A copy was sent to the newly elected President Franklin D. Roosevelt and other world leaders. The work was taken seriously by both the American and British governments, and according to Robert Skidelsky, helped pave the way for the later acceptance of Keynesian ideas, though it had little immediate practical influence. In the 1933 London Economic Conference opinions remained too diverse for a unified course of action to be agreed upon.[39]
",4
4045,"Keynesian-like policies were adopted by Sweden and Germany, but Sweden was seen as too small to command much attention, and Keynes was deliberately silent about the successful efforts of Germany as he was dismayed by its imperialist ambitions and its treatment of Jews.[39] Apart from Great Britain, Keynes's attention was primarily focused on the United States. In 1931, he received considerable support for his views on counter-cyclical public spending in Chicago, then America's foremost center for economic views alternative to the mainstream.[24][39] However, orthodox economic opinion remained generally hostile regarding fiscal intervention to mitigate the depression, until just before the outbreak of war.[24] In late 1933 Keynes was persuaded by Felix Frankfurter to address President Roosevelt directly, which he did by letters and face to face in 1934, after which the two men spoke highly of each other.[39] However, according to Skidelsky, the consensus is that Keynes's efforts began to have a more than marginal influence on US economic policy only after 1939.[39]
",4
4046,"Keynes's magnum opus, The General Theory of Employment, Interest and Money was published in 1936.[40] It was researched and indexed by one of Keynes's favourite students, later the economist David Bensusan-Butt.[41] The work served as a theoretical justification for the interventionist policies Keynes favoured for tackling a recession. The General Theory challenged the earlier neoclassical economic paradigm, which had held that provided it was unfettered by government interference, the market would naturally establish full employment equilibrium. In doing so Keynes was partly setting himself against his former teachers Marshall and Pigou. Keynes believed the classical theory was a ""special case"" that applied only to the particular conditions present in the 19th century, his theory being the general one. Classical economists had believed in Say's law, which, simply put, states that ""supply creates its demand"", and that in a free market workers would always be willing to lower their wages to a level where employers could profitably offer them jobs. An innovation from Keynes was the concept of price stickiness – the recognition that in reality workers often refuse to lower their wage demands even in cases where a classical economist might argue that it is rational for them to do so. Due in part to price stickiness, it was established that the interaction of ""aggregate demand"" and ""aggregate supply"" may lead to stable unemployment equilibria – and in those cases, it is on the state, not the market, that economies must depend for their salvation.
",4
4047,"The General Theory argues that demand, not supply, is the key variable governing the overall level of economic activity. Aggregate demand, which equals total un-hoarded income in a society, is defined by the sum of consumption and investment. In a state of unemployment and unused production capacity, one can enhance employment and total income only by first increasing expenditures for either consumption or investment. Without government intervention to increase expenditure, an economy can remain trapped in a low-employment equilibrium. The demonstration of this possibility has been described as the revolutionary formal achievement of the work.[42]
The book advocated activist economic policy by government to stimulate demand in times of high unemployment, for example by spending on public works. ""Let us be up and doing, using our idle resources to increase our wealth,"" he wrote in 1928. ""With men and plants unemployed, it is ridiculous to say that we cannot afford these new developments. It is precisely with these plants and these men that we shall afford them.""[38]
",4
4048,"The General Theory is often viewed as the foundation of modern macroeconomics. Few senior American economists agreed with Keynes through most of the 1930s.[43]
Yet his ideas were soon to achieve widespread acceptance, with eminent American professors such as Alvin Hansen agreeing with the General Theory before the outbreak of World War II.[44][45][46]
",4
4049,"Keynes himself had only limited participation in the theoretical debates that followed the publication of the General Theory as he suffered a heart attack in 1937, requiring him to take long periods of rest. Among others, Hyman Minsky and Post-Keynesian economists have argued that as result, Keynes's ideas were diluted by those keen to compromise with classical economists or to render his concepts with mathematical models like the IS–LM model (which, they argue, distort Keynes's ideas).[24][46] Keynes began to recover in 1939, but for the rest of his life his professional energies were directed largely towards the practical side of economics: the problems of ensuring optimum allocation of resources for the war efforts, post-war negotiations with America, and the new international financial order that was presented at the Bretton Woods Conference.
",4
4050,"In the General Theory and later, Keynes responded to the socialists who argued, especially during the Great Depression of the 1930s, that capitalism caused war. He argued that if capitalism were managed domestically and internationally (with coordinated international Keynesian policies, an international monetary system that did not pit the interests of countries against one another, and a high degree of freedom of trade), then this system of managed capitalism could promote peace rather than conflict between countries. His plans during World War II for post-war international economic institutions and policies (which contributed to the creation at Bretton Woods of the International Monetary Fund and the World Bank, and later to the creation of the General Agreement on Tariffs and Trade and eventually the World Trade Organization) were aimed to give effect to this vision.[47]
",4
4051,"Although Keynes has been widely criticized – especially by members of the Chicago school of economics – for advocating irresponsible government spending financed by borrowing, in fact he was a firm believer in balanced budgets and regarded the proposals for programs of public works during the Great Depression as an exceptional measure to meet the needs of exceptional circumstances.[48]
",4
4052,"During the Second World War, Keynes argued in How to Pay for the War, published in 1940, that the war effort should be largely financed by higher taxation and especially by compulsory saving (essentially workers lending money to the government), rather than deficit spending, in order to avoid inflation. Compulsory saving would act to dampen domestic demand, assist in channeling additional output towards the war efforts, would be fairer than punitive taxation and would have the advantage of helping to avoid a post-war slump by boosting demand once workers were allowed to withdraw their savings. In September 1941 he was proposed to fill a vacancy in the Court of Directors of the Bank of England, and subsequently carried out a full term from the following April.[49] In June 1942, Keynes was rewarded for his service with a hereditary peerage in the King's Birthday Honours.[50] On 7 July his title was gazetted as ""Baron Keynes, of Tilton, in the County of Sussex"" and he took his seat in the House of Lords on the Liberal Party benches.[51]
",4
4053,"As the Allied victory began to look certain, Keynes was heavily involved, as leader of the British delegation and chairman of the World Bank commission, in the mid-1944 negotiations that established the Bretton Woods system. The Keynes plan, concerning an international clearing-union, argued for a radical system for the management of currencies. He proposed the creation of a common world unit of currency, the bancor, and new global institutions – a world central bank and the International Clearing Union. Keynes envisaged these institutions managing an international trade and payments system with strong incentives for countries to avoid substantial trade deficits or surpluses.[52] The USA's greater negotiating strength, however, meant that the outcomes accorded more closely to the more conservative plans of Harry Dexter White. According to US economist J. Bradford DeLong, on almost every point where he was overruled by the Americans, Keynes was later proved correct by events.[53]
",4
4054,"The two new institutions, later known as the World Bank and the International Monetary Fund (IMF), were founded as a compromise that primarily reflected the American vision. There would be no incentives for states to avoid a large trade surplus; instead, the burden for correcting a trade imbalance would continue to fall only on the deficit countries, which Keynes had argued were least able to address the problem without inflicting economic hardship on their populations. Yet, Keynes was still pleased when accepting the final agreement, saying that if the institutions stayed true to their founding principles, ""the brotherhood of man will have become more than a phrase.""[54][55]
",4
4055,"After the war, Keynes continued to represent the United Kingdom in international negotiations despite his deteriorating health. He succeeded in obtaining preferential terms from the United States for new and outstanding debts to facilitate the rebuilding of the British economy.[56]
",4
4056,"Just before his death in 1946, Keynes told Henry Clay, a professor of social economics and advisor to the Bank of England,[57] of his hopes that Adam Smith's ""invisible hand"" could help Britain out of the economic hole it was in: ""I find myself more and more relying for a solution of our problems on the invisible hand which I tried to eject from economic thinking twenty years ago.""[58]
",4
4057,"From the end of the Great Depression to the mid-1970s, Keynes provided the main inspiration for economic policymakers in Europe, America and much of the rest of the world.[46] While economists and policymakers had become increasingly won over to Keynes's way of thinking in the mid and late 1930s, it was only after the outbreak of World War II that governments started to borrow money for spending on a scale sufficient to eliminate unemployment. According to the economist John Kenneth Galbraith (then a US government official charged with controlling inflation), in the rebound of the economy from wartime spending, ""one could not have had a better demonstration of the Keynesian ideas.""[59]
",4
4058,"The Keynesian Revolution was associated with the rise of modern liberalism in the West during the post-war period.[60] Keynesian ideas became so popular that some scholars point to Keynes as representing the ideals of modern liberalism, as Adam Smith represented the ideals of classical liberalism.[61] After the war, Winston Churchill attempted to check the rise of Keynesian policy-making in the United Kingdom and used rhetoric critical of the mixed economy in his 1945 election campaign. Despite his popularity as a war hero, Churchill suffered a landslide defeat to Clement Attlee whose government's economic policy continued to be influenced by Keynes's ideas.[59]
",4
4059,"In the late 1930s and 1940s, economists (notably John Hicks, Franco Modigliani, and Paul Samuelson) attempted to interpret and formalise Keynes's writings in terms of formal mathematical models. In what had become known as the neoclassical synthesis, they combined Keynesian analysis with neoclassical economics to produce neo-Keynesian economics, which came to dominate mainstream macroeconomic thought for the next 40 years.
",4
4060,"By the 1950s, Keynesian policies were adopted by almost the entire developed world and similar measures for a mixed economy were used by many developing nations. By then, Keynes's views on the economy had become mainstream in the world's universities. Throughout the 1950s and 1960s, the developed and emerging free capitalist economies enjoyed exceptionally high growth and low unemployment.[62][63] Professor Gordon Fletcher has written that the 1950s and 1960s, when Keynes's influence was at its peak, appear in retrospect as a golden age of capitalism.[46]
",4
4061,"In late 1965 Time magazine ran a cover article with a title comment from Milton Friedman (later echoed by U.S. President Richard Nixon), ""We are all Keynesians now"". The article described the exceptionally favourable economic conditions then prevailing, and reported that ""Washington's economic managers scaled these heights by their adherence to Keynes's central theme: the modern capitalist economy does not automatically work at top efficiency, but can be raised to that level by the intervention and influence of the government."" The article also states that Keynes was one of the three most important economists who ever lived, and that his General Theory was more influential than the magna opera of other famous economists, like Adam Smith's The Wealth of Nations.[64]
",4
4062,"Keynesian economics were officially discarded by the British Government in 1979, but forces had begun to gather against Keynes's ideas over 30 years earlier. Friedrich Hayek had formed the Mont Pelerin Society in 1947, with the explicit intention of nurturing intellectual currents to one day displace Keynesianism and other similar influences. Its members included the Austrian School economist Ludwig von Mises along with the then young Milton Friedman. Initially the society had little impact on the wider world – according to Hayek it was as if Keynes had been raised to sainthood after his death and that people refused to allow his work to be questioned.[65][66]
Friedman however began to emerge as a formidable critic of Keynesian economics from the mid-1950s, and especially after his 1963 publication of A Monetary History of the United States.
",4
4063,"On the practical side of economic life, ""big government"" had appeared to be firmly entrenched in the 1950s, but the balance began to shift towards the power of private interests in the 1960s. Keynes had written against the folly of allowing ""decadent and selfish"" speculators and financiers the kind of influence they had enjoyed after World War I. For two decades after World War II the public opinion was strongly against private speculators, the disparaging label ""Gnomes of Zürich"" being typical of how they were described during this period. International speculation was severely restricted by the capital controls in place after Bretton Woods. According to the journalists Larry Elliott and Dan Atkinson, 1968 was the pivotal year when power shifted in favour of private agents such as currency speculators. As the key 1968 event Elliott and Atkinson picked out America's suspension of the conversion of the dollar into gold except on request of foreign governments, which they identified as the beginning of the breakdown of the Bretton Woods system.[67]
",4
4064,"Criticisms of Keynes's ideas had begun to gain significant acceptance by the early 1970s, as they were then able to make a credible case that Keynesian models no longer reflected economic reality. Keynes himself included few formulas and no explicit mathematical models in his General Theory. For economists such as Hyman Minsky, Keynes's limited use of mathematics was partly the result of his scepticism about whether phenomena as inherently uncertain as economic activity could ever be adequately captured by mathematical models. Nevertheless, many models were developed by Keynesian economists, with a famous example being the Phillips curve which predicted an inverse relationship between unemployment and inflation. It implied that unemployment could be reduced by government stimulus with a calculable cost to inflation. In 1968, Milton Friedman published a paper arguing that the fixed relationship implied by the Philips curve did not exist.[68]
Friedman suggested that sustained Keynesian policies could lead to both unemployment and inflation rising at once – a phenomenon that soon became known as stagflation. In the early 1970s stagflation appeared in both the US and Britain just as Friedman had predicted, with economic conditions deteriorating further after the 1973 oil crisis. Aided by the prestige gained from his successful forecast, Friedman led increasingly successful criticisms against the Keynesian consensus, convincing not only academics and politicians but also much of the general public with his radio and television broadcasts. The academic credibility of Keynesian economics was further undermined by additional criticism from other monetarists trained in the Chicago school of economics, by the Lucas critique and by criticisms from Hayek's Austrian School.[46] So successful were these criticisms that by 1980 Robert Lucas claimed economists would often take offence if described as Keynesians.[69]
",4
4065,"Keynesian principles fared increasingly poorly on the practical side of economics – by 1979 they had been displaced by monetarism as the primary influence on Anglo-American economic policy.[46] However, many officials on both sides of the Atlantic retained a preference for Keynes, and in 1984 the Federal Reserve officially discarded monetarism, after which Keynesian principles made a partial comeback as an influence on policy making.[70]
Not all academics accepted the criticism against Keynes – Minsky has argued that Keynesian economics had been debased by excessive mixing with neoclassical ideas from the 1950s, and that it was unfortunate that this branch of economics had even continued to be called ""Keynesian"".[24] Writing in The American Prospect, Robert Kuttner argued it was not so much excessive Keynesian activism that caused the economic problems of the 1970s but the breakdown of the Bretton Woods system of capital controls, which allowed capital flight from regulated economies into unregulated economies in a fashion similar to Gresham's law phenomenon (where weak currencies undermine strong currencies).[71]
Historian Peter Pugh has stated that a key cause of the economic problems afflicting America in the 1970s was the refusal to raise taxes to finance the Vietnam War, which was against Keynesian advice.[72]
",4
4066,"A more typical response was to accept some elements of the criticisms while refining Keynesian economic theories to defend them against arguments that would invalidate the whole Keynesian framework – the resulting body of work largely composing New Keynesian economics. In 1992 Alan Blinder wrote about a ""Keynesian Restoration"", as work based on Keynes's ideas had to some extent become fashionable once again in academia, though in the mainstream it was highly synthesised with monetarism and other neoclassical thinking. In the world of policy making, free market influences broadly sympathetic to monetarism have remained very strong at government level – in powerful normative institutions like the World Bank, the IMF and US Treasury, and in prominent opinion-forming media such as the Financial Times and The Economist.[73]
",4
4067,"The global financial crisis of 2007–08 led to public skepticism about the free market consensus even from some on the economic right. In March 2008, Martin Wolf, chief economics commentator at the Financial Times, announced the death of the dream of global free-market capitalism.[75] In the same month macroeconomist James K. Galbraith used the 25th Annual Milton Friedman Distinguished Lecture to launch a sweeping attack against the consensus for monetarist economics and argued that Keynesian economics were far more relevant for tackling the emerging crises.[76]
Economist Robert J. Shiller had begun advocating robust government intervention to tackle the financial crises, specifically citing Keynes.[77][78][79]
Nobel laureate Paul Krugman also actively argued the case for vigorous Keynesian intervention in the economy in his columns for The New York Times.[80][81][82]
Other prominent economic commentators who have argued for Keynesian government intervention to mitigate the financial crisis include George Akerlof,[83] J. Bradford DeLong,[84]
Robert Reich,[85]
and Joseph Stiglitz.[86]
Newspapers and other media have also cited work relating to Keynes by Hyman Minsky,[24] Robert Skidelsky,[13] Donald Markwell[87]
and Axel Leijonhufvud.[88]
",4
4068,"A series of major bailouts were pursued during the financial crisis, starting on 7 September with the announcement that the U.S. Government was to nationalise the two government-sponsored enterprises which oversaw most of the U.S. subprime mortgage market – Fannie Mae and Freddie Mac. In October, Alistair Darling, the British Chancellor of the Exchequer, referred to Keynes as he announced plans for substantial fiscal stimulus to head off the worst effects of recession, in accordance with Keynesian economic thought.[89][90] Similar policies have been adopted by other governments worldwide.[91][92]
This is in stark contrast to the action imposed on Indonesia during the Asian financial crisis of 1997, when it was forced by the IMF to close 16 banks at the same time, prompting a bank run.[93]
Much of the post-crisis discussion reflected Keynes's advocacy of international coordination of fiscal or monetary stimulus, and of international economic institutions such as the IMF and the World Bank, which many had argued should be reformed as a ""new Bretton Woods"", and should have been even before the crises broke out.[94]
The IMF and United Nations economists advocated a coordinated international approach to fiscal stimulus.[95]
Donald Markwell argued that in the absence of such an international approach, there would be a risk of worsening international relations and possibly even world war arising from economic factors similar to those present during the depression of the 1930s.[87]
",4
4069,"By the end of December 2008, the Financial Times reported that ""the sudden resurgence of Keynesian policy is a stunning reversal of the orthodoxy of the past several decades.""[96]
In December 2008, Paul Krugman released his book The Return of Depression Economics and the Crisis of 2008, arguing that economic conditions similar to those that existed during the earlier part of the 20th century had returned, making Keynesian policy prescriptions more relevant than ever. In February 2009 Robert J. Shiller and George Akerlof published Animal Spirits, a book where they argue the current US stimulus package is too small as it does not take into account Keynes's insight on the importance of confidence and expectations in determining the future behaviour of businesspeople and other economic agents.
",4
4070,"In the March 2009 speech entitled Reform the International Monetary System, Zhou Xiaochuan, the governor of the People's Bank of China, came out in favour of Keynes's idea of a centrally managed global reserve currency. Zhou argued that it was unfortunate that part of the reason for the Bretton Woods system breaking down was the failure to adopt Keynes's bancor. Zhou proposed a gradual move towards increased use of IMF special drawing rights (SDRs).[97][98]
Although Zhou's ideas had not been broadly accepted, leaders meeting in April at the 2009 G-20 London summit agreed to allow $250 billion of special drawing rights to be created by the IMF, to be distributed globally. Stimulus plans were credited for contributing to a better than expected economic outlook by both the OECD[99]
and the IMF,[100][101] in reports published in June and July 2009. Both organisations warned global leaders that recovery was likely to be slow, so counter recessionary measures ought not be rolled back too early.
",4
4071,"While the need for stimulus measures was broadly accepted among policy makers, there had been much debate over how to fund the spending. Some leaders and institutions, such as Angela Merkel[102]
and the European Central Bank,[103]
expressed concern over the potential impact on inflation, national debt and the risk that a too large stimulus will create an unsustainable recovery.
",4
4072,"Among professional economists the revival of Keynesian economics has been even more divisive. Although many economists, such as George Akerlof, Paul Krugman, Robert Shiller, and Joseph Stiglitz, supported Keynesian stimulus, others did not believe higher government spending would help the United States economy recover from the Great Recession. Some economists, such as Robert Lucas, questioned the theoretical basis for stimulus packages.[104] Others, like Robert Barro and Gary Becker, say that empirical evidence for beneficial effects from Keynesian stimulus does not exist.[105] However, there is a growing academic literature that shows that fiscal expansion helps an economy grow in the near term, and that certain types of fiscal stimulus are particularly effective.[106][107]
",4
4073,"On a personal level, Keynes's charm was such that he was generally well received wherever he went – even those who found themselves on the wrong side of his occasionally sharp tongue rarely bore a grudge.[108] Keynes's speech at the closing of the Bretton Woods negotiations was received with a lasting standing ovation, rare in international relations, as the delegates acknowledged the scale of his achievements made despite poor health.[22]
",4
4074,"Austrian School economist Friedrich Hayek was Keynes's most prominent contemporary critic, with sharply opposing views on the economy.[42] Yet after Keynes's death, he wrote: ""He was the one really great man I ever knew, and for whom I had unbounded admiration. The world will be a very much poorer place without him.""[109]
",4
4075,"Lionel Robbins, former head of the economics department at the London School of Economics, who engaged in many heated debates with Keynes in the 1930s, had this to say after observing Keynes in early negotiations with the Americans while drawing up plans for Bretton Woods:[42]
",4
4076,"This went very well indeed. Keynes was in his most lucid and persuasive mood: and the effect was irresistible. At such moments, I often find myself thinking that Keynes must be one of the most remarkable men that have ever lived – the quick logic, the birdlike swoop of intuition, the vivid fancy, the wide vision, above all the incomparable sense of the fitness of words, all combine to make something several degrees beyond the limit of ordinary human achievement. ",4
4077,"Douglas LePan,[42] an official from the Canadian High Commission, wrote:
",4
4078,"I am spellbound. This is the most beautiful creature I have ever listened to. Does he belong to our species? Or is he from some other order? There is something mythic and fabulous about him. I sense in him something massive and sphinx like, and yet also a hint of wings. ",4
4079,"Bertrand Russell[110] named Keynes one of the most intelligent people he had ever known, commenting:[111]
",4
4080,"Keynes's intellect was the sharpest and clearest that I have ever known. When I argued with him, I felt that I took my life in my hands, and I seldom emerged without feeling something of a fool.",4
4081,"Keynes's obituary in The Times included the comment: ""There is the man himself – radiant, brilliant, effervescent, gay, full of impish jokes ... He was a humane man genuinely devoted to the cause of the common good.""[44]
",4
4082,"As a man of the centre described by some as having the greatest impact of any 20th-century economist,[37] Keynes attracted considerable criticism from both sides of the political spectrum. In the 1920s, Keynes was seen as anti-establishment and was mainly attacked from the right. In the ""red 1930s"", many young economists favoured Marxist views, even in Cambridge,[24] and while Keynes was engaging principally with the right to try to persuade them of the merits of more progressive policy, the most vociferous criticism against him came from the left, who saw him as a supporter of capitalism. From the 1950s and onwards, most of the attacks against Keynes have again been from the right.
",4
4083,"
In 1931 Friedrich Hayek extensively critiqued Keynes's 1930 Treatise on Money.[112] After reading Hayek's The Road to Serfdom, Keynes wrote to Hayek[113] ""Morally and philosophically I find myself in agreement with virtually the whole of it"", but concluded the letter with the recommendation: ",4
4084,"What we need therefore, in my opinion, is not a change in our economic programmes, which would only lead in practice to disillusion with the results of your philosophy; but perhaps even the contrary, namely, an enlargement of them. Your greatest danger is the probable practical failure of the application of your philosophy in the United States.",4
4085," On the pressing issue of the time, whether deficit spending could lift a country from depression, Keynes replied to Hayek's criticism[114] in the following way:
",4
4086,"I should... conclude rather differently. I should say that what we want is not no planning, or even less planning, indeed I should say we almost certainly want more. But the planning should take place in a community in which as many people as possible, both leaders and followers wholly share your moral position. Moderate planning will be safe enough if those carrying it out are rightly oriented in their minds and hearts to the moral issue.",4
4087,"Asked why Keynes expressed ""moral and philosophical"" agreement with Hayek's Road to Serfdom, Hayek stated:[115]
",4
4088,"Because he believed that he was fundamentally still a classical English liberal and wasn't quite aware of how far he had moved away from it. His basic ideas were still those of individual freedom. He did not think systematically enough to see the conflicts. He was, in a sense, corrupted by political necessity.",4
4089,"According to some observers,[who?] Hayek felt that the post-World War II ""Keynesian orthodoxy"" gave too much power to the state, and that such policies would lead toward socialism.[116]
",4
4090,"While Milton Friedman described The General Theory as ""a great book"", he argues that its implicit separation of nominal from real magnitudes is neither possible nor desirable. Macroeconomic policy, Friedman argues, can reliably influence only the nominal.[117] He and other monetarists have consequently argued that Keynesian economics can result in stagflation, the combination of low growth and high inflation that developed economies suffered in the early 1970s. More to Friedman's taste was the Tract on Monetary Reform (1923), which he regarded as Keynes's best work because of its focus on maintaining domestic price stability.[117]
",4
4091,"Joseph Schumpeter was an economist of the same age as Keynes and one of his main rivals. He was among the first reviewers to argue that Keynes's General Theory was not a general theory, but a special case.[118] He said the work expressed ""the attitude of a decaying civilisation"". After Keynes's death Schumpeter wrote a brief biographical piece Keynes the Economist – on a personal level he was very positive about Keynes as a man, praising his pleasant nature, courtesy and kindness. He assessed some of Keynes's biographical and editorial work as among the best he'd ever seen. Yet Schumpeter remained critical about Keynes's economics, linking Keynes's childlessness to what Schumpeter saw as an essentially short-term view. He considered Keynes to have a kind of unconscious patriotism that caused him to fail to understand the problems of other nations. For Schumpeter ""Practical Keynesianism is a seedling which cannot be transplanted into foreign soil: it dies there and becomes poisonous as it dies.""[119]
""Schumpeter admired and envied Keynes, but when Keynes died in 1946, Schumpeter's obituary gave Keynes the same off-key, perfunctory treatment he would later give Adam Smith in the History of Economic Analysis, the ""discredit of not adding a single innovation to the techniques of economic analysis"".[120]
",4
4092,"President Harry S. Truman was sceptical of Keynesian theorizing: ""Nobody can ever convince me that government can spend a dollar that it's not got,"" he told Leon Keyserling, a Keynesian economist who chaired Truman's Council of Economic Advisers.[38]
",4
4093,"Keynes sometimes explained the mass murder that took place during the first years of communist Russia on a racial basis, as part of the ""Russian and Jewish nature"", rather than as a result of the communist rule. After a trip to Russia, he wrote in his Short View of Russia that there is ""beastliness on the Russian and Jewish natures when, as now, they are allied together"". He also wrote that ""out of the cruelty and stupidity of the Old Russia nothing could ever emerge, but (...) beneath the cruelty and stupidity of the New Russia a speck of the ideal may lie hid.""[121]
",4
4094,"Some critics have sought to show that Keynes had sympathies towards Nazism, and a number of writers have described him as antisemitic. Keynes's private letters contain portraits and descriptions, some of which can be characterized as antisemitic, while others as philosemitic.[122][123] Scholars have suggested that these reflect clichés current at the time that he accepted uncritically, rather than any racism.[124] On several occasions Keynes used his influence to help his Jewish friends, most notably when he successfully lobbied for Ludwig Wittgenstein to be allowed residency in the United Kingdom, explicitly in order to rescue him from being deported to Nazi-occupied Austria. Keynes was a supporter of Zionism, serving on committees supporting the cause.[124]
",4
4095,"Allegations that he was racist or had totalitarian beliefs have been rejected by Robert Skidelsky and other biographers.[22] Professor Gordon Fletcher wrote that ""the suggestion of a link between Keynes and any support of totalitarianism cannot be sustained"".[46] Once the aggressive tendencies of the Nazis towards Jews and other minorities had become apparent, Keynes made clear his loathing of Nazism. As a lifelong pacifist he had initially favoured peaceful containment of Nazi Germany, yet he began to advocate a forceful resolution while many conservatives were still arguing for appeasement. After the war started he roundly criticised the Left for losing their nerve to confront Hitler:
",4
4096,"The intelligentsia of the Left were the loudest in demanding that the Nazi aggression should be resisted at all costs. When it comes to a showdown, scarce four weeks have passed before they remember that they are pacifists and write defeatist letters to your columns, leaving the defence of freedom and civilisation to Colonel Blimp and the Old School Tie, for whom Three Cheers.[42]",4
4097,"
Keynes has been characterised as being indifferent or even positive about mild inflation.[125] He had indeed expressed a preference for inflation over deflation, saying that if one has to choose between the two evils, it is ""better to disappoint the rentier"" than to inflict pain on working class families.[126] He also supported the German hyperinflation as a way to get free from reparations obligations.  However, Keynes was also aware of the dangers of inflation.[46] In The Economic Consequences of the Peace, he wrote: ",4
4098,"Lenin is said to have declared that the best way to destroy the Capitalist System was to debauch the currency. By a continuing process of inflation, governments can confiscate, secretly and unobserved, an important part of the wealth of their citizens. There is no subtler, no surer means of overturning the existing basis of society than to debauch the currency. The process engages all the hidden forces of economic law on the side of destruction, and does it in a manner which not one man in a million is able to diagnose.[125]",4
4099,"Keynes was the principal author of a proposal – the so-called Keynes Plan – for an International Clearing Union. The two governing principles of the plan were that the problem of settling outstanding balances should be solved by ""creating"" additional ""international money"", and that debtor and creditor should be treated almost alike as disturbers of equilibrium. In the event, though, the plans were rejected, in part because ""American opinion was naturally reluctant to accept the principle of equality of treatment so novel in debtor-creditor relationships"".[127]
",4
4100,"The new system is not founded on free-trade (liberalisation[128] of foreign trade[129]) but rather on the regulation of international trade, in order to eliminate trade imbalances: the nations with a surplus would have an incentive to reduce it, and in doing so they would automatically clear other nations deficits.[130] He proposed a global bank that would issue its currency – the bancor – which was exchangeable with national currencies at fixed rates of exchange and would become the unit of account between nations, which means it would be used to measure a country's trade deficit or trade surplus. Every country would have an overdraft facility in its bancor account at the International Clearing Union. He pointed out that surpluses lead to weak global aggregate demand – countries running surpluses exert a ""negative externality"" on trading partners, and posed, far more than those in deficit, a threat to global prosperity.[131]
",4
4101,"In his 1933 Yale Review article ""National Self-Sufficiency,""[132][133] he already highlighted the problems created by free trade. His view, supported by many economists and commentators at the time, was that creditor nations may be just as responsible as debtor nations for disequilibrium in exchanges and that both should be under an obligation to bring trade back into a state of balance. Failure for them to do so could have serious consequences. In the words of Geoffrey Crowther, then editor of The Economist, ""If the economic relationships between nations are not, by one means or another, brought fairly close to balance, then there is no set of financial arrangements that can rescue the world from the impoverishing results of chaos.""[134]
",4
4102,"These ideas were informed by events prior to the Great Depression when – in the opinion of Keynes and others – international lending, primarily by the U.S., exceeded the capacity of sound investment and so got diverted into non-productive and speculative uses, which in turn invited default and a sudden stop to the process of lending.[135]
",4
4103,"Influenced by Keynes, economics texts in the immediate post-war period put a significant emphasis on balance in trade. For example, the second edition of the popular introductory textbook, An Outline of Money,[136] devoted the last three of its ten chapters to questions of foreign exchange management and in particular the ""problem of balance"". However, in more recent years, since the end of the Bretton Woods system in 1971, with the increasing influence of Monetarist schools of thought in the 1980s, and particularly in the face of large sustained trade imbalances, these concerns – and particularly concerns about the destabilising effects of large trade surpluses – have largely disappeared from mainstream economics discourse[137] and Keynes' insights have slipped from view.[138] They are receiving some attention again in the wake of the financial crisis of 2007–08.[139]
",4
4104,"Keynes's early romantic and sexual relationships were exclusively with men.[140] Keynes had been in relationships while at Eton and Cambridge; significant among these early partners were Dilly Knox and Daniel Macmillan.[16][141] Keynes was open about his affairs, and from 1901 to 1915 kept separate diaries in which he tabulated his many sexual encounters.[142][143] Keynes's relationship and later close friendship with Macmillan was to be fortunate, as Macmillan's company first published his tract Economic Consequences of the Peace.[144]
",4
4105,"Attitudes in the Bloomsbury Group, in which Keynes was avidly involved, were relaxed about homosexuality. Keynes, together with writer Lytton Strachey, had reshaped the Victorian attitudes of the Cambridge Apostles: ""since [their] time, homosexual relations among the members were for a time common"", wrote Bertrand Russell.[145]  The artist Duncan Grant, whom he met in 1908, was one of Keynes's great loves. Keynes was also involved with Lytton Strachey,[140] though they were for the most part love rivals, not lovers. Keynes had won the affections of Arthur Hobhouse,[146] and as with Grant, fell out with a jealous Strachey for it.[147] Strachey had previously found himself put off by Keynes, not least because of his manner of ""treat[ing] his love affairs statistically"".[148]
",4
4106,"Political opponents have used Keynes's sexuality to attack his academic work.[149] One line of attack held that he was uninterested in the long term ramifications of his theories because he had no children.[149]
",4
4107,"Keynes's friends in the Bloomsbury Group were initially surprised when, in his later years, he began pursuing affairs with women,[150] demonstrating himself to be bisexual.[151] Ray Costelloe (who later married Oliver Strachey) was an early heterosexual interest of Keynes.[152] In 1906, Keynes had written of this infatuation that, ""I seem to have fallen in love with Ray a little bit, but as she isn't male I haven't [been] able to think of any suitable steps to take.""[153]
",4
4108,"In 1921, Keynes wrote that he had fallen ""very much in love"" with Lydia Lopokova, a well-known Russian ballerina and one of the stars of Sergei Diaghilev's Ballets Russes.[154] In the early years of his courtship, he maintained an affair with a younger man, Sebastian Sprott, in tandem with Lopokova, but eventually chose Lopokova exclusively.[155][156] They were married in 1925, with Keynes's former lover Duncan Grant as best man.[110][140] ""What a marriage of beauty and brains, the fair Lopokova and John Maynard Keynes"" was said at the time. Keynes later commented to Strachey that beauty and intelligence were rarely found in the same person, and that only in Duncan Grant had he found the combination.[157] The union was happy, with biographer Peter Clarke writing that the marriage gave Keynes ""a new focus, a new emotional stability and a sheer delight of which he never wearied"".[27][158]
Lydia became pregnant in 1927 but miscarried.[27]
",4
4109,"Among Keynes's Bloomsbury friends, Lopokova was, at least initially, subjected to criticism for her manners, mode of conversation, and supposedly humble social origins – the last of the ostensible causes being particularly noted in the letters of Vanessa and Clive Bell, and Virginia Woolf.[159][160] In her novel Mrs Dalloway (1925), Woolf bases the character of Rezia Warren Smith on Lopokova.[161] E. M. Forster later wrote in contrition about ""Lydia Keynes, every whose word should be recorded"":[162] ""How we all used to underestimate her"".[159]
",4
4110,"Keynes thought that the pursuit of money for its own sake was a pathological condition, and that the proper aim of work is to provide leisure. He wanted shorter working hours and longer holidays for all.[48]
",4
4111,"Keynes was interested in literature in general and drama in particular and supported the Cambridge Arts Theatre financially, which allowed the institution to become one of the major British stages outside London.[110]
",4
4112,"Keynes's interest in classical opera and dance led him to support the Royal Opera House at Covent Garden and the Ballet Company at Sadler's Wells. During the war, as a member of CEMA (Council for the Encouragement of Music and the Arts), Keynes helped secure government funds to maintain both companies while their venues were shut. Following the war, Keynes was instrumental in establishing the Arts Council of Great Britain and was its founding chairman in 1946. From the start, the two organisations that received the largest grants from the new body were the Royal Opera House and Sadler's Wells.
",4
4113,"Like several other notable British authors of his time, Keynes was a member of the Bloomsbury Group. Virginia Woolf's biographer tells an anecdote of how Virginia Woolf, Keynes, and T. S. Eliot discussed religion at a dinner party, in the context of their struggle against Victorian era morality.[164]
Keynes may have been confirmed,[165] but according to Cambridge University he was clearly an agnostic, which he remained until his death.[166] According to one biographer, ""he was never able to take religion seriously, regarding it as a strange aberration of the human mind.""[165]
",4
4114,"Keynes was ultimately a successful investor, building up a private fortune. His assets were nearly wiped out following the Wall Street Crash of 1929, which he did not foresee, but he soon recouped. At Keynes's death, in 1946, his net worth stood just short of £500,000 – equivalent to about £20.5 million ($27.1 million) in 2018. The sum had been amassed despite lavish support for various charities and philanthropies, and his ethic which made him reluctant to sell on a falling market, in cases where he saw such behaviour as likely to deepen a slump.[167]
",4
4115,"Keynes managed the endowment of King's College, Cambridge starting in the 1920s, initially with an unsuccessful strategy based on market timing but later shifting to focus in the publicly traded stock of small and medium size companies that paid large dividends.[168] This was a controversial decision at the time, as stocks were considered high-risk and the centuries-old endowment had traditionally been invested in agricultural land and fixed income assets like bonds.[169] Keynes was granted permission to invest a small minority of assets in stocks, and his adroit management resulted this portion of the endowment growing to become the majority of the endowment's assets.[169] The active component of his portfolio outperformed a British equity index by an average of 6%[168] to 8% a year over a quarter century, earning him favourable mention by later investors such as Warren Buffett and George Soros.[170] Joel Tillinghast of Fidelity Investments describes Keynes as an early practitioner of value investing, a school of thought formalized in the U.S. by Benjamin Graham and David Dodd at Columbia Business School during the 1920s and '30s,[168] but Keynes is believed to have developed his ideas independently.[169]
",4
4116,"Keynes built up a substantial collection of fine art, including works by Paul Cézanne, Edgar Degas, Amedeo Modigliani, Georges Braque, Pablo Picasso, and Georges Seurat (some of which can now be seen at the Fitzwilliam Museum).[110] He enjoyed collecting books; he collected and protected many of Isaac Newton's papers. In part on the basis of these papers, Keynes wrote of Newton as ""the last of the magicians.""[171]
",4
4117,"Keynes was a lifelong member of the Liberal Party, which until the 1920s had been one of the two main political parties in the United Kingdom, and as late as 1916 had often been the dominant power in government. Keynes had helped campaign for the Liberals at elections from about 1906, yet he always refused to run for office himself, despite being asked to do so on three separate occasions in 1920. From 1926, when Lloyd George became leader of the Liberals, Keynes took a major role in defining the party's economic policy, but by then the Liberals had been displaced into third-party status by the growing workers-oriented Labour Party.[13]
",4
4118,"In 1939 Keynes had the option to enter Parliament as an independent MP with the University of Cambridge seat. A by-election for the seat was to be held due to the illness of an elderly Tory, and the master of Magdalene College had obtained agreement that none of the major parties would field a candidate if Keynes chose to stand. Keynes declined the invitation as he felt he would wield greater influence on events if he remained a free agent.[27]
",4
4119,"Keynes was a proponent of eugenics.[172] He served as director of the British Eugenics Society from 1937 to 1944. As late as 1946, shortly before his death, Keynes declared eugenics to be ""the most important, significant and, I would add, genuine branch of sociology which exists.""[173]
",4
4120,"Keynes once remarked that ""the youth had no religion save communism and this was worse than nothing.""[164] Marxism ""was founded upon nothing better than a misunderstanding of Ricardo"", and, given time, he (Keynes) ""would deal thoroughly with the Marxists"" and other economists to solve the economic problems their theories ""threaten to cause"".[164]
",4
4121,"In 1931 Keynes had the following to say on Marxism:[174]
",4
4122,"How can I accept the Communist doctrine, which sets up as its bible, above and beyond criticism, an obsolete textbook which I know not only to be scientifically erroneous but without interest or application to the modern world? How can I adopt a creed which, preferring the mud to the fish, exalts the boorish proletariat above the bourgeoisie and the intelligentsia, who with all their faults, are the quality of life and surely carry the seeds of all human achievement? Even if we need a religion, how can we find it in the turbid rubbish of the red bookshop? It is hard for an educated, decent, intelligent son of Western Europe to find his ideals here, unless he has first suffered some strange and horrid process of conversion which has changed all his values.",4
4123,"Keynes was a firm supporter of women's rights and in 1932 became vice-chairman of the Marie Stopes Society which provided birth control education. He also campaigned against job discrimination against women and unequal pay. He was an outspoken campaigner for reform of the laws against homosexuality.[48]
",4
4124,"Throughout his life, Keynes worked energetically for the benefit both of the public and his friends; even when his health was poor, he laboured to sort out the finances of his old college.[175] Helping to set up the Bretton Woods system, he worked to institute an international monetary system that would be beneficial for the world economy. In 1946, Keynes suffered a series of heart attacks, which ultimately proved fatal. They began during negotiations for the Anglo-American loan in Savannah, Georgia, where he was trying to secure favourable terms for the United Kingdom from the United States, a process he described as ""absolute hell"".[37][176] A few weeks after returning from the United States, Keynes died of a heart attack at Tilton, his farmhouse home near Firle, East Sussex, England, on 21 April 1946, at the age of 62.[13][177] Against his wishes (he wanted his ashes to be deposited in the crypt at King's), his ashes were scattered on the Downs above Tilton.[178]
",4
4125,"Both of Keynes's parents outlived him: his father John Neville Keynes (1852–1949) by three years, and his mother Florence Ada Keynes (1861–1958) by twelve. Keynes's brother Sir Geoffrey Keynes (1887–1982) was a distinguished surgeon, scholar, and bibliophile. His nephews include Richard Keynes (1919–2010), a physiologist, and Quentin Keynes (1921–2003), an adventurer and bibliophile. Keynes had no children; his widow, Lydia Lopokova, died in 1981.
",4
4126,"(A partial list.)
",4
4127,"
",4
4128,"Free trade is a trade policy that does not restrict imports or exports. It can also be understood as the free market idea applied to international trade. In government, free trade is predominantly advocated by political parties that hold liberal economic positions while economically left-wing and nationalist political parties generally support protectionism,[1][2][3][4] the opposite of free trade.
",4
4129,"Most nations are today members of the World Trade Organization multilateral trade agreements. Free trade was best exemplified by the unilateral stance of Great Britain who reduced regulations and duties on imports and exports from the mid-nineteenth century to the 1920s.[5] An alternative approach, of creating free trade areas between groups of countries by agreement, such as that of the European Economic Area and the Mercosur open markets, creates a protectionist barrier between that free trade area and the rest of the world. Most governments still impose some protectionist policies that are intended to support local employment, such as applying tariffs to imports or subsidies to exports. Governments may also restrict free trade to limit exports of natural resources. Other barriers that may hinder trade include import quotas, taxes and non-tariff barriers, such as regulatory legislation.
",4
4130,"Historically, openness to free trade substantially increased from 1815 to the outbreak of World War I. Trade openness increased again during the 1920s, but collapsed (in particular in Europe and North America) during the Great Depression. Trade openness increased substantially again from the 1950s onwards (albeit with a slowdown during the oil crisis of the 1970s). Economists and economic historians contend that current levels of trade openness are the highest they have ever been.[6][7][8]
",4
4131,"Economists are generally supportive of free trade.[9] There is a broad consensus among economists that protectionism has a negative effect on economic growth and economic welfare while free trade and the reduction of trade barriers has a positive effect on economic growth[10][11][12][13][14][15] and economic stability.[16] However, liberalization of trade can cause significant and unequally distributed losses and the economic dislocation of workers in import-competing sectors.[11]
",4
4132,"Free trade policies may promote the following features:[citation needed]
",4
4133,"Two simple ways to understand the proposed benefits of free trade are through David Ricardo's theory of comparative advantage and by analyzing the impact of a tariff or import quota. An economic analysis using the law of supply and demand and the economic effects of a tax can be used to show the theoretical benefits and disadvantages of free trade.[17][18]
",4
4134,"Most economists would recommend that even developing nations should set their tariff rates quite low, but the economist Ha-Joon Chang, a proponent of industrial policy, believes higher levels may be justified in developing nations because the productivity gap between them and developed nations today is much higher than what developed nations faced when they were at a similar level of technological development. Underdeveloped nations today, Chang believes, are weak players in a much more competitive system.[19][20] Counterarguments to Chang's point of view are that the developing countries are able to adopt technologies from abroad whereas developed nations had to create new technologies themselves and that developing countries can sell to export markets far richer than any that existed in the 19th century.
",4
4135,"If the chief justification for a tariff is to stimulate infant industries, it must be high enough to allow domestic manufactured goods to compete with imported goods in order to be successful. This theory, known as import substitution industrialization, is largely considered ineffective for currently developing nations.[19]
",4
4136,"The chart at the right analyzes the effect of the imposition of an import tariff on some imaginary good. Prior to the tariff, the price of the good in the world market (and hence in the domestic market) is Pworld. The tariff increases the domestic price to Ptariff. The higher price causes domestic production to increase from QS1 to QS2 and causes domestic consumption to decline from QC1 to QC2.[21][22]
",4
4137,"This has three main effects on societal welfare. Consumers are made worse off because the consumer surplus (green region) becomes smaller. Producers are better off because the producer surplus (yellow region) is made larger. The government also has additional tax revenue (blue region). However, the loss to consumers is greater than the gains by producers and the government. The magnitude of this societal loss is shown by the two pink triangles. Removing the tariff and having free trade would be a net gain for society.[21][22]
",4
4138,"An almost identical analysis of this tariff from the perspective of a net producing country yields parallel results. From that country's perspective, the tariff leaves producers worse off and consumers better off, but the net loss to producers is larger than the benefit to consumers (there is no tax revenue in this case because the country being analyzed is not collecting the tariff). Under similar analysis, export tariffs, import quotas and export quotas all yield nearly identical results.[17]
",4
4139,"Sometimes consumers are better off and producers worse off and sometimes consumers are worse off and producers are better off, but the imposition of trade restrictions causes a net loss to society because the losses from trade restrictions are larger than the gains from trade restrictions. Free trade creates winners and losers, but theory and empirical evidence show that the size of the winnings from free trade are larger than the losses.[17]
",4
4140,"Economic models indicate that free trade leads to greater technology adoption and innovation.[23][24]
",4
4141,"According to mainstream economics theory, the selective application of free trade agreements to some countries and tariffs on others can lead to economic inefficiency through the process of trade diversion. It is efficient for a good to be produced by the country which is the lowest cost producer, but this does not always take place if a high cost producer has a free trade agreement while the low cost producer faces a high tariff. Applying free trade to the high cost producer and not the low cost producer as well can lead to trade diversion and a net economic loss. This reason is why many economists place such high importance on negotiations for global tariff reductions, such as the Doha Round.[17]
",4
4142,"The literature analysing the economics of free trade is rich. Economists have done extensive work on the theoretical and empirical effects of free trade. Although it creates winners and losers, the broad consensus among economists is that free trade provides a net gain for society.[25][26] In a 2006 survey of American economists (83 responders), ""87.5% agree that the U.S. should eliminate remaining tariffs and other barriers to trade"" and ""90.1% disagree with the suggestion that the U.S. should restrict employers from outsourcing work to foreign countries"".[27]
",4
4143,"Quoting Harvard economics professor N. Gregory Mankiw, ""[f]ew propositions command as much consensus among professional economists as that open world trade increases economic growth and raises living standards"".[28] In a survey of leading economists, none disagreed with the notion that ""freer trade improves productive efficiency and offers consumers better choices, and in the long run these gains are much larger than any effects on employment"".[29]
",4
4144,"Most economists would agree[citation needed] that although increasing returns to scale might mean that a certain industry could settle in a particular geographical area without any strong economic reason derived from comparative advantage, this is not a reason to argue against free trade because the absolute level of output enjoyed by both winner and loser will increase, with the winner gaining more than the loser, but both gaining more than before in an absolute level.[citation needed]
",4
4145,"An overwhelming number of people internationally – both in developed and developing countries – support trade with other countries, but are more split when it comes to whether or not they believe trade creates jobs, increases wages, and decreases prices.[30] The median belief in advanced economies is that trade increase increases wages, with 31 percent of people believing they do, compared to 27 percent who they decrease wages. In emerging economies, 47 percent of people believe trade increases wages, compared to 20 percent who says it lowers wages. There is a positive relationship of 0.66 between the average GDP growth rate for the years 2014 to 2017 and the percentage of people in a given country that says trade increases wages.[31] Most people, in both advanced and emerging economies, believe that trade increases prices. 35 percent of people in advanced economies and 56 percent in emerging economies believe trade increases prices, and 29 percent and 18 percent, respectively, believe that trade lowers prices. Those with a higher level of education are more likely than those with less education to believe that trade lowers prices.[32]
",4
4146,"The notion of a free trade system encompassing multiple sovereign states originated in a rudimentary form in 16th century Imperial Spain.[33] American jurist Arthur Nussbaum noted that Spanish theologian Francisco de Vitoria was ""the first to set forth the notions (though not the terms) of freedom of commerce and freedom of the seas"".[34] Vitoria made the case under principles of jus gentium.[34] However, it was two early British economists Adam Smith and David Ricardo who later developed the idea of free trade into its modern and recognizable form.
",4
4147,"Economists who advocated free trade believed trade was the reason why certain civilizations prospered economically. For example, Smith pointed to increased trading as being the reason for the flourishing of not just Mediterranean cultures such as Egypt, Greece and Rome, but also of Bengal (East India) and China. Netherlands prospered greatly after throwing off Spanish Imperial rule and pursuing a policy of free trade.[35] This made the free trade/mercantilist dispute the most important question in economics for centuries. Free trade policies have battled with mercantilist, protectionist, isolationist, socialist, populist and other policies over the centuries.
",4
4148,"The Ottoman Empire had liberal free trade policies by the 18th century, with origins in capitulations of the Ottoman Empire, dating back to the first commercial treaties signed with France in 1536 and taken further with capitulations in 1673, in 1740 which lowered duties to only 3% for imports and exports and in 1790. Ottoman free trade policies were praised by British economists advocating free trade such as J. R. McCulloch in his Dictionary of Commerce (1834), but criticized by British politicians opposing free trade such as Prime Minister Benjamin Disraeli, who cited the Ottoman Empire as ""an instance of the injury done by unrestrained competition"" in the 1846 Corn Laws debate, arguing that it destroyed what had been ""some of the finest manufactures of the world"" in 1812.[36]
",4
4149,"Trade in colonial America was regulated by the British mercantile system through the Acts of Trade and Navigation. Until the 1760s, few colonists openly advocated for free trade, in part because regulations were not strictly enforced (New England was famous for smuggling), but also because colonial merchants did not want to compete with foreign goods and shipping. According to historian Oliver Dickerson, a desire for free trade was not one of the causes of the American Revolution. ""The idea that the basic mercantile practices of the eighteenth century were wrong"", wrote Dickerson, ""was not a part of the thinking of the Revolutionary leaders"".[37]
",4
4150,"Free trade came to what would become the United States as a result of the American Revolution. After the British Parliament issued the Prohibitory Act in 1775, blockading colonial ports, the Continental Congress responded by effectively declaring economic independence, opening American ports to foreign trade on 6 April 1776 - three months before declaring sovereign independence. According to historian John W. Tyler, ""[f]ree trade had been forced on the Americans, like it or not"".[38]
",4
4151,"In March 1801, the Pope Pius VII ordered some liberalization of trade to face the economic crisis in the Papal States with the motu proprio Le più colte. Despite this, the export of national corn was forbidden to ensure the food for the Papal States.
",4
4152,"In Britain, free trade became a central principle practiced by the repeal of the Corn Laws in 1846. Large-scale agitation was sponsored by the Anti-Corn Law League. Under the Treaty of Nanking, China opened five treaty ports to world trade in 1843. The first free trade agreement, the Cobden-Chevalier Treaty, was put in place in 1860 between Britain and France which led to successive agreements between other countries in Europe.[39]
",4
4153,"Many classical liberals, especially in 19th and early 20th century Britain (e.g. John Stuart Mill) and in the United States for much of the 20th century (e.g. Henry Ford and Secretary of State Cordell Hull), believed that free trade promoted peace. Woodrow Wilson included free-trade rhetoric in his ""Fourteen Points"" speech of 1918:
",4
4154,"The program of the world's peace, therefore, is our program; and that program, the only possible program, all we see it, is this: [...]
3. The removal, so far as possible, of all economic barriers and the establishment of equality of trade conditions among all the nations consenting to the peace and associating themselves for its maintenance.[40]",4
4155,"According to economic historian Douglas Irwin, a common myth about United States trade policy is that low tariffs harmed American manufacturers in the early 19th century and then that high tariffs made the United States into a great industrial power in the late 19th century.[41] A review by the Economist of Irwin's 2017 book Clashing over Commerce: A History of US Trade Policy notes:[41]
",4
4156,"Political dynamics would lead people to see a link between tariffs and the economic cycle that was not there. A boom would generate enough revenue for tariffs to fall, and when the bust came pressure would build to raise them again. By the time that happened, the economy would be recovering, giving the impression that tariff cuts caused the crash and the reverse generated the recovery. Mr Irwin also methodically debunks the idea that protectionism made America a great industrial power, a notion believed by some to offer lessons for developing countries today. As its share of global manufacturing powered from 23% in 1870 to 36% in 1913, the admittedly high tariffs of the time came with a cost, estimated at around 0.5% of GDP in the mid-1870s. In some industries, they might have sped up development by a few years. But American growth during its protectionist period was more to do with its abundant resources and openness to people and ideas.",4
4157,"According to Paul Bairoch, since the end of the 18th century, the United States has been ""the homeland and bastion of modern protectionism"". In fact, the United States never adhered to free trade until 1945. For the most part, the Jeffersonians strongly opposed it. In the 19th century, statesmen such as Senator Henry Clay continued Alexander Hamilton's themes within the Whig Party under the name American System. The opposition Democratic Party contested several elections throughout the 1830s, 1840s and 1850s in part over the issue of the tariff and protection of industry.[42] The Democratic Party favored moderate tariffs used for government revenue only while the Whigs favored higher protective tariffs to protect favored industries. The economist Henry Charles Carey became a leading proponent of the American System of economics. This mercantilist American System was opposed by the Democratic Party of Andrew Jackson, Martin Van Buren, John Tyler, James K. Polk, Franklin Pierce and James Buchanan.
",4
4158,"The fledgling Republican Party led by Abraham Lincoln, who called himself a ""Henry Clay tariff Whig"", strongly opposed free trade and implemented a 44% tariff during the Civil War, in part to pay for railroad subsidies and for the war effort and in part to protect favored industries.[43] William McKinley (later to become President of the United States) stated the stance of the Republican Party (which won every election for president from 1868 until 1912, except the two non-consecutive terms of Grover Cleveland) as thus:
",4
4159,"Under free trade the trader is the master and the producer the slave. Protection is but the law of nature, the law of self-preservation, of self-development, of securing the highest and best destiny of the race of man. [It is said] that protection is immoral [...]. Why, if protection builds up and elevates 63,000,000 [the U.S. population] of people, the influence of those 63,000,000 of people elevates the rest of the world. We cannot take a step in the pathway of progress without benefitting mankind everywhere. Well, they say, 'Buy where you can buy the cheapest'…. Of course, that applies to labor as to everything else. Let me give you a maxim that is a thousand times better than that, and it is the protection maxim: 'Buy where you can pay the easiest.' And that spot of earth is where labor wins its highest rewards.[44]",4
4160,"During the interwar period, economic protectionism took hold in the United States, most famously in the form of the Smoot–Hawley Tariff Act which is credited by economists with the prolonging and worldwide propagation of the Great Depression.[45]:33[46] From 1934, trade liberalization began to take place through the Reciprocal Trade Agreements Act.
",4
4161,"Since the end of World War II, in part due to industrial size and the onset of the Cold War, the United States has often been a proponent of reduced tariff-barriers and free trade. The United States helped establish the General Agreement on Tariffs and Trade and later the World Trade Organization, although it had rejected an earlier version in the 1950s, the International Trade Organization.[47][citation needed] Since the 1970s, United States governments have negotiated managed-trade agreements, such as the North American Free Trade Agreement in the 1990s, the Dominican Republic-Central America Free Trade Agreement in 2006 and a number of bilateral agreements (such as with Jordan).[citation needed]
",4
4162,"In Europe, six countries formed the European Coal and Steel Community in 1951 which became the European Economic Community (EEC) in 1958. Two core objectives of the EEC were the development of a common market, subsequently renamed the single market, and establishing a customs union between its member states. After expanding its membership, the EEC became the European Union in 1993. The European Union, now the world's largest single market,[48] has concluded free trade agreements with many countries around the world.[49]
",4
4163,"Most countries in the world are members of the World Trade Organization[50] which limits in certain ways but does not eliminate tariffs and other trade barriers. Most countries are also members of regional free trade areas that lower trade barriers among participating countries. The European Union and the United States are negotiating a Transatlantic Trade and Investment Partnership. in 2018, the Comprehensive and Progressive Agreement for Trans-Pacific Partnership came into force, which includes eleven countries that have borders on the Pacific Ocean.
",4
4164,"Free trade may apply to trade in services as well as in goods. Non-economic considerations may inhibit free trade as a country may espouse free trade in principle, but ban certain drugs (such as alcohol) or certain practices (such as prostitution)[51] and limiting international free trade.
",4
4165,"Some degree of protectionism is nevertheless the norm throughout the world. Most developed nations maintain controversial[citation needed] agricultural tariffs. From 1820 to 1980, the average tariffs on manufactures in twelve industrial countries ranged from 11 to 32%. In the developing world, average tariffs on manufactured goods are approximately 34%.[52] The American economist C. Fred Bergsten devised the bicycle theory to describe trade policy. According to this model, trade policy is dynamically unstable in that it constantly tends towards either liberalisation or protectionism. To prevent falling off the bike (the disadvantages of protectionism), trade policy and multilateral trade negotiations must constantly pedal towards greater liberalisation. To achieve greater liberalisation, decision makers must appeal to the greater welfare for consumers and the wider national economy over narrower parochial interests. However, Bergsten also posits that it is also necessary to compensate the losers in trade and help them find new work as this will both reduce the backlash against globalisation and the motives for trades unions and politicians to call for protection of trade.[53]
",4
4166,"In Kicking Away the Ladder, development economist Ha-Joon Chang reviews the history of free trade policies and economic growth and notes that many of the now-industrialized countries had significant barriers to trade throughout their history. The United States and Britain, sometimes considered the homes of free trade policy, employed protectionism to varying degrees at all times. Britain abolished the Corn Laws which restricted import of grain in 1846 in response to domestic pressures and reduced protectionism for manufactures only in the mid 19th century when its technological advantage was at its height, but tariffs on manufactured products had returned to 23% by 1950. The United States maintained weighted average tariffs on manufactured products of approximately 40–50% up until the 1950s, augmented by the natural protectionism of high transportation costs in the 19th century.[54] The most consistent practitioners of free trade have been Switzerland, the Netherlands and to a lesser degree Belgium.[55] Chang describes the export-oriented industrialization policies of the Four Asian Tigers as ""far more sophisticated and fine-tuned than their historical equivalents"".[56]
",4
4167,"The Global Enabling Trade Report measures the factors, policies and services that facilitate the trade in goods across borders and to destinations. The index summarizes four sub-indexes, namely market access; border administration; transport and communications infrastructure; and business environment. As of 2016, the top 30 countries and areas were the following:[57]
",4
4168,"Academics, governments and interest groups debate the relative costs, benefits and beneficiaries of free trade.
",4
4169,"
Arguments for protectionism fall into the economic category (trade hurts the economy or groups in the economy) or into the moral category (the effects of trade might help the economy, but have ill effects in other areas). A general argument against free trade is that it represents colonialism or imperialism in disguise.[citation needed]",4
4170," The moral category is wide, including concerns about:[58][better source needed]
",4
4171,"However, poor countries that have adopted free-trade policies have experienced high economic growth, with China and India as prime examples. Free trade allows companies from rich countries to directly invest in poor countries, sharing their knowledge, providing capital and giving access to markets.
",4
4172,"Economic arguments against free trade criticize the assumptions or conclusions of economic theories. Sociopolitical arguments against free trade cite social and political effects that economic arguments do not capture, such as political stability, national security, human rights and environmental protection.[citation needed]  Some products are important to national security and governments may deem it dangerous to allow domestic producers of these products to go out of business, especially if otherwise they might come to depend on producers who operate in a country that may one day become an enemy. Countries that allow low wages have a competitive advantage in attracting industry, which may lead to a general lowering of wages for workers in all countries.[citation needed] Some countries may facilitate low-cost production of goods in their countries by allowing pollution of the environment: their pricing ignores environmental full-cost accounting and hidden costs are paid by their local, national and international neighbours.[citation needed]
",4
4173,"Domestic industries often oppose free trade on the grounds that it would lower prices for imported goods would reduce their profits and market share.[59][60] For example, if the United States reduced tariffs on imported sugar, sugar producers would receive lower prices and profits, and sugar consumers would spend less for the same amount of sugar because of those same lower prices. The economic theory of David Ricardo holds that consumers would necessarily gain more than producers would lose.[61][62] Since each of the domestic sugar producers would lose a lot while each of a great number of consumers would gain only a little, domestic producers are more likely to mobilize against the reduction in tariffs.[60] More generally, producers often favor domestic subsidies and tariffs on imports in their home countries while objecting to subsidies and tariffs in their export markets.
",4
4174,"Socialists frequently oppose free trade on the ground that it allows maximum exploitation of workers by capital. For example, Karl Marx wrote in The Communist Manifesto (1848): ""The bourgeoisie [...] has set up that single, unconscionable freedom – free trade. In one word, for exploitation, veiled by religious and political illusions, it has substituted naked, shameless, direct, brutal exploitation"".  Marx supported free trade, however, solely because he felt that it would hasten the social revolution.[65]
",4
4175,"Many anti-globalization groups oppose free trade based on their assertion that free-trade agreements generally do not increase the economic freedom of the poor or of the working class and frequently make them poorer.
",4
4176,"Some opponents of free trade favor free-trade theory, but oppose free-trade agreements as applied. Some opponents of NAFTA see the agreement as materially harming the common people, but some of the arguments are actually against the particulars of government-managed trade, rather than against free trade per se. For example, it is argued that it would be wrong to let subsidized corn from the United States into Mexico freely under NAFTA at prices well below production cost (dumping) because of its ruinous effects to Mexican farmers. Indeed, such subsidies violate free-trade theory, so this argument is not actually against the principle of free trade, but rather against its selective implementation.[citation needed]
",4
4177,"
Research shows that support for trade restrictions is highest among respondents with the lowest levels of education.[66] Hainmueller and Hiscox find ",4
4178,"""that the impact of education on how voters think about trade and globalization has more to do with exposure to economic ideas and information about the aggregate and varied effects of these economic phenomena, than it does with individual calculations about how trade affects personal income or job security. This is not to say that the latter types of calculations are not important in shaping individuals' views of trade – just that they are not being manifest in the simple association between education and support for trade openness"".[66]",4
4179," A 2017 study found that individuals whose occupations are routine-task-intensive and who do jobs that are offshorable are more likely to favor protectionism.[67]
",4
4180,"Research suggests that attitudes towards free trade do not necessarily reflect individuals' self-interests.[68][69]
",4
4181,"Various proponents of economic nationalism and of the school of mercantilism have long portrayed free trade as a form of colonialism or imperialism. In the 19th century, such groups criticized British calls for free trade as cover for British Empire, notably in the works of American Henry Clay, architect of the American System[70] and of the German-American economist Friedrich List (1789-1846).[71]
",4
4182,"Free-trade debates and associated matters involving the colonial administration of Ireland[72]
have periodically (such as in 1846 and 1906) caused ructions in the British Conservative (Tory) Party (Corn Law issues in the 1820s to the 1840s, Irish Home Rule issues throughout the 19th and early-20th centuries).
",4
4183,"Ecuadorian President Rafael Correa (in office from 2007 to 2017) denounced the ""sophistry of free trade"" in an introduction he wrote for a 2006 book,The Hidden Face of Free Trade Accords,[73] which was written in part by Correa's Energy Minister Alberto Acosta. Citing as his source the 2002 book Kicking Away the Ladder written by Ha-Joon Chang,[74]
Correa identified the difference between an ""American system"" opposed to a ""British System"" of free trade. The Americans explicitly viewed the latter, he says, as ""part of the British imperialist system"". According to Correa, Chang showed that Treasury Secretary Alexander Hamilton (in office 1789–1795), rather than List, first presented a systematic argument defending industrial protectionism.
",4
4184,"The following alternatives to free trade have been proposed: protectionism,[75] imperialism,[76][failed verification] balanced trade,[citation needed] fair trade,[citation needed] and industrial policy.[citation needed]
",4
4185,"The value of free trade was first observed and documented in 1776 by Adam Smith in The Wealth of Nations, writing:[77]
",4
4186,"It is the maxim of every prudent master of a family, never to attempt to make at home what it will cost him more to make than to buy. [...] If a foreign country can supply us with a commodity cheaper than we ourselves can make it, better buy it of them with some part of the produce of our own industry, employed in a way in which we have some advantage.[78]",4
4187,"This statement uses the concept of absolute advantage to present an argument in opposition to mercantilism, the dominant view surrounding trade at the time which held that a country should aim to export more than it imports and thus amass wealth.[79] Instead, Smith argues, countries could gain from each producing exclusively the goods in which they are most suited to, trading between each other as required for the purposes of consumption. In this vein, it is not the value of exports relative to that of imports that is important, but the value of the goods produced by a nation. However, the concept of absolute advantage does not address a situation where a country has no advantage in the production of a particular good or type of good.[80]
",4
4188,"This theoretical shortcoming was addressed by the theory of comparative advantage. Generally attributed to David Ricardo, who expanded on it in his 1817 book On the Principles of Political Economy and Taxation,[81] it makes a case for free trade based not on absolute advantage in production of a good, but on the relative opportunity costs of production. A country should specialize in whatever good it can produce at the lowest cost, trading this good to buy other goods it requires for consumption. This allows for countries to benefit from trade even when they do not have an absolute advantage in any area of production. While their gains from trade might not be equal to those of a country more productive in all goods, they will still be better off economically from trade than they would be under a state of autarky.[82][83]
",4
4189,"Exceptionally, Henry George's 1886 book Protection or Free Trade was read out loud in full into the Congressional Record by five Democratic congressmen.[84][85] American economist Tyler Cowen wrote that Protection or Free Trade ""remains perhaps the best-argued tract on free trade to this day"".[86] Although George is very critical towards protectionism, he discusses the subject in particular with respect to the interests of labor:
",4
4190,"We all hear with interest and pleasure of improvements in transportation by water or land; we are all disposed to regard the opening of canals, the building of railways, the deepening of harbors, the improvement of steamships as beneficial. But if such things are beneficial, how can tariffs be beneficial? The effect of such things is to lessen the cost of transporting commodities; the effect of tariffs is to increase it. If the protective theory be true, every improvement that cheapens the carriage of goods between country and country is an injury to mankind unless tariffs be commensurately increased.[87]",4
4191,"George considers the general free trade argument inadequate. He argues that the removal of protective tariffs alone is never sufficient to improve the situation of the working class, unless accompanied by a shift towards land value tax.[88]
",4
4192,"
",4
4193,"
",4
4194,"
",4
4195,"Capitalism is an economic system based on the private ownership of the means of production and their operation for profit.[1][2][3][4] Central characteristics of capitalism include capital accumulation, competitive markets, a price system, private property and the recognition of property rights, voluntary exchange and wage labor.[5][6] In a capitalist market economy, decision-making and investments are determined by every owner of wealth, property or production ability in capital and financial markets whereas prices and the distribution of goods and services are mainly determined by competition in goods and services markets.[7]
",4
4196,"Economists, historians, political economists and sociologists have adopted different perspectives in their analyses of capitalism and have recognized various forms of it in practice. These include laissez-faire or free-market capitalism, state capitalism and welfare capitalism. Different forms of capitalism feature varying degrees of free markets, public ownership,[8] obstacles to free competition and state-sanctioned social policies. The degree of competition in markets and the role of intervention and regulation as well as the scope of state ownership vary across different models of capitalism.[9][10] The extent to which different markets are free and the rules defining private property are matters of politics and policy. Most of the existing capitalist economies are mixed economies that combine elements of free markets with state intervention and in some cases economic planning.[11]
",4
4197,"Market economies have existed under many forms of government and in many different times, places and cultures. Modern capitalist societies—marked by a universalization of money-based social relations, a consistently large and system-wide class of workers who must work for wages (the proletariat) and a capitalist class which owns the means of production—developed in Western Europe in a process that led to the Industrial Revolution. Capitalist systems with varying degrees of direct government intervention have since become dominant in the Western world and continue to spread. Constant economic growth is a characteristic tendency of capitalist economies.[12]
",4
4198,"Critics of capitalism argue that it concentrates power in the hands of a minority capitalist class that exists through the exploitation of the majority working class and their labor; prioritizes profit over social good, natural resources and the environment; is an engine of inequality, corruption and economic instabilities; and that many are not able to access its purported benefits and freedoms, such as freely investing. Supporters argue that it provides better products and innovation through competition, promotes pluralism and decentralization of power, disperses wealth to people who are able to invest in useful enterprises based on market demands, allows for a flexible incentive system where efficiency and sustainability are priorities to protect capital, creates strong economic growth, and yields productivity and prosperity that greatly benefit society.
",4
4199,"The term ""capitalist"", meaning an owner of capital, appears earlier than the term ""capitalism"" and dates to the mid-17th century. ""Capitalism"" is derived from capital, which evolved from capitale, a late Latin word based on caput, meaning ""head""—which is also the origin of ""chattel"" and ""cattle"" in the sense of movable property (only much later to refer only to livestock). Capitale emerged in the 12th to 13th centuries to refer to funds, stock of merchandise, sum of money or money carrying interest.[24]:232[25] By 1283, it was used in the sense of the capital assets of a trading firm and was often interchanged with other words—wealth, money, funds, goods, assets, property and so on.[24]:233
",4
4200,"The Hollantse (German: holländische) Mercurius uses ""capitalists"" in 1633 and 1654 to refer to owners of capital.[24]:234 In French, Étienne Clavier referred to capitalistes in 1788,[26] six years before its first recorded English usage by Arthur Young in his work Travels in France (1792).[25][27] In his Principles of Political Economy and Taxation (1817), David Ricardo referred to ""the capitalist"" many times.[28] English poet Samuel Taylor Coleridge used ""capitalist"" in his work Table Talk (1823).[29] Pierre-Joseph Proudhon used the term in his first work, What is Property? (1840), to refer to the owners of capital. Benjamin Disraeli used the term in his 1845 work Sybil.[25]
",4
4201,"The initial use of the term ""capitalism"" in its modern sense is attributed to Louis Blanc in 1850 (""What I call 'capitalism' that is to say the appropriation of capital by some to the exclusion of others"") and Pierre-Joseph Proudhon in 1861 (""Economic and social regime in which capital, the source of income, does not generally belong to those who make it work through their labor"").[24]:237 Karl Marx and Friedrich Engels referred to the ""capitalistic system""[30][31] and to the ""capitalist mode of production"" in Capital (1867).[32] The use of the word ""capitalism"" in reference to an economic system appears twice in Volume I of Capital, p. 124 (German Edition) and in Theories of Surplus Value, volume II, p. 493 (German Edition). Marx did not extensively use the form capitalism, but instead capitalist and capitalist mode of production, which appear more than 2,600 times in the trilogy Capital (Das Kapital).
",4
4202,"In the English language, the term ""capitalism"" first appears, according to the Oxford English Dictionary (OED), in 1854, in the novel The Newcomes by novelist William Makepeace Thackeray, where the word meant ""having ownership of capital"".[33] Also according to the OED, Carl Adolph Douai, a German American socialist and abolitionist, used the term ""private capitalism"" in 1863.
",4
4203,"Capitalism in its modern form can be traced to the emergence of agrarian capitalism and mercantilism in the early Renaissance, in city-states like Florence.[34] Capital has existed incipiently on a small scale for centuries[35] in the form of merchant, renting and lending activities and occasionally as small-scale industry with some wage labour. Simple commodity exchange and consequently simple commodity production, which is the initial basis for the growth of capital from trade, have a very long history. Arabs promulgated capitalist economic policies such as free trade and banking. Their use of Indo-Arabic numerals facilitated bookkeeping. These innovations migrated to Europe through trade partners in cities such as Venice and Pisa. The Italian mathematician Fibonacci traveled the Mediterranean talking to Arab traders and returned to popularize the use of Indo-Arabic numerals in Europe.[36]
",4
4204,"Capital and commercial trade thus existed for much of history, but until recent centuries it did not lead to industrialization or dominate the production process of society. That required a set of conditions, including specific technologies of mass production, the ability to independently and privately own and trade in means of production, a class of workers willing to sell their labor power for a living, a legal framework promoting commerce, a physical infrastructure allowing the circulation of goods on a large scale and security for private accumulation. Many of these conditions do not currently exist in many Third World countries, although there is plenty of capital and labor. The obstacles for the development of capitalist markets are therefore less technical and more social, cultural and political.
",4
4205,"The economic foundations of the feudal agricultural system began to shift substantially in 16th-century England as the manorial system had broken down and land began to become concentrated in the hands of fewer landlords with increasingly large estates. Instead of a serf-based system of labor, workers were increasingly employed as part of a broader and expanding money-based economy. The system put pressure on both landlords and tenants to increase the productivity of agriculture to make profit; the weakened coercive power of the aristocracy to extract peasant surpluses encouraged them to try better methods, and the tenants also had incentive to improve their methods in order to flourish in a competitive labor market. Terms of rent for land were becoming subject to economic market forces rather than to the previous stagnant system of custom and feudal obligation.[37][38]
",4
4206,"By the early 17th century, England was a centralized state in which much of the feudal order of Medieval Europe had been swept away. This centralization was strengthened by a good system of roads and by a disproportionately large capital city, London. The capital acted as a central market hub for the entire country, creating a very large internal market for goods, contrasting with the fragmented feudal holdings that prevailed in most parts of the Continent.
",4
4207,"The economic doctrine prevailing from the 16th to the 18th centuries is commonly called mercantilism.[39][40] This period, the Age of Discovery, was associated with the geographic exploration of foreign lands by merchant traders, especially from England and the Low Countries. Mercantilism was a system of trade for profit, although commodities were still largely produced by non-capitalist methods.[41] Most scholars consider the era of merchant capitalism and mercantilism as the origin of modern capitalism,[42][43] although Karl Polanyi argued that the hallmark of capitalism is the establishment of generalized markets for what he called the ""fictitious commodities"", i.e. land, labor and money. Accordingly, he argued that ""not until 1834 was a competitive labor market established in England, hence industrial capitalism as a social system cannot be said to have existed before that date"".[44]
",4
4208,"England began a large-scale and integrative approach to mercantilism during the Elizabethan Era (1558–1603). A systematic and coherent explanation of balance of trade was made public through Thomas Mun's argument England's Treasure by Forraign Trade, or the Balance of our Forraign Trade is The Rule of Our Treasure. It was written in the 1620s and published in 1664.[45]
",4
4209,"European merchants, backed by state controls, subsidies and monopolies, made most of their profits by buying and selling goods. In the words of Francis Bacon, the purpose of mercantilism was ""the opening and well-balancing of trade; the cherishing of manufacturers; the banishing of idleness; the repressing of waste and excess by sumptuary laws; the improvement and husbanding of the soil; the regulation of prices..."".[46]
",4
4210,"After the period of the proto-industrialization, the British East India Company and the Dutch East India Company, after massive contributions from the Mughal Bengal,[47][48] inaugurated an expansive era of commerce and trade.[49][50] These companies were characterized by their colonial and expansionary powers given to them by nation-states.[49] During this era, merchants, who had traded under the previous stage of mercantilism, invested capital in the East India Companies and other colonies, seeking a return on investment.
",4
4211,"In the mid-18th century a group of economic theorists, led by David Hume (1711–1776)[52] and Adam Smith (1723–1790), challenged fundamental mercantilist doctrines – such as the belief that the world's wealth remained constant and that a state could only increase its wealth at the expense of another state.
",4
4212,"During the Industrial Revolution, industrialists replaced merchants as a dominant factor in the capitalist system and effected the decline of the traditional handicraft skills of artisans, guilds and journeymen. Also during this period, the surplus generated by the rise of commercial agriculture encouraged increased mechanization of agriculture.[citation needed] Industrial capitalism marked the development of the factory system of manufacturing, characterized by a complex division of labor between and within work process and the routine of work tasks; and eventually established the domination of the capitalist mode of production.[53]
",4
4213,"Industrial Britain eventually abandoned the protectionist policy formerly prescribed by mercantilism. In the 19th century, Richard Cobden (1804–1865) and John Bright (1811–1889), who based their beliefs on the Manchester School, initiated a movement to lower tariffs.[54] In the 1840s Britain adopted a less protectionist policy, with the 1846 repeal of the Corn Laws and the 1849 repeal of the Navigation Acts.[55] Britain reduced tariffs and quotas, in line with David Ricardo's advocacy of free trade.
",4
4214,"Capitalism was carried across the world by broader processes of globalization and by the beginning of the nineteenth century a series of loosely connected market systems had come together as a relatively integrated global system, in turn intensifying processes of economic and other globalization.[56][57] Later in the 20th century, capitalism overcame a challenge by centrally-planned economies and is now the encompassing system worldwide,[16][58] with the mixed economy being its dominant form in the industrialized Western world.
",4
4215,"Industrialization allowed cheap production of household items using economies of scale while rapid population growth created sustained demand for commodities. Globalization in this period was decisively shaped by 18th-century imperialism.[56][59][60][61]
",4
4216,"
After the First and Second Opium Wars and the completion of the British conquest of India, vast populations of these regions became ready consumers of European exports. Also in this period, areas of sub-Saharan Africa and the Pacific islands were colonized. The conquest of new parts of the globe, notably sub-Saharan Africa, by Europeans yielded valuable natural resources such as rubber, diamonds and coal and helped fuel trade and investment between the European imperial powers, their colonies and the United States: ",4
4217,"The inhabitant of London could order by telephone, sipping his morning tea, the various products of the whole earth, and reasonably expect their early delivery upon his doorstep. Militarism and imperialism of racial and cultural rivalries were little more than the amusements of his daily newspaper. What an extraordinary episode in the economic progress of man was that age which came to an end in August 1914.[62]",4
4218,"In this period, the global financial system was mainly tied to the gold standard. The United Kingdom first formally adopted this standard in 1821. Soon to follow were Canada in 1853, Newfoundland in 1865, the United States and Germany (de jure) in 1873. New technologies, such as the telegraph, the transatlantic cable, the radiotelephone, the steamship and railway allowed goods and information to move around the world at an unprecedented degree.[63]
",4
4219,"In the period following the global depression of the 1930s, the state played an increasingly prominent role in the capitalistic system throughout much of the world. The postwar boom ended in the late 1960s and early 1970s and the situation was worsened by the rise of stagflation.[64] Monetarism, a modification of Keynesianism that is more compatible with laissez-faire, gained increasing prominence in the capitalist world, especially under the leadership of Ronald Reagan in the United States and Margaret Thatcher in the United Kingdom in the 1980s. Public and political interest began shifting away from the so-called collectivist concerns of Keynes's managed capitalism to a focus on individual choice, called ""remarketized capitalism"".[65]
",4
4220,"According to Harvard academic Shoshana Zuboff, a new genus of capitalism, surveillance capitalism monetizes data acquired through surveillance.[66][67][68] She states it was first discovered and consolidated at Google, emerged due to the ""coupling of the vast powers of the digital with the radical indifference and intrinsic narcissism of the financial capitalism and its neoliberal vision that have dominated commerce for at least three decades, especially in the Anglo economies""[67] and depends on the global architecture of computer mediation which produces a distributed and largely uncontested new expression of power she calls ""Big Other"".[69]
",4
4221,"Harvard Kennedy School economist Dani Rodrik distinguishes between three historical variants of capitalism: Capitalism 1.0 during the 19th century entailed largely unregulated markets with a minimal role for the state (aside from national defense, and protecting property rights); Capitalism 2.0 during the post-World War II years entailed Keynesianism, a substantial role for the state in regulating markets, and strong welfare states; and Capitalism 2.1 which entailed a combination of unregulated markets, globalization, and various national obligations by the state.[70]
",4
4222,"The relationship between democracy and capitalism is a contentious area in theory and in popular political movements. The extension of adult male suffrage in 19th-century Britain occurred along with the development of industrial capitalism and democracy became widespread at the same time as capitalism, leading capitalists to posit a causal or mutual relationship between them.[71] However, according to some authors in the 20th-century, capitalism also accompanied a variety of political formations quite distinct from liberal democracies, including fascist regimes, absolute monarchies and single-party states.[40] Democratic peace theory asserts that democracies seldom fight other democracies, but critics[who?] of that theory suggest that this may be because of political similarity or stability rather than because they are democratic or capitalist. Moderate critics argue that though economic growth under capitalism has led to democracy in the past, it may not do so in the future as authoritarian regimes have been able to manage economic growth using some of capitalism's competitive principles[72][73] without making concessions to greater political freedom.[74][75] Political scientists Torben Iversen and David Soskice argue that democracy and capitalism are mutually supportive.[76]
",4
4223,"Milton Friedman, one of the biggest supporters of the idea that capitalism promotes political freedom, argued that competitive capitalism allows economic and political power to be separate, ensuring that they do not clash with one another. Moderate critics have recently challenged this, stating that the current influence lobbying groups have had on policy in the United States is a contradiction, given the approval of Citizens United. This has led people to question the idea that competitive capitalism promotes political freedom. The ruling on Citizens United allows corporations to spend undisclosed and unregulated amounts of money on political campaigns, shifting outcomes in favor of special interests and undermining true democracy. As explained in Robin Hahnel's writings, the centerpiece of the ideological defense of the free market system is the concept of economic freedom and that supporters equate economic democracy with economic freedom and claim that only the free market system can provide economic freedom. According to Hahnel, there are a few objections to the premise that capitalism offers freedom through economic freedom. These objections are guided by critical questions about who or what decides whose freedoms are more protected. Often, the question of inequality is brought up when discussing how well capitalism promotes democracy. An argument that could stand is that economic growth can lead to inequality given that capital can be acquired at different rates by different people. In Capital in the Twenty-First Century (2013), Thomas Piketty of the Paris School of Economics asserted that inequality is the inevitable consequence of economic growth in a capitalist economy and the resulting concentration of wealth can destabilize democratic societies and undermine the ideals of social justice upon which they are built.[77]
",4
4224,"States with capitalistic economic systems have thrived under political regimes deemed to be authoritarian or oppressive. Singapore has a successful open market economy as a result of its competitive, business-friendly climate and robust rule of law. Nonetheless, it often comes under fire for its style of government which, though democratic and consistently one of the least corrupt,[78] operates largely under a one-party rule. Furthermore, it does not vigorously defend freedom of expression as evidenced by its government-regulated press, and it is penchant for upholding laws protecting ethnic and religious harmony, judicial dignity and personal reputation. The private (capitalist) sector in the People's Republic of China has grown exponentially and thrived since its inception, despite having an authoritarian government. Augusto Pinochet's rule in Chile led to economic growth and high levels of inequality[79] by using authoritarian means to create a safe environment for investment and capitalism. Similarly, Suharto's authoritarian reign and extirpation of the Communist Party of Indonesia allowed for the expansion of capitalism in Indonesia.[80][81]
",4
4225,"The term ""capitalism"" in its modern sense is often attributed to Karl Marx.[41][82] In his Das Kapital, Marx analyzed the ""capitalist mode of production"" using a method of understanding today known as Marxism. However, Marx himself rarely used the term ""capitalism"" while it was used twice in the more political interpretations of his work, primarily authored by his collaborator Friedrich Engels. In the 20th century, defenders of the capitalist system often replaced the term ""capitalism"" with phrases such as free enterprise and private enterprise and replaced ""capitalist"" with rentier and investor in reaction to the negative connotations associated with capitalism.[83]
",4
4226,"In general, capitalism as an economic system and mode of production can be summarised by the following:[84]
",4
4227,"In free market and laissez-faire forms of capitalism, markets are used most extensively with minimal or no regulation over the pricing mechanism. In mixed economies, which are almost universal today,[92] markets continue to play a dominant role, but they are regulated to some extent by the state in order to correct market failures, promote social welfare, conserve natural resources, fund defense and public safety or other rationale. In state capitalist systems, markets are relied upon the least, with the state relying heavily on state-owned enterprises or indirect economic planning to accumulate capital.
",4
4228,"Supply is the amount of a good or service that is available for purchase or sale. Demand is the measure of value for a good that people are willing to buy at a given time. Prices tend to rise when demand for an available resource increases or its supply diminishes and fall with demand or when supply increases.
",4
4229,"Competition arises when more than one producer is trying to sell the same or similar products to the same buyers. Adherents of the capitalist theory believe that competition leads to innovation and more affordable prices. Monopolies or cartels can develop, especially if there is no competition. A monopoly occurs when a firm is granted exclusivity over a market. Hence, the firm can engage in rent seeking behaviors such as limiting output and raising prices because it has no fear of competition. A cartel is a group of firms that act together in a monopolistic manner to control output and prices.
",4
4230,"Governments have implemented legislation for the purpose of preventing the creation of monopolies and cartels. In 1890, the Sherman Antitrust Act became the first legislation passed by the United States Congress to limit monopolies.[93]
",4
4231,"The profit motive, in the theory of capitalism, is the desire to earn income in the form of profit. Stated differently, the reason for a business's existence is to turn a profit. The profit motive functions according to rational choice theory, or the theory that individuals tend to pursue what is in their own best interests. Accordingly, businesses seek to benefit themselves and/or their shareholders by maximizing profit.
",4
4232,"In capitalist theoretics, the profit motive is said to ensure that resources are being allocated efficiently. For instance, Austrian economist Henry Hazlitt explains: ""If there is no profit in making an article, it is a sign that the labor and capital devoted to its production are misdirected: the value of the resources that must be used up in making the article is greater than the value of the article itself"".[94] In other words, profits let companies know whether an item is worth producing. Theoretically[according to whom?], in free and competitive markets maximising profit ensures that resources are not wasted.
",4
4233,"The relationship between the state, its formal mechanisms, and capitalist societies has been debated in many fields of social and political theory, with active discussion since the 19th century. Hernando de Soto is a contemporary Peruvian economist who has argued that an important characteristic of capitalism is the functioning state protection of property rights in a formal property system where ownership and transactions are clearly recorded.[95]
",4
4234,"According to de Soto, this is the process by which physical assets are transformed into capital, which in turn may be used in many more ways and much more efficiently in the market economy. A number of Marxian economists have argued that the Enclosure Acts in England and similar legislation elsewhere were an integral part of capitalist primitive accumulation and that specific legal frameworks of private land ownership have been integral to the development of capitalism.[96][97]
",4
4235,"In capitalist economics, market competition is the rivalry among sellers trying to achieve such goals as increasing profits, market share and sales volume by varying the elements of the marketing mix: price, product, distribution and promotion. Merriam-Webster defines competition in business as ""the effort of two or more parties acting independently to secure the business of a third party by offering the most favourable terms"".[98] It was described by Adam Smith in The Wealth of Nations (1776) and later economists as allocating productive resources to their most highly valued uses[99] and encouraging efficiency. Smith and other classical economists before Antoine Augustine Cournot were referring to price and non-price rivalry among producers to sell their goods on best terms by bidding of buyers, not necessarily to a large number of sellers nor to a market in final equilibrium.[100] Competition is widespread throughout the market process. It is a condition where ""buyers tend to compete with other buyers, and sellers tend to compete with other sellers"".[101] In offering goods for exchange, buyers competitively bid to purchase specific quantities of specific goods which are available, or might be available if sellers were to choose to offer such goods. Similarly, sellers bid against other sellers in offering goods on the market, competing for the attention and exchange resources of buyers. Competition results from scarcity, as it is not possible to satisfy all conceivable human wants, and occurs as people try to meet the criteria being used to determine allocation.[101]:105
",4
4236,"Economic growth is a characteristic tendency of capitalist economies.[12]
",4
4237,"The capitalist mode of production refers to the systems of organising production and distribution within capitalist societies. Private money-making in various forms (renting, banking, merchant trade, production for profit and so on) preceded the development of the capitalist mode of production as such. The capitalist mode of production proper based on wage-labour and private ownership of the means of production and on industrial technology began to grow rapidly in Western Europe from the Industrial Revolution, later extending to most of the world.[citation needed]
",4
4238,"The term capitalist mode of production is defined by private ownership of the means of production, extraction of surplus value by the owning class for the purpose of capital accumulation, wage-based labour and, at least as far as commodities are concerned, being market-based.[102]
",4
4239,"Capitalism in the form of money-making activity has existed in the shape of merchants and money-lenders who acted as intermediaries between consumers and producers engaging in simple commodity production (hence the reference to ""merchant capitalism"") since the beginnings of civilisation. What is specific about the ""capitalist mode of production"" is that most of the inputs and outputs of production are supplied through the market (i.e. they are commodities) and essentially all production is in this mode.[9] By contrast, in flourishing feudalism most or all of the factors of production, including labour, are owned by the feudal ruling class outright and the products may also be consumed without a market of any kind, it is production for use within the feudal social unit and for limited trade.[85] This has the important consequence that, under capitalism, the whole organisation of the production process is reshaped and re-organised to conform with economic rationality as bounded by capitalism, which is expressed in price relationships between inputs and outputs (wages, non-labour factor costs, sales and profits) rather than the larger rational context faced by society overall—that is, the whole process is organised and re-shaped in order to conform to ""commercial logic"". Essentially, capital accumulation comes to define economic rationality in capitalist production.[86]
",4
4240,"A society, region or nation is capitalist if the predominant source of incomes and products being distributed is capitalist activity, but even so this does not yet mean necessarily that the capitalist mode of production is dominant in that society.
",4
4241,"In capitalist economic structures, supply and demand is an economic model of price determination in a market. It postulates that in a perfectly competitive market, the unit price for a particular good will vary until it settles at a point where the quantity demanded by consumers (at the current price) will equal the quantity supplied by producers (at the current price), resulting in an economic equilibrium for price and quantity.
",4
4242,"The basic laws of supply and demand, as described by David Besanko and Ronald Braeutigam, are the following four:[103]:37
",4
4243,"Although it is normal to regard the quantity demanded and the quantity supplied as functions of the price of the goods, the standard graphical representation, usually attributed to Alfred Marshall, has price on the vertical axis and quantity on the horizontal axis, the opposite of the standard convention for the representation of a mathematical function.
",4
4244,"Since determinants of supply and demand other than the price of the goods in question are not explicitly represented in the supply-demand diagram, changes in the values of these variables are represented by moving the supply and demand curves (often described as ""shifts"" in the curves). By contrast, responses to changes in the price of the good are represented as movements along unchanged supply and demand curves.
",4
4245,"A supply schedule is a table that shows the relationship between the price of a good and the quantity supplied. Under the assumption of perfect competition, supply is determined by marginal cost. That is, firms will produce additional output while the cost of producing an extra unit of output is less than the price they would receive. A hike in the cost of raw goods would decrease supply and shift costs up, while a discount would increase supply and shift costs down, hurting producers as producer surplus decreases.
",4
4246,"By its very nature, conceptualising a supply curve requires the firm to be a perfect competitor (i.e. to have no influence over the market price). This is true because each point on the supply curve is the answer to the question ""If this firm is faced with this potential price, how much output will it be able to and willing to sell?"". If a firm has market power, its decision of how much output to provide to the market influences the market price, therefore the firm is not ""faced with"" any price and the question becomes less relevant.
",4
4247,"Economists distinguish between the supply curve of an individual firm and the market supply curve. The market supply curve is obtained by summing the quantities supplied by all suppliers at each potential price, thus in the graph of the supply curve individual firms' supply curves are added horizontally to obtain the market supply curve.
",4
4248,"Economists also distinguish the short-run market supply curve from the long-run market supply curve. In this context, two things are assumed constant by definition of the short run: the availability of one or more fixed inputs (typically physical capital) and the number of firms in the industry. In the long-run, firms can adjust their holdings of physical capital, enabling them to better adjust their quantity supplied at any given price. Furthermore, in the long-run potential competitors can enter or exit the industry in response to market conditions. For both of these reasons, long-run market supply curves are generally flatter than their short-run counterparts.
",4
4249,"The determinants of supply are:
",4
4250,"A demand schedule, depicted graphically as the demand curve, represents the amount of some goods that buyers are willing and able to purchase at various prices, assuming all determinants of demand other than the price of the good in question, such as income, tastes and preferences, the price of substitute goods and the price of complementary goods, remain the same. According to the law of demand, the demand curve is almost always represented as downward-sloping, meaning that as price decreases, consumers will buy more of the good.[104]
",4
4251,"Just like the supply curves reflect marginal cost curves, demand curves are determined by marginal utility curves.[105] Consumers will be willing to buy a given quantity of a good at a given price, if the marginal utility of additional consumption is equal to the opportunity cost determined by the price—that is, the marginal utility of alternative consumption choices. The demand schedule is defined as the willingness and ability of a consumer to purchase a given product in a given frame of time.
",4
4252,"While the aforementioned demand curve is generally downward-sloping, there may be rare examples of goods that have upward-sloping demand curves. Two different hypothetical types of goods with upward-sloping demand curves are Giffen goods (an inferior, but staple good) and Veblen goods (goods made more fashionable by a higher price).
",4
4253,"By its very nature, conceptualising a demand curve requires that the purchaser be a perfect competitor—that is, that the purchaser has no influence over the market price. This is true because each point on the demand curve is the answer to the question ""If this buyer is faced with this potential price, how much of the product will it purchase?"". If a buyer has market power, so its decision of how much to buy influences the market price, then the buyer is not ""faced with"" any price and the question is meaningless.
",4
4254,"Like with supply curves, economists distinguish between the demand curve of an individual and the market demand curve. The market demand curve is obtained by summing the quantities demanded by all consumers at each potential price, thus in the graph of the demand curve individuals' demand curves are added horizontally to obtain the market demand curve. The determinants of demand are:
",4
4255,"In the context of supply and demand, economic equilibrium refers to a state where economic forces such as supply and demand are balanced and in the absence of external influences the (equilibrium) values of economic variables will not change. For example, in the standard text-book model of perfect competition equilibrium occurs at the point at which quantity demanded and quantity supplied are equal.[106] Market equilibrium, in this case, refers to a condition where a market price is established through competition such that the amount of goods or services sought by buyers is equal to the amount of goods or services produced by sellers. This price is often called the competitive price or market clearing price, and will tend not to change unless demand or supply changes. The quantity is called ""competitive quantity"" or market clearing quantity.
",4
4256,"Partial equilibrium, as the name suggests, takes into consideration only a part of the market to attain equilibrium. Jain proposes (attributed to George Stigler): ""A partial equilibrium is one which is based on only a restricted range of data, a standard example is price of a single product, the prices of all other products being held fixed during the analysis"".[107]
",4
4257,"The supply and demand model is a partial equilibrium model of economic equilibrium, where the clearance on the market of some specific goods is obtained independently from prices and quantities in other markets. In other words, the prices of all substitutes and complements as well as income levels of consumers are constant. This makes analysis much simpler than in a general equilibrium model which includes an entire economy.
",4
4258,"The dynamic process is that prices adjust until supply equals demand. It is a powerfully simple technique that allows one to study equilibrium, efficiency and comparative statics. The stringency of the simplifying assumptions inherent in this approach make the model considerably more tractable, but it may produce results which while seemingly precise do not effectively model real world economic phenomena.
",4
4259,"Partial equilibrium analysis examines the effects of policy action in creating equilibrium only in that particular sector or market which is directly affected, ignoring its effect in any other market or industry assuming that they being small will have little impact if any. Hence, this analysis is considered to be useful in constricted markets.
",4
4260,"Léon Walras first formalised the idea of a one-period economic equilibrium of the general economic system, but it was French economist Antoine Augustin Cournot and English political economist Alfred Marshall who developed tractable models to analyse an economic system.
",4
4261,"Demand and supply relations in a market can be statistically estimated from price, quantity and other data with sufficient information in the model. This can be done with simultaneous-equation methods of estimation in econometrics. Such methods allow solving for the model-relevant ""structural coefficients"", the estimated algebraic counterparts of the theory. The parameter identification problem is a common issue in ""structural estimation"". Typically, data on exogenous variables (that is, variables other than price and quantity, both of which are endogenous variables) are needed to perform such an estimation. An alternative to ""structural estimation"" is reduced-form estimation, which regresses each of the endogenous variables on the respective exogenous variables.
",4
4262,"Demand and supply have also been generalised to explain macroeconomic variables in a market economy, including the quantity of total output and the general price level. The Aggregate Demand–Aggregate Supply model may be the most direct application of supply and demand to macroeconomics, but other macroeconomic models also use supply and demand. Compared to microeconomic uses of demand and supply, different (and more controversial) theoretical considerations apply to such macroeconomic counterparts as aggregate demand and aggregate supply. Demand and supply are also used in macroeconomic theory to relate money supply and money demand to interest rates and to relate labor supply and labor demand to wage rates.
",4
4263,"According to Hamid S. Hosseini, the ""power of supply and demand"" was discussed to some extent by several early Muslim scholars, such as fourteenth-century Mamluk scholar Ibn Taymiyyah, who wrote: ""If desire for goods increases while its availability decreases, its price rises. On the other hand, if availability of the good increases and the desire for it decreases, the price comes down"".[108]
",4
4264,"John Locke's 1691 work Some Considerations on the Consequences of the Lowering of Interest and the Raising of the Value of Money[109] includes an early and clear description of supply and demand and their relationship. In this description, demand is rent: ""The price of any commodity rises or falls by the proportion of the number of buyer and sellers"" and ""that which regulates the price... [of goods] is nothing else but their quantity in proportion to their rent"".
",4
4265,"The phrase ""supply and demand"" was first used by James Denham-Steuart in his Inquiry into the Principles of Political Economy, published in 1767.
",4
4266,"Adam Smith used the phrase in his 1776 book The Wealth of Nations. In The Wealth of Nations, Smith generally assumed that the supply price was fixed, but that its ""merit"" (value) would decrease as its ""scarcity"" increased, in effect what was later also called the law of demand .
",4
4267,"David Ricardo titled one chapter of his 1817 work Principles of Political Economy and Taxation ""On the Influence of Demand and Supply on Price"".[110]
In Principles of Political Economy and Taxation, Ricardo more rigorously laid down the idea of the assumptions that were used to build his ideas of supply and demand.
",4
4268,"Antoine Augustin Cournot first developed a mathematical model of supply and demand in his 1838 Researches into the Mathematical Principles of Wealth, including diagrams.
",4
4269,"During the late 19th century, the marginalist school of thought emerged. This field mainly was started by Stanley Jevons, Carl Menger and Léon Walras. The key idea was that the price was set by the most expensive price—that is, the price at the margin. This was a substantial change from Adam Smith's thoughts on determining the supply price.
",4
4270,"In his 1870 essay ""On the Graphical Representation of Supply and Demand"", Fleeming Jenkin in the course of ""introduc[ing] the diagrammatic method into the English economic literature"" published the first drawing of supply and demand curves therein,[111] including comparative statics from a shift of supply or demand and application to the labor market.[112] The model was further developed and popularized by Alfred Marshall in the 1890 textbook Principles of Economics.[110]
",4
4271,"In a capitalist system, the government protects private property and guarantees the right of citizens to choose their job. In most cases, the government does not prevent firms from determining what wages they will pay and what prices they will charge for their products. However, many countries have minimum wage laws and minimum safety standards.
",4
4272,"Under some versions of capitalism, the government carries out a number of economic functions, such as issuing money, supervising public utilities, and enforcing private contracts. Many countries have competition laws that prohibit monopolies and cartels. Despite anti-monopoly laws, large corporations can form near-monopolies in some industries. Such firms can temporarily drop prices and accept losses to prevent competition from entering the market and then raise them again once the threat of competition is reduced. In many countries, public utilities such as electricity, heating fuel and communications are able to operate as a monopoly under government regulation due to high economies of scale.
",4
4273,"Government agencies regulate the standards of service in many industries, such as airlines and broadcasting, as well as financing a wide range of programs. In addition, the government regulates the flow of capital and uses financial tools such as the interest rate to control such factors as inflation and unemployment.[113]
",4
4274,"In his book The Road to Serfdom (1944), Friedrich Hayek (1899–1992) asserted that the free market understanding of economic freedom as present in capitalism is a requisite of political freedom. He argued that the market mechanism is the only way of deciding what to produce and how to distribute the items without using coercion. Milton Friedman, Andrew Brennan and Ronald Reagan also promoted this view. Friedman claimed that centralized economic operations are always accompanied by political repression. In his view, transactions in a market economy are voluntary and that the wide diversity that voluntary activity permits is a fundamental threat to repressive political leaders and greatly diminishes their power to coerce. Some of Friedman's views were shared by John Maynard Keynes, who believed that capitalism is vital for freedom to survive and thrive.[114][115] Freedom House, an American think tank that conducts international research on, and advocates for, democracy, political freedom and human rights, has argued ""there is a high and statistically significant correlation between the level of political freedom as measured by Freedom House and economic freedom as measured by the Wall Street Journal/Heritage Foundation survey"".[116]
",4
4275,"There are many variants of capitalism in existence that differ according to country and region.[citation needed] They vary in their institutional makeup and by their economic policies. The common features among all the different forms of capitalism is that they are predominantly based on the private ownership of the means of production and the production of goods and services for profit; the market-based allocation of resources; and the accumulation of capital.
",4
4276,"They include advanced capitalism, corporate capitalism, finance capitalism, free-market capitalism, mercantilism, social capitalism, state capitalism and welfare capitalism. Other variants of capitalism include anarcho-capitalism, community capitalism, humanistic capitalism, neo-capitalism, state monopoly capitalism, supercapitalism and technocapitalism.[citation needed]
",4
4277,"Advanced capitalism is the situation that pertains to a society in which the capitalist model has been integrated and developed deeply and extensively for a prolonged period. Various writers identify Antonio Gramsci as an influential early theorist of advanced capitalism, even if he did not use the term himself. In his writings, Gramsci sought to explain how capitalism had adapted to avoid the revolutionary overthrow that had seemed inevitable in the 19th century. At the heart of his explanation was the decline of raw coercion as a tool of class power, replaced by use of civil society institutions to manipulate public ideology in the capitalists' favour.[117][118][119]
",4
4278,"Jürgen Habermas has been a major contributor to the analysis of advanced-capitalistic societies. Habermas observed four general features that characterise advanced capitalism:
",4
4279,"Corporate capitalism is a free or mixed-market capitalist economy characterized by the dominance of hierarchical, bureaucratic corporations.
",4
4280,"Finance capitalism is the subordination of processes of production to the accumulation of money profits in a financial system. In their critique of capitalism, Marxism and Leninism both emphasise the role of finance capital as the determining and ruling-class interest in capitalist society, particularly in the latter stages.[121][122]
",4
4281,"Rudolf Hilferding is credited[by whom?] with first bringing the term finance capitalism into prominence through Finance Capital, his 1910 study of the links between German trusts, banks and monopolies—a study subsumed by Vladimir Lenin into Imperialism, the Highest Stage of Capitalism (1917), his analysis of the imperialist relations of the great world powers.[123] Lenin concluded that the banks at that time operated as ""the chief nerve centres of the whole capitalist system of national economy"".[124] For the Comintern (founded in 1919), the phrase ""dictatorship of finance capitalism""[125] became a regular one.
",4
4282,"Fernand Braudel would later point to two earlier periods when finance capitalism had emerged in human history—with the Genoese in the 16th century and with the Dutch in the 17th and 18th centuries—although at those points it developed from commercial capitalism.[126][need quotation to verify] Giovanni Arrighi extended Braudel's analysis to suggest that a predominance of finance capitalism is a recurring, long-term phenomenon, whenever a previous phase of commercial/industrial capitalist expansion reaches a plateau.[127]
",4
4283,"A capitalist free-market economy is an economic system where prices for goods and services are set entirely by the forces of supply and demand and are expected, by its adherents, to reach their point of equilibrium without intervention by government policy. It typically entails support for highly competitive markets and private ownership of the means of production. Laissez-faire capitalism is a more extensive form of this free-market economy, but one in which the role of the state is limited to protecting property rights. In anarcho-capitalist theory, property rights are protected by private firms and market-generated law. According to anarcho-capitalists, this entails property rights without statutory law through market-generated tort, contract and property law, and self-sustaining private industry.
",4
4284,"Mercantilism is a nationalist form of early capitalism that came into existence approximately in the late 16th century. It is characterized by the intertwining of national business interests with state-interest and imperialism. Consequently, the state apparatus is utilized to advance national business interests abroad. An example of this is colonists living in America who were only allowed to trade with and purchase goods from their respective mother countries (e.g. Britain, France and Portugal). Mercantilism was driven by the belief that the wealth of a nation is increased through a positive balance of trade with other nations—it corresponds to the phase of capitalist development sometimes called the primitive accumulation of capital.
",4
4285,"A social market economy is a free-market or mixed-market capitalist system, sometimes classified as a coordinated market economy, where government intervention in price formation is kept to a minimum, but the state provides significant services in areas such as social security, health care, unemployment benefits and the recognition of labor rights through national collective bargaining arrangements.
",4
4286,"This model is prominent in Western and Northern European countries as well as Japan, albeit in slightly different configurations. The vast majority of enterprises are privately owned in this economic model.
",4
4287,"Rhine capitalism is the contemporary model of capitalism and adaptation of the social market model that exists in continental Western Europe today.
",4
4288,"State capitalism is a capitalist market economy dominated by state-owned enterprises, where the state enterprises are organized as commercial, profit-seeking businesses. The designation has been used broadly throughout the 20th century to designate a number of different economic forms, ranging from state-ownership in market economies to the command economies of the former Eastern Bloc. According to Aldo Musacchio, a professor at Harvard Business School, state capitalism is a system in which governments, whether democratic or autocratic, exercise a widespread influence on the economy either through direct ownership or various subsidies. Musacchio notes a number of differences between today's state capitalism and its predecessors. In his opinion, gone are the days when governments appointed bureaucrats to run companies: the world's largest state-owned enterprises are now traded on the public markets and kept in good health by large institutional investors. Contemporary state capitalism is associated with the East Asian model of capitalism, dirigisme and the economy of Norway.[128] Alternatively, Merriam-Webster defines state capitalism as ""an economic system in which private capitalism is modified by a varying degree of government ownership and control"".[129]
",4
4289,"In Socialism: Utopian and Scientific, Friedrich Engels argued that state-owned enterprises would characterize the final stage of capitalism, consisting of ownership and management of large-scale production and communication by the bourgeois state.[130] In his writings, Vladimir Lenin characterized the economy of Soviet Russia as state capitalist, believing state capitalism to be an early step toward the development of socialism.[131][132]
",4
4290,"Some economists and left-wing academics including Richard D. Wolff and Noam Chomsky, as well as many Marxist philosophers and revolutionaries such as Raya Dunayevskaya and C.L.R. James, argue that the economies of the former Soviet Union and Eastern Bloc represented a form of state capitalism because their internal organization within enterprises and the system of wage labor remained intact.[133][134][135][136][137]
",4
4291,"The term is not used by Austrian School economists to describe state ownership of the means of production. The economist Ludwig von Mises argued that the designation of state capitalism was simply a new label for the old labels of state socialism and planned economy and differed only in non-essentials from these earlier designations.[138]
",4
4292,"The debate between proponents of private versus state capitalism is centered around questions of managerial efficacy, productive efficiency and fair distribution of wealth.
",4
4293,"Welfare capitalism is capitalism that includes social welfare policies. Today, welfare capitalism is most often associated with the models of capitalism found in Central Mainland and Northern Europe such as the Nordic model, social market economy and Rhine capitalism. In some cases, welfare capitalism exists within a mixed economy, but welfare states can and do exist independently of policies common to mixed economies such as state interventionism and extensive regulation.
",4
4294,"A mixed economy is a largely market-based capitalist economy consisting of both private and public ownership of the means of production and economic interventionism through macroeconomic policies intended to correct market failures, reduce unemployment and keep inflation low. The degree of intervention in markets varies among different countries. Some mixed economies such as France under dirigisme also featured a degree of indirect economic planning over a largely capitalist-based economy.
",4
4295,"Most modern capitalist economies are defined as mixed economies to some degree.
",4
4296,"The accumulation of capital is the process of ""making money"", or growing an initial sum of money through investment in production. Capitalism is based on the accumulation of capital, whereby financial capital is invested in order to make a profit and then reinvested into further production in a continuous process of accumulation. In Marxian economic theory, this dynamic is called the law of value. Capital accumulation forms the basis of capitalism, where economic activity is structured around the accumulation of capital, defined as investment in order to realize a financial profit.[139] In this context, ""capital"" is defined as money or a financial asset invested for the purpose of making more money (whether in the form of profit, rent, interest, royalties, capital gain or some other kind of return).[140]
",4
4297,"In mainstream economics, accounting and Marxian economics, capital accumulation is often equated with investment of profit income or savings, especially in real capital goods. The concentration and centralisation of capital are two of the results of such accumulation. In modern macroeconomics and econometrics, the phrase ""capital formation"" is often used in preference to ""accumulation"", though the United Nations Conference on Trade and Development (UNCTAD) refers nowadays to ""accumulation"". The term ""accumulation"" is occasionally used in national accounts.
",4
4298,"Accumulation can be measured as the monetary value of investments, the amount of income that is reinvested, or the change in the value of assets owned (the increase in the value of the capital stock). Using company balance sheets, tax data and direct surveys as a basis, government statisticians estimate total investments and assets for the purpose of national accounts, national balance of payments and flow of funds statistics. The Reserve Banks and the Treasury usually provide interpretations and analysis of this data. Standard indicators include capital formation, gross fixed capital formation, fixed capital, household asset wealth and foreign direct investment.
",4
4299,"Organisations such as the International Monetary Fund, the UNCTAD, the World Bank Group, the OECD and the Bank for International Settlements use national investment data to estimate world trends. The Bureau of Economic Analysis, Eurostat and the Japan Statistical Office provide data on the United States, Europe and Japan respectively. Other useful sources of investment information are business magazines such as Fortune, Forbes, The Economist, Business Week and so on as well as various corporate ""watchdog"" organisations and non-governmental organisation publications. A reputable scientific journal is the Review of Income & Wealth. In the case of the United States, the ""Analytical Perspectives"" document (an annex to the yearly budget) provides useful wealth and capital estimates applying to the whole country.
",4
4300,"In Karl Marx' economic theory, capital accumulation refers to the operation whereby profits are reinvested increasing the total quantity of capital. Capital is viewed by Marx as expanding value, that is, in other terms, as a sum of capital, usually expressed in money, that is transformed through human labor into a larger value, extracted as profits and expressed as money. Here, capital is defined essentially as economic or commercial asset value in search of additional value or surplus-value. This requires property relations which enable objects of value to be appropriated and owned, and trading rights to be established. Capital accumulation has a double origin, namely in trade and in expropriation, both of a legal or illegal kind. The reason is that a stock of capital can be increased through a process of exchange or ""trading up"", but also through directly taking an asset or resource from someone else without compensation. David Harvey calls this accumulation by dispossession.
",4
4301,"The continuation and progress of capital accumulation depends on the removal of obstacles to the expansion of trade and this has historically often been a violent process. As markets expand, more and more new opportunities develop for accumulating capital because more and more types of goods and services can be traded in. However, capital accumulation may also confront resistance when people refuse to sell, or refuse to buy (for example a strike by investors or workers, or consumer resistance).
",4
4302,"According to Marx, capital has the tendency for concentration and centralization in the hands of the wealthy. Marx explains: ""It is concentration of capitals already formed, destruction of their individual independence, expropriation of capitalist by capitalist, transformation of many small into few large capitals. [...] Capital grows in one place to a huge mass in a single hand, because it has in another place been lost by many. [...] The battle of competition is fought by cheapening of commodities. The cheapness of commodities demands, caeteris paribus, on the productiveness of labour, and this again on the scale of production. Therefore, the larger capitals beat the smaller. It will further be remembered that, with the development of the capitalist mode of production, there is an increase in the minimum amount of individual capital necessary to carry on a business under its normal conditions. The smaller capitals, therefore, crowd into spheres of production which Modern Industry has only sporadically or incompletely got hold of. Here competition rages [...] It always ends in the ruin of many small capitalists, whose capitals partly pass into the hands of their conquerors, partly vanish"".[141]
",4
4303,"In Marxian economics, the rate of accumulation is defined as the value of the real net increase in the stock of capital in an accounting period and the proportion of realised surplus-value or profit-income which is reinvested, rather than consumed. This rate can be expressed by means of various ratios between the original capital outlay, the realised turnover, surplus-value or profit and reinvestments (e.g. the writings of the economist Michał Kalecki).
",4
4304,"Other things being equal, the greater the amount of profit-income that is disbursed as personal earnings and used for consumptive purposes, the lower the savings rate and the lower the rate of accumulation is likely to be. However, earnings spent on consumption can also stimulate market demand and higher investment. This is the cause of endless controversies in economic theory about ""how much to spend, and how much to save"".
",4
4305,"In a boom period of capitalism, the growth of investments is cumulative, i.e. one investment leads to another, leading to a constantly expanding market, an expanding labor force and an increase in the standard of living for the majority of the people.[citation needed]
",4
4306,"In a stagnating, decadent capitalism, the accumulation process is increasingly oriented towards investment on military and security forces, real estate, financial speculation and luxury consumption. In that case, income from value-adding production will decline in favour of interest, rent and tax income, with as a corollary an increase in the level of permanent unemployment. The more capital one owns, the more capital one can also borrow. The inverse is also true and this is one factor in the widening gap between the rich and the poor.[citation needed]
",4
4307,"Ernest Mandel emphasised that the rhythm of capital accumulation and growth depended critically on the division of a society's social product between ""necessary product"" and ""surplus product""; and the division of the surplus product between investment and consumption. In turn, this allocation pattern reflected the outcome of competition among capitalists, competition between capitalists and workers and competition between workers. The pattern of capital accumulation can therefore never be simply explained by commercial factors as it also involved social factors and power relationships.
",4
4308,"Strictly speaking, capital has accumulated only when realised profit income has been reinvested in capital assets. As suggested in the first volume of Marx' Das Kapital, the process of capital accumulation in production has at least seven distinct but linked moments:
",4
4309,"All of these moments do not refer simply to an ""economic"" or commercial process. Rather, they assume the existence of legal, social, cultural and economic power conditions, without which creation, distribution and circulation of the new wealth could not occur. This becomes especially clear when the attempt is made to create a market where none exists, or where people refuse to trade.
",4
4310,"In the second volume of Das Kapital, Marx continues the story and shows that with the aid of bank credit capital in search of growth can more or less smoothly mutate from one form to another, alternately taking the form of money capital (liquid deposits, securities and so on), commodity capital (tradable products, real estate and the like), or production capital (means of production and labor power).
",4
4311,"His discussion of the simple and expanded reproduction of the conditions of production offers a more sophisticated model of the parameters of the accumulation process as a whole. At simple reproduction, a sufficient amount is produced to sustain society at the given living standard; the stock of capital stays constant. At expanded reproduction, more product-value is produced than is necessary to sustain society at a given living standard (a surplus product); the additional product-value is available for investments which enlarge the scale and variety of production.
",4
4312,"According to Marx, the bourgeois claim that there is no economic law according to which capital is necessarily re-invested in the expansion of production, that instead this depends on anticipated profitability, market expectations and perceptions of investment risk. Such statements only explain the subjective experiences of investors and ignore the objective realities which would influence such opinions. As Marx states in the second volume of Das Kapital, simple reproduction only exists if the variable and surplus capital realised by Dept. 1—producers of means of production—exactly equals that of the constant capital of Dept. 2, producers of articles of consumption (p. 524). Such equilibrium rests on various assumptions, such as a constant labor supply (no population growth). Accumulation does not imply a necessary change in total magnitude of value produced, but can simply refer to a change in the composition of an industry (p. 514).
",4
4313,"Ernest Mandel introduced the additional concept of contracted economic reproduction, i.e. reduced accumulation where business operating at a loss outnumbers growing business, or economic reproduction on a decreasing scale, for example due to wars, natural disasters or devalorisation.
",4
4314,"Balanced economic growth requires that different factors in the accumulation process expand in appropriate proportions. However, markets themselves cannot spontaneously create that balance and in fact what drives business activity is precisely the imbalances between supply and demand: inequality is the motor of growth. This partly explains why the worldwide pattern of economic growth is very uneven and unequal, even although markets have existed almost everywhere for a very long-time. Some people argue that it also explains government regulation of market trade and protectionism.
",4
4315,"""Accumulation of capital"" sometimes also refers in Marxist writings to the reproduction of capitalist social relations (institutions) on a larger scale over time, i.e. the expansion of the size of the proletariat and of the wealth owned by the bourgeoisie.
",4
4316,"This interpretation emphasises that capital ownership, predicated on command over labor, is a social relation: the growth of capital implies the growth of the working class (a ""law of accumulation""). In the first volume of Das Kapital, Marx had illustrated this idea with reference to Edward Gibbon Wakefield's theory of colonisation:
",4
4317,"Wakefield discovered that in the Colonies, property in money, means of subsistence, machines, and other means of production, does not as yet stamp a man as a capitalist if there be wanting the correlative—the wage-worker, the other man who is compelled to sell himself of his own free-will. He discovered that capital is not a thing, but a social relation between persons, established by the instrumentality of things. Mr. Peel, he moans, took with him from England to Swan River, West Australia, means of subsistence and of production to the amount of £50,000. Mr. Peel had the foresight to bring with him, besides, 3,000 persons of the working-class, men, women, and children. Once arrived at his destination, 'Mr. Peel was left without a servant to make his bed or fetch him water from the river.' Unhappy Mr. Peel, who provided for everything except the export of English modes of production to Swan River!",4
4318,"In the third volume of Das Kapital, Marx refers to the ""fetishism of capital"" reaching its highest point with interest-bearing capital because now capital seems to grow of its own accord without anybody doing anything:
",4
4319,"The relations of capital assume their most externalised and most fetish-like form in interest-bearing capital. We have here 



M
−

M
′



{\displaystyle M-M'}

, money creating more money, self-expanding value, without the process that effectuates these two extremes. In merchant's capital, 



M
−
C
−

M
′



{\displaystyle M-C-M'}

, there is at least the general form of the capitalistic movement, although it confines itself solely to the sphere of circulation, so that profit appears merely as profit derived from alienation; but it is at least seen to be the product of a social relation, not the product of a mere thing. [...] This is obliterated in 



M
−

M
′



{\displaystyle M-M'}

, the form of interest-bearing capital. [...] The thing (money, commodity, value) is now capital even as a mere thing, and capital appears as a mere thing. The result of the entire process of reproduction appears as a property inherent in the thing itself. It depends on the owner of the money, i.e., of the commodity in its continually exchangeable form, whether he wants to spend it as money or loan it out as capital. In interest-bearing capital, therefore, this automatic fetish, self-expanding value, money generating money, are brought out in their pure state and in this form it no longer bears the birth-marks of its origin. The social relation is consummated in the relation of a thing, of money, to itself. Instead of the actual transformation of money into capital, we see here only form without content.",4
4320,"Wage labour refers to the sale of labour under a formal or informal employment contract to an employer.[142] These transactions usually occur in a labour market where wages are market determined.[143] Individuals who possess and supply financial capital to productive ventures often become owners, either jointly (as shareholders) or individually.[citation needed] In Marxist economics, these owners of the means of production and suppliers of capital are generally called capitalists. The description of the role of the capitalist has shifted, first referring to a useless intermediary between producers, then to an employer of producers, and finally to the owners of the means of production.[83] Labor includes all physical and mental human resources, including entrepreneurial capacity and management skills, which are needed to produce products and services. Production is the act of making goods or services by applying labor power.[144][145]
",4
4321,"Critics of the capitalist mode of production see wage labour as a major, if not defining, aspect of hierarchical industrial systems. Most opponents of the institution support worker self-management and economic democracy as alternatives to both wage labour and capitalism. While most opponents of the wage system blame the capitalist owners of the means of production for its existence, most anarchists and other libertarian socialists also hold the state as equally responsible as it exists as a tool utilised by capitalists to subsidise themselves and protect the institution of private ownership of the means of production. As some opponents of wage labour take influence from Marxist propositions, many are opposed to private property, but maintain respect for personal property.
",4
4322,"The most common form of wage labour currently is ordinary direct, or ""full-time"", employment in which a free worker sells their labour for an indeterminate time (from a few years to the entire career of the worker) in return for a money-wage or salary and a continuing relationship with the employer (which it does not in general offer contractors or other irregular staff). However, wage labour takes many other forms and explicit as opposed to implicit (i.e. conditioned by local labour and tax law) contracts are not uncommon. Economic history shows a great variety of ways in which labour is traded and exchanged. The differences show up in the form of:
",4
4323,"Criticism of capitalism comes from various political and philosophical approaches, including anarchist, socialist, religious and nationalist viewpoints. Some believe that capitalism can only be overcome through revolution while others believe that structural change can come slowly through political reforms. Some critics believe there are merits in capitalism and wish to balance it with some form of social control, typically through government regulation (e.g. the social market movement).
",4
4324,"Prominent among critiques of capitalism are accusations that capitalism is inherently exploitative, alienating, unstable, unsustainable, inefficient, creates massive economic inequality, commodifies people, degrades the environment, is anti-democratic and leads to an erosion of human rights while it incentivizes imperialist expansion and war.
",4
4325,"Although the term ""liberalism"" retains its original meaning in most of the world, it has unfortunately come to have a very different meaning in late twentieth-century America. Hence terms such as ""market liberalism,"" ""classical liberalism,"" or ""libertarianism"" are often used in its place in America.",4
4326,"Heterodox
",4
4327,"Economic growth can be defined as the increase in the inflation-adjusted market value of the goods and services produced by an economy over time. Statisticians conventionally measure such growth as the percent rate of increase in real gross domestic product, or real GDP.[1]
",4
4328,"Growth is usually calculated in real terms – i.e., inflation-adjusted terms – to eliminate the distorting effect of inflation on the prices of goods produced. Measurement of economic growth uses national income accounting.[2] Since economic growth is measured as the annual percent change of gross domestic product (GDP), it has all the advantages and drawbacks of that measure. The economic growth-rates of countries are commonly compared[by whom?] using the ratio of the GDP to population (per-capita income).[3]
",4
4329,"The ""rate of economic growth"" refers to the geometric annual rate of growth in GDP between the first and the last year over a period of time. This growth rate represents the trend in the average level of GDP over the period, and ignores any fluctuations in the GDP around this trend.
",4
4330,"Economists refer to an increase in economic growth caused by more efficient use of inputs (increased productivity of labor, of physical capital, of energy or of materials) as intensive growth. In contrast, GDP growth caused only by increases in the amount of inputs available for use (increased population, for example, or new territory) counts as extensive growth.[4]
",4
4331,"Development of new goods and services also generates economic growth.[citation needed] As it so happens, in the U.S. about 60% of consumer spending in 2013 went on goods and services that did not exist in 1869.[5]
",4
4332," The economic growth rate is calculated from data on GDP estimated by countries' statistical agencies. The rate of growth of GDP per capita is calculated from data on GDP and people for the initial and final periods included in the analysis of the analyst.
",4
4333,"Living standards vary widely from country to country, and furthermore, the change in living standards over time varies widely from country to country. Below is a table which shows GDP per person and annualized per person GDP growth for a selection of countries over a period of about 100 years. The GDP per person data are adjusted for inflation, hence they are ""real"". GDP per person (more commonly called ""per capita"" GDP) is the GDP of the entire country divided by the number of people in the country; GDP per person is conceptually analogous to ""average income"".
",4
4334,"Seemingly small differences in yearly GDP growth lead to large changes in GDP when compounded over time. For instance, in the above table, GDP per person in the United Kingdom in the year 1870 was $4,808. At the same time in the United States, GDP per person was $4,007, lower than the UK by about 20%. However, in 2008 the positions were reversed: GDP per person was $36,130 in the United Kingdom and $46,970 in the United States, i.e. GDP per person in the US was 30% more than it was in the UK. As the above table shows, this means that GDP per person grew, on average, by 1.80% per year in the US and by 1.47% in the UK. Thus, a difference in GDP growth by only a few tenths of a percent per year results in large differences in outcomes when the growth is persistent over a generation. This and other observations have led some economists to view GDP growth as the most important part of the field of macroeconomics:
",4
4335,"...if we can learn about government policy options that have even small effects on long-term growth rates, we can contribute much more to improvements in standards of living than has been provided by the entire history of macroeconomic analysis of countercyclical policy and fine-tuning. Economic growth [is] the part of macroeconomics that really matters.[7]",4
4336,"It has been observed that GDP growth is influenced by the size of the economy. The relation between GDP growth and GDP across the countries at a particular point of time is convex. Growth increases with GDP reaches its maximum and then begins to decline. There exists some extremum value. This is not exactly middle-income trap. It is observed for both developed and developing economies. Actually, countries having this property belong to conventional growth domain. However, the extremum could be extended by technological and policy innovations and some countries move into innovative growth domain with higher limiting values.[8]
",4
4337,"In national income accounting, per capita output can be calculated using the following factors: output per unit of labor input (labor productivity), hours worked (intensity), the percentage of the working-age population actually working (participation rate) and the proportion of the working-age population to the total population (demographics). ""The rate of change of GDP/population is the sum of the rates of change of these four variables plus their cross products.""[9]
",4
4338,"Economists distinguish between long-run economic growth and short-run economic changes in production. Short-run variation in economic growth is termed the business cycle. Generally, economists attribute the ups and downs in the business cycle to fluctuations in aggregate demand. In contrast, economic growth is concerned with the long-run trend in production due to structural causes such as technological growth and factor accumulation.
",4
4339,"Increases in labor productivity (the ratio of the value of output to labor input) have historically been the most important source of real per capita economic growth.[10][11][12][13][14] ""In a famous estimate, MIT Professor Robert Solow concluded that technological progress has accounted for 80 percent of the long-term rise in U.S. per capita income, with increased investment in capital explaining only the remaining 20 percent.""[15]
",4
4340,"Increases in productivity lower the real cost of goods. Over the 20th century the real price of many goods fell by over 90%.[16]
",4
4341,"Economic growth has traditionally been attributed to the accumulation of human and physical capital and the increase in productivity and creation of new goods arising from technological innovation.[17] Further division of labour (specialization) is also fundamental to rising productivity.[18]
",4
4342,"Before industrialization technological progress resulted in an increase in the population, which was kept in check by food supply and other resources, which acted to limit per capita income, a condition known as the Malthusian trap.[19][20] The rapid economic growth that occurred during the Industrial Revolution was remarkable because it was in excess of population growth, providing an escape from the Malthusian trap.[21] Countries that industrialized eventually saw their population growth slow down, a phenomenon known as the demographic transition.
",4
4343,"Increases in productivity are the major factor responsible for per capita economic growth—this has been especially evident since the mid-19th century. Most of the economic growth in the 20th century was due to increased output per unit of labor, materials, energy, and land (less input per widget). The balance of the growth in output has come from using more inputs. Both of these changes increase output. The increased output included more of the same goods produced previously and new goods and services.[22]
",4
4344,"During the Industrial Revolution, mechanization began to replace hand methods in manufacturing, and new processes streamlined production of chemicals, iron, steel, and other products.[23] Machine tools made the economical production of metal parts possible, so that parts could be interchangeable.[24] (See: Interchangeable parts.)
",4
4345,"During the Second Industrial Revolution, a major factor of productivity growth was the substitution of inanimate power for human and animal labor. Also there was a great increase in power as steam-powered electricity generation and internal combustion supplanted limited wind and water power.[23] Since that replacement, the great expansion of total power was driven by continuous improvements in energy conversion efficiency.[25] Other major historical sources of productivity were automation, transportation infrastructures (canals, railroads, and highways),[26][27] new materials (steel) and power, which includes steam and internal combustion engines and electricity. Other productivity improvements included mechanized agriculture and scientific agriculture including chemical fertilizers and livestock and poultry management, and the Green Revolution. Interchangeable parts made with machine tools powered by electric motors evolved into mass production, which is universally used today.[24]
",4
4346,"Great sources of productivity improvement in the late 19th century were railroads, steam ships, horse-pulled reapers and combine harvesters, and steam-powered factories.[28][29] The invention of processes for making cheap steel were important for many forms of mechanization and transportation. By the late 19th century both prices and weekly work hours fell because less labor, materials, and energy were required to produce and transport goods. However, real wages rose, allowing workers to improve their diet, buy consumer goods and afford better housing.[28]
",4
4347,"Mass production of the 1920s created overproduction, which was arguably one of several causes of the Great Depression of the 1930s.[30] Following the Great Depression, economic growth resumed, aided in part by increased demand for existing goods and services, such as automobiles, telephones, radios, electricity and household appliances. New goods and services included television, air conditioning and commercial aviation (after 1950), creating enough new demand to stabilize the work week.[31] The building of highway infrastructures also contributed to post World War II growth, as did capital investments in manufacturing and chemical industries.[32] The post World War II economy also benefited from the discovery of vast amounts of oil around the world, particularly in the Middle East. By John W. Kendrick's estimate, three-quarters of increase in U.S. per capita GDP from 1889 to 1957 was due to increased productivity.[14]
",4
4348,"Economic growth in the United States slowed down after 1973.[33] In contrast growth in Asia has been strong since then, starting with Japan and spreading to Four Asian Tigers, China, Southeast Asia, the Indian subcontinent and Asia Pacific.[34] In 1957 South Korea had a lower per capita GDP than Ghana,[35] and by 2008 it was 17 times as high as Ghana's.[36] The Japanese economic growth has slackened considerably since the late 1980s.
",4
4349,"Productivity in the United States grew at an increasing rate throughout the 19th century and was most rapid in the early to middle decades of the 20th century.[37][38][39][40][41] U.S. productivity growth spiked towards the end of the century in 1996–2004, due to an acceleration in the rate of technological innovation known as Moore's law.[42][43][44][45] After 2004 U.S. productivity growth returned to the low levels of 1972–96.[42]
",4
4350,"Capital in economics ordinarily refers to physical capital, which consists of structures (largest component of physical capital) and equipment used in business (machinery, factory equipment, computers and office equipment, construction equipment, business vehicles, medical equipment, etc.).[2] Up to a point increases in the amount of capital per worker are an important cause of economic output growth. Capital is subject to diminishing returns because of the amount that can be effectively invested and because of the growing burden of depreciation. In the development of economic theory, the distribution of income was considered to be between labor and the owners of land and capital.[46] In recent decades there have been several Asian countries with high rates of economic growth driven by capital investment.[47]
",4
4351,"The work week declined considerably over the 19th century.[48][49] By the 1920s the average work week in the U.S. was 49 hours, but the work week was reduced to 40 hours (after which overtime premium was applied) as part of the National Industrial Recovery Act of 1933.
",4
4352,"Demographic factors may influence growth by changing the employment to population ratio and the labor force participation rate.[10] Industrialization creates a demographic transition in which birth rates decline and the average age of the population increases.
",4
4353,"Women with fewer children and better access to market employment tend to join the labor force in higher percentages. There is a reduced demand for child labor and children spend more years in school. The increase in the percentage of women in the labor force in the U.S. contributed to economic growth, as did the entrance of the baby boomers into the workforce.[10]
",4
4354,"See: Spending wave
",4
4355,"Many theoretical and empirical analyses of economic growth attribute a major role to a country's level of human capital, defined as the skills of the population or the work force. Human capital has been included in both neoclassical and endogenous growth models.[50][51][52]
",4
4356,"A country's level of human capital is difficult to measure since it is created at home, at school, and on the job. Economists have attempted to measure human capital using numerous proxies, including the population's level of literacy, its level of numeracy, its level of book production/capita, its average level of formal schooling, its average test score on international tests, and its cumulative depreciated investment in formal schooling. The most commonly-used measure of human capital is the level (average years) of school attainment in a country, building upon the data development of Robert Barro and Jong-Wha Lee.[53] This measure is widely used because Barro and Lee provide data for numerous countries in five-year intervals for a long period of time.
",4
4357,"One problem with the schooling attainment measure is that the amount of human capital acquired in a year of schooling is not the same at all levels of schooling and is not the same in all countries. This measure also presumes that human capital is only developed in formal schooling, contrary to the extensive evidence that families, neighborhoods, peers, and health also contribute to the development of human capital. Despite these potential limitations, Theodore Breton has shown that this measure can represent human capital in log-linear growth models because across countries GDP/adult has a log-linear relationship to average years of schooling, which is consistent with the log-linear relationship between workers' personal incomes and years of schooling in the Mincer model.[54]
",4
4358,"Eric Hanushek and Dennis Kimko introduced measures of students' mathematics and science skills from international assessments into growth analysis.[55] They found that this measure of human capital was very significantly related to economic growth. Eric Hanushek and Ludger Wößmann have extended this analysis.[56][57] Theodore Breton shows that the correlation between economic growth and students' average test scores in Hanushek and Wößmann's analyses is actually due to the relationship in countries with less than eight years of schooling. He shows that economic growth is not correlated with average scores in more educated countries.[54] Hanushek and Wößmann further investigate whether the relationship of knowledge capital to economic growth is causal. They show that the level of students' cognitive skills can explain the slow growth in Latin America and the rapid growth in East Asia.[58]
",4
4359,"Joerg Baten and Jan Luiten van Zanden employ book production per capita as a proxy for sophisticated literacy capabilities and find that ""Countries with high levels of human capital formation in the 18th century initiated or participated in the industrialization process of the 19th century, whereas countries with low levels of human capital formation were unable to do so, among them many of today’s Less Developed Countries such as India, Indonesia, and China.""[59]
",4
4360,"“As institutions influence behavior and incentives in real life, they forge the success or failure of nations.”[60]",4
4361,"In economics and economic history, the transition to capitalism from earlier economic systems was enabled by the adoption of government policies that facilitated commerce and gave individuals more personal and economic freedom. These included new laws favorable to the establishment of business, including contract law and laws providing for the protection of private property, and the abolishment of anti-usury laws.[61][62]
",4
4362,"Much of this literature was built on the success story of the British state after the Glorious Revolution of 1688, in which high fiscal capacity combined with constraints on the power of the king generated some respect for the rule of law.[63][64][65][60] However, others have questioned that this institutional formula is not so easily replicable elsewhere as a change in the Constitution—and the type of institutions created by that change—does not necessarily create a change in political power if the economic powers of that society are not aligned with the new set of rule of law institutions.[66] In England, a dramatic increase in the state's fiscal capacity followed the creation of constraints on the crown, but elsewhere in Europe increases in state capacity happened before major rule of law reforms.[67]
",4
4363,"There are many different ways through which states achieved state (fiscal) capacity and this different capacity accelerated or hindered their economic development. Thanks to the underlying homogeneity of its land and people, England was able to achieve a unified legal and fiscal system since the Middle Ages that enabled it to substantially increase the taxes it raised after 1689.[67] On the other hand, the French experience of state building faced much stronger resistance from local feudal powers keeping it legally and fiscally fragmented until the French Revolution despite significant increases in state capacity during the seventeenth century.[68][69] Furthermore, Prussia and the Habsburg empire—much more heterogeneous states than England—were able to increase state capacity during the eighteenth century without constraining the powers of the executive.[67] Nevertheless, it is unlikely that a country will generate institutions that respect property rights and the rule of law without having had first intermediate fiscal and political institutions that create incentives for elites to support them. Many of these intermediate level institutions relied on informal private-order arrangements that combined with public-order institutions associated with states, to lay the foundations of modern rule of law states.[67]
",4
4364,"In many poor and developing countries much land and housing are held outside the formal or legal property ownership registration system. In many urban areas the poor ""invade"" private or government land to build their houses, so they do not hold title to these properties. Much unregistered property is held in informal form through various property associations and other arrangements. Reasons for extra-legal ownership include excessive bureaucratic red tape in buying property and building. In some countries, it can take over 200 steps and up to 14 years to build on government land. Other causes of extra-legal property are failures to notarize transaction documents or having documents notarized but failing to have them recorded with the official agency.[70]
",4
4365,"Not having clear legal title to property limits its potential to be used as collateral to secure loans, depriving many poor countries of one of their most important potential sources of capital. Unregistered businesses and lack of accepted accounting methods are other factors that limit potential capital.[70]
",4
4366,"Businesses and individuals participating in unreported business activity and owners of unregistered property face costs such as bribes and pay-offs that offset much of any taxes avoided.[70]
",4
4367,"""Democracy Does Cause Growth"", according to Acemoglu et al. Specifically, ""democracy increases future GDP by encouraging investment, increasing schooling, inducing economic reforms, improving public goods provision, and reducing social unrest.""[71] UNESCO and the United Nations also consider that cultural property protection, high-quality education, cultural diversity and social cohesion in armed conflicts are particularly necessary for qualitative growth.[72]
",4
4368,"According to Daron Acemoglu, Simon Johnson and James Robinson, the positive correlation between high income and cold climate is a by-product of history. Europeans adopted very different colonization policies in different colonies, with different associated institutions. In places where these colonizers faced high mortality rates (e.g., due to the presence of tropical diseases), they could not settle permanently, and they were thus more likely to establish extractive institutions, which persisted after independence; in places where they could settle permanently (e.g. those with temperate climates), they established institutions with this objective in mind and modeled them after those in their European homelands. In these 'neo-Europes' better institutions in turn produced better development outcomes. Thus, although other economists focus on the identity or type of legal system of the colonizers to explain institutions, these authors look at the environmental conditions in the colonies to explain institutions. For instance, former colonies have inherited corrupt governments and geopolitical boundaries (set by the colonizers) that are not properly placed regarding the geographical locations of different ethnic groups, creating internal disputes and conflicts that hinder development. In another example, societies that emerged in colonies without solid native populations established better property rights and incentives for long-term investment than those where native populations were large.[73]
",4
4369,"In Why Nations Fail, Acemoglu and Robinson said that the English in North America started by trying to repeat the success of the Spanish Conquistadors in extracting wealth (especially gold and silver) from the countries they had conquered.  This system repeatedly failed for the English .  Their successes rested on giving land and a voice in the government to every male settler to incentivize productive labor.  In Virginia it took twelve years and many deaths from starvation before the governor decided to try democracy.[74]
",4
4370,"Policymakers and scholars frequently emphasize the importance of entrepreneurship for economic growth. However, surprisingly few research empirically examine and quantify entrepreneurship's impact on growth. This is due to endogeneity—forces that drive economic growth also drive entrepreneurship. In other words, the empirical analysis of the impact of entrepreneurship on growth is difficult because of the joint determination of entrepreneurship and economic growth. A few papers use quasi-experimental designs, and have found that entrepreneurship and the density of small businesses indeed have a causal impact on regional growth.[75][76]
",4
4371,"Another major cause of economic growth is the introduction of new products and services and the improvement of existing products. New products create demand, which is necessary to offset the decline in employment that occurs through labor-saving technology (and to a lesser extent employment declines due to savings in energy and materials).[43][77] In the U.S. by 2013 about 60% of consumer spending was for goods and services that did not exist in 1869. Also, the creation of new services has been more important than invention of new goods.[78]
",4
4372,"Economic growth in the U.S. and other developed countries went through phases that affected growth through changes in the labor force participation rate and the relative sizes of economic sectors. The transition from an agricultural economy to manufacturing increased the size of the sector with high output per hour (the high-productivity manufacturing sector), while reducing the size of the sector with lower output per hour (the lower productivity agricultural sector). Eventually high productivity growth in manufacturing reduced the sector size, as prices fell and employment shrank relative to other sectors.[79][80] The service and government sectors, where output per hour and productivity growth is low, saw increases in their shares of the economy and employment during the 1990s.[10] The public sector has since contracted, while the service economy expanded in the 2000s.
",4
4373,"The structural change could also be viewed from another angle. It is possible to divide real economic growth into two components: an indicator of extensive economic growth—the ‘quantitative’ GDP—and an indicator of the improvement of the quality of goods and services—the ‘qualitative’ GDP.[81]
",4
4374,"The Malthusian theory proposes that over most of human history technological progress caused larger population growth but had no impact on income per capita in the long run. According to the theory, while technologically advanced economies over this epoch were characterized by higher population density, their level of income per capita was not different than those among technologically regressed society.
",4
4375,"The conceptual foundations of the Malthusian theory were formed by Thomas Malthus,[82] and a modern representation of these approach is provided by Ashraf and Galor.[83] In line with the predictions of the Malthusian theory, a cross-country analysis finds a significant positive effect of the technological level on population density and an insignificant effect on income per capita significantly over the years 1–1500.[83]
",4
4376,"In classical (Ricardian) economics, the theory of production and the theory of growth are based on the theory or law of variable proportions, whereby increasing either of the factors of production (labor or capital), while holding the other constant and assuming no technological change, will increase output, but at a diminishing rate that eventually will approach zero. These concepts have their origins in Thomas Malthus’s theorizing about agriculture. Malthus's examples included the number of seeds harvested relative to the number of seeds planted (capital) on a plot of land and the size of the harvest from a plot of land versus the number of workers employed.[84] See also Diminishing returns.
",4
4377,"Criticisms of classical growth theory are that technology, an important factor in economic growth, is held constant and that economies of scale are ignored.[85]
",4
4378,"One popular theory in the 1940s was the big push model, which suggested that countries needed to jump from one stage of development to another through a virtuous cycle, in which large investments in infrastructure and education coupled with private investments would move the economy to a more productive stage, breaking free from economic paradigms appropriate to a lower productivity stage.[86] The idea was revived and formulated rigorously, in the late 1980s by Kevin Murphy, Andrei Shleifer and Robert Vishny.[87]
",4
4379,"Robert Solow and Trevor Swan developed what eventually became the main model used in growth economics in the 1950s.[88][89] This model assumes that there are diminishing returns to capital and labor. Capital accumulates through investment, but its level or stock continually decreases due to depreciation. Due to the diminishing returns to capital, with increases in capital/worker and absent technological progress, economic output/worker eventually reaches a point where capital per worker and economic output/worker remain constant because annual investment in capital equals annual depreciation. This condition is called the 'steady state'.
",4
4380,"In the Solow–Swan model if productivity increases through technological progress, then output/worker increases even when the economy is in the steady state. If productivity increases at a constant rate, output/worker also increases at a related steady-state rate. As a consequence, growth in the model can occur either by increasing the share of GDP invested or through technological progress. But at whatever share of GDP invested, capital/worker eventually converges on the steady state, leaving the growth rate of output/worker determined only by the rate of technological progress. As a consequence, with world technology available to all and progressing at a constant rate, all countries have the same steady state rate of growth. Each country has a different level of GDP/worker determined by the share of GDP it invests, but all countries have the same rate of economic growth. Implicitly in this model rich countries are those that have invested a high share of GDP for a long time. Poor countries can become rich by increasing the share of GDP they invest. One important prediction of the model, mostly borne out by the data, is that of conditional convergence; the idea that poor countries will grow faster and catch up with rich countries as long as they have similar investment (and saving) rates and access to the same technology.
",4
4381,"The Solow–Swan model is considered an ""exogenous"" growth model because it does not explain why countries invest different shares of GDP in capital nor why technology improves over time. Instead, the rate of investment and the rate of technological progress are exogenous. The value of the model is that it predicts the pattern of economic growth once these two rates are specified. Its failure to explain the determinants of these rates is one of its limitations.
",4
4382,"Although the rate of investment in the model is exogenous, under certain conditions the model implicitly predicts convergence in the rates of investment across countries. In a global economy with a global financial capital market, financial capital flows to the countries with the highest return on investment. In the Solow-Swan model countries with less capital/worker (poor countries) have a higher return on investment due to the diminishing returns to capital. As a consequence, capital/worker and output/worker in a global financial capital market should converge to the same level in all countries.[90] Since historically financial capital has not flowed to the countries with less capital/worker, the basic Solow–Swan model has a conceptual flaw. Beginning in the 1990s, this flaw has been addressed by adding additional variables to the model that can explain why some countries are less productive than others and, therefore, do not attract flows of global financial capital even though they have less (physical) capital/worker.
",4
4383,"In practice, convergence was rarely achieved. In 1957, Solow applied his model to data from the U.S. gross national product to estimate contributions. This showed that the increase in capital and labor stock only accounted for about half of the output, while the population increase adjustments to capital explained eighth. This remaining unaccounted growth output is known as the Solow Residual. Here the A of (t) ""technical progress"" was the reason for increased output. Nevertheless, the model still had flaws. It gave no room for policy to influence the growth rate. Few attempts were also made by the RAND Corporation the non-profit think tank and frequently visiting economist Kenneth Arrow to work out the kinks in the model. They suggested that new knowledge was indivisible and that it is endogenous with a certain fixed cost. Arrow's further explained that new knowledge obtained by firms comes from practice and built a model that ""knowledge"" accumulated through experience.[91]
",4
4384,"According to Harrod, the natural growth rate is the maximum rate of growth allowed by the increase of variables like population growth, technological improvement and growth in natural resources.
",4
4385,"In fact, the natural growth rate is the highest attainable growth rate which would bring about the fullest possible employment of the resources existing in the economy.
",4
4386,"Unsatisfied with the assumption of exogenous technological progress in the Solow–Swan model, economists worked to ""endogenize"" (i.e., explain it ""from within"" the models) productivity growth in the 1980s; the resulting endogenous growth theory, most notably advanced by Robert Lucas, Jr. and his student Paul Romer, includes a mathematical explanation of technological advancement.[17][92] This model also incorporated a new concept of human capital, the skills and knowledge that make workers productive. Unlike physical capital, human capital has increasing rates of return. Research done in this area has focused on what increases human capital (e.g. education) or technological change (e.g. innovation).[93]
",4
4387,"On Memorial Day weekend in 1988, a conference in Buffalo brought together the great minds in economics the idea was to evaluate the conflicting theories of growth. Romer, Krugman, Barro, Becker were in attendance along with many other rising stars and high profiled economists of the time. Amongst many papers that day the one that stood out was Romer's ""Micro Foundations for Aggregate Technological Change."" The Micro Foundation claimed that endogenous technological change had the concept of Intellectual Property imbedded and that knowledge is an input and output of production. Romer argued that outcomes to the national growth rates were significantly affected by public policy, trade activity, and intellectual property. He stressed that cumulative capital and specialization were key, and that not only population growth can increase capital of knowledge, it was human capital that is specifically trained in harvesting new ideas.[94]
",4
4388,"While intellectual property may be important, Baker (2016) cites multiple sources claiming that ""stronger patent protection seems to be associated with slower growth"".  That's particularly true for patents in the ethical health care industry.  In effect taxpayers pay twice for new drugs and diagnostic procedures:  First in tax subsidies and second for the high prices of diagnostic procedures treatments.  If the results of research paid by taxpayers were placed in the public domain, Baker claims that people everywhere would be healthier, because better diagnoses and treatment would be more affordable the world over.[95]
",4
4389,"One branch of endogenous growth theory was developed on the foundations of the Schumpeterian theory, named after the 20th-century Austrian economist Joseph Schumpeter.[96] The approach explains growth as a consequence of innovation and a process of creative destruction that captures the dual nature of technological progress: in terms of creation, entrepreneurs introduce new products or processes in the hope that they will enjoy temporary monopoly-like profits as they capture markets. In doing so, they make old technologies or products obsolete. This can be seen as an annulment of previous technologies, which makes them obsolete, and ""destroys the rents generated by previous innovations"".[97]:855[98] A major model that illustrates Schumpeterian growth is the Aghion–Howitt model [ru].[99][97]
",4
4390,"Unified growth theory was developed by Oded Galor and his co-authors to address the inability of endogenous growth theory to explain key empirical regularities in the growth processes of individual economies and the world economy as a whole.[100][101] Unlike endogenous growth theory that focuses entirely on the modern growth regime and is therefore unable to explain the roots of inequality across nations, unified growth theory captures in a single framework the fundamental phases of the process of development in the course of human history: (i) the Malthusian epoch that was prevalent over most of human history, (ii) the escape from the Malthusian trap, (iii) the emergence of human capital as a central element in the growth process, (iv) the onset of the fertility decline, (v) the origins of the modern era of sustained economic growth, and (vi) the roots of divergence in income per capita across nations in the past two centuries. The theory suggests that during most of human existence, technological progress was offset by population growth, and living standards were near subsistence across time and space. However, the reinforcing interaction between the rate of technological progress and the size and composition of the population has gradually increased the pace of technological progress, enhancing the importance of education in the ability of individuals to adapt to the changing technological environment. The rise in the allocation of resources towards education triggered a fertility decline enabling economies to allocate a larger share of the fruits of technological progress to a steady increase in income per capita, rather than towards the growth of population, paving the way for the emergence of sustained economic growth. The theory further suggests that variations in biogeographical characteristics, as well as cultural and institutional characteristics, have generated a differential pace of transition from stagnation to growth across countries and consequently divergence in their income per capita over the past two centuries.[100][101]
",4
4391,"The prevailing views about the role of inequality in the growth process has radically shifted in the past century.[102]
",4
4392,"The classical perspective, as expressed by Adam Smith, and others, suggests that inequality fosters the growth process.[103][104] Specifically, since the aggregate saving increases with inequality due to higher property to save among the wealthy, the classical viewpoint suggests that inequality stimulates capital accumulation and therefore economic growth.[105]
",4
4393,"The Neoclassical perspective that is based on representative agent approach denies the role of inequality in the growth process. It suggests that while the growth process may affect inequality, income distribution has no impact on the growth process.
",4
4394,"The modern perspective which has emerged in the late 1980s suggests, in contrast, that income distribution has a significant impact on the growth process. The modern perspective, originated by Galor and Zeira,[106][107] highlights the important role of heterogeneity in the determination of aggregate economic activity, and economic growth. In particular, Galor and Zeira argue that since credit markets are imperfect, inequality has an enduring impact on human capital formation, the level of income per capita, and the growth process.[108] In contrast to the classical paradigm, which underlined the positive implications of inequality for capital formation and economic growth, Galor and Zeira argue that inequality has an adverse effect on human capital formation and the development process, in all but the very poor economies.
",4
4395,"Later theoretical developments have reinforced the view that inequality has an adverse effect on the growth process. Specifically, Alesina and Rodrik and Persson and Tabellini advance a political economy mechanism and argue that inequality has a negative impact on economic development since it creates a pressure for distortionary redistributive policies that have an adverse effect on investment and economic growth.[109][110]
",4
4396,"In accordance with the credit market imperfection approach, a study by Roberto Perotti showed that inequality is associated with lower level of human capital formation (education, experience, apprenticeship) and higher level of fertility, while lower level of human capital is associated with lower growth and lower levels of economic growth. In contrast, his examination of the political economy channel found no support for the political economy mechanism.[111] Consequently, the political economy perspective on the relationship between inequality and growth have been revised and later studies have established that inequality may provide an incentive for the elite to block redistributive policies and institutional changes. In particular, inequality in the distribution of land ownership provides the landed elite with an incentive to limit the mobility of rural workers by depriving them from education and by blocking the development of the industrial sector.[112]
",4
4397,"A unified theory of inequality and growth that captures that changing role of inequality in the growth process offers a reconciliation between the conflicting predictions of classical viewpoint that maintained that inequality is beneficial for growth and the modern viewpoint that suggests that in the presence of credit market imperfections, inequality predominantly results in underinvestment in human capital and lower economic growth. This unified theory of inequality and growth, developed by Oded Galor and Omer Moav,[113] suggests that the effect of inequality on the growth process has been reversed as human capital has replaced physical capital as the main engine of economic growth. In the initial phases of industrialization, when physical capital accumulation was the dominating source of economic growth, inequality boosted the development process by directing resources toward individuals with higher propensity to save. However, in later phases, as human capital become the main engine of economic growth, more equal distribution of income, in the presence of credit constraints, stimulated investment in human capital and economic growth.
",4
4398,"In 2013, French economist Thomas Piketty postulated that in periods when the average annual rate on return on investment in capital (r) exceeds the average annual growth in economic output (g), the rate of inequality will increase.[114] According to Piketty, this is the case because wealth that is already held or inherited, which is expected to grow at the rate r, will grow at a rate faster than wealth accumulated through labor, which is more closely tied to g. An advocate of reducing inequality levels, Piketty suggests levying a global wealth tax in order to reduce the divergence in wealth caused by inequality.
",4
4399,"The reduced form empirical relationship between inequality and growth was studied by Alberto Alesina and Dani Rodrik, and Torsten Persson and Guido Tabellini.[109][110] They find that inequality is negatively associated with economic growth in a cross-country analysis.
",4
4400,"Robert Barro reexamined the reduced form relationship between inequality on economic growth in a panel of countries.[115] He argues that there is ""little overall relation between income inequality and rates of growth and investment"". However, his empirical strategy limits its applicability to the understanding of the relationship between inequality and growth for several reasons. First, his regression analysis control for education, fertility, investment, and it therefore excludes, by construction, the important effect of inequality on growth via education, fertility, and investment. His findings simply imply that inequality has no direct effect on growth beyond the important indirect effects through the main channels proposed in the literature. Second, his study analyzes the effect of inequality on the average growth rate in the following 10 years. However, existing theories suggest that the effect of inequality will be observed much later, as is the case in human capital formation, for instance. Third, the empirical analysis does not account for biases that are generated by reverse causality and omitted variables.
",4
4401,"Recent papers based on superior data, find negative relationship between inequality and growth. Andrew Berg and Jonathan Ostry of the International Monetary Fund, find that ""lower net inequality is robustly correlated with faster and more durable growth, controlling for the level of redistribution"".[116] Likewise, Dierk Herzer and Sebastian Vollmer find that increased income inequality reduces economic growth.[117]
",4
4402,"The Galor and Zeira's model predicts that the effect of rising inequality on GDP per capita is negative in relatively rich countries but positive in poor countries.[106][107] These testable predictions have been examined and confirmed empirically in recent studies.[118][119] In particular, Brückner and Lederman test the prediction of the model by in the panel of countries during the period 1970–2010, by considering the impact of the interaction between the level of income inequality and the initial level of GDP per capita. In line with the predictions of the model, they find that at the 25th percentile of initial income in the world sample, a 1 percentage point increase in the Gini coefficient increases income per capita by 2.3%, whereas at the 75th percentile of initial income a 1 percentage point increase in the Gini coefficient decreases income per capita by -5.3%. Moreover, the proposed human capital mechanism that mediates the effect of inequality on growth in the Galor-Zeira model is also confirmed. Increases in income inequality increase human capital in poor countries but reduce it in high and middle-income countries.
",4
4403,"This recent support for the predictions of the Galor-Zeira model is in line with earlier findings. Roberto Perotti showed that in accordance with the credit market imperfection approach, developed by Galor and Zeira, inequality is associated with lower level of human capital formation (education, experience, apprenticeship) and higher level of fertility, while lower level of human capital is associated with lower levels of economic growth.[111] Princeton economist Roland Benabou's finds that the growth process of Korea and the Philippines ""are broadly consistent with the credit-constrained human-capital accumulation hypothesis"".[120] In addition, Andrew Berg and Jonathan Ostry[116] suggest that inequality seems to affect growth through human capital accumulation and fertility channels.
",4
4404,"In contrast, Perotti argues that the political economy mechanism is not supported empirically. Inequality is associated with lower redistribution, and lower redistribution (under-investment in education and infrastructure) is associated with lower economic growth.[111]
",4
4405,"Over long periods of time, even small rates of growth, such as a 2% annual increase, have large effects. For example, the United Kingdom experienced a 1.97% average annual increase in its inflation-adjusted GDP between 1830 and 2008.[121] In 1830, the GDP was 41,373 million pounds. It grew to 1,330,088 million pounds by 2008. A growth rate that averaged 1.97% over 178 years resulted in a 32-fold increase in GDP by 2008.
",4
4406,"The large impact of a relatively small growth rate over a long period of time is due to the power of exponential growth. The rule of 72, a mathematical result, states that if something grows at the rate of x% per year, then its level will double every 72/x years. For example, a growth rate of 2.5% per annum leads to a doubling of the GDP within 28.8 years, whilst a growth rate of 8% per year leads to a doubling of GDP within nine years. Thus, a small difference in economic growth rates between countries can result in very different standards of living for their populations if this small difference continues for many years.
",4
4407,"One theory that relates economic growth with quality of life is the ""Threshold Hypothesis"", which states that economic growth up to a point brings with it an increase in quality of life. But at that point – called the threshold point – further economic growth can bring with it a deterioration in quality of life.[122] This results in an upside-down-U-shaped curve, where the vertex of the curve represents the level of growth that should be targeted. Happiness has been shown to increase with GDP per capita, at least up to a level of $15,000 per person.[123]
",4
4408,"Economic growth has the indirect potential to alleviate poverty, as a result of a simultaneous increase in employment opportunities and increased labor productivity.[124] A study by researchers at the Overseas Development Institute (ODI) of 24 countries that experienced growth found that in 18 cases, poverty was alleviated.[124]
",4
4409,"In some instances, quality of life factors such as healthcare outcomes and educational attainment, as well as social and political liberties, do not improve as economic growth occurs.[125][dubious  – discuss]
",4
4410,"Productivity increases do not always lead to increased wages, as can be seen in the United States, where the gap between productivity and wages has been rising since the 1980s.[124]
",4
4411,"While acknowledging the central role economic growth can potentially play in human development, poverty reduction and the achievement of the Millennium Development Goals, it is becoming widely understood amongst the development community that special efforts must be made to ensure poorer sections of society are able to participate in economic growth.[126][127][128] The effect of economic growth on poverty reduction – the growth elasticity of poverty – can depend on the existing level of inequality.[129][130] For instance, with low inequality a country with a growth rate of 2% per head and 40% of its population living in poverty, can halve poverty in ten years, but a country with high inequality would take nearly 60 years to achieve the same reduction.[131][132] In the words of the Secretary General of the United Nations Ban Ki-Moon: ""While economic growth is necessary, it is not sufficient for progress on reducing poverty.""[126]
",4
4412,"Critics such as the Club of Rome argue that a narrow view of economic growth, combined with globalization, is creating a scenario where we could see a systemic collapse of our planet's natural resources.[133][134]
",4
4413,"Concerns about negative environmental effects of growth have prompted some people to advocate lower levels of growth, or the abandoning of growth altogether. In academia, concepts like uneconomic growth, steady-state economy and degrowth have been developed in order to achieve this and to overcome possible growth imperatives. In politics, green parties embrace the Global Greens Charter, recognising that ""... the dogma of economic growth at any cost and the excessive and wasteful use of natural resources without considering Earth's carrying capacity, are causing extreme deterioration in the environment and a massive extinction of species.""[135]:2
",4
4414,"The 2019 Global Assessment Report on Biodiversity and Ecosystem Services published by the United Nations' Intergovernmental Science-Policy Platform on Biodiversity and Ecosystem Services warned that given the substantial loss of biodiversity, society should not focus solely on economic growth.[136][137] Anthropologist Eduardo S. Brondizio, one of the co-chairs of the report, said ""We need to change our narratives. Both our individual narratives that associate wasteful consumption with quality of life and with status, and the narratives of the economic systems that still consider that environmental degradation and social inequality are inevitable outcomes of economic growth. Economic growth is a means and not an end. We need to look for the quality of life of the planet.""[138]
",4
4415,"Those more optimistic about the environmental impacts of growth believe that, though localized environmental effects may occur, large-scale ecological effects are minor. The argument, as stated by commentator Julian Lincoln Simon, states that if these global-scale ecological effects exist, human ingenuity will find ways to adapt to them.[139] Conversely Partha Dasgupta, in a 2021 report on the economics of biodiversity commissioned by the British Treasury, argues that biodiversity is collapsing faster than at any time in human history as a result of the demands of contemporary human civilization, which ""far exceed nature's capacity to supply us with the goods and services we all rely on. We would require 1.6 Earths to maintain the world’s current living standards."" He says that major transformative changes will be needed ""akin to, or even greater than, those of the Marshall Plan,"" including abandoning GDP as a measure of economic success and societal progress.[140]
",4
4416,"In 2019, a warning on climate change signed by 11,000 scientists from over 150 nations said economic growth is the driving force behind the ""excessive extraction of materials and overexploitation of ecosystems"" and that this ""must be quickly curtailed to maintain long-term sustainability of the biosphere."" They add that ""our goals need to shift from GDP growth and the pursuit of affluence toward sustaining ecosystems and improving human well-being by prioritizing basic needs and reducing inequality.""[141][142] A 2021 paper authored by top scientists in Frontiers in Conservation Science posited that given the environmental crises including biodiversity loss and climate change, and possible ""ghastly future"" facing humanity, there must be ""fundamental changes to global capitalism,"" including the ""abolition of perpetual economic growth.""[143][144][145]
",4
4417,"Up to the present, there is a close correlation between economic growth and the rate of carbon dioxide emissions across nations, although there is also a considerable divergence in carbon intensity (carbon emissions per GDP).[146] Up to the present, there is also a direct relation between global economic wealth and the rate of global emissions.[147] The Stern Review notes that the prediction that, ""Under business as usual, global emissions will be sufficient to propel greenhouse gas concentrations to over 550 ppm CO2 by 2050 and over 650–700 ppm by the end of this century is robust to a wide range of changes in model assumptions."" The scientific consensus is that planetary ecosystem functioning without incurring dangerous risks requires stabilization at 450–550 ppm.[148]
",4
4418,"As a consequence, growth-oriented environmental economists propose government intervention into switching sources of energy production, favouring wind, solar, hydroelectric, and nuclear. This would largely confine use of fossil fuels to either domestic cooking needs (such as for kerosene burners) or where carbon capture and storage technology can be cost-effective and reliable.[149] The Stern Review, published by the United Kingdom Government in 2006, concluded that an investment of 1% of GDP (later changed to 2%) would be sufficient to avoid the worst effects of climate change, and that failure to do so could risk climate-related costs equal to 20% of GDP. Because carbon capture and storage are as yet widely unproven, and its long term effectiveness (such as in containing carbon dioxide 'leaks') unknown, and because of current costs of alternative fuels, these policy responses largely rest on faith of technological change.
",4
4419,"British conservative politician and journalist Nigel Lawson has deemed carbon emission trading an 'inefficient system of rationing'. Instead, he favours carbon taxes to make full use of the efficiency of the market. However, in order to avoid the migration of energy-intensive industries, the whole world should impose such a tax, not just Britain, Lawson pointed out. There is no point in taking the lead if nobody follows suit.[150]
",4
4420,"Many earlier predictions of resource depletion, such as Thomas Malthus' 1798 predictions about approaching famines in Europe, The Population Bomb,[151][152] and the Simon–Ehrlich wager (1980)[153] have not materialized. Diminished production of most resources has not occurred so far, one reason being that advancements in technology and science have allowed some previously unavailable resources to be produced.[153] In some cases, substitution of more abundant materials, such as plastics for cast metals, lowered growth of usage for some metals. In the case of the limited resource of land, famine was relieved firstly by the revolution in transportation caused by railroads and steam ships, and later by the Green Revolution and chemical fertilizers, especially the Haber process for ammonia synthesis.[154][155]
",4
4421,"Resource quality is composed of a variety of factors including ore grades, location, altitude above or below sea level, proximity to railroads, highways, water supply and climate. These factors affect the capital and operating cost of extracting resources. In the case of minerals, lower grades of mineral resources are being extracted, requiring higher inputs of capital and energy for both extraction and processing. Copper ore grades have declined significantly over the last century.[156][157] Another example is natural gas from shale and other low permeability rock, whose extraction requires much higher inputs of energy, capital, and materials than conventional gas in previous decades. Offshore oil and gas have exponentially increased cost as water depth increases.
",4
4422,"Some physical scientists like Sanyam Mittal regard continuous economic growth as unsustainable.[158][159] Several factors may constrain economic growth – for example: finite, peaked, or depleted resources.
",4
4423,"In 1972, The Limits to Growth study modeled limitations to infinite growth; originally ridiculed,[151][152][160] some of the predicted trends have materialized, raising concerns of an impending collapse or decline due to resource constraints.[161][162][163]
",4
4424,"Malthusians such as William R. Catton, Jr. are skeptical of technological advances that improve resource availability. Such advances and increases in efficiency, they suggest, merely accelerate the drawing down of finite resources. Catton claims that increasing rates of resource extraction are ""...stealing ravenously from the future"".[164]
",4
4425,"Energy economic theories hold that rates of energy consumption and energy efficiency are linked causally to economic growth. The Garrett Relation holds that there has been a fixed relationship between current rates of global energy consumption and the historical accumulation of world GDP, independent of the year considered. It follows that economic growth, as represented by GDP growth, requires higher rates of energy consumption growth. Seemingly paradoxically, these are sustained through increases in energy efficiency.[165] Increases in energy efficiency were a portion of the increase in Total factor productivity.[14] Some of the most technologically important innovations in history involved increases in energy efficiency. These include the great improvements in efficiency of conversion of heat to work, the reuse of heat, the reduction in friction and the transmission of power, especially through electrification.[166][167] There is a strong correlation between per capita electricity consumption and economic development.[168][169]
",4
4426,"
",4
4427,"Milton Friedman (/ˈfriːdmən/; July 31, 1912 – November 16, 2006) was an American economist and statistician who received the 1976 Nobel Memorial Prize in Economic Sciences for his research on consumption analysis, monetary history and theory and the complexity of stabilization policy.[4] With George Stigler and others, Friedman was among the intellectual leaders of the Chicago school of economics, a neoclassical school of economic thought associated with the work of the faculty at the University of Chicago that rejected Keynesianism in favor of monetarism until the mid-1970s, when it turned to new classical macroeconomics heavily based on the concept of rational expectations. Several students and young professors who were recruited or mentored by Friedman at Chicago went on to become leading economists, including Gary Becker, Robert Fogel, Thomas Sowell[5] and Robert Lucas Jr.[6]
",4
4428,"Friedman's challenges to what he later called ""naive Keynesian theory""[7] began with his 1950s interpretation of the consumption function. During the 1960s he became the main advocate opposing Keynesian government policies,[8] and described his approach (along with mainstream economics) as using ""Keynesian language and apparatus"" yet rejecting its initial conclusions.[9] He theorized that there existed a natural rate of unemployment and argued that unemployment below this rate would cause inflation to accelerate.[10] He argued that the Phillips curve was in the long run vertical at the 'natural rate' and predicted what would come to be known as stagflation.[11] Friedman promoted an alternative macroeconomic viewpoint known as 'monetarism' and argued that a steady, small expansion of the money supply was the preferred policy.[12] His ideas concerning monetary policy, taxation, privatization and deregulation influenced government policies, especially during the 1980s. His monetary theory influenced the Federal Reserve's response to the global financial crisis of 2007–2008.[13]
",4
4429,"Friedman was an advisor to Republican President Ronald Reagan[3] and Conservative British Prime Minister Margaret Thatcher.[2] His political philosophy extolled the virtues of a free market economic system with minimal government intervention. He once stated that his role in eliminating conscription in the United States was his proudest accomplishment. In his 1962 book Capitalism and Freedom, Friedman advocated policies such as a volunteer military, freely floating exchange rates, abolition of medical licenses, a negative income tax and school vouchers[14] and opposed the war on drugs. His support for school choice led him to found the Friedman Foundation for Educational Choice, later renamed EdChoice.[15]
",4
4430,"Friedman's works include monographs, books, scholarly articles, papers, magazine columns, television programs, and lectures, and cover a broad range of economic topics and public policy issues.[16] His books and essays have had global influence, including in former communist states.[17][18][19][20] A 2011 survey of economists ranked Friedman as the second-most popular economist of the 20th century, following only John Maynard Keynes.[21] Upon his death, The Economist described him as ""the most influential economist of the second half of the 20th century ... possibly of all of it"".[22]
",4
4431,"Friedman was born in Brooklyn, New York on July 31, 1912. His parents, Sára Ethel (née Landau) and Jenő Saul Friedman,[23] were Jewish immigrants from Beregszász in Carpathian Ruthenia, Kingdom of Hungary (now Berehove in Ukraine). They both worked as dry goods merchants. Shortly after his birth, the family relocated to Rahway, New Jersey. In his early teens, Friedman was injured in a car accident, which scarred his upper lip.[24][25] A talented student, Friedman graduated from Rahway High School in 1928, just before his 16th birthday.[26][27] He was awarded a competitive scholarship to Rutgers University (then a private university receiving limited support from the State of New Jersey, e.g., for such scholarships). He specialized in mathematics and economics, and became influenced by two economics professors, Arthur F. Burns and Homer Jones, who convinced him that modern economics could help end the Great Depression.
",4
4432,"Friedman graduated in 1932, and initially intended to become an actuary. But he was offered two scholarships to do graduate work, one in mathematics at Brown University and the other in economics at the University of Chicago.[28] Friedman chose the latter, earning a Master of Arts degree in 1933. He was strongly influenced by Jacob Viner, Frank Knight, and Henry Simons. Friedman met his future wife, economist Rose Director, while at the University of Chicago.[29]
",4
4433,"During the 1933–1934 academic year, he had a fellowship at Columbia University, where he studied statistics with statistician and economist Harold Hotelling. He was back in Chicago for the 1934–1935 academic year, working as a research assistant for Henry Schultz, who was then working on Theory and Measurement of Demand. That year, Friedman formed what would prove to be lifelong friendships with George Stigler and W. Allen Wallis.[30]
",4
4434,"Friedman was unable to find academic employment, so in 1935 he followed his friend W. Allen Wallis to Washington, D.C., where Franklin D. Roosevelt's New Deal was ""a lifesaver"" for many young economists.[31] At this stage, Friedman said that he and his wife ""regarded the job-creation programs such as the WPA, CCC, and PWA appropriate responses to the critical situation,"" but not ""the price- and wage-fixing measures of the National Recovery Administration and the Agricultural Adjustment Administration.""[32] Foreshadowing his later ideas, he believed price controls interfered with an essential signaling mechanism to help resources be used where they were most valued. Indeed, Friedman later concluded that all government intervention associated with the New Deal was ""the wrong cure for the wrong disease,"" arguing that the money supply should simply have been expanded, instead of contracted.[33] Later, Friedman and his colleague Anna Schwartz wrote A Monetary History of the United States, 1867–1960, which argued that the Great Depression was caused by a severe monetary contraction due to banking crises and poor policy on the part of the Federal Reserve.[34] Robert J. Shiller describes the book as the ""most influential account"" of the Great Depression.[35]
",4
4435,"During 1935, he began working for the National Resources Planning Board,[36] which was then working on a large consumer budget survey. Ideas from this project later became a part of his Theory of the Consumption Function. Friedman began employment with the National Bureau of Economic Research during the autumn of 1937 to assist Simon Kuznets in his work on professional income. This work resulted in their jointly authored publication Incomes from Independent Professional Practice, which introduced the concepts of permanent and transitory income, a major component of the Permanent Income Hypothesis that Friedman worked out in greater detail in the 1950s. The book hypothesizes that professional licensing artificially restricts the supply of services and raises prices.
",4
4436,"During 1940, Friedman was appointed as an assistant professor teaching Economics at the University of Wisconsin–Madison, but encountered antisemitism in the Economics department and returned to government service.[37][38] From 1941 to 1943 Friedman worked on wartime tax policy for the federal government, as an advisor to senior officials of the United States Department of the Treasury. As a Treasury spokesman during 1942, he advocated a Keynesian policy of taxation. He helped to invent the payroll withholding tax system, since the federal government needed money to fund the war.[39] He later said, ""I have no apologies for it, but I really wish we hadn't found it necessary and I wish there were some way of abolishing withholding now.""[40] In Milton and Rose Friedman's jointly-written memoir, he wrote, ""Rose has repeatedly chided me over the years about the role that I played in making possible the current overgrown government we both criticize so strongly.""[41]
",4
4437,"In 1940, Friedman accepted a position at the University of Wisconsin–Madison, but left because of differences with faculty regarding United States involvement in World War II. Friedman believed the United States should enter the war.[42] In 1943, Friedman joined the Division of War Research at Columbia University (headed by W. Allen Wallis and Harold Hotelling), where he spent the rest of World War II working as a mathematical statistician, focusing on problems of weapons design, military tactics, and metallurgical experiments.[42][43]
",4
4438,"In 1945, Friedman submitted Incomes from Independent Professional Practice (co-authored with Kuznets and completed during 1940) to Columbia as his doctoral dissertation. The university awarded him a PhD in 1946.[44][45] Friedman spent the 1945–1946 academic year teaching at the University of Minnesota (where his friend George Stigler was employed). On February 12, 1945, his son, David D. Friedman was born.
",4
4439,"In 1946, Friedman accepted an offer to teach economic theory at the University of Chicago (a position opened by departure of his former professor Jacob Viner to Princeton University). Friedman would work for the University of Chicago for the next 30 years. There he contributed to the establishment of an intellectual community that produced a number of Nobel Memorial Prize winners, known collectively as the Chicago school of economics.
",4
4440,"At that time, Arthur F. Burns, who was then the head of the National Bureau of Economic Research, asked Friedman to rejoin the Bureau's staff. He accepted the invitation, and assumed responsibility for the Bureau's inquiry into the role of money in the business cycle. As a result, he initiated the ""Workshop in Money and Banking"" (the ""Chicago Workshop""), which promoted a revival of monetary studies. During the latter half of the 1940s, Friedman began a collaboration with Anna Schwartz, an economic historian at the Bureau, that would ultimately result in the 1963 publication of a book co-authored by Friedman and Schwartz, A Monetary History of the United States, 1867–1960.
",4
4441,"Friedman spent the 1954–1955 academic year as a Fulbright Visiting Fellow at Gonville and Caius College, Cambridge. At the time, the Cambridge economics faculty was divided into a Keynesian majority (including Joan Robinson and Richard Kahn) and an anti-Keynesian minority (headed by Dennis Robertson). Friedman speculated that he was invited to the fellowship, because his views were unacceptable to both of the Cambridge factions. Later his weekly columns for Newsweek magazine (1966–84) were well read and increasingly influential among political and business people,[46] and helped earn the magazine a Gerald Loeb Special Award in 1968.[47] From 1968 to 1978, he and Paul Samuelson participated in the Economics Cassette Series, a biweekly subscription series where the economist would discuss the days' issues for about a half-hour at a time.[48][49]
",4
4442,"One of Milton Friedman's most popular works, A Theory of the Consumption Function, challenged traditional Keynesian viewpoints about the household. This work was originally published in 1957 by Princeton University Press, and it reanalysed the relationship displayed ""between aggregate consumption or aggregate savings and aggregate income."" [50] Keynes believed that people would modify their household consumption expenditures to relate to their existing income levels. Friedman's research introduced the term ""permanent income"" to the world, which was the average of a household's expected income over several years, and he also developed the permanent income hypothesis. Milton Friedman's research changed how economists interpreted the consumption function, and his work pushed the idea that current income was not the only factor that affected people's adjustment household consumption expenditures. Instead, expected income levels also affected how households would change their consumption expenditures. Friedman's contributions strongly influenced research on consumer behavior, and he further defined how to predict consumption smoothing, which contradicts Keynes' marginal propensity to consume. Although this work presented many controversial points of view that differed from existing viewpoints established by Keynes, A Theory of the Consumption Function helped Friedman gain respect in the field of economics.
",4
4443,"His Capitalism and Freedom, inspired by a series of lectures he gave at Wabash College,[51] brought him national and international attention outside academia. It was published in 1962 by the University of Chicago Press and consists of essays that used non-mathematical economic models to explore issues of public policy.[52] It sold over 400,000 copies in the first eighteen years[53] and more than half a million since 1962. It has been translated into eighteen languages. Friedman talks about the need to move to a classically liberal society, that free markets would help nations and individuals in the long-run and fix the efficiency problems currently faced by the United States and other major countries of the 1950s and 1960s. He goes through the chapters specifying a specific issue in each respective chapter from the role of government and money supply to social welfare programs to a special chapter on occupational licensure. Friedman concludes Capitalism and Freedom with his ""classical liberal"" (more accurately, libertarian) stance, that government should stay out of matters that do not need and should only involve itself when absolutely necessary for the survival of its people and the country. He recounts how the best of a country's abilities come from its free markets while its failures come from government intervention.[54]
",4
4444,"In 1977, at the age of 65, Friedman retired from the University of Chicago after teaching there for 30 years. He and his wife moved to San Francisco, where he became a visiting scholar at the Federal Reserve Bank of San Francisco. From 1977 on, he was affiliated with the Hoover Institution at Stanford University. During the same year, Friedman was approached by the Free To Choose Network and asked to create a television program presenting his economic and social philosophy.
",4
4445,"The Friedmans worked on this project for the next three years, and during 1980, the ten-part series, titled Free to Choose, was broadcast by the Public Broadcasting Service (PBS). The companion book to the series (co-authored by Milton and his wife, Rose Friedman), also titled Free To Choose, was the bestselling nonfiction book of 1980 and has since been translated into 14 languages.
",4
4446,"Friedman served as an unofficial adviser to Ronald Reagan during his 1980 presidential campaign, and then served on the President's Economic Policy Advisory Board for the rest of the Reagan Administration. Ebenstein says Friedman was ""the 'guru' of the Reagan administration.""[3] In 1988 he received the National Medal of Science and Reagan honored him with the Presidential Medal of Freedom.
",4
4447,"Friedman is known now as one of the most influential economists of the 20th century.[55][56] Throughout the 1980s and 1990s, Friedman continued to write editorials and appear on television. He made several visits to Eastern Europe and to China, where he also advised governments. He was also for many years a Trustee of the Philadelphia Society.[57][58][59]
",4
4448,"According to a 2007 article in Commentary magazine, his ""parents were moderately observant Jews, but Friedman, after an intense burst of childhood piety, rejected religion altogether.""[60] He described himself as an agnostic.[61] Friedman wrote extensively of his life and experiences, especially in 1998 in his memoirs with his wife, Rose, titled Two Lucky People. In this book, Rose Friedman describes how she and Milton Friedman raised their two children, Janet and David, with a Christmas Tree in the home. ""Orthodox Jews of course, do not celebrate Christmas. However, just as, when I was a child, my mother had permitted me to have a Christmas tree one year when my friend had one, she not only tolerated our having a Christmas tree, she even strung popcorn to hang on it.""[62]
",4
4449,"Friedman died of heart failure at the age of 94 years in San Francisco on November 16, 2006.[63] He was still a working economist performing original economic research; his last column was published in The Wall Street Journal the day after his death.[64] He was survived by his wife (who would die on August 18, 2009) and their two children, David, known for the anarcho-capitalist book The Machinery of Freedom, and bridge expert Jan Martel.
",4
4450,"Heterodox
",4
4451,"Friedman was best known for reviving interest in the money supply as a determinant of the nominal value of output, that is, the quantity theory of money. Monetarism is the set of views associated with modern quantity theory. Its origins can be traced back to the 16th-century School of Salamanca or even further; however, Friedman's contribution is largely responsible for its modern popularization. He co-authored, with Anna Schwartz, A Monetary History of the United States, 1867–1960 (1963), which was an examination of the role of the money supply and economic activity in the U.S. history. A striking conclusion of their research regarded the way in which money supply fluctuations contribute to economic fluctuations. Several regression studies with David Meiselman during the 1960s suggested the primacy of the money supply over investment and government spending in determining consumption and output. These challenged a prevailing, but largely untested, view on their relative importance. Friedman's empirical research and some theory supported the conclusion that the short-run effect of a change of the money supply was primarily on output but that the longer-run effect was primarily on the price level.
",4
4452,"Friedman was the main proponent of the monetarist school of economics. He maintained that there is a close and stable association between inflation and the money supply, mainly that inflation could be avoided with proper regulation of the monetary base's growth rate. He famously used the analogy of ""dropping money out of a helicopter"",[65] in order to avoid dealing with money injection mechanisms and other factors that would overcomplicate his models.
",4
4453,"Friedman's arguments were designed to counter the popular concept of cost-push inflation, that the increased general price level at the time was the result of increases in the price of oil, or increases in wages; as he wrote:
",4
4454,Inflation is always and everywhere a monetary phenomenon.,4
4455,"Friedman rejected the use of fiscal policy as a tool of demand management; and he held that the government's role in the guidance of the economy should be restricted severely. Friedman wrote extensively on the Great Depression, and he termed the 1929–1933 period the Great Contraction. He argued that the Depression had been caused by an ordinary financial shock whose duration and seriousness were greatly increased by the subsequent contraction of the money supply caused by the misguided policies of the directors of the Federal Reserve.
",4
4456,"The Fed was largely responsible for converting what might have been a garden-variety recession, although perhaps a fairly severe one, into a major catastrophe. Instead of using its powers to offset the depression, it presided over a decline in the quantity of money by one-third from 1929 to 1933 ... Far from the depression being a failure of the free-enterprise system, it was a tragic failure of government.",4
4457,"This theory was put forth in A Monetary History of the United States, and the chapter on the Great Depression was then published as a stand-alone book entitled The Great Contraction, 1929–1933. Both books are still in print from Princeton University Press, and some editions include as an appendix a speech at a University of Chicago event honoring Friedman[68] in which Ben Bernanke made this statement:
",4
4458,"Let me end my talk by abusing slightly my status as an official representative of the Federal Reserve. I would like to say to Milton and Anna: Regarding the Great Depression, you're right. We did it. We're very sorry. But thanks to you, we won't do it again.[69][68]",4
4459,"Friedman also argued for the cessation of government intervention in currency markets, thereby spawning an enormous literature on the subject, as well as promoting the practice of freely floating exchange rates. His close friend George Stigler explained, ""As is customary in science, he did not win a full victory, in part because research was directed along different lines by the theory of rational expectations, a newer approach developed by Robert Lucas, also at the University of Chicago.""[70] The relationship between Friedman and Lucas, or new classical macroeconomics as a whole, was highly complex. The Friedmanian Phillips curve was an interesting starting point for Lucas, but he soon realized that the solution provided by Friedman was not quite satisfactory. Lucas elaborated a new approach in which rational expectations were presumed instead of the Friedmanian adaptive expectations. Due to this reformulation, the story in which the theory of the new classical Phillips curve was embedded radically changed. This modification, however, had a significant effect on Friedman's own approach, so, as a result, the theory of the Friedmanian Phillips curve also changed.[71] Moreover, new classical Neil Wallace, who was a graduate student at the University of Chicago between 1960 and 1963, regarded Friedman's theoretical courses as a mess.[72] This evaluation clearly indicates the broken relationship between Friedmanian monetarism and new classical macroeconomics.
",4
4460,"Friedman was also known for his work on the consumption function, the permanent income hypothesis (1957), which Friedman himself referred to as his best scientific work.[73] This work contended that rational consumers would spend a proportional amount of what they perceived to be their permanent income. Windfall gains would mostly be saved. Tax reductions likewise, as rational consumers would predict that taxes would have to increase later to balance public finances. Other important contributions include his critique of the Phillips curve and the concept of the natural rate of unemployment (1968). This critique associated his name, together with that of Edmund Phelps, with the insight that a government that brings about greater inflation cannot permanently reduce unemployment by doing so. Unemployment may be temporarily lower, if the inflation is a surprise, but in the long run unemployment will be determined by the frictions and imperfections of the labor market.
",4
4461,"Friedman's essay ""The Methodology of Positive Economics"" (1953) provided the epistemological pattern for his own subsequent research and to a degree that of the Chicago School. There he argued that economics as science should be free of value judgments for it to be objective. Moreover, a useful economic theory should be judged not by its descriptive realism but by its simplicity and fruitfulness as an engine of prediction. That is, students should measure the accuracy of its predictions, rather than the 'soundness of its assumptions'. His argument was part of an ongoing debate among such statisticians as Jerzy Neyman, Leonard Savage, and Ronald Fisher.[74]
",4
4462,"However, despite being an advocate of the free market, Milton Friedman believed that the government had two crucial roles. In an interview with Phil Donahue, Milton Friedman argued that ""the two basic functions of a government are to protect the nation against foreign enemy, and to protect citizens against its fellows.”.[75] He also, admitted that although privatisation of national defence could reduce the overall cost, he has not yet thought of a way to make this privatisation possible.
",4
4463,"One of his most famous contributions to statistics is sequential sampling. Friedman did statistical work at the Division of War Research at Columbia, where he and his colleagues came up with the technique. It became, in the words of The New Palgrave Dictionary of Economics, ""the standard analysis of quality control inspection"". The dictionary adds, ""Like many of Friedman's contributions, in retrospect it seems remarkably simple and obvious to apply basic economic ideas to quality control; that, however, is a measure of his genius.""[76]
",4
4464,"Although Friedman concluded the government does have a role in the monetary system[77] he was critical of the Federal Reserve due to its poor performance and felt it should be abolished.[78][79][80] He was opposed to Federal Reserve policies, even during the so-called 'Volcker shock' that was labeled 'monetarist'.[81] Friedman believed that the Federal Reserve System should ultimately be replaced with a computer program.[82] He favored a system that would automatically buy and sell securities in response to changes in the money supply.[83]
",4
4465,"The proposal to constantly grow the money supply at a certain predetermined amount every year has become known as Friedman's k-percent rule.[84] There is debate about the effectiveness of a theoretical money supply targeting regime.[85][86] The Fed's inability to meet its money supply targets from 1978–1982 has led some to conclude it is not a feasible alternative to more conventional inflation and interest rate targeting.[87] Towards the end of his life, Friedman expressed doubt about the validity of targeting the quantity of money.[88]
",4
4466,"Idealistically, Friedman actually favored the principles of the 1930s Chicago plan, which would have ended fractional reserve banking and, thus, private money creation.  It would force banks to have 100% reserves backing deposits, and instead place money creation powers solely in the hands of the US Government.  This would make targeting money growth more possible, as endogenous money created by fractional reserve lending would no longer be a major issue.[84]
",4
4467,"Friedman was a strong advocate for floating exchange rates throughout the entire Bretton-Woods period. He argued that a flexible exchange rate would make external adjustment possible and allow countries to avoid balance of payments crises. He saw fixed exchange rates as an undesirable form of government intervention. The case was articulated in an influential 1953 paper, ""The Case for Flexible Exchange Rates"", at a time when most commentators regarded the possibility of floating exchange rates as a fantasy.[89][90]
",4
4468,"In his 1955 article ""The Role of Government in Education""[91] Friedman proposed supplementing publicly operated schools with privately run but publicly funded schools through a system of school vouchers.[92] Reforms similar to those proposed in the article were implemented in, for example, Chile in 1981 and Sweden in 1992.[93] In 1996, Friedman, together with his wife, founded the Friedman Foundation for Educational Choice to advocate school choice and vouchers. In 2016, the Friedman Foundation changed its name to EdChoice to honor the Friedmans' desire to have the educational choice movement live on without their names attached to it after their deaths.[15]
",4
4469,"While Walter Oi is credited with establishing the economic basis for a volunteer military, Friedman was a proponent, stating that the draft was ""inconsistent with a free society.""[94][95]
In Capitalism and Freedom, he argued that conscription is inequitable and arbitrary, preventing young men from shaping their lives as they see fit.[96] During the Nixon administration he headed the committee to research a conversion to paid/volunteer armed force. He would later state that his role in eliminating the conscription in the United States was his proudest accomplishment.[12] Friedman did, however, believe that the introduction of a system of universal military training as a reserve in cases of war-time could be justified.[96]
But opposed its implementation in the United States, describing it as a “monstrosity”.[97]
",4
4470,"Biographer Lanny Ebenstein noted a drift over time in Friedman's views from an interventionist to a more cautious foreign policy.[98] He supported US involvement in the Second World War and initially supported a hard-line against Communism, but moderated over time.[98] However, Friedman did state in a 1995 interview that he was an anti-interventionist.[99] He opposed the Gulf War and the Iraq War.[98] In a spring 2006 interview, Friedman said that the US's stature in the world had been eroded by the Iraq War, but that it might be improved if Iraq were to become a peaceful and independent country.[100]
",4
4471,"Friedman was an economic advisor and speech writer in Barry Goldwater's presidential campaign in 1964.  He was an advisor to California governor Ronald Reagan, and was active in Reagan's presidential campaigns.[101] He served as a member of President Reagan's Economic Policy Advisory Board starting in 1981. In 1988, he received the Presidential Medal of Freedom and the National Medal of Science. He said that he was a libertarian philosophically, but a member of the U.S. Republican Party for the sake of ""expediency"" (""I am a libertarian with a small 'l' and a Republican with a capital 'R.' And I am a Republican with a capital 'R' on grounds of expediency, not on principle."") But, he said, ""I think the term classical liberal is also equally applicable. I don't really care very much what I'm called. I'm much more interested in having people thinking about the ideas, rather than the person.""[102]
",4
4472,"Friedman was supportive of the state provision of some public goods that private businesses are not considered as being able to provide. However, he argued that many of the services performed by government could be performed better by the private sector. Above all, if some public goods are provided by the state, he believed that they should not be a legal monopoly where private competition is prohibited; for example, he wrote:
",4
4473,"There is no way to justify our present public monopoly of the post office. It may be argued that the carrying of mail is a technical monopoly and that a government monopoly is the least of evils. Along these lines, one could perhaps justify a government post office, but not the present law, which makes it illegal for anybody else to carry the mail. If the delivery of mail is a technical monopoly, no one else will be able to succeed in competition with the government. If it is not, there is no reason why the government should be engaged in it. The only way to find out is to leave other people free to enter.",4
4474,"In 1962, Friedman criticized Social Security in his book Capitalism and Freedom, arguing that it had created welfare dependency.[103] However, in the penultimate chapter of the same book, Friedman argued that while capitalism had greatly reduced the extent of poverty in absolute terms, ""poverty is in part a relative matter, [and] even in [wealthy Western] countries, there are clearly many people living under conditions that the rest of us label as poverty."" Friedman also noted that while private charity could be one recourse for alleviating poverty and cited late 19th century Britain and the United States as exemplary periods of extensive private charity and eleemosynary activity, he made the following point:
",4
4475,"It can be argued that private charity is insufficient because the benefits from it accrue to people other than those who make the gifts— ... a neighborhood effect. I am distressed by the sight of poverty; I am benefited by its alleviation; but I am benefited equally whether I or someone else pays for its alleviation; the benefits of other people's charity therefore partly accrue to me. To put it differently, we might all of us be willing to contribute to the relief of poverty, provided everyone else did. We might not be willing to contribute the same amount without such assurance. In small communities, public pressure can suffice to realize the proviso even with private charity. In the large impersonal communities that are increasingly coming to dominate our society, it is much more difficult for it to do so.
Suppose one accepts, as I do, this line of reasoning as justifying governmental action to alleviate poverty; to set, as it were, a floor under the standard of life of every person in the community. [While there are questions of how much should be spent and how, the] arrangement that recommends itself on purely mechanical grounds is a negative income tax. ... The advantages of this arrangement are clear. It is directed specifically at the problem of poverty. It gives help in the form most useful to the individual, namely, cash. It is general and could be substituted for the host of special measures now in effect. It makes explicit the cost borne by society. It operates outside the market. Like any other measures to alleviate poverty, it reduces the incentives of those helped to help themselves, but it does not eliminate that incentive entirely, as a system of supplementing incomes up to some fixed minimum would. An extra dollar earned always means more money available for expenditure.",4
4476,"Friedman argued further that other advantages of the negative income tax were that it could fit directly into the tax system, would be less costly, and would reduce the administrative burden of implementing a social safety net.[104] Friedman reiterated these arguments 18 years later in Free to Choose, with the additional proviso that such a reform would only be satisfactory if it replaced the current system of welfare programs rather than augment it.[105] According to economist Robert H. Frank, writing in The New York Times, Friedman's views in this regard were grounded in a belief that while ""market forces ... accomplish wonderful things"", they ""cannot ensure a distribution of income that enables all citizens to meet basic economic needs"".[106]
",4
4477,"Friedman also supported libertarian policies such as legalization of drugs and prostitution. During 2005, Friedman and more than 500 other economists advocated discussions regarding the economic benefits of the legalization of marijuana.[107]
",4
4478,"Friedman was also a supporter of gay rights.[108] He never specifically supported same-sex marriage, instead saying ""I do not believe there should be any discrimination against gays.""[109]
",4
4479,"Friedman favored immigration, saying ""legal and illegal immigration has a very positive impact on the U.S. economy.""[110] However, he suggested that immigrants ought not to have access to the welfare system.[110] Friedman stated that immigration from Mexico had been a ""good thing"", in particular illegal immigration.[110] Friedman argued that illegal immigration was a boon because they ""take jobs that most residents of this country are unwilling to take, they provide employers with workers of a kind they cannot get"" and they do not use welfare.[110] In Free to Choose, Friedman wrote:[105]
",4
4480,"No arbitrary obstacles should prevent people from achieving those positions for which their talents fit them and which their values lead them to seek. Not birth, nationality, color, religion, sex, nor any other irrelevant characteristic should determine the opportunities that are open to a person — only his abilities.",4
4481,"Michael Walker of the Fraser Institute and Friedman hosted a series of conferences from 1986 to 1994. The goal was to create a clear definition of economic freedom and a method for measuring it. Eventually this resulted in the first report on worldwide economic freedom, Economic Freedom in the World.[111] This annual report has since provided data for numerous peer-reviewed studies and has influenced policy in several nations.
",4
4482,"Along with sixteen other distinguished economists he opposed the Copyright Term Extension Act, and signed on to an amicus brief filed in Eldred v. Ashcroft.[112] Friedman jokingly described it as a ""no-brainer"".[113]
",4
4483,"Friedman argued for stronger basic legal (constitutional) protection of economic rights and freedoms to further promote industrial-commercial growth and prosperity and buttress democracy and freedom and the rule of law generally in society.[114]
",4
4484,"George H. Nash, a leading historian of American conservatism, says that by ""the end of the 1960s he was probably the most highly regarded and influential conservative scholar in the country, and one of the few with an international reputation.""[115] In 1971, Friedman received the Golden Plate Award of the American Academy of Achievement.[116][117] Friedman allowed the libertarian Cato Institute to use his name for its biannual Milton Friedman Prize for Advancing Liberty beginning in 2001. A Friedman Prize was given to the late British economist Peter Bauer in 2002, Peruvian economist Hernando de Soto in 2004, Mart Laar, former Estonian Prime Minister in 2006 and a young Venezuelan student Yon Goicoechea in 2008. His wife Rose, sister of Aaron Director, with whom he initiated the Friedman Foundation for Educational Choice, served on the international selection committee.[118][119]
",4
4485,"Friedman was also a recipient of the Nobel Memorial Prize in Economics.
",4
4486,"Upon Friedman's death, Harvard President Lawrence Summers called him ""The Great Liberator"", saying ""... any honest Democrat will admit that we are now all Friedmanites."" He said Friedman's great popular contribution was ""in convincing people of the importance of allowing free markets to operate.""[120]
",4
4487,"Stephen Moore, a member of the editorial forward of The Wall Street Journal, said in 2013: ""Quoting the most-revered champion of free-market economics since Adam Smith has become a little like quoting the Bible."" He adds, ""There are sometimes multiple and conflicting interpretations.""[121]
",4
4488,"Friedman won the Nobel Memorial Prize in Economic Sciences, the sole recipient for 1976, ""for his achievements in the fields of consumption analysis, monetary history and theory and for his demonstration of the complexity of stabilization policy.""[4]
",4
4489,"Friedman once said: ""If you want to see capitalism in action, go to Hong Kong.""[122] He wrote in 1990 that the Hong Kong economy was perhaps the best example of a free market economy.[123]
",4
4490,"One month before his death, he wrote the article ""Hong Kong Wrong—What would Cowperthwaite say?"" in The Wall Street Journal, criticizing Donald Tsang, the Chief Executive of Hong Kong, for abandoning ""positive noninterventionism.""[124] Tsang later said he was merely changing the slogan to ""big market, small government"", where small government is defined as less than 20% of GDP. In a debate between Tsang and his rival Alan Leong before the 2007 Hong Kong Chief Executive election, Leong introduced the topic and jokingly accused Tsang of angering Friedman to death.[125]
",4
4491,"During 1975, two years after the military coup that brought military dictator President Augusto Pinochet to power and ended the government of Salvador Allende, the economy of Chile experienced a severe crisis. Friedman and Arnold Harberger accepted an invitation of a private Chilean foundation to visit Chile and speak on principles of economic freedom.[126] He spent seven days in Chile giving a series of lectures at the Universidad Católica de Chile and the (National) University of Chile. One of the lectures was entitled ""The Fragility of Freedom"" and according to Friedman, ""dealt with precisely the threat to freedom from a centralized military government.""[127]
",4
4492,"In a letter to Pinochet of April 21, 1975, Friedman considered the ""key economic problems of Chile are clearly ... inflation and the promotion of a healthy social market economy"".[128] He stated that ""There is only one way to end inflation: by drastically reducing the rate of increase of the quantity of money ..."" and that ""... cutting government spending is by far and away the most desirable way to reduce the fiscal deficit, because it ... strengthens the private sector thereby laying the foundations for healthy economic growth"".[128] As to how rapidly inflation should be ended, Friedman felt that ""for Chile where inflation is raging at 10–20% a month ... gradualism is not feasible. It would involve so painful an operation over so long a period that the patient would not survive."" Choosing ""a brief period of higher unemployment ..."" was the lesser evil.. and that ""the experience of Germany, ... of Brazil ..., of the post-war adjustment in the U.S. ... all argue for shock treatment"". In the letter Friedman recommended to deliver the shock approach with ""... a package to eliminate the surprise and to relieve acute distress"" and ""... for definiteness let me sketch the contents of a package proposal ... to be taken as illustrative"" although his knowledge of Chile was ""too limited to enable [him] to be precise or comprehensive"". He listed a ""sample proposal"" of 8 monetary and fiscal measures including ""the removal of as many as obstacles as possible that now hinder the private market. For example, suspend ... the present law against discharging employees"". He closed, stating ""Such a shock program could end inflation in months"". His letter suggested that cutting spending to reduce the fiscal deficit would result in less transitional unemployment than raising taxes.
",4
4493,"Sergio de Castro, a Chilean Chicago School graduate, became the nation's Minister of Finance in 1975. During his six-year tenure, foreign investment increased, restrictions were placed on striking and labor unions, and GDP rose yearly.[129] A foreign exchange program was created between the Catholic University of Chile and the University of Chicago. Many other Chicago School alumni were appointed government posts during and after the Pinochet years; others taught its economic doctrine at Chilean universities. They became known as the Chicago Boys.[130]
",4
4494,"Friedman defended his activity in Chile on the grounds that, in his opinion, the adoption of free market policies not only improved the economic situation of Chile but also contributed to the amelioration of Pinochet's rule and to the eventual transition to a democratic government during 1990. That idea is included in Capitalism and Freedom, in which he declared that economic freedom is not only desirable in itself but is also a necessary condition for political freedom. In his 1980 documentary Free to Choose, he said the following: ""Chile is not a politically free system, and I do not condone the system. But the people there are freer than the people in Communist societies because government plays a smaller role. ... The conditions of the people in the past few years has been getting better and not worse. They would be still better to get rid of the junta and to be able to have a free democratic system.""[131][132] In 1984, Friedman stated that he has ""never refrained from criticizing the political system in Chile.""[127] In 1991 he said: ""I have nothing good to say about the political regime that Pinochet imposed. It was a terrible political regime. The real miracle of Chile is not how well it has done economically; the real miracle of Chile is that a military junta was willing to go against its principles and support a free market regime designed by principled believers in a free market. ... In Chile, the drive for political freedom, that was generated by economic freedom and the resulting economic success, ultimately resulted in a referendum that introduced political democracy. Now, at long last, Chile has all three things: political freedom, human freedom and economic freedom. Chile will continue to be an interesting experiment to watch to see whether it can keep all three or whether, now that it has political freedom, that political freedom will tend to be used to destroy or reduce economic freedom.""[133] He stressed that the lectures he gave in Chile were the same lectures he later gave in China and other socialist states.[134] He further stated ""I do not consider it as evil for an economist to render technical economic advice to the Chilean Government, any more than I would regard it as evil for a physician to give technical medical advice to the Chilean Government to help end a medical plague.""[135]
",4
4495,"During the 2000 PBS documentary The Commanding Heights (based on the book), Friedman continued to argue that ""free markets would undermine [Pinochet's] political centralization and political control."",[136][137] and that criticism over his role in Chile missed his main contention that freer markets resulted in freer people, and that Chile's unfree economy had caused the military government. Friedman advocated for free markets which undermined ""political centralization and political control"".[138]
",4
4496,"Friedman visited Iceland during the autumn of 1984, met with important Icelanders and gave a lecture at the University of Iceland on the ""tyranny of the status quo."" He participated in a lively television debate on August 31, 1984, with socialist intellectuals, including Ólafur Ragnar Grímsson, who later became the president of Iceland.[139] When they complained that a fee was charged for attending his lecture at the university and that, hitherto, lectures by visiting scholars had been free-of-charge, Friedman replied that previous lectures had not been free-of-charge in a meaningful sense: lectures always have related costs. What mattered was whether attendees or non-attendees covered those costs. Friedman thought that it was fairer that only those who attended paid. In this discussion Friedman also stated that he did not receive any money for delivering that lecture.
",4
4497,"Although Friedman never visited Estonia, his book Free to Choose exercised a great influence on that nation's then 32-year-old prime minister, Mart Laar, who has claimed that it was the only book on economics he had read before taking office. Laar's reforms are often credited with responsibility for transforming Estonia from an impoverished Soviet Republic to the ""Baltic Tiger."" A prime element of Laar's program was introduction of the flat tax. Laar won the 2006 Milton Friedman Prize for Advancing Liberty, awarded by the Cato Institute.[140]
",4
4498,"After 1950 Friedman was frequently invited to lecture in Britain, and by the 1970s his ideas had gained widespread attention in conservative circles. For example, he was a regular speaker at the Institute of Economic Affairs (IEA), a libertarian think tank. Conservative politician Margaret Thatcher closely followed IEA programs and ideas, and met Friedman there in 1978. He also strongly influenced Keith Joseph, who became Thatcher's senior advisor on economic affairs, as well as Alan Walters and Patrick Minford, two other key advisers. Major newspapers, including the Daily Telegraph, The Times, and The Financial Times all promulgated Friedman's monetarist ideas to British decision-makers. Friedman's ideas strongly influenced Thatcher and her allies when she became Prime Minister in 1979.[141][142]
",4
4499,"After his death a number of obituaries and articles were written in Friedman's honor, citing him as one of the most important and influential economists of the post-war era.[143][144][145][146] Milton Friedman's somewhat controversial legacy[147][148] in America remains strong within the conservative movement.[149] However, some journalists and economists like Noah Smith and Scott Sumner have argued Friedman's academic legacy has been buried under his political philosophy and misinterpreted by modern conservatives.[150][151][152][153]
",4
4500,"Econometrician David Hendry criticized part of Friedman's and Anna Schwartz's 1982 Monetary Trends.[154] When asked about it during an interview with Icelandic TV in 1984,[155] Friedman said that the criticism referred to a different problem from that which he and Schwartz had tackled, and hence was irrelevant,[156] and pointed out the lack of consequential peer review amongst econometricians on Hendry's work.[157] In 2006, Hendry said that Friedman was guilty of ""serious errors"" of misunderstanding that meant ""the t-ratios he reported for UK money demand were overstated by nearly 100 per cent"", and said that, in a paper published in 1991 with Neil Ericsson,[158] he had refuted ""almost every empirical claim ... made about UK money demand"" by Friedman and Schwartz.[159] A 2004 paper updated and confirmed the validity of the Hendry–Ericsson findings through 2000.[160]
",4
4501,"Although Keynesian Nobel laureate Paul Krugman praised Friedman as a ""great economist and a great man"" after Friedman's death in 2006, and acknowledged his many, widely accepted contributions to empirical economics, Krugman had been, and remains, a prominent critic of Friedman. Krugman has written that ""he slipped all too easily into claiming both that markets always work and that only markets work. It's extremely hard to find cases in which Friedman acknowledged the possibility that markets could go wrong, or that government intervention could serve a useful purpose.""[161] Others agree Friedman was not open enough to the possibility of market inefficiencies.[162] Economist Noah Smith argues that while Friedman made many important contributions to economic theory not all of his ideas relating to macroeconomics have entirely held up over the years and that too few people are willing to challenge them.[87][163]
",4
4502,"Political scientist C.B. Macpherson disagreed with Friedman's historical assessment of economic freedom leading to political freedom, suggesting that political freedom actually gave way to economic freedom for property-owning elites. He also challenged the notion that markets efficiently allocated resources and rejected Friedman's definition of liberty.[164] Friedman's positivist methodological approach to economics has also been critiqued and debated.[165][166][167] Finnish economist Uskali Mäki has argued some of his assumptions were unrealistic and vague.[168][169]
",4
4503,"In her book The Shock Doctrine, author and social activist Naomi Klein criticized Friedman's economic liberalism, identifying it with the principles that guided the economic restructuring that followed the military coups in countries such as Chile and Argentina. Based on their assessments of the extent to which what she describes as neoliberal policies contributed to income disparities and inequality, both Klein and Noam Chomsky have suggested that the primary role of what they describe as neoliberalism was as an ideological cover for capital accumulation by multinational corporations.[170]
",4
4504,"Because of his involvement with the Pinochet government, there were international protests when Friedman was awarded the Nobel Memorial Prize in 1976.[171] Friedman was accused of supporting the military dictatorship in Chile because of the relation of economists of the University of Chicago to Pinochet, and a controversial seven-day trip[172] he took to Chile during March 1975 (less than two years after the coup that ended with the death of President Salvador Allende). Friedman answered that he was never an adviser to the dictatorship, but only gave some lectures and seminars on inflation, and met with officials, including Augusto Pinochet, while in Chile.[173]
",4
4505,"Chilean economist Orlando Letelier asserted that Pinochet's dictatorship resorted to oppression because of popular opposition to Chicago School policies in Chile.[174] After a 1991 speech on drug legalisation, Friedman answered a question on his involvement with the Pinochet regime, saying that he was never an advisor to Pinochet (also mentioned in his 1984 Iceland interview),[127] but that a group of his students at the University of Chicago were involved in Chile's economic reforms. Friedman credited these reforms with high levels of economic growth and with the establishment of democracy that has subsequently occurred in Chile.[175][176] In October 1988, after returning from a lecture tour of China during which he had met with Zhao Ziyang, General Secretary of the Communist Party of China, Friedman wrote to The Stanford Daily asking if he should anticipate a similar ""avalanche of protests for having been willing to give advice to so evil a government? And if not, why not?""[177]
",4
4506,"See also Federal Reserve International Finance Discussion Paper No. 270 Archived November 3, 2013, at the Wayback Machine (December 1985), which is a revised and shortened version of Hendry–Ericsson 1983.
",4
4507,"
",4
4508,"
",4
4509,"Friedrich August von Hayek CH FBA  (/ˈhaɪək/ HY-ək, German: [ˈfʁiːdʁɪç ˈʔaʊɡʊst ˈhaɪɛk]; 8 May 1899 – 23 March 1992), often referred to by his initials F. A. Hayek, was an Austrian-British economist and philosopher who is best known for his defence of classical liberalism. Hayek shared the 1974 Nobel Memorial Prize in Economic Sciences with Gunnar Myrdal for his ""pioneering work in the theory of money and economic fluctuations and [...] penetrating analysis of the interdependence of economic, social and institutional phenomena"".[1] His account of how changing prices communicate information that helps individuals co-ordinate their plans is widely regarded as an important achievement in economics, leading to his Nobel Prize.[2][3][4]
",4
4510,"Hayek served in World War I during his teenage years and said that this experience in the war and his desire to help avoid the mistakes that had led to the war drew him into economics.[5][6] At the University of Vienna, he studied economics, eventually receiving his doctoral degrees in law in 1921 and in political science in 1923.[5][7] He subsequently lived and worked in Austria, Great Britain, the United States, and Germany; he became a British subject in 1938. Hayek's academic life was mostly spent at the London School of Economics, and later at the University of Chicago, and the University of Freiburg. Although he is widely considered a leader of the Austrian School of Economics, he also had close connections with the Chicago School of Economics.[5][8][9][10] Hayek was also a major social theorist and political philosopher of the 20th century and as the co-founder of Mont Pelerin Society he contributed to the revival of classical liberalism in the post-war era.[11][12] His most popular work, The Road to Serfdom, has sold over 2.25 million copies (as of 2020).[13][14]
",4
4511,"Hayek was appointed a Companion of Honour in 1984 for ""services to the study of economics"".[15][16] He was the first recipient of the Hanns Martin Schleyer Prize in 1984.[17] He also received the Presidential Medal of Freedom in 1991 from President George H. W. Bush.[18] In 2011, his article ""The Use of Knowledge in Society"" was selected as one of the top 20 articles published in The American Economic Review during its first 100 years.[19]
",4
4512,"1899: Hayek born in Vienna.
",4
4513,"1917: Hayek joins the Austro-Hungarian Army.
",4
4514,"1921: Hayek earns a doctorate in law from the University of Vienna.
",4
4515,"1921: Ludwig von Mises hires Hayek in an office dealing with finance issues.
",4
4516,"1923: Hayek earns another doctorate in political science.
",4
4517,"1927: Mises and Hayek found the Austrian Institute for Business Cycle Research.
",4
4518,"1928: Hayek first meets John Maynard Keynes at a conference in London.
",4
4519,"1931: Hayek moves to the London School of Economics at the invitation of Lionel Robbins.
",4
4520,"1931–1932: Hayek becomes a critic of Keynes, writing critical reviews of his books and exchanging letters in The Times on the merits of government spending versus private investment.
",4
4521,"1936: Keynes publishes The General Theory of Employment, Interest and Money.
",4
4522,"1936: At the London Economic Club, Hayek gives a talk on the key role of information in economics.
",4
4523,"1938: Hayek becomes a British subject.
",4
4524,"1944: Hayek publishes The Road to Serfdom.
",4
4525,"1945–1946: Hayek lectures across the United States and becomes Visiting Professor at Stanford University.
",4
4526,"1947: Hayek founds the Mont Pelerin Society, aiming to keep liberty alive in a postwar world.
",4
4527,"1952: Hayek publishes The Counter-Revolution of Science and The Sensory Order.
",4
4528,"1956: Antony Fisher founds the free-market Institute of Economic Affairs, having been inspired by Hayek.
",4
4529,"1960: Publication of The Constitution of Liberty.
",4
4530,"1962: Hayek moves to the University of Freiburg, West Germany. His ideas on unplanned orders and other subjects are published in Studies in Philosophy, Politics and Economics (1967). He begins work on Law, Legislation and Liberty.
",4
4531,"1972: As prices soar in Europe and the United States, Hayek publishes a passionate critique of inflation and the Keynesian policies that cause it in A Tiger by the Tail. He goes on to propose solutions in Choice in Currency (1976) and The Denationalisation of Money (1976).
",4
4532,"1973: Death of Mises
",4
4533,"1974: Hayek is awarded the Nobel Memorial Prize.
",4
4534,"1975: Through an introduction by the Institute of Economic Affairs, the British Conservative leader Margaret Thatcher meets Hayek for the first time and is greatly impressed.
",4
4535,"1988: Publication of The Fatal Conceit: The Errors of Socialism.
",4
4536,"1991: Hayek is awarded the United States Presidential Medal of Freedom.
",4
4537,"1992: Hayek dies in Freiburg.
",4
4538,"Friedrich August von Hayek was born in Vienna to August von Hayek and Felicitas Hayek (née von Juraschek). His father, born in 1871 also in Vienna, was a medical doctor employed by the municipal ministry of health. August had a passion for botany, about which he wrote a number of monographs and was also a part-time botany lecturer at the University of Vienna. Felicitas von Juraschek was born in 1875 to a wealthy conservative and land-owning family. As her mother died several years prior to Hayek's birth, Felicitas received a significant inheritance, which provided as much as half of her and her husband's income during the early years of their marriage. Friedrich was the oldest of three brothers, Heinrich (1900–1969) and Erich (1904–1986), who were one-and-a-half and five years younger than he was.[21]
",4
4539,"His father's career as a university professor influenced Hayek's goals later in life.[22] Both of his grandfathers, who lived long enough for Hayek to know them, were scholars. Franz von Juraschek was a leading economist in Austria-Hungary and a close friend of Eugen Böhm von Bawerk, one of the founders of the Austrian School of Economics.[23] Hayek's paternal grandfather, Gustav Edler von Hayek, taught natural sciences at the Imperial Realobergymnasium (secondary school) in Vienna. He wrote works in the field of biological systematics, some of which are relatively well known.[24]
",4
4540,"On his mother's side, Hayek was second cousin to the philosopher Ludwig Wittgenstein. His mother often played with Wittgenstein's sisters and had known him well. As a result of their family relationship, Hayek became one of the first to read Wittgenstein's Tractatus Logico-Philosophicus when the book was published in its original German edition in 1921. Although he met Wittgenstein on only a few occasions, Hayek said that Wittgenstein's philosophy and methods of analysis had a profound influence on his own life and thought.[25] In his later years, Hayek recalled a discussion of philosophy with Wittgenstein when both were officers during World War I.[26] After Wittgenstein's death, Hayek had intended to write a biography of Wittgenstein and worked on collecting family materials and later assisted biographers of Wittgenstein.[27] He was related to Wittgenstein on the non-Jewish side of the Wittgenstein family. Since his youth, Hayek frequently socialized with Jewish intellectuals and he mentions that people often speculated whether he was also of Jewish ancestry. That made him curious, so he spent some time researching his ancestors and found out that he has no Jewish ancestors within five generations.[28] The surname Hayek uses the German spelling of the Czech surname Hájek.
",4
4541,"Hayek displayed an intellectual and academic bent from a very young age. He read fluently and frequently before going to school.[29] However, despite his intelligence and inquisitiveness, he did quite poorly at school, due to lack of interest and problems with teachers, which also forced him to change schools.  He was at the bottom of his class in most subjects, and once received three failing grades, in Latin, Greek and mathematics.[30]  He was very interested in theater, even attempting to write some tragedies, and biology, regularly helping his father with his botanical work.[31] At his father's suggestion, as a teenager he read the genetic and evolutionary works of Hugo de Vries and August Weismann and the philosophical works of Ludwig Feuerbach.[32] He noted Goethe as the greatest early intellectual influence.[31]  In school, Hayek was much taken by one instructor's lectures on Aristotle's ethics.[33] In his unpublished autobiographical notes, Hayek recalled a division between him and his younger brothers who were only a few years younger than him, but he believed that they were somehow of a different generation. He preferred to associate with adults.[29]
",4
4542,"In 1917, Hayek joined an artillery regiment in the Austro-Hungarian Army and fought on the Italian front. Much of Hayek's combat experience was spent as a spotter in an aeroplane. Hayek suffered damage to his hearing in his left ear during the war[34] and was decorated for bravery. During this time, Hayek also survived the 1918 flu pandemic.[35]
",4
4543,"Hayek then decided to pursue an academic career, determined to help avoid the mistakes that had led to the war. Hayek said of his experience: ""The decisive influence was really World War I. It's bound to draw your attention to the problems of political organization"". He vowed to work for a better world.[36]
",4
4544,"At the University of Vienna, Hayek initially studied mostly philosophy, psychology and economics. The University allowed students to choose their subjects freely and there wasn't much obligatory written work, or tests except main exams at the end of the study.[37] By the end of his studies Hayek became more interested in economics, mostly for financial and career reasons; he planned to combine law and economics to start a career in diplomatic service.[38]  He earned doctorates in law and political science in 1921 and 1923 respectively.
",4
4545,"For a short time, when the University of Vienna closed he studied in Constantin von Monakow's Institute of Brain Anatomy, where Hayek spent much of his time staining brain cells. Hayek's time in Monakow's lab and his deep interest in the work of Ernst Mach inspired his first intellectual project, eventually published as The Sensory Order (1952). It located connective learning at the physical and neurological levels, rejecting the ""sense data"" associationism of the empiricists and logical positivists.[39] Hayek presented his work to the private seminar he had created with Herbert Furth called the Geistkreis.[40]
",4
4546,"During Hayek's years at the University of Vienna, Carl Menger's work on the explanatory strategy of social science and Friedrich von Wieser's commanding presence in the classroom left a lasting influence on him.[32] Upon the completion of his examinations, Hayek was hired by Ludwig von Mises on the recommendation of Wieser as a specialist for the Austrian government working on the legal and economic details of the Treaty of Saint Germain. Between 1923 and 1924, Hayek worked as a research assistant to Professor Jeremiah Jenks of New York University, compiling macroeconomic data on the American economy and the operations of the Federal Reserve.[41] He was influenced by Wesley Clair Mitchell and started a doctoral program on problems of monetary stabilization but didn't finish it.[42]  His time in America wasn't especially happy.  He had very limited social contacts, missed the cultural life of Vienna, and was troubled by his poverty.[43] His family's financial situation deteriorated significantly after the War.
",4
4547,"Initially sympathetic to Wieser's democratic socialism he found Marxism rigid and unattractive, and his mild socialist phase lasted until he was about 23.[44]  Hayek's economic thinking shifted away from socialism and toward the classical liberalism of Carl Menger after reading von Mises' book Socialism. It was sometime after reading Socialism that Hayek began attending von Mises' private seminars, joining several of his university friends, including Fritz Machlup, Alfred Schutz, Felix Kaufmann and Gottfried Haberler, who were also participating in Hayek's own more general and private seminar. It was during this time that he also encountered and befriended noted political philosopher Eric Voegelin, with whom he retained a long-standing relationship.[45]
",4
4548,"With the help of Mises, in the late 1920s he founded and served as director of the Austrian Institute for Business Cycle Research before joining the faculty of the London School of Economics (LSE) in 1931 at the behest of Lionel Robbins. Upon his arrival in London, Hayek was quickly recognised as one of the leading economic theorists in the world and his development of the economics of processes in time and the co-ordination function of prices inspired the ground-breaking work of John Hicks, Abba P. Lerner and many others in the development of modern microeconomics.[46]
",4
4549,"In 1932, Hayek suggested that private investment in the public markets was a better road to wealth and economic co-ordination in Britain than government spending programs as argued in an exchange of letters with John Maynard Keynes, co-signed with Lionel Robbins and others in The Times.[47][48] The nearly decade long deflationary depression in Britain dating from Winston Churchill's decision in 1925 to return Britain to the gold standard at the old pre-war and pre-inflationary par was the public policy backdrop for Hayek's dissenting engagement with Keynes over British monetary and fiscal policy. Well beyond that single public conflict, regarding the economics of extending the length of production to the economics of labour inputs, Hayek and Keynes disagreed on many essential economics matters. Their economic disagreements were both practical and fundamental in nature. Keynes called Hayek's book Prices and Production ""one of the most frightful muddles I have ever read"", famously adding: ""It is an extraordinary example of how, starting with a mistake, a remorseless logician can end in Bedlam"".[49]
",4
4550,"Notable economists who studied with Hayek at the LSE in the 1930s and 1940s include Arthur Lewis, Ronald Coase, William Baumol, the aforementioned John Kenneth Galbraith, Leonid Hurwicz, Abba Lerner, Nicholas Kaldor, George Shackle, Thomas Balogh, L. K. Jha, Arthur Seldon, Paul Rosenstein-Rodan and Oskar Lange.[50][51][52] Some were supportive and some were critical of his ideas. Hayek also taught or tutored many other LSE students, including David Rockefeller.[53]
",4
4551,"Unwilling to return to Austria after the Anschluss brought it under the control of Nazi Germany in 1938, Hayek remained in Britain. Hayek and his children became British subjects in 1938.[54] He held this status for the remainder of his life, but he did not live in Great Britain after 1950. He lived in the United States from 1950 to 1962 and then mostly in Germany, but also briefly in Austria.[55]
",4
4552,"In 1947, Hayek was elected a Fellow of the Econometric Society.[56]
",4
4553,"Hayek was concerned about the general view in Britain's academia that fascism was a capitalist reaction to socialism and The Road to Serfdom arose from those concerns. It was written between 1940 and 1943. The title was inspired by the French classical liberal thinker Alexis de Tocqueville's writings on the ""road to servitude"".[57] It was first published in Britain by Routledge in March 1944 and was quite popular, leading Hayek to call it ""that unobtainable book"" also due in part to wartime paper rationing.[58] When it was published in the United States by the University of Chicago in September of that year, it achieved greater popularity than in Britain.[59] At the instigation of editor Max Eastman, the American magazine Reader's Digest also published an abridged version in April 1945, enabling The Road to Serfdom to reach a far wider audience than academics. The book is widely popular among those advocating individualism and classical liberalism.[60]
",4
4554,"In 1950, Hayek left the London School of Economics. After spending the 1949–1950 academic year as a visiting professor at the University of Arkansas, Hayek was brought on[clarification needed] by the University of Chicago, where he became a professor in the Committee on Social Thought. Hayek's salary was funded not by the university, but by an outside foundation, the William Volker Fund.
",4
4555,"Hayek had made contact with many at the University of Chicago in the 1940s, with Hayek's The Road to Serfdom playing a seminal role in transforming how Milton Friedman and others understood how society works.[61] Hayek conducted a number of influential faculty seminars while at the University of Chicago and a number of academics worked on research projects sympathetic to some of Hayek's own, such as Aaron Director, who was active in the Chicago School in helping to fund and establish what became the ""Law and Society"" program in the University of Chicago Law School.[62] Hayek, Frank Knight, Friedman and George Stigler worked together in forming the Mont Pèlerin Society, an international forum for neoliberals.[63] Hayek and Friedman cooperated in support of the Intercollegiate Society of Individualists, later renamed the Intercollegiate Studies Institute, an American student organisation devoted to libertarian ideas.[55][64]
",4
4556,"Although they shared most political beliefs, disagreeing primarily on question of monetary policy,[65] Hayek and Friedman worked in separate university departments with different research interests and never developed a close working relationship.  Despite their occasional social interaction they were not personally close.  According Alan O. Ebenstein, who wrote biographies of both of them, Hayek probably had a closer friendship with Keynes than with Friedman.[66]
",4
4557,"Hayek's first class at Chicago was a faculty seminar on the philosophy of science attended by many of the University of Chicago's most notable scientists of the time, including Enrico Fermi, Sewall Wright and Leó Szilárd. During his time at Chicago, he worked on the philosophy of science, economics, political philosophy and the history of ideas. His economics notes from this period have yet to be published. Hayek received a Guggenheim Fellowship in 1954.[67]
",4
4558,"Another influential political philosopher and German-speaking exile at the University of Chicago at the time was Leo Strauss, but according to his student Joseph Cropsey who also knew Hayek, there was no contact between the two of them.[68]
",4
4559,"After editing a book on John Stuart Mill's letters he planned to publish two books on the liberal order, The Constitution of Liberty and ""The Creative Powers of a Free Civilization"" (eventually the title for the second chapter of The Constitution of Liberty).[69] He completed The Constitution of Liberty in May 1959, with publication in February 1960. Hayek was concerned that ""with that condition of men in which coercion of some by others is reduced as much as is possible in society"".[70] Hayek was disappointed that the book did not receive the same enthusiastic general reception as The Road to Serfdom had sixteen years before.[71]
",4
4560,"He left Chicago mostly because of financial reasons, being concerned about his pension provisions.  His primary source of income was his salary and he received some additional money from book royalties, but avoided other lucrative sources of income for academics such as writing textbooks.[72]  He spent a lot on his frequent travels. [72] He regularly spent summers in Austrian Alps, usually in the Tyrolean village Obergurgl where he enjoyed mountain climbing, and also visited Japan four times with additional trips to Tahiti, Fiji, Indonesia, Australia, New Caledonia and Ceylon.[73]   Divorce also caused him significant financial burden, and he mentioned that he lost significant money in a financial swindle.[74]
",4
4561,"From 1962 until his retirement in 1968, he was a professor at the University of Freiburg, West Germany, where he began work on his next book, Law, Legislation and Liberty. Hayek regarded his years at Freiburg as ""very fruitful"".[75] Following his retirement, Hayek spent a year as a visiting professor of philosophy at the University of California, Los Angeles, where he continued work on Law, Legislation and Liberty, teaching a graduate seminar by the same name and another on the philosophy of social science. Preliminary drafts of the book were completed by 1970, but Hayek chose to rework his drafts and finally brought the book to publication in three volumes in 1973, 1976 and 1979.
",4
4562,"Hayek became a professor at the University of Salzburg from 1969 to 1977 and then returned to Freiburg, where he spent the rest of his days. When Hayek left Salzburg in 1977, he wrote: ""I made a mistake in moving to Salzburg"". The economics department was small and the library facilities were inadequate.[76]
",4
4563,"Hayek suffered from poor health and severe depression from 1969, with some improvement after 1974.  He had two heart attacks (one of them already in 1960) which were discovered only in retrospect and was later misdiagnosed and treated for diabetes which reduced his blood sugar level.  He also took medication for depression.  His hearing declined and that affected his social life and forced him to give up his enjoyment of theatre.  His work also suffered, he spent years unable to do any demanding work, and was occasionally so unwell that he could not get out of bed. He would continue to work on Law, Legislation and Liberty in periods when he was feeling better.[77]
",4
4564,"On 9 October 1974, it was announced that Hayek would be awarded the Nobel Memorial Prize in Economics along with Swedish economist Gunnar Myrdal. The reasons for the two of them winning the prize are described in the Nobel committee's press release.[78] He was surprised at being given the award and believed that he was given it with Myrdal to balance the award with someone from the opposite side of the political spectrum.[79] Nobel Prize in Economics was established only in 1968 and Hayek was the first free-market, non-Keynesian economist to win it.
",4
4565,"During the Nobel ceremony in December 1974, Hayek met the Russian dissident Aleksandr Solzhenitsyn. Hayek later sent him a Russian translation of The Road to Serfdom.[79] He spoke with apprehension at his award speech about the danger the authority of the prize would lend to an economist,[80] but the prize brought much greater public awareness to the then controversial ideas of Hayek and has been described by his biographer as ""the great rejuvenating event in his life"".[81]
",4
4566,"In February 1975, Margaret Thatcher was elected leader of the British Conservative Party. The Institute of Economic Affairs arranged a meeting between Hayek and Thatcher in London soon after.[82] During Thatcher's only visit to the Conservative Research Department in the summer of 1975, a speaker had prepared a paper on why the ""middle way"" was the pragmatic path the Conservative Party should take, avoiding the extremes of left and right. Before he had finished, Thatcher ""reached into her briefcase and took out a book. It was Hayek's The Constitution of Liberty. Interrupting our pragmatist, she held the book up for all of us to see. 'This', she said sternly, 'is what we believe', and banged Hayek down on the table"".[83]
",4
4567,"Despite the media depictions of him as Thatcher's guru and power behind the throne, the communication between him and the Prime Minister was not very regular, they were in contact only once or twice a year.[84]  Besides Thatcher, Hayek also made a significant influence on Enoch Powell, Keith Joseph, Nigel Lawson, Geoffrey Howe and John Biffen.[85]
",4
4568,"Hayek gained some controversy in 1978 by praising Thatcher's anti-immigration policy proposal in an article which ignited numerous accusations of anti-Semitism and racism because of his reflections on the inability of assimilation of Eastern European Jews in the Vienna of his youth.[85]  He defended himself by explaining that he made no racial judgements, only highlighted the problems of acculturation.[86]
",4
4569,"In 1977, Hayek was critical of the Lib–Lab pact in which the British Liberal Party agreed to keep the British Labour government in office. Writing to The Times, Hayek said: ""May one who has devoted a large part of his life to the study of the history and the principles of liberalism point out that a party that keeps a socialist government in power has lost all title to the name 'Liberal'. Certainly no liberal can in future vote 'Liberal'"".[87] Hayek was criticised by Liberal politicians Gladwyn Jebb and Andrew Phillips, who both claimed that the purpose of the pact was to discourage socialist legislation.
",4
4570,"Lord Gladwyn pointed out that the German Free Democrats were in coalition with the German Social Democrats.[88] However, Hayek was defended by Professor Antony Flew, who stated that—unlike the British Labour Party—the German Social Democrats had since the late 1950s abandoned public ownership of the means of production, distribution and exchange and had instead embraced the social market economy.[89]
",4
4571,"In 1978, Hayek came into conflict with Liberal Party leader David Steel, who claimed that liberty was possible only with ""social justice and an equitable distribution of wealth and power, which in turn require a degree of active government intervention"" and that the Conservative Party were more concerned with the connection between liberty and private enterprise than between liberty and democracy. Hayek claimed that a limited democracy might be better than other forms of limited government at protecting liberty, but that an unlimited democracy was worse than other forms of unlimited government because ""its government loses the power even to do what it thinks right if any group on which its majority depends thinks otherwise"".
",4
4572,"Hayek stated that if the Conservative leader had said ""that free choice is to be exercised more in the market place than in the ballot box, she has merely uttered the truism that the first is indispensable for individual freedom while the second is not: free choice can at least exist under a dictatorship that can limit itself but not under the government of an unlimited democracy which cannot"".[90]
",4
4573,"Hayek supported Britain in the Falklands War, writing that it would be justified to attack Argentinian territory instead of just defending the islands, which earned him a lot of criticism in Argentina, a country which he also visited several times.  He was also displeased by the weak response of the United States to the Iran hostage crisis, claiming that an ultimatum should be issued and Iran bombed if they do not comply. He supported Ronald Reagan's decision to keep high defence spending, believing that a strong US military is a guarantee of world peace and necessary to keep the Soviet Union under control.[91]  President Reagan listed Hayek as among the two or three people who most influenced his philosophy and welcomed him to the White House as a special guest.[92] Senator Barry Goldwater listed Hayek as his favourite political philosopher and congressman Jack Kemp named him an inspiration for his political career.[93]
",4
4574,"In 1980, Hayek, a non-practicing Catholic,[94] was one of twelve Nobel laureates to meet with Pope John Paul II ""to dialogue, discuss views in their fields, communicate regarding the relationship between Catholicism and science, and 'bring to the Pontiff's attention the problems which the Nobel Prize Winners, in their respective fields of study, consider to be the most urgent for contemporary man'"".[95]
",4
4575,"Hayek was appointed a Companion of Honour (CH) in the 1984 Birthday Honours by Elizabeth II on the advice of British Prime Minister Margaret Thatcher for his ""services to the study of economics"".[15][16] Hayek had hoped to receive a baronetcy and after being awarded the CH sent a letter to his friends requesting that he be called the English version of Friedrich (i.e. Frederick) from now on. After his twenty-minute audience with the Queen, he was ""absolutely besotted"" with her according to his daughter-in-law Esca Hayek. Hayek said a year later that he was ""amazed by her. That ease and skill, as if she'd known me all my life"". The audience with the Queen was followed by a dinner with family and friends at the Institute of Economic Affairs. When later that evening Hayek was dropped off at the Reform Club, he commented: ""I've just had the happiest day of my life"".[96]
",4
4576,"In 1991, President George H.W. Bush awarded Hayek the Presidential Medal of Freedom, one of the two highest civilian awards in the United States, for a ""lifetime of looking beyond the horizon"".
",4
4577,"Hayek died on 23 March 1992 in Freiburg, Germany and was buried on 4 April in the Neustift am Walde cemetery in the northern outskirts of Vienna according to the Catholic rite.[97] In 2011, his article ""The Use of Knowledge in Society"" was selected as one of the top 20 articles published in The American Economic Review during its first 100 years.[19]
",4
4578,"The New York University Journal of Law and Liberty holds an annual lecture in his honor.[98]
",4
4579,"Hayek's principal investigations in economics concerned capital, money and the business cycle. Ludwig von Mises had earlier applied the concept of marginal utility to the value of money in his Theory of Money and Credit (1912) in which he also proposed an explanation for ""industrial fluctuations"" based on the ideas of the old British Currency School and of Swedish economist Knut Wicksell. Hayek used this body of work as a starting point for his own interpretation of the business cycle, elaborating what later became known as the Austrian theory of the business cycle. Hayek spelled out the Austrian approach in more detail in his book, published in 1929, an English translation of which appeared in 1933 as Monetary Theory and the Trade Cycle. There, Hayek argued for a monetary approach to the origins of the cycle. In his Prices and Production (1931), Hayek argued that the business cycle resulted from the central bank's inflationary credit expansion and its transmission over time, leading to a capital misallocation caused by the artificially low interest rates. Hayek claimed that ""the past instability of the market economy is the consequence of the exclusion of the most important regulator of the market mechanism, money, from itself being regulated by the market process"".
",4
4580,"Hayek's analysis was based on Eugen Böhm von Bawerk's concept of the ""average period of production""[99] and on the effects that monetary policy could have upon it. In accordance with the reasoning later outlined in his essay ""The Use of Knowledge in Society"" (1945), Hayek argued that a monopolistic governmental agency like a central bank can neither possess the relevant information which should govern supply of money, nor have the ability to use it correctly.[100]
",4
4581,"In 1929, Lionel Robbins assumed the helm of the London School of Economics (LSE). Eager to promote alternatives to what he regarded as the narrow approach of the school of economic thought that then dominated the English-speaking academic world (centred at the University of Cambridge and deriving largely from the work of Alfred Marshall), Robbins invited Hayek to join the faculty at LSE, which he did in 1931. According to Nicholas Kaldor, Hayek's theory of the time-structure of capital and of the business cycle initially ""fascinated the academic world"" and appeared to offer a less ""facile and superficial"" understanding of macroeconomics than the Cambridge school's.[101]
",4
4582,"Also in 1931, Hayek critiqued John Maynard Keynes's Treatise on Money (1930) in his ""Reflections on the pure theory of Mr. J.M. Keynes""[102] and published his lectures at the LSE in book form as Prices and Production.[103] For Keynes, unemployment and idle resources are caused by a lack of effective demand, but for Hayek they stem from a previous unsustainable episode of easy money and artificially low interest rates. Keynes asked his friend Piero Sraffa to respond. Sraffa elaborated on the effect of inflation-induced ""forced savings"" on the capital sector and about the definition of a ""natural"" interest rate in a growing economy (see Sraffa–Hayek debate).[104] Others who responded negatively to Hayek's work on the business cycle included John Hicks, Frank Knight and Gunnar Myrdal.[105] Kaldor later wrote that Hayek's Prices and Production had produced ""a remarkable crop of critics"" and that the total number of pages in British and American journals dedicated to the resulting debate ""could rarely have been equalled in the economic controversies of the past"".[101]
",4
4583,"Hayek continued his research on monetary and capital theory, revising his theories of the relations between credit cycles and capital structure in Profits, Interest and Investment (1939) and The Pure Theory of Capital (1941), but his reputation as an economic theorist had by then fallen so much that those works were largely ignored, except for scathing critiques by Nicholas Kaldor.[101][106] Lionel Robbins himself, who had embraced the Austrian theory of the business cycle in The Great Depression (1934), later regretted having written the book and accepted many of the Keynesian counter-arguments.[107]
",4
4584,"Hayek never produced the book-length treatment of ""the dynamics of capital"" that he had promised in the Pure Theory of Capital. After 1941, he continued to publish works on the economics of information, political philosophy, the theory of law and psychology, but seldom on macroeconomics. At the University of Chicago, Hayek was not part of the economics department and did not influence the rebirth of neoclassical theory that took place there (see Chicago school of economics). When in 1974 he shared the Nobel Memorial Prize in Economics with Myrdal, the latter complained about being paired with an ""ideologue"". Milton Friedman declared himself ""an enormous admirer of Hayek, but not for his economics. I think Prices and Production is a very flawed book. I think his [Pure Theory of Capital] is unreadable. On the other hand, The Road to Serfdom is one of the great books of our time"".[107]
",4
4585,"Building on the earlier work of Mises and others, Hayek also argued that while in centrally planned economies an individual or a select group of individuals must determine the distribution of resources, these planners will never have enough information to carry out this allocation reliably. This argument, first proposed by Max Weber, says that the efficient exchange and use of resources can be maintained only through the price mechanism in free markets (see economic calculation problem).
",4
4586,"In 1935, Hayek published Collectivist Economic Planning, a collection of essays from an earlier debate that had been initiated by Mises. Hayek included Mises's essay in which Mises argued that rational planning was impossible under socialism.
",4
4587,"Some socialists such as H. D. Dickinson and Oskar Lange responded by invoking general equilibrium theory, which they argued disproved Mises's thesis. They noted that the difference between a planned and a free market system lay in who was responsible for solving the equations. They argued that if some of the prices chosen by socialist managers were wrong, gluts or shortages would appear, signalling them to adjust the prices up or down, just as in a free market. Through such a trial and error, a socialist economy could mimic the efficiency of a free market system while avoiding its many problems.
",4
4588,"Hayek challenged this vision in a series of contributions. In ""Economics and Knowledge"" (1937), he pointed out that the standard equilibrium theory assumed that all agents have full and correct information. However, in the real world different individuals have different bits of knowledge and furthermore some of what they believe is wrong.
",4
4589,"In ""The Use of Knowledge in Society"" (1945), Hayek argued that the price mechanism serves to share and synchronise local and personal knowledge, allowing society's members to achieve diverse and complicated ends through a principle of spontaneous self-organization. He contrasted the use of the price mechanism with central planning, arguing that the former allows for more rapid adaptation to changes in particular circumstances of time and place.[108] Thus, Hayek set the stage for Oliver Williamson's later contrast between markets and hierarchies as alternative co-ordination mechanisms for economic transactions.[109] He used the term catallaxy to describe a ""self-organizing system of voluntary co-operation"". Hayek's research into this argument was specifically cited by the Nobel Committee in its press release awarding Hayek the Nobel prize.[78]
",4
4590,"Hayek was one of the leading academic critics of collectivism in the 20th century. Hayek argued that all forms of collectivism (even those theoretically based on voluntary co-operation) could only be maintained by a central authority of some kind. In Hayek's view, the central role of the state should be to maintain the rule of law, with as little arbitrary intervention as possible. In his popular book The Road to Serfdom (1944) and in subsequent academic works, Hayek argued that socialism required central economic planning and that such planning in turn leads towards totalitarianism.[110]
",4
4591,"
In The Road to Serfdom, Hayek wrote:.mw-parser-output .templatequote{overflow:hidden;margin:1em 0;padding:0 40px}.mw-parser-output .templatequote .templatequotecite{line-height:1.5em;text-align:left;padding-left:1.6em;margin-top:0}",4
4592,"Although our modern socialists' promise of greater freedom is genuine and sincere, in recent years observer after observer has been impressed by the unforeseen consequences of socialism, the extraordinary similarity in many respects of the conditions under ""communism"" and ""fascism"".[111]",4
4593,"Hayek posited that a central planning authority would have to be endowed with powers that would impact and ultimately control social life because the knowledge required for centrally planning an economy is inherently decentralised, and would need to be brought under control.
",4
4594,"Though Hayek did argue that the state should provide law centrally, others have pointed out that this contradicts his arguments about the role of judges in ""discovering"" the law, suggesting that Hayek would have supported decentralized provision of legal services.[112]
",4
4595,"
Hayek also wrote that the state can play a role in the economy, specifically in creating a safety net, saying: ",4
4596,"There is no reason why, in a society which has reached the general level of wealth ours has, the first kind of security should not be guaranteed to all without endangering general freedom; that is: some minimum of food, shelter and clothing, sufficient to preserve health. Nor is there any reason why the state should not help to organize a comprehensive system of social insurance in providing for those common hazards of life against which few can make adequate provision.[113]",4
4597,"""The Denationalization of Money"" is one of his literary works, in which he advocated the establishment of competitions in issuing moneys.
",4
4598,"Perhaps more fully than any other economist, Hayek investigated the choice theory of investment. He examined the inter-relations between non-permanent production goods and ""latent"" or potentially economic permanent resources, building on the choice theoretical insight that ""processes that take more time will evidently not be adopted unless they yield a greater return than those that take less time"".[114]
",4
4599,"Hayek's work on the microeconomics of the choice theoretics of investment, non-permanent goods, potential permanent resources and economically-adapted permanent resources mark a central dividing point between his work in areas of macroeconomics and that of almost all other economists. Hayek's work on the macroeconomic subjects of central planning, trade cycle theory, the division of knowledge and entrepreneurial adaptation especially, differ greatly from the opinions of macroeconomic ""Marshallian"" economists who follow the tradition of John Maynard Keynes and the microeconomic ""Walrasian"" economists who follow the tradition of Abba Lerner.
",4
4600,"During World War II, Hayek began the Abuse of Reason project. His goal was to show how a number of then-popular doctrines and beliefs had a common origin in some fundamental misconceptions about the social science.[115] In his philosophy of science, which has much in common with that of his good friend Karl Popper, Hayek was highly critical of what he termed ""scientism"", a false understanding of the methods of science that has been mistakenly forced upon the social sciences, but that is contrary to the practices of genuine science. Usually, scientism involves combining the philosophers' ancient demand for demonstrative justification with the associationists' false view that all scientific explanations are simple two-variable linear relationships.
",4
4601,"Hayek points out that much of science involves the explanation of complex multivariable and nonlinear phenomena[citation needed] and the social science of economics and undesigned order compares favourably with such complex sciences as Darwinian biology. These ideas were developed in The Counter-Revolution of Science in 1952 and in some of Hayek's later essays in the philosophy of science such as ""Degrees of Explanation"" (1955) and ""The Theory of Complex Phenomena"" (1964).
",4
4602,"
In Counter-Revolution, for example, Hayek observed that the hard sciences attempt to remove the ""human factor"" to obtain objective and strictly controlled results: ",4
4603,"[T]he persistent effort of modern Science has been to get down to ""objective facts,"" to cease studying what men thought about nature or regarding the given concepts as true images of the real world, and, above all, to discard all theories which pretended to explain phenomena by imputing to them a directing mind like our own. Instead, its main task became to revise and reconstruct the concepts formed from ordinary experience on the basis of a systematic testing of the phenomena, so as to be better able to recognize the particular as an instance of a general rule.",4
4604,"
Meanwhile, the soft sciences are attempting to measure human action itself:[116] ",4
4605,"The social sciences in the narrower sense, i.e., those which used to be described as the moral sciences, are concerned with man's conscious or reflected action, actions where a person can be said to choose between various courses open to him, and here the situation is essentially different. The external stimulus which may be said to cause or occasion such actions can of course also be defined in purely physical terms. But if we tried to do so for the purposes of explaining human action, we would confine ourselves to less than we know about the situation.",4
4606,"He notes that these are mutually exclusive and that social sciences should not attempt to impose positivist methodology, nor to claim objective or definite results:[117]
",4
4607,"Hayek's first academic essay was a psychological work titled 'Contributions to the Theory of the Development of Consciousness' (Beiträge zur Theorie der Entwicklung des Bewußtseins) In The Sensory Order: An Inquiry into the Foundations of Theoretical Psychology (1952), Hayek independently developed a ""Hebbian learning"" model of learning and memory—an idea he first conceived in 1920 prior to his study of economics. Hayek's expansion of the ""Hebbian synapse"" construction into a global brain theory has received attention in neuroscience, cognitive science, computer science, behavioural science and evolutionary psychology by scientists such as Gerald Edelman and Joaquin Fuster.[118][119][120]
",4
4608,"The Sensory Order can be viewed as a development of his attack on scientism. Hayek posited two orders, namely the sensory order that we experience and the natural order that natural science has revealed. Hayek thought that the sensory order actually is a product of the brain. He described the brain as a very complex yet self-ordering hierarchical classification system, a huge network of connections. Because of the nature of the classifier system, richness of our sensory experience can exist. Hayek's description posed problems to behaviorism, whose proponents took the sensory order as fundamental.[115]
",4
4609,"In the latter half of his career, Hayek made a number of contributions to social and political philosophy which he based on his views on the limits of human knowledge[121] and the idea of spontaneous order in social institutions. He argues in favour of a society organised around a market order in which the apparatus of state is employed almost (though not entirely) exclusively to enforce the legal order (consisting of abstract rules and not particular commands) necessary for a market of free individuals to function. These ideas were informed by a moral philosophy derived from epistemological concerns regarding the inherent limits of human knowledge. Hayek argued that his ideal individualistic and free-market polity would be self-regulating to such a degree that it would be ""a society which does not depend for its functioning on our finding good men for running it"".[122]
",4
4610,"Although Hayek believed in a society governed by laws, he disapproved of the notion of ""social justice"". He compared the market to a game in which ""there is no point in calling the outcome just or unjust""[123] and argued that ""social justice is an empty phrase with no determinable content"".[124] Likewise, ""the results of the individual's efforts are necessarily unpredictable, and the question as to whether the resulting distribution of incomes is just has no meaning"".[125] He generally regarded government redistribution of income or capital as an unacceptable intrusion upon individual freedom, saying that ""the principle of distributive justice, once introduced, would not be fulfilled until the whole of society was organized in accordance with it. This would produce a kind of society which in all essential respects would be the opposite of a free society"".[124]
",4
4611,"Hayek viewed the free price system not as a conscious invention (that which is intentionally designed by man), but as spontaneous order or what Scottish philosopher Adam Ferguson referred to as ""the result of human action but not of human design"".[126] For instance, Hayek put the price mechanism on the same level as language.
",4
4612,"Hayek attributed the birth of civilisation to private property in his book The Fatal Conceit (1988). He explained that price signals are the only means of enabling each economic decision maker to communicate tacit knowledge or dispersed knowledge to each other to solve the economic calculation problem. Alain de Benoist of the Nouvelle Droite (New Right) produced a highly critical essay on Hayek's work in an issue of Telos, citing the flawed assumptions behind Hayek's idea of ""spontaneous order"" and the authoritarian and totalising implications of his free-market ideology.[127]
",4
4613,"Hayek's concept of the market as a spontaneous order has been recently applied to ecosystems to defend a broadly non-interventionist policy.[128] Like the market, ecosystems contain complex networks of information, involve an ongoing dynamic process, contain orders within orders and the entire system operates without being directed by a conscious mind.[129] On this analysis, species takes the place of price as a visible element of the system formed by a complex set of largely unknowable elements. Human ignorance about the countless interactions between the organisms of an ecosystem limits our ability to manipulate nature.[130] Since humans rely on the ecosystem to sustain themselves, we have a prima facie obligation to not disrupt such systems. This analysis of ecosystems as spontaneous orders does not rely on markets qualifying as spontaneous orders. As such, one need not endorse Hayek's analysis of markets to endorse ecosystems as spontaneous orders.
",4
4614,"
With regard to a social safety net, Hayek advocated ""some provision for those threatened by the extremes of indigence or starvation due to circumstances beyond their control"" and argued that the ""necessity of some such arrangement in an industrial society is unquestioned—be it only in the interest of those who require protection against acts of desperation on the part of the needy"".[131] Summarizing Hayek's views on the topic, journalist Nicholas Wapshott has argued that ""[Hayek] advocated mandatory universal health care and unemployment insurance, enforced, if not directly provided, by the state"".[132] Critical theorist Bernard Harcourt has argued further that ""Hayek was adamant about this"".[133] In 1944, Hayek wrote in The Road to Serfdom: ",4
4615,"There is no reason why in a society which has reached the general level of wealth which ours has attained [that security against severe physical privation, the certainty of a given minimum of sustenance for all; or more briefly, the security of a minimum income] should not be guaranteed to all without endangering general freedom. There are difficult questions about the precise standard which should thus be assured... but there can be no doubt that some minimum of food, shelter, and clothing, sufficient to preserve health and the capacity to work, can be assured to everybody. ... Nor is there any reason why the state should not assist... individuals in providing for those common hazards of life against which, because of their uncertainty, few individuals can make adequate provision. Where, as in the case of sickness and accident, neither the desire to avoid such calamities nor the efforts to overcome their consequences are as a rule weakened by the provision of assistance – where, in short, we deal with genuinely insurable risks – the case for the state's helping to organize a comprehensive system of social insurance is very strong. There are many points of detail where those wishing to preserve the competitive system and those wishing to supersede it by something different will disagree on the details of such schemes; and it is possible under the name of social insurance to introduce measures which tend to make competition more or less effective. But there is no incompatibility in principle between the state's providing greater security in this way and the preservation of individual freedom. Wherever communal action can mitigate disasters against which the individual can neither attempt to guard himself nor make the provision for the consequences, such communal action should undoubtedly be taken.[134]",4
4616,"
In 1973, Hayek reiterated in Law, Legislation and Liberty: ",4
4617,"There is no reason why in a free society government should not assure to all, protection against severe deprivation in the form of an assured minimum income, or a floor below which nobody need to descend. To enter into such an insurance against extreme misfortune may well be in the interest of all; or it may be felt to be a clear moral duty of all to assist, within the organised community, those who cannot help themselves.  So long as such a uniform minimum income is provided outside the market to all those who, for any reason, are unable to earn in the market an adequate maintenance, this need not lead to a restriction of freedom, or conflict with the Rule of law.[135]",4
4618,"
Arthur M. Diamond argues Hayek's problems arise when he goes beyond claims that can be evaluated within economic science. Diamond argued: ",4
4619,"The human mind, Hayek says, is not just limited in its ability to synthesize a vast array of concrete facts, it is also limited in its ability to give a deductively sound ground to ethics. Here is where the tension develops, for he also wants to give a reasoned moral defense of the free market. He is an intellectual skeptic who wants to give political philosophy a secure intellectual foundation. It is thus not too surprising that what results is confused and contradictory.[136]",4
4620,"Chandran Kukathas argues that Hayek's defence of liberalism is unsuccessful because it rests on presuppositions that are incompatible. The unresolved dilemma of his political philosophy is how to mount a systematic defence of liberalism if one emphasizes the limited capacity of reason.[137] Norman P. Barry similarly notes that the ""critical rationalism"" in Hayek's writings appears incompatible with ""a certain kind of fatalism, that we must wait for evolution to pronounce its verdict"".[138] Milton Friedman and Anna Schwartz argue that the element of paradox exists in the views of Hayek. Noting Hayek's vigorous defense of ""invisible hand"" evolution that Hayek claimed has created better economic institutions than could be created by rational design, Friedman pointed out the irony that Hayek was then proposing to replace the monetary system thus created with a deliberate construct of his own design.[139] John N. Gray summarized this view as ""his scheme for an ultra-liberal constitution was a prototypical version of the philosophy he had attacked"".[140] Bruce Caldwell wrote that ""[i]f one is judging his work against the standard of whether he provided a finished political philosophy, Hayek clearly did not succeed"", although he thinks that ""economists may find Hayek's political writings useful"".[141]
",4
4621,"Hayek sent António de Oliveira Salazar a copy of The Constitution of Liberty (1960) in 1962. Hayek hoped that his book—this ""preliminary sketch of new constitutional principles""—""may assist"" Salazar ""in his endeavour to design a constitution which is proof against the abuses of democracy"".[142]
",4
4622,"Hayek visited Chile in the 1970s and 1980s during the Government Junta of general Augusto Pinochet and accepted being appointed Honorary Chairman of the Centro de Estudios Públicos, the think tank formed by the economists who transformed Chile into a free market economy.[142]
",4
4623,"
Asked about the military dictatorship of Chile by a Chilean interviewer, Hayek is translated from German to Spanish to English as having said the following: ",4
4624,"As long term institutions, I am totally against dictatorships. But a dictatorship may be a necessary system for a transitional period. [...] Personally I prefer a liberal dictatorship to democratic government devoid of liberalism. My personal impression – and this is valid for South America – is that in Chile, for example, we will witness a transition from a dictatorial government to a liberal government.[143]",4
4625,"In a letter to the London Times, he defended the Pinochet regime and said that he had ""not been able to find a single person even in much maligned Chile who did not agree that personal freedom was much greater under Pinochet than it had been under Allende"".[144][145] Hayek admitted that ""it is not very likely that this will succeed, even if, at a particular point in time, it may be the only hope there is"", but he explained that ""[i]t is not certain hope, because it will always depend on the goodwill of an individual, and there are very few individuals one can trust. But if it is the sole opportunity which exists at a particular moment it may be the best solution despite this. And only if and when the dictatorial government is visibly directing its steps towards limited democracy"".
",4
4626,"For Hayek, the distinction between authoritarianism and totalitarianism has much importance and he was at pains to emphasise his opposition to totalitarianism, noting that the concept of transitional dictatorship which he defended was characterised by authoritarianism, not totalitarianism. For example, when Hayek visited Venezuela in May 1981, he was asked to comment on the prevalence of totalitarian regimes in Latin America. In reply, Hayek warned against confusing ""totalitarianism with authoritarianism"" and said that he was unaware of ""any totalitarian governments in Latin America. The only one was Chile under Allende"". For Hayek, the word ""totalitarian"" signifies something very specific, namely the intention to ""organize the whole of society"" to attain a ""definite social goal"" which is stark in contrast to ""liberalism and individualism"".[146] He claimed that democracy can also be repressive and totalitarian; in The Constitution of Liberty he often refers to Jacob Talmon's concept of totalitarian democracy.
",4
4627,"Hayek was skeptical about international immigration and supported Thatcher's anti-immigration policies.[85]  In Law, Legislation and Liberty he elaborated:
",4
4628,Freedom of migration is one of the widely accepted and wholly admirable principles of liberalism. But should this generally give the stranger a right to settle down in a community in which he is not welcome? Has he a claim to be given a job or be sold a house if no resident is willing to do so? He clearly should be entitled to accept a job or buy a house if offered to him. But have the individual inhabitants a duty to offer either to him? Or ought it to be an offence if they voluntarily agree not to do so? Swiss and Tyrolese villages have a way of keeping out strangers which neither infringe nor rely on any law. Is this anti-liberal or morally justified? For established old communities I have no certain answers to these questions.[147],4
4629,"He was mainly preoccupied with practical problems concerning immigration:
",4
4630,"There exist, of course, other reasons why such restrictions appear unavoidable so long as certain differences in national or ethnic traditions (especially differences in the rate of propagation) exist-which in turn are not likely to disappear so long as restrictions on migration continue. We must face the fact that we here encounter a limit to the universal application of those liberal principles of policy which the existing facts of the present world make unavoidable.[148]",4
4631,"He was not sympathetic to nationalist ideas and was afraid that mass immigration might revive nationalist sentiment among domestic population and ruin the postwar progress that was made among Western nations.[149] He additionally explained:
",4
4632,"However far modern man accepts in principle the ideal that the same rules should apply to all men, in fact he does concede it only to those whom he regards as similar to himself, and only slowly learns to extend the range of those he does accept as his likes. There is little legislation can do to speed up this process and much it may do to reverse it by re-awakening sentiments that are already on the wane.[149]",4
4633,"Despite his opposition to nationalism, Hayek made numerous controversial and inflammatory comments about specific ethnic groups. Answering an interview question about people he cannot deal with he mentioned his dislike of Middle Eastern populations, claiming they were dishonest, and also expressed ""profound dislike"" of Indian students at London School of Economics, saying that were usually ""detestable sons of Bengali moneylenders"".[150]  However, he claimed that his attitude is not based on any racial feeling.[150]  During World War II he discussed the possibility of sending his children to the United States, but was concerned that they might be placed with a ""coloured family"".[151]  In a later interview, questioned about his attitude towards Black people, he said laconically that he ""did not like dancing Negroes""[152] and on another occasion he ridiculed the decision to award the Nobel Peace Prize to Martin Luther King Jr..[153] He also made negative comments about awarding the Prize to Ralph Bunche, Albert Luthuli, and his LSE colleague W. Arthur Lewis who he described as an ""unusually able West Indian negro"".[153] In 1978 Hayek made a month-long visit to South Africa (his third) where he gave numerous lectures, interviews, and met prominent politicians and business leaders, unconcerned about possible propagandistic effect of his tour for Apartheid regime. He expressed his opposition to some of the government policies, believing that publicly funded institutions should treat all citizens equally, but also claimed that private institutions have the right to discriminate.  Additionally, he condemned the ""scandalous"" hostility and interference of the international community in South African internal affairs.[154]  He further explained his attitude: 
",4
4634,"People in South Africa have to deal with their own problems, and the idea that you can use external pressure to change people, who after all have built up a civilization of a kind, seems to me morally a very doubtful belief.[155]",4
4635,"Hayek claimed that the idea that ""all men are born equal"" is untrue because evolution and genetic differences have created ""boundless variety of human nature"".  He emphasized the importance of nature, complaining that it became too fashionable to ascribe all human differences to environment.[156] Hayek defended economic inequality, believing that the existence of wealthy class is important not only for economic reasons – accumulating capital and directing investments – but also for political, cultural, scientific and conservationist goals which are often financed and promoted by philanthropists.  Since the market mechanism cannot provide for all societal needs, some of which are outside of economic calculation, existence of wealthy individuals guarantees the efficiency and pluralism in their development and realization, which could not be guaranteed in the case of state monopoly.[157] Individual wealth offers independence and can create intellectual, moral, political and artistic leaders which are not employed and influenced by the state.[158] According to Hayek the society benefits from having a hereditary wealthy class because individuals born in it don't have to devote their energy to earning a living and can devote themselves to other purposes such as experimenting with different ideas, hobbies and lifestyles which can later be adopted by broader society.[159] In The Constitution of Liberty he wrote:
",4
4636,"Yet is it really so obvious that the tennis or golf professional is a more useful member of society than the wealthy amateurs who devoted their time to perfecting these games? Or that the paid curator of a public museum is more useful than a private collector? Before the reader answers these questions too hastily, I would ask him to consider whether there would ever have been golf or tennis professionals or museum curators if wealthy amateurs had not preceded them. Can we not hope that other new interests will still arise from the playful explorations of those who can indulge in them for the short span of a human life? It is only natural that the development of the art of living and of the non-materialistic values should have profited most from the activities of those who had no material worries.[160]",4
4637,"He contrasted individuals who inherited wealth, along with upper class values and education, with the nouveau riche who often use their wealth in more vulgar ways.[159] He decried the disappearance of such leisured aristocratic class, claiming that contemporary Western elites are usually business groups that lack intellectual leadership and coherent ""philosophy of life"" and use their wealth mostly for economic purposes.[161]
",4
4638,"Hayek was against high taxes on inheritance, believing that it is natural function of the family to transmit standards, traditions and material goods. Without transmission of property, parents might try to secure the future of their children by placing them in prestigious and high-paying positions, as was customary in socialist countries, which creates even worse injustices.[162] He was also strongly against progressive taxation, noting that in most countries additional taxes paid by the rich amount to insignificantly small amount of total tax revenue and that the only major result of the policy is ""gratification of the envy of the less-well-off"".[163] He also claimed that it is contrary to idea of equality under law and against democratic principle that majority should not impose discriminatory rules against minority.[164][165]
",4
4639,"Hayek's influence on the development of economics is widely acknowledged. With regard to the popularity of his Nobel acceptance lecture, Hayek is the second-most frequently cited economist (after Kenneth Arrow) in the Nobel lectures of the prize winners in economics. Hayek wrote critically there of the field of orthodox economics and neo-classical modelisation.[166] A number of Nobel Laureates in economics, such as Vernon Smith and Herbert A. Simon, recognise Hayek as the greatest modern economist.[167] Another Nobel winner, Paul Samuelson, believed that Hayek was worthy of his award, but nevertheless claimed that ""there were good historical reasons for fading memories of Hayek within the mainstream last half of the twentieth century economist fraternity. In 1931, Hayek's Prices and Production had enjoyed an ultra-short Byronic success. In retrospect hindsight tells us that its mumbo-jumbo about the period of production grossly misdiagnosed the macroeconomics of the 1927–1931 (and the 1931–2007) historical scene"".[168] Despite this comment, Samuelson spent the last 50 years of his life obsessed with the problems of capital theory identified by Hayek and Böhm-Bawerk, and Samuelson flatly judged Hayek to have been right and his own teacher Joseph Schumpeter to have been wrong on the central economic question of the 20th century, the feasibility of socialist economic planning in a production goods dominated economy.[169]
",4
4640,"Hayek is widely recognised for having introduced the time dimension to the equilibrium construction and for his key role in helping inspire the fields of growth theory, information economics and the theory of spontaneous order. The ""informal"" economics presented in Milton Friedman's massively influential popular work Free to Choose (1980) is explicitly Hayekian in its account of the price system as a system for transmitting and co-ordinating knowledge. This can be explained by the fact that Friedman taught Hayek's famous paper ""The Use of Knowledge in Society"" (1945) in his graduate seminars.
",4
4641,"In 1944, he was elected as a Fellow of the British Academy[170] after he was nominated for membership by Keynes.[171]
",4
4642,"Harvard economist and former Harvard University President Lawrence Summers explains Hayek's place in modern economics: ""What's the single most important thing to learn from an economics course today? What I tried to leave my students with is the view that the invisible hand is more powerful than the [un]hidden hand. Things will happen in well-organized efforts without direction, controls, plans. That's the consensus among economists. That's the Hayek legacy"".[172]
",4
4643,"By 1947, Hayek was an organiser of the Mont Pelerin Society, a group of classical liberals who sought to oppose socialism. Hayek was also instrumental in the founding of the Institute of Economic Affairs, the right-wing libertarian and free-market think tank that inspired Thatcherism. He was in addition a member of the conservative and libertarian Philadelphia Society.[173]
",4
4644,"Hayek had a long-standing and close friendship with philosopher of science Karl Popper, who was also from Vienna. In a letter to Hayek in 1944, Popper stated: ""I think I have learnt more from you than from any other living thinker, except perhaps Alfred Tarski"".[174] Popper dedicated his Conjectures and Refutations to Hayek. For his part, Hayek dedicated a collection of papers, Studies in Philosophy, Politics, and Economics, to Popper and in 1982 said that ""ever since his Logik der Forschung first came out in 1934, I have been a complete adherent to his general theory of methodology"".[175] Popper also participated in the inaugural meeting of the Mont Pelerin Society. Their friendship and mutual admiration do not change the fact that there are important differences between their ideas.[176]
",4
4645,"
Hayek also played a central role in Milton Friedman's intellectual development. Friedman wrote: ",4
4646,"My interest in public policy and political philosophy was rather casual before I joined the faculty of the University of Chicago. Informal discussions with colleagues and friends stimulated a greater interest, which was reinforced by Friedrich Hayek's powerful book The Road to Serfdom, by my attendance at the first meeting of the Mont Pelerin Society in 1947, and by discussions with Hayek after he joined the university faculty in 1950. In addition, Hayek attracted an exceptionally able group of students who were dedicated to a libertarian ideology. They started a student publication, The New Individualist Review, which was the outstanding libertarian journal of opinion for some years. I served as an adviser to the journal and published a number of articles in it....[177]",4
4647,"While Friedman often mentioned Hayek as an important influence, Hayek rarely mentioned Friedman.[178]  He deeply disagreed with Chicago School methodology, quantitative and macroeconomic focus, and claimed that Friedman's Essays in Positive Economics was as dangerous book as Keynes' General Theory.[179]  Friedman also claimed that despite some Popperian influence Hayek always retained basic Misesian praxeological view which he found ""utterly nonsensical"".[180]  He also noted that he admired Hayek only for his political works, and disagreed with his technical economics; he called Prices and Production a ""very flawed book"" and The Pure Theory of Capital ""unreadable"". [181]  There were occasional tensions at the Mont Pelerin meetings between the Hayek's and Friedman's followers that sometimes threatened to split the Society.[65]  Although they worked at the same university and shared political beliefs, Hayek and Friedman rarely collaborated professionally and were not close friends.[66]
",4
4648,"Hayek's greatest intellectual debt was to Carl Menger, who pioneered an approach to social explanation similar to that developed in Britain by Bernard Mandeville and the Scottish moral philosophers in the Scottish Enlightenment. He had a wide-reaching influence on contemporary economics, politics, philosophy, sociology, psychology and anthropology. For example, Hayek's discussion in The Road to Serfdom (1944) about truth, falsehood and the use of language influenced some later opponents of postmodernism.[182]
",4
4649,"
Some radical libertarians had a negative view of Hayek and his milder form of liberalism. Ayn Rand disliked him, seeing him as a conservative and compromiser.[183]  In a letter to Rose Wilder Lane in 1946 she wrote:",4
4650,"Now to your question: 'Do those almost with us do more harm than 100% enemies?’ I don’t think this can be answered with a flat 'yes' or 'no,’ because the 'almost' is such a wide term. There is one general rule to observe: those who are with us, but merely do not go far enough are the ones who may do us some good. Those who agree with us in some respects, yet preach contradictory ideas at the same time, are definitely more harmful than 100% enemies. As an example of the kind of 'almost' I would tolerate, I’d name Ludwig von Mises. As an example of our most pernicious enemy, I would name Hayek. That one is real poison.[184]",4
4651,"Hayek made no known written references to Rand.[185]
",4
4652,"Hayek received new attention in the 1980s and 1990s with the rise of conservative governments in the United States, United Kingdom and Canada. After winning the 1979 United Kingdom general election, Margaret Thatcher appointed Keith Joseph, the director of the Hayekian Centre for Policy Studies, as her secretary of state for industry in an effort to redirect parliament's economic strategies. Likewise, David Stockman, Ronald Reagan's most influential financial official in 1981, was an acknowledged follower of Hayek.[186]
",4
4653,"Hayek wrote an essay, ""Why I Am Not a Conservative"" (included as an appendix to The Constitution of Liberty).[187] In it he disparaged conservatism for its inability to adapt to changing human realities or to offer a positive political program, remarking: ""Conservatism is only as good as what it conserves"". Although he noted that modern day American and British conservatism share many opinions on economics with classical liberals, particularly a belief in the free market, he believed it is because conservatism wants to ""stand still"" whereas liberalism embraces the free market because it ""wants to go somewhere"". He was much more critical of conservativism in continental Europe which he saw as more similar to socialism.  European conservatives, according to Hayek, are similar to socialists in their belief that social and political problems can be solved by placing right people in governmental positions and giving them the opportunity to rule without much restrictions.  Both are less concerned with limiting state power and more concerned with arbitrarily using that power to promote their own goals and force their values on other people.[188] Hayek also disliked conservative tendency to obscurantism, such as rejection of theory of evolution and naturalistic explanations of life because of supposedly problematic moral consequences that follow from them.[189] He opposed conservatism for ""its hostility to internationalism and its proneness to a strident nationalism"", with its frequent association with imperialism.[190] He also criticized the intolerance and lack of pluralism:
",4
4654,What I mean is that he [conservative] has no political principles which enable him to work with people whose moral values differ from his own for a political order in which both can obey their convictions. It is the recognition of such principles that permits the coexistence of different sets of values that makes it possible to build a peaceful society with a minimum of force. The acceptance of such principles means that we agree to tolerate much that we dislike. There are many values of the conservative which appeal to me more than those of the socialists; yet for a liberal the importance he personally attaches to specific goals is no sufficient justification for forcing others to serve them.[191],4
4655,"Hayek identified himself as a classical liberal, but noted that in the United States it had become almost impossible to use ""liberal"" in its original definition and the term ""libertarian"" has been used instead. He also found libertarianism a term ""singularly unattractive"" and offered the term ""Old Whig"" (a phrase borrowed from Edmund Burke) instead. In his later life, he said: ""I am becoming a Burkean Whig"". However, Whiggery as a political doctrine had little affinity for classical political economy, the tabernacle of the Manchester School and William Gladstone.[192] His essay has served as an inspiration to other liberal-minded economists wishing to distinguish themselves from conservative thinkers, for example James M. Buchanan's essay ""Why I, Too, Am Not a Conservative: The Normative Vision of Classical Liberalism"".
",4
4656,"His opponents have attacked Hayek as a leading promoter of neoliberalism. A British journalist, Samuel Brittan, concluded in 2010 that ""Hayek's book [The Constitution of Liberty] is still probably the most comprehensive statement of the underlying ideas of the moderate free market philosophy espoused by neoliberals"".[193] Brittan adds that although Raymond Plant (2009) comes out in the end against Hayek's doctrines, Plant gives The Constitution of Liberty a ""more thorough and fair-minded analysis than it has received even from its professed adherents"".[193]
",4
4657,"In Why F A Hayek is a Conservative, British policy analyst Madsen Pirie claims Hayek mistakes the nature of the conservative outlook. Conservatives, he says, are not averse to change, but like Hayek they are highly averse to change being imposed on the social order by people in authority who think they know how to run things better. They wish to allow the market to function smoothly and give it the freedom to change and develop. It is an outlook, according to Pirie, that Hayek and conservatives both share.[194]
",4
4658,"Hayek's ideas on spontaneous order and the importance of prices in dealing with the knowledge problem has inspired a debate on economic development and transition economies after the fall of the Berlin wall. For instance, economist Peter Boettke elaborated in detail on why reforming socialism failed and the Soviet Union broke down.[195] Economist Ronald McKinnon uses Hayekian ideas to describe the challenges of transition from a centralized state and planned economy to a market economy.[196] Former World Bank Chief Economist William Easterly emphasizes why foreign aid tends to have no effect at best in books such as The White Man's Burden: Why the West's Efforts to Aid the Rest Have Done So Much Ill and So Little Good.[197]
",4
4659,"Since the 2007–2008 financial crisis, there is a renewed interest in Hayek's core explanation of boom-and-bust cycles, which serves as an alternative explanation to that of the savings glut as launched by economist and former Federal Reserve Chair Ben Bernanke. Economists at the Bank for International Settlements, e.g. William R. White, emphasize the importance of Hayekian insights and the impact of monetary policies and credit growth as root causes of financial cycles.[198] Andreas Hoffmann and Gunther Schnabl provide an international perspective and explain recurring financial cycles in the world economy as consequence of gradual interest rate cuts led by the central banks in the large advanced economies since the 1980s.[199][200] Nicolas Cachanosky outlines the impact of American monetary policy on the production structure in Latin America.[201]
",4
4660,"In line with Hayek, an increasing number of contemporary researchers sees expansionary monetary policies and too low interest rates as mal-incentives and main drivers of financial crises in general and the subprime market crisis in particular.[202][203] To prevent problems caused by monetary policy, Hayekian and Austrian economists discuss alternatives to current policies and organizations. For instance, Lawrence H. White has argued in favor of free banking in the spirit of Hayek's ""Denationalization of Money"".[204] Along with market monetarist economist Scott Sumner,[205] White has also noted that the monetary policy norm that Hayek prescribed, first in Prices and Production (1931) and as late as the 1970s,[206][207] was the stabilization of nominal income.[208]
",4
4661,"Hayek's ideas find their way into the discussion of the post-Great Recession issues of secular stagnation. Monetary policy and mounting regulation are argued to have undermined the innovative forces of the market economies. Quantitative easing following the financial crises is argued to have not only conserved structural distortions in the economy, leading to a fall in trend-growth. It also created new distortions and contributes to distributional conflicts.[209]
",4
4662,"In the 1970s and 1980s, the writings of Hayek were a major influence on some of the future postsocialist economic and political elites in Central and Eastern Europe. Supporting examples include the following:
",4
4663,"There is no figure who had more of an influence, no person had more of an influence on the intellectuals behind the Iron Curtain than Friedrich Hayek. His books were translated and published by the underground and black market editions, read widely, and undoubtedly influenced the climate of opinion that ultimately brought about the collapse of the Soviet Union.[210]",4
4664,"The most interesting among the courageous dissenters of the 1980s were the classical liberals, disciples of F.A. Hayek, from whom they had learned about the crucial importance of economic freedom and about the often-ignored conceptual difference between liberalism and democracy.[211]",4
4665,"Estonian Prime Minister Mart Laar came to my office the other day to recount his country's remarkable transformation. He described a nation of people who are harder-working, more virtuous – yes, more virtuous, because the market punishes immorality – and more hopeful about the future than they've ever been in their history. I asked Mr. Laar where his government got the idea for these reforms. Do you know what he replied? He said, ""We read Milton Friedman and F.A. Hayek.""[212]",4
4666,"I was 25 years old and pursuing my doctorate in economics when I was allowed to spend six months of post-graduate studies in Naples, Italy. I read the Western economic textbooks and also the more general work of people like Hayek. By the time I returned to Czechoslovakia, I had an understanding of the principles of the market. In 1968, I was glad at the political liberalism of the Dubcek Prague Spring, but was very critical of the Third Way they pursued in economics.[213]",4
4667,"In August 1926, Hayek married Helen Berta Maria von Fritsch (1901–1960), a secretary at the civil service office where Hayek worked, on the rebound upon hearing of his cousin's marriage. They had two children together.[214] Upon the close of World War II, Hayek restarted a relationship with his cousin, who had married since they first met, but kept it secret until 1948. Hayek and Fritsch divorced in July 1950 and he married his cousin[215] Helene Bitterlich (1900–1996)[216] just a few weeks later after moving to Arkansas to take advantage of permissive divorce laws.[217] His wife and children were offered settlement and compensation for accepting a divorce. The divorce caused some scandal at LSE where certain academics refused to have anything to do with Hayek.[217] In a 1978 interview to explain his actions, Hayek stated that he was unhappy in his first marriage and as his wife would not grant him a divorce he had to enforce it.[218]
",4
4668,"After divorce, for a time, Hayek rarely visited his children, but continued more regular contact with them in his older age, after moving to Europe.[215][219]  Hayek's son, Laurence Hayek (1934–2004) was a distinguished microbiologist.[220] His daughter Christine was an entomologist at the British Museum of Natural History, and she cared for him during his last years of declining health.[219][221]
",4
4669,"Hayek had a lifelong interest in biology and was also concerned with ecology and environmental protection.  After being awarded Nobel Prize he offered his name to be used for endorsements by World Wildlife Fund, National Audubon Society, and conservationist National Trust.[222]
",4
4670,"Hayek was brought up in non-religious setting and decided that he was an agnostic from age 15.[31] He died in 1992 in Freiburg, Germany, where he had lived since leaving Chicago in 1961.[223]
",4
4671,"Even after his death, Hayek's intellectual presence is noticeable, especially in the universities where he had taught, namely the London School of Economics, the University of Chicago and the University of Freiburg. A number of tributes have resulted, many established posthumously:
",4
4672,"
",4
4673,"The Industrial Revolution was the transition to new manufacturing processes in Europe and the United States, in the period from about 1760 to sometime between 1820 and 1840. This transition included going from hand production methods to machines, new chemical manufacturing and iron production processes, the increasing use of steam power and water power, the development of machine tools and the rise of the mechanized factory system. The Industrial Revolution also led to an unprecedented rise in the rate of population growth.
",4
4674,"Textiles were the dominant industry of the Industrial Revolution in terms of employment, value of output and capital invested. The textile industry was also the first to use modern production methods.[1]:40
",4
4675,"The Industrial Revolution began in Great Britain, and many of the technological innovations were of British origin.[2][3] By the mid-18th century Britain was the world's leading commercial nation,[4] controlling a global trading empire with colonies in North America and the Caribbean, and with major military and political hegemony on the Indian subcontinent, particularly with the proto-industrialised Mughal Bengal, through the activities of the East India Company.[5][6][7][8] The development of trade and the rise of business were among the major causes of the Industrial Revolution.[1]:15
",4
4676,"The Industrial Revolution marks a major turning point in history; almost every aspect of daily life was influenced in some way. In particular, average income and population began to exhibit unprecedented sustained growth. Some economists have said the most important effect of the Industrial Revolution was that the standard of living for the general population in the western world began to increase consistently for the first time in history, although others have said that it did not begin to meaningfully improve until the late 19th and 20th centuries.[9][10][11]
",4
4677,"GDP per capita was broadly stable before the Industrial Revolution and the emergence of the modern capitalist economy,[12] while the Industrial Revolution began an era of per-capita economic growth in capitalist economies.[13] Economic historians are in agreement that the onset of the Industrial Revolution is the most important event in the history of humanity since the domestication of animals and plants.[14]
",4
4678,"The precise start and end of the Industrial Revolution is still debated among historians, as is the pace of economic and social changes.[15][16][17][18] Eric Hobsbawm held that the Industrial Revolution began in Britain in the 1780s and was not fully felt until the 1830s or 1840s,[15] while T. S. Ashton held that it occurred roughly between 1760 and 1830.[16] Rapid industrialization first began in Britain, starting with mechanized spinning in the 1780s,[19] with high rates of growth in steam power and iron production occurring after 1800. Mechanized textile production spread from Great Britain to continental Europe and the United States in the early 19th century, with important centres of textiles, iron and coal emerging in Belgium and the United States and later textiles in France.[1]
",4
4679,"An economic recession occurred from the late 1830s to the early 1840s when the adoption of the Industrial Revolution's early innovations, such as mechanized spinning and weaving, slowed and their markets matured. Innovations developed late in the period, such as the increasing adoption of locomotives, steamboats and steamships, hot blast iron smelting and new technologies, such as the electrical telegraph, widely introduced in the 1840s and 1850s, were not powerful enough to drive high rates of growth. Rapid economic growth began to occur after 1870, springing from a new group of innovations in what has been called the Second Industrial Revolution. These innovations included new steel making processes, mass-production, assembly lines, electrical grid systems, the large-scale manufacture of machine tools and the use of increasingly advanced machinery in steam-powered factories.[1][20][21][22]
",4
4680,"The earliest recorded use of the term ""Industrial Revolution"" appears to have been in a letter from 6 July 1799 written by French envoy Louis-Guillaume Otto, announcing that France had entered the race to industrialise.[23] In his 1976 book Keywords: A Vocabulary of Culture and Society, Raymond Williams states in the entry for ""Industry"": ""The idea of a new social order based on major industrial change was clear in Southey and Owen, between 1811 and 1818, and was implicit as early as Blake in the early 1790s and Wordsworth at the turn of the [19th] century."" The term Industrial Revolution applied to technological change was becoming more common by the late 1830s, as in Jérôme-Adolphe Blanqui's description in 1837 of la révolution industrielle.[24] Friedrich Engels in The Condition of the Working Class in England in 1844 spoke of ""an industrial revolution, a revolution which at the same time changed the whole of civil society"". However, although Engels wrote his book in the 1840s, it was not translated into English until the late 1800s, and his expression did not enter everyday language until then. Credit for popularising the term may be given to Arnold Toynbee, whose 1881 lectures gave a detailed account of the term.[25]
",4
4681,"Economic historians and authors such as Mendels, Pomeranz and Kridte argue that the proto-industrialization in parts of Europe, Islamic world, Mughal India, and China created the social and economic conditions that led to the Industrial Revolution, thus causing the Great Divergence.[26][27][28]
",4
4682,"Some historians, such as John Clapham and Nicholas Crafts, have argued that the economic and social changes occurred gradually, and that the term revolution is a misnomer. This is still a subject of debate among some historians.[29]
",4
4683,"Six factors facilitated industrialization: high levels of agricultural productivity to provide excess manpower and food; a pool of managerial and entrepreneurial skills;  available ports, rivers, canals and roads to cheaply move raw materials and outputs; natural resources such as coal, iron and waterfalls; political stability and a legal system that supported business; and financial capital available to invest. Once industrialization began in Great Britain, new factors can be added: the eagerness British entrepreneurs to export industrial expertise and the willingness to import the process. Britain met the criteria and industrialized starting in the 18th century. Britain exported the process to western Europe (especially Belgium, France and the German states) in the early 19th century. The United States copied the British model in the early 19th century and Japan copied the Western European models in the late 19th century.[30][31]
",4
4684,"The commencement of the Industrial Revolution is closely linked to a small number of innovations,[32] beginning in the second half of the 18th century.  By the 1830s the following gains had been made in important technologies:
",4
4685,"In 1750 Britain imported 2.5 million pounds of raw cotton, most of which was spun and woven by cottage industry in Lancashire. The work was done by hand in workers' homes or occasionally in shops of master weavers. In 1787 raw cotton consumption was 22 million pounds, most of which was cleaned, carded and spun on machines.[1]:41–42 The British textile industry used 52 million pounds of cotton in 1800, which increased to 588 million pounds in 1850.[39]
",4
4686,"The share of value added by the cotton textile industry in Britain was 2.6% in 1760, 17% in 1801 and 22.4% in 1831.  Value added by the British woollen industry was 14.1% in 1801.  Cotton factories in Britain numbered approximately 900 in 1797.  In 1760 approximately one-third of cotton cloth manufactured in Britain was exported, rising to two-thirds by 1800.  In 1781 cotton spun amounted to 5.1 million pounds, which increased to 56 million pounds by 1800.  In 1800 less than 0.1% of world cotton cloth was produced on machinery invented in Britain.  In 1788 there were 50,000 spindles in Britain, rising to 7 million over the next 30 years.[40]
",4
4687,"Wages in Lancashire, a core region for cottage industry and later factory spinning and weaving, were about six times those in India in 1770, when overall productivity in Britain was about three times higher than in India.[40]
",4
4688,"Parts of India, China, Central America, South America and the Middle-East have a long history of hand manufacturing cotton textiles, which became a major industry sometime after 1000 AD. In tropical and subtropical regions where it was grown, most was grown by small farmers alongside their food crops and was spun and woven in households, largely for domestic consumption.  In the 15th century China began to require households to pay part of their taxes in cotton cloth. By the 17th century almost all Chinese wore cotton clothing.  Almost everywhere cotton cloth could be used as a medium of exchange.  In India a significant amount of cotton textiles were manufactured for distant markets, often produced by professional weavers.  Some merchants also owned small weaving workshops. India produced a variety of cotton cloth, some of exceptionally fine quality.[40]
",4
4689,"Cotton was a difficult raw material for Europe to obtain before it was grown on colonial plantations in the Americas.[40] The early Spanish explorers found Native Americans growing unknown species of excellent quality cotton: sea island cotton (Gossypium barbadense) and upland green seeded cotton Gossypium hirsutum.  Sea island cotton grew in tropical areas and on barrier islands of Georgia and South Carolina, but did poorly inland.  Sea island cotton began being exported from Barbados in the 1650s. Upland green seeded cotton grew well on inland areas of the southern U.S., but was not economical because of the difficulty of removing seed, a problem solved by the cotton gin.[21]:157 A strain of cotton seed brought from Mexico to Natchez, Mississippi in 1806 became the parent genetic material for over 90% of world cotton production today; it produced bolls that were three to four times faster to pick.[40]
",4
4690,"The Age of Discovery was followed by a period of colonialism beginning around the 16th century. Following the discovery of a trade route to India around southern Africa by the Portuguese, the Dutch established the Verenigde Oostindische Compagnie (abbr. VOC) or Dutch East India Company, the world's first transnational corporation and the first multinational enterprise to issue shares of stock to the public.[a][41] The British later founded the East India Company, along with smaller companies of different nationalities which established trading posts and employed agents to engage in trade throughout the Indian Ocean region and between the Indian Ocean region and North Atlantic Europe.  One of the largest segments of this trade was in cotton textiles, which were purchased in India and sold in Southeast Asia, including the Indonesian archipelago, where spices were purchased for sale to Southeast Asia and Europe.  By the mid-1760s cloth was over three-quarters of the East India Company's exports.  Indian textiles were in demand in North Atlantic region of Europe where previously only wool and linen were available; however, the amount of cotton goods consumed in Western Europe was minor until the early 19th century.[40]
",4
4691,"By 1600 Flemish refugees began weaving cotton cloth in English towns where cottage spinning and weaving of wool and linen was well established; however, they were left alone by the guilds who did not consider cotton a threat.  Earlier European attempts at cotton spinning and weaving were in 12th-century Italy and 15th-century southern Germany, but these industries eventually ended when the supply of cotton was cut off.  The Moors in Spain grew, spun and wove cotton beginning around the 10th century.[40]
",4
4692,"British cloth could not compete with Indian cloth because India's labour cost was approximately one-fifth to one-sixth that of Britain's.[19] In 1700 and 1721 the British government passed Calico Acts in order to protect the domestic woollen and linen industries from the increasing amounts of cotton fabric imported from India.[1][42]
",4
4693,"The demand for heavier fabric was met by a domestic industry based around Lancashire that produced fustian, a cloth with flax warp and cotton weft.  Flax was used for the warp because wheel-spun cotton did not have sufficient strength, but the resulting blend was not as soft as 100% cotton and was more difficult to sew.[42]
",4
4694,"On the eve of the Industrial Revolution, spinning and weaving were done in households, for domestic consumption and as a cottage industry under the putting-out system.  Occasionally the work was done in the workshop of a master weaver. Under the putting-out system, home-based workers produced under contract to merchant sellers, who often supplied the raw materials.  In the off season the women, typically farmers' wives, did the spinning and the men did the weaving.  Using the spinning wheel, it took anywhere from four to eight spinners to supply one hand loom weaver.[1][42][43]:823
",4
4695,"The flying shuttle, patented in 1733 by John Kay, with a number of subsequent improvements including an important one in 1747, doubled the output of a weaver, worsening the imbalance between spinning and weaving.  It became widely used around Lancashire after 1760 when John's son, Robert, invented the drop box, which facilitated changing thread colors.[43]:821–22
",4
4696,"Lewis Paul patented the roller spinning frame and the flyer-and-bobbin system for drawing wool to a more even thickness. The technology was developed with the help of John Wyatt of Birmingham.  Paul and Wyatt opened a mill in Birmingham which used their new rolling machine powered by a donkey. In 1743 a factory opened in Northampton with 50 spindles on each of five of Paul and Wyatt's machines. This operated until about 1764. A similar mill was built by Daniel Bourn in Leominster, but this burnt down. Both Lewis Paul and Daniel Bourn patented carding machines in 1748. Based on two sets of rollers that travelled at different speeds, it was later used in the first cotton spinning mill. Lewis's invention was later developed and improved by Richard Arkwright in his water frame and Samuel Crompton in his spinning mule.
",4
4697,"In 1764 in the village of Stanhill, Lancashire, James Hargreaves invented the spinning jenny, which he patented in 1770. It was the first practical spinning frame with multiple spindles.[44] The jenny worked in a similar manner to the spinning wheel, by first clamping down on the fibres, then by drawing them out, followed by twisting.[45] It was a simple, wooden framed machine that only cost about £6 for a 40-spindle model in 1792,[46] and was used mainly by home spinners. The jenny produced a lightly twisted yarn only suitable for weft, not warp.[43]:825–27
",4
4698,"The spinning frame or water frame was developed by Richard Arkwright who, along with two partners, patented it in 1769. The design was partly based on a spinning machine built for Thomas High by clockmaker John Kay, who was hired by Arkwright.[43]:827–30  For each spindle the water frame used a series of four pairs of rollers, each operating at a successively higher rotating speed, to draw out the fibre, which was then twisted by the spindle.  The roller spacing was slightly longer than the fibre length.  Too close a spacing caused the fibres to break while too distant a spacing caused uneven thread.  The top rollers were leather-covered and loading on the rollers was applied by a weight.  The weights kept the twist from backing up before the rollers. The bottom rollers were wood and metal, with fluting along the length.  The water frame was able to produce a hard, medium count thread suitable for warp, finally allowing 100% cotton cloth to be made in Britain.  A horse powered the first factory to use the spinning frame. Arkwright and his partners used water power at a factory in Cromford, Derbyshire in 1771, giving the invention its name.
",4
4699,"Samuel Crompton's Spinning Mule was introduced in 1779.  Mule implies a hybrid because it was a combination of the spinning jenny and the water frame, in which the spindles were placed on a carriage, which went through an operational sequence during which the rollers stopped while the carriage moved away from the drawing roller to finish drawing out the fibres as the spindles started rotating.[43]:832  Crompton's mule was able to produce finer thread than hand spinning and at a lower cost.  Mule spun thread was of suitable strength to be used as warp, and finally allowed Britain to produce highly competitive yarn in large quantities.[43]:832
",4
4700,"Realising that the expiration of the Arkwright patent would greatly increase the supply of spun cotton and led to a shortage of weavers, Edmund Cartwright developed a vertical power loom which he patented in 1785.  In 1776 he patented a two-man operated loom which was more conventional.[43]:834  Cartwright built two factories; the first burned down and the second was sabotaged by his workers. Cartwright's loom design had several flaws, the most serious being thread breakage. Samuel Horrocks patented a fairly successful loom in 1813.  Horock's loom was improved by Richard Roberts in 1822 and these were produced in large numbers by Roberts, Hill & Co.[47]
",4
4701,"The demand for cotton presented an opportunity to planters in the Southern United States, who thought upland cotton would be a profitable crop if a better way could be found to remove the seed. Eli Whitney responded to the challenge by inventing the inexpensive cotton gin.  A man using a cotton gin could remove seed from as much upland cotton in one day as would previously, working at the rate of one pound of cotton per day, have taken a woman two months to process.[21][48]
",4
4702,"These advances were capitalised on by entrepreneurs, of whom the best known is Richard Arkwright. He is credited with a list of inventions, but these were actually developed by such people as Thomas Highs and John Kay; Arkwright nurtured the inventors, patented the ideas, financed the initiatives, and protected the machines. He created the cotton mill which brought the production processes together in a factory, and he developed the use of power—first horse power and then water power—which made cotton manufacture a mechanised industry. Other inventors increased the efficiency of the individual steps of spinning (carding, twisting and spinning, and rolling) so that the supply of yarn increased greatly. Before long steam power was applied to drive textile machinery. Manchester acquired the nickname Cottonopolis during the early 19th century owing to its sprawl of textile factories.[49]
",4
4703,"Although mechanization dramatically decreased the cost of cotton cloth, by the mid-19th century machine-woven cloth still could not equal the quality of hand-woven Indian cloth, in part due to the fineness of thread made possible by the type of cotton used in India, which allowed high thread counts.  However, the high productivity of British textile manufacturing allowed coarser grades of British cloth to undersell hand-spun and woven fabric in low-wage India, eventually destroying the industry.[40]
",4
4704,"The earliest European attempts at mechanized spinning were with wool; however, wool spinning proved more difficult to mechanize than cotton.  Productivity improvement in wool spinning during the Industrial Revolution was significant but was far less than that of cotton.[1][8]
",4
4705,"Arguably the first highly mechanised factory was John Lombe's water-powered silk mill at Derby, operational by 1721. Lombe learned silk thread manufacturing by taking a job in Italy and acting as an industrial spy; however, because the Italian silk industry guarded its secrets closely, the state of the industry at that time is unknown. Although Lombe's factory was technically successful, the supply of raw silk from Italy was cut off to eliminate competition.  In order to promote manufacturing the Crown paid for models of Lombe's machinery which were exhibited in the Tower of London.[50][51]
",4
4706,"Bar iron was the commodity form of iron used as the raw material for making hardware goods such as nails, wire, hinges, horse shoes, wagon tires, chains, etc. and for structural shapes. A small amount of bar iron was converted into steel.  Cast iron was used for pots, stoves and other items where its brittleness was tolerable.  Most cast iron was refined and converted to bar iron, with substantial losses.  Bar iron was also made by the bloomery process, which was the predominant iron smelting process until the late 18th century.
",4
4707,"In the UK in 1720 there were 20,500 tons of cast iron produced with charcoal and 400 tons with coke. In 1750 charcoal iron production was 24,500 and coke iron was 2,500 tons.  In 1788 the production of charcoal cast iron was 14,000 tons while coke iron production was 54,000 tons.  In 1806 charcoal cast iron production was 7,800 tons and coke cast iron was 250,000 tons.[36]:125
",4
4708,"In 1750 the UK imported 31,200 tons of bar iron and either refined from cast iron or directly produced 18,800 tons of bar iron using charcoal and 100 tons using coke.  In 1796 the UK was making 125,000 tons of bar iron with coke and 6,400 tons with charcoal; imports were 38,000 tons and exports were 24,600 tons. In 1806 the UK did not import bar iron but exported 31,500 tons.[36]:125
",4
4709,"A major change in the iron industries during the era of the Industrial Revolution was the replacement of wood and other bio-fuels with coal. For a given amount of heat, coal required much less labour to mine than cutting wood and converting it to charcoal,[53] and coal was much more abundant than wood, supplies of which were becoming scarce before the enormous increase in iron production that took place in the late 18th century.[1][36]:122  By 1750 coke had generally replaced charcoal in smelting of copper and lead, and was in widespread use in making glass.  In the smelting and refining of iron, coal and coke produced inferior iron to that made with charcoal because of the coal's sulfur content.  Low sulfur coals were known, but they still contained harmful amounts.  Conversion of coal to coke only slightly reduces the sulfur content.[36]:122–25 A minority of coals are coking.
",4
4710,"Another factor limiting the iron industry before the Industrial Revolution was the scarcity of water power to power blast bellows.  This limitation was overcome by the steam engine.[36]
",4
4711,"Use of coal in iron smelting started somewhat before the Industrial Revolution, based on innovations by Sir Clement Clerke and others from 1678, using coal reverberatory furnaces known as cupolas. These were operated by the flames playing on the ore and charcoal or coke mixture, reducing the oxide to metal. This has the advantage that impurities (such as sulphur ash) in the coal do not migrate into the metal. This technology was applied to lead from 1678 and to copper from 1687. It was also applied to iron foundry work in the 1690s, but in this case the reverberatory furnace was known as an air furnace. (The foundry cupola is a different, and later, innovation.)[citation needed]
",4
4712,"By 1709 Abraham Darby made progress using coke to fuel his blast furnaces at Coalbrookdale.[54] However, the coke pig iron he made was not suitable for making wrought iron and was used mostly for the production of cast iron goods, such as pots and kettles. He had the advantage over his rivals in that his pots, cast by his patented process, were thinner and cheaper than theirs.
",4
4713,"Coke pig iron was hardly used to produce wrought iron until 1755–56, when Darby's son Abraham Darby II built furnaces at Horsehay and Ketley where low sulfur coal was available (and not far from Coalbrookdale).  These new furnaces were equipped with water-powered bellows, the water being pumped by Newcomen steam engines.  The Newcomen engines were not attached directly to the blowing cylinders because the engines alone could not produce a steady air blast.  Abraham Darby III installed similar steam-pumped, water-powered blowing cylinders at the Dale Company when he took control in 1768.  The Dale Company used several Newcomen engines to drain its mines and made parts for engines which it sold throughout the country.[36]:123–25
",4
4714,"Steam engines made the use of higher-pressure and volume blast practical; however, the leather used in bellows was expensive to replace. In 1757, iron master John Wilkinson patented a hydraulic powered blowing engine for blast furnaces.[55] The blowing cylinder for blast furnaces was introduced in 1760 and the first blowing cylinder made of cast iron is believed to be the one used at Carrington in 1768 that was designed by John Smeaton.[36]:124, 135  Cast iron cylinders for use with a piston were difficult to manufacture; the cylinders had to be free of holes and had to be machined smooth and straight to remove any warping.  James Watt had great difficulty trying to have a cylinder made for his first steam engine.  In 1774 John Wilkinson, who built a cast iron blowing cylinder for his iron works, invented a precision boring machine for boring cylinders. After Wilkinson bored the first successful cylinder for a Boulton and Watt steam engine in 1776, he was given an exclusive contract for providing cylinders.[21][56] After Watt developed a rotary steam engine in 1782, they were widely applied to blowing, hammering, rolling and slitting.[36]:124
",4
4715,"The solutions to the sulfur problem were the addition of sufficient limestone to the furnace to force sulfur into the slag and the use of low sulfur coal.  Use of lime or limestone required higher furnace temperatures to form a free-flowing slag. The increased furnace temperature made possible by improved blowing also increased the capacity of blast furnaces and allowed for increased furnace height.[36]:123–25  In addition to lower cost and greater availability, coke had other important advantages over charcoal in that it was harder and made the column of materials (iron ore, fuel, slag) flowing down the blast furnace more porous and did not crush in the much taller furnaces of the late 19th century.[57][58]
",4
4716,"As cast iron became cheaper and widely available, it began being a structural material for bridges and buildings.  A famous early example was the Iron Bridge built in 1778 with cast iron produced by Abraham Darby III.[52] However, most cast iron was converted to wrought iron.
",4
4717,"Europe relied on the bloomery for most of its wrought iron until the large scale production of cast iron.  Conversion of cast iron was done in a finery forge, as it long had been.  An improved refining process known as potting and stamping was developed, but this was superseded by Henry Cort's puddling process. Cort developed two significant iron manufacturing processes: rolling in 1783 and puddling in 1784.[1]:91  Puddling produced a structural grade iron at a relatively low cost.
",4
4718,"Puddling was a means of decarburizing molten pig iron by slow oxidation in a reverberatory furnace by manually stirring it with a long rod.  The decarburized iron, having a higher melting point than cast iron, was raked into globs by the puddler.  When the glob was large enough, the puddler would remove it.  Puddling was backbreaking and extremely hot work.  Few puddlers lived to be 40.[59] Because puddling was done in a reverberatory furnace, coal or coke could be used as fuel.  The puddling process continued to be used until the late 19th century when iron was being displaced by steel.  Because puddling required human skill in sensing the iron globs, it was never successfully mechanised. Rolling was an important part of the puddling process because the grooved rollers expelled most of the molten slag and consolidated the mass of hot wrought iron. Rolling was 15 times faster at this than a trip hammer.  A different use of rolling, which was done at lower temperatures than that for expelling slag, was in the production of iron sheets, and later structural shapes such as beams, angles and rails.
",4
4719,"The puddling process was improved in 1818 by Baldwyn Rogers, who replaced some of the sand lining on the reverberatory furnace bottom with iron oxide.[60] In 1838 John Hall patented the use of roasted tap cinder (iron silicate) for the furnace bottom, greatly reducing the loss of iron through increased slag caused by a sand lined bottom. The tap cinder also tied up some phosphorus, but this was not understood at the time.[36]:166  Hall's process also used iron scale or rust, which reacted with carbon in the molten iron. Hall's process, called wet puddling, reduced losses of iron with the slag from almost 50% to around 8%.[1]:93
",4
4720,"Puddling became widely used after 1800. Up to that time British iron manufacturers had used considerable amounts of iron imported from Sweden and Russia to supplement domestic supplies.  Because of the increased British production, imports began to decline in 1785 and by the 1790s Britain eliminated imports and became a net exporter of bar iron.[citation needed]
",4
4721,"Hot blast, patented by James Beaumont Neilson in 1828, was the most important development of the 19th century for saving energy in making pig iron.  By using preheated combustion air, the amount of fuel to make a unit of pig iron was reduced at first by between one-third using coke or two-thirds using coal;[61] however, the efficiency gains continued as the technology improved.[62] Hot blast also raised the operating temperature of furnaces, increasing their capacity.  Using less coal or coke meant introducing fewer impurities into the pig iron.  This meant that lower quality coal or anthracite could be used in areas where coking coal was unavailable or too expensive;[63] however, by the end of the 19th century transportation costs fell considerably.
",4
4722,"Shortly before the Industrial Revolution an improvement was made in the production of steel, which was an expensive commodity and used only where iron would not do, such as for cutting edge tools and for springs. Benjamin Huntsman developed his crucible steel technique in the 1740s. The raw material for this was blister steel, made by the cementation process.[citation needed]
",4
4723,"The supply of cheaper iron and steel aided a number of industries, such as those making nails, hinges, wire and other hardware items. The development of machine tools allowed better working of iron, causing it to be increasingly used in the rapidly growing machinery and engine industries.[64]
",4
4724,"The development of the stationary steam engine was an important element of the Industrial Revolution; however, during the early period of the Industrial Revolution, most industrial power was supplied by water and wind.  In Britain by 1800 an estimated 10,000 horsepower was being supplied by steam.  By 1815 steam power had grown to 210,000 hp.[65]
",4
4725,"The first commercially successful industrial use of steam power was due to Thomas Savery in 1698. He constructed and patented in London a low-lift combined vacuum and pressure water pump, that generated about one horsepower (hp) and was used in numerous water works and in a few mines (hence its ""brand name"", The Miner's Friend). Savery's pump was economical in small horsepower ranges, but was prone to boiler explosions in larger sizes.  Savery pumps continued to be produced until the late 18th century.[citation needed]
",4
4726,"The first successful piston steam engine was introduced by Thomas Newcomen before 1712. A number of Newcomen engines were installed in Britain for draining hitherto unworkable deep mines, with the engine on the surface; these were large machines, requiring a significant amount of capital to build, and produced upwards of 5 hp (3.7 kW). They were also used to power municipal water supply pumps.  They were extremely inefficient by modern standards, but when located where coal was cheap at pit heads, opened up a great expansion in coal mining by allowing mines to go deeper. Despite their disadvantages, Newcomen engines were reliable and easy to maintain and continued to be used in the coalfields until the early decades of the 19th century. By 1729, when Newcomen died, his engines had spread (first) to Hungary in 1722, Germany, Austria, and Sweden. A total of 110 are known to have been built by 1733 when the joint patent expired, of which 14 were abroad. In the 1770s the engineer John Smeaton built some very large examples and introduced a number of improvements. A total of 1,454 engines had been built by 1800.[66]
",4
4727,"A fundamental change in working principles was brought about by Scotsman James Watt. With financial support from his business partner Englishman Matthew Boulton, he had succeeded by 1778 in perfecting his steam engine, which incorporated a series of radical improvements, notably the closing off of the upper part of the cylinder, thereby making the low-pressure steam drive the top of the piston instead of the atmosphere, use of a steam jacket and the celebrated separate steam condenser chamber.  The separate condenser did away with the cooling water that had been injected directly into the cylinder, which cooled the cylinder and wasted steam.  Likewise, the steam jacket kept steam from condensing in the cylinder, also improving efficiency.  These improvements increased engine efficiency so that Boulton and Watt's engines used only 20–25% as much coal per horsepower-hour as Newcomen's. Boulton and Watt opened the Soho Foundry for the manufacture of such engines in 1795.[citation needed]
",4
4728,"By 1783 the Watt steam engine had been fully developed into a double-acting rotative type, which meant that it could be used to directly drive the rotary machinery of a factory or mill. Both of Watt's basic engine types were commercially very successful, and by 1800, the firm Boulton & Watt had constructed 496 engines, with 164 driving reciprocating pumps, 24 serving blast furnaces, and 308 powering mill machinery; most of the engines generated from 5 to 10 hp (3.7 to 7.5 kW).
",4
4729,"Until about 1800 the most common pattern of steam engine was the beam engine, built as an integral part of a stone or brick engine-house, but soon various patterns of self-contained rotative engines (readily removable, but not on wheels) were developed, such as the table engine. Around the start of the 19th century, at which time the Boulton and Watt patent expired, the Cornish engineer Richard Trevithick and the American Oliver Evans began to construct higher-pressure non-condensing steam engines, exhausting against the atmosphere. High pressure yielded an engine and boiler compact enough to be used on mobile road and rail locomotives and steam boats.[citation needed]
",4
4730,"The development of machine tools, such as the engine lathe, planing, milling and shaping machines powered by these engines, enabled all the metal parts of the engines to be easily and accurately cut and in turn made it possible to build larger and more powerful engines.[citation needed]
",4
4731,"Small industrial power requirements continued to be provided by animal and human muscle until widespread electrification in the early 20th century. These included crank-powered, treadle-powered and horse-powered workshop and light industrial machinery.[67]
",4
4732,"Pre-industrial machinery was built by various craftsmen—millwrights built water and windmills, carpenters made wooden framing, and smiths and turners made metal parts. Wooden components had the disadvantage of changing dimensions with temperature and humidity, and the various joints tended to rack (work loose) over time.  As the Industrial Revolution progressed, machines with metal parts and frames became more common.  Other important uses of metal parts were in firearms and threaded fasteners, such as machine screws, bolts and nuts. There was also the need for precision in making parts.  Precision would allow better working machinery, interchangeability of parts and standardization of threaded fasteners.
",4
4733,"The demand for metal parts led to the development of several machine tools. They have their origins in the tools developed in the 18th century by makers of clocks and watches and scientific instrument makers to enable them to batch-produce small mechanisms.
",4
4734,"Before the advent of machine tools, metal was worked manually using the basic hand tools of hammers, files, scrapers, saws and chisels. Consequently, the use of metal machine parts was kept to a minimum.  Hand methods of production were very laborious and costly and precision was difficult to achieve.[38][21]
",4
4735,"The first large precision machine tool was the cylinder boring machine invented by John Wilkinson in 1774. It was used for boring the large-diameter cylinders on early steam engines. Wilkinson's boring machine differed from earlier cantilevered machines used for boring cannon in that the cutting tool was mounted on a beam that ran through the cylinder being bored and was supported outside on both ends.[21]
",4
4736,"The planing machine, the milling machine and the shaping machine were developed in the early decades of the 19th century. Although the milling machine was invented at this time, it was not developed as a serious workshop tool until somewhat later in the 19th century.[38][21]
",4
4737,"Henry Maudslay, who trained a school of machine tool makers early in the 19th century, was a mechanic with superior ability who had been employed at the Royal Arsenal, Woolwich. He worked as an apprentice in the Royal Gun Foundry of Jan Verbruggen. In 1774 Jan Verbruggen had installed a horizontal boring machine in Woolwich which was the first industrial size lathe in the UK. Maudslay was hired away by Joseph Bramah for the production of high-security metal locks that required precision craftsmanship.  Bramah patented a lathe that had similarities to the slide rest lathe.  Maudslay perfected the slide rest lathe, which could cut machine screws of different thread pitches by using changeable gears between the spindle and the lead screw.  Before its invention screws could not be cut to any precision using various earlier lathe designs, some of which copied from a template.[21][43]:392–95  The slide rest lathe was called one of history's most important inventions.  Although it was not entirely Maudslay's idea, he was the first person to build a functional lathe using a combination of known innovations of the lead screw, slide rest and change gears.[21]:31, 36
",4
4738,"Maudslay left Bramah's employment and set up his own shop. He was engaged to build the machinery for making ships' pulley blocks for the Royal Navy in the Portsmouth Block Mills. These machines were all-metal and were the first machines for mass production and making components with a degree of interchangeability. The lessons Maudslay learned about the need for stability and precision he adapted to the development of machine tools, and in his workshops he trained a generation of men to build on his work, such as Richard Roberts, Joseph Clement and Joseph Whitworth.[21]
",4
4739,"James Fox of Derby had a healthy export trade in machine tools for the first third of the century, as did Matthew Murray of Leeds. Roberts was a maker of high-quality machine tools and a pioneer of the use of jigs and gauges for precision workshop measurement.
",4
4740,"The effect of machine tools during the Industrial Revolution was not that great because other than firearms, threaded fasteners and a few other industries there were few mass-produced metal parts. The techniques to make mass-produced metal parts made with sufficient precision to be interchangeable is largely attributed to a program of the U.S. Department of War which perfected interchangeable parts for firearms in the early 19th century.[38]
",4
4741,"In the half century following the invention of the fundamental machine tools the machine industry became the largest industrial sector of the U.S. economy, by value added.[68]
",4
4742,"The large-scale production of chemicals was an important development during the Industrial Revolution. The first of these was the production of sulphuric acid by the lead chamber process invented by the Englishman John Roebuck (James Watt's first partner) in 1746. He was able to greatly increase the scale of the manufacture by replacing the relatively expensive glass vessels formerly used with larger, less expensive chambers made of riveted sheets of lead. Instead of making a small amount each time, he was able to make around 100 pounds (50 kg) in each of the chambers, at least a tenfold increase.
",4
4743,"The production of an alkali on a large scale became an important goal as well, and Nicolas Leblanc succeeded in 1791 in introducing a method for the production of sodium carbonate. The Leblanc process was a reaction of sulfuric acid with sodium chloride to give sodium sulfate and hydrochloric acid. The sodium sulfate was heated with limestone (calcium carbonate) and coal to give a mixture of sodium carbonate and calcium sulfide. Adding water separated the soluble sodium carbonate from the calcium sulfide. The process produced a large amount of pollution (the hydrochloric acid was initially vented to the air, and calcium sulfide was a useless waste product). Nonetheless, this synthetic soda ash proved economical compared to that from burning specific plants (barilla) or from kelp, which were the previously dominant sources of soda ash,[69] and also to potash (potassium carbonate) produced from hardwood ashes.
",4
4744,"These two chemicals were very important because they enabled the introduction of a host of other inventions, replacing many small-scale operations with more cost-effective and controllable processes. Sodium carbonate had many uses in the glass, textile, soap, and paper industries. Early uses for sulfuric acid included pickling (removing rust from) iron and steel, and for bleaching cloth.
",4
4745,"The development of bleaching powder (calcium hypochlorite) by Scottish chemist Charles Tennant in about 1800, based on the discoveries of French chemist Claude Louis Berthollet, revolutionised the bleaching processes in the textile industry by dramatically reducing the time required (from months to days) for the traditional process then in use, which required repeated exposure to the sun in bleach fields after soaking the textiles with alkali or sour milk. Tennant's factory at St Rollox, North Glasgow, became the largest chemical plant in the world.
",4
4746,"After 1860 the focus on chemical innovation was in dyestuffs, and Germany took world leadership, building a strong chemical industry.[70] Aspiring chemists flocked to German universities in the 1860–1914 era to learn the latest techniques. British scientists by contrast, lacked research universities and did not train advanced students; instead, the practice was to hire German-trained chemists.[71]
",4
4747,"In 1824 Joseph Aspdin, a British bricklayer turned builder, patented a chemical process for making portland cement which was an important advance in the building trades. This process involves sintering a mixture of clay and limestone to about 1,400 °C (2,552 °F), then grinding it into a fine powder which is then mixed with water, sand and gravel to produce concrete. Portland cement was used by the famous English engineer Marc Isambard Brunel several years later when constructing the Thames Tunnel.[72] Cement was used on a large scale in the construction of the London sewerage system a generation later.
",4
4748,"Another major industry of the later Industrial Revolution was gas lighting. Though others made a similar innovation elsewhere, the large-scale introduction of this was the work of William Murdoch, an employee of Boulton & Watt, the Birmingham steam engine pioneers. The process consisted of the large-scale gasification of coal in furnaces, the purification of the gas (removal of sulphur, ammonia, and heavy hydrocarbons), and its storage and distribution. The first gas lighting utilities were established in London between 1812 and 1820. They soon became one of the major consumers of coal in the UK. Gas lighting affected social and industrial organisation because it allowed factories and stores to remain open longer than with tallow candles or oil. Its introduction allowed nightlife to flourish in cities and towns as interiors and streets could be lighted on a larger scale than before.[73]
",4
4749,"Glass was made in ancient Greece and Rome.[74] A new method of producing glass, known as the cylinder process, was developed in Europe during the early 19th century. In 1832 this process was used by the Chance Brothers to create sheet glass. They became the leading producers of window and plate glass. This advancement allowed for larger panes of glass to be created without interruption, thus freeing up the space planning in interiors as well as the fenestration of buildings. The Crystal Palace is the supreme example of the use of sheet glass in a new and innovative structure.[75]
",4
4750,"A machine for making a continuous sheet of paper on a loop of wire fabric was patented in 1798 by Nicholas Louis Robert who worked for Saint-Léger Didot family in France. The paper machine is known as a Fourdrinier after the financiers, brothers Sealy and Henry Fourdrinier, who were stationers in London. Although greatly improved and with many variations, the Fourdriner machine is the predominant means of paper production today.
",4
4751,"The method of continuous production demonstrated by the paper machine influenced the development of continuous rolling of iron and later steel and other continuous production processes.[76]
",4
4752,"The British Agricultural Revolution is considered one of the causes of the Industrial Revolution because improved agricultural productivity freed up workers to work in other sectors of the economy.[77] However, per-capita food supply in Europe was stagnant or declining and did not improve in some parts of Europe until the late 18th century.[78]
",4
4753,"Industrial technologies that affected farming included the seed drill, the Dutch plough, which contained iron parts, and the threshing machine.
",4
4754,"The English lawyer Jethro Tull invented an improved seed drill in 1701. It was a mechanical seeder which distributed seeds evenly across a plot of land and planted them at the correct depth.  This was important because the yield of seeds harvested to seeds planted at that time was around four or five.  Tull's seed drill was very expensive and not very reliable and therefore did not have much of an effect. Good quality seed drills were not produced until the mid 18th century.[79]
",4
4755,"Joseph Foljambe's Rotherham plough of 1730 was the first commercially successful iron plough.[80][81][82][83] The threshing machine, invented by the Scottish engineer Andrew Meikle in 1784, displaced hand threshing with a flail, a laborious job that took about one-quarter of agricultural labour.[84]:286  It took several decades to diffuse[85] and was the final straw for many farm labourers, who faced near starvation, leading to the 1830 agricultural rebellion of the Swing Riots.
",4
4756,"Machine tools and metalworking techniques developed during the Industrial Revolution eventually resulted in precision manufacturing techniques in the late 19th century for mass-producing agricultural equipment, such as reapers, binders and combine harvesters.[38]
",4
4757,"Coal mining in Britain, particularly in South Wales, started early. Before the steam engine, pits were often shallow bell pits following a seam of coal along the surface, which were abandoned as the coal was extracted. In other cases, if the geology was favourable, the coal was mined by means of an adit or drift mine driven into the side of a hill. Shaft mining was done in some areas, but the limiting factor was the problem of removing water. It could be done by hauling buckets of water up the shaft or to a sough (a tunnel driven into a hill to drain a mine). In either case, the water had to be discharged into a stream or ditch at a level where it could flow away by gravity. The introduction of the steam pump by Thomas Savery in 1698 and the Newcomen steam engine in 1712 greatly facilitated the removal of water and enabled shafts to be made deeper, enabling more coal to be extracted. These were developments that had begun before the Industrial Revolution, but the adoption of John Smeaton's improvements to the Newcomen engine followed by James Watt's more efficient steam engines from the 1770s reduced the fuel costs of engines, making mines more profitable.  The Cornish engine, developed in the 1810s, was much more efficient than the Watt steam engine.[86]
",4
4758,"Coal mining was very dangerous owing to the presence of firedamp in many coal seams. Some degree of safety was provided by the safety lamp which was invented in 1816 by Sir Humphry Davy and independently by George Stephenson. However, the lamps proved a false dawn because they became unsafe very quickly and provided a weak light. Firedamp explosions continued, often setting off coal dust explosions, so casualties grew during the entire 19th century. Conditions of work were very poor, with a high casualty rate from rock falls.
",4
4759,"At the beginning of the Industrial Revolution, inland transport was by navigable rivers and roads, with coastal vessels employed to move heavy goods by sea. Wagonways were used for conveying coal to rivers for further shipment, but canals had not yet been widely constructed. Animals supplied all of the motive power on land, with sails providing the motive power on the sea.  The first horse railways were introduced toward the end of the 18th century, with steam locomotives being introduced in the early decades of the 19th century.  Improving sailing technologies boosted average sailing speed 50% between 1750 and 1830.[87]
",4
4760,"The Industrial Revolution improved Britain's transport infrastructure with a turnpike road network, a canal and waterway network, and a railway network. Raw materials and finished products could be moved more quickly and cheaply than before. Improved transportation also allowed new ideas to spread quickly.
",4
4761,"Before and during the Industrial Revolution navigation on several British rivers was improved by removing obstructions, straightening curves, widening and deepening and building navigation locks.  Britain had over 1,000 miles of navigable rivers and streams by 1750.[1]:46
",4
4762,"Canals and waterways allowed bulk materials to be economically transported long distances inland.  This was because a horse could pull a barge with a load dozens of times larger than the load that could be drawn in a cart.[43][88]
",4
4763,"In the UK, canals began to be built in the late 18th century to link the major manufacturing centres across the country.  Known for its huge commercial success, the Bridgewater Canal in North West England, which opened in 1761 and was mostly funded by The 3rd Duke of Bridgewater.  From Worsley to the rapidly growing town of Manchester its construction cost £168,000 (£22,589,130 as of 2013[update]),[89][90] but its advantages over land and river transport meant that within a year of its opening in 1761, the price of coal in Manchester fell by about half.[91] This success helped inspire a period of intense canal building, known as Canal Mania.[92] New canals were hastily built in the aim of replicating the commercial success of the Bridgewater Canal, the most notable being the Leeds and Liverpool Canal and the Thames and Severn Canal which opened in 1774 and 1789 respectively.
",4
4764,"By the 1820s a national network was in existence. Canal construction served as a model for the organisation and methods later used to construct the railways. They were eventually largely superseded as profitable commercial enterprises by the spread of the railways from the 1840s on. The last major canal to be built in the United Kingdom was the Manchester Ship Canal, which upon opening in 1894 was the largest ship canal in the world,[93] and opened Manchester as a port. However it never achieved the commercial success its sponsors had hoped for and signalled canals as a dying mode of transport in an age dominated by railways, which were quicker and often cheaper.
",4
4765,"Britain's canal network, together with its surviving mill buildings, is one of the most enduring features of the early Industrial Revolution to be seen in Britain.[citation needed]
",4
4766,"France was known for having an excellent system of roads at the time of the Industrial Revolution; however, most of the roads on the European Continent and in the U.K. were in bad condition and dangerously rutted.[88][95]
",4
4767,"Much of the original British road system was poorly maintained by thousands of local parishes, but from the 1720s (and occasionally earlier) turnpike trusts were set up to charge tolls and maintain some roads. Increasing numbers of main roads were turnpiked from the 1750s to the extent that almost every main road in England and Wales was the responsibility of a turnpike trust. New engineered roads were built by John Metcalf, Thomas Telford and most notably John McAdam, with the first 'macadamised' stretch of road being Marsh Road at Ashton Gate, Bristol in 1816.[96] The first macadamised road in the U.S. was the ""Boonsborough Turnpike Road"" between Hagerstown and Boonsboro, Maryland in 1823.[94]
",4
4768,"The major turnpikes radiated from London and were the means by which the Royal Mail was able to reach the rest of the country. Heavy goods transport on these roads was by means of slow, broad wheeled, carts hauled by teams of horses. Lighter goods were conveyed by smaller carts or by teams of pack horse. Stagecoaches carried the rich, and the less wealthy could pay to ride on carriers carts.
",4
4769,"Productivity of road transport increased greatly during the Industrial Revolution and the cost of travel fell dramatically. Between 1690 and 1840 productivity almost tripled for long-distance carrying and increased four-fold in stage coaching.[97]
",4
4770,"Reducing friction was one of the major reasons for the success of railroads compared to wagons. This was demonstrated on an iron plate covered wooden tramway in 1805 at Croydon, England.
",4
4771,"""A good horse on an ordinary turnpike road can draw two thousand pounds, or one ton.  A party of gentlemen were invited to witness the experiment, that the superiority of the new road might be established by ocular demonstration.  Twelve wagons were loaded with stones, till each wagon weighed three tons, and the wagons were fastened together.  A horse was then attached, which drew the wagons with ease, six miles in two hours, having stopped four times, in order to show he had the power of starting, as well as drawing his great load.""[98]",4
4772,"Railways were made practical by the widespread introduction of inexpensive puddled iron after 1800, the rolling mill for making rails, and the development of the high-pressure steam engine also around 1800.
",4
4773,"Wagonways for moving coal in the mining areas had started in the 17th century and were often associated with canal or river systems for the further movement of coal. These were all horse drawn or relied on gravity, with a stationary steam engine to haul the wagons back to the top of the incline. The first applications of the steam locomotive were on wagon or plate ways (as they were then often called from the cast-iron plates used). Horse-drawn public railways did not begin until the early years of the 19th century when improvements to pig and wrought iron production were lowering costs.
",4
4774,"Steam locomotives began being built after the introduction of high-pressure steam engines after the expiration of the Boulton and Watt patent in 1800. High-pressure engines exhausted used steam to the atmosphere, doing away with the condenser and cooling water.  They were also much lighter weight and smaller in size for a given horsepower than the stationary condensing engines.  A few of these early locomotives were used in mines. Steam-hauled public railways began with the Stockton and Darlington Railway in 1825.[99]
",4
4775,"The rapid introduction of railways followed the 1829 Rainhill Trials, which demonstrated Robert Stephenson's successful locomotive design and the 1828 development of hot blast, which dramatically reduced the fuel consumption of making iron and increased the capacity of the blast furnace.
",4
4776,"On 15 September 1830, the Liverpool and Manchester Railway, the first inter-city railway in the world, was opened, and was attended by Prime Minister, the Duke of Wellington.[100] The railway was engineered by Joseph Locke and George Stephenson, linked the rapidly expanding industrial town of Manchester with the port town of Liverpool. The opening was marred by problems, due to the primitive nature of the technology being employed, however problems were gradually ironed out and the railway became highly successful, transporting passengers and freight. The success of the inter-city railway, particularly in the transport of freight and commodities, led to Railway Mania.
",4
4777,"Construction of major railways connecting the larger cities and towns began in the 1830s but only gained momentum at the very end of the first Industrial Revolution. After many of the workers had completed the railways, they did not return to their rural lifestyles but instead remained in the cities, providing additional workers for the factories.
",4
4778,"Other developments included more efficient water wheels, based on experiments conducted by the British engineer John Smeaton,[101] the beginnings of a machine industry[21][102] and the rediscovery of concrete (based on hydraulic lime mortar) by John Smeaton, which had been lost for 1,300 years.[103]
",4
4779,"Prior to the Industrial Revolution, most of the workforce was employed in agriculture, either as self-employed farmers as landowners or tenants, or as landless agricultural labourers. It was common for families in various parts of the world to spin yarn, weave cloth and make their own clothing.  Households also spun and wove for market production.  At the beginning of the Industrial Revolution India, China and regions of Iraq and elsewhere in Asia and the Middle East produced most of the world's cotton cloth while Europeans produced wool and linen goods.
",4
4780,"In Britain by the 16th century the putting-out system, by which farmers and townspeople produced goods for market in their homes, often described as cottage industry, was being practiced.  Typical putting out system goods included spinning and weaving.  Merchant capitalists typically provided the raw materials, paid workers by the piece, and were responsible for the sale of the goods.  Embezzlement of supplies by workers and poor quality were common problems.  The logistical effort in procuring and distributing raw materials and picking up finished goods were also limitations of the putting out system.[104]
",4
4781,"Some early spinning and weaving machinery, such as a 40 spindle jenny for about six pounds in 1792, was affordable for cottagers.[105] Later machinery such as spinning frames, spinning mules and power looms were expensive (especially if water powered), giving rise to capitalist ownership of factories.
",4
4782,"The majority of textile factory workers during the Industrial Revolution were unmarried women and children, including many orphans.  They typically worked for 12 to 14 hours per day with only Sundays off.  It was common for women take factory jobs seasonally during slack periods of farm work.  Lack of adequate transportation, long hours and poor pay made it difficult to recruit and maintain workers.[40] Many workers, such as displaced farmers and agricultural workers, who had nothing but their labour to sell, became factory workers out of necessity.  (See: British Agricultural Revolution, Threshing machine)
",4
4783,"The change in the social relationship of the factory worker compared to farmers and cottagers was viewed unfavourably by Karl Marx; however, he recognized the increase in productivity made possible by technology.[106]
",4
4784,"Some economists, such as Robert E. Lucas, Jr., say that the real effect of the Industrial Revolution was that ""for the first time in history, the living standards of the masses of ordinary people have begun to undergo sustained growth ... Nothing remotely like this economic behaviour is mentioned by the classical economists, even as a theoretical possibility.""[9] Others, however, argue that while growth of the economy's overall productive powers was unprecedented during the Industrial Revolution, living standards for the majority of the population did not grow meaningfully until the late 19th and 20th centuries, and that in many ways workers' living standards declined under early capitalism: for instance, studies have shown that real wages in Britain only increased 15% between the 1780s and 1850s, and that life expectancy in Britain did not begin to dramatically increase until the 1870s.[10][11] Similarly, the average height of the population declined during the Industrial Revolution, implying that their nutritional status was also decreasing. Real wages were not keeping up with the price of food.[107][108]
",4
4785,"During the Industrial Revolution, the life expectancy of children increased dramatically. The percentage of the children born in London who died before the age of five decreased from 74.5% in 1730–1749 to 31.8% in 1810–1829.[109]
",4
4786,"The effects on living conditions of the industrial revolution have been very controversial, and were hotly debated by economic and social historians from the 1950s to the 1980s.[110] A series of 1950s essays by Henry Phelps Brown and Sheila V. Hopkins later set the academic consensus that the bulk of the population, that was at the bottom of the social ladder, suffered severe reductions in their living standards.[110] During 1813–1913, there was a significant increase in worker wages.[111][112]
",4
4787,"Chronic hunger and malnutrition were the norm for the majority of the population of the world including Britain and France, until the late 19th century. Until about 1750, in large part due to malnutrition, life expectancy in France was about 35 years and about 40 years in Britain. The United States population of the time was adequately fed, much taller on average and had life expectancy of 45–50 years although U.S. life expectancy declined by a few years by the mid 19th century. Food consumption per capita also declined during an episode known as the Antebellum Puzzle.[113]
",4
4788,"Food supply in Great Britain was adversely affected by the Corn Laws (1815–1846).  The Corn Laws, which imposed tariffs on imported grain, were enacted to keep prices high in order to benefit domestic producers.  The Corn Laws were repealed in the early years of the Great Irish Famine.
",4
4789,"The initial technologies of the Industrial Revolution, such as mechanized textiles, iron and coal, did little, if anything, to lower food prices.[78] In Britain and the Netherlands, food supply increased before the Industrial Revolution due to better agricultural practices; however, population grew too, as noted by Thomas Malthus.[1][84][114][115] This condition is called the Malthusian trap, and it finally started to be overcome by transportation improvements, such as canals, improved roads and steamships.[116] Railroads and steamships were introduced near the end of the Industrial Revolution.[84]
",4
4790,"The rapid population growth in the 19th century included the new industrial and manufacturing cities, as well as service centers such as Edinburgh and London.[117] The critical factor was financing, which was handled by building societies that dealt directly with large contracting firms.[118][119] Private renting from housing landlords was the dominant tenure. P. Kemp says this was usually of advantage to tenants.[120] People moved in so rapidly there was not enough capital to build adequate housing for everyone, so low-income newcomers squeezed into increasingly overcrowded slums. Clean water, sanitation, and public health facilities were inadequate; the death rate was high, especially infant mortality, and tuberculosis among young adults. Cholera from polluted water and typhoid were endemic. Unlike rural areas, there were no famines such as the one that devastated Ireland in the 1840s.[121][122][123]
",4
4791,"A large exposé literature grew up condemning the unhealthy conditions. By far the most famous publication was by one of the founders of the Socialist movement, The Condition of the Working Class in England in 1844 Friedrich Engels described backstreet sections of Manchester and other mill towns, where people lived in crude shanties and shacks, some not completely enclosed, some with dirt floors.  These shanty towns had narrow walkways between irregularly shaped lots and dwellings.  There were no sanitary facilities. Population density was extremely high.[124] However, not everyone lived in such poor conditions. The Industrial Revolution also created a middle class of businessmen, clerks, foremen and engineers who lived in much better conditions.
",4
4792,"Conditions improved over the course of the 19th century due to new public health acts regulating things such as sewage, hygiene and home construction. In the introduction of his 1892 edition, Engels notes that most of the conditions he wrote about in 1844 had been greatly improved. For example, the Public Health Act 1875 led to the more sanitary byelaw terraced house.
",4
4793,"In The Condition of the Working Class in England in 1844 Friedrich Engels described how untreated sewage created awful odours and turned the rivers green in industrial cities.
",4
4794,"In 1854 John Snow traced a cholera outbreak in Soho in London to faecal contamination of a public water well by a home cesspit.  Snow's findings that cholera could be spread by contaminated water took some years to be accepted, but his work led to fundamental changes in the design of public water and waste systems.
",4
4795,"Pre-industrial water supply relied on gravity systems and pumping of water was done by water wheels.  Pipes were typically made of wood.  Steam powered pumps and iron pipes allowed the widespread piping of water to horse watering troughs and households.[95]
",4
4796,"Modern industrialization began in England and Scotland in the 18th century, where there were relatively high levels of literacy among farmers, especially in Scotland. This permitted the recruitment of literate craftsman, skilled workers, foremen and managers who supervised the emerging textile factories and coal mines.  Much of a labor was unskilled, and especially in textile mills children as young as eight proved useful in handling chores and adding to the family income. Indeed, children were taken out of school to work alongside their parents in the factories. However, by the mid-nineteenth century, unskilled labor forces were common in Western Europe, and British industry moved upscale, needing many more engineers and skilled workers who could handle technical instructions and handle complex situations. Literacy was essential to be hired.[125][126] A senior government official told Parliament in 1870:
",4
4797,"The invention of the paper machine and the application of steam power to the industrial processes of printing supported a massive expansion of newspaper and pamphlet publishing, which contributed to rising literacy and demands for mass political participation.[128]
",4
4798,"Consumers benefited from falling prices for clothing and household articles such as cast iron cooking utensils, and in the following decades, stoves for cooking and space heating.  Coffee, tea, sugar, tobacco and chocolate became affordable to many in Europe.  Watches and household clocks became popular consumer items.[citation needed]
",4
4799,"Meeting the demands of the consumer revolution and growth in wealth of the middle classes in Britain, potter and entrepreneur Josiah Wedgwood, founder of Wedgwood fine china and porcelain, created goods such as tableware, which was starting to become a common feature on dining tables.[129]
",4
4800,"A growing consumer culture also saw people start to spend more money on entertainment. Increased literacy rates, industrialisation, and the invention of railway, created a new market for cheap popular literature for the masses and the ability for it to be circulated on a large scale. Penny dreadfuls were created in the 1830s to meet this demand.[130] The Guardian described penny dreadfuls as ""Britain's first taste of mass-produced popular culture for the young"", and ""the Victorian equivalent of video games"".[131] More than one million boys' periodicals were sold per week.[131]
",4
4801,"In 1861, Welsh entrepreneur Pryce Pryce-Jones formed the first mail order business, an idea which would change the nature of retail. Selling Welsh flannel, he created mail order catalogues, with customers able to order by mail for the first time—this following the Uniform Penny Post in 1840 and the invention of the postage stamp (Penny Black) where there was a charge of one penny for carriage and delivery between any two places in the United Kingdom irrespective of distance—and the goods were delivered throughout the UK via the newly created railway system.[132] As the railway network expanded overseas, so did his business.[132]
",4
4802,"The Industrial Revolution was the first period in history during which there was a simultaneous increase in both population and per capita income.[133]
",4
4803,"According to Robert Hughes in The Fatal Shore, the population of England and Wales, which had remained steady at six million from 1700 to 1740, rose dramatically after 1740. The population of England had more than doubled from 8.3 million in 1801 to 16.8 million in 1850 and, by 1901, had nearly doubled again to 30.5 million.[134] Improved conditions led to the population of Britain increasing from 10 million to 40 million in the 1800s.[135][136] Europe's population increased from about 100 million in 1700 to 400 million by 1900.[137]
",4
4804,"The growth of modern industry since the late 18th century led to massive urbanisation and the rise of new great cities, first in Europe and then in other regions, as new opportunities brought huge numbers of migrants from rural communities into urban areas.  In 1800, only 3% of the world's population lived in cities,[138] compared to nearly 50% today (the beginning of the 21st century).[139] Manchester had a population of 10,000 in 1717, but by 1911 it had burgeoned to 2.3 million.[140]
",4
4805,"Women's historians have debated the effect of the Industrial Revolution and capitalism generally on the status of women.[141][142] Taking a pessimistic side, Alice Clark argued that when capitalism arrived in 17th-century England, it lowered the status of women as they lost much of their economic importance. Clark argues that in 16th-century England, women were engaged in many aspects of industry and agriculture. The home was a central unit of production and women played a vital role in running farms, and in some trades and landed estates. Their useful economic roles gave them a sort of equality with their husbands. However, Clark argues, as capitalism expanded in the 17th century, there was more and more division of labour with the husband taking paid labour jobs outside the home, and the wife reduced to unpaid household work. Middle- and upper-class women were confined to an idle domestic existence, supervising servants; lower-class women were forced to take poorly paid jobs. Capitalism, therefore, had a negative effect on powerful women.[143]
",4
4806,"In a more positive interpretation, Ivy Pinchbeck argues that capitalism created the conditions for women's emancipation.[144] Tilly and Scott have emphasised the continuity in the status of women, finding three stages in English history. In the pre-industrial era, production was mostly for home use and women produce much of the needs of the households. The second stage was the ""family wage economy"" of early industrialisation; the entire family depended on the collective wages of its members, including husband, wife and older children. The third or modern stage is the ""family consumer economy,"" in which the family is the site of consumption, and women are employed in large numbers in retail and clerical jobs to support rising standards of consumption.[145]
",4
4807,"Ideas of thrift and hard work characterized middle-class families as the Industrial Revolution swept Europe. These values were displayed in Samuel Smiles' book Self-Help, in which he states that the misery of the poorer classes was ""voluntary and self-imposed – the results of idleness, thriftlessness, intemperance, and misconduct.""[146]
",4
4808,"In terms of social structure, the Industrial Revolution witnessed the triumph of a middle class of industrialists and businessmen over a landed class of nobility and gentry. Ordinary working people found increased opportunities for employment in the new mills and factories, but these were often under strict working conditions with long hours of labour dominated by a pace set by machines. As late as the year 1900, most industrial workers in the United States still worked a 10-hour day (12 hours in the steel industry), yet earned from 20% to 40% less than the minimum deemed necessary for a decent life;[147] however, most workers in textiles, which was by far the leading industry in terms of employment, were women and children.[40] For workers of the labouring classes, industrial life ""was a stony desert, which they had to make habitable by their own efforts.""[148] Also, harsh working conditions were prevalent long before the Industrial Revolution took place. Pre-industrial society was very static and often cruel – child labour, dirty living conditions, and long working hours were just as prevalent before the Industrial Revolution.[149]
",4
4809,"Industrialisation led to the creation of the factory. The factory system contributed to the growth of urban areas, as large numbers of workers migrated into the cities in search of work in the factories. Nowhere was this better illustrated than the mills and associated industries of Manchester, nicknamed ""Cottonopolis"", and the world's first industrial city.[150] Manchester experienced a six-times increase in its population between 1771 and 1831. Bradford grew by 50% every ten years between 1811 and 1851 and by 1851 only 50% of the population of Bradford was actually born there.[151]
",4
4810,"In addition, between 1815 and 1939, 20 percent of Europe's population left home, pushed by poverty, a rapidly growing population, and the displacement of peasant farming and artisan manufacturing. They were pulled abroad by the enormous demand for labour overseas, the ready availability of land, and cheap transportation. Still, many did not find a satisfactory life in their new homes, leading 7 million of them to return to Europe.[152] This mass migration had large demographic effects: in 1800, less than one percent of the world population consisted of overseas Europeans and their descendants; by 1930, they represented 11 percent.[153] The Americas felt the brunt of this huge emigration, largely concentrated in the United States.
",4
4811,"For much of the 19th century, production was done in small mills, which were typically water-powered and built to serve local needs. Later, each factory would have its own steam engine and a chimney to give an efficient draft through its boiler.
",4
4812,"In other industries, the transition to factory production was not so divisive. Some industrialists themselves tried to improve factory and living conditions for their workers. One of the earliest such reformers was Robert Owen, known for his pioneering efforts in improving conditions for workers at the New Lanark mills, and often regarded as one of the key thinkers of the early socialist movement.
",4
4813,"By 1746 an integrated brass mill was working at Warmley near Bristol. Raw material went in at one end, was smelted into brass and was turned into pans, pins, wire, and other goods. Housing was provided for workers on site. Josiah Wedgwood and Matthew Boulton (whose Soho Manufactory was completed in 1766) were other prominent early industrialists, who employed the factory system.
",4
4814,"The Industrial Revolution led to a population increase but the chances of surviving childhood did not improve throughout the Industrial Revolution, although infant mortality rates were reduced markedly.[109][155] There was still limited opportunity for education and children were expected to work. Employers could pay a child less than an adult even though their productivity was comparable; there was no need for strength to operate an industrial machine, and since the industrial system was completely new, there were no experienced adult labourers. This made child labour the labour of choice for manufacturing in the early phases of the Industrial Revolution between the 18th and 19th centuries. In England and Scotland in 1788, two-thirds of the workers in 143 water-powered cotton mills were described as children.[156]
",4
4815,"Child labour existed before the Industrial Revolution but with the increase in population and education it became more visible. Many children were forced to work in relatively bad conditions for much lower pay than their elders,[157] 10–20% of an adult male's wage.[citation needed]
",4
4816,"Reports were written detailing some of the abuses, particularly in the coal mines[158] and textile factories,[159] and these helped to popularise the children's plight. The public outcry, especially among the upper and middle classes, helped stir change in the young workers' welfare.
",4
4817,"Politicians and the government tried to limit child labour by law but factory owners resisted; some felt that they were aiding the poor by giving their children money to buy food to avoid starvation, and others simply welcomed the cheap labour. In 1833 and 1844, the first general laws against child labour, the Factory Acts, were passed in Britain: Children younger than nine were not allowed to work, children were not permitted to work at night, and the work day of youth under the age of 18 was limited to twelve hours. Factory inspectors supervised the execution of the law, however, their scarcity made enforcement difficult.[citation needed] About ten years later, the employment of children and women in mining was forbidden. Although laws such as these decreased the number of child labourers, child labour remained significantly present in Europe and the United States until the 20th century.[160]
",4
4818,"The Industrial Revolution concentrated labour into mills, factories and mines, thus facilitating the organisation of combinations or trade unions to help advance the interests of working people. The power of a union could demand better terms by withdrawing all labour and causing a consequent cessation of production. Employers had to decide between giving in to the union demands at a cost to themselves or suffering the cost of the lost production. Skilled workers were hard to replace, and these were the first groups to successfully advance their conditions through this kind of bargaining.
",4
4819,"The main method the unions used to effect change was strike action. Many strikes were painful events for both sides, the unions and the management. In Britain, the Combination Act 1799 forbade workers to form any kind of trade union until its repeal in 1824. Even after this, unions were still severely restricted. One British newspaper in 1834 described unions as ""the most dangerous institutions that were ever permitted to take root, under shelter of law, in any country...""[161]
",4
4820,"In 1832, the Reform Act extended the vote in Britain but did not grant universal suffrage. That year six men from Tolpuddle in Dorset founded the Friendly Society of Agricultural Labourers to protest against the gradual lowering of wages in the 1830s. They refused to work for less than ten shillings a week, although by this time wages had been reduced to seven shillings a week and were due to be further reduced to six. In 1834 James Frampton, a local landowner, wrote to the Prime Minister, Lord Melbourne, to complain about the union, invoking an obscure law from 1797 prohibiting people from swearing oaths to each other, which the members of the Friendly Society had done. James Brine, James Hammett, George Loveless, George's brother James Loveless, George's brother in-law Thomas Standfield, and Thomas's son John Standfield were arrested, found guilty, and transported to Australia. They became known as the Tolpuddle Martyrs. In the 1830s and 1840s, the Chartist movement was the first large-scale organised working class political movement which campaigned for political equality and social justice. Its Charter of reforms received over three million signatures but was rejected by Parliament without consideration.
",4
4821,"Working people also formed friendly societies and co-operative societies as mutual support groups against times of economic hardship. Enlightened industrialists, such as Robert Owen also supported these organisations to improve the conditions of the working class.
",4
4822,"Unions slowly overcame the legal restrictions on the right to strike. In 1842, a general strike involving cotton workers and colliers was organised through the Chartist movement which stopped production across Great Britain.[162]
",4
4823,"Eventually, effective political organisation for working people was achieved through the trades unions who, after the extensions of the franchise in 1867 and 1885, began to support socialist political parties that later merged to become the British Labour Party.
",4
4824,"The rapid industrialisation of the English economy cost many craft workers their jobs. The movement started first with lace and hosiery workers near Nottingham and spread to other areas of the textile industry owing to early industrialisation. Many weavers also found themselves suddenly unemployed since they could no longer compete with machines which only required relatively limited (and unskilled) labour to produce more cloth than a single weaver. Many such unemployed workers, weavers, and others, turned their animosity towards the machines that had taken their jobs and began destroying factories and machinery. These attackers became known as Luddites, supposedly followers of Ned Ludd, a folklore figure.[163] The first attacks of the Luddite movement began in 1811. The Luddites rapidly gained popularity, and the British government took drastic measures, using the militia or army to protect industry. Those rioters who were caught were tried and hanged, or transported for life.[164]
",4
4825,"Unrest continued in other sectors as they industrialised, such as with agricultural labourers in the 1830s when large parts of southern Britain were affected by the Captain Swing disturbances. Threshing machines were a particular target, and hayrick burning was a popular activity. However, the riots led to the first formation of trade unions, and further pressure for reform.
",4
4826,"The traditional centers of hand textile production such as India, parts of the Middle East and later China could not withstand the competition from machine-made textiles, which over a period of decades destroyed the hand made textile industries and left millions of people without work, many of whom starved.[40]
",4
4827,"The Industrial Revolution also generated an enormous and unprecedented economic division in the world, as measured by the share of manufacturing output.
",4
4828,"Cheap cotton textiles increased the demand for raw cotton; previously, it had primarily been consumed in subtropical regions where it was grown, with little raw cotton available for export. Consequently, prices of raw cotton rose. Some cotton had been grown in the West Indies, particularly in Hispaniola, but Haitian cotton production was halted by the Haitian Revolution in 1791. The invention of the cotton gin in 1792 allowed Georgia green seeded cotton to be profitable, leading to the widespread growth of cotton plantations in the United States and Brazil. In 1791 world cotton production was estimated to be 490,000,000 pounds with U.S. production accounting to 2,000,000 pounds.  By 1800, U.S. production was 35,000,000 pounds, of which 17,790,000 were exported.  In 1945 the U.S. produced seven-eights of the 1,169,600,000 pounds of world production.[21]:150
",4
4829,"The Americas, particularly the U.S., had labour shortages and high priced labour, which made slavery attractive.  America's cotton plantations were highly efficient and profitable, and able to keep up with demand.[166] The U.S. Civil War created a ""cotton famine"" that led to increased production in other areas of the world, including new colonies in Africa.
",4
4830,"The origins of the environmental movement lay in the response to increasing levels of smoke pollution in the atmosphere during the Industrial Revolution. The emergence of great factories and the concomitant immense growth in coal consumption gave rise to an unprecedented level of air pollution in industrial centers; after 1900 the large volume of industrial chemical discharges added to the growing load of untreated human waste.[167] The first large-scale, modern environmental laws came in the form of Britain's Alkali Acts, passed in 1863, to regulate the deleterious air pollution (gaseous hydrochloric acid) given off by the Leblanc process, used to produce soda ash. An Alkali inspector and four sub-inspectors were appointed to curb this pollution. The responsibilities of the inspectorate were gradually expanded, culminating in the Alkali Order 1958 which placed all major heavy industries that emitted smoke, grit, dust and fumes under supervision.
",4
4831,"The manufactured gas industry began in British cities in 1812–1820. The technique used produced highly toxic effluent that was dumped into sewers and rivers. The gas companies were repeatedly sued in nuisance lawsuits. They usually lost and modified the worst practices. The City of London repeatedly indicted gas companies in the 1820s for polluting the Thames and poisoning its fish. Finally, Parliament wrote company charters to regulate toxicity.[168] The industry reached the US around 1850 causing pollution and lawsuits.[169]
",4
4832,"In industrial cities local experts and reformers, especially after 1890, took the lead in identifying environmental degradation and pollution, and initiating grass-roots movements to demand and achieve reforms.[170] Typically the highest priority went to water and air pollution. The Coal Smoke Abatement Society was formed in Britain in 1898 making it one of the oldest environmental NGOs. It was founded by artist Sir William Blake Richmond, frustrated with the pall cast by coal smoke. Although there were earlier pieces of legislation, the Public Health Act 1875 required all furnaces and fireplaces to consume their own smoke. It also provided for sanctions against factories that emitted large amounts of black smoke. The provisions of this law were extended in 1926 with the Smoke Abatement Act to include other emissions, such as soot, ash, and gritty particles and to empower local authorities to impose their own regulations.[171]
",4
4833,"In his 1983 book Nations and Nationalism, philosopher Ernest Gellner argues that the industrial revolution and economic modernization spurred the creation of nations.[172]
",4
4834,"The Industrial Revolution in Continental Europe came later than in Great Britain. It started in Belgium and France, then spread to the German states by the middle of the 19th century. In many industries, this involved the application of technology developed in Britain in new places. Typically the technology was purchased from Britain or British engineers and entrepreneurs moved abroad in search of new opportunities. By 1809, part of the Ruhr Valley in Westphalia was called 'Miniature England' because of its similarities to the industrial areas of Britain. Most European governments provided state funding to the new industries. In some cases (such as iron), the different availability of resources locally meant that only some aspects of the British technology were adopted.[173][174]
",4
4835,"Belgium was the second country in which the Industrial Revolution took place and the first in continental Europe: Wallonia (French-speaking southern Belgium) took the lead. Starting in the middle of the 1820s, and especially after Belgium became an independent nation in 1830, numerous works comprising coke blast furnaces as well as puddling and rolling mills were built in the coal mining areas around Liège and Charleroi. The leader was a transplanted Englishman John Cockerill. His factories at Seraing integrated all stages of production, from engineering to the supply of raw materials, as early as 1825.[175][176]
",4
4836,"Wallonia exemplified the radical evolution of industrial expansion. Thanks to coal (the French word ""houille"" was coined in Wallonia),[177] the region geared up to become the 2nd industrial power in the world after Britain. But it is also pointed out by many researchers, with its Sillon industriel, 'Especially in the Haine, Sambre and Meuse valleys, between the Borinage and Liège...there was a huge industrial development based on coal-mining and iron-making...'.[178] Philippe Raxhon wrote about the period after 1830: ""It was not propaganda but a reality the Walloon regions were becoming the second industrial power all over the world after Britain.""[179] ""The sole industrial centre outside the collieries and blast furnaces of Walloon was the old cloth-making town of Ghent.""[180] Professor Michel De Coster stated: ""The historians and the economists say that Belgium was the second industrial power of the world, in proportion to its population and its territory [...] But this rank is the one of Wallonia where the coal-mines, the blast furnaces, the iron and zinc factories, the wool industry, the glass industry, the weapons industry... were concentrated.""[181]
",4
4837,"Wallonia was also the birthplace of a strong Socialist party and strong trade-unions in a particular sociological landscape. At the left, the Sillon industriel, which runs from Mons in the west, to Verviers in the east (except part of North Flanders, in another period of the industrial revolution, after 1920). Even if Belgium is the second industrial country after Britain, the effect of the industrial revolution there was very different. In 'Breaking stereotypes', Muriel Neven and Isabelle Devious say:
",4
4838,"The industrial revolution changed a mainly rural society into an urban one, but with a strong contrast between northern and southern Belgium. During the Middle Ages and the Early Modern Period, Flanders was characterised by the presence of large urban centres [...] at the beginning of the nineteenth century this region (Flanders), with an urbanisation degree of more than 30 per cent, remained one of the most urbanised in the world. By comparison, this proportion reached only 17 per cent in Wallonia, barely 10 per cent in most West European countries, 16 per cent in France and 25 per cent in Britain. Nineteenth century industrialisation did not affect the traditional urban infrastructure, except in Ghent....Also, in Wallonia the traditional urban network was largely unaffected by the industrialisation process, even though the proportion of city-dwellers rose from 17 to 45 per cent between 1831 and 1910. Especially in the Haine, Sambre and Meuse valleys, between the Borinage and Liège, where there was a huge industrial development based on coal-mining and iron-making, urbanisation was fast. During these eighty years the number of municipalities with more than 5,000 inhabitants increased from only 21 to more than one hundred, concentrating nearly half of the Walloon population in this region. Nevertheless, industrialisation remained quite traditional in the sense that it did not lead to the growth of modern and large urban centres, but to a conurbation of industrial villages and towns developed around a coal-mine or a factory. Communication routes between these small centres only became populated later and created a much less dense urban morphology than, for instance, the area around Liège where the old town was there to direct migratory flows.[182]",4
4839,"The industrial revolution in France followed a particular course as it did not correspond to the main model followed by other countries. Notably, most French historians argue France did not go through a clear take-off.[183] Instead, France's economic growth and industrialisation process was slow and steady through the 18th and 19th centuries. However, some stages were identified by Maurice Lévy-Leboyer:
",4
4840,"Based on its leadership in chemical research in the universities and industrial laboratories, Germany, which was unified in 1871, became dominant in the world's chemical industry in the late 19th century. At first the production of dyes based on aniline was critical.[184]
",4
4841,"Germany's political disunity—with three dozen states—and a pervasive conservatism made it difficult to build railways in the 1830s. However, by the 1840s, trunk lines linked the major cities; each German state was responsible for the lines within its own borders. Lacking a technological base at first, the Germans imported their engineering and hardware from Britain, but quickly learned the skills needed to operate and expand the railways. In many cities, the new railway shops were the centres of technological awareness and training, so that by 1850, Germany was self-sufficient in meeting the demands of railroad construction, and the railways were a major impetus for the growth of the new steel industry. Observers found that even as late as 1890, their engineering was inferior to Britain's. However, German unification in 1870 stimulated consolidation, nationalisation into state-owned companies, and further rapid growth. Unlike the situation in France, the goal was support of industrialisation, and so heavy lines crisscrossed the Ruhr and other industrial districts, and provided good connections to the major ports of Hamburg and Bremen. By 1880, Germany had 9,400 locomotives pulling 43,000 passengers and 30,000 tons of freight, and pulled ahead of France.[185]
",4
4842,"The Habsburg realms which became Austria-Hungary in 1867 included 23 million inhabitants in 1800, growing to 36 million by 1870, second only to Russia in population. The population was overwhelmingly rural.  Nationally the per capita rate of industrial growth averaged about 3% between 1818 and 1870. However there were strong regional differences.  The railway system was built in the 1850-1873 period. Before they arrived transportation was very slow and expensive.  In the Alpine and Bohemian regions, proto-industrialization at begun by 1750, and became the center of the first phases of the industrial revolution after 1800. The textile industry was the main factor, utilizing mechanization, steam engines, and the factory system. Much of machinery was purchased from the British. In the Bohemian regions, machine spinning started later and only became a major factor by 1840. Bohemia's resources were successfully exploited, growing 10% a year. The iron industry had developed in the Alpine regions after 1750, with smaller centers in Bohemia and Moravia. Hungary—the eastern half of the Dual Monarchy, was heavily rural with little industry before 1870.[186]
",4
4843,"Technological change accelerated industrialization and urbanization. The GNP per capita grew roughly 1.76% per year from 1870–1913. That level of growth compared very favorably to that of other European nations such as Britain (1%), France (1.06%), and Germany (1.51%).[187] However, in a comparison with Germany and Britain: the Austro-Hungarian economy as a whole still lagged considerably, as sustained modernization had begun much later.[188]
",4
4844,"During the period 1790–1815 Sweden experienced two parallel economic movements: an agricultural revolution with larger agricultural estates, new crops and farming tools and a commercialisation of farming, and a protoindustrialisation, with small industries being established in the countryside and with workers switching between agricultural work in summer and industrial production in winter. This led to economic growth benefiting large sections of the population and leading up to a consumption revolution starting in the 1820s. Between 1815 and 1850, the protoindustries developed into more specialised and larger industries. This period witnessed increasing regional specialisation with mining in Bergslagen, textile mills in Sjuhäradsbygden and forestry in Norrland. Several important institutional changes took place in this period, such as free and mandatory schooling introduced in 1842 (as the first country in the world), the abolition of the national monopoly on trade in handicrafts in 1846, and a stock company law in 1848.[189]
",4
4845,"From 1850 to 1890, Sweden experienced its ""first"" Industrial Revolution with a veritable explosion in export, dominated by crops, wood and steel. Sweden abolished most tariffs and other barriers to free trade in the 1850s and joined the gold standard in 1873. Large infrastructural investments were made during this period, mainly in the expanding rail road network, which was financed in part by the government and in part by private enterprises.[190] From 1890 to 1930, new industries developed with their focus on the domestic market: mechanical engineering, power utilities, papermaking and textile.
",4
4846,"The industrial revolution began about 1870 as Meiji period leaders decided to catch up with the West. The government built railroads, improved roads, and inaugurated a land reform programme to prepare the country for further development. It inaugurated a new Western-based education system for all young people, sent thousands of students to the United States and Europe, and hired more than 3,000 Westerners to teach modern science, mathematics, technology, and foreign languages in Japan (Foreign government advisors in Meiji Japan).
",4
4847,"In 1871, a group of Japanese politicians known as the Iwakura Mission toured Europe and the United States to learn western ways. The result was a deliberate state-led industrialisation policy to enable Japan to quickly catch up. The Bank of Japan, founded in 1882,[191] used taxes to fund model steel and textile factories. Education was expanded and Japanese students were sent to study in the west.
",4
4848,"Modern industry first appeared in textiles, including cotton and especially silk, which was based in home workshops in rural areas.[192]
",4
4849,"During the late 18th and early 19th centuries when the UK and parts of Western Europe began to industrialise, the US was primarily an agricultural and natural resource producing and processing economy.[193] The building of roads and canals, the introduction of steamboats and the building of railroads were important for handling agricultural and natural resource products in the large and sparsely populated country of the period.[194][195]
",4
4850,"Important American technological contributions during the period of the Industrial Revolution were the cotton gin and the development of a system for making interchangeable parts, the latter aided by the development of the milling machine in the US.  The development of machine tools and the system of interchangeable parts were the basis for the rise of the US as the world's leading industrial nation in the late 19th century.
",4
4851,"Oliver Evans invented an automated flour mill in the mid-1780s that used control mechanisms and conveyors so that no labour was needed from the time grain was loaded into the elevator buckets until flour was discharged into a wagon.  This is considered to be the first modern materials handling system an important advance in the progress toward mass production.[38]
",4
4852,"The United States originally used horse-powered machinery for small scale applications such as grain milling, but eventually switched to water power after textile factories began being built in the 1790s. As a result, industrialisation was concentrated in New England and the Northeastern United States, which has fast-moving rivers. The newer water-powered production lines proved more economical than horse-drawn production. In the late 19th century steam-powered manufacturing overtook water-powered manufacturing, allowing the industry to spread to the Midwest.
",4
4853,"Thomas Somers and the Cabot Brothers founded the Beverly Cotton Manufactory in 1787, the first cotton mill in America, the largest cotton mill of its era,[196] and a significant milestone in the research and development of cotton mills in the future. This mill was designed to use horse power, but the operators quickly learned that the horse-drawn platform was economically unstable, and had economic losses for years. Despite the losses, the Manufactory served as a playground of innovation, both in turning a large amount of cotton, but also developing the water-powered milling structure used in Slater's Mill.[197]
",4
4854,"In 1793, Samuel Slater (1768–1835) founded the Slater Mill at Pawtucket, Rhode Island. He had learned of the new textile technologies as a boy apprentice in Derbyshire, England, and defied laws against the emigration of skilled workers by leaving for New York in 1789, hoping to make money with his knowledge. After founding Slater's Mill, he went on to own 13 textile mills.[198] Daniel Day established a wool carding mill in the Blackstone Valley at Uxbridge, Massachusetts in 1809, the third woollen mill established in the US (The first was in Hartford, Connecticut, and the second at Watertown, Massachusetts.) The John H. Chafee Blackstone River Valley National Heritage Corridor retraces the history of ""America's Hardest-Working River', the Blackstone. The Blackstone River and its tributaries, which cover more than 45 miles (72 km) from Worcester, Massachusetts to Providence, Rhode Island, was the birthplace of America's Industrial Revolution. At its peak over 1,100 mills operated in this valley, including Slater's mill, and with it the earliest beginnings of America's Industrial and Technological Development.
",4
4855,"Merchant Francis Cabot Lowell from Newburyport, Massachusetts memorised the design of textile machines on his tour of British factories in 1810. Realising that the War of 1812 had ruined his import business but that a demand for domestic finished cloth was emerging in America, on his return to the United States, he set up the Boston Manufacturing Company. Lowell and his partners built America's second cotton-to-cloth textile mill at Waltham, Massachusetts, second to the Beverly Cotton Manufactory. After his death in 1817, his associates built America's first planned factory town, which they named after him. This enterprise was capitalised in a public stock offering, one of the first uses of it in the United States. Lowell, Massachusetts, using 5.6 miles (9.0 km) of canals and 10,000 horsepower delivered by the Merrimack River, is considered by some as a major contributor to the success of the American Industrial Revolution. The short-lived utopia-like Waltham-Lowell system was formed, as a direct response to the poor working conditions in Britain. However, by 1850, especially following the Great Famine of Ireland, the system had been replaced by poor immigrant labour.
",4
4856,"A major U.S. contribution to industrialisation was the development of techniques to make interchangeable parts from metal.  Precision metal machining techniques were developed by the U.S. Department of War to make interchangeable parts for small firearms.  The development work took place at the Federal Arsenals at Springfield Armory and Harpers Ferry Armory.  Techniques for precision machining using machine tools included using fixtures to hold the parts in proper position, jigs to guide the cutting tools and precision blocks and gauges to measure the accuracy.  The milling machine, a fundamental machine tool, is believed to have been invented by Eli Whitney, who was a government contractor who built firearms as part of this program.  Another important invention was the Blanchard lathe, invented by Thomas Blanchard.  The Blanchard lathe, or pattern tracing lathe, was actually a shaper that could produce copies of wooden gun stocks.  The use of machinery and the techniques for producing standardised and interchangeable parts became known as the American system of manufacturing.[38]
",4
4857,"Precision manufacturing techniques made it possible to build machines that mechanised the shoe industry.[199] and the watch industry. The industrialisation of the watch industry started 1854 also in Waltham, Massachusetts, at the Waltham Watch Company, with the development of machine tools, gauges and assembling methods adapted to the micro precision required for watches.
",4
4858,"Steel is often cited as the first of several new areas for industrial mass-production, which are said to characterise a ""Second Industrial Revolution"", beginning around 1850, although a method for mass manufacture of steel was not invented until the 1860s, when Sir Henry Bessemer invented a new furnace which could convert molten pig iron into steel in large quantities. However, it only became widely available in the 1870s after the process was modified to produce more uniform quality.[43][200] Bessemer steel was being displaced by the open hearth furnace near the end of the 19th century.
",4
4859,"This Second Industrial Revolution gradually grew to include chemicals, mainly the chemical industries, petroleum (refining and distribution), and, in the 20th century, the automotive industry, and was marked by a transition of technological leadership from Britain to the United States and Germany.
",4
4860,"The increasing availability of economical petroleum products also reduced the importance of coal and further widened the potential for industrialisation.
",4
4861,"A new revolution began with electricity and electrification in the electrical industries. The introduction of hydroelectric power generation in the Alps enabled the rapid industrialisation of coal-deprived northern Italy, beginning in the 1890s.
",4
4862,"By the 1890s, industrialisation in these areas had created the first giant industrial corporations with burgeoning global interests, as companies like U.S. Steel, General Electric, Standard Oil and Bayer AG joined the railroad and ship companies on the world's stock markets.
",4
4863,"The causes of the Industrial Revolution were complicated and remain a topic for debate.  Geographic factors include Britain's vast mineral resources.  In addition to metal ores, Britain had the highest quality coal reserves known at the time, as well as abundant water power, highly productive agriculture, and numerous seaports and navigable waterways.[201]
",4
4864,"Some historians believe the Industrial Revolution was an outgrowth of social and institutional changes brought by the end of feudalism in Britain after the English Civil War in the 17th century, although feudalism began to break down after the Black Death of the mid 14th century, followed by other epidemics, until the population reached a low in the 14th century. This created labour shortages and led to falling food prices and a peak in real wages around 1500, after which population growth began reducing wages. Inflation caused by coinage debasement after 1540 followed by precious metals supply increasing from the Americas caused land rents (often long-term leases that transferred to heirs on death) to fall in real terms.[202]
",4
4865,"The Enclosure movement and the British Agricultural Revolution made food production more efficient and less labour-intensive, forcing the farmers who could no longer be self-sufficient in agriculture into cottage industry, for example weaving, and in the longer term into the cities and the newly developed factories.[203] The colonial expansion of the 17th century with the accompanying development of international trade, creation of financial markets and accumulation of capital are also cited as factors, as is the scientific revolution of the 17th century.[204] A change in marrying patterns to getting married later made people able to accumulate more human capital during their youth, thereby encouraging economic development.[205]
",4
4866,"Until the 1980s, it was universally believed by academic historians that technological innovation was the heart of the Industrial Revolution and the key enabling technology was the invention and improvement of the steam engine.[206] However, recent research into the Marketing Era has challenged the traditional, supply-oriented interpretation of the Industrial Revolution.[207]
",4
4867,"Lewis Mumford has proposed that the Industrial Revolution had its origins in the Early Middle Ages, much earlier than most estimates.[208] He explains that the model for standardised mass production was the printing press and that ""the archetypal model for the industrial era was the clock"". He also cites the monastic emphasis on order and time-keeping, as well as the fact that medieval cities had at their centre a church with bell ringing at regular intervals as being necessary precursors to a greater synchronisation necessary for later, more physical, manifestations such as the steam engine.
",4
4868,"The presence of a large domestic market should also be considered an important driver of the Industrial Revolution, particularly explaining why it occurred in Britain. In other nations, such as France, markets were split up by local regions, which often imposed tolls and tariffs on goods traded among them.[209] Internal tariffs were abolished by Henry VIII of England, they survived in Russia until 1753, 1789 in France and 1839 in Spain.
",4
4869,"Governments' grant of limited monopolies to inventors under a developing patent system (the Statute of Monopolies in 1623) is considered an influential factor. The effects of patents, both good and ill, on the development of industrialisation are clearly illustrated in the history of the steam engine, the key enabling technology. In return for publicly revealing the workings of an invention the patent system rewarded inventors such as James Watt by allowing them to monopolise the production of the first steam engines, thereby rewarding inventors and increasing the pace of technological development. However, monopolies bring with them their own inefficiencies which may counterbalance, or even overbalance, the beneficial effects of publicising ingenuity and rewarding inventors.[210] Watt's monopoly prevented other inventors, such as Richard Trevithick, William Murdoch, or Jonathan Hornblower, whom Boulton and Watt sued, from introducing improved steam engines, thereby retarding the spread of steam power.[211][212]
",4
4870,"One question of active interest to historians is why the Industrial Revolution occurred in Europe and not in other parts of the world in the 18th century, particularly China, India, and the Middle East (which pioneered in shipbuilding, textile production, water mills, and much more in the period between 750 and 1100[213]), or at other times like in Classical Antiquity[214] or the Middle Ages.[215] A recent account argued that Europeans have been characterized for thousands of years by a freedom-loving culture originating from the aristocratic societies of early Indo-European invaders.[216] Many historians, however, have challenged this explanation as being not only Eurocentric, but also ignoring historical context. In fact, before the Industrial Revolution, ""there existed something of a global economic parity between the most advanced regions in the world economy.""[217] These historians have suggested a number of other factors, including education, technological changes[218] (see Scientific Revolution in Europe), ""modern"" government, ""modern"" work attitudes, ecology, and culture.[219]
",4
4871,"China was the world's most technologically advanced country for many centuries; however, China stagnated economically and technologically and was surpassed by Western Europe before the Age of Discovery, by which time China banned imports and denied entry to foreigners. China was also a totalitarian society.  China also heavily taxed transported goods.[220][221] Modern estimates of per capita income in Western Europe in the late 18th century are of roughly 1,500 dollars in purchasing power parity (and Britain had a per capita income of nearly 2,000 dollars[222]) whereas China, by comparison, had only 450 dollars. India was essentially feudal, politically fragmented and not as economically advanced as Western Europe.[223]
",4
4872,"Historians such as David Landes and sociologists Max Weber and Rodney Stark credit the different belief systems in Asia and Europe with dictating where the revolution occurred.[224][225] The religion and beliefs of Europe were largely products of Judaeo-Christianity and Greek thought. Conversely, Chinese society was founded on men like Confucius, Mencius, Han Feizi (Legalism), Lao Tzu (Taoism), and Buddha (Buddhism), resulting in very different worldviews.[226] Other factors include the considerable distance of China's coal deposits, though large, from its cities as well as the then unnavigable Yellow River that connects these deposits to the sea.[227]
",4
4873,"Regarding India, the Marxist historian Rajani Palme Dutt said: ""The capital to finance the Industrial Revolution in India instead went into financing the Industrial Revolution in Britain.""[228] In contrast to China, India was split up into many competing kingdoms after the decline of the Mughal Empire, with the major ones in its aftermath including the Marathas, Sikhs, Bengal Subah, and Kingdom of Mysore. In addition, the economy was highly dependent on two sectors—agriculture of subsistence and cotton, and there appears to have been little technical innovation. It is believed that the vast amounts of wealth were largely stored away in palace treasuries by monarchs prior to the British take over.[citation needed]
",4
4874,"Economic historian Joel Mokyr argued that political fragmentation (the presence of a large number of European states) made it possible for heterodox ideas to thrive, as entrepreneurs, innovators, ideologues and heretics could easily flee to a neighboring state in the event that the one state would try to suppress their ideas and activities. This is what set Europe apart from the technologically advanced, large unitary empires such as China and India[contradictory] by providing ""an insurance against economic and technological stagnation"".[229] China had both a printing press and movable type, and India had similar levels of scientific and technological achievement as Europe in 1700, yet the Industrial Revolution would occur in Europe, not China or India. In Europe, political fragmentation was coupled with an ""integrated market for ideas"" where Europe's intellectuals used the lingua franca of Latin, had a shared intellectual basis in Europe's classical heritage and the pan-European institution of the Republic of Letters.[230]
",4
4875,"In addition, Europe's monarchs desperately needed revenue, pushing them into alliances with their merchant classes. Small groups of merchants were granted monopolies and tax-collecting responsibilities in exchange for payments to the state. Located in a region ""at the hub of the largest and most varied network of exchange in history,""[231] Europe advanced as the leader of the Industrial Revolution. In the Americas, Europeans found a windfall of silver, timber, fish, and maize, leading historian Peter Stearns to conclude that ""Europe's Industrial Revolution stemmed in great part from Europe's ability to draw disproportionately on world resources.""[232]
",4
4876,"Modern capitalism originated in the Italian city-states around the end of the first millennium. The city-states were prosperous cities that were independent from feudal lords. They were largely republics whose governments were typically composed of merchants, manufacturers, members of guilds, bankers and financiers. The Italian city-states built a network of branch banks in leading western European cities and introduced double entry bookkeeping. Italian commerce was supported by schools that taught numeracy in financial calculations through abacus schools.[225]
",4
4877,"Great Britain provided the legal and cultural foundations that enabled entrepreneurs to pioneer the Industrial Revolution.[233] Key factors fostering this environment were:
",4
4878,"– British historian Jeremy Black on the BBC's Why the Industrial Revolution Happened Here.[129]
",4
4879,"There were two main values that really drove the Industrial Revolution in Britain. These values were self-interest and an entrepreneurial spirit. Because of these interests, many industrial advances were made that resulted in a huge increase in personal wealth and a consumer revolution.[129] These advancements also greatly benefitted the British society as a whole. Countries around the world started to recognise the changes and advancements in Britain and use them as an example to begin their own Industrial Revolutions.[234]
",4
4880,"The debate about the start of the Industrial Revolution also concerns the massive lead that Great Britain had over other countries. Some have stressed the importance of natural or financial resources that Britain received from its many overseas colonies or that profits from the British slave trade between Africa and the Caribbean helped fuel industrial investment. However, it has been pointed out that slave trade and West Indian plantations provided only 5% of the British national income during the years of the Industrial Revolution.[235] Even though slavery accounted for so little, Caribbean-based demand accounted for 12% of Britain's industrial output.[236]
",4
4881,"Instead, the greater liberalisation of trade from a large merchant base may have allowed Britain to produce and use emerging scientific and technological developments more effectively than countries with stronger monarchies, particularly China and Russia. Britain emerged from the Napoleonic Wars as the only European nation not ravaged by financial plunder and economic collapse, and having the only merchant fleet of any useful size (European merchant fleets were destroyed during the war by the Royal Navy[237]). Britain's extensive exporting cottage industries also ensured markets were already available for many early forms of manufactured goods. The conflict resulted in most British warfare being conducted overseas, reducing the devastating effects of territorial conquest that affected much of Europe. This was further aided by Britain's geographical position—an island separated from the rest of mainland Europe.
",4
4882,"Another theory is that Britain was able to succeed in the Industrial Revolution due to the availability of key resources it possessed. It had a dense population for its small geographical size. Enclosure of common land and the related agricultural revolution made a supply of this labour readily available. There was also a local coincidence of natural resources in the North of England, the English Midlands, South Wales and the Scottish Lowlands. Local supplies of coal, iron, lead, copper, tin, limestone and water power resulted in excellent conditions for the development and expansion of industry. Also, the damp, mild weather conditions of the North West of England provided ideal conditions for the spinning of cotton, providing a natural starting point for the birth of the textiles industry.
",4
4883,"The stable political situation in Britain from around 1688 following the Glorious Revolution, and British society's greater receptiveness to change (compared with other European countries) can also be said to be factors favouring the Industrial Revolution. Peasant resistance to industrialisation was largely eliminated by the Enclosure movement, and the landed upper classes developed commercial interests that made them pioneers in removing obstacles to the growth of capitalism.[239] (This point is also made in Hilaire Belloc's The Servile State.)
",4
4884,"The French philosopher Voltaire wrote about capitalism and religious tolerance in his book on English society, Letters on the English (1733), noting why England at that time was more prosperous in comparison to the country's less religiously tolerant European neighbours. ""Take a view of the Royal Exchange in London, a place more venerable than many courts of justice, where the representatives of all nations meet for the benefit of mankind. There the Jew, the Mahometan [Muslim], and the Christian transact together, as though they all professed the same religion, and give the name of infidel to none but bankrupts. There the Presbyterian confides in the Anabaptist, and the Churchman depends on the Quaker's word. If one religion only were allowed in England, the Government would very possibly become arbitrary; if there were but two, the people would cut one another's throats; but as there are such a multitude, they all live happy and in peace.""[240]
",4
4885,"Britain's population grew 280% 1550–1820, while the rest of Western Europe grew 50–80%. Seventy percent of European urbanisation happened in Britain 1750–1800. By 1800, only the Netherlands was more urbanised than Britain. This was only possible because coal, coke, imported cotton, brick and slate had replaced wood, charcoal, flax, peat and thatch. The latter compete with land grown to feed people while mined materials do not. Yet more land would be freed when chemical fertilisers replaced manure and horse's work was mechanised. A workhorse needs 3 to 5 acres (1.21 to 2.02 ha) for fodder while even early steam engines produced four times more mechanical energy.
",4
4886,"In 1700, 5/6 of coal mined worldwide was in Britain, while the Netherlands had none; so despite having Europe's best transport, most urbanised, well paid, literate people and lowest taxes, it failed to industrialise. In the 18th century, it was the only European country whose cities and population shrank. Without coal, Britain would have run out of suitable river sites for mills by the 1830s.[241] Based on science and experimentation from the continent, the steam engine was developed specifically for pumping water out of mines, many of which in Britain had been mined to below the water table. Although extremely inefficient they were economical because they used unsaleable coal.[242] Iron rails were developed to transport coal, which was a major economic sector in Britain.
",4
4887,"Economic historian Robert Allen has argued that high wages, cheap capital and very cheap energy in Britain made it the ideal place for the industrial revolution to occur.[243] These factors made it vastly more profitable to invest in research and development, and to put technology to use in Britain than other societies.[243] However, two 2018 studies in The Economic History Review showed that wages were not particularly high in the British spinning sector or the construction sector, casting doubt on Allen's explanation.[244][245]
",4
4888,"Knowledge of innovation was spread by several means. Workers who were trained in the technique might move to another employer or might be poached. A common method was for someone to make a study tour, gathering information where he could. During the whole of the Industrial Revolution and for the century before, all European countries and America engaged in study-touring; some nations, like Sweden and France, even trained civil servants or technicians to undertake it as a matter of state policy. In other countries, notably Britain and America, this practice was carried out by individual manufacturers eager to improve their own methods. Study tours were common then, as now, as was the keeping of travel diaries. Records made by industrialists and technicians of the period are an incomparable source of information about their methods.
",4
4889,"Another means for the spread of innovation was by the network of informal philosophical societies, like the Lunar Society of Birmingham, in which members met to discuss 'natural philosophy' (i.e. science) and often its application to manufacturing. The Lunar Society flourished from 1765 to 1809, and it has been said of them, ""They were, if you like, the revolutionary committee of that most far reaching of all the eighteenth century revolutions, the Industrial Revolution"".[246] Other such societies published volumes of proceedings and transactions. For example, the London-based Royal Society of Arts published an illustrated volume of new inventions, as well as papers about them in its annual Transactions.
",4
4890,"There were publications describing technology. Encyclopaedias such as Harris's Lexicon Technicum (1704) and Abraham Rees's Cyclopaedia (1802–1819) contain much of value. Cyclopaedia contains an enormous amount of information about the science and technology of the first half of the Industrial Revolution, very well illustrated by fine engravings. Foreign printed sources such as the Descriptions des Arts et Métiers and Diderot's Encyclopédie explained foreign methods with fine engraved plates.
",4
4891,"Periodical publications about manufacturing and technology began to appear in the last decade of the 18th century, and many regularly included notice of the latest patents. Foreign periodicals, such as the Annales des Mines, published accounts of travels made by French engineers who observed British methods on study tours.
",4
4892,"Another theory is that the British advance was due to the presence of an entrepreneurial class which believed in progress, technology and hard work.[247] The existence of this class is often linked to the Protestant work ethic (see Max Weber) and the particular status of the Baptists and the dissenting Protestant sects, such as the Quakers and Presbyterians that had flourished with the English Civil War. Reinforcement of confidence in the rule of law, which followed establishment of the prototype of constitutional monarchy in Britain in the Glorious Revolution of 1688, and the emergence of a stable financial market there based on the management of the national debt by the Bank of England, contributed to the capacity for, and interest in, private financial investment in industrial ventures.[248]
",4
4893,"Dissenters found themselves barred or discouraged from almost all public offices, as well as education at England's only two universities at the time (although dissenters were still free to study at Scotland's four universities). When the restoration of the monarchy took place and membership in the official Anglican Church became mandatory due to the Test Act, they thereupon became active in banking, manufacturing and education. The Unitarians, in particular, were very involved in education, by running Dissenting Academies, where, in contrast to the universities of Oxford and Cambridge and schools such as Eton and Harrow, much attention was given to mathematics and the sciences – areas of scholarship vital to the development of manufacturing technologies.
",4
4894,"Historians sometimes consider this social factor to be extremely important, along with the nature of the national economies involved. While members of these sects were excluded from certain circles of the government, they were considered fellow Protestants, to a limited extent, by many in the middle class, such as traditional financiers or other businessmen. Given this relative tolerance and the supply of capital, the natural outlet for the more enterprising members of these sects would be to seek new opportunities in the technologies created in the wake of the scientific revolution of the 17th century.
",4
4895,"During the Industrial Revolution, an intellectual and artistic hostility towards the new industrialisation developed, associated with the Romantic movement.  Romanticism revered the traditionalism of rural life and recoiled against the upheavals caused by industrialization, urbanization and the wretchedness of the working classes.[249] Its major exponents in English included the artist and poet William Blake and poets William Wordsworth, Samuel Taylor Coleridge, John Keats, Lord Byron and Percy Bysshe Shelley. The movement stressed the importance of ""nature"" in art and language, in contrast to ""monstrous"" machines and factories; the ""Dark satanic mills"" of Blake's poem ""And did those feet in ancient time"". Mary Shelley's novel Frankenstein reflected concerns that scientific progress might be two-edged. French Romanticism likewise was highly critical of industry.[250]
",4
4896,"
",4
4897,"Heterodox
",4
4898,"In economics, inflation (or less frequently, price inflation) is a general rise in the price level in an economy over a period of time.[1][2][3][4]
When the general price level rises, each unit of currency buys fewer goods and services; consequently, inflation reflects a reduction in the purchasing power per unit of money – a loss of real value in the medium of exchange and unit of account within the economy.[5][6] The opposite of inflation is deflation, a sustained decrease in the general price level of goods and services. The common measure of inflation is the inflation rate, the annualized percentage change in a general price index, usually the consumer price index, over time.[7]
",4
4899,"Economists believe that very high rates of inflation and hyperinflation are harmful, and are caused by an excessive growth of the money supply.[8] Views on which factors determine low to moderate rates of inflation are more varied. Low or moderate inflation may be attributed to fluctuations in real demand for goods and services, or changes in available supplies such as during scarcities.[9] However, the consensus view is that a long sustained period of inflation is caused by money supply growing faster than the rate of economic growth.[10][11]
",4
4900,"Inflation affects economies in various positive and negative ways. The negative effects of inflation include an increase in the opportunity cost of holding money, uncertainty over future inflation which may discourage investment and savings, and if inflation were rapid enough, shortages of goods as consumers begin hoarding out of concern that prices will increase in the future. Positive effects include reducing unemployment due to nominal wage rigidity,[12] allowing the central bank more leeway in carrying out monetary policy, encouraging loans and investment instead of money hoarding, and avoiding the inefficiencies associated with deflation.
",4
4901,"Today, most economists favor a low and steady rate of inflation.[13] Low (as opposed to zero or negative) inflation reduces the severity of economic recessions by enabling the labor market to adjust more quickly in a downturn, and reduces the risk that a liquidity trap prevents monetary policy from stabilizing the economy.[14] The task of keeping the rate of inflation low and stable is usually given to monetary authorities. Generally, these monetary authorities are the central banks that control monetary policy through the setting of interest rates, through open market operations, and through the setting of banking reserve requirements.[15]
",4
4902,"The term ""inflation"" originally referred to a rise in the general price level caused by an imbalance between the quantity of money and trade needs.[16] However, economists today commonly use the term ""inflation"" to refer to increases in the price level. An increase in the money supply may be called monetary inflation, to distinguish it from rising prices, which for clarity may be called ""price inflation"".[17] Economists generally agree that in the long run, price inflation is related to increases in the money supply.[18]
",4
4903,"Conceptually, inflation refers to the general trend of prices, not changes in any specific price. For example, if people choose to buy more cucumbers than tomatoes, cucumbers consequently become more expensive and tomatoes cheaper. These changes are not related to inflation; they reflect a shift in tastes. Inflation is related to the value of currency itself. When currency was linked with gold, if new gold deposits were found, the price of gold and the value of currency would fall, and consequently, prices of all other goods would become higher.[19]
",4
4904,"Other economic concepts related to inflation include: deflation – a fall in the general price level; disinflation – a decrease in the rate of inflation; hyperinflation – an out-of-control inflationary spiral; stagflation – a combination of inflation, slow economic growth and high unemployment; reflation – an attempt to raise the general level of prices to counteract deflationary pressures; and asset price inflation – a general rise in the prices of financial assets without a corresponding increase in the prices of goods or services.
",4
4905,"By the nineteenth century, economists categorized three separate factors that cause a rise or fall in the price of goods: a change in the value or production costs of the good, a change in the price of money which then was usually a fluctuation in the commodity price of the metallic content in the currency, and currency depreciation resulting from an increased supply of currency relative to the quantity of redeemable metal backing the currency. Following the proliferation of private banknote currency printed during the American Civil War, the term ""inflation"" started to appear as a direct reference to the currency depreciation that occurred as the quantity of redeemable banknotes outstripped the quantity of metal available for their redemption. At that time, the term inflation referred to the devaluation of the currency, and not to a rise in the price of goods.[17]
",4
4906,"This relationship between the over-supply of banknotes and a resulting depreciation in their value was noted by earlier classical economists such as David Hume and David Ricardo, who would go on to examine and debate what effect a currency devaluation (later termed monetary inflation) has on the price of goods (later termed price inflation, and eventually just inflation).[20]
",4
4907,"Historically, large infusions of gold or silver into an economy had led to inflation. For instance, when silver was used as currency, the government could collect silver coins, melt them down, mix them with other metals such as copper or lead and reissue them at the same nominal value, a process known as debasement. At the ascent of Nero as Roman emperor in AD 54, the denarius contained more than 90% silver, but by the 270s hardly any silver was left. By diluting the silver with other metals, the government could issue more coins without increasing the amount of silver used to make them. When the cost of each coin is lowered in this way, the government profits from an increase in seigniorage.[21] This practice would increase the money supply but at the same time the relative value of each coin would be lowered. As the relative value of the coins becomes lower, consumers would need to give more coins in exchange for the same goods and services as before. These goods and services would experience a price increase as the value of each coin is reduced.[22]
",4
4908,"The adoption of fiat currency by many countries, from the 18th century onwards, made much larger variations in the supply of money possible. Rapid increases in the money supply have taken place a number of times in countries experiencing political crises, producing hyperinflations –  episodes of extreme inflation rates much higher than those observed in earlier periods of commodity money. The hyperinflation in the Weimar Republic of Germany is a notable example. Currently, the hyperinflation in Venezuela is the highest in the world, with an annual inflation rate of 833,997% as of October 2018.[23]
",4
4909,"However, since the 1980s, inflation has been held low and stable in countries with strong independent central banks. This has led to a moderation of the business cycle and a reduction in variation in most macroeconomic indicators - an event known as the Great Moderation.[24]
",4
4910,"Rapid increases in the quantity of money or in the overall money supply have occurred in many different societies throughout history, changing with different forms of money used.[25][26]
",4
4911,"Song Dynasty China introduced the practice of printing paper money to create fiat currency.[27] During the Mongol Yuan Dynasty, the government spent a great deal of money fighting costly wars, and reacted by printing more money, leading to inflation.[28] Fearing the inflation that plagued the Yuan dynasty, the Ming Dynasty initially rejected the use of paper money, and reverted to using copper coins.[29]
",4
4912,"During the Malian king Mansa Musa's hajj to Mecca in 1324, he was reportedly accompanied by a camel train that included thousands of people and nearly a hundred camels. When he passed through Cairo, he spent or gave away so much gold that it depressed its price in Egypt for over a decade, causing high inflation.[30] A contemporary Arab historian remarked about Mansa Musa's visit:
",4
4913,"Gold was at a high price in Egypt until they came in that year. The mithqal did not go below 25 dirhams and was generally above, but from that time its value fell and it cheapened in price and has remained cheap till now. The mithqal does not exceed 22 dirhams or less. This has been the state of affairs for about twelve years until this day by reason of the large amount of gold which they brought into Egypt and spent there [...].",4
4914,"From the second half of the 15th century to the first half of the 17th, Western Europe experienced a major inflationary cycle referred to as the ""price revolution"",[32][33] with prices on average rising perhaps sixfold over 150 years. This was largely caused by the sudden influx of gold and silver from the New World into Habsburg Spain.[34] The silver spread throughout a previously cash-starved Europe and caused widespread inflation.[35][36] Demographic factors also contributed to upward pressure on prices, with European population growth after depopulation caused by the Black Death pandemic.
",4
4915,"Since there are many possible measures of the price level, there are many possible measures of price inflation. Most frequently, the term ""inflation"" refers to a rise in a broad price index representing the overall price level for goods and services in the economy. The Consumer Price Index (CPI), the Personal consumption expenditures price index (PCEPI) and the GDP deflator are some examples of broad price indices. However, ""inflation"" may also be used to describe a rising price level within a narrower set of assets, goods or services within the economy, such as commodities (including food, fuel, metals), tangible assets (such as real estate), financial assets (such as stocks, bonds), services (such as entertainment and health care), or labor. Although the values of capital assets are often casually said to ""inflate,"" this should not be confused with inflation as a defined term; a more accurate description for an increase in the value of a capital asset is appreciation. The Reuters-CRB Index (CCI), the Producer Price Index, and Employment Cost Index (ECI) are examples of narrow price indices used to measure price inflation in particular sectors of the economy. Core inflation is a measure of inflation for a subset of consumer prices that excludes food and energy prices, which rise and fall more than other prices in the short term. The Federal Reserve Board pays particular attention to the core inflation rate to get a better estimate of long-term future inflation trends overall.[37]
",4
4916,"The inflation rate is most widely calculated by determining the movement or change in a price index, typically the consumer price index.[38]
The inflation rate is the percentage change of a price index over time. The Retail Prices Index is also a measure of inflation that is commonly used in the United Kingdom. It is broader than the CPI and contains a larger basket of goods and services.
",4
4917,"To illustrate the method of calculation, in January 2007, the U.S. Consumer Price Index was 202.416, and in January 2008 it was 211.080. The formula for calculating the annual percentage rate inflation in the CPI over the course of the year is: 




(



211.080
−
202.416

202.416


)

×
100
%
=
4.28
%


{\displaystyle \left({\frac {211.080-202.416}{202.416}}\right)\times 100\%=4.28\%}


The resulting inflation rate for the CPI in this one-year period is 4.28%, meaning the general level of prices for typical U.S. consumers rose by approximately four percent in 2007.[39]
",4
4918,"Other widely used price indices for calculating price inflation include the following:
",4
4919,"Other common measures of inflation are:
",4
4920,"∴ 





GDP Deflator


=



Nominal GDP


Real GDP





{\displaystyle {\mbox{GDP Deflator}}={\frac {\mbox{Nominal GDP}}{\mbox{Real GDP}}}}


",4
4921,"Measuring inflation in an economy requires objective means of differentiating changes in nominal prices on a common set of goods and services, and distinguishing them from those price shifts resulting from changes in value such as volume, quality, or performance. For example, if the price of a can of corn changes from $0.90 to $1.00 over the course of a year, with no change in quality, then this price difference represents inflation. This single price change would not, however, represent general inflation in an overall economy. To measure overall inflation, the price change of a large ""basket"" of representative goods and services is measured. This is the purpose of a price index, which is the combined price of a ""basket"" of many goods and services. The combined price is the sum of the weighted prices of items in the ""basket"". A weighted price is calculated by multiplying the unit price of an item by the number of that item the average consumer purchases. Weighted pricing is a necessary means to measuring the impact of individual unit price changes on the economy's overall inflation. The Consumer Price Index, for example, uses data collected by surveying households to determine what proportion of the typical consumer's overall spending is spent on specific goods and services, and weights the average prices of those items accordingly. Those weighted average prices are combined to calculate the overall price. To better relate price changes over time, indexes typically choose a ""base year"" price and assign it a value of 100. Index prices in subsequent years are then expressed in relation to the base year price.[15] While comparing inflation measures for various periods one has to take into consideration the base effect as well.
",4
4922,"Inflation measures are often modified over time, either for the relative weight of goods in the basket, or in the way in which goods and services from the present are compared with goods and services from the past. Over time, adjustments are made to the type of goods and services selected to reflect changes in the sorts of goods and services purchased by 'typical consumers'. New products may be introduced, older products disappear, the quality of existing products may change, and consumer preferences can shift. Both the sorts of goods and services which are included in the ""basket"" and the weighted price used in inflation measures will be changed over time to keep pace with the changing marketplace.[citation needed]  Different segments of the population may naturally consume different ""baskets"" of goods and services and may even experience different inflation rates.  It is argued that companies have put more innovation into bringing down prices for wealthy families than for poor families.[40]
",4
4923,"Inflation numbers are often seasonally adjusted to differentiate expected cyclical cost shifts. For example, home heating costs are expected to rise in colder months, and seasonal adjustments are often used when measuring for inflation to compensate for cyclical spikes in energy or fuel demand. Inflation numbers may be averaged or otherwise subjected to statistical techniques to remove statistical noise and volatility of individual prices.[citation needed]
",4
4924,"When looking at inflation, economic institutions may focus only on certain kinds of prices, or special indices, such as the core inflation index which is used by central banks to formulate monetary policy.[41]
",4
4925,"Most inflation indices are calculated from weighted averages of selected price changes. This necessarily introduces distortion, and can lead to legitimate disputes about what the true inflation rate is. This problem can be overcome by including all available price changes in the calculation, and then choosing the median value.[42] In some other cases, governments may intentionally report false inflation rates; for instance, during the presidency of Cristina Kirchner (2007–2015) the government of Argentina was criticised for manipulating economic data, such as inflation and GDP figures, for political gain and to reduce payments on its inflation-indexed debt.[43][44]
",4
4926,"Inflation expectations or expected inflation is the rate of inflation that is anticipated for some period of time in the foreseeable future. There are two major approaches to modeling the formation of inflation expectations. Adaptive expectations models them as a weighted average of what was expected one period earlier and the actual rate of inflation that most recently occurred. Rational expectations models them as unbiased, in the sense that the expected inflation rate is not systematically above or systematically below the inflation rate that actually occurs.
",4
4927,"A long-standing survey of inflation expectations is the University of Michigan survey.[45]
",4
4928,"Inflation expectations affect the economy in several ways. They are more or less built into nominal interest rates, so that a rise (or fall) in the expected inflation rate will typically result in a rise (or fall) in nominal interest rates, giving a smaller effect if any on real interest rates. In addition, higher expected inflation tends to be built into the rate of wage increases, giving a smaller effect if any on the changes in real wages. Moreover, the response of inflationary expectations to monetary policy can influence the division of the effects of policy between inflation and unemployment (see Monetary policy credibility).
",4
4929,"Historically, a great deal of economic literature was concerned with the question of what causes inflation and what effect it has. There were different schools of thought as to the causes of inflation. Most can be divided into two broad areas: quality theories of inflation and quantity theories of inflation.
",4
4930,"The quality theory of inflation rests on the expectation of a seller accepting currency to be able to exchange that currency at a later time for goods they desire as a buyer. The quantity theory of inflation rests on the quantity equation of money that relates the money supply, its velocity, and the nominal value of exchanges.
",4
4931,"Currently, the quantity theory of money is widely accepted as an accurate model of inflation in the long run. Consequently, there is now broad agreement among economists that in the long run, the inflation rate is essentially dependent on the growth rate of the money supply relative to the growth of the economy. However, in the short and medium term inflation may be affected by supply and demand pressures in the economy, and influenced by the relative elasticity of wages, prices and interest rates.[46]
",4
4932,"The question of whether the short-term effects last long enough to be important is the central topic of debate between monetarist and Keynesian economists. In monetarism prices and wages adjust quickly enough to make other factors merely marginal behavior on a general trend-line. In the Keynesian view, prices and wages adjust at different rates, and these differences have enough effects on real output to be ""long term"" in the view of people in an economy.
",4
4933,"Keynesian economics proposes that changes in the money supply do not directly affect prices in the short run, and that visible inflation is the result of demand pressures in the economy expressing themselves in prices.
",4
4934,"There are three major sources of inflation, as part of what Robert J. Gordon calls the ""triangle model"":[47]
",4
4935,"Demand-pull theory states that inflation accelerates when aggregate demand increases beyond the ability of the economy to produce (its potential output). Hence, any factor that increases aggregate demand can cause inflation.[49] However, in the long run, aggregate demand can be held above productive capacity only by increasing the quantity of money in circulation faster than the real growth rate of the economy. Another (although much less common) cause can be a rapid decline in the demand for money, as happened in Europe during the Black Death, or in the Japanese occupied territories just before the defeat of Japan in 1945.
",4
4936,"The effect of money on inflation is most obvious when governments finance spending in a crisis, such as a civil war, by printing money excessively. This sometimes leads to hyperinflation, a condition where prices can double in a month or less. The money supply is also thought to play a major role in determining moderate levels of inflation, although there are differences of opinion on how important it is. For example, monetarist economists believe that the link is very strong; Keynesian economists, by contrast, typically emphasize the role of aggregate demand in the economy rather than the money supply in determining inflation. That is, for Keynesians, the money supply is only one determinant of aggregate demand.
",4
4937,"Some Keynesian economists also disagree with the notion that central banks fully control the money supply, arguing that central banks have little control, since the money supply adapts to the demand for bank credit issued by commercial banks. This is known as the theory of endogenous money, and has been advocated strongly by post-Keynesians as far back as the 1960s. This position is not universally accepted –  banks create money by making loans, but the aggregate volume of these loans diminishes as real interest rates increase. Thus, central banks can influence the money supply by making money cheaper or more expensive, thus increasing or decreasing its production.
",4
4938,"A fundamental concept in inflation analysis is the relationship between inflation and unemployment, called the Phillips curve. This model suggests that there is a trade-off between price stability and employment. Therefore, some level of inflation could be considered desirable to minimize unemployment. The Phillips curve model described the U.S. experience well in the 1960s but failed to describe the stagflation experienced in the 1970s. Thus, modern macroeconomics describes inflation using a Phillips curve that is able to shift due to such matters as supply shocks and structural inflation. The former refers to such events like the 1973 oil crisis, while the latter refers to the price/wage spiral and inflationary expectations implying that inflation is the new normal. Thus, the Phillips curve represents only the demand-pull component of the triangle model.
",4
4939,"Another concept of note is the potential output (sometimes called the ""natural gross domestic product""), a level of GDP, where the economy is at its optimal level of production given institutional and natural constraints. (This level of output corresponds to the Non-Accelerating Inflation Rate of Unemployment, NAIRU, or the ""natural"" rate of unemployment or the full-employment unemployment rate.) If GDP exceeds its potential (and unemployment is below the NAIRU), the theory says that inflation will accelerate as suppliers increase their prices and built-in inflation worsens. If GDP falls below its potential level (and unemployment is above the NAIRU), inflation will decelerate as suppliers attempt to fill excess capacity, cutting prices and undermining built-in inflation.[50]
",4
4940,"However, one problem with this theory for policy-making purposes is that the exact level of potential output (and of the NAIRU) is generally unknown and tends to change over time. Inflation also seems to act in an asymmetric way, rising more quickly than it falls. Worse, it can change because of policy: for example, high unemployment under British Prime Minister Margaret Thatcher might have led to a rise in the NAIRU (and a fall in potential) because many of the unemployed found themselves as structurally unemployed, unable to find jobs that fit their skills. A rise in structural unemployment implies that a smaller percentage of the labor force can find jobs at the NAIRU, where the economy avoids crossing the threshold into the realm of accelerating inflation.
",4
4941,"A connection between inflation and unemployment has been drawn since the emergence of large scale unemployment in the 19th century, and connections continue to be drawn today. However, the unemployment rate generally only affects inflation in the short-term but not the long-term.[51] In the long term, the velocity of money is far more predictive of inflation than low unemployment.[52]
",4
4942,"In Marxian economics, the unemployed serve as a reserve army of labor, which restrain wage inflation. In the 20th century, similar concepts in Keynesian economics include the NAIRU (Non-Accelerating Inflation Rate of Unemployment) and the Phillips curve.
",4
4943,"Monetarists believe the most significant factor influencing inflation or deflation is how fast the money supply grows or shrinks. They consider fiscal policy, or government spending and taxation, as ineffective in controlling inflation.[53] The monetarist economist Milton Friedman famously stated, ""Inflation is always and everywhere a monetary phenomenon.""[54]
",4
4944,"Monetarists assert that the empirical study of monetary history shows that inflation has always been a monetary phenomenon. The quantity theory of money, simply stated, says that any change in the amount of money in a system will change the price level. This theory begins with the equation of exchange:
",4
4945,"where
",4
4946,"In this formula, the general price level is related to the level of real economic activity (Q), the quantity of money (M) and the velocity of money (V). The formula is an identity because the velocity of money (V) is defined to be the ratio of final nominal expenditure (



P
Q


{\displaystyle PQ}

) to the quantity of money (M).
",4
4947,"Monetarists assume that the velocity of money is unaffected by monetary policy (at least in the long run), and the real value of output is determined in the long run by the productive capacity of the economy. Under these assumptions, the primary driver of the change in the general price level is changes in the quantity of money. With exogenous velocity (that is, velocity being determined externally and not being influenced by monetary policy), the money supply determines the value of nominal output (which equals final expenditure) in the short run. In practice, velocity is not exogenous in the short run, and so the formula does not necessarily imply a stable short-run relationship between the money supply and nominal output. However, in the long run, changes in velocity are assumed to be determined by the evolution of the payments mechanism. If velocity is relatively unaffected by monetary policy, the long-run rate of increase in prices (the inflation rate) is equal to the long-run growth rate of the money supply plus the exogenous long-run rate of velocity growth minus the long run growth rate of real output.[10]
",4
4948,"If economic growth matches the growth of the money supply, inflation should not occur when all else is equal.[55] A large variety of factors can affect the rate of both. For example, investment in market production, infrastructure, education, and preventive health care can all grow an economy in greater amounts than the investment spending.[56][57]
",4
4949,"Rational expectations theory holds that economic actors look rationally into the future when trying to maximize their well-being, and do not respond solely to immediate opportunity costs and pressures. In this view, while generally grounded in monetarism, future expectations and strategies are important for inflation as well.
",4
4950,"A core assertion of rational expectations theory is that actors will seek to ""head off"" central-bank decisions by acting in ways that fulfill predictions of higher inflation. This means that central banks must establish their credibility in fighting inflation, or economic actors will make bets that the central bank will expand the money supply rapidly enough to prevent recession, even at the expense of exacerbating inflation.  Thus, if a central bank has a reputation as being ""soft"" on inflation, when it announces a new policy of fighting inflation with restrictive monetary growth economic agents will not believe that the policy will persist; their inflationary expectations will remain high, and so will inflation.  On the other hand, if the central bank has a reputation of being ""tough"" on inflation, then such a policy announcement will be believed and inflationary expectations will come down rapidly, thus allowing inflation itself to come down rapidly with minimal economic disruption.
",4
4951,"There are also other theories about inflation that are no longer accepted by mainstream economists.[citation needed]
",4
4952,"The Austrian School stresses that inflation is not uniform over all assets, goods, and services. Inflation depends on differences in markets and on where newly created money and credit enter the economy.[citation needed] Ludwig von Mises said that inflation should refer to an increase in the quantity of money that is not offset by a corresponding increase in the need for money, and that price inflation will necessarily follow.[58][59]
",4
4953,"The real bills doctrine asserts that banks should issue their money in exchange for short-term real bills of adequate value. As long as banks only issue a dollar in exchange for assets worth at least a dollar, the issuing bank's assets will naturally move in step with its issuance of money, and the money will hold its value. Should the bank fail to get or maintain assets of adequate value, then the bank's money will lose value, just as any financial security will lose value if its asset backing diminishes. The real bills doctrine (also known as the backing theory) thus asserts that inflation results when money outruns its issuer's assets. The quantity theory of money, in contrast, claims that inflation results when money outruns the economy's production of goods.
",4
4954,"Currency and banking schools of economics argue the RBD, that banks should also be able to issue currency against bills of trading, which is ""real bills"" that they buy from merchants. This theory was important in the 19th century in debates between ""Banking"" and ""Currency"" schools of monetary soundness, and in the formation of the Federal Reserve. In the wake of the collapse of the international gold standard post 1913, and the move towards deficit financing of government, RBD has remained a minor topic, primarily of interest in limited contexts, such as currency boards. It is generally held in ill repute today, with Frederic Mishkin, a governor of the Federal Reserve going so far as to say it had been ""completely discredited.""
",4
4955,"The debate between currency, or quantity theory, and the banking schools during the 19th century prefigures current questions about the credibility of money in the present. In the 19th century, the banking schools had greater influence in policy in the United States and Great Britain, while the currency schools had more influence ""on the continent"", that is in non-British countries, particularly in the Latin Monetary Union and the earlier Scandinavia monetary union.
",4
4956,"In 2019 monetary historians Thomas M. Humphrey and Richard H. Timberlake published ""Gold, the Real Bills Doctrine, and the Fed: Sources of Monetary Disorder 1922-1938"".[60]
",4
4957,"Inflation is the decrease in the purchasing power of a currency. That is, when the general level of prices rise, each monetary unit can buy fewer goods and services in aggregate. The impact of inflation differs on different sectors of the economy, with some sectors being adversely impacted while others benefitting. For example, with inflation, those segments in society which own physical assets, such as property, stock etc., benefit from the price/value of their holdings going up, when those who seek to acquire them will need to pay more for them. Their ability to do so will depend on the degree to which their income is fixed.  For example, increases in payments to workers and pensioners often lag behind inflation, and for some people income is fixed. Also, individuals or institutions with cash assets will experience a decline in the purchasing power of the cash. Increases in the price level (inflation) erode the real value of money (the functional currency) and other items with an underlying monetary nature.
",4
4958,"Debtors who have debts with a fixed nominal rate of interest will see a reduction in the ""real"" interest rate as the inflation rate rises.  The real interest on a loan is the nominal rate minus the inflation rate. The formula R = N-I approximates the correct answer as long as both the nominal interest rate and the inflation rate are small. The correct equation is r = n/i where r, n and i are expressed as ratios (e.g. 1.2 for +20%, 0.8 for −20%). As an example, when the inflation rate is 3%, a loan with a nominal interest rate of 5% would have a real interest rate of approximately 2% (in fact, it's 1.94%). Any unexpected increase in the inflation rate would decrease the real interest rate.  Banks and other lenders adjust for this inflation risk either by including an inflation risk premium to fixed interest rate loans, or lending at an adjustable rate.
",4
4959,"High or unpredictable inflation rates are regarded as harmful to an overall economy. They add inefficiencies in the market, and make it difficult for companies to budget or plan long-term. Inflation can act as a drag on productivity as companies are forced to shift resources away from products and services to focus on profit and losses from currency inflation.[15] Uncertainty about the future purchasing power of money discourages investment and saving.[61] Inflation can also impose hidden tax increases. For instance, inflated earnings push taxpayers into higher income tax rates unless the tax brackets are indexed to inflation.
",4
4960,"With high inflation, purchasing power is redistributed from those on fixed nominal incomes, such as some pensioners whose pensions are not indexed to the price level, towards those with variable incomes whose earnings may better keep pace with the inflation.[15] This redistribution of purchasing power will also occur between international trading partners. Where fixed exchange rates are imposed, higher inflation in one economy than another will cause the first economy's exports to become more expensive and affect the balance of trade. There can also be negative impacts to trade from an increased instability in currency exchange prices caused by unpredictable inflation.
",4
4961," The second effect noted by Tsiang is that when savers have substituted money holding for lending on financial markets, the role of those markets in channeling savings into investment is undermined. With nominal interest rates driven to zero, or near zero, from the competition with a high return money asset, there would be no price mechanism in whatever is left of those markets. With financial markets effectively euthanized, the remaining goods and physical asset prices would move in perverse directions. For example, an increased desire to save could not push interest rates further down (and thereby stimulate investment) but would instead cause additional money hoarding, driving consumer prices further down and making investment in consumer goods production thereby less attractive. Moderate inflation, once its expectation is incorporated into nominal interest rates, would give those interest rates room to go both up and down in response to shifting investment opportunities, or savers' preferences, and thus allow financial markets to function in a more normal fashion.",4
4962,"Although both fiscal and monetary policy can affect inflation, ever since the 1980s, most countries primarily rely on monetary policy to control inflation. When inflation beyond an acceptable level is taking place, the country's central bank can increase the interest rate, which typically will tend to slow or stop the growth of the money supply. Some central banks have a symmetrical inflation target while others only control inflation when it rises above a threshold, whether publicly disclosed or not.
",4
4963,"In the 21st century, most economists favor a low and steady rate of inflation. In most countries, central banks or other monetary authorities are tasked with keeping their interbank lending rates at low stable levels, and the target inflation rate of about 2% to 3%. Central banks target a low inflation rate because they believe that high inflation is economically costly because it would create uncertainty about differences in relative prices and about the inflation rate itself. A low positive inflation rate is targeted rather than a zero or negative one because the latter could cause or worsen recessions;[13] low (as opposed to zero or negative) inflation reduces the severity of economic recessions by enabling the labor market to adjust more quickly in a downturn, and reduces the risk that a liquidity trap prevents monetary policy from stabilizing the economy.[14]
",4
4964,"Higher interest rates reduce the economy's money supply because fewer people seek loans. When banks make loans, the loan proceeds are generally deposited in bank accounts that are part of the money supply. Therefore, when a person pays back a loan and no other loans are made to replace it, the amount of bank deposits and hence the money supply decrease. For example, in the early 1980s, when the federal funds rate exceeded 15%, the quantity of Federal Reserve dollars fell 8.1%, from US$8.6 trillion down to $7.9 trillion.
",4
4965,"In the latter part of the 20th century, there was a debate between Keynesians and monetarists about the appropriate instrument to use to control inflation. Monetarists emphasize a low and steady growth rate of the money supply, while the Keynesians emphasize reducing aggregate demand during economic expansions and increasing demand during recessions to keep inflation stable. Control of aggregate demand can be achieved using both monetary policy and fiscal policy (increased taxation or reduced government spending to reduce demand).
",4
4966,"A variety of other methods and policies have been proposed and used to control inflation. The inflationary nature of fiat systems provides a potential large market opportunity for new technologies such as blockchain-based solutions that mitigate or even solve for the erosion in purchasing power. These systems may take on the form of simple fiat pegs immediately available for credit markets, or more sophisticated systaes that avoid inflationary products entirely, swapping one asset presentation for another — similar to commodity-backed currencies of the past.[71]
",4
4967,"Under a fixed exchange rate currency regime, a country's currency is tied in value to another single currency or to a basket of other currencies (or sometimes to another measure of value, such as gold). A fixed exchange rate is usually used to stabilize the value of a currency, vis-a-vis the currency it is pegged to. It can also be used as a means to control inflation. However, as the value of the reference currency rises and falls, so does the currency pegged to it. This essentially means that the inflation rate in the fixed exchange rate country is determined by the inflation rate of the country the currency is pegged to. In addition, a fixed exchange rate prevents a government from using domestic monetary policy to achieve macroeconomic stability.
",4
4968,"Under the Bretton Woods agreement, most countries around the world had currencies that were fixed to the U.S. dollar. This limited inflation in those countries, but also exposed them to the danger of speculative attacks. After the Bretton Woods agreement broke down in the early 1970s, countries gradually turned to floating exchange rates. However, in the later part of the 20th century, some countries reverted to a fixed exchange rate as part of an attempt to control inflation. This policy of using a fixed exchange rate to control inflation was used in many countries in South America in the later part of the 20th century (e.g. Argentina (1991–2002), Bolivia, Brazil, and Chile). 
",4
4969,"The gold standard is a monetary system in which a region's common medium of exchange is paper notes (or other monetary token) that are normally freely convertible into pre-set, fixed quantities of gold. The standard specifies how the gold backing would be implemented, including the amount of specie per currency unit. The currency itself has no innate value, but is accepted by traders because it can be redeemed for the equivalent specie. A U.S. silver certificate, for example, could be redeemed for an actual piece of silver.
",4
4970,"The gold standard was partially abandoned via the international adoption of the Bretton Woods system. Under this system all other major currencies were tied at fixed rates to the US dollar, which itself was tied by the US government to gold at the rate of US$35 per ounce. The Bretton Woods system broke down in 1971, causing most countries to switch to fiat money –  money backed only by the laws of the country.
",4
4971,"Under a gold standard, the long term rate of inflation (or deflation) would be determined by the growth rate of the supply of gold relative to total output.[72] Critics argue that this will cause arbitrary fluctuations in the inflation rate, and that monetary policy would essentially be determined by gold mining.[73][74]
",4
4972,"Another method attempted in the past have been wage and price controls (""incomes policies""). Wage and price controls have been successful in wartime environments in combination with rationing. However, their use in other contexts is far more mixed. Notable failures of their use include the 1972 imposition of wage and price controls by Richard Nixon. More successful examples include the Prices and Incomes Accord in Australia and the Wassenaar Agreement in the Netherlands.
",4
4973,"In general, wage and price controls are regarded as a temporary and exceptional measure, only effective when coupled with policies designed to reduce the underlying causes of inflation during the wage and price control regime, for example, winning the war being fought. They often have perverse effects, due to the distorted signals they send to the market. Artificially low prices often cause rationing and shortages and discourage future investment, resulting in yet further shortages. The usual economic analysis is that any product or service that is under-priced is overconsumed. For example, if the official price of bread is too low, there will be too little bread at official prices, and too little investment in bread making by the market to satisfy future needs, thereby exacerbating the problem in the long term.
",4
4974,"Temporary controls may complement a recession as a way to fight inflation: the controls make the recession more efficient as a way to fight inflation (reducing the need to increase unemployment), while the recession prevents the kinds of distortions that controls cause when demand is high. However, in general the advice of economists is not to impose price controls but to liberalize prices by assuming that the economy will adjust and abandon unprofitable economic activity. The lower activity will place fewer demands on whatever commodities were driving inflation, whether labor or resources, and inflation will fall with total economic output. This often produces a severe recession, as productive capacity is reallocated and is thus often very unpopular with the people whose livelihoods are destroyed (see creative destruction).
",4
4975,"The real purchasing power of fixed payments is eroded by inflation unless they are inflation-adjusted to keep their real values constant. In many countries, employment contracts, pension benefits, and government entitlements (such as social security) are tied to a cost-of-living index, typically to the consumer price index.[75] A cost-of-living adjustment (COLA) adjusts salaries based on changes in a cost-of-living index. It does not control inflation, but rather seeks to mitigate the consequences of inflation for those on fixed incomes. Salaries are typically adjusted annually in low inflation economies. During hyperinflation they are adjusted more often.[75] They may also be tied to a cost-of-living index that varies by geographic location if the employee moves.
",4
4976,"Annual escalation clauses in employment contracts can specify retroactive or future percentage increases in worker pay which are not tied to any index. These negotiated increases in pay are colloquially referred to as cost-of-living adjustments (""COLAs"") or cost-of-living increases because of their similarity to increases tied to externally determined indexes.[76]
",4
4977,"Heterodox
",4
4978,"Unemployment, according to the OECD (Organisation for Economic Co-operation and Development), is persons above a specified age (usually 15)[2] not being in paid employment or self-employment but currently available for work during the reference period.[3]
",4
4979,"Unemployment is measured by the unemployment rate, which is the number of people who are unemployed as a percentage of the labour force (the total number of people employed added to those unemployed).[4]
",4
4980,"Unemployment can have many sources, such as the following:
",4
4981,"Unemployment and the status of the economy can be influenced by a country through, for example, fiscal policy. Furthermore, the monetary authority of a country, such as the central bank, can influence the availability and cost for money through its monetary policy.
",4
4982,"In addition to theories of unemployment, a few categorisations of unemployment are used for more precisely modelling the effects of unemployment within the economic system. Some of the main types of unemployment include structural unemployment, frictional unemployment, cyclical unemployment, involuntary unemployment and classical unemployment. Structural unemployment focuses on foundational problems in the economy and inefficiencies inherent in labor markets, including a mismatch between the supply and demand of laborers with necessary skill sets. Structural arguments emphasize causes and solutions related to disruptive technologies and globalization. Discussions of frictional unemployment focus on voluntary decisions to work based on individuals' valuation of their own work and how that compares to current wage rates added to the time and effort required to find a job. Causes and solutions for frictional unemployment often address job entry threshold and wage rates.
",4
4983,"According to the UN's International Labour Organization (ILO), there were 172 million people worldwide (or 5% of the reported global workforce) without work in 2018.[5]
",4
4984,"Because of the difficulty in measuring the unemployment rate by, for example, using surveys (as in the United States) or through registered unemployed citizens (as in some European countries), statistical figures such as the employment-to-population ratio might be more suitable for evaluating the status of the workforce and the economy if they were based on people who are registered, for example, as taxpayers.[6]
",4
4985,"The state of being without any work yet looking for work is called unemployment. Economists distinguish between various overlapping types of and theories of unemployment, including cyclical or Keynesian unemployment, frictional unemployment, structural unemployment and classical unemployment. Some additional types of unemployment that are occasionally mentioned are seasonal unemployment, hardcore unemployment, and hidden unemployment.
",4
4986,"Though there have been several definitions of ""voluntary"" and ""involuntary unemployment"" in the economics literature, a simple distinction is often applied. Voluntary unemployment is attributed to the individual's decisions, but involuntary unemployment exists because of the socio-economic environment (including the market structure, government intervention, and the level of aggregate demand) in which individuals operate. In these terms, much or most of frictional unemployment is voluntary since it reflects individual search behavior. Voluntary unemployment includes workers who reject low-wage jobs, but involuntary unemployment includes workers fired because of an economic crisis, industrial decline, company bankruptcy, or organizational restructuring.
",4
4987,"On the other hand, cyclical unemployment, structural unemployment, and classical unemployment are largely involuntary in nature. However, the existence of structural unemployment may reflect choices made by the unemployed in the past, and classical (natural) unemployment may result from the legislative and economic choices made by labour unions or political parties.
",4
4988,"The clearest cases of involuntary unemployment are those with fewer job vacancies than unemployed workers even when wages are allowed to adjust and so even if all vacancies were to be filled, some unemployed workers would still remain. That happens with cyclical unemployment, as macroeconomic forces cause microeconomic unemployment, which can boomerang back and exacerbate those macroeconomic forces.
",4
4989,"Classical, or real-wage, unemployment, occurs when real wages for a job are set above the market-clearing level, causing the number of job-seekers to exceed the number of vacancies. On the other hand, most economists argue that as wages fall below a livable wage, many choose to drop out of the labor market and no longer seek employment. That is especially true in countries in which low-income families are supported through public welfare systems. In such cases, wages would have to be high enough to motivate people to choose employment over what they receive through public welfare. Wages below a livable wage are likely to result in lower labor market participation in the above-stated scenario. In addition, consumption of goods and services is the primary driver of increased demand for labor. Higher wages lead to workers having more income available to consume goods and services. Therefore, higher wages increase general consumption and as a result demand for labor increases and unemployment decreases.
",4
4990,"Many economists[who?] have argued that unemployment increases with increased governmental regulation. For example, minimum wage laws raise the cost of some low-skill laborers above market equilibrium, resulting in increased unemployment as people who wish to work at the going rate cannot (as the new and higher enforced wage is now greater than the value of their labour).[7][8] Laws restricting layoffs may make businesses less likely to hire in the first place, as hiring becomes more risky.[8]
",4
4991,"However, that argument overly simplifies the relationship between wage rates and unemployment by ignoring numerous factors that contribute to unemployment.[9][10][11][12][13] Some, such as Murray Rothbard, suggest that even social taboos can prevent wages from falling to the market-clearing level.[14]
",4
4992,"In Out of Work: Unemployment and Government in the Twentieth-Century America, economists Richard Vedder and Lowell Gallaway argue that the empirical record of wages rates, productivity, and unemployment in America validates classical unemployment theory. Their data shows a strong correlation between adjusted real wage and unemployment in the United States from 1900 to 1990. However, they maintain that their data does not take into account exogenous events.[15]
",4
4993,"Cyclical, deficient-demand, or Keynesian unemployment occurs when there is not enough aggregate demand in the economy to provide jobs for everyone who wants to work. Demand for most goods and services falls, less production is needed and consequently, fewer workers are needed, wages are sticky and do not fall to meet the equilibrium level, and unemployment results.[16] Its name is derived from the frequent ups and downs in the business cycle, but unemployment can also be persistent, such as during the Great Depression.
",4
4994,"With cyclical unemployment, the number of unemployed workers exceeds the number of job vacancies and so even if all open jobs were filled, some workers would still remain unemployed. Some associate cyclical unemployment with frictional unemployment because the factors that cause the friction are partially caused by cyclical variables. For example, a surprise decrease in the money supply may suddenly inhibit aggregate demand and thus inhibit labor demand.
",4
4995,"Keynesian economists, on the other hand, see the lack of supply of jobs as potentially resolvable by government intervention. One suggested intervention involves deficit spending to boost employment and goods demand. Another intervention involves an expansionary monetary policy to increase the supply of money, which should reduce interest rates, which, in turn, should lead to an increase in non-governmental spending.[17]
",4
4996,"In demand-based theory, it is possible to abolish cyclical unemployment by increasing the aggregate demand for products and workers. However, the economy eventually hits an ""inflation barrier"" that is imposed by the four other kinds of unemployment to the extent that they exist. Historical experience suggests that low unemployment affects inflation in the short term but not the long term.[18] In the long term, the velocity of money supply measures such as the MZM (""money zero maturity"", representing cash and equivalent demand deposits) velocity is far more predictive of inflation than low unemployment.[19][20]
",4
4997,"Some demand theory economists see the inflation barrier as corresponding to the natural rate of unemployment. The ""natural"" rate of unemployment is defined as the rate of unemployment that exists when the labour market is in equilibrium, and there is pressure for neither rising inflation rates nor falling inflation rates. An alternative technical term for that rate is the NAIRU, the Non-Accelerating Inflation Rate of Unemployment. Whatever its name, demand theory holds that if the unemployment rate gets ""too low,"" inflation will accelerate in the absence of wage and price controls (incomes policies).
",4
4998,"One of the major problems with the NAIRU theory is that no one knows exactly what the NAIRU is, and it clearly changes over time.[18] The margin of error can be quite high relative to the actual unemployment rate, making it hard to use the NAIRU in policy-making.[19]
",4
4999,"Another, normative, definition of full employment might be called the ideal unemployment rate. It would exclude all types of unemployment that represent forms of inefficiency. This type of ""full employment"" unemployment would correspond to only frictional unemployment (excluding that part encouraging the McJobs management strategy) and so would be very low. However, it would be impossible to attain this full-employment target using only demand-side Keynesian stimulus without getting below the NAIRU and causing accelerating inflation (absent incomes policies). Training programs aimed at fighting structural unemployment would help here.
",4
5000,"To the extent that hidden unemployment exists, it implies that official unemployment statistics provide a poor guide to what unemployment rate coincides with ""full employment.""[18]
",4
5001,"Structural unemployment occurs when a labour market is unable to provide jobs for everyone who wants one because there is a mismatch between the skills of the unemployed workers and the skills needed for the available jobs. Structural unemployment is hard to separate empirically from frictional unemployment except that it lasts longer. As with frictional unemployment, simple demand-side stimulus will not work to abolish this type of unemployment easily.
",4
5002,"Structural unemployment may also be encouraged to rise by persistent cyclical unemployment: if an economy suffers from longlasting low aggregate demand, it means that many of the unemployed become disheartened, and their skills (including job-searching skills) become ""rusty"" and obsolete. Problems with debt may lead to homelessness and a fall into the vicious circle of poverty.
",4
5003,"That means that they may not fit the job vacancies that are created when the economy recovers. The implication is that sustained high demand may lower structural unemployment. This theory of persistence in structural unemployment has been referred to as an example of path dependence or ""hysteresis.""
",4
5004,"Much technological unemployment,[21] caused by the replacement of workers by machines might be counted as structural unemployment. Alternatively, technological unemployment might refer to the way in which steady increases in labour productivity mean that fewer workers are needed to produce the same level of output every year. The fact that aggregate demand can be raised to deal with the problem suggests that the problem is instead one of cyclical unemployment. As indicated by Okun's law, the demand side must grow sufficiently quickly to absorb not only the growing labour force but also the workers who are made redundant by the increased labour productivity.
",4
5005,"Seasonal unemployment may be seen as a kind of structural unemployment since it is linked to certain kinds of jobs (construction and migratory farm work). The most-cited official unemployment measures erase this kind of unemployment from the statistics using ""seasonal adjustment"" techniques. That results in substantial and permanent structural unemployment.
",4
5006,"Frictional unemployment is the time period between jobs in which a worker searches for or transitions from one job to another. It is sometimes called search unemployment and can be voluntary, based on the circumstances of the unemployed individual. Frictional unemployment exists because both jobs and workers are heterogeneous, and a mismatch can result between the characteristics of supply and demand. Such a mismatch can be related to skills, payment, work-time, location, seasonal industries, attitude, taste, and a multitude of other factors. New entrants (such as graduating students) and re-entrants (such as former homemakers) can also suffer a spell of frictional unemployment.
",4
5007,"Workers and employers accept a certain level of imperfection, risk or compromise, but usually not right away. They will invest some time and effort to find a better match. That is, in fact, beneficial to the economy since it results in a better allocation of resources. However, if the search takes too long and mismatches are too frequent, the economy suffers since some work will not get done. Therefore, governments will seek ways to reduce unnecessary frictional unemployment by multiple means including providing education, advice, training, and assistance such as daycare centers.
",4
5008,"The frictions in the labour market are sometimes illustrated graphically with a Beveridge curve, a downward-sloping, convex curve that shows a correlation between the unemployment rate on one axis and the vacancy rate on the other. Changes in the supply of or demand for labour cause movements along the curve. An increase or decrease in labour market frictions will shift the curve outwards or inwards.
",4
5009,"Official statistics often underestimate unemployment rates because of hidden, or covered, unemployment. That is the unemployment of potential workers that are not reflected in official unemployment statistics because of how the statistics are collected. In many countries, only those who have no work but are actively looking for work and/or qualifying for social security benefits are counted as unemployed. Those who have given up looking for work and sometimes those who are on government ""retraining"" programs are not officially counted among the unemployed even though they are not employed. 
",4
5010,"The statistic also does not count the ""underemployed"", those working fewer hours than they would prefer or in a job that fails to make good use of their capabilities. In addition, those who are of working age but are currently in full-time education are usually not considered unemployed in government statistics. Traditional unemployed native societies who survive by gathering, hunting, herding, and farming in wilderness areas may or may not be counted in unemployment statistics.
",4
5011,"Long-term unemployment (LTU) is defined in European Union statistics as unemployment lasting for longer than one year (while unemployment lasting over two years is defined as very long-term unemployment). The United States Bureau of Labor Statistics (BLS), which reports current long-term unemployment rate at 1.9 percent, defines this as unemployment lasting 27 weeks or longer. Long-term unemployment is a component of structural unemployment, which results in long-term unemployment existing in every social group, industry, occupation, and all levels of education.[22]
",4
5012,"In 2015 the European Commission published recommendations on how to reduce long-term unemployment.[23] These advised governments to:
",4
5013,"In 2017–2019 it implemented the Long-Term Unemployment project to research solutions implemented by EU member states and produce a toolkit[24] to guide government action. Progress was evaluated[25] in 2019.
",4
5014,It is in the very nature of the capitalist mode of production to overwork some workers while keeping the rest as a reserve army of unemployed paupers.,4
5015,"Marxists share the Keynesian viewpoint of the relationship between economic demand and employment, but with the caveat that the market system's propensity to slash wages and reduce labor participation on an enterprise level causes a requisite decrease in aggregate demand in the economy as a whole, causing crises of unemployment and periods of low economic activity before the capital accumulation (investment) phase of economic growth can continue. According to Karl Marx, unemployment is inherent within the unstable capitalist system and periodic crises of mass unemployment are to be expected. He theorized that unemployment was inevitable and even a necessary part of the capitalist system, with recovery and regrowth also part of the process.[27] The function of the proletariat within the capitalist system is to provide a ""reserve army of labour"" that creates downward pressure on wages. This is accomplished by dividing the proletariat into surplus labour (employees) and under-employment (unemployed).[28] This reserve army of labour fight among themselves for scarce jobs at lower and lower wages. At first glance, unemployment seems inefficient since unemployed workers do not increase profits, but unemployment is profitable within the global capitalist system because unemployment lowers wages which are costs from the perspective of the owners. From this perspective low wages benefit the system by reducing economic rents. Yet, it does not benefit workers; according to Karl Marx, the workers (proletariat) work to benefit the bourgeoisie through their production of capital.[29] Capitalist systems unfairly manipulate the market for labour by perpetuating unemployment which lowers laborers' demands for fair wages. Workers are pitted against one another at the service of increasing profits for owners. As a result of the capitalist mode of production, Marx argued that workers experienced alienation and estrangement through their economic identity.[30] According to Marx, the only way to permanently eliminate unemployment would be to abolish capitalism and the system of forced competition for wages and then shift to a socialist or communist economic system. For contemporary Marxists, the existence of persistent unemployment is proof of the inability of capitalism to ensure full employment.[31]
",4
5016,"There are also different ways national statistical agencies measure unemployment. The differences may limit the validity of international comparisons of unemployment data.[32] To some degree, the differences remain despite national statistical agencies increasingly adopting the definition of unemployment of the International Labour Organization.[33] To facilitate international comparisons, some organizations, such as the OECD, Eurostat, and International Labor Comparisons Program, adjust data on unemployment for comparability across countries.
",4
5017,"Though many people care about the number of unemployed individuals, economists typically focus on the unemployment rate, which corrects for the normal increase in the number of people employed caused by increases in population and increases in the labour force relative to the population. The unemployment rate is expressed as a percentage and calculated as follows:
",4
5018,"As defined by the International Labour Organization, ""unemployed workers"" are those who are currently not working but are willing and able to work for pay, currently available to work, and have actively searched for work.[34]
Individuals who are actively seeking job placement must make the effort to be in contact with an employer, have job interviews, contact job placement agencies, send out resumes, submit applications, respond to advertisements, or some other means of active job searching within the prior four weeks. Simply looking at advertisements and not responding will not count as actively seeking job placement. Since not all unemployment may be ""open"" and counted by government agencies, official statistics on unemployment may not be accurate.[35] In the United States, for example, the unemployment rate does not take into consideration those individuals who are not actively looking for employment, such as those who are still attending college.[36]
",4
5019,"According to the OECD, Eurostat, and the US Bureau of Labor Statistics the unemployment rate is the number of unemployed people as a percentage of the labour force.
",4
5020,"""An unemployed person is defined by Eurostat, according to the guidelines of the International Labour Organization, as:
",4
5021,"The labour force, or workforce, includes both employed (employees and self-employed) and unemployed people but not the economically inactive, such as pre-school children, school children, students and pensioners.[38]
",4
5022,"The unemployment rate of an individual country is usually calculated and reported on a monthly, quarterly, and yearly basis by the National Agency of Statistics. Organisations like the OECD report statistics for all of its member states.[39]
",4
5023,"Certain countries provide unemployment compensation for a certain period of time for unemployed citizens who are registered as unemployed at the government employment agency. Furthermore, pension receivables or claims could depend on the registration at the government employment agency.[40][41]
",4
5024,"In many countries like in Germany, the unemployment rate is based on the number of people who are registered as unemployed.[42] Other countries like the United States use a labour force survey to calculate the unemployment rate.[43][44]
",4
5025,"The ILO describes four different methods to calculate the unemployment rate:[45]
",4
5026,"The primary measure of unemployment, U3, allows for comparisons between countries. Unemployment differs from country to country and across different time periods. For example, in the 1990s and 2000s, the United States had lower unemployment levels than many countries in the European Union,[46] which had significant internal variation, with countries like the United Kingdom and Denmark outperforming Italy and France. However, large economic events like the Great Depression can lead to similar unemployment rates across the globe.
",4
5027,"In 2013, the ILO adopted a resolution to introduce new indicators to measure the unemployment rate.[47]
",4
5028,"x 100
",4
5029,"labour force) / (extended labour force)] × 100
",4
5030,"Eurostat, the statistical office of the European Union, defines unemployed as those persons between age 15 and 74 who are not working, have looked for work in the last four weeks, and are ready to start work within two weeks; this definition conforms to ILO standards. Both the actual count and the unemployment rate are reported. Statistical data are available by member state for the European Union as a whole (EU28) as well as for the eurozone (EA19). Eurostat also includes a long-term unemployment rate, which is defined as part of the unemployed who have been unemployed for more than one year.[48]
",4
5031,"The main source used is the European Union Labour Force Survey (EU-LFS). It collects data on all member states each quarter. For monthly calculations, national surveys or national registers from employment offices are used in conjunction with quarterly EU-LFS data. The exact calculation for individual countries, resulting in harmonized monthly data, depends on the availability of the data.[49]
",4
5032,"The Bureau of Labor Statistics measures employment and unemployment (of those over 17 years of age) by using two different labor force surveys[51] conducted by the United States Census Bureau (within the United States Department of Commerce) and/or the Bureau of Labor Statistics (within the United States Department of Labor) that gather employment statistics monthly. The Current Population Survey (CPS), or ""Household Survey,"" conducts a survey based on a sample of 60,000 households. The survey measures the unemployment rate based on the ILO definition.[52]
",4
5033,"The Current Employment Statistics survey (CES), or ""Payroll Survey,"" conducts a survey based on a sample of 160,000 businesses and government agencies, which represent 400,000 individual employers.[53] Since the survey measures only civilian nonagricultural employment, it does not calculate an unemployment rate, and it differs from the ILO unemployment rate definition. Both sources have different classification criteria and usually produce differing results. Additional data are also available from the government, such as the unemployment insurance weekly claims report available from the Office of Workforce Security, within the U.S. Department of Labor's Employment and Training Administration.[54] The Bureau of Labor Statistics provides up-to-date numbers via a PDF linked here.[55] The BLS also provides a readable concise current Employment Situation Summary, updated monthly.[56]
",4
5034,"The Bureau of Labor Statistics also calculates six alternate measures of unemployment, U1 to U6, which measure different aspects of unemployment:[57]
",4
5035,"Note: ""Marginally attached workers"" are added to the total labour force for unemployment rate calculation for U4, U5, and U6. The BLS revised the CPS in 1994 and among the changes the measure representing the official unemployment rate was renamed U3 instead of U5.[60] In 2013, Representative Hunter proposed that the Bureau of Labor Statistics use the U5 rate instead of the current U3 rate.[61]
",4
5036,"Statistics for the US economy as a whole hide variations among groups. For example, in January 2008, the US unemployment rates were 4.4% for adult men, 4.2% for adult women, 4.4% for Caucasians, 6.3% for Hispanics or Latinos (all races), 9.2% for African Americans, 3.2% for Asian Americans, and 18.0% for teenagers.[53] Also, the US unemployment rate would be at least 2% higher if prisoners and jail inmates were counted.[62][63]
",4
5037,"The unemployment rate is included in a number of major economic indices including the US Conference Board's Index of Leading Indicators a macroeconomic measure of the state of the economy.
",4
5038,"Some critics believe that current methods of measuring unemployment are inaccurate in terms of the impact of unemployment on people as these methods do not take into account the 1.5% of the available working population incarcerated in US prisons (who may or may not be working while they are incarcerated); those who have lost their jobs and have become discouraged over time from actively looking for work; those who are self-employed or wish to become self-employed, such as tradesmen or building contractors or information technology consultants; those who have retired before the official retirement age but would still like to work (involuntary early retirees); those on disability pensions who do not possess full health but still wish to work in occupations that suitable for their medical conditions; or those who work for payment for as little as one hour per week but would like to work full time.[69]
",4
5039,"The last people are ""involuntary part-time"" workers, those who are underemployed, such as a computer programmer who is working in a retail store until he can find a permanent job, involuntary stay-at-home mothers who would prefer to work, and graduate and professional school students who are unable to find worthwhile jobs after they graduated with their bachelor's degrees.
",4
5040,"Internationally, some nations' unemployment rates are sometimes muted or appear less severe because of the number of self-employed individuals working in agriculture.[64] Small independent farmers are often considered self-employed and so cannot be unemployed. That can impact non-industrialized economies, such as the United States and Europe in the early 19th century, since overall unemployment was approximately 3% because so many individuals were self-employed, independent farmers; however, non-agricultural unemployment was as high as 80%.[64]
",4
5041,"Many economies industrialize and so experience increasing numbers of non-agricultural workers. For example, the United States' non-agricultural labour force increased from 20% in 1800 to 50% in 1850 and  97% in 2000.[64] The shift away from self-employment increases the percentage of the population that is included in unemployment rates. When unemployment rates between countries or time periods are compared, it is best to consider differences in their levels of industrialization and self-employment.
",4
5042,"Additionally, the measures of employment and unemployment may be ""too high."" In some countries, the availability of unemployment benefits can inflate statistics by giving an incentive to register as unemployed. People who do not seek work may choose to declare themselves unemployed to get benefits; people with undeclared paid occupations may try to get unemployment benefits in addition to the money that they earn from their work.[70]
",4
5043,"However, in the United States, Canada, Mexico, Australia, Japan, and the European Union, unemployment is measured using a sample survey (akin to a Gallup poll).[33] According to the BLS, a number of Eastern European nations have instituted labour force surveys as well. The sample survey has its own problems because the total number of workers in the economy is calculated based on a sample, rather than a census.
",4
5044,"It is possible to be neither employed nor unemployed by ILO definitions by being outside of the ""labour force.""[35] Such people have no job and are not looking for one. Many of them go to school or are retired. Family responsibilities keep others out of the labour force. Still others have a physical or mental disability that prevents them from participating in the labour force. Some people simply elect not to work and prefer to be dependent on others for sustenance.
",4
5045,"Typically, employment and the labour force include only work that is done for monetary gain. Hence, a homemaker is neither part of the labour force nor unemployed. Also, full-time students and prisoners are considered to be neither part of the labour force nor unemployed.[69] The number of prisoners can be important. In 1999, economists Lawrence F. Katz and Alan B. Krueger estimated that increased incarceration lowered measured unemployment in the United States by 0.17% between 1985 and the late 1990s.[69]
",4
5046,"In particular, as of 2005, roughly 0.7% of the US population is incarcerated (1.5% of the available working population). Additionally, children, the elderly, and some individuals with disabilities are typically not counted as part of the labour force and so are not included in the unemployment statistics. However, some elderly and many disabled individuals are active in the labour market.
",4
5047,"In the early stages of an economic boom, unemployment often rises.[16] That is because people join the labour market (give up studying, start a job hunt, etc.) as a result of the improving job market, but until they have actually found a position, they are counted as unemployed. Similarly, during a recession, the increase in the unemployment rate is moderated by people leaving the labour force or being otherwise discounted from the labour force, such as with the self-employed.
",4
5048,"For the fourth quarter of 2004, according to OECD (Employment Outlook 2005 .mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:""\""""""\""""""'""""'""}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url(""//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg"")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url(""//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg"")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url(""//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg"")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url(""//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg"")right 0.1em center/12px no-repeat}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}ISBN 92-64-01045-9), normalized unemployment for men aged 25 to 54 was 4.6% in the US and 7.4% in France. At the same time and for the same population, the employment rate (number of workers divided by population) was 86.3% in the US and 86.7% in France. That example shows that the unemployment rate was 60% higher in France than in the US, but more people in that demographic were working in France than in the US, which is counterintuitive if it is expected that the unemployment rate reflects the health of the labour market.[71][72]
",4
5049,"Those deficiencies make many labour market economists prefer to look at a range of economic statistics such as labour market participation rate, the percentage of people between 15 and 64 who are currently employed or searching for employment, the total number of full-time jobs in an economy, the number of people seeking work as a raw number and not a percentage, and the total number of person-hours worked in a month compared to the total number of person-hours people would like to work. In particular, the National Bureau of Economic Research does not use the unemployment rate but prefers various employment rates to date recessions.[73]
",4
5050,"The labor force participation rate is the ratio between the labor force and the overall size of their cohort (national population of the same age range). In the West, during the later half of the 20th century, the labor force participation rate increased significantly because of an increase in the number of women entering the workplace.
",4
5051,"In the United States, there have been four significant stages of women's participation in the labour force: increases in the 20th century and decreases in the 21st century. Male labor force participation decreased from 1953 to 2013. Since October 2013, men have been increasingly joining the labour force.
",4
5052,"From the late 19th century to the 1920s, very few women worked outside the home. They were young single women who typically withdrew from the labor force at marriage unless family needed two incomes. Such women worked primarily in the textile manufacturing industry or as domestic workers. That profession empowered women and allowed them to earn a living wage. At times, they were a financial help to their families.
",4
5053,"Between 1930 and 1950, female labor force participation increased primarily because of the increased demand for office workers, women's participation in the high school movement, and electrification, which reduced the time that was spent on household chores. From the 1950s to the early 1970s, most women were secondary earners working mainly as secretaries, teachers, nurses, and librarians (pink-collar jobs).
",4
5054,"From the mid-1970s to the late 1990s, there was a period of revolution of women in the labor force brought on by various factors, many of which arose from the second-wave feminism movement. Women more accurately planned for their future in the work force by investing in more applicable majors in college that prepared them to enter and compete in the labor market. In the United States, the female labor force participation rate rose from approximately 33% in 1948 to a peak of 60.3% in 2000. As of April 2015, the female labor force participation is at 56.6%, the male labor force participation rate is at 69.4%, and the total is 62.8%.[74]
",4
5055,"A common theory in modern economics claims that the rise of women participating in the US labor force in the 1950s to the 1990s was caused by the introduction of a new contraceptive technology, birth control pills, as well as the adjustment of age of majority laws. The use of birth control gave women the flexibility of opting to invest and to advance their career while they maintained a relationship. By having control over the timing of their fertility, they were not running a risk of thwarting their career choices. However, only 40% of the population actually used the birth control pill.
",4
5056,"That implies that other factors may have contributed to women choosing to invest in advancing their careers. One factor may be that an increasing number of men delayed the age of marriage, which allowed women to marry later in life without them worrying about the quality of older men. Other factors include the changing nature of work, with machines replacing physical labor, thus eliminating many traditional male occupations, and the rise of the service sector in which many jobs are gender neutral.
",4
5057,"Another factor that may have contributed to the trend was the Equal Pay Act of 1963, which aimed at abolishing wage disparity based on sex. Such legislation diminished sexual discrimination and encouraged more women to enter the labor market by receiving fair remuneration to help raising families and children.
",4
5058,"At the turn of the 21st century, the labor force participation began to reverse its long period of increase. Reasons for the change include a rising share of older workers, an increase in school enrollment rates among young workers, and a decrease in female labor force participation.[75]
",4
5059,"The labor force participation rate can decrease when the rate of growth of the population outweighs that of the employed and the unemployed together. The labor force participation rate is a key component in long-term economic growth, almost as important as productivity.
",4
5060,"A historic shift began around the end of the Great Recession as women began leaving the labor force in the United States and other developed countries. The female labor force participation rate in the United States has steadily decreased since 2009, and as of April 2015, the female labor force participation rate has gone back down to 1988 levels of 56.6%.[74]
",4
5061,"Participation rates are defined as follows:
",4
5062,"The labor force participation rate explains how an increase in the unemployment rate can occur simultaneously with an increase in employment. If a large number of new workers enter the labor force but only a small fraction become employed, then the increase in the number of unemployed workers can outpace the growth in employment.[76]
",4
5063,"The unemployment ratio calculates the share of unemployed for the whole population. Particularly, many young people between 15 and 24 are studying full-time and so are neither working nor looking for a job. That means that they are not part of the labor force, which is used as the denominator when the unemployment rate is calculated.[77] The youth unemployment ratios in the European Union range from 5.2 (Austria) to 20.6 percent (Spain). They are considerably lower than the standard youth unemployment rates, ranging from 7.9 (Germany) to 57.9 percent (Greece).[78]
",4
5064,"High and the persistent unemployment, in which economic inequality increases, has a negative effect on subsequent long-run economic growth. Unemployment can harm growth because it is a waste of resources; generates redistributive pressures and subsequent distortions; drives people to poverty; constrains liquidity limiting labor mobility; and erodes self-esteem promoting social dislocation, unrest, and conflict.[79] The 2013 winner of the Nobel Prize in Economics, Robert J. Shiller, said that rising inequality in the United States and elsewhere is the most important problem.[80]
",4
5065,"Unemployed individuals are unable to earn money to meet financial obligations. Failure to pay mortgage payments or to pay rent may lead to homelessness through foreclosure or eviction.[81] Across the United States the growing ranks of people made homeless in the foreclosure crisis are generating tent cities.[82]
",4
5066,"Unemployment increases susceptibility to cardiovascular disease, somatization, anxiety disorders, depression, and suicide. In addition, unemployed people have higher rates of medication use, poor diet, physician visits, tobacco smoking, alcoholic beverage consumption, drug use, and lower rates of exercise.[83] According to a study published in Social Indicator Research, even those who tend to be optimistic find it difficult to look on the bright side of things when unemployed. Using interviews and data from German participants aged 16 to 94, including individuals coping with the stresses of real life and not just a volunteering student population, the researchers determined that even optimists struggled with being unemployed.[84]
",4
5067,"In 1979, M. Harvey Brenner found that for every 10% increase in the number of unemployed, there is an increase of 1.2% in total mortality, a 1.7% increase in cardiovascular disease, 1.3% more cirrhosis cases, 1.7% more suicides, 4.0% more arrests, and 0.8% more assaults reported to the police.[85][86]
",4
5068,"A study by Christopher Ruhm in 2000 on the effect of recessions on health found that several measures of health actually improve during recessions.[87] As for the impact of an economic downturn on crime, during the Great Depression, the crime rate did not decrease. The unemployed in the US often use welfare programs such as food stamps or accumulating debt because unemployment insurance in the US generally does not replace most of the income that was received on the job, and one cannot receive such aid indefinitely.
",4
5069,"Not everyone suffers equally from unemployment. In a prospective study of 9,570 individuals over four years, highly-conscientious people suffered more than twice as much if they became unemployed.[88] The authors suggested that may because of conscientious people making different attributions about why they became unemployed or through experiencing stronger reactions following failure. There is also the possibility of reverse causality from poor health to unemployment.[89]
",4
5070,"Some researchers hold that many of the low-income jobs are not really a better option than unemployment with a welfare state, with its unemployment insurance benefits. However, since it is difficult or impossible to get unemployment insurance benefits without having worked in the past, those jobs and unemployment are more complementary than they are substitutes. (They are often held short-term, either by students or by those trying to gain experience; turnover in most low-paying jobs is high.)
",4
5071,"Another cost for the unemployed is that the combination of unemployment, lack of financial resources, and social responsibilities may push unemployed workers to take jobs that do not fit their skills or allow them to use their talents. Unemployment can cause underemployment, and fear of job loss can spur psychological anxiety. As well as anxiety, it can cause depression, lack of confidence, and huge amounts of stress, which is increased when the unemployed are faced with health issues, poverty, and lack of relational support.[90]
",4
5072,"Another personal cost of unemployment is its impact on relationships. A 2008 study from Covizzi, which examined the relationship between unemployment and divorce, found that the rate of divorce is greater for couples when one partner is unemployed.[91] However, a more recent study has found that some couples often stick together in ""unhappy"" or ""unhealthy"" marriages when they are unemployed to buffer financial costs.[92] A 2014 study by Van der Meer found that the stigma that comes from being unemployed affects personal well-being, especially for men, who often feel as though their masculine identities are threatened by unemployment.[93]
",4
5073,"Unemployment can also bring personal costs in relation to gender. One study found that women are more likely to experience unemployment than men and that they are less likely to move from temporary positions to permanent positions.[94] Another study on gender and unemployment found that men, however, are more likely to experience greater stress, depression, and adverse effects from unemployment, largely stemming from the perceived threat to their role as breadwinner.[95] The study found that men expect themselves to be viewed as ""less manly"" after a job loss than they actually are and so they engage in compensating behaviors, such as financial risk-taking and increased assertiveness. Unemployment has been linked to extremely adverse effects on men's mental health.[96] Professor Ian Hickie of the University of Sydney said that evidence showed that men have more restricted social networks than women and that men have are heavily work-based. Therefore, the loss of a job for men means the loss of a whole set of social connections as well. That loss can then lead to men becoming socially isolated very quickly.[97] An Australian study on the mental health impacts of graduating during an economic downturn found that the negative mental health outcomes are greater and more scarring for men than women. The effect was particuarly pronounced for those with vocational or secondary education.[98]
",4
5074,"Costs of unemployment also vary depending on age. The young and the old are the two largest age groups currently experiencing unemployment.[99] A 2007 study from Jacob and Kleinert found that young people (ages 18 to 24) who have fewer resources and limited work experiences are more likely to be unemployed.[100] Other researchers have found that today's high school seniors place a lower value on work than those in the past, which is likely because they recognize the limited availability of jobs.[101] At the other end of the age spectrum, studies have found that older individuals have more barriers than younger workers to employment, require stronger social networks to acquire work, and are also less likely to move from temporary to permanent positions.[94][99] Additionally, some older people see age discrimination as the reason for them not getting hired.[102]
",4
5075,"An economy with high unemployment is not using all of the resources, specifically labour, available to it. Since it is operating below its production possibility frontier, it could have higher output if all of the workforce were usefully employed. However, there is a tradeoff between economic efficiency and unemployment: if all frictionally unemployed accepted the first job that they were offered, they would be likely to be operating at below their skill level, reducing the economy's efficiency.[103]
",4
5076,"During a long period of unemployment, workers can lose their skills, causing a loss of human capital. Being unemployed can also reduce the life expectancy of workers by about seven years.[8]
",4
5077,"High unemployment can encourage xenophobia and protectionism since workers fear that foreigners are stealing their jobs.[104] Efforts to preserve existing jobs of domestic and native workers include legal barriers against ""outsiders"" who want jobs, obstacles to immigration, and/or tariffs and similar trade barriers against foreign competitors.
",4
5078,"High unemployment can also cause social problems such as crime. If people have less disposable income than before, it is very likely that crime levels within the economy will increase.
",4
5079,"A 2015 study published in The Lancet, estimates that unemployment causes 45,000 suicides a year globally.[105]
",4
5080,"High levels of unemployment can be causes of civil unrest,[106] in some cases leading to revolution, particularly totalitarianism. The fall of the Weimar Republic in 1933 and Adolf Hitler's rise to power, which culminated in World War II and the deaths of tens of millions and the destruction of much of the physical capital of Europe, is attributed to the poor economic conditions in Germany at the time, notably a high unemployment rate[107] of above 20%; see Great Depression in Central Europe for details.
",4
5081,"However the hyperinflation in the Weimar Republic is not directly blamed for the Nazi rise. Hyperinflation occurred primarily in 1921 to 1923, the year of Hitler's Beer Hall Putsch. Although hyperinflation has been blamed for damaging the credibility of democratic institutions, the Nazis did not assume government until 1933, ten years after the hyperinflation but in the midst of high unemployment.
",4
5082,"Rising unemployment has traditionally been regarded by the public and the media in any country as a key guarantor of electoral defeat for any government that oversees it. That was very much the consensus in the United Kingdom until 1983, when Thatcher's Conservative government won a landslide in the general election, despite overseeing a rise in unemployment from 1.5 million to 3.2 million since the 1979 election.[108]
",4
5083,"The primary benefit of unemployment is that people are available for hire, without being headhunted away from their existing employers. That permits both new and old businesses to take on staff.
",4
5084,"Unemployment is argued to be ""beneficial"" to the people who are not unemployed in the sense that it averts inflation, which itself has damaging effects, by providing (in Marxian terms) a reserve army of labour, which keeps wages in check.[109] However, the direct connection between full local employment and local inflation has been disputed by some because of the recent increase in international trade that supplies low-priced goods even while local employment rates rise to full employment.[110]
",4
5085," Full employment cannot be achieved because workers would shirk if they were not threatened with the possibility of unemployment.[111] The curve for the no-shirking condition (labelled NSC) thus goes to infinity at full employment. The inflation-fighting benefits to the entire economy arising from a presumed optimum level of unemployment have been studied extensively.[112] The Shapiro–Stiglitz model suggests that wages never bid down sufficiently to reach 0% unemployment.[113] That occurs because employers know that when wages decrease, workers will shirk and expend less effort. Employers avoid shirking by preventing wages from decreasing so low that workers give up and become unproductive. The higher wages perpetuate unemployment, but the threat of unemployment reduces shirking.
",4
5086,"Before current levels of world trade were developed, unemployment was shown to reduce inflation, following the Phillips curve, or to decelerate inflation, following the NAIRU/natural rate of unemployment theory since it is relatively easy to seek a new job without losing a current job. When more jobs are available for fewer workers (lower unemployment), that may allow workers to find the jobs that better fit their tastes, talents and needs.
",4
5087,"As in the Marxian theory of unemployment, special interests may also benefit. Some employers may expect that employees with no fear of losing their jobs will not work as hard or will demand increased wages and benefit. According to that theory, unemployment may promote general labour productivity and profitability by increasing employers' rationale for their monopsony-like power (and profits).[26]
",4
5088,"Optimal unemployment has also been defended as an environmental tool to brake the constantly-accelerated growth of the GDP to maintain levels that are sustainable in the context of resource constraints and environmental impacts.[114] However, the tool of denying jobs to willing workers seems a blunt instrument for conserving resources and the environment. It reduces the consumption of the unemployed across the board and only in the short term. Full employment of the unemployed workforce, all focused toward the goal of developing more environmentally-efficient methods for production and consumption, might provide a more significant and lasting cumulative environmental benefit and reduced resource consumption.[115]
",4
5089,"Some critics of the ""culture of work"" such as the anarchist Bob Black see employment as culturally overemphasized in modern countries. Such critics often propose quitting jobs when possible, working less, reassessing the cost of living to that end, creation of jobs that are ""fun"" as opposed to ""work,"" and creating cultural norms in which work is seen as unhealthy. These people advocate an ""anti-work"" ethic for life.[116]
",4
5090,"As a result of productivity, the work week declined considerably during the 19th century.[117][118] By the 1920s, the average workweek in the US was 49 hours, but it was reduced to 40 hours (after which overtime premium was applied) as part of the 1933 National Industrial Recovery Act. During the Great Depression, the enormous productivity gains caused by electrification, mass production, and agricultural mechanization were believed to have ended the need for a large number of previously-employed workers.[21][119]
",4
5091,"Societies try a number of different measures to get as many people as possible into work, and various societies have experienced close to full employment for extended periods, particularly during the post-World War II economic expansion. The United Kingdom in the 1950s and 1960s averaged 1.6% unemployment,[121] and in Australia, the 1945 White Paper on Full Employment in Australia established a government policy of full employment, which lasted until the 1970s.[122]
",4
5092,"However, mainstream economic discussions of full employment since the 1970s suggest that attempts to reduce the level of unemployment below the natural rate of unemployment will fail but result only in less output and more inflation.
",4
5093,"Increases in the demand for labour move the economy along the demand curve, increasing wages and employment. The demand for labour in an economy is derived from the demand for goods and services. As such, if the demand for goods and services in the economy increases, the demand for labour will increase, increasing employment and wages.
",4
5094,"There are many ways to stimulate demand for goods and services. Increasing wages to the working class (those more likely to spend the increased funds on goods and services, rather than various types of savings or commodity purchases) is one theory that is proposed. Increased wages are believed to be more effective in boosting demand for goods and services than central banking strategies, which put the increased money supply mostly into the hands of wealthy persons and institutions. Monetarists suggest that increasing money supply in general increases short-term demand. As for the long-term demand, the increased demand is negated by inflation. A rise in fiscal expenditures is another strategy for boosting aggregate demand.
",4
5095,"Providing aid to the unemployed is a strategy that is used to prevent cutbacks in consumption of goods and services, which can lead to a vicious cycle of further job losses and further decreases in consumption and demand. Many countries aid the unemployed through social welfare programs. Such unemployment benefits include unemployment insurance, unemployment compensation, welfare, and subsidies to aid in retraining. The main goal of such programs is to alleviate short-term hardships and, more importantly, to allow workers more time to search for a job.
",4
5096,"A direct demand-side solution to unemployment is government-funded employment of the able-bodied poor. This was notably implemented in Britain from the 17th century until 1948 in the institution of the workhouse, which provided jobs for the unemployed with harsh conditions and poor wages to dissuade their use. A modern alternative is a job guarantee in which the government guarantees work at a living wage.
",4
5097,"Temporary measures can include public works programs such as the Works Progress Administration. Government-funded employment is not widely advocated as a solution to unemployment except in times of crisis. That is attributed to the public sector jobs' existence depending directly on the tax receipts from private sector employment.
",4
5098,"In the US, the unemployment insurance allowance is based solely on previous income (not time worked, family size, etc.) and usually compensates for one third of previous income. To qualify, people must reside in their respective state for at least a year and work. The system was established by the Social Security Act of 1935. Although 90% of citizens are covered by unemployment insurance, less than 40% apply for and receive benefits.[123] However, the number applying for and receiving benefits increases during recessions. For highly-seasonal industries, the system provides income to workers during the off-season, thus encouraging them to stay attached to the industry.
",4
5099,"According to classical economic theory, markets reach equilibrium where supply equals demand; everyone who wants to sell at the market price can do so. Those who do not want to sell at that price do not; in the labour market, this is classical unemployment. Monetary policy and fiscal policy can both be used to increase short-term growth in the economy, increasing the demand for labour and decreasing unemployment.
",4
5100,"However, the labor market is not 100% efficient although it may be more efficient than the bureaucracy. Some argue that minimum wages and union activity keep wages from falling, which means that too many people want to sell their labour at the going price but cannot. That assumes perfect competition exists in the labour market, specifically that no single entity is large enough to affect wage levels and that employees are similar in ability.
",4
5101,"Advocates of supply-side policies believe those policies can solve the problem by making the labour market more flexible. These include removing the minimum wage and reducing the power of unions. Supply-siders argue that their reforms increase long-term growth by reducing labour costs. The increased supply of goods and services requires more workers, increasing employment. It is argued that supply-side policies, which include cutting taxes on businesses and reducing regulation, create jobs, reduce unemployment, and decrease labor's share of national income. Other supply-side policies include education to make workers more attractive to employers.
",4
5102,"There are relatively limited historical records on unemployment because it has not always been acknowledged or measured systematically. Industrialization involves economies of scale, which often prevent individuals from having the capital to create their own jobs to be self-employed. An individual who cannot join an enterprise or create a job is unemployed. As individual farmers, ranchers, spinners, doctors and merchants are organized into large enterprises, those who cannot join or compete become unemployed.
",4
5103,"Recognition of unemployment occurred slowly as economies across the world industrialized and bureaucratized. Before then, traditional self-sufficient native societies have no concept of unemployment. The recognition of the concept of ""unemployment"" is best exemplified through the well documented historical records in England. For example, in 16th-century England no distinction was made between vagrants and the jobless; both were simply categorized as ""sturdy beggars"", who were to be punished and moved on.[125]
",4
5104,"The closing of the monasteries in the 1530s increased poverty, as the Roman Catholic Church had helped the poor. In addition, there was a significant rise in enclosures during the Tudor period. Also, the population was rising. Those unable to find work had a stark choice: starve or break the law. In 1535, a bill was drawn up calling for the creation of a system of public works to deal with the problem of unemployment, which were to be funded by a tax on income and capital. A law that was passed a year later allowed vagabonds to be whipped and hanged.[126]
",4
5105,"In 1547, a bill was passed that subjected vagrants to some of the more extreme provisions of the criminal law: two years' servitude and branding with a ""V"" as the penalty for the first offense and death for the second.[127] During the reign of Henry VIII, as many as 72,000 people are estimated to have been executed.[128] In the 1576 Act, each town was required to provide work for the unemployed.[129]
",4
5106,"The Elizabethan Poor Law of 1601, one of the world's first government-sponsored welfare programs, made a clear distinction between those who were unable to work and those able-bodied people who refused employment.[130] Under the Poor Law systems of England and Wales, Scotland and Ireland, a workhouse was a place For people unable to support themselves could go to live and work.[131]
",4
5107,"Poverty was a highly visible problem in the eighteenth century, both in cities and in the countryside. In France and Britain by the end of the century, an estimated 10 percent of the people depended on charity or begging for their food.",4
5108," By 1776, some 1,912 parish and corporation workhouses had been established in England and Wales and housed almost 100,000 paupers.
",4
5109,"A description of the miserable living standards of the mill workers in England in 1844 was given by Fredrick Engels in The Condition of the Working-Class in England in 1844.[132] In the preface to the 1892 edition, Engels noted that the extreme poverty he had written about in 1844 had largely disappeared. David Ames Wells also noted that living conditions in England had improved near the end of the 19th century and that unemployment was low.
",4
5110,"The scarcity and the high price of labor in the US in the 19th century was well documented by contemporary accounts, as in the following:
",4
5111,"""The laboring classes are comparatively few in number, but this is counterbalanced by, and indeed, may be one of the causes of the eagerness by which they call in the use of machinery in almost every department of industry. Wherever it can be applied as a substitute for manual labor, it is universally and willingly resorted to.... It is this condition of the labor market, and this eager resort to machinery wherever it can be applied, to which, under the guidance of superior education and intelligence, the remarkable prosperity of the United States is due.""[133] Joseph Whitworth, 1854",4
5112,"Scarcity of labor was a factor in the economics of slavery in the United States.
",4
5113,"As new territories were opened and federal land sales were conducted, land had to be cleared and new homesteads established. Hundreds of thousands of immigrants annually came to the US and found jobs digging canals and building railroads. Almost all work during most of the 19th century was done by hand or with horses, mules, or oxen since there was very little mechanization. The workweek during most of the 19th century was 60 hours. Unemployment at times was between one and two percent.
",4
5114,"The tight labor market was a factor in productivity gains by allowing workers to maintain or to increase their nominal wages during the secular deflation that caused real wages to rise at various times in the 19th century, especially in its final decades.[134]
",4
5115,"There were labor shortages during World War I.[21] Ford Motor Co. doubled wages to reduce turnover. After 1925, unemployment gradually began to rise.[135]
",4
5116,"The 1930s saw the Great Depression impact unemployment across the globe. In Germany and the United States, the unemployment rate reached about 25% in 1932.[136]
",4
5117,"In some towns and cities in the northeast of England, unemployment reached as high as 70%; the national unemployment level peaked at more than 22% in 1932.[137] Unemployment in Canada reached 27% at the depth of the Depression in 1933.[138] In 1929, the U.S. unemployment rate averaged 3%.[139]
",4
5118,"In the US, the Works Progress Administration (1935–43) was the largest make-work program. It hired men (and some women) off the relief roles (""dole"") typically for unskilled labor.[140]
During the New Deal, over three million unemployed young men were taken out of their homes and placed for six months into more than 2600 work camps managed by the Civilian Conservation Corps.[141]
",4
5119,"Unemployment in the United Kingdom fell later in the 1930s as the Depression eased, and it remained low (in six figures) after World War II.
",4
5120,"Fredrick Mills found that in the US, 51% of the decline in work hours was due to the fall in production and 49% was from increased productivity.[142]
",4
5121,"By 1972, unemployment in the United Kingdom had crept back up above 1,000,000, and it was even higher by the end of the decade, with inflation also being high. Although the monetarist economic policies of Margaret Thatcher's Conservative government saw inflation reduced after 1979, unemployment soared in the early 1980s and in 1982, it exceeded 3,000,000, a level that had not been seen for some 50 years. That represented one in eight of the workforce, with unemployment exceeding 20% in some places that had relied on declining industries such as coal mining.[143]
",4
5122,"However, it was a time of high unemployment in all other major industrialised nations as well.[144] By the spring of 1983, unemployment had risen by 6% in the previous 12 months, compared to 10% in Japan, 23% in the US, and 34% in West Germany (seven years before Reunification).[145]
",4
5123,"Unemployment in the United Kingdom remained above 3,000,000 until the spring of 1987, when the economy enjoyed a boom.[143] By the end of 1989, unemployment had fallen to 1,600,000. However, inflation had reached 7.8%, and the following year, it reached a nine-year high of 9.5%; leading to increased interest rates.[146]
",4
5124,"Another recession occurred from 1990 to 1992. Unemployment began to increase, and by the end of 1992, nearly 3,000,000 in the United Kingdom were unemployed, a number that was soon lowered by a strong economic recovery.[143] With inflation down to 1.6% by 1993, unemployment then began to fall rapidly and stood at 1,800,000 by early 1997.[147]
",4
5125,"The official unemployment rate in the 16 European Union (EU) countries that use the euro rose to 10% in December 2009 as a result of another recession.[148] Latvia had the highest unemployment rate in the EU, at 22.3% for November 2009.[149] Europe's young workers have been especially hard hit.[150] In November 2009, the unemployment rate in the EU27 for those aged 15–24 was 18.3%. For those under 25, the unemployment rate in Spain was 43.8%.[151] Unemployment has risen in two thirds of European countries since 2010.[152]
",4
5126,"Into the 21st century, unemployment in the United Kingdom remained low and the economy remaining strong, and several other European economies, such as France and Germany, experienced a minor recession and a substantial rise in unemployment.[153]
",4
5127,"In 2008, when the recession brought on another increase in the United Kingdom, after 15 years of economic growth and no major rises in unemployment.[154] In early 2009, unemployment passed the 2 million mark, and economists were predicting it would soon reach 3 million.[155] However, the end of the recession was declared in January 2010[156] and unemployment peaked at nearly 2.7 million in 2011,[157] appearing to ease fears of unemployment reaching 3 million.[158] The unemployment rate of Britain's young black people was 47.4% in 2011.[159] 2013/2014 has seen the employment rate increase from 1,935,836 to 2,173,012 as supported by[160] showing the UK is creating more job opportunities and forecasts the rate of increase in 2014/2015 will be another 7.2%.[161]
",4
5128,"The 2008–2012 global recession has been called a ""mancession"" because of the disproportionate number of men who lost their jobs as compared to women. The gender gap became wide in the United States in 2009, when 10.5% of men in the labor force were unemployed, compared with 8% of women.[162][163] Three quarters of the jobs that were lost in the recession in the US were held by men.[164][165]
",4
5129,"A 26 April 2005 Asia Times article noted, ""In regional giant South Africa, some 300,000 textile workers have lost their jobs in the past two years due to the influx of Chinese goods"".[166] The increasing US trade deficit with China cost 2.4 million American jobs between 2001–2008, according to a study by the Economic Policy Institute (EPI).[167] From 2000–2007, the United States lost a total of 3.2 million manufacturing jobs.[168] 12.1% of US military veterans who had served after the September 11 attacks in 2001 were unemployed as of 2011; 29.1% of male veterans aged 18–24 were unemployed.[83] As of September 2016, the total veteran unemployment rate was 4.3 percent. By September 2017, that figure had dropped to 3 percent.[169]
",4
5130,"About 25,000,000 people in the world's 30 richest countries lost their jobs between the end of 2007 and the end of 2010, as the economic downturn pushed most countries into recession.[170] In April 2010, the US unemployment rate was 9.9%, but the government's broader U-6 unemployment rate was 17.1%.[171] In April 2012, the unemployment rate was 4.6% in Japan.[172] In a 2012 story, the Financial Post reported, ""Nearly 75 million youth are unemployed around the world, an increase of more than 4 million since 2007. In the European Union, where a debt crisis followed the financial crisis, the youth unemployment rate rose to 18% last year from 12.5% in 2007, the ILO report shows.""[173] In March 2018, according to US Unemployment Rate Statistics, the unemployment rate was 4.1%, below the 4.5–5.0% norm.[174]
",4
5131," Quotations related to unemployment at Wikiquote
 The dictionary definition of unemployment at Wiktionary
",4
5132,"
",4
5133,"
",4
5134,"The balance of trade, commercial balance, or net exports (sometimes symbolized as NX), is the difference between the monetary value of a nation's exports and imports over a certain time period.[1] Sometimes a distinction is made between a balance of trade for goods versus one for services. The balance of trade measures a flow of exports and imports over a given period of time. The notion of the balance of trade does not mean that exports and imports are ""in balance"" with each other.
",4
5135,"If a country exports a greater value than it imports, it has a trade surplus or positive trade balance, and conversely, if a country imports a greater value than it exports, it has a trade deficit or negative trade balance. As of 2016, about 60 out of 200 countries have a trade surplus. The notion that bilateral trade deficits are bad in and of themselves is overwhelmingly rejected by trade experts and economists.[2][3][4][5][6]
",4
5136,"The balance of trade forms part of the current account, which includes other transactions such as income from the net international investment position as well as international aid. If the current account is in surplus, the country's net international asset position increases correspondingly. Equally, a deficit decreases the net international asset position.
",4
5137,"The trade balance is identical to the difference between a country's output and its domestic demand (the difference between what goods a country produces and how many goods it buys from abroad; this does not include money re-spent on foreign stock, nor does it factor in the concept of importing goods to produce for the domestic market).
",4
5138,"Measuring the balance of trade can be problematic because of problems with recording and collecting data. As an illustration of this problem, when official data for all the world's countries are added up, exports exceed imports by almost 1%; it appears the world is running a positive balance of trade with itself. This cannot be true, because all transactions involve an equal credit or debit in the account of each nation. The discrepancy is widely believed to be explained by transactions intended to launder money or evade taxes, smuggling and other visibility problems. While the accuracy of developing countries statistics would be suspicious, most of the discrepancy actually occurs between developed countries of trusted statistics,[7][8][9]
",4
5139,"Factors that can affect the balance of trade include:
",4
5140,"In addition, the trade balance is likely to differ across the business cycle. In export-led growth (such as oil and early industrial goods), the balance of trade will shift towards exports during an economic expansion.[citation needed] However, with domestic demand-led growth (as in the United States and Australia) the trade balance will shift towards imports at the same stage in the business cycle.
",4
5141,"The monetary balance of trade is different from the physical balance of trade[10] (which is expressed in amount of raw materials, known also as Total Material Consumption). Developed countries usually import a substantial amount of raw materials from developing countries. Typically, these imported materials are transformed into finished products and might be exported after adding value. Financial trade balance statistics conceal material flow. Most developed countries have a large physical trade deficit because they consume more raw materials than they produce. Many[who?] civil society organisations claim this imbalance is predatory and campaign for ecological debt repayment.
",4
5142,"Many countries in early modern Europe adopted a policy of mercantilism, which theorized that a trade surplus was beneficial to a country. Mercantilist ideas also influenced how European nations regulated trade policies with their colonies, promoting the idea that natural resources and cash crops should be exported to Europe, with processed goods being exported back to the colonies in return. Ideas such as bullionism spurred the popularity of mercantilism in European governments.[11]
",4
5143,"An early statement concerning the balance of trade appeared in Discourse of the Common Wealth of this Realm of England, 1549: ""We must always take heed that we buy no more from strangers than we sell them, for so should we impoverish ourselves and enrich them.""[12] Similarly, a systematic and coherent explanation of balance of trade was made public through Thomas Mun's 1630 ""England's treasure by foreign trade, or, The balance of our foreign trade is the rule of our treasure"".[13]
",4
5144,"Since the mid-1980s, the United States has had a growing deficit in tradeable goods, especially with Asian nations (China and Japan) which now hold large sums of U.S debt that has in part funded the consumption.[14][15][16] The U.S. has a trade surplus with nations such as Australia. The issue of trade deficits can be complex. Trade deficits generated in tradeable goods such as manufactured goods or software may impact domestic employment to different degrees than do trade deficits in raw materials.[15]
",4
5145,"Economies that have savings surpluses, such as Japan and Germany, typically run trade surpluses. China, a high-growth economy, has tended to run trade surpluses. A higher savings rate generally corresponds to a trade surplus. Correspondingly, the U.S. with its lower savings rate has tended to run high trade deficits, especially with Asian nations.[15]
",4
5146,"Some have said that China pursues a mercantilist economic policy.[17][18][19] Russia pursues a policy based on protectionism, according to which international trade is not a ""win-win"" game but a zero-sum game: surplus countries get richer at the expense of deficit countries.[20][21][22][23][24][25]
",4
5147,"In March 2019, Armenia recorded a trade deficit of US$203.9 million. For the last two decades, the Armenian trade balance has been negative, reaching an all-time high of –33.98 USD million in August 2003. The reason for the trade deficit is that Armenia's foreign trade is limited by its landlocked location and border disputes with Turkey and Azerbaijan, to the west and east respectively. The situation results in the country's typically reporting large trade deficits.[28]
",4
5148,"The notion that bilateral trade deficits are bad in and of themselves is overwhelmingly rejected by trade experts and economists.[2][3][4][5][6] According to the IMF trade deficits can cause a balance of payments problem, which can affect foreign exchange shortages and hurt countries.[29] On the other hand, Joseph Stiglitz points out that countries running surpluses exert a ""negative externality"" on trading partners, and pose a threat to global prosperity, far more than those in deficit.[30][31][32] Ben Bernanke argues that ""persistent imbalances within the euro zone are... unhealthy, as they lead to financial imbalances as well as to unbalanced growth. The fact that Germany is selling so much more than it is buying redirects demand from its neighbors (as well as from other countries around the world), reducing output and employment outside Germany.""[33]
",4
5149,"A 2018 National Bureau of Economic Research paper by economists at the International Monetary Fund and University of California, Berkeley, found in a study of 151 countries over 1963-2014 that the imposition of tariffs had little effect on the trade balance.[34]
",4
5150,"In the foregoing part of this chapter I have endeavoured to show, even upon the principles of the commercial system, how unnecessary it is to lay extraordinary restraints upon the importation of goods from those countries with which the balance of trade is supposed to be disadvantageous.
Nothing, however, can be more absurd than this whole doctrine of the balance of trade, upon which, not only these restraints, but almost all the other regulations of commerce are founded. When two places trade with one another, this [absurd] doctrine supposes that, if the balance be even, neither of them either loses or gains; but if it leans in any degree to one side, that one of them loses and the other gains in proportion to its declension from the exact equilibrium.",4
5151,"In the last few years of his life, John Maynard Keynes was much preoccupied with the question of balance in international trade. He was the leader of the British delegation to the United Nations Monetary and Financial Conference in 1944 that established the Bretton Woods system of international currency management.
He was the principal author of a proposal – the so-called Keynes Plan – for an International Clearing Union. The two governing principles of the plan were that the problem of settling outstanding balances should be solved by 'creating' additional 'international money', and that debtor and creditor should be treated almost alike as disturbers of equilibrium. In the event, though, the plans were rejected, in part because ""American opinion was naturally reluctant to accept the principle of equality of treatment so novel in debtor-creditor relationships"".[36]
",4
5152,"The new system is not founded on free-trade (liberalisation[37] of foreign trade[38]) but rather on the regulation of international trade, in order to eliminate trade imbalances: the nations with a surplus would have a powerful incentive to get rid of it, and in doing so they would automatically clear other nations deficits.[39] He proposed a global bank that would issue its own currency – the bancor – which was exchangeable with national currencies at fixed rates of exchange and would become the unit of account between nations, which means it would be used to measure a country's trade deficit or trade surplus. Every country would have an overdraft facility in its bancor account at the International Clearing Union. He pointed out that surpluses lead to weak global aggregate demand – countries running surpluses exert a ""negative externality"" on trading partners, and posed far more than those in deficit, a threat to global prosperity.[40]
In ""National Self-Sufficiency"" The Yale Review, Vol. 22, no. 4 (June 1933),[41][42] he already highlighted the problems created by free trade.
",4
5153,"His view, supported by many economists and commentators at the time, was that creditor nations may be just as responsible as debtor nations for disequilibrium in exchanges and that both should be under an obligation to bring trade back into a state of balance. Failure for them to do so could have serious consequences. In the words of Geoffrey Crowther, then editor of The Economist, ""If the economic relationships between nations are not, by one means or another, brought fairly close to balance, then there is no set of financial arrangements that can rescue the world from the impoverishing results of chaos.""[43]
",4
5154,"These ideas were informed by events prior to the Great Depression when – in the opinion of Keynes and others – international lending, primarily by the U.S., exceeded the capacity of sound investment and so got diverted into non-productive and speculative uses, which in turn invited default and a sudden stop to the process of lending.[44]
",4
5155,"Influenced by Keynes, economics texts in the immediate post-war period put a significant emphasis on balance in trade. For example, the second edition of the popular introductory textbook, An Outline of Money,[45] devoted the last three of its ten chapters to questions of foreign exchange management and in particular the 'problem of balance'. However, in more recent years, since the end of the Bretton Woods system in 1971, with the increasing influence of monetarist schools of thought in the 1980s, and particularly in the face of large sustained trade imbalances, these concerns – and particularly concerns about the destabilising effects of large trade surpluses – have largely disappeared from mainstream economics discourse[46] and Keynes' insights have slipped from view.[47] They are receiving some attention again in the wake of the financial crisis of 2007–08.[48]
",4
5156,"Prior to 20th-century monetarist theory, the 19th-century economist and philosopher Frédéric Bastiat expressed the idea that trade deficits actually were a manifestation of profit, rather than a loss. He proposed as an example to suppose that he, a Frenchman, exported French wine and imported British coal, turning a profit. He supposed he was in France and sent a cask of wine which was worth 50 francs to England. The customhouse would record an export of 50 francs. If in England, the wine sold for 70 francs (or the pound equivalent), which he then used to buy coal, which he imported into France, and was found to be worth 90 francs in France, he would have made a profit of 40 francs. But the customhouse would say that the value of imports exceeded that of exports and was trade deficit against the ledger of France.
",4
5157,"By reductio ad absurdum, Bastiat argued that the national trade deficit was an indicator of a successful economy, rather than a failing one. Bastiat predicted that a successful, growing economy would result in greater trade deficits, and an unsuccessful, shrinking economy would result in lower trade deficits. This was later, in the 20th century, echoed by economist Milton Friedman.
",4
5158,"In the 1980s, Milton Friedman, a Nobel Memorial Prize-winning economist and a proponent of monetarism, contended that some of the concerns of trade deficits are unfair criticisms in an attempt to push macroeconomic policies favorable to exporting industries.
",4
5159,"Friedman argued that trade deficits are not necessarily important, as high exports raise the value of the currency, reducing aforementioned exports, and vice versa for imports, thus naturally removing trade deficits not due to investment. Since 1971, when the Nixon administration decided to abolish fixed exchange rates, America's Current Account accumulated trade deficits have totaled $7.75 trillion as of 2010. This deficit exists as it is matched by investment coming into the United States – purely by the definition of the balance of payments, any current account deficit that exists is matched by an inflow of foreign investment.
",4
5160,"In the late 1970s and early 1980s, the U.S. had experienced high inflation and Friedman's policy positions tended to defend the stronger dollar at that time. He stated his belief that these trade deficits were not necessarily harmful to the economy at the time since the currency comes back to the country (country A sells to country B, country B sells to country C who buys from country A, but the trade deficit only includes A and B). However, it may be in one form or another including the possible tradeoff of foreign control of assets. In his view, the ""worst-case scenario"" of the currency never returning to the country of origin was actually the best possible outcome: the country actually purchased its goods by exchanging them for pieces of cheaply made paper. As Friedman put it, this would be the same result as if the exporting country burned the dollars it earned, never returning it to market circulation.[49]
",4
5161,"This position is a more refined version of the theorem first discovered by David Hume.[50] Hume argued that England could not permanently gain from exports, because hoarding gold (i.e., currency) would make gold more plentiful in England; therefore, the prices of English goods would rise, making them less attractive exports and making foreign goods more attractive imports. In this way, countries' trade balances would balance out.
",4
5162,"Friedman presented his analysis of the balance of trade in Free to Choose, widely considered his most significant popular work.
",4
5163,"Exports directly increase and imports directly reduce a nation's balance of trade (i.e. net exports). A trade surplus is a positive net balance of trade, and a trade deficit is a negative net balance of trade. Due to the balance of trade being explicitly added to the calculation of the nation's gross domestic product using the expenditure method of calculating gross domestic product (i.e. GDP), trade surpluses are contributions and trade deficits are ""drags"" upon their nation's GDP; however, foreign made goods sold (e.g., retail) contribute to total GDP.[51][52][53]
",4
5164,"The Marshall Plan (officially the European Recovery Program, ERP) was an American initiative passed in 1948 for foreign aid to Western Europe. The United States transferred over $12 billion (equivalent to $130 billion in 2019) in economic recovery programs to Western European economies after the end of World War II. Replacing an earlier proposal for a Morgenthau Plan, it operated for four years beginning on April 3, 1948.[1] The goals of the United States were to rebuild war-torn regions, remove trade barriers, modernize industry, improve European prosperity, and prevent the spread of communism.[2] The Marshall Plan required a reduction of interstate barriers, a dropping of many regulations, and encouraged an increase in productivity, as well as the adoption of modern business procedures.[3]
",4
5165,"The Marshall Plan aid was divided among the participant states roughly on a per capita basis. A larger amount was given to the major industrial powers, as the prevailing opinion was that their resuscitation was essential for the general European revival. Somewhat more aid per capita was also directed toward the Allied nations, with less for those that had been part of the Axis or remained neutral. The largest recipient of Marshall Plan money was the United Kingdom (receiving about 26% of the total), but the enormous cost that Britain incurred through the ""Lend-Lease"" scheme was not fully re-paid to the USA until 2006.[4] The next highest contributions went to France (18%) and West Germany (11%). Some eighteen European countries received Plan benefits.[5] Although offered participation, the Soviet Union refused Plan benefits, and also blocked benefits to Eastern Bloc countries, such as Hungary and Poland.[6] The United States provided similar aid programs in Asia, but they were not part of the Marshall Plan.[7]
",4
5166,"Its role in the rapid recovery has been debated. The Marshall Plan's accounting reflects that aid accounted for about 3% of the combined national income of the recipient countries between 1948 and 1951,[8] which means an increase in GDP growth of less than half a percent.[9]
",4
5167,"After World War II, in 1947, industrialist Lewis H. Brown wrote (at the request of General Lucius D. Clay) A Report on Germany, which served as a detailed recommendation for the reconstruction of post-war Germany, and served as a basis for the Marshall Plan. The initiative was named after United States Secretary of State George Marshall. The plan had bipartisan support in Washington, where the Republicans controlled Congress and the Democrats controlled the White House with Harry S. Truman as President. The Plan was largely the creation of State Department officials, especially William L. Clayton and George F. Kennan, with help from the Brookings Institution, as requested by Senator Arthur Vandenberg, chairman of the United States Senate Committee on Foreign Relations.[10] Marshall spoke of an urgent need to help the European recovery in his address at Harvard University in June 1947.[2] The purpose of the Marshall Plan was to aid in the economic recovery of nations after World War II and to reduce the influence of Communist parties within them. To combat the effects of the Marshall Plan, the USSR developed its own economic plan, known as the Molotov Plan, in spite of the fact that large amounts of resources from the Eastern Bloc countries to the USSR were paid as reparations, for countries participating in the Axis Power during the war.
",4
5168,"The phrase ""equivalent of the Marshall Plan"" is often used to describe a proposed large-scale economic rescue program.[11]
",4
5169,"In 1951 the Marshall Plan was largely replaced by the Mutual Security Act.
",4
5170,"The reconstruction plan, developed at a meeting of the participating European states, was drafted on June 5, 1947. It offered the same aid to the Soviet Union and its allies, but they refused to accept it,[12][13] as doing so would allow a degree of US control over the communist economies.[14] In fact, the Soviet Union prevented its satellite states (i.e., East Germany, Poland, etc.) from accepting. Secretary Marshall became convinced Stalin had no interest in helping restore economic health in Western Europe.[15]
",4
5171,"President Harry Truman signed the Marshall Plan on April 3, 1948, granting $5 billion in aid to 16 European nations. During the four years the plan was in effect, the United States donated $17 billion (equivalent to $202.18 billion in 2019) in economic and technical assistance to help the recovery of the European countries that joined the Organisation for European Economic Co-operation. The $17 billion was in the context of a US GDP of $258 billion in 1948, and on top of $17 billion in American aid to Europe between the end of the war and the start of the Plan that is counted separately from the Marshall Plan.[16] The Marshall Plan was replaced by the Mutual Security Plan at the end of 1951; that new plan gave away about $7.5 billion annually until 1961 when it was replaced by another program.[17]
",4
5172,"The ERP addressed each of the obstacles to postwar recovery. The plan looked to the future and did not focus on the destruction caused by the war. Much more important were efforts to modernize European industrial and business practices using high-efficiency American models, reducing artificial trade barriers, and instilling a sense of hope and self-reliance.[18][19]
",4
5173,"By 1952, as the funding ended, the economy of every participant state had surpassed pre-war levels; for all Marshall Plan recipients, output in 1951 was at least 35% higher than in 1938.[20] Over the next two decades, Western Europe enjoyed unprecedented growth and prosperity, but economists are not sure what proportion was due directly to the ERP, what proportion indirectly, and how much would have happened without it.
A common American interpretation of the program's role in European recovery was expressed by Paul Hoffman, head of the Economic Cooperation Administration, in 1949, when he told Congress Marshall aid had provided the ""critical margin"" on which other investment needed for European recovery depended.[21] The Marshall Plan was one of the first elements of European integration, as it erased trade barriers and set up institutions to coordinate the economy on a continental level—that is, it stimulated the total political reconstruction of Western Europe.[22]
",4
5174,"Belgian economic historian Herman Van der Wee concludes the Marshall Plan was a ""great success"":
",4
5175,"It gave a new impetus to reconstruction in Western Europe and made a decisive contribution to the renewal of the transport system, the modernization of industrial and agricultural equipment, the resumption of normal production, the raising of productivity, and the facilitating of intra-European trade.[23]",4
5176,"By the end of World War II, much of Europe was devastated. Sustained aerial bombardment during the war had badly damaged most major cities, and industrial facilities were especially hard-hit. Millions of refugees were in temporary camps.[24] The region's trade flows had been thoroughly disrupted; millions were in refugee camps living on aid from the United States, which was provided by the United Nations Relief and Rehabilitation Administration and other agencies. Food shortages were severe, especially in the harsh winter of 1946–47. From July 1945 through June 1946, the United States shipped 16.5 million tons of food, primarily wheat, to Europe and Japan. It amounted to one-sixth of the American food supply and provided 35 trillion calories, enough to provide 400 calories a day for one year to 300 million people.[25]
",4
5177,"Especially damaged was transportation infrastructure, as railways, bridges, and docks had been specifically targeted by airstrikes, while much merchant shipping had been sunk. Although most small towns and villages had not suffered as much damage, the destruction of transportation left them economically isolated. None of these problems could be easily remedied, as most nations engaged in the war had exhausted their treasuries in the process.[26]
",4
5178,"The only major powers whose infrastructure had not been significantly harmed in World War II were the United States and Canada.[citation needed] They were much more prosperous than before the war but exports were a small factor in their economy. Much of the Marshall Plan aid would be used by the Europeans to buy manufactured goods and raw materials from the United States and Canada.
",4
5179,"Most of Europe's economies were recovering slowly, as unemployment and food shortages led to strikes and unrest in several nations. Agricultural production was 83% of 1938 levels, industrial production was 88%, and exports 59%.[27] Exceptions were the United Kingdom, the Netherlands and France, where by the end of 1947 production had already been restored to pre-war levels before the Marshall Plan. Italy and Belgium would follow by the end of 1948.[28][29]
",4
5180,"In Germany in 1945–46 housing and food conditions were bad, as the disruption of transport, markets, and finances slowed a return to normality. In the West, the bombing had destroyed 5,000,000 houses and apartments, and 12,000,000 refugees from the east had crowded in.[30] Food production was two-thirds of the pre-war level in 1946–48, while normal grain and meat shipments no longer arrived from the East. The drop in food production can be attributed to a drought that killed a major portion of the wheat crop while a severe winter destroyed the majority of the wheat crop the following year. This caused most Europeans to rely on a 1,500 calorie per day diet.[31] Furthermore, the large shipments of food stolen from occupied nations during the war no longer reached Germany. Industrial production fell more than half and reached pre-war levels at the end of 1949.[32]
",4
5181,"While Germany struggled to recover from the destruction of the War, the recovery effort began in June 1948, moving on from emergency relief. The currency reform in 1948 was headed by the military government and helped Germany to restore stability by encouraging production. The reform revalued old currency and deposits and introduced new currency. Taxes were also reduced and Germany prepared to remove economic barriers.[33]
",4
5182,"During the first three years of occupation of Germany, the UK and US vigorously pursued a military disarmament program in Germany, partly by removal of equipment but mainly through an import embargo on raw materials, part of the Morgenthau Plan approved by President Franklin D. Roosevelt.[34]
",4
5183,"Nicholas Balabkins concludes that ""as long as German industrial capacity was kept idle the economic recovery of Europe was delayed.""[35] By July 1947 Washington realized that economic recovery in Europe could not go forward without the reconstruction of the German industrial base, deciding that an ""orderly, prosperous Europe requires the economic contributions of a stable and productive Germany.""[36] In addition, the strength of Moscow-controlled communist parties in France and Italy worried Washington.[37]
",4
5184,"In the view of the State Department under President Harry S Truman, the United States needed to adopt a definite position on the world scene or fear losing credibility. The emerging doctrine of containment (as opposed to rollback) argued that the United States needed to substantially aid non-communist countries to stop the spread of Soviet influence. There was also some hope that the Eastern Bloc nations would join the plan, and thus be pulled out of the emerging Soviet bloc, but that did not happen.
",4
5185,"In January 1947, Truman appointed retired General George Marshall as Secretary of State. In July 1947 Marshall scrapped Joint Chiefs of Staff Directive 1067, which was based on the Morgenthau Plan which had decreed ""take no steps looking toward the economic rehabilitation of Germany [or] designed to maintain or strengthen the German economy."" The new plan JCS 1779 stated that ""an orderly and prosperous Europe requires the economic contributions of a stable and productive Germany.""[38] The restrictions placed on German heavy industry production were partly ameliorated; permitted steel production levels were raised from 25% of pre-war capacity to a new limit placed at 50% of pre-war capacity.[39]
",4
5186,"With a communist, although non-Soviet, insurgency threatening Greece, and Britain financially unable to continue its aid, the President announced his Truman Doctrine on March 12, 1947, ""to support free peoples who are resisting attempted subjugation by armed minorities or by outside pressures"", with an aid request for consideration and decision, concerning Greece and Turkey. Herbert Hoover noted that ""The whole economy of Europe is interlinked with German economy through the exchange of raw materials and manufactured goods. The productivity of Europe cannot be restored without the restoration of Germany as a contributor to that productivity.""[40] Hoover's report led to a realization in Washington that a new policy was needed; ""almost any action would be an improvement on current policy.""[41] In Washington, the Joint Chiefs declared that the ""complete revival of German industry, particularly coal mining"" was now of ""primary importance"" to American security.[38]
",4
5187,"The United States was already spending a great deal to help Europe recover. Over $14 billion was spent or loaned during the postwar period through the end of 1947 and is not counted as part of the Marshall Plan. Much of this aid was designed to restore infrastructure and help refugees. Britain, for example, received an emergency loan of $3.75 billion.[42]
",4
5188,"The United Nations also launched a series of humanitarian and relief efforts almost wholly funded by the United States. These efforts had important effects, but they lacked any central organization and planning, and failed to meet many of Europe's more fundamental needs.[43] Already in 1943, the United Nations Relief and Rehabilitation Administration (UNRRA) was founded to provide relief to areas liberated from Germany. UNRRA provided billions of dollars of rehabilitation aid and helped about 8 million refugees. It ceased operation of displaced persons camps in Europe in 1947; many of its functions were transferred to several UN agencies.
",4
5189,"After Marshall's appointment in January 1947, administration officials met with Soviet Foreign Minister Vyacheslav Molotov and others to press for an economically self-sufficient Germany, including a detailed accounting of the industrial plants, goods and infrastructure already removed by the Soviets in their occupied zone.[44] Molotov refrained from supplying accounts of Soviet assets.[45] The Soviets took a punitive approach, pressing for a delay rather than an acceleration in economic rehabilitation, demanding unconditional fulfillment of all prior reparation claims, and pressing for progress toward nationwide socioeconomic transformation.[46]
",4
5190,"After six weeks of negotiations, Molotov rejected all of the American and British proposals.[46] Molotov also rejected the counter-offer to scrap the British-American ""Bizonia"" and to include the Soviet zone within the newly constructed Germany.[46] Marshall was particularly discouraged after personally meeting with Stalin to explain that the United States could not possibly abandon its position on Germany, while Stalin expressed little interest in a solution to German economic problems.[46]
",4
5191,"After the adjournment of the Moscow conference following six weeks of failed discussions with the Soviets regarding a potential German reconstruction, the United States concluded that a solution could not wait any longer. To clarify the American position, a major address by Secretary of State George Marshall was planned. Marshall gave the address at Harvard University on June 5, 1947. He offered American aid to promote European recovery and reconstruction. The speech described the dysfunction of the European economy and presented a rationale for US aid.
",4
5192,"The modern system of the division of labor upon which the exchange of products is based is in danger of breaking down. ... Aside from the demoralizing effect on the world at large and the possibilities of disturbances arising as a result of the desperation of the people concerned, the consequences to the economy of the United States should be apparent to all. It is logical that the United States should do whatever it is able to do to assist in the return of normal economic health to the world, without which there can be no political stability and no assured peace. Our policy is not directed against any country, but against hunger, poverty, desperation and chaos. Any government that is willing to assist in recovery will find full co-operation on the part of the United States. Its purpose should be the revival of a working economy in the world so as to permit the emergence of political and social conditions in which free institutions can exist.[47]",4
5193,"Marshall was convinced that economic stability would provide political stability in Europe. He offered aid, but the European countries had to organize the program themselves.
",4
5194,"The speech, written at Marshall's request and guidance by Charles Bohlen,[48] contained virtually no details and no numbers. More a proposal than a plan, it was a challenge to European leaders to cooperate and coordinate. It asked Europeans to create their own plan for rebuilding Europe, indicating the United States would then fund this plan. The administration felt that the plan would likely be unpopular among many Americans, and the speech was mainly directed at a European audience. In an attempt to keep the speech out of American papers, journalists were not contacted, and on the same day, Truman called a press conference to take away headlines. In contrast, Dean Acheson, an Under Secretary of State, was dispatched to contact the European media, especially the British media, and the speech was read in its entirety on the BBC.[49][50]
",4
5195,"British Foreign Secretary Ernest Bevin heard Marshall's radio broadcast speech and immediately contacted French Foreign Minister Georges Bidault to begin preparing a quick European response to (and acceptance of) the offer, which led to the creation of the Committee of European Economic Co-operation. The two agreed that it would be necessary to invite the Soviets as the other major allied power. Marshall's speech had explicitly included an invitation to the Soviets, feeling that excluding them would have been a sign of distrust. State Department officials, however, knew that Stalin would almost certainly not participate and that any plan that would send large amounts of aid to the Soviets was unlikely to get Congressional approval.
",4
5196,"Speaking at the Paris Peace Conference on October 10, 1946 Molotov had already stated Soviet fears: ""If American capital was given a free hand in the small states ruined and enfeebled by the war [it] would buy up the local industries, appropriate the more attractive Romanian, Yugoslav ... enterprises and would become the master in these small states.""[51] While the Soviet ambassador in Washington suspected that the Marshall Plan could lead to the creation of an anti-Soviet bloc, Stalin was open to the offer.[52] He directed that—in negotiations to be held in Paris regarding the aid—countries in the Eastern Bloc should not reject economic conditions being placed upon them.[52] Stalin only changed his outlook when he learned that (a) credit would only be extended under conditions of economic cooperation and, (b) aid would also be extended to Germany in total, an eventuality which Stalin thought would hamper the Soviets' ability to exercise influence in western Germany.[52]
",4
5197,"Initially, Stalin maneuvered to kill the Plan, or at least hamper it by means of destructive participation in the Paris talks regarding conditions.[52] He quickly realized, however, that this would be impossible after Molotov reported—following his arrival in Paris in July 1947—that conditions for the credit were non-negotiable.[52] Looming as just as large a concern was the Czechoslovak eagerness to accept the aid, as well as indications of a similar Polish attitude.[52]
",4
5198,"Soviet Foreign Minister Vyacheslav Molotov left Paris, rejecting the plan.[53] Thereafter, statements were made suggesting a future confrontation with the West, calling the United States both a ""fascizing"" power and the ""center of worldwide reaction and anti-Soviet activity"", with all U.S.-aligned countries branded as enemies.[53] The Soviets also then blamed the United States for communist losses in elections in Belgium, France and Italy months earlier, in the spring of 1947.[53] It claimed that ""marshallization"" must be resisted and prevented by any means, and that French and Italian communist parties were to take maximum efforts to sabotage the implementation of the Plan.[53] In addition, Western embassies in Moscow were isolated, with their personnel being denied contact with Soviet officials.[53]
",4
5199,"On July 12, a larger meeting was convened in Paris. Every country of Europe was invited, with the exceptions of Spain (a World War II neutral that had sympathized with the Axis powers) and the small states of Andorra, San Marino, Monaco, and Liechtenstein. The Soviet Union was invited with the understanding that it would likely refuse. The states of the future Eastern Bloc were also approached, and Czechoslovakia and Poland agreed to attend. In one of the clearest signs and reflections of tight Soviet control and domination over the region, Jan Masaryk, the foreign minister of Czechoslovakia, was summoned to Moscow and berated by Stalin for considering Czechoslovakia's possible involvement with and joining of the Marshall Plan. The prime minister of Poland, Józef Cyrankiewicz, was rewarded by Stalin for his country's rejection of the Plan, which came in the form of the Soviet Union's offer of a lucrative trade agreement lasting for a period of five years, a grant amounting to the approximate equivalent of $450 million (in 1948; the sum would have been $4.4 billion in 2014[54]) in the form of long-term credit and loans and the provision of 200,000 tonnes of grain, heavy and manufacturing machinery and factories and heavy industries to Poland.[55]
",4
5200,"The Marshall Plan participants were not surprised when the Czechoslovakian and Polish delegations were prevented from attending the Paris meeting. The other Eastern Bloc states immediately rejected the offer.[56] Finland also declined, to avoid antagonizing the Soviets (see also Finlandization). The Soviet Union's ""alternative"" to the Marshall plan, which was purported to involve Soviet subsidies and trade with western Europe, became known as the Molotov Plan, and later, the Comecon. In a 1947 speech to the United Nations, Soviet deputy foreign minister Andrei Vyshinsky said that the Marshall Plan violated the principles of the United Nations. He accused the United States of attempting to impose its will on other independent states, while at the same time using economic resources distributed as relief to needy nations as an instrument of political pressure.[57]
",4
5201,"Although all other Communist European Countries had deferred to Stalin and rejected the aid, the Yugoslavs, led by Josip Broz (Tito), at first went along and rejected the Marshall Plan. However, in 1948 Tito broke decisively with Stalin on other issues, making Yugoslavia an independent communist state. Yugoslavia requested American aid. American leaders were internally divided, but finally agreed and began sending money on a small scale in 1949, and on a much larger scale in 1950–53. The American aid was not part of the Marshall Plan.[58]
",4
5202,"In late September, the Soviet Union called a meeting of nine European Communist parties in southwest Poland.[59] A Communist Party of the Soviet Union (CPSU) report was read at the outset to set the heavily anti-Western tone, stating now that ""international politics is dominated by the ruling clique of the American imperialists"" which have embarked upon the ""enslavement of the weakened capitalist countries of Europe"".[60] Communist parties were to struggle against the US presence in Europe by any means necessary, including sabotage.[61] The report further claimed that ""reactionary imperialist elements throughout the world, particularly in the United States, in Britain and France, had put particular hope on Germany and Japan, primarily on Hitlerite Germany—first as a force most capable of striking a blow at the Soviet Union"".[62]
",4
5203,"Referring to the Eastern Bloc, the report stated that ""the Red Army's liberating role was complemented by an upsurge of the freedom-loving peoples' liberation struggle against the fascist predators and their hirelings.""[62] It argued that ""the bosses of Wall Street"" were ""tak[ing] the place of Germany, Japan and Italy"".[62] The Marshall Plan was described as ""the American plan for the enslavement of Europe"".[62] It described the world now breaking down ""into basically two camps—the imperialist and antidemocratic camp on the one hand, and the antiimperialist and democratic camp on the other"".[62]
",4
5204,"Although the Eastern Bloc countries except Czechoslovakia had immediately rejected Marshall Plan aid, Eastern Bloc communist parties were blamed for permitting even minor influence by non-communists in their respective countries during the run up to the Marshall Plan.[63] The meeting's chair, Andrei Zhdanov, who was in permanent radio contact with the Kremlin from whom he received instructions,[60] also castigated communist parties in France and Italy for collaboration with those countries' domestic agendas.[64] Zhdanov warned that if they continued to fail to maintain international contact with Moscow to consult on all matters, ""extremely harmful consequences for the development of the brother parties' work"" would result.[64]
",4
5205,"Italian and French communist leaders were prevented by party rules from pointing out that it was actually Stalin who had directed them not to take opposition stances in 1944.[64] The French communist party, as others, was then to redirect its mission to ""destroy capitalist economy"" and that the Soviet Communist Information Bureau (Cominform) would take control of the French Communist Party's activities to oppose the Marshall Plan.[61] When they asked Zhdanov if they should prepare for armed revolt when they returned home, he did not answer.[61] In a follow-up conversation with Stalin, he explained that an armed struggle would be impossible and that the struggle against the Marshall Plan was to be waged under the slogan of national independence.[65]
",4
5206,"Congress, under the control of conservative Republicans, agreed to the program for multiple reasons. The 20-member conservative isolationist Senate wing of the party, based in the rural Midwest and led by Senator Kenneth S. Wherry (R-Nebraska), was outmaneuvered by the emerging internationalist wing, led by Senator Arthur H. Vandenberg (R-Michigan). The opposition argued that it made no sense to oppose communism by supporting the socialist governments in Western Europe; and that American goods would reach Russia and increase its war potential. They called it ""a wasteful 'operation rat-hole'""[66] Vandenberg, assisted by Senator Henry Cabot Lodge Jr. (R-Massachusetts) admitted there was no certainty that the plan would succeed, but said it would halt economic chaos, sustain Western civilization, and stop further Soviet expansion. Senator Robert A. Taft (R-Ohio) hedged on the issue. He said it was without economic justification; however, it was ""absolutely necessary"" in ""the world battle against communism."" In the end, only 17 senators voted against it on March 13, 1948[67] A bill granting an initial $5 billion passed Congress with strong bipartisan support. Congress eventually allocated $12.4 billion in aid over the four years of the plan.[68]
",4
5207,"Congress reflected public opinion, which resonated with the ideological argument that communism flourishes in poverty. Truman's own prestige and power had been greatly enhanced by his stunning victory in the 1948 election. Across America, multiple interest groups, including business, labor, farming, philanthropy, ethnic groups, and religious groups, saw the Marshall Plan as an inexpensive solution to a massive problem, noting it would also help American exports and stimulate the American economy as well. Major newspapers were highly supportive, including such conservative outlets as Time magazine. Vandenberg made sure of bipartisan support on the Senate Foreign Relations Committee. The Solid Democratic South was highly supportive, the upper Midwest was dubious, but heavily outnumbered. The plan was opposed by conservatives in the rural Midwest, who opposed any major government spending program and were highly suspicious of Europeans.[69] The plan also had some opponents on the left, led by Henry A. Wallace, the former Vice President. He said the Plan was hostile to the Soviet Union, a subsidy for American exporters, and sure to polarize the world between East and West.[70] However, opposition against the Marshall Plan was greatly reduced by the shock of the Communist coup in Czechoslovakia in February 1948. The appointment of the prominent businessman Paul G. Hoffman as director reassured conservative businessmen that the gigantic sums of money would be handled efficiently.[71][72]
",4
5208,"Turning the plan into reality required negotiations among the participating nations. Sixteen nations met in Paris to determine what form the American aid would take, and how it would be divided. The negotiations were long and complex, with each nation having its own interests. France's major concern was that Germany not be rebuilt to its previous threatening power. The Benelux countries (Belgium, Netherlands, and Luxembourg), despite also suffering under the Nazis, had long been closely linked to the German economy and felt their prosperity depended on its revival. The Scandinavian nations, especially Sweden, insisted that their long-standing trading relationships with the Eastern Bloc nations not be disrupted and that their neutrality not be infringed.[73]
",4
5209,"The United Kingdom insisted on special status as a longstanding belligerent during the war, concerned that if it were treated equally with the devastated continental powers it would receive virtually no aid. The Americans were pushing the importance of free trade and European unity to form a bulwark against communism. The Truman administration, represented by William L. Clayton, promised the Europeans that they would be free to structure the plan themselves, but the administration also reminded the Europeans that implementation depended on the plan's passage through Congress. A majority of Congress members were committed to free trade and European integration, and were hesitant to spend too much of the money on Germany.[73] However, before the Marshall Plan was in effect, France, Austria, and Italy needed immediate aid. On December 17, 1947, the United States agreed to give $40 million to France, Austria, China, and Italy.[74]
",4
5210,"Agreement was eventually reached and the Europeans sent a reconstruction plan to Washington, which was formulated and agreed upon by the Committee of European Economic Co-operation in 1947. In the document, the Europeans asked for $22 billion in aid. Truman cut this to $17 billion in the bill he put to Congress.
On March 17, 1948, Truman addressed European security and condemned the Soviet Union before a hastily convened Joint Session of Congress. Attempting to contain spreading Soviet influence in the Eastern Bloc, Truman asked Congress to restore a peacetime military draft and to swiftly pass the Economic Cooperation Act, the name given to the Marshall Plan. Of the Soviet Union Truman said, ""The situation in the world today is not primarily the result of the natural difficulties which follow a great war. It is chiefly due to the fact that one nation has not only refused to cooperate in the establishment of a just and honorable peace but—even worse—has actively sought to prevent it.""[75]
",4
5211,"Members of the Republican-controlled 80th Congress (1947–1949) were skeptical. ""In effect, he told the Nation that we have lost the peace, that our whole war effort was in vain."", noted Representative Frederick Smith of Ohio. Others thought he had not been forceful enough to contain the USSR. ""What [Truman] said fell short of being tough"", noted Representative Eugene Cox, a Democrat from Georgia, ""there is no prospect of ever winning Russian cooperation."" Despite its reservations, the 80th Congress implemented Truman's requests, further escalating the Cold War with the USSR.[75]
",4
5212,"Truman signed the Economic Cooperation Act into law on April 3, 1948; the Act established the Economic Cooperation Administration (ECA) to administer the program. ECA was headed by economic cooperation administrator Paul G. Hoffman. In the same year, the participating countries (Austria, Belgium, Denmark, France, West Germany, the United Kingdom, Greece, Iceland, Ireland, Italy, Luxembourg, the Netherlands, Norway, Sweden, Switzerland, Turkey, and the United States) signed an accord establishing a master financial-aid-coordinating agency, the Organisation for European Economic Co-operation (later called the Organisation for Economic Co-operation and Development or OECD), which was headed by Frenchman Robert Marjolin.
",4
5213,"According to Armin Grunbacher:
",4
5214,"The ECA's official mission statement was to give a boost to the European economy: to promote European production, to bolster European currency, and to facilitate international trade, especially with the United States, whose economic interest required Europe to become wealthy enough to import US goods. Another unofficial goal of ECA (and of the Marshall Plan) was the containment of growing Soviet influence in Europe, evident especially in the growing strength of communist parties in France, and Italy.
",4
5215,"The Marshall Plan money was transferred to the governments of the European nations. The funds were jointly administered by the local governments and the ECA. Each European capital had an ECA envoy, generally a prominent American businessman, who would advise on the process. The cooperative allocation of funds was encouraged, and panels of government, business, and labor leaders were convened to examine the economy and see where aid was needed. The recipient nations were represented collectively by the Organisation for Economic Co-operation and Development (OECD), headed by British statesman Oliver Franks.[77]
",4
5216,"The Marshall Plan aid was mostly used for goods from the United States. The European nations had all but exhausted their foreign-exchange reserves during the war, and the Marshall Plan aid represented almost their sole means of importing goods from abroad. At the start of the plan, these imports were mainly much-needed staples such as food and fuel, but later the purchases turned toward reconstruction needs as was originally intended. In the latter years, under pressure from the United States Congress and with the outbreak of the Korean War, an increasing amount of the aid was spent on rebuilding the militaries of Western Europe. Of the some $13 billion allotted by mid-1951, $3.4 billion had been spent on imports of raw materials and semi-manufactured products; $3.2 billion on food, feed, and fertilizer; $1.9 billion on machines, vehicles, and equipment; and $1.6 billion on fuel.[78]
",4
5217,"Also established were counterpart funds, which used Marshall Plan aid to establish funds in the local currency. According to ECA rules, recipients had to invest 60% of these funds in industry. This was prominent in Germany, where these government-administered funds played a crucial role in lending money to private enterprises which would spend the money rebuilding. These funds played a central role in the reindustrialization of Germany. In 1949–50, for instance, 40% of the investment in the German coal industry was by these funds.[79]
",4
5218,"The companies were obligated to repay the loans to the government, and the money would then be lent out to another group of businesses. This process has continued to this day in the guise of the state-owned KfW bank, (Kreditanstalt für Wiederaufbau, meaning Reconstruction Credit Institute). The Special Fund, then supervised by the Federal Economics Ministry, was worth over DM 10 billion in 1971. In 1997 it was worth DM 23 billion. Through the revolving loan system, the Fund had by the end of 1995 made low-interest loans to German citizens amounting to around DM 140 billion. The other 40% of the counterpart funds were used to pay down the debt, stabilize the currency, or invest in non-industrial projects. France made the most extensive use of counterpart funds, using them to reduce the budget deficit. In France, and most other countries, the counterpart fund money was absorbed into general government revenues, and not recycled as in Germany.[80]
",4
5219,"The Netherlands received US aid for economic recovery in the Netherlands Indies. However, in January 1949, the American government suspended this aid in response to the Dutch efforts to restore colonial rule in Indonesia during the Indonesian National Revolution, and it implicitly threatened to suspend Marshall aid to the Netherlands if the Dutch government continued to oppose the independence of Indonesia.[81]
",4
5220,"At the time the United States was a significant oil producing nation — one of the goals of the Marshall Plan was for Europe to use oil in place of coal, but the Europeans wanted to buy crude oil and use the Marshall Plan funds to build refineries instead. However, when independent American oil companies complained, the ECA denied funds for European refinery construction.[82]
",4
5221,"A high priority was increasing industrial productivity in Europe, which proved one of the more successful aspects of the Marshall Plan.[83] The US Bureau of Labor Statistics (BLS) contributed heavily to the success of the Technical Assistance Program. The United States Congress passed a law on June 7, 1940 that allowed the BLS to ""make continuing studies of labor productivity""[84] and appropriated funds for the creation of a Productivity and Technological Development Division. The BLS could then use its expertise in the field of productive efficiency to implement a productivity drive in each Western European country receiving Marshall Plan aid. Counterpart funds were used to finance large-scale tours of American industry. France, for example, sent 500 missions with 4700 businessmen and experts to tour American factories, farms, stores, and offices. They were especially impressed with the prosperity of American workers, and how they could purchase an inexpensive new automobile for nine months work, compared to 30 months in France.[85]
",4
5222,"By implementing technological literature surveys and organized plant visits, American economists, statisticians, and engineers were able to educate European manufacturers in statistical measurement. The goal of the statistical and technical assistance from the Americans was to increase productive efficiency of European manufacturers in all industries.
",4
5223,"To conduct this analysis, the BLS performed two types of productivity calculations. First, they used existing data to calculate how much a worker produces per hour of work—the average output rate. Second, they compared the existing output rates in a particular country to output rates in other nations. By performing these calculations across all industries, the BLS was able to identify the strengths and weaknesses of each country's manufacturing and industrial production. From that, the BLS could recommend technologies (especially statistical) that each individual nation could implement. Often, these technologies came from the United States; by the time the Technical Assistance Program began, the United States used statistical technologies ""more than a generation ahead of what [the Europeans] were using"".[84]
",4
5224,"The BLS used these statistical technologies to create Factory Performance Reports for Western European nations. The American government sent hundreds of technical advisers to Europe to observe workers in the field. This on-site analysis made the Factory Performance Reports especially helpful to the manufacturers. In addition, the Technical Assistance Program funded 24,000 European engineers, leaders, and industrialists to visit America and tour America's factories, mines, and manufacturing plants.[86] This way, the European visitors would be able to return to their home countries and implement the technologies used in the United States. The analyses in the Factory Performance Reports and the ""hands-on"" experience had by the European productivity teams effectively identified productivity deficiencies in European industries; from there, it became clearer how to make European production more effective.
",4
5225,"Before the Technical Assistance Program even went into effect, United States Secretary of Labor Maurice Tobin expressed his confidence in American productivity and technology to both American and European economic leaders. He urged that the United States play a large role in improving European productive efficiency by providing four recommendations for the program's administrators:
",4
5226,"The effects of the Technical Assistance Program were not limited to improvements in productive efficiency. While the thousands of European leaders took their work/study trips to the United States, they were able to observe a number of aspects of American society as well. The Europeans could watch local, state, and federal governments work together with citizens in a pluralist society. They observed a democratic society with open universities and civic societies in addition to more advanced factories and manufacturing plants. The Technical Assistance Program allowed Europeans to bring home many types of American ideas.[88]
",4
5227,"Another important aspect of the Technical Assistance Program was its low cost. While $19.4 billion was allocated for capital costs in the Marshall Plan, the Technical Assistance Program only required $300 million. Only one-third of that $300 million cost was paid by the United States.[87]
",4
5228,"In the aftermath of the war Britain faced a deep financial crisis, whereas the United States enjoyed an economic boom. The United States continue to finance the British treasury after the war. Much of this aid was designed to restore infrastructure and help refugees. Britain received an emergency loan of $3.75 billion in 1946; it was a 50-year loan with a low 2% interest rate.[42] The Marshall Plan provided a more permanent solution as it gave $3.3 billion to Britain. The Marshall money was a gift and carried requirements that Britain balance its budget, control tariffs and maintain adequate currency reserves. The British Labour government under Prime Minister Clement Attlee was an enthusiastic participant.[89][90]
",4
5229,"The American goals for the Marshall plan were to help rebuild the postwar British economy, help modernize the economy, and minimize trade barriers. When the Soviet Union refused to participate or allow its satellites to participate, the Marshall plan became an element of the emerging Cold War.[91]
",4
5230,"There were political tensions between the two nations regarding Marshall plan requirements.[92] London was dubious about Washington's emphasis on European economic integration as the solution to postwar recovery. Integration with Europe at this point would mean cutting close ties to the emerging Commonwealth. London tried to convince Washington that that American economic aid, especially to the sterling currency area, was necessary to solve the dollar shortage. British economist argued that their position was validated by 1950 as European industrial production exceeded prewar levels. Washington demanded convertibility of sterling currency on 15 July 1947, which produced a severe financial crisis for Britain. Convertibility was suspended on 20 August 1947. However by 1950, American rearmament and heavy spending on the Korean War and Cold War finally ended the dollar shortage.[93] the balance of payment problems the trouble the postwar government was caused less by economic decline and more by political overreach, according to Jim Tomlinson.[94]
",4
5231,"The Marshall Plan was implemented in West Germany 1948-1950 as a way to modernize business procedures and utilize the best practices. The Marshall Plan made it possible for West Germany to return quickly to its traditional pattern of industrial production with a strong export sector. Without the plan, agriculture would have played a larger role in the recovery period, which itself would have been longer.[95][96][97] With respect to Austria, Günter Bischof has noted that ""the Austrian economy, injected with an overabundance of European Recovery Program funds, produced “miracle” growth figures that matched and at times surpassed the German ones.""[98]
",4
5232,"Marshall Aid in general and the counterpart funds in particular had actually quite a significant impact in Cold-War propaganda and economic matters in Western Europe, which most likely contributed to the declining appeal of communism.[99]
",4
5233,"The Marshall Plan aid was divided among the participant states on a roughly per capita basis. A larger amount was given to the major industrial powers, as the prevailing opinion was that their resuscitation was essential for general European revival. Somewhat more aid per capita was also directed toward the Allied nations, with less for those that had been part of the Axis or remained neutral. The exception was Iceland, which had been neutral during the war, but received far more on a per capita basis than the second highest recipient.[100] The table below shows Marshall Plan aid by country and year (in millions of dollars) from The Marshall Plan Fifty Years Later.[101] There is no clear consensus on exact amounts, as different scholars differ on exactly what elements of American aid during this period were part of the Marshall Plan.
",4
5234,"The Marshall Plan, just as GARIOA, consisted of aid both in the form of grants and in the form of loans.[102] Out of the total, US$1.2 billion were loan-aid.[103]
",4
5235,"Ireland which received US$146.2 million through the Marshall Plan, received US$128.2 million as loans, and the remaining US$18 million as grants.[104] By 1969 the Irish Marshall Plan debt, which was still being repaid, amounted to 31 million pounds, out of a total Irish foreign debt of 50 million pounds.[105]
",4
5236,"The UK received US$385 million of its Marshall Plan aid in the form of loans.[103] Unconnected to the Marshall Plan the UK also received direct loans from the US amounting to US$4.6 billion.[103] The proportion of Marshall Plan loans versus Marshall Plan grants was roughly 15% to 85% for both the UK and France.[106]
",4
5237,"Germany, which up until the 1953 Debt agreement had to work on the assumption that all the Marshall Plan aid was to be repaid, spent its funds very carefully. Payment for Marshall Plan goods, ""counterpart funds"", were administered by the Reconstruction Credit Institute, which used the funds for loans inside Germany. In the 1953 Debt agreement, the amount of Marshall plan aid that Germany was to repay was reduced to less than US$1 billion.[107] This made the proportion of loans versus grants to Germany similar to that of France and the UK.[106] The final German loan repayment was made in 1971.[108] Since Germany chose to repay the aid debt out of the German Federal budget, leaving the German ERP fund intact, the fund was able to continue its reconstruction work. By 1996 it had accumulated a value of 23 billion Deutsche Mark.[109]
",4
5238,"The Central Intelligence Agency received 5% of the Marshall Plan funds (about $685 million spread over six years), which it used to finance secret operations abroad. Through the Office of Policy Coordination money was directed toward support for labor unions, newspapers, student groups, artists and intellectuals, who were countering the anti-American counterparts subsidized by the Communists. The largest sum went to the Congress for Cultural Freedom. There were no agents working among the Soviets or their satellite states.[110] The founding conference of the Congress for Cultural Freedom was held in Berlin in June 1950. Among the leading intellectuals from the US and Western Europe were writers, philosophers, critics and historians: Franz Borkenau, Karl Jaspers, John Dewey, Ignazio Silone, James Burnham, Hugh Trevor-Roper, Arthur Schlesinger Jr., Bertrand Russell, Ernst Reuter, Raymond Aron, Alfred Ayer, Benedetto Croce, Arthur Koestler, Richard Löwenthal, Melvin J. Lasky, Tennessee Williams, Irving Brown, and Sidney Hook. There were conservatives among the participants, but non-Communist (or former Communist) left-wingers were more numerous.[111][112]
",4
5239,"The Marshall Plan was originally scheduled to end in 1953. Any effort to extend it was halted by the growing cost of the Korean War and rearmament. American Republicans hostile to the plan had also gained seats in the 1950 Congressional elections, and conservative opposition to the plan was revived. Thus the plan ended in 1951, though various other forms of American aid to Europe continued afterward.
",4
5240,"The years 1948 to 1952 saw the fastest period of growth in European history. Industrial production increased by 35%. Agricultural production substantially surpassed pre-war levels.[68] The poverty and starvation of the immediate postwar years disappeared, and Western Europe embarked upon an unprecedented two decades of growth that saw standards of living increase dramatically. Additionally, the long-term effect of economic integration raised European income levels substantially, by nearly 20 percent by the mid-1970s.[113] There is some debate among historians over how much this should be credited to the Marshall Plan. Most reject the idea that it alone miraculously revived Europe, as evidence shows that a general recovery was already underway. Most believe that the Marshall Plan sped this recovery, but did not initiate it. Many argue that the structural adjustments that it forced were of great importance. Economic historians J. Bradford DeLong and Barry Eichengreen call it ""history's most successful structural adjustment program.""[8] One effect of the plan was that it subtly ""Americanized"" European countries, especially Austria, through new exposure to American popular culture, including the growth in influence of Hollywood movies and rock n' roll.[114]
",4
5241,"The political effects of the Marshall Plan may have been just as important as the economic ones. Marshall Plan aid allowed the nations of Western Europe to relax austerity measures and rationing, reducing discontent and bringing political stability. The communist influence on Western Europe was greatly reduced, and throughout the region, communist parties faded in popularity in the years after the Marshall Plan. The trade relations fostered by the Marshall Plan helped forge the North Atlantic alliance that would persist throughout the Cold War in the form of NATO. At the same time, the nonparticipation of the states of the Eastern Bloc was one of the first clear signs that the continent was now divided.
",4
5242,"The Marshall Plan also played an important role in European integration. Both the Americans and many of the European leaders felt that European integration was necessary to secure the peace and prosperity of Europe, and thus used Marshall Plan guidelines to foster integration. In some ways, this effort failed, as the OEEC never grew to be more than an agent of economic cooperation. Rather, it was the separate European Coal and Steel Community, which did not include Britain, that would eventually grow into the European Union. However, the OEEC served as both a testing and training ground for the structures that would later be used by the European Economic Community. The Marshall Plan, linked into the Bretton Woods system, also mandated free trade throughout the region.
",4
5243,"While some historians today feel some of the praise for the Marshall Plan is exaggerated, it is still viewed favorably and many thus feel that a similar project would help other areas of the world. After the fall of communism, several proposed a ""Marshall Plan for Eastern Europe"" that would help revive that region. Others have proposed a Marshall Plan for Africa to help that continent, and US Vice President Al Gore suggested a Global Marshall Plan.[115] ""Marshall Plan"" has become a metaphor for any very large-scale government program that is designed to solve a specific social problem. It is usually used when calling for federal spending to correct a perceived failure of the private sector.
",4
5244,"Nicholas Shaxson comments: “It is widely believed that the plan worked by offsetting European countries’ yawning deficits. But its real importance ... was simply to compensate for the US failure to institute controls on inflows of hot money from Europe. ... American post-war aid was less than the money flowing in the other direction.“[116] European hot money inflated the US dollar, to the disadvantage of US exporters.
",4
5245,"The Marshall Plan money was in the form of grants from the U.S. Treasury that did not have to be repaid.[citation needed] The Organisation for European Economic Co-operation took the leading role in allocating funds, and the OEEC arranged for the transfer of the goods. The American supplier was paid in dollars, which were credited against the appropriate European Recovery Program funds. The European recipient, however, was not given the goods as a gift but had to pay for them (usually on credit) in local currency. These payments were kept by the European government involved in a special counterpart fund. This counterpart money, in turn, could be used by the government for further investment projects. Five percent of the counterpart money was paid to the US to cover the administrative costs of the ERP.[117] In addition to ERP grants, the Export-Import Bank (an agency of the US government) at the same time made long-term loans at low interest rates to finance major purchases in the US, all of which were repaid.
",4
5246,"In the case of Germany, there also were 16 billion marks of debts from the 1920s which had defaulted in the 1930s, but which Germany decided to repay to restore its reputation. This money was owed to government and private banks in the US, France, and Britain. Another 16 billion marks represented postwar loans by the US. Under the London Debts Agreement of 1953, the repayable amount was reduced by 50% to about 15 billion marks and stretched out over 30 years, and compared to the fast-growing German economy were of minor impact.[118]
",4
5247,"Large parts of the world devastated by World War II did not benefit from the Marshall Plan. The only major Western European nation excluded was Francisco Franco's Spain, which was highly unpopular in Washington. With the escalation of the Cold War, the United States reconsidered its position, and in 1951 embraced Spain as an ally, encouraged by Franco's aggressive anti-communist policies. Over the next decade, a considerable amount of American aid would go to Spain, but less than its neighbors had received under the Marshall Plan.[119]
",4
5248,"The Soviet Union had been as badly affected as any part of the world by the war. The Soviets imposed large reparations payments on the Axis allies that were in its sphere of influence. Austria, Finland, Hungary, Romania, and especially East Germany were forced to pay vast sums and ship large amounts of supplies to the USSR. These reparation payments meant the Soviet Union itself received about the same as 16 European countries received in total from Marshall Plan aid.[120]
",4
5249,"In accordance with the agreements with the USSR, shipment of dismantled German industrial installations from the west began on March 31, 1946. Under the terms of the agreement, the Soviet Union would in return ship raw materials such as food and timber to the western zones. In view of the Soviet failure to do so, the western zones halted the shipments east, ostensibly on a temporary basis, although they were never resumed. It was later shown that the main reason for halting shipments east was not the behavior of the USSR but rather the recalcitrant behavior of France.[121] Examples of material received by the USSR were equipment from the Kugel-Fischer ballbearing plant at Schweinfurt, the Daimler-Benz underground aircraft-engine plant at Obrigheim, the Deschimag shipyards at Bremen-Weser, and the Gendorf powerplant.[122][123]
",4
5250,"The USSR did establish COMECON as a riposte to the Marshall Plan to deliver aid for Eastern Bloc countries, but this was complicated by the Soviet efforts to manage their own recovery from the war. The members of Comecon looked to the Soviet Union for oil; in turn, they provided machinery, equipment, agricultural goods, industrial goods, and consumer goods to the Soviet Union. Economic recovery in the East was much slower than in the West, resulting in the formation of the shortage economies and a gap in wealth between East and West. Finland, which the USSR forbade to join the Marshall Plan and which was required to give large reparations to the USSR, saw its economy recover to pre-war levels in 1947.[124] France, which received billions of dollars through the Marshall Plan, similarly saw its average income per person return to almost pre-war level by 1949.[125] By mid-1948 industrial production in Poland, Hungary, Bulgaria, and Czechoslovakia had recovered to a level somewhat above pre-war level.[126]
",4
5251,"From the end of the war to the end of 1953, the US provided grants and credits amounting to $5.9 billion to Asian countries, especially Rep. Of China (Taiwan) ($1.051 billion), India ($255 million), Indonesia ($215 million), Japan ($2.44 billion), South Korea ($894 million), Pakistan ($98 million) and the Philippines ($803 million). In addition, another $282 million went to Israel and $196 million to the rest of the Middle East.[127] All this aid was separate from the Marshall Plan.[128]
",4
5252,"Canada, like the United States, was damaged little by the war and in 1945 was one of the world's richest economies. It operated its own aid program. In 1948, the US allowed ERP aid to be used in purchasing goods from Canada. Canada made over a billion dollars in sales in the first two years of operation.[129]
",4
5253,"The total of American grants and loans to the world from 1945 to 1953 came to $44.3 billion.[130]
",4
5254,"Bradford DeLong and Barry Eichengreen conclude it was ""History's Most Successful Structural Adjustment Program."" They state:
",4
5255,"It was not large enough to have significantly accelerated recovery by financing investment, aiding the reconstruction of damaged infrastructure, or easing commodity bottlenecks. We argue, however, that the Marshall Plan did play a major role in setting the stage for post-World War II Western Europe's rapid growth. The conditions attached to Marshall Plan aid pushed European political economy in a direction that left its post World War II ""mixed economies"" with more ""market"" and less ""controls"" in the mix.[8]",4
5256,"Prior to passing and enacting the Marshall Plan, President Truman and George Marshall started a domestic overhaul of public opinion from coast to coast. The purpose of this campaign was to sway public opinion in their direction and to inform the common person of what the Marshall Plan was and what the Plan would ultimately do. They spent months attempting to convince Americans that their cause was just and that they should embrace the higher taxes that would come in the foreseeable future.[131]
",4
5257,"A copious amount of propaganda ended up being highly effective in swaying public opinion toward supporting the Marshall Plan. During the nationwide campaign for support, ""more than a million pieces of pro-Marshall Plan publications-booklets, leaflets, reprints, and fact sheets"", were disseminated.[132] Truman's and Marshall's efforts proved to be effective. A Gallup Poll taken between the months of July and December 1947 shows the percentage of Americans unaware of the Marshall Plan fell from 51% to 36% nationwide.[133] By the time the Marshall Plan was ready to be implemented, there was a general consensus throughout the American public that this was the right policy for both America, and the countries who would be receiving aid.
",4
5258,"During the period leading up to World War II, Americans were highly isolationist, and many called The Marshall Plan a ""milestone"" for American ideology.[132] By looking at polling data over time from pre-World War II to post-World War II, one would find that there was a change in public opinion in regards to ideology. Americans swapped their isolationist ideals for a much more global internationalist ideology after World War II.
",4
5259,"In a National Opinion Research Center (NORC) poll taken in April 1945, a cross-section of Americans were asked, ""If our government keeps on sending lendlease materials, which we may not get paid for, to friendly countries for about three years after the war, do you think this will mean more jobs or fewer jobs for most Americans, or won't it make any difference?"" 75% said the same or more jobs; 10% said fewer.[134]
",4
5260,"Before proposing anything to Congress in 1947, the Truman administration made an elaborate effort to organize public opinion in favor of the Marshall Plan spending, reaching out to numerous national organizations representing business, labor, farmers, women, and other interest groups. Political scientist Ralph Levering points out that:
",4
5261,"Mounting large public relations campaigns and supporting private groups such as the Citizens Committee for the Marshall Plan, the administration carefully built public and bipartisan Congressional support before bringing these measures to a vote.[135]",4
5262,"Public opinion polls in 1947 consistently showed strong support for the Marshall plan among Americans. Furthermore, Gallup polls in England, France, and Italy showed favorable majorities over 60%.[136]
",4
5263,"Laissez-faire criticism of the Marshall Plan came from a number of economists. Wilhelm Röpke, who influenced German Minister for Economy Ludwig Erhard in his economic recovery program, believed recovery would be found in eliminating central planning and restoring a market economy in Europe, especially in those countries which had adopted more fascist and corporatist economic policies. Röpke criticized the Marshall Plan for forestalling the transition to the free market by subsidizing the current, failing systems. Erhard put Röpke's theory into practice and would later credit Röpke's influence for West Germany's preeminent success.[137]
",4
5264,"Henry Hazlitt criticized the Marshall Plan in his 1947 book Will Dollars Save the World?, arguing that economic recovery comes through savings, capital accumulation, and private enterprise, and not through large cash subsidies. Austrian School economist Ludwig von Mises criticized the Marshall Plan in 1951, believing that ""the American subsidies make it possible for [Europe's] governments to conceal partially the disastrous effects of the various socialist measures they have adopted"".[138] Some critics and Congressmen at the time believed that America was giving too much aid to Europe. America had already given Europe $9 billion in other forms of help in previous years. The Marshall Plan gave another $13 billion, equivalent to about $100 billion in 2010 value.[139]
",4
5265,"However, its role in the rapid recovery has been debated. Most reject the idea that it alone miraculously revived Europe since the evidence shows that a general recovery was already underway. The Marshall Plan grants were provided at a rate that was not much higher in terms of flow than the previous UNRRA aid and represented less than 3% of the combined national income of the recipient countries between 1948 and 1951,[8] which would mean an increase in GDP growth of only 0.3%.[9] In addition, there is no correlation between the amount of aid received and the speed of recovery: both France and the United Kingdom received more aid, but West Germany recovered significantly faster.[9]
",4
5266,"Criticism of the Marshall Plan became prominent among historians of the revisionist school, such as Walter LaFeber, during the 1960s and 1970s. They argued that the plan was American economic imperialism and that it was an attempt to gain control over Western Europe just as the Soviets controlled Eastern Europe economically through the Comecon. In a review of West Germany's economy from 1945 to 1951, German analyst Werner Abelshauser concluded that ""foreign aid was not crucial in starting the recovery or in keeping it going"". The economic recoveries of France, Italy, and Belgium, Cowen argues, began a few months before the flow of US money. Belgium, the country that relied earliest and most heavily on free-market economic policies after its liberation in 1944, experienced swift recovery and avoided the severe housing and food shortages seen in the rest of continental Europe.[140]
",4
5267,"Former US Chairman of the Federal Reserve Bank Alan Greenspan gives most credit to German Chancellor Ludwig Erhard for Europe's economic recovery. Greenspan writes in his memoir The Age of Turbulence that Erhard's economic policies were the most important aspect of postwar Western European recovery, even outweighing the contributions of the Marshall Plan. He states that it was Erhard's reductions in economic regulations that permitted Germany's miraculous recovery, and that these policies also contributed to the recoveries of many other European countries. Its recovery is attributed to traditional economic stimuli, such as increases in investment, fueled by a high savings rate and low taxes. Japan saw a large infusion of US investment during the Korean War.[141]
",4
5268,"Noam Chomsky said the Marshall Plan ""set the stage for large amounts of private U.S. investment in Europe, establishing the basis for modern transnational corporations"".[142]
",4
5269,"Alfred Friendly, press aide to the US Secretary of Commerce W. Averell Harriman, wrote a humorous operetta about the Marshall Plan during its first year; one of the lines in the operetta was: ""Wines for Sale; will you swap / A little bit of steel for Chateau Neuf du Pape?""[143]
",4
5270,"Spanish director Luis García Berlanga co-wrote and directed the movie Welcome Mr. Marshall!, a comedy about the residents of a small Spanish village who dream about the life of wealth and self-fulfilment the Marshall Plan will bring them. The film highlights the stereotypes held by both the Spanish and the Americans regarding the culture of the other, as well as displays social criticism of 1950s Francoist Spain.
",4
5271,"A Treatise on Money is a two-volume book by English economist John Maynard Keynes published in 1930.
",4
5272,"In the Treatise Keynes drew a distinction between savings and investment, arguing that where saving exceeded investment, recession would occur. Thus, Keynes reasoned that during a depression the best course of action would be to promote spending and to discourage saving.[1] Keynes most notably clarified his Theory of Money in catty dialog[2] with other famous economists of the day, such as Friedrich Hayek and Dennis Robertson.  Keynes described his rejoinder as such “in my Rejoinder to Mr. D. H. Robertson, Published in the Economic Journal for September, 1931, I have endeavored to re-state in a clearer way what my own theory actually is.”[3]
",4
5273,"In Keynes’ Treatise, he does not agree that booms and busts happen solely because of extrinsic random variables such as “sunspots”. Instead, he believes that economic events emerge when there are discrepancies between savings and investments.
According to Keynes, a true measure of a nation's prosperity is not anything of physical value such as gold or silver, but by national income. To him, the most important characteristic of national income is consumption.[4]
",4
5274,"In Keynes's Treatise, he explained how recessions could happen, but not long-term depressions. He was able to address this further in The General Theory of Employment, Interest and Money. In his General Theory, Keynes argued against the seesaw theory and said that the economy was more like an elevator that can stop at any level. This is because once the economy reaches the bottom,  individuals would have no excess income to save. No savings results in no investment so the economy cannot save itself. Without the savings, there is no pressure to lower interest rates, so there is no incentive for businesses to invest. In his theory on money he asserts that investment is an ""undependable drive wheel for the economy,"" and when no new investment can be found, the economy will begin to falter.[5]
",4
5275,"Keynes and Hayek debated the former's theory of money. Keynes felt that Hayek was splitting hairs with him terminologically and  published a public response to the Austrian's criticisms, writing, “Dr Hayek has seriously misapprehended the character of my conclusions. He thinks that my central contention is something different from what it really is”; “It is essential to that theory to deny these propositions which Dr Hayek puts in my mouth.”  The meat of their disagreement from Keynes's perspective concerned ancillary points, and semantic differences in definition, leading him to conclude that Hayek was nit-picking: “So long as a problem of this major magnitude is not cleared up between us, what is the use of discussing 'irritating' terminology, which might not bother Dr Hayek at all if he were not, for these excellent other reasons, looking for trouble? Dr Hayek has missed, or at least does not discuss, the critical point at which our arguments part company. Having passed this by, but finding himself being led down strange and distasteful paths, he tries to prevent himself from being dragged along any further by representing the molehills in the pathway as mountains”
",4
5276,"John Hicks stated that the A Treatise on Money was the first economics publication to use the term liquidity, because he had not been able to find the term used in earlier works.[6]
",4
5277,"
",4
5278,"The Chicago school of economics is a neoclassical school of economic thought associated with the work of the faculty at the University of Chicago, some of whom have constructed and popularized its principles.
",4
5279,"In the context of macroeconomics, it is connected to the freshwater school of macroeconomics, in contrast to the saltwater school based in coastal universities (notably Harvard, Yale, Penn, UC Berkeley, and UCLA).[1] Chicago macroeconomic theory rejected Keynesianism in favor of monetarism until the mid-1970s, when it turned to new classical macroeconomics heavily based on the concept of rational expectations. The freshwater–saltwater distinction is largely antiquated today, as the two traditions have heavily incorporated ideas from each other. Specifically, new Keynesian economics was developed as a response to new classical economics, electing to incorporate the insight of rational expectations without giving up the traditional Keynesian focus on imperfect competition and sticky wages.
",4
5280,"Chicago economists have also left their intellectual influence in other fields, notably in pioneering public choice theory and law and economics, which have led to revolutionary changes in the study of political science and law. Other economists affiliated with Chicago have made their impact in fields as diverse as social economics and economic history. Thus, there is not a clear delineation of the Chicago school of economics, a term that is more commonly used in the popular media than in academic circles.[citation needed] Nonetheless, Kaufman (2010) says that the Chicago school can be generally characterized by the following:[2]
",4
5281,"A deep commitment to rigorous scholarship and open academic debate, an uncompromising belief in the usefulness and insight of neoclassical price theory, and a normative position that favors and promotes economic liberalism and free markets.",4
5282,"As of 2018, the University of Chicago Economics department, considered one of the world's foremost economics departments, has been awarded 13 Nobel Memorial Prize in Economic Sciences—more than any other university—and has been awarded 6 John Bates Clark Medals.[3][4][5] However, it is important to note that not all members of the department belong to the Chicago school of economics, which is a school of thought rather than an organization. 
",4
5283,"The term was coined in the 1950s to refer to economists teaching in the Economics Department at the University of Chicago, and closely related academic areas at the University such as the Booth School of Business and the Law School. They met together in frequent intense discussions that helped set a group outlook on economic issues, based on price theory. The 1950s saw the height of popularity of the Keynesian school of economics, so the members of the University of Chicago were considered outside the mainstream.
",4
5284,"Besides what is popularly known as the ""Chicago school"", there is also an ""Old Chicago"" or the first-generation Chicago school of economics, consisting of an earlier generation of economists such as Frank Knight, Henry Simons, Lloyd Mints, Jacob Viner, Aaron Director and others.[6] This group had diverse interests and approaches, but Knight, Simons, and Director in particular advocated a focus on the role of incentives and the complexity of economic events rather than on general equilibrium. Outside of Chicago, these early leaders were important influences on the Virginia school of political economy.[7] Nonetheless, these scholars had an important influence on the thought of Milton Friedman and George Stigler who were the leaders of the second-generation Chicago school, most notably in the development of price theory and transaction cost economics.[8][9] The third generation of Chicago economics is led by Gary Becker, as well as macroeconomists Robert Lucas Jr. and Eugene Fama.[9][10]
",4
5285,"A further significant branching of Chicago thought was dubbed by George Stigler as ""Chicago political economy"". Inspired by the Coasian view that institutions evolve to maximize the Pareto efficiency, Chicago political economy came to the surprising and controversial view that politics tends towards efficiency and that policy advice is irrelevant.
",4
5286,"As of 2018, the University of Chicago Economics Department has been awarded 13 Nobel Memorial Prize in Economic Sciences (laureates were affiliated with the department when receiving the prizes) since the prize was first awarded in 1969. In addition, as of October 2018, 32 out of the total 81 Nobel laureates in Economics have been affiliated with the university as alumni, faculty members or researchers.[4] However, not all members of the department belong to the Chicago school of economics.
",4
5287,"
",4
5288,"As of 2019, the University of Chicago Economics Department has been awarded 6 John Bates Clark Medals (medalists were affiliated with the department when receiving the medals) since the medal was first awarded in 1947.[5] However, some medalists may not belong to the Chicago school of economics.
",4
5289,"Frank Knight (1885–1972) was an early member of the University of Chicago department. He joined the department in 1929, coming from the University of Iowa.[29] His most influential work was Risk, Uncertainty and Profit (1921) from which the term Knightian uncertainty was derived. Knight's perspective was iconoclastic, and markedly different from later Chicago school thinkers. He believed that while the free market could be inefficient, government programs were even less efficient. He drew from other economic schools of thought such as institutional economics to form his own nuanced perspective.
",4
5290,"Henry Calvert Simons (1899–1946) did his graduate work at the University of Chicago but did not submit his final dissertation to receive a degree.[30] In fact, he was initially influenced by Frank Knight while he was an assistant professor at the University of Iowa from 1925–1927, and in summer 1927 Simons decided to join the Department of Economics at the University of Chicago (earlier than Knight did).[29][30] He was a long-term member in the Chicago economics department, most notable for his antitrust and monetarist models.[31]
",4
5291,"Jacob Viner (1892–1970) was in the faculty of Chicago's economics department for 30 years (1916–1946). He inspired a generation of economists at Chicago, including Milton Friedman.[32][33]
",4
5292,"Aaron Director (1901–2004) had been a professor at Chicago's Law School since 1946. He is regarded as a founder of the field Law and Economics, and established The Journal of Law & Economics in 1958.[34] Director influenced some of the next generation of jurists, including Richard Posner, Antonin Scalia and Chief Justice William Rehnquist.
",4
5293,"A group of agricultural economists led by Theodore Schultz (1902–1998) and D. Gale Johnson (1916–2003) moved from Iowa State to the University of Chicago in the mid-1940s. Schultz served as the chair of economics from 1946 to 1961. He became president of the American Economic Association in 1960, retired in 1967, though he remained active at the University of Chicago until his death in 1998. Johnson served as department chair from 1971–1975 and 1980–1984 and was president of the American Economics Association in 1999. Their research in farm and agricultural economics was widely influential and attracted funding from the Rockefeller Foundation to the agricultural economics program at the University. Among the graduate students and faculty affiliated with the pair in the 1940s and 1950s were Clifford Hardin, Zvi Griliches, Marc Nerlove, and George S. Tolley.[35] In 1979, Schultz was awarded the Nobel Prize in Economics for his work in human capital theory and economic development.
",4
5294,"Milton Friedman (1912–2006) stands as one of the most influential economists of the late twentieth century. A student of Frank Knight, he was awarded the Nobel Prize in Economics in 1976 for, among other things, A Monetary History of the United States (1963). Friedman argued that the Great Depression had been caused by the Federal Reserve's policies through the 1920s, and worsened in the 1930s. Friedman argued that laissez-faire government policy is more desirable than government intervention in the economy.
",4
5295,One of the great mistakes is to judge policies and programs by their intentions rather than their results.,4
5296,"Governments should aim for a neutral monetary policy oriented toward long-run economic growth, by gradual expansion of the money supply. He advocated the quantity theory of money, that general prices are determined by money. Therefore, active monetary (e.g. easy credit) or fiscal (e.g. tax and spend) policy can have unintended negative effects. In Capitalism and Freedom (1992) Friedman wrote:[36]
",4
5297,There is likely to be a lag between the need for action and government recognition of the need; a further lag between recognition of the need for action and the taking of action; and a still further lag between the action and its effects.,4
5298,"The slogan that ""money matters"" has come to be associated with Friedman, but Friedman had also leveled harsh criticism of his ideological opponents. Referring to Thorstein Veblen's assertion that economics unrealistically models people as ""lightning calculator[s] of pleasure and pain"", Friedman wrote:[37]
",4
5299,Criticism of this type is largely beside the point unless supplemented by evidence that a hypothesis differing in one or another of these respects from the theory being criticized yields better predictions for as wide a range of phenomena.,4
5300,"George Stigler (1911–1991) was tutored for his thesis by Frank Knight and was awarded the Nobel Prize in Economics in 1982. He is best known for developing the Economic Theory of Regulation,[38] also known as regulatory capture, which says that interest groups and other political participants will use the regulatory and coercive powers of government to shape laws and regulations in a way that is beneficial to them. This theory is an important component of the Public Choice field of economics. He also carried out extensive research into the history of economic thought. His 1962 article ""Information in the Labor Market""[39] developed the theory of search unemployment.
",4
5301,"Ronald Coase (1910–2013) was the most prominent economic analyst of law and the 1991 Nobel Prize-winner. His first major article, ""The Nature of the Firm"" (1937), argued that the reason for the existence of firms (companies, partnerships, etc.) is the existence of transaction costs. Rational individuals trade through bilateral contracts on open markets until the costs of transactions mean that using corporations to produce things is more cost-effective.[40]
",4
5302,"His second major article, ""The Problem of Social Cost"" (1960), argued that if we lived in a world without transaction costs, people would bargain with one another to create the same allocation of resources, regardless of the way a court might rule in property disputes. Coase used the example of an 1879 London legal case about nuisance named Sturges v Bridgman, in which a noisy sweetmaker and a quiet doctor were neighbours; the doctor went to court seeking an injunction against the noise produced by the sweetmaker.[40] Coase said that regardless of whether the judge ruled that the sweetmaker had to stop using his machinery, or that the doctor had to put up with it, they could strike a mutually beneficial bargain that reaches the same outcome of resource distribution. Only the existence of transaction costs may prevent this.[41]
",4
5303,"So, the law ought to pre-empt what would happen, and be guided by the most efficient solution. The idea is that law and regulation are not as important or effective at helping people as lawyers and government planners believe.[42] Coase and others like him wanted a change of approach, to put the burden of proof for positive effects on a government that was intervening in the market, by analysing the costs of action.[43]
",4
5304,"Gary Becker (1930–2014) received the Nobel Prize in Economics 1992 and the Presidential Medal of Freedom in 2007.[44] Becker received his PhD at the University of Chicago in 1955 under H. Gregg Lewis, and was influenced by Milton Friedman.[45] In 1970, he returned to Chicago as a professor and stayed affiliated with the university until his death.[45] He is considered as one of the founding fathers of Chicago political economy, and one of the most influential economists and social scientists in the second half of the twentieth century.[46][47][48][49][50]
",4
5305,"Becker was known in his work for applying economic methods of thinking to other fields, such as crime, sexual relationships, slavery and drugs, assuming that people act rationally. His work was originally focused in labor economics. His work partly inspired the popular economics book Freakonomics. In June 2011, the Becker Friedman Institute for Research in Economics was established at the University of Chicago in honor of Gary Becker and Milton Friedman.[51]
",4
5306,"Robert Lucas (born 1937), who won the Nobel Prize in 1995, has dedicated his life to unwinding Keynesianism. His major contribution is the argument that macroeconomics should not be seen as a separate mode of thought from microeconomics, and that analysis in both should be built on the same foundations. Lucas's works cover several topics in macroeconomics, included economic growth, asset pricing, and monetary Economics.
",4
5307,"Eugene Fama (born 1939) is an American financial economist who was awarded the Nobel Prize in Economics in 2013 for his work on empirical asset pricing and is the fourth most highly cited economist of all time.[52] He has spent all of his teaching career at the University of Chicago and is the originator of the efficient-market hypothesis, first defined in his 1965 article as market where ""at any point in time, the actual price of a security will be a good estimate of its intrinsic value"". The notion was further explored in his 1970 article, ""Efficient Capital Markets: A Review of Theory and Empirical Work"", which brought the notion of efficient markets into the forefront of modern economic theory, and his 1991 article, ""Efficient Markets II"".  Whilst his 1965 Ph.D. thesis, ""The Behavior of Stock Market Prices"", showed that stock prices can be approximated by a random walk in the short-term; in later work he showed that insofar as stock prices are predictable in the long-term, it is largely due to rational time-varying risk premia which can be modelled using the Fama–French three-factor model (1993, 1996) or their updated five-factor model (2014). His work showing that the value premium can persist despite rational forecasts of future earnings[53] and that the performance of actively managed funds is almost entirely due to chance or exposure to risk[54] are all supportive of an efficient-markets view of the world.
",4
5308,"Robert Fogel (1926–2013), a co-winner of the Nobel Prize in 1993, is well known for his historical analysis and his introduction of New economic history,[55] and invention of cliometrics.[56] In his tract, Railroads and American Economic Growth: Essays in Econometric History,  Fogel set out to rebut comprehensively the idea that railroads contributed to economic growth in the 19th century. Later, in Time on the Cross: The Economics of American Negro Slavery, he argued that slaves in the Southern states of America had a higher standard of living than the industrial proletariat of the Northern states before the American civil war.
",4
5309,"James Heckman (born 1944) is a Nobel Prize-winner from 2000, is known for his pioneering work in econometrics and microeconomics.
",4
5310,"Lars Peter Hansen (born 1952) is an American economist who won the Nobel Prize in Economics in 2013 with Eugene Fama and Robert Shiller for their work on asset pricing. Hansen began teaching at the University of Chicago in 1981 and is the David Rockefeller Distinguished Service Professor of economics at the University of Chicago. Although best known for his work on the Generalized method of moments, he is also a distinguished macroeconomist, focusing on the linkages between the financial and real sectors of the economy.
",4
5311,"Richard Posner (born 1939) is known primarily for his work in law and economics, though Robert Solow describes Posner's grasp of certain economic ideas as ""in some respects,... precarious"".[57] A federal appellate judge rather than an economist, Posner's main work, Economic Analysis of Law attempts to apply rational choice models to areas of law. He has chapters on tort, contract, corporations, labor law, but also criminal law, discrimination and family law. Posner goes so far as to say that:[58]
",4
5312,"[the central] meaning of justice, perhaps the most common is – efficiency… [because] in a world of scarce resources waste should be regarded as immoral.",4
5313,"Friedrich Hayek (1899–1992) made frequent contacts with many at the University of Chicago during 1940s. His book The Road to Serfdom, published in the U.S. by the University of Chicago Press in September 1944 with the help of Aaron Director, played a seminal role in transforming how Milton Friedman and others understood how society works.[59][60] The University Press continued to publish a large number of Hayek's works in later years, such as The Fatal Conceit and The Constitution of Liberty.[61] In 1947, Hayek, Frank Knight, Friedman and George Stigler worked together in forming the Mont Pèlerin Society, an international forum for libertarian economists.[62]
",4
5314,"During 1950–1962, Hayek was a faculty member of the Committee of Social Thought at the University of Chicago, where he conducted a number of influential faculty seminars.[63] There were a number of Chicago academics who worked on research projects sympathetic to some of Hayek's own, such as Aaron Director, who was active in the Chicago School in helping to fund and establish what became the ""Law and Society"" program in the University of Chicago Law School.[64] Hayek and Friedman also cooperated in support of the Intercollegiate Society of Individualists, later renamed the Intercollegiate Studies Institute, an American student organisation devoted to libertarian ideas.[65][66]
",4
5315,"James M. Buchanan (1919–2013) won the 1986 Nobel Prize in Economics for his public choice theory.[67] He studied under Frank H. Knight at the University of Chicago, receiving PhD in 1948. Although he did not hold any position at the university afterwards, his later work is closely related to the thought of the Chicago school. Buchanon was the foremost proponent of the Virginia school of political economy.
",4
5316,"Thomas Sowell (born in 1930) received his PhD at the University of Chicago in 1968, under George Stigler. A libertarian conservative in his perspective, he is considered to be a representative of the Chicago school.[68][69]
",4
5317,"Paul Douglas, economist and Democratic senator from Illinois for 18 years, was uncomfortable with the environment he found at the university. He stated that, ""…I was disconcerted to find that the economic and political conservatives had acquired almost complete dominance over my department and taught that market decisions were always right and profit values the supreme ones… The opinions of my colleagues would have confined government to the eighteenth-century functions of justice, police, and arms, which I thought had been insufficient even for that time and were certainly so for ours. These men would neither use statistical data to develop economic theory nor accept critical analysis of the economic system… (Frank) Knight was now openly hostile, and his disciples seemed to be everywhere. If I stayed, it would be in an unfriendly environment.""[70]
",4
5318,"While the efficacy of Eugene Fama's efficient-market hypothesis (EMH) was debated after the financial crisis of 2007–08, proponents emphasized that the EMH is consistent with the large decline in asset prices since the event was unpredictable.[71] Specifically, if market crashes never occurred, this would contradict the EMH since the average return of risky assets would be too large to justify the decreased risk of a large decline in prices; and if anything, the equity premium puzzle implies that market crashes do not happen enough to justify the high Sharpe ratio of US stocks and other risky assets.
",4
5319,"Economist Brad DeLong of the University of California, Berkeley says the Chicago School has experienced an ""intellectual collapse"", while Nobel laureate Paul Krugman of Princeton University says that some recent comments from Chicago school economists are ""the product of a Dark Age of macroeconomics in which hard-won knowledge has been forgotten"", claiming that most peer-reviewed macroeconomic research since the mid-1960s has been wrong, preferring models developed in the 1930s.[72] Chicago finance economist John Cochrane countered that these criticisms were ad hominem, displayed a ""deep and highly politicized ignorance of what economics and finance is really all about"", and failed to disentangle bubbles from rational risk premiums and crying wolf too many times in a row, emphasizing that even if these criticisms were true, it would make a stronger argument against regulation and control.[73]
",4
5320,"Finally, the school also has been criticized for training economists who advised the libertarian Chilean military junta during the 1970s and 1980s. While they were credited with transforming Chile into Latin America's best performing economy (see Miracle of Chile) with GDP per capita increasing from US$693 at the start of 1975 (the year Milton Friedman met with dictator Augusto Pinochet; ninth highest of 12 South American countries) to $14,528 by the end of 2014 (the second highest in South America).[74]
",4
5321,"In the years since the reforms were introduced, the economic system implemented by the ""Chicago Boys"" (a label given to this group of economists) have mostly remained in place.[75] The percent of total income earned by the richest 20% of the Chilean population in 2006 was 56.8%, while the percent of total income earned by the poorest 20% of the Chilean population was 4.1%, leaving a strong middle class earning 39.1% of total income.[76] Chile's Gini index (measure of income distribution) was 52.0 in 2006, compared to 24.7 of Denmark (most equally distributed) and 74.3 of Namibia (most unequally distributed).[76] Chile has the widest inequality gap of any nation in the OECD.[77]
",4
5322,"A film titled Chicago Boys, which had a highly critical view of the economic reforms, was released in Chile in November 2015.[78]
",4
5323,"Gastronomy is a compund word that derives from the ancient greek γαστήρ -τρός ""stomach"" and -νομία ""-rule"".[1] It is the study of the relationship between food and culture, the art of preparing and serving rich or delicate and appetizing food, the cooking styles of particular regions, and the science of good eating.[2][full citation needed] One who is well versed in gastronomy is called a gastronome, while a gastronomist is one who unites theory and practice in the study of gastronomy. Practical gastronomy is associated with the practice and study of the preparation, production, and service of the various foods and beverages, from countries around the world. Theoretical gastronomy supports practical gastronomy. It is related with a system and process approach, focused on recipes, techniques and cookery books. Food gastronomy is connected with food and beverages and their genesis. Technical gastronomy underpins practical gastronomy, introducing a rigorous approach to evaluation of gastronomic topics.[3][4][unreliable source?]
",5
5324,"Gastronomy involves discovering, tasting, experiencing, researching, understanding and writing about food preparation and the sensory qualities of human nutrition as a whole. It also studies how nutrition interfaces with the broader culture. The biological and chemical basis of cooking has become known as molecular gastronomy, while gastronomy covers a much broader, interdisciplinary ground.
",5
5325,"The culinary term appears for the first time in a title in a poem by Joseph Berchoux in 1801 entitled ""Gastronomie""[5] Pascal Ory, a French historian, defines gastronomy as the establishment of rules of eating and drinking, an ""art of the table"", and distinguishes it from good cooking (bonne cuisine) or fine cooking (haute cuisine). Ory traces the origins of gastronomy back to the French reign of Louis XIV when people took interest in developing rules to discriminate between good and bad style and extended their thinking to define good culinary taste. The lavish and sophisticated cuisine and practices of the French court became the culinary model for the French. Alexandre Grimod de La Reynière wrote the gastronomic work Almanach des gourmands (1803), elevating the status of food discourse to a disciplined level based on his views of French tradition and morals. Grimod aimed to reestablish order lost after the revolution and institute gastronomy as a serious subject in France. Grimod expanded gastronomic literature to the three forms of the genre: the guidebook, the gastronomic treatise, and the gourmet periodical. The invention of gastronomic literature coincided with important cultural transformations in France that increased the relevance of the subject. The end of nobility in France changed how people consumed food; fewer wealthy households employed cooks and the new bourgeoisie class wanted to assert their status by consuming elitist food. The emergence of the restaurant satisfied these social needs and provided good food available for popular consumption. The center of culinary excellence in France shifted from Versailles to Paris, a city with a competitive and innovative culinary culture. The culinary commentary of Grimod and other gastronomes influenced the tastes and expectations of consumers in an unprecedented manner as a third party to the consumer-chef interaction.[5]
",5
5326,"The French origins of gastronomy explain the widespread use of French terminology in gastronomic literature. Pascal Ory criticizes this literature as conceptually vague; relying heavily on anecdotal evidence; and using confusing, poorly defined terminology. Nevertheless, gastronomy has grown from a marginalized subject in France to a serious and popular interest worldwide.[5]
",5
5327,"The derivative gourmet has come into use since the publication of Physiology of Taste (Physiologie du goût) an 1825 cooking treatise by Jean Anthelme Brillat-Savarin, a lawyer and politician who aimed to define classic French cuisine. While the work contains some flamboyant recipes, it goes into the theory of preparation of French dishes and hospitality.[6] According to Brillat-Savarin: ""Gastronomy is the knowledge and understanding of all that relates to man as he eats. Its purpose is to ensure the conservation of men, using the best food possible.""[6][7]
",5
5328,"Many writings on gastronomy throughout the world capture the thoughts and aesthetics of a culture's cuisine during a period in their history. Some works continue to define or influence the contemporary gastronomic thought and cuisine of their respective cultures.
",5
5329,"Some additional historical examples:
",5
5330,"
",5
5331,"Food is any substance[1] consumed to provide nutritional support for an organism. Food is usually of plant, animal or fungal origin, and contains essential nutrients, such as carbohydrates, fats, proteins, vitamins, or minerals. The substance is ingested by an organism and assimilated by the organism's cells to provide energy, maintain life, or stimulate growth. Different species of animals have different feeding behaviours that satisfy the needs of their unique metabolisms, often evolved to fill a specific ecological niche within specific geographical contexts. 
",5
5332,"Omnivorous humans are highly adaptable and have adapted to obtain food in many different ecosystems. Historically, humans secured food through two main methods: hunting and gathering and agriculture. As agricultural technologies increased, humans settled into agriculture lifestyles with diets shaped by the agriculture opportunities in their geography. Geographic and cultural differences has led to creation of numerous cuisines and culinary arts, including a wide array of ingredients, herbs, spices, techniques, and dishes. As cultures have mixed through forces like international trade and globalization, ingredients have become more widely available beyond their geographic and cultural origins, creating a cosmopolitan exchange of different food traditions and practices.
",5
5333,"Today, the majority of the food energy required by the ever-increasing population of the world is supplied by the industrial food industry, which produces food with intensive agriculture and distributes it through complex food processing and food distribution systems. This system of conventional agriculture relies heavily on fossil fuels, which means that the food and agricultural system is one of the major contributors to climate change, accountable for as much as 37% of total greenhouse gas emissions.[2] Addressing the carbon intensity of the food system and food waste are important mitigation measures in the global response to climate change.
",5
5334,"The food system has significant impacts on a wide range of other social and political issues including: sustainability, biological diversity, economics, population growth, water supply, and access to food. The right to food is a human right derived from the International Covenant on Economic, Social and Cultural Rights (ICESCR), recognizing the ""right to an adequate standard of living, including adequate food"", as well as the ""fundamental right to be free from hunger"". Because of these fundamental rights, food security is often a priority international policy activity; for example Sustainable Development Goal 2 ""Zero hunger"" is meant to eliminate hunger by 2030. Food safety and food security are monitored by international agencies like the International Association for Food Protection, World Resources Institute, World Food Programme, Food and Agriculture Organization, and International Food Information Council, and are often subject to national regulation by institutions, like the Food and Drug Administration in the United States.
",5
5335,"Most food has its origin in plants. Some food is obtained directly from plants; but even animals that are used as food sources are raised by feeding them food derived from plants. Cereal grain is a staple food that provides more food energy worldwide than any other type of crop.[3] Corn (maize), wheat, and rice – in all of their varieties – account for 87% of all grain production worldwide.[4][5][6] Most of the grain that is produced worldwide is fed to livestock.
",5
5336,"Some foods not from animal or plant sources include various edible fungi, especially mushrooms. Fungi and ambient bacteria are used in the preparation of fermented and pickled foods like leavened bread, alcoholic drinks, cheese, pickles, kombucha, and yogurt. Another example is blue-green algae such as Spirulina.[7] Inorganic substances such as salt, baking soda and cream of tartar are used to preserve or chemically alter an ingredient.
",5
5337,"Many plants and plant parts are eaten as food and around 2,000 plant species are cultivated for food. Many of these plant species have several distinct cultivars.[8]
",5
5338,"Seeds of plants are a good source of food for animals, including humans, because they contain the nutrients necessary for the plant's initial growth, including many healthful fats, such as omega fats. In fact, the majority of food consumed by human beings are seed-based foods. Edible seeds include cereals (corn, wheat, rice, et cetera), legumes (beans, peas, lentils, et cetera), and nuts. Oilseeds are often pressed to produce rich oils - sunflower, flaxseed, rapeseed (including canola oil), sesame, et cetera.[9]
",5
5339,"Seeds are typically high in unsaturated fats and, in moderation, are considered a health food. However, not all seeds are edible. Large seeds, such as those from a lemon, pose a choking hazard, while seeds from cherries and apples  contain cyanide which could be poisonous only if consumed in large volumes.[10]
",5
5340,"Fruits are the ripened ovaries of plants, including the seeds within. Many plants and animals have coevolved such that the fruits of the former are an attractive food source to the latter, because animals that eat the fruits may excrete the seeds some distance away. Fruits, therefore, make up a significant part of the diets of most cultures. Some botanical fruits, such as tomatoes, pumpkins, and eggplants, are eaten as vegetables.[11] (For more information, see list of fruits.)
",5
5341,"Vegetables are a second type of plant matter that is commonly eaten as food. These include root vegetables (potatoes and carrots), bulbs (onion family), leaf vegetables (spinach and lettuce), stem vegetables (bamboo shoots and asparagus), and inflorescence vegetables (globe artichokes and broccoli and other vegetables such as cabbage or cauliflower).[12]
",5
5342,"Animals are used as food either directly or indirectly by the products they produce. Meat is an example of a direct product taken from an animal, which comes from muscle systems or from organs (offal).
",5
5343,"Food products produced by animals include milk produced by mammary glands, which in many cultures is drunk or processed into dairy products (cheese, butter, etc.). In addition, birds and other animals lay eggs, which are often eaten, and bees produce honey, a reduced nectar from flowers, which is a popular sweetener in many cultures. Some cultures consume blood, sometimes in the form of blood sausage, as a thickener for sauces, or in a cured, salted form for times of food scarcity, and others use blood in stews such as jugged hare.[13]
",5
5344,"Some cultures and people do not consume meat or animal food products for cultural, dietary, health, ethical, or ideological reasons. Vegetarians choose to forgo food from animal sources to varying degrees. Vegans do not consume any foods that are or contain ingredients from an animal source.
",5
5345,"Adulteration is a legal term meaning that a food product fails to meet the legal standards. One form of adulteration is an addition of another substance to a food item in order to increase the quantity of the food item in raw form or prepared form, which may result in the loss of actual quality of food item. These substances may be either available food items or non-food items. Among meat and meat products some of the items used to adulterate are water or ice, carcasses, or carcasses of animals other than the animal meant to be consumed.[14]
",5
5346,"Camping food includes ingredients used to prepare food suitable for backcountry camping and backpacking. The foods differ substantially from the ingredients found in a typical home kitchen. The primary differences relate to campers' and backpackers' special needs for foods that have appropriate cooking time, perishability, weight, and nutritional content.
",5
5347,"To address these needs, camping food is often made up of either freeze-dried, precooked or dehydrated ingredients. Many campers use a combination of these foods.
",5
5348,"Freeze-drying requires the use of heavy machinery and is not something that most campers are able to do on their own. Freeze-dried ingredients are often considered superior to dehydrated ingredients however because they rehydrate at camp faster and retain more flavor than their dehydrated counterparts. Freeze-dried ingredients take so little time to rehydrate that they can often be eaten without cooking them first and have a texture similar to a crunchy chip.
",5
5349,"Dehydration can reduce the weight of the food by sixty to ninety percent by removing water through evaporation. Some foods dehydrate well, such as onions, peppers, and tomatoes.[15][16] Dehydration often produces a more compact, albeit slightly heavier, end result than freeze-drying.
",5
5350,"Surplus precooked military Meals, Meals, Ready-to-Eat (MREs) are sometimes used by campers. These meals contain pre-cooked foods in retort pouches. A retort pouch is a plastic and metal foil laminate pouch that is used as an alternative to traditional industrial canning methods.
",5
5351,"Diet food or dietetic food refers to any food or beverage whose recipe is altered to reduce fat, carbohydrates, abhor/adhore sugar in order to make it part of a weight loss program or diet. Such foods are usually intended to assist in weight loss or a change in body type, although bodybuilding supplements are designed to aid in gaining weight or muscle.
",5
5352,"The process of making a diet version of a food usually requires finding an acceptable low-food-energy substitute for some high-food-energy ingredient.[17] This can be as simple as replacing some or all of the food's sugar with a sugar substitute as is common with diet soft drinks such as Coca-Cola (for example Diet Coke). In some snacks, the food may be baked instead of fried thus reducing the food energy. In other cases, low-fat ingredients may be used as replacements.
",5
5353,"In whole grain foods, the higher fiber content effectively displaces some of the starch components of the flour. Since certain fibers have no food energy, this results in a modest energy reduction. Another technique relies on the intentional addition of other reduced-food-energy ingredients, such as resistant starch or dietary fiber, to replace part of the flour and achieve a more significant energy reduction.
",5
5354,"Finger food is food meant to be eaten directly using the hands, in contrast to food eaten with a knife and fork, spoon, chopsticks, or other utensils.[18]  In some cultures, food is almost always eaten with the hands; for example, Ethiopian cuisine is eaten by rolling various dishes up in injera bread.[19]  Foods considered street foods are frequently, though not exclusively, finger foods.
",5
5355,"In the western world, finger foods are often either appetizers (hors d'œuvres) or entree/main course items. Examples of these are miniature meat pies, sausage rolls, sausages on sticks, cheese and olives on sticks, chicken drumsticks or wings, spring rolls, miniature quiches, samosas, sandwiches, Merenda or other such based foods, such as pitas or items in buns, bhajjis, potato wedges, vol au vents, several other such small items and risotto balls (arancini). Other well-known foods that are generally eaten with the hands include hamburgers, pizza, Chips, hot dogs, fruit and bread.
",5
5356,"In East Asia, foods like pancakes or flatbreads (bing 饼) and street foods such as chuan (串, also pronounced chuan) are often eaten with the hands.
",5
5357,"Fresh food is food which has not been preserved and has not spoiled yet. For vegetables and fruits, this means that they have been recently harvested and treated properly postharvest; for meat, it has recently been slaughtered and butchered; for fish, it has been recently caught or harvested and kept cold.
",5
5358,"Dairy products are fresh and will spoil quickly. Thus, fresh cheese is cheese which has not been dried or salted for aging. Soured cream may be considered ""fresh"" (crème fraîche).
",5
5359,"Fresh food has not been dried, smoked, salted, frozen, canned, pickled, or otherwise preserved.[20]
",5
5360,"Freezing food preserves it from the time it is prepared to the time it is eaten. Since early times, farmers, fishermen, and trappers have preserved grains and produce in unheated buildings during the winter season.[21] Freezing food slows down decomposition by turning residual moisture into ice, inhibiting the growth of most bacterial species. In the food commodity industry, there are two processes: mechanical and cryogenic (or flash freezing). The kinetics of the freezing is important to preserve food quality and texture. Quicker freezing generates smaller ice crystals and maintains cellular structure. Cryogenic freezing is the quickest freezing technology available utilizing the extremely low temperature of liquid nitrogen  −196 °C (−320 °F).[22]
",5
5361,"Preserving food in domestic kitchens during modern times is achieved using household freezers. Accepted advice to householders was to freeze food on the day of purchase. An initiative by a supermarket group in 2012 (backed by the UK's Waste & Resources Action Programme) promotes the freezing of food ""as soon as possible up to the product's 'use by' date"". The Food Standards Agency was reported as supporting the change, providing the food had been stored correctly up to that time.[23]
",5
5362,"A functional food is a food given an additional function (often one related to health-promotion or disease prevention) by adding new ingredients or more of existing ingredients.[24] The term may also apply to traits purposely bred into existing edible plants, such as purple or gold potatoes having enriched anthocyanin or carotenoid contents, respectively.[25] Functional foods may be ""designed to have physiological benefits and/or reduce the risk of chronic disease beyond basic nutritional functions, and may be similar in appearance to conventional food and consumed as part of a regular diet"".[26]
",5
5363,"The term was first used in Japan in the 1980s where there is a government approval process for functional foods called Foods for Specified Health Use (FOSHU).[27]
",5
5364,"Health food is food marketed to provide human health effects beyond a normal healthy diet required for human nutrition. Foods marketed as health foods may be part of one or more categories, such as natural foods, organic foods, whole foods,  vegetarian foods or dietary supplements. These products may be sold in health food stores or in the health food or organic sections of grocery stores.
",5
5365,"A healthy diet is a diet that helps to maintain or improve overall health. A healthy diet provides the body with essential nutrition: fluid, macronutrients, micronutrients, and adequate calories.[28][29]
",5
5366,"For people who are healthy, a healthy diet is not complicated and contains mostly fruits, vegetables, and whole grains, and includes little to no processed food and sweetened beverages.  The requirements for a healthy diet can be met from a variety of plant-based and animal-based foods, although a non-animal source of vitamin B12 is needed for those following a vegan diet.[30]  Various nutrition guides are published by medical and governmental institutions to educate individuals on what they should be eating to be healthy. Nutrition facts labels are also mandatory in some countries to allow consumers to choose between foods based on the components relevant to health.[31]
",5
5367,"A healthy lifestyle includes getting exercise every day along with eating a healthy diet. A healthy lifestyle may lower disease risks, such as obesity, heart disease, type 2 diabetes, hypertension and cancer.[28][32]
",5
5368,"There are specialized healthy diets, called medical nutrition therapy, for people with various diseases or conditions.  There are also prescientific ideas about such specialized diets, as in dietary therapy in traditional Chinese medicine.
",5
5369,"The World Health Organization (WHO) makes the following 5 recommendations with respect to both populations and individuals:[33]
",5
5370,"Live food is living food for carnivorous or omnivorous animals kept in captivity; in other words, small animals such as insects or mice fed to larger carnivorous or omnivorous species kept either in a zoo or as a pet.
",5
5371,"Live food is commonly used as feed for a variety of species of exotic pets and zoo animals, ranging from alligators to various snakes, frogs and lizards, but also including other, non-reptile, non-amphibian carnivores and omnivores (for instance, skunks, which are omnivorous mammals, can technically be fed a limited amount of live food, though this is not a common practice). Common live food ranges from crickets (used as an inexpensive form of feed for carnivorous and omnivorous reptiles such as bearded dragons and commonly available in pet stores for this reason), waxworms, mealworms and to a lesser extent cockroaches and locusts, to small birds and mammals such as mice or chickens.
",5
5372,"Medical foods are foods that are specially formulated and intended for the dietary management of a disease that has distinctive nutritional needs that cannot be met by normal diet alone. In the United States they were defined in the Food and Drug Administration's 1988 Orphan Drug Act Amendments[36] and are subject to the general food and safety labeling requirements of the Federal Food, Drug, and Cosmetic Act. In Europe the European Food Safety Authority established definitions for ""foods for special medical purposes"" (FSMPs) in 2015.[37]
",5
5373,"Medical foods, called ""food for special medical purposes"" in Europe,[38] are distinct from the broader category of foods for special dietary use, from traditional foods that bear a health claim, and from dietary supplements. In order to be considered a medical food the product must, at a minimum:[39][40]
",5
5374,"Medical foods can be classified into the following categories:
",5
5375,"Natural foods and ""all-natural foods"" are widely used terms in food labeling and marketing with a variety of definitions, most of which are vague. The term is often assumed to imply foods that are not processed and whose ingredients are all natural products (in the chemist's sense of that term), thus conveying an appeal to nature. But the lack of standards in most jurisdictions means that the term assures nothing. In some countries, the term ""natural"" is defined and enforced. In others, such as the United States, it is not enforced.
",5
5376,"“Natural foods” are often assumed to be foods that are not processed, or do not contain any food additives, or do not contain particular additives such as hormones, antibiotics, sweeteners, food colors, or flavorings that were not originally in the food.[41]  In fact, many people (63%) when surveyed showed a preference for products labeled ""natural"" compared to the unmarked counterparts, based on the common belief (86% of polled consumers) that the term ""natural"" indicated that the food does not contain any artificial ingredients.[42] The terms are variously used and misused on labels and in advertisements.[43]
",5
5377,"The international Food and Agriculture Organization’s Codex Alimentarius does not recognize the term “natural” but does have a standard for organic foods.[44]
",5
5378,"A negative-calorie food is food that supposedly requires more food energy to be digested than the food provides. Its thermic effect or specific dynamic action – the caloric ""cost"" of digesting the food – would be greater than its food energy content. Despite its recurring popularity in dieting guides, there is no scientific evidence supporting the idea that any food is calorically negative. While some chilled beverages are calorically negative, the effect is minimal[45] and drinking large amounts of water can be dangerous.
",5
5379,"Organic food is food produced by methods that comply with the standards of organic farming. Standards vary worldwide, but organic farming in general features practices that strive to cycle resources, promote ecological balance, and conserve biodiversity. Organizations regulating organic products may restrict the use of certain pesticides and fertilizers in farming. In general, organic foods are also usually not processed using irradiation, industrial solvents or synthetic food additives.[46]
",5
5380,"Currently, the European Union, the United States, Canada, Mexico, Japan, and many other countries require producers to obtain special certification in order to market food as organic within their borders. In the context of these regulations, organic food is produced in a way that complies with organic standards set by regional organizations, national governments, and international organizations. Although the produce of kitchen gardens may be organic, selling food with an organic label is regulated by governmental food safety authorities, such as the US Department of Agriculture (USDA) or European Commission (EC).[47]
",5
5381,"Fertilizing and the use of pesticides in conventional farming has caused, and is causing, enormous damage worldwide to local ecosystems, biodiversity, groundwater and drinking water supplies, and sometimes farmer health and fertility. These environmental, economic and health issues are intended to be minimized or avoided in organic farming. From a consumers perspective, there is not sufficient evidence in scientific and medical literature to support claims that organic food is safer or healthier to eat than conventionally grown food. While there may be some differences in the nutrient and antinutrient contents of organically- and conventionally-produced food, the variable nature of food production and handling makes it difficult to generalize results.[48][49][50][51][52] Claims that organic food tastes better are generally not supported by tests.[49][53]
",5
5382,"Peasant foods are dishes specific to a particular culture, made from accessible and inexpensive ingredients, and usually prepared and seasoned to make them more palatable. They often form a significant part of the diets of people who live in poverty, or have a lower income compared to the average for their society or country.
",5
5383,"Peasant foods have been described as being the diet of peasants, that is, tenant or poorer farmers and their farm workers,[54] and by extension, of other cash-poor people. They may use ingredients, such as offal and less-tender cuts of meat, which are not as marketable as a cash crop. Characteristic recipes often consist of hearty one-dish meals, in which chunks of meat and various vegetables are eaten in a savory broth, with bread or other staple food. Sausages are also amenable to varied readily available ingredients, and they themselves tend to contain offal and grains.
",5
5384,"Peasant foods often involve skilled preparation by knowledgeable cooks using inventiveness and skills passed down from earlier generations. Such dishes are often prized as ethnic foods by other cultures and by descendants of the native culture who still desire these traditional dishes.[citation needed]
",5
5385,"Prison food is the term for meals served to prisoners while incarcerated in correctional institutions. While some prisons prepare their own food, many use staff from on-site catering companies. Many prisons today support the requirements of specific religions, as well as vegetarianism.[55] It is said that prison food of many developed countries is adequate to maintain health and dieting.[56][unreliable source?]
",5
5386,"""Seasonal"" here refers to the times of the year when the harvest or the flavor of a given type of food is at its peak. This is usually the time when the item is harvested, with some exceptions; an example being sweet potatoes which are best eaten quite a while after harvest. It also appeals to people who prefer a low carbon diet that reduces the greenhouse gas emissions resulting from food consumption (Food miles).
",5
5387,"Shelf-stable food (sometimes ambient food) is food of a type that can be safely stored at room temperature in a sealed container. This includes foods that would normally be stored refrigerated but which have been processed so that they can be safely stored at room or ambient temperature for a usefully long shelf life.
",5
5388,"Various food preservation and packaging techniques are used to extend a food's shelf life.  Decreasing the amount of available water in a product, increasing its acidity, or irradiating[57] or otherwise sterilizing the food and then sealing it in an air-tight container are all ways of depriving bacteria of suitable conditions in which to thrive. All of these approaches can all extend a food's shelf life without unacceptably changing its taste or texture.
",5
5389,"For some foods, alternative ingredients can be used. Common oils and fats become rancid relatively quickly if not refrigerated; replacing them with hydrogenated oils delays the onset of rancidity, increasing shelf life. This is a common approach in industrial food production, but recent concerns about health hazards associated with trans fats have led to their strict control in several jurisdictions.[58] Even where trans fats are not prohibited, in many places there are new labeling laws (or rules), which require information to be printed on packages, or to be published elsewhere, about the amount of trans fat contained in certain products.
",5
5390,"Space food is a type of food product created and processed for consumption by astronauts in outer space. The food has specific requirements of providing balanced nutrition for individuals working in space while being easy and safe to store, prepare and consume in the machinery-filled weightless environments of crewed spacecraft.
",5
5391,"In recent years, space food has been used by various nations engaging in space programs as a way to share and show off their cultural identity and facilitate intercultural communication. Although astronauts consume a wide variety of foods and beverages in space, the initial idea from The Man in Space Committee of the Space Science Board in 1963 was to supply astronauts with a formula diet that would supply all the needed vitamins and nutrients.[59]
",5
5392,"Traditional foods are foods and dishes that are passed through generations[60] or which have been consumed many generations.[61] Traditional foods and dishes are traditional in nature, and may have a historic precedent in a national dish, regional cuisine[60] or local cuisine. Traditional foods and beverages may be produced as homemade, by restaurants and small manufacturers, and by large food processing plant facilities.[62]
",5
5393,"Some traditional foods have geographical indications and traditional specialities in the European Union designations per European Union schemes of geographical indications and traditional specialties: Protected designation of origin (PDO), Protected geographical indication (PGI) and Traditional specialities guaranteed (TSG). These standards serve to promote and protect names of quality agricultural products and foodstuffs.[63]
",5
5394,"This article also includes information about traditional beverages.
",5
5395,"Whole foods are plant foods that are unprocessed and unrefined, or processed and refined as little as possible, before being consumed.[64] Examples of whole foods include whole grains, tubers, legumes, fruits, vegetables.[65]
",5
5396,"There is some confusion over the usage of the term surrounding the inclusion of certain foods, in particular animal foods. The modern usage of the term whole foods diet is now widely synonymous with ""whole foods plant-based diet"" with animal products, oil and salt no longer constituting whole foods.[66]
",5
5397,"The earliest use of the term in the post-industrial age appears to be in 1946 in The Farmer, a quarterly magazine published and edited from his farm by F. Newman Turner, a writer and pioneering organic farmer. The magazine sponsored the establishment of the Producer-Consumer Whole Food Society Ltd, with Newman Turner as president and Derek Randal as vice-president.[67] Whole food was defined as ""mature produce of field, orchard, or garden without subtraction, addition, or alteration grown from seed without chemical dressing, in fertile soil manured solely with animal and vegetable wastes, and composts therefrom, and ground, raw rock and without chemical manures, sprays, or insecticides,"" having intent to connect suppliers and the growing public demand for such food.[67] Such diets are rich in whole and unrefined foods, like whole grains, dark green and yellow/orange-fleshed vegetables and fruits, legumes, nuts and seeds.[64]
",5
5398,"Animals, specifically humans, have five different types of tastes: sweet, sour, salty, bitter, and umami. As animals have evolved, the tastes that provide the most energy (sugar and fats) are the most pleasant to eat while others, such as bitter, are not enjoyable.[68] Water, while important for survival, has no taste.[69] Fats, on the other hand, especially saturated fats, are thicker and rich and are thus considered more enjoyable to eat.
",5
5399,"Generally regarded as the most pleasant taste, sweetness is almost always caused by a type of simple sugar such as glucose or fructose, or disaccharides such as sucrose, a molecule combining glucose and fructose.[70] Complex carbohydrates are long chains and thus do not have the sweet taste. Artificial sweeteners such as sucralose are used to mimic the sugar molecule, creating the sensation of sweet, without the calories. Other types of sugar include raw sugar, which is known for its amber color, as it is unprocessed. As sugar is vital for energy and survival, the taste of sugar is pleasant.
",5
5400,"The stevia plant contains a compound known as steviol which, when extracted, has 300 times the sweetness of sugar while having minimal impact on blood sugar.[71]
",5
5401,"Sourness is caused by the taste of acids, such as vinegar in alcoholic beverages. Sour foods include citrus, specifically lemons, limes, and to a lesser degree oranges. Sour is evolutionarily significant as it is a sign for a food that may have gone rancid due to bacteria.[72] Many foods, however, are slightly acidic, and help stimulate the taste buds and enhance flavor.
",5
5402,"Saltiness is the taste of alkali metal ions such as sodium and potassium. It is found in almost every food in low to moderate proportions to enhance flavor, although to eat pure salt is regarded as highly unpleasant. There are many different types of salt, with each having a different degree of saltiness, including sea salt, fleur de sel, kosher salt, mined salt, and grey salt. Other than enhancing flavor, its significance is that the body needs and maintains a delicate electrolyte balance, which is the kidney's function. Salt may be iodized, meaning iodine has been added to it, a necessary nutrient that promotes thyroid function. Some canned foods, notably soups or packaged broths, tend to be high in salt as a means of preserving the food longer. Historically salt has long been used as a meat preservative as salt promotes water excretion. Similarly, dried foods also promote food safety.[73]
",5
5403,"Bitterness is a sensation often considered unpleasant characterized by having a sharp, pungent taste. Unsweetened dark chocolate, caffeine, lemon rind, and some types of fruit are known to be bitter.
",5
5404,"Umami (/uːˈmɑːmi/ from Japanese: 旨味 [ɯmami]), or savoriness, is one of the five basic tastes.[74][75] It has been described as savory and is characteristic of broths and cooked meats.[76][77]
",5
5405,"People taste umami through taste receptors that typically respond to glutamates and nucleotides, which are widely present in meat broths and fermented products. Glutamates are commonly added to some foods in the form of monosodium glutamate (MSG), and nucleotides are commonly added in the form of inosine monophosphate (IMP) or guanosine monophosphate (GMP).[78][79][80] Since umami has its own receptors rather than arising out of a combination of the traditionally recognized taste receptors, scientists now consider umami to be a distinct taste.[75][81]
",5
5406,"Foods that have a strong umami flavor include broths, gravies, soups, shellfish, fish (including fish sauce and preserved fish such as maldive fish), tomatoes, mushrooms, hydrolyzed vegetable protein, meat extract, yeast extract, cheeses, and soy sauce.
",5
5407,"Many scholars claim that the rhetorical function of food is to represent the culture of a country, and that it can be used as a form of communication. According to Goode, Curtis and Theophano, food ""is the last aspect of an ethnic culture to be lost"".[82]
",5
5408,"Many cultures have a recognizable cuisine, a specific set of cooking traditions using various spices or a combination of flavors unique to that culture, which evolves over time. Other differences include preferences (hot or cold, spicy, etc.) and practices, the study of which is known as gastronomy. Many cultures have diversified their foods by means of preparation, cooking methods, and manufacturing. This also includes a complex food trade which helps the cultures to economically survive by way of food, not just by consumption.
",5
5409,"Some popular types of ethnic foods include Italian, French, Japanese, Chinese, American, Cajun, Thai, African, Indian and Nepalese. Various cultures throughout the world study the dietary analysis of food habits. While evolutionarily speaking, as opposed to culturally, humans are omnivores, religion and social constructs such as morality, activism, or environmentalism will often affect which foods they will consume. Food is eaten and typically enjoyed through the sense of taste, the perception of flavor from eating and drinking. Certain tastes are more enjoyable than others, for evolutionary purposes.
",5
5410,"Aesthetically pleasing and eye-appealing food presentations can encourage people to consume foods. A common saying is that people ""eat with their eyes"". Food presented in a clean and appetizing way will encourage a good flavor, even if unsatisfactory.[83][84]
",5
5411,"Texture plays a crucial role in the enjoyment of eating foods. Contrasts in textures, such as something crunchy in an otherwise smooth dish, may increase the appeal of eating it. Common examples include adding granola to yogurt, adding croutons to a salad or soup, and toasting bread to enhance its crunchiness for a smooth topping, such as jam or butter.[85]
",5
5412,"Another universal phenomenon regarding food is the appeal of contrast in taste and presentation. For example, such opposite flavors as sweetness and saltiness tend to go well together, as in kettle corn and nuts.
",5
5413,"While many foods can be eaten raw, many also undergo some form of preparation for reasons of safety, palatability, texture, or flavor. At the simplest level this may involve washing, cutting, trimming, or adding other foods or ingredients, such as spices. It may also involve mixing, heating or cooling, pressure cooking, fermentation, or combination with other food. In a home, most food preparation takes place in a kitchen. Some preparation is done to enhance the taste or aesthetic appeal; other preparation may help to preserve the food; others may be involved in cultural identity. A meal is made up of food which is prepared to be eaten at a specific time and place.[86]
",5
5414,"The preparation of animal-based food usually involves slaughter, evisceration, hanging, portioning, and rendering. In developed countries, this is usually done outside the home in slaughterhouses, which are used to process animals en masse for meat production. Many countries regulate their slaughterhouses by law. For example, the United States has established the Humane Slaughter Act of 1958, which requires that an animal be stunned before killing. This act, like those in many countries, exempts slaughter in accordance with religious law, such as kosher, shechita, and dhabīḥah halal. Strict interpretations of kashrut require the animal to be fully aware when its carotid artery is cut.[87]
",5
5415,"On the local level, a butcher may commonly break down larger animal meat into smaller manageable cuts, and pre-wrap them for commercial sale or wrap them to order in butcher paper. In addition, fish and seafood may be fabricated into smaller cuts by a fishmonger. However, fish butchery may be done onboard a fishing vessel and quick-frozen for the preservation of quality.[88]
",5
5416,"Certain cultures highlight animal and vegetable foods in a raw state. Salads consisting of raw vegetables or fruits are common in many cuisines. Sashimi in Japanese cuisine consists of raw sliced fish or other meat, and sushi often incorporates raw fish or seafood. Steak tartare and salmon tartare are dishes made from diced or ground raw beef or salmon, mixed with various ingredients and served with baguettes, brioche, or frites.[89] In Italy, carpaccio is a dish of very thinly sliced raw beef, drizzled with a vinaigrette made with olive oil.[90] The health food movement known as raw foodism promotes a mostly vegan diet of raw fruits, vegetables, and grains prepared in various ways, including juicing, food dehydration, sprouting, and other methods of preparation that do not heat the food above 118 °F (47.8 °C).[91] An example of a raw meat dish is ceviche, a Latin American dish made with raw meat that is ""cooked"" from the highly acidic citric juice from lemons and limes along with other aromatics such as garlic.
",5
5417,"The term ""cooking"" encompasses a vast range of methods, tools, and combinations of ingredients to improve the flavor or digestibility of food. Cooking technique, known as culinary art, generally requires the selection, measurement, and combining of ingredients in an ordered procedure in an effort to achieve the desired result. Constraints on success include the variability of ingredients, ambient conditions, tools, and the skill of the individual cook.[92] The diversity of cooking worldwide is a reflection of the myriad nutritional, aesthetic, agricultural, economic, cultural, and religious considerations that affect it.[93]
",5
5418,"Cooking requires applying heat to a food which usually, though not always, chemically changes the molecules, thus changing its flavor, texture, appearance, and nutritional properties.[94] Cooking certain proteins, such as egg whites, meats, and fish, denatures the protein, causing it to firm. There is archaeological evidence of roasted foodstuffs at Homo erectus campsites dating from 420,000 years ago.[95] Boiling as a means of cooking requires a container, and has been practiced at least since the 10th millennium BC with the introduction of pottery.[96]
",5
5419,"There are many different types of equipment used for cooking.
",5
5420,"Ovens are mostly hollow devices that get very hot (up to 500 °F (260 °C)) and are used for baking or roasting and offer a dry-heat cooking method. Different cuisines will use different types of ovens. For example, Indian culture uses a tandoor oven, which is a cylindrical clay oven which operates at a single high temperature.[97] Western kitchens use variable temperature convection ovens, conventional ovens, toaster ovens, or non-radiant heat ovens like the microwave oven. Classic Italian cuisine includes the use of a brick oven containing burning wood. Ovens may be wood-fired, coal-fired, gas, electric, or oil-fired.[98]
",5
5421,"Various types of cook-tops are used as well. They carry the same variations of fuel types as the ovens mentioned above. Cook-tops are used to heat vessels placed on top of the heat source, such as a sauté pan, sauce pot, frying pan, or pressure cooker. These pieces of equipment can use either a moist or dry cooking method and include methods such as steaming, simmering, boiling, and poaching for moist methods, while the dry methods include sautéing, pan frying, and deep-frying.[99]
",5
5422,"In addition, many cultures use grills for cooking. A grill operates with a radiant heat source from below, usually covered with a metal grid and sometimes a cover. An open-pit barbecue in the American south is one example along with the American style outdoor grill fueled by wood, liquid propane, or charcoal along with soaked wood chips for smoking.[100] A Mexican style of barbecue is called barbacoa, which involves the cooking of meats such as whole sheep over an open fire. In Argentina, an asado (Spanish for ""grilled"") is prepared on a grill held over an open pit or fire made upon the ground, on which a whole animal or smaller cuts are grilled.[101]
",5
5423,"Restaurants employ chefs to prepare the food, and waiters to serve customers at the table.[102] The term restaurant comes from an old term for a restorative meat broth; this broth (or bouillon) was served in elegant outlets in Paris from the mid 18th century.[103][104] These refined ""restaurants"" were a marked change from the usual basic eateries such as inns and taverns,[104] and some had developed from early Parisian cafés, such as Café Procope, by first serving bouillon, then adding other cooked food to their menus.[105]
",5
5424,"Commercial eateries existed during the Roman period, with evidence of 150 ""thermopolia"", a form of fast food restaurant, found in Pompeii,[106] and urban sales of prepared foods may have existed in China during the Song dynasty.[107]
",5
5425,"In 2005, the population of the United States spent $496 billion on out-of-home dining. Expenditures by type of out-of-home dining were as follows: 40% in full-service restaurants, 37.2% in limited service restaurants (fast food), 6.6% in schools or colleges, 5.4% in bars and vending machines, 4.7% in hotels and motels, 4.0% in recreational places, and 2.2% in others, which includes military bases.[108][better source needed][relevant?  – discuss]
",5
5426,"Food systems have complex economic and social value chains that effect many parts of the global economy.
",5
5427,"Most food has always been obtained through agriculture. With increasing concern over both the methods and products of modern industrial agriculture, there has been a growing trend toward sustainable agricultural practices. This approach, partly fueled by consumer demand, encourages biodiversity, local self-reliance and organic farming methods.[109] Major influences on food production include international organizations (e.g. the World Trade Organization and Common Agricultural Policy), national government policy (or law), and war.[110]
",5
5428,"Several organisations have begun calling for a new kind of agriculture in which agroecosystems provide food but also support vital ecosystem services so that soil fertility and biodiversity are maintained rather than compromised. According to the International Water Management Institute and UNEP, well-managed agroecosystems not only provide food, fiber and animal products, they also provide services such as flood mitigation, groundwater recharge, erosion control and habitats for plants, birds, fish and other animals.[111]
",5
5429,"Packaged foods are manufactured outside the home for purchase. This can be as simple as a butcher preparing meat, or as complex as a modern international food industry. Early food processing techniques were limited by available food preservation, packaging, and transportation. This mainly involved salting, curing, curdling, drying, pickling, fermenting, and smoking.[112] Food manufacturing arose during the industrial revolution in the 19th century.[113] This development took advantage of new mass markets and emerging technology, such as milling, preservation, packaging and labeling, and transportation. It brought the advantages of pre-prepared time-saving food to the bulk of ordinary people who did not employ domestic servants.[114]
",5
5430,"At the start of the 21st century, a two-tier structure has arisen, with a few international food processing giants controlling a wide range of well-known food brands. There also exists a wide array of small local or national food processing companies.[115] Advanced technologies have also come to change food manufacture. Computer-based control systems, sophisticated processing and packaging methods, and logistics and distribution advances can enhance product quality, improve food safety, and reduce costs.[114]
",5
5431,"The World Bank reported that the European Union was the top food importer in 2005, followed at a distance by the US and Japan. Britain's need for food was especially well-illustrated in World War II.  Despite the implementation of food rationing, Britain remained dependent on food imports and the result was a long term engagement in the Battle of the Atlantic.
",5
5432,"Food is traded and marketed on a global basis. The variety and availability of food is no longer restricted by the diversity of locally grown food or the limitations of the local growing season.[116] Between 1961 and 1999, there was a 400% increase in worldwide food exports.[117] Some countries are now economically dependent on food exports, which in some cases account for over 80% of all exports.[118]
",5
5433,"In 1994, over 100 countries became signatories to the Uruguay Round of the General Agreement on Tariffs and Trade in a dramatic increase in trade liberalization. This included an agreement to reduce subsidies paid to farmers, underpinned by the WTO enforcement of agricultural subsidy, tariffs, import quotas, and settlement of trade disputes that cannot be bilaterally resolved.[119] Where trade barriers are raised on the disputed grounds of public health and safety, the WTO refer the dispute to the Codex Alimentarius Commission, which was founded in 1962 by the United Nations Food and Agriculture Organization and the World Health Organization. Trade liberalization has greatly affected world food trade.[120]
",5
5434,"Food marketing brings together the producer and the consumer. The marketing of even a single food product can be a complicated process involving many producers and companies. For example, fifty-six companies are involved in making one can of chicken noodle soup. These businesses include not only chicken and vegetable processors but also the companies that transport the ingredients and those who print labels and manufacture cans.[121] The food marketing system is the largest direct and indirect non-government employer in the United States.
",5
5435,"In the pre-modern era, the sale of surplus food took place once a week when farmers took their wares on market day into the local village marketplace. Here food was sold to grocers for sale in their local shops for purchase by local consumers.[93][114] With the onset of industrialization and the development of the food processing industry, a wider range of food could be sold and distributed in distant locations. Typically early grocery shops would be counter-based shops, in which purchasers told the shop-keeper what they wanted, so that the shop-keeper could get it for them.[93][122]
",5
5436,"In the 20th century, supermarkets were born. Supermarkets brought with them a self service approach to shopping using shopping carts, and were able to offer quality food at lower cost through economies of scale and reduced staffing costs. In the latter part of the 20th century, this has been further revolutionized by the development of vast warehouse-sized, out-of-town supermarkets, selling a wide range of food from around the world.[123]
",5
5437,"Unlike food processors, food retailing is a two-tier market in which a small number of very large companies control a large proportion of supermarkets. The supermarket giants wield great purchasing power over farmers and processors, and strong influence over consumers. Nevertheless, less than 10% of consumer spending on food goes to farmers, with larger percentages going to advertising, transportation, and intermediate corporations.[124]
",5
5438,"Food prices refer to the average price level for food across countries, regions and on a global scale.[125] Food prices have an impact on producers and consumers of food.   
",5
5439,"Price levels depend on the food production process, including food marketing and food distribution. Fluctuation in food prices is determined by a number of compounding factors.[126] Geopolitical events, global demand, exchange rates,[127] government policy, diseases and crop yield, energy costs, availability of natural resources for agriculture,[128] food speculation,[129][130][131] changes in the use of soil and weather events have a direct impact on the increase or decrease of food prices.[132]
",5
5440,"The consequences of food price fluctuation are multiple. Increases in food prices endangers food security, particularly for developing countries, and can cause social unrest.[133][134][135] Increases in food prices is related to disparities in diet quality and health,[136] particularly among vulnerable populations, such as women and children.[137]
",5
5441,"Food prices will on average continue to rise due to a variety of reasons. Growing world population will put more pressure on the supply and demand. Climate change will increase extreme weather events, including droughts, storms and heavy rain, and overall increases in temperature will have an impact on food production.[138]
",5
5442,"Food speculation is betting on food prices (unregulated) financial markets. Food speculation by global players like banks, hedge funds or pension funds is alleged to cause price swings in staple foods such as wheat, maize and soy – even though too large price swings in an idealized economy are theoretically ruled out: Adam Smith in 1776 reasoned that the only way to make money from commodities trading is by buying low and selling high, which has the effect of smoothing out price swings and mitigating shortages.[139][140] For the actors, the apparently random swings are predictable, which means potential huge profits. For the global poor, food speculation and resulting price peaks may result in increased poverty or even famine.[141]
",5
5443,"In contrast to food hoarding, speculation does not mean that real food shortages or scarcity need to be evoked, the price changes are only due to trading activity.[142]
",5
5444,"Because of its centrality to human life, problems related to access, quality and production of food effect every aspect of human life.
",5
5445,"Between the extremes of optimal health and death from starvation or malnutrition, there is an array of disease states that can be caused or alleviated by changes in diet. Deficiencies, excesses, and imbalances in diet can produce negative impacts on health, which may lead to various health problems such as scurvy, obesity, or osteoporosis, diabetes, cardiovascular diseases as well as psychological and behavioral problems. The science of nutrition attempts to understand how and why specific dietary aspects influence health.
",5
5446,"Nutrients in food are grouped into several categories. Macronutrients are fat, protein, and carbohydrates. Micronutrients are the minerals and vitamins. Additionally, food contains water and dietary fiber.
",5
5447,"As previously discussed, the body is designed by natural selection to enjoy sweet and fattening foods for evolutionary diets, ideal for hunters and gatherers. Thus, sweet and fattening foods in nature are typically rare and are very pleasurable to eat. In modern times, with advanced technology, enjoyable foods are easily available to consumers. Unfortunately, this promotes obesity in adults and children alike.
",5
5448,"Food deprivation leads to malnutrition and ultimately starvation. This is often connected with famine, which involves the absence of food in entire communities. This can have a devastating and widespread effect on human health and mortality. Rationing is sometimes used to distribute food in times of shortage, most notably during times of war.[110]
",5
5449,"Starvation is a significant international problem. Approximately 815 million people are undernourished, and over 16,000 children die per day from hunger-related causes.[145] Food deprivation is regarded as a deficit need in Maslow's hierarchy of needs and is measured using famine scales.[146]
",5
5450,"Food waste or food loss is food that is not eaten. The causes of food waste or loss are numerous and occur throughout the food system, during production, processing, distribution, retail and consumption. Global food loss and waste[148] amount to between one-third[149] and one-half[150] of all food produced. In low-income countries, most loss occurs during production, while in developed countries much food – about 100 kilograms (220 lb) per person per year – is wasted at the consumption stage.[151]
",5
5451,"Food waste is a major part of the impact of agriculture on climate change. and other environmental issues. The Food and Agricultural Organization estimated in 2014 that food waste lost causes a global economic, environmental and social cost of $2.6 trillion a year and is responsible for 8 percent of global greenhouse gas emissions.[152] Moreover, food waste that is not handled or reclaimed properly, i.e. through composting, can have many negative environmental consequences. For example, landfill gas from anaerobic digestion of organic matter is a major source of the greenhouse gas methane, and un-reclaimed phosphorus in food waste, leads to further phosphate mining. Moreover reducing food waste in all parts of the food system is an important part of reducing the environmental impact of agriculture, by reducing the total amount of water, land and other resources needed to feed the global community.
",5
5452,"Food policy is the area of public policy concerning how food is produced, processed, distributed, purchased, or provided. Food policies are designed to influence the operation of the food and agriculture system balanced with ensuring human health needs. This often includes decision-making around production and processing techniques, marketing, availability, utilization and consumption of food, in the interest of meeting or furthering social objectives. Food policy can be promulgated on any level, from local to global, and by a government agency, business, or organization. Food policymakers engage in activities such as regulation of food-related industries, establishing eligibility standards for food assistance programs for the poor, ensuring safety of the food supply, food labeling, and even the qualifications of a product to be considered organic.[154]
",5
5453,"Most food policy is initiated at the domestic level for purposes of ensuring a safe and adequate food supply for the citizenry.[155] In a developing nation, there are three main objectives for food policy: to protect the poor from crises, to develop long-run markets that enhance efficient resource use, and to increase food production that will in turn promote an increase in income.[156]
",5
5454,"Food policy comprises the mechanisms by which food-related matters are addressed or administered by governments, including international bodies or networks, and by public institutions or private organizations. Agricultural producers often bear the burden of governments' desire to keep food prices sufficiently low for growing urban populations. Low prices for consumers can be a disincentive for farmers to produce more food, often resulting in hunger, poor trade prospects, and an increased need for food imports.[155]
",5
5455,"Some countries list a legal definition of food, often referring them with the word foodstuff. These countries list food as any item that is to be processed, partially processed, or unprocessed for consumption. The listing of items included as food includes any substance intended to be, or reasonably expected to be, ingested by humans. In addition to these foodstuffs, drink, chewing gum, water, or other items processed into said food items are part of the legal definition of food. Items not included in the legal definition of food include animal feed, live animals (unless being prepared for sale in a market), plants prior to harvesting, medicinal products, cosmetics, tobacco and tobacco products, narcotic or psychotropic substances, and residues and contaminants.[158]
",5
5456,"The right to food, and its variations, is a human right protecting the right of people to feed themselves in dignity, implying that sufficient food is available, that people have the means to access it, and that it adequately meets the individual's dietary needs. The right to food protects the right of all human beings to be free from hunger, food insecurity and malnutrition.[162] The right to food does not imply that governments have an obligation to hand out free food to everyone who wants it, or a right to be fed. However, if people are deprived of access to food for reasons beyond their control, for example, because they are in detention, in times of war or after natural disasters, the right requires the government to provide food directly.[163]
",5
5457,"The right is derived from the International Covenant on Economic, Social and Cultural Rights[163] which has 170 state parties as of April 2020.[160] States that sign the covenant agree to take steps to the maximum of their available resources to achieve progressively the full realization of the right to adequate food, both nationally and internationally.[164][162] In a total of 106 countries the right to food is applicable either via constitutional arrangements of various forms or via direct applicability in law of various international treaties in which the right to food is protected.[165]
",5
5458,"At the 1996 World Food Summit, governments reaffirmed the right to food and committed themselves to halve the number of hungry and malnourished from 840 to 420 million by 2015. However, the number has increased over the past years, reaching an infamous record in 2009 of more than 1 billion undernourished people worldwide.[162] Furthermore, the number who suffer from hidden hunger – micronutrient deficiences that may cause stunted bodily and intellectual growth in children – amounts to over 2 billion people worldwide.[166]
",5
5459,"Food security[170] is a measure of the availability of food and individuals' ability to access it. According the United Nations’ Committee on World Food Security, food security is defined as the means that all people, at all times, have physical, social, and economic access to sufficient, safe, and nutritious food that meets their food preferences and dietary needs for an active and healthy life.[171] The availability of food irrespective of class, gender or region is another one. There is evidence of food security being a concern many thousands of years ago, with central authorities in ancient China and ancient Egypt being known to release food from storage in times of famine. At the 1974 World Food Conference the term ""food security"" was defined with an emphasis on supply; food security is defined as the ""availability at all times of adequate, nourishing, diverse, balanced and moderate world food supplies of basic foodstuffs to sustain a steady expansion of food consumption and to offset fluctuations in production and prices"".[172] Later definitions added demand and access issues to the definition. The final report of the 1996 World Food Summit states that food security ""exists when all people, at all times, have physical and economic access to sufficient, safe and nutritious food to meet their dietary needs and food preferences for an active and healthy life.""[173][174]
",5
5460,"Household food security exists when all members, at all times, have access to enough food for an active, healthy life.[175] Individuals who are food secure do not live in hunger or fear of starvation.[176] Food insecurity, on the other hand, is defined by the United States Department of Agriculture (USDA) as a situation of ""limited or uncertain availability of nutritionally adequate and safe foods or limited or uncertain ability to acquire acceptable foods in socially acceptable ways"".[177] Food security incorporates a measure of resilience to future disruption or unavailability of critical food supply due to various risk factors including droughts, shipping disruptions, fuel shortages, economic instability, and wars. In the years 2011–2013, an estimated 842 million people were suffering from chronic hunger.[178] The Food and Agriculture Organization of the United Nations, or FAO, identified the four pillars of food security as availability, access, utilization, and stability.[179] The United Nations (UN) recognized the Right to Food in the Declaration of Human Rights in 1948,[176] and has since said that it is vital for the enjoyment of all other rights.[180]
",5
5461,"Food aid can benefit people suffering from a shortage of food. It can be used to improve peoples' lives in the short term, so that a society can increase its standard of living to the point that food aid is no longer required.[182] Conversely, badly managed food aid can create problems by disrupting local markets, depressing crop prices, and discouraging food production. Sometimes a cycle of food aid dependence can develop.[183] Its provision, or threatened withdrawal, is sometimes used as a political tool to influence the policies of the destination country, a strategy known as food politics. Sometimes, food aid provisions will require certain types of food be purchased from certain sellers, and food aid can be misused to enhance the markets of donor countries.[184] International efforts to distribute food to the neediest countries are often coordinated by the World Food Programme.[185]
",5
5462,"Foodborne illness, commonly called ""food poisoning"", is caused by bacteria, toxins, viruses, parasites, and prions. Roughly 7 million people die of food poisoning each year, with about 10 times as many suffering from a non-fatal version.[186] The two most common factors leading to cases of bacterial foodborne illness are cross-contamination of ready-to-eat food from other uncooked foods and improper temperature control. Less commonly, acute adverse reactions can also occur if chemical contamination of food occurs, for example from improper storage, or use of non-food grade soaps and disinfectants. Food can also be adulterated by a very wide range of articles (known as ""foreign bodies"") during farming, manufacture, cooking, packaging, distribution, or sale. These foreign bodies can include pests or their droppings, hairs, cigarette butts, wood chips, and all manner of other contaminants. It is possible for certain types of food to become contaminated if stored or presented in an unsafe container, such as a ceramic pot with lead-based glaze.[186]
",5
5463,"Food poisoning has been recognized as a disease since as early as Hippocrates.[187] The sale of rancid, contaminated, or adulterated food was commonplace until the introduction of hygiene, refrigeration, and vermin controls in the 19th century. Discovery of techniques for killing bacteria using heat, and other microbiological studies by scientists such as Louis Pasteur, contributed to the modern sanitation standards that are ubiquitous in developed nations today. This was further underpinned by the work of Justus von Liebig, which led to the development of modern food storage and food preservation methods.[188] In more recent years, a greater understanding of the causes of food-borne illnesses has led to the development of more systematic approaches such as the Hazard Analysis and Critical Control Points (HACCP), which can identify and eliminate many risks.[189]
",5
5464,"Recommended measures for ensuring food safety include maintaining a clean preparation area with foods of different types kept separate, ensuring an adequate cooking temperature, and refrigerating foods promptly after cooking.[190]
",5
5465,"Foods that spoil easily, such as meats, dairy, and seafood, must be prepared a certain way to avoid contaminating the people for whom they are prepared. As such, the rule of thumb is that cold foods (such as dairy products) should be kept cold and hot foods (such as soup) should be kept hot until storage. Cold meats, such as chicken, that are to be cooked should not be placed at room temperature for thawing, at the risk of dangerous bacterial growth, such as Salmonella or E. coli.[191]
",5
5466,"Some people have allergies or sensitivities to foods that are not problematic to most people. This occurs when a person's immune system mistakes a certain food protein for a harmful foreign agent and attacks it. About 2% of adults and 8% of children have a food allergy.[192] The amount of the food substance required to provoke a reaction in a particularly susceptible individual can be quite small. In some instances, traces of food in the air, too minute to be perceived through smell, have been known to provoke lethal reactions in extremely sensitive individuals. Common food allergens are gluten, corn, shellfish (mollusks), peanuts, and soy.[192] Allergens frequently produce symptoms such as diarrhea, rashes, bloating, vomiting, and regurgitation. The digestive complaints usually develop within half an hour of ingesting the allergen.[192]
",5
5467,"Rarely, food allergies can lead to a medical emergency, such as anaphylactic shock, hypotension (low blood pressure), and loss of consciousness. An allergen associated with this type of reaction is peanut, although latex products can induce similar reactions.[192] Initial treatment is with epinephrine (adrenaline), often carried by known patients in the form of an Epi-pen or Twinject.[193][194]
",5
5468,"Human diet was estimated to cause perhaps around 35% of cancers in a human epidemiological analysis by Richard Doll and Richard Peto in 1981.[195]  These cancer may be caused by carcinogens that are present in food naturally or as contaminants. Food contaminated with fungal growth may contain mycotoxins such as aflatoxins which may be found in contaminated corn and peanuts.  Other carcinogens identified in food include heterocyclic amines generated in meat when cooked at high temperature, polyaromatic hydrocarbons in charred meat and smoked fish, and nitrosamines generated from nitrites used as food preservatives in cured meat such as bacon.[196]
",5
5469,"Anticarcinogens that may help prevent cancer can also be found in many food especially fruit and vegetables. Antioxidants are important groups of compounds that may help remove potentially harmful chemicals. It is however often difficult to identify the specific components in diet that serve to increase or decrease cancer risk since many food, such as beef steak and broccoli, contain low concentrations of both carcinogens and anticarcinogens.[196]
There are many international certifications in the cooking field, such as Monde Selection, A.A. Certification, iTQi. They use high-quality evaluation methods to make the food safer.
",5
5470,"Many cultures hold some food preferences and some food taboos. Dietary choices can also define cultures and play a role in religion. For example, only kosher foods are permitted by Judaism, halal foods by Islam, and in Hinduism beef is restricted.[200] In addition, the dietary choices of different countries or regions have different characteristics. This is highly related to a culture's cuisine.
",5
5471,"Dietary habits play a significant role in the health and mortality of all humans. Imbalances between the consumed fuels and expended energy results in either starvation or excessive reserves of adipose tissue, known as body fat.[201] Poor intake of various vitamins and minerals can lead to diseases that can have far-reaching effects on health. For instance, 30% of the world's population either has, or is at risk for developing, iodine deficiency.[202] It is estimated that at least 3 million children are blind due to vitamin A deficiency.[203] Vitamin C deficiency results in scurvy.[204] Calcium, Vitamin D, and phosphorus are inter-related; the consumption of each may affect the absorption of the others. Kwashiorkor and marasmus are childhood disorders caused by lack of dietary protein.[205]
",5
5472,"Many individuals limit what foods they eat for reasons of morality or other habits. For instance, vegetarians choose to forgo food from animal sources to varying degrees. Others choose a healthier diet, avoiding sugars or animal fats and increasing consumption of dietary fiber and antioxidants.[206] Obesity, a serious problem in the western world, leads to higher chances of developing heart disease, diabetes, cancer and many other diseases.[207] More recently, dietary habits have been influenced by the concerns that some people have about possible impacts on health or the environment from genetically modified food.[208] Further concerns about the impact of industrial farming (grains) on animal welfare, human health, and the environment are also having an effect on contemporary human dietary habits. This has led to the emergence of a movement with a preference for organic and local food.[209]
",5
5473,"
",5
5474,"French cuisine (French: Cuisine française) consists of the cooking traditions and practices from France.
",5
5475,"French cuisine developed throughout the centuries influenced by the many surrounding cultures of Spain, Italy, Switzerland, Germany and Belgium, in addition to its own food traditions on the long western coastlines of the Atlantic, the Channel and of course, inland.
",5
5476,"In the 14th century, Guillaume Tirel, a court chef known as ""Taillevent"", wrote Le Viandier, one of the earliest recipe collections of medieval France. In the 17th century, chefs François Pierre La Varenne and Marie-Antoine Carême spearheaded movements that shifted French cooking away from its foreign influences and developed France's own indigenous style.
",5
5477,"Cheese and wine are a major part of the cuisine. They play different roles regionally and nationally, with many variations and appellation d'origine contrôlée (AOC) (regulated appellation) laws.[citation needed]
",5
5478,"French cuisine was made important in the 20th century by Auguste Escoffier to become the modern haute cuisine; Escoffier, however, left out much of the local culinary character to be found in the regions of France and was considered difficult to execute by home cooks.
",5
5479,"Culinary tourism and the Guide Michelin helped to acquaint people[who?] with the cuisine bourgeoise of the urban elites[dubious  – discuss] and the peasant cuisine of the French countryside starting in the 20th century. Gascon cuisine has also had great influence over the cuisine in the southwest of France. Many dishes that were once regional have proliferated in variations across the country.
",5
5480,"Knowledge of French cooking has contributed significantly to Western cuisines. Its criteria are used widely in Western cookery school boards and culinary education. In November 2010, French gastronomy was added by the UNESCO to its lists of the world's ""intangible cultural heritage"".[1][2]
",5
5481,"In French medieval cuisine, banquets were common among the aristocracy. Multiple courses would be prepared, but served in a style called service en confusion, or all at once. Food was generally eaten by hand, meats being sliced off in large pieces held between the thumb and two fingers. The sauces were highly seasoned and thick, and heavily flavored mustards were used.
",5
5482,"Pies were a common banquet item, with the crust serving primarily as a container, rather than as food itself, and it was not until the very end of the Late Middle Ages that the shortcrust pie was developed.
",5
5483,"Meals often ended with an issue de table, which later changed into the modern dessert, and typically consisted of dragées (in the Middle Ages, meaning spiced lumps of hardened sugar or honey), aged cheese and spiced wine, such as hypocras.[3]:1–7
",5
5484,"The ingredients of the time varied greatly according to the seasons and the church calendar, and many items were preserved with salt, spices, honey, and other preservatives. Late spring, summer, and autumn afforded abundance, while winter meals were more sparse. Livestock were slaughtered at the beginning of winter. Beef was often salted, while pork was salted and smoked. Bacon and sausages would be smoked in the chimney, while the tongue and hams were brined and dried.  Cucumbers were brined as well, while greens would be packed in jars with salt. Fruits, nuts and root vegetables would be boiled in honey for preservation. Whale, dolphin and porpoise were considered fish, so during Lent, the salted meats of these sea mammals were eaten.[3]:9–12
",5
5485,"Artificial freshwater ponds (often called stews) held carp, pike, tench, bream, eel, and other fish. Poultry was kept in special yards, with pigeon and squab being reserved for the elite. Game was highly prized, but very rare, and included venison, wild boar, hare, rabbit, and birds.
",5
5486,"Kitchen gardens provided herbs, including some, such as tansy, rue, pennyroyal, and hyssop, which are rarely used today. Spices were treasured and very expensive at that time—they included pepper, cinnamon, cloves, nutmeg, and mace. Some spices used then, but no longer today in French cuisine are cubebs, long pepper (both from vines similar to black pepper), grains of paradise, and galengale.
",5
5487,"Sweet-sour flavors were commonly added to dishes with vinegars and verjus combined with sugar (for the affluent) or honey. A common form of food preparation was to finely cook, pound and strain mixtures into fine pastes and mushes, something believed to be beneficial to make use of nutrients.[3]:13–15
",5
5488,"Visual display was prized. Brilliant colors were obtained by the addition of, for example, juices from spinach and the green part of leeks. Yellow came from saffron or egg yolk, while red came from sunflower, and purple came from Crozophora tinctoria or Heliotropium europaeum.
",5
5489,"Gold and silver leaf were placed on food surfaces and brushed with egg whites. Elaborate and showy dishes were the result, such as tourte parmerienne which was a pastry dish made to look like a castle with chicken-drumstick turrets coated with gold leaf. One of the grandest showpieces of the time was roast swan or peacock sewn back into its skin with feathers intact, the feet and beak being gilded. Since both birds are stringy, and taste unpleasant, the skin and feathers could be kept and filled with the cooked, minced and seasoned flesh of tastier birds, like goose or chicken.[3]:15–16
",5
5490,"The most well known French chef of the Middle Ages was Guillaume Tirel, also known as Taillevent. Taillevent worked in numerous royal kitchens during the 14th century. His first position was as a kitchen boy in 1326. He was chef to Philip VI, then the Dauphin who was son of John II. The Dauphin became King Charles V of France in 1364, with Taillevent as his chief cook. His career spanned sixty-six years, and upon his death he was buried in grand style between his two wives. His tombstone represents him in armor, holding a shield with three cooking pots, marmites, on it.[3]:18–21
",5
5491,"Paris was the central hub of culture and economic activity, and as such, the most highly skilled culinary craftsmen were to be found there. Markets in Paris such as Les Halles, la Mégisserie, those found along Rue Mouffetard, and similar smaller versions in other cities were very important to the distribution of food. Those that gave French produce its characteristic identity were regulated by the guild system, which developed in the Middle Ages. In Paris, the guilds were regulated by city government as well as by the French crown. A guild restricted those in a given branch of the culinary industry to operate only within that field.[3]:71–72
",5
5492,"There were two groups of guilds—first, those that supplied the raw materials: butchers, fishmongers, grain merchants, and gardeners. The second group were those that supplied prepared foods: bakers, pastry cooks, sauce makers, poulterers, and caterers. There were also guilds that offered both raw materials and prepared food, such as the charcutiers and rôtisseurs (purveyors of roasted meat dishes). They would supply cooked meat pies and dishes as well as raw meat and poultry. This caused issues with butchers and poulterers, who sold the same raw materials.[3]:72–73
",5
5493,"The guilds served as a training ground for those within the industry. The degrees of assistant cook, full-fledged cook and master chef were conferred. Those who reached the level of master chef were of considerable rank in their individual industry, and enjoyed a high level of income as well as economic and job security. At times, those in the royal kitchens did fall under the guild hierarchy, but it was necessary to find them a parallel appointment based on their skills after leaving the service of the royal kitchens. This was not uncommon as the Paris cooks' guild regulations allowed for this movement.[3]:73
",5
5494,"During the 16th and 17th centuries, French cuisine assimilated many new food items from the New World. Although they were slow to be adopted, records of banquets show Catherine de' Medici (1519–1589?) serving sixty-six turkeys at one dinner.[3]:81  The dish called cassoulet has its roots in the New World discovery of haricot beans, which are central to the dish's creation, but had not existed outside of the Americas until the arrival of European colonizers.[3]:85
",5
5495,"Haute cuisine (pronounced [ot kɥizin], ""high cuisine"") has foundations during the 17th century with a chef named La Varenne. As author of works such as Le Cuisinier françois, he is credited with publishing the first true French cookbook. His book includes the earliest known reference to roux using pork fat. The book contained two sections, one for meat days, and one for fasting. His recipes marked a change from the style of cookery known in the Middle Ages, to new techniques aimed at creating somewhat lighter dishes, and more modest presentations of pies as individual pastries and turnovers. La Varenne also published a book on pastry in 1667 entitled Le Parfait confitvrier (republished as Le Confiturier françois) which similarly updated and codified the emerging haute cuisine standards for desserts and pastries.[3]:114–120
",5
5496,"Chef François Massialot wrote Le Cuisinier roïal et bourgeois in 1691, during the reign of Louis XIV. The book contains menus served to the royal courts in 1690. Massialot worked mostly as a freelance cook, and was not employed by any particular household. Massialot and many other royal cooks received special privileges by association with the French royalty. They were not subject to the regulation of the guilds; therefore, they could cater weddings and banquets without restriction. His book is the first to list recipes alphabetically, perhaps a forerunner of the first culinary dictionary. It is in this book that a marinade is first seen in print, with one type for poultry and feathered game, while a second is for fish and shellfish. No quantities are listed in the recipes, which suggests that Massialot was writing for trained cooks.[3]:149–154
",5
5497,"The successive updates of Le Cuisinier roïal et bourgeois include important refinements such as adding a glass of wine to fish stock. Definitions were also added to the 1703 edition. The 1712 edition, retitled Le Nouveau cuisinier royal et bourgeois, was increased to two volumes, and was written in a more elaborate style with extensive explanations of technique. Additional smaller preparations are included in this edition as well, leading to lighter preparations, and adding a third course to the meal. Ragout, a stew still central to French cookery, makes its first appearance as a single dish in this edition as well; prior to that, it was listed as a garnish.[3]:155
",5
5498,"Shortly before the French Revolution, dishes like bouchées à la Reine gained prominence. Essentially royal cuisine produced by the royal household, this is a chicken-based recipe served on vol-au-vent created under the influence of Queen Marie Leszczyńska, the Polish-born wife of Louis XV. This recipe is still popular today, as are other recipes from Queen Marie Leszczyńska like consommé à la Reine and filet d'aloyau braisé à la royale. Queen Marie is also credited with introducing lentils to the French diet and Polonaise garnishing.
",5
5499,"The French Revolution was integral to the expansion of French cuisine, because it abolished the guild system. This meant anyone could now produce and sell any culinary item they wished.
",5
5500,"Bread was a significant food source among peasants and the working class in the late 18th century, with many of the nation's people being dependent on it. In French provinces, bread was often consumed three times a day by the people of France.[4] According to Brace, bread was referred to as the basic dietary item for the masses, and it was also used as a foundation for soup.  In fact, bread was so important that harvest, interruption of commerce by wars, heavy flour exploration, and prices and supply were all watched and controlled by the French Government. Among the underprivileged, constant fear of famine was always prevalent. From 1725 to 1789, there were fourteen years of bad yields to blame for low grain supply. In Bordeaux, during 1708–1789, thirty-three bad harvests occurred.[4]
",5
5501,"Marie-Antoine Carême was born in 1784, five years before the Revolution. He spent his younger years working at a pâtisserie until he was discovered by Charles Maurice de Talleyrand-Périgord, who would later cook for Napoleon Bonaparte. Prior to his employment with Talleyrand, Carême had become known for his pièces montées, which were extravagant constructions of pastry and sugar architecture.[5]:144–145
",5
5502,"More important to Carême's career was his contribution to the refinement of French cuisine. The basis for his style of cooking was his sauces, which he named mother sauces. Often referred to as fonds, meaning ""foundations"", these base sauces, espagnole, velouté, and béchamel, are still known today. Each of these sauces was made in large quantities in his kitchen, then formed the basis of multiple derivatives. Carême had over one hundred sauces in his repertoire.
",5
5503,"In his writings, soufflés appear for the first time. Although many of his preparations today seem extravagant, he simplified and codified an even more complex cuisine that existed beforehand. Central to his codification of the cuisine were Le Maître d'hôtel français (1822), Le Cuisinier parisien (1828) and L'Art de la cuisine française au dix-neuvième siècle (1833–5).[5]:144–148
",5
5504,"Georges Auguste Escoffier is commonly acknowledged as the central figure to the modernization of haute cuisine and organizing what would become the national cuisine of France. His influence began with the rise of some of the great hotels in Europe and America during the 1880s-1890s. The Savoy Hotel managed by César Ritz was an early hotel in which Escoffier worked, but much of his influence came during his management of the kitchens in the Carlton from 1898 until 1921. He created a system of ""parties"" called the brigade system, which separated the professional kitchen into five separate stations.
",5
5505,"These five stations included the garde manger that prepared cold dishes; the entremettier prepared starches and vegetables, the rôtisseur prepared roasts, grilled and fried dishes; the saucier prepared sauces and soups; and the pâtissier prepared all pastry and desserts items.
",5
5506,"This system meant that instead of one person preparing a dish on one's own, now multiple cooks would prepare the different components for the dish. An example used is oeufs au plat Meyerbeer, the prior system would take up to fifteen minutes to prepare the dish, while in the new system, the eggs would be prepared by the entremettier, kidney grilled by the rôtisseur, truffle sauce made by the saucier and thus the dish could be prepared in a shorter time and served quickly in the popular restaurants.[5]:157–159
",5
5507,"Escoffier also simplified and organized the modern menu and structure of the meal. He published a series of articles in professional journals which outlined the sequence, and he finally published his Livre des menus in 1912. This type of service embraced the service à la russe (serving meals in separate courses on individual plates), which Félix Urbain Dubois had made popular in the 1860s. Escoffier's largest contribution was the publication of Le Guide Culinaire in 1903, which established the fundamentals of French cookery. The book was a collaboration with Philéas Gilbert, E. Fetu, A. Suzanne, B. Reboul, Ch. Dietrich, A. Caillat and others. The significance of this is to illustrate the universal acceptance by multiple high-profile chefs to this new style of cooking.[5]:159–160
",5
5508,"Le Guide Culinaire deemphasized the use of heavy sauces and leaned toward lighter fumets, which are the essence of flavor taken from fish, meat and vegetables. This style of cooking looked to create garnishes and sauces whose function is to add to the flavor of the dish, rather than mask flavors like the heavy sauces and ornate garnishes of the past. Escoffier took inspiration for his work from personal recipes in addition to recipes from Carême, Dubois and ideas from Taillevent's Le Viandier, which had a modern version published in 1897. A second source for recipes came from existing peasant dishes that were translated into the refined techniques of haute cuisine.
",5
5509,"Expensive ingredients would replace the common ingredients, making the dishes much less humble. The third source of recipes was Escoffier himself, who invented many new dishes, such as pêche Melba.[5]:160–162  Escoffier updated Le Guide Culinaire four times during his lifetime, noting in the foreword to the book's first edition that even with its 5,000 recipes, the book should not be considered an ""exhaustive"" text, and that even if it were at the point when he wrote the book, ""it would no longer be so tomorrow, because progress marches on each day.""[6]
",5
5510,"
This period is also marked by the appearance of the nouvelle cuisine. The term ""nouvelle cuisine"" has been used many times in the history of French cuisine which emphasized the freshness, lightness and clarity of flavor and inspired by new movements in world cuisine. In the 1740s, Menon first used the term, but the cooking of Vincent La Chapelle and François Marin was also considered modern. In the 1960s, Henri Gault and Christian Millau revived it to describe the cooking of Paul Bocuse, Jean and Pierre Troisgros, Michel Guérard, Roger Vergé and Raymond Oliver.[7] These chefs were working toward rebelling against the ""orthodoxy"" of Escoffier's cuisine. Some of the chefs were students of Fernand Point at the Pyramide in Vienne, and had left to open their own restaurants. Gault and Millau ""discovered the formula"" contained in ten characteristics of this new style of cooking.[5]:163–164
",5
5511,"The first characteristic was a rejection of excessive complication in cooking. Second, the cooking times for most fish, seafood, game birds, veal, green vegetables and pâtés was greatly reduced in an attempt to preserve the natural flavors. Steaming was an important trend from this characteristic. The third characteristic was that the cuisine was made with the freshest possible ingredients. Fourth, large menus were abandoned in favor of shorter menus. Fifth, strong marinades for meat and game ceased to be used. Sixth, they stopped using heavy sauces such as espagnole and béchamel thickened with flour based ""roux"" in favor of seasoning their dishes with fresh herbs, quality butter, lemon juice, and vinegar. Seventh, they used regional dishes for inspiration instead of haute cuisine dishes. Eighth, new techniques were embraced and modern equipment was often used; Bocuse even used microwave ovens. Ninth, the chefs paid close attention to the dietary needs of their guests through their dishes. Tenth, and finally, the chefs were extremely inventive and created new combinations and pairings.[5]:163–164
",5
5512,"Some have speculated that a contributor to nouvelle cuisine was World War II when animal protein was in short supply during the German occupation.[8] By the mid-1980s food writers stated that the style of cuisine had reached exhaustion and many chefs began returning to the haute cuisine style of cooking, although much of the lighter presentations and new techniques remained.[5]:163–164
",5
5513,"There are many dishes that are considered part of French national cuisine today.
",5
5514,"A meal often consists of three courses, hors d'œuvre or entrée (introductory course, sometimes soup), plat principal (main course), fromage (cheese course) or dessert, sometimes with a salad offered before the cheese or dessert.
",5
5515,"Basil salmon terrine
",5
5516,"Bisque is a smooth and creamy French potage.
",5
5517,"Foie gras with mustard seeds and green onions in duck jus
",5
5518,"Croque monsieur
",5
5519,"Pot-au-feu is a cuisine classique dish.
",5
5520,"Steak frites is a simple and popular dish.
",5
5521,"Typical French pâtisserie
",5
5522,"Mille-feuille
",5
5523,"Macaron
",5
5524,"Éclair
",5
5525,"Crème brûlée
",5
5526,"Mousse au chocolat
",5
5527,"Crêpe
",5
5528,"Floating island
",5
5529,"French regional cuisine is characterized by its extreme diversity and style. Traditionally, each region of France has its own distinctive cuisine.[9]
",5
5530,"Paris and Île-de-France are central regions where almost anything from the country is available, as all train lines meet in the city. Over 9,000 restaurants exist in Paris and almost any cuisine can be obtained here. High-quality Michelin Guide-rated restaurants proliferate here.[10]
",5
5531,"Game and ham are popular in Champagne, as well as the special sparkling wine simply known as Champagne. Fine fruit preserves are known from Lorraine as well as the quiche Lorraine.[11] Alsace is influenced by the German cuisine, especially the one from the Palatinate and Baden region. As such, beers made in the area are similar to the style of bordering Germany. Dishes like choucroute (French for sauerkraut) are also popular.[10]:55 Many ""Eaux de vie"" (distilled alcohol from fruit) also called schnaps are from this region, due to a wide variety of local fruits (cherry, raspberry, pear, grapes) and especially prunes (mirabelle, plum).[9]:259,295[clarification needed]
",5
5532,"Flute of Champagne wine
",5
5533,"Alsatian Flammekueche
",5
5534,"Andouillette
",5
5535,"Quiche
",5
5536,"The coastline supplies many crustaceans, sea bass, monkfish and herring. Normandy has top-quality seafood, such as scallops and sole, while Brittany has a supply of lobster, crayfish and mussels.
",5
5537,"Normandy is home to a large population of apple trees; apples are often used in dishes, as well as cider and Calvados. The northern areas of this region, especially Nord, grow ample amounts of wheat, sugar beets and chicory. Thick stews are found often in these northern areas as well.
",5
5538,"The produce of these northern regions is also considered some of the best in the country, including cauliflower and artichokes. Buckwheat grows widely in Brittany as well and is used in the region's galettes, called jalet, which is where this dish originated.[10]:93
",5
5539,"Crème Chantilly, created at the Château de Chantilly.
",5
5540,"Camembert, cheese specialty from Normandy
",5
5541,"Crêpe and Cider, specialty from Brittany
",5
5542,"Belon oysters
",5
5543,"High-quality fruits come from the Loire Valley and central France, including cherries grown for the liqueur Guignolet and Belle Angevine pears. The strawberries and melons are also of high quality.
",5
5544,"Fish are seen in the cuisine, often served with a beurre blanc sauce, as well as wild game, lamb, calves, Charolais cattle, Géline fowl, and goat cheeses.
",5
5545,"Young vegetables are used often, as are the specialty mushrooms of the region, champignons de Paris. Vinegars from Orléans are a specialty ingredient used as well.[10]:129, 132
",5
5546,"Burgundy and Franche-Comté are known for their wines. Pike, perch, river crabs, snails, game, redcurrants, blackcurrants are from both Burgundy and Franche-Comté.
",5
5547,"Amongst savorous specialties accounted in the Cuisine franc-comtoise from the Franche-Comté region are Croûte aux morilles [fr], Poulet à la Comtoise [fr], trout, smoked meats and cheeses such as Mont d'Or, Comté and Morbier which are best eaten hot or cold, the exquisite Coq au vin jaune [fr] and the special dessert gâteau de ménage [fr].
",5
5548,"Charolais beef, poultry from Bresse, sea snail, honey cake, Chaource and Epoisses cheese are specialties of the local cuisine of Burgundy. Dijon mustard is also a specialty of Burgundy cuisine. Crème de cassis is a popular liquor made from the blackcurrants. Oils are used in the cooking here, types include nut oils and rapeseed oil.[10]:153,156,166,185
",5
5549,"Coq au vin jaune [fr]
",5
5550,"Poulet à la Comtoise [fr]
",5
5551,"Mont d'Or chaud [fr]
",5
5552,"Escargots, with special tongs and fork
",5
5553,"Coq au vin
",5
5554,"Bœuf bourguignon
",5
5555,"Beaujolais wine
",5
5556,"Dijon mustard
",5
5557,"Comté cheese and Vin jaune
",5
5558,"Gâteau de ménage
",5
5559,"The area covers the old province of Dauphiné, once known as the ""larder"" of France,[dubious  – discuss] that gave its name to gratin dauphinois,[12] traditionally made in a large baking dish rubbed with garlic. Successive layers of potatoes, salt, pepper and milk are piled up to the top of the dish. It  is then baked in the oven at low temperature for 2 hours.[13]
",5
5560,"Fruit and young vegetables are popular in the cuisine from the Rhône valley, as are great wines like Hermitage AOC, Crozes-Hermitage AOC and Condrieu AOC. Walnuts and walnut products and oil from Noix de Grenoble AOC, lowland cheeses, like St. Marcellin, St. Félicien and Bleu du Vercors-Sassenage.
",5
5561,"Poultry from Bresse, guinea fowl from Drôme and fish from the Dombes, a light yeast-based cake, called Pogne de Romans and the regional speciality, Raviole du Dauphiné, and there is the short-crust ""Suisse"", a Valence biscuit speciality.
",5
5562,"Lakes and mountain streams in Rhône-Alpes are key to the cuisine as well. Lyon and Savoy supply sausages while the Alpine regions supply their specialty cheeses like Beaufort, Abondance, Reblochon, Tomme and Vacherin.[citation needed]
",5
5563,"Mères lyonnaises are female restaurateurs particular to this region who provide local gourmet establishments.[14] Celebrated chefs from this region include Fernand Point, Paul Bocuse, the Troisgros brothers and Alain Chapel.[15]
",5
5564,"The Chartreuse Mountains are the source of the green and yellow Digestif liquor, Chartreuse produced by the monks of the Grande Chartreuse.[10]:197,230
",5
5565,"Since the 2014 administrative reform, the ancient area of Auvergne is now part of the region. One of its leading chefs is Regis Marcon.
",5
5566,"Gratin dauphinois
",5
5567,"Bleu du Vercors-Sassenage
",5
5568,"Chartreuse Elixir Végétal
",5
5569,"Salade de ravioles
",5
5570,"Condrieu wine
",5
5571,"Suisse de Valence biscuit [fr]
",5
5572,"Bleu de Bresse
",5
5573,"Poulet de Bresse chicken salad
",5
5574,"Rosette de Lyon charcuterie
",5
5575,"Noix de Grenoble, unusual trilaterally symmetric walnut
",5
5576,"Beaufort cheeses ripening in a cellar
",5
5577,"Oysters come from the Oléron-Marennes basin, while mussels come from the Bay of Aiguillon.
",5
5578,"High-quality produce comes from the region's hinterland, especially goat cheese. This region and in the Vendée is grazing ground for Parthenaise cattle, while poultry is raised in Challans.
",5
5579,"The region of Poitou-Charentes purportedly produces the best butter and cream in France. Cognac is also made in the region along the Charente River. 
",5
5580,"Limousin is home to the Limousin cattle, as well as sheep. The woodlands offer game and mushrooms. The southern area around Brive draws its cooking influence from Périgord and Auvergne to produce a robust cuisine.[10]:237
",5
5581,"Bordeaux is known for its wine, with certain areas offering specialty grapes for wine-making. Fishing is popular in the region for the cuisine, sea fishing in the Bay of Biscay, trapping in the Garonne and stream fishing in the Pyrenees.
",5
5582,"The Pyrenees also has lamb, such as the Agneau de Pauillac, as well as sheep cheeses. Beef cattle in the region include the Blonde d'Aquitaine, Boeuf de Chalosse, Boeuf Gras de Bazas, and Garonnaise.
",5
5583,"Free-range chicken, turkey, pigeon, capon, goose and duck prevail in the region as well.  Gascony and Périgord cuisines includes pâtés, terrines, confits and magrets. This is one of the regions notable for its production of foie gras, or fattened goose or duck liver.
",5
5584,"The cuisine of the region is often heavy and farm based.  Armagnac is also from this region, as are prunes from Agen.[10]:259,295
",5
5585,"Confit de canard
",5
5586,"A terrine of foie gras with a bottle of Sauternes
",5
5587,"Black Périgord Truffle
",5
5588,"Tourin, a garlic soup from Dordogne
",5
5589,"Gers, a department of France, is within this region and has poultry, while La Montagne Noire and Lacaune area offer hams and dry sausages.
",5
5590,"White corn is planted heavily in the area both for use in fattening ducks and geese for foie gras and for the production of millas, a cornmeal porridge.  Haricot beans are also grown in this area, which are central to the dish cassoulet.
",5
5591,"The finest sausage in France is saucisse de Toulouse, which also part of cassoulet of Toulouse. The Cahors area produces a specialty ""black wine"" as well as truffles and mushrooms.
",5
5592,"This region also produces milk-fed lamb. Unpasteurized ewe's milk is used to produce Roquefort in Aveyron, while in Laguiole is producing unpasteurized cow's milk cheese. Salers cattle produce milk for cheese, as well as beef and veal products.
",5
5593,"The volcanic soils create flinty cheeses and superb lentils. Mineral waters are produced in high volume in this region as well.[10]:313 Cabécou cheese is from Rocamadour, a medieval settlement erected directly on a cliff, in the rich countryside of Causses du Quercy.
",5
5594,"This area is one of the region's oldest milk producers; it has chalky soil, marked by history and human activity, and is favourable for the raising of goats.
",5
5595,"Aligot
",5
5596,"Roquefort cheese
",5
5597,"Cassoulet
",5
5598,"Restaurants are popular in the area known as Le Midi. Oysters come from the Étang de Thau, to be served in the restaurants of Bouzigues, Mèze, and Sète. Mussels are commonly seen here in addition to fish specialties of Sète, bourride, tielles and rouille de seiche.
",5
5599,"In the Languedoc jambon cru, sometimes known as jambon de montagne is produced. High quality Roquefort comes from the brebis (sheep) on the Larzac plateau.
",5
5600,"The Les Cévennes area offers mushrooms, chestnuts, berries, honey, lamb, game, sausages, pâtés and goat cheeses.  Catalan influence can be seen in the cuisine here with dishes like brandade made from a purée of dried cod wrapped in mangold leaves. Snails are plentiful and are prepared in a specific Catalan style known as a cargolade. Wild boar can be found in the more mountainous regions of the Midi.[10]:349,360
",5
5601,"The Provence and Côte d'Azur region is rich in quality citrus, vegetables, fruits and herbs; the region is one of the largest suppliers of all these ingredients in France. The region also produces the largest amount of olives, and creates superb olive oil. Lavender is used in many dishes found in Haute Provence. Other important herbs in the cuisine include thyme, sage, rosemary, basil, savory, fennel, marjoram, tarragon, oregano, and bay leaf.[16] Honey is a prized ingredient in the region.
",5
5602,"Seafood is widely available throughout the coastal area and is heavily represented in the cuisine. Goat cheeses, air-dried sausages, lamb, beef, and chicken are popular here. Garlic and anchovies are used in many of the region's sauces, as in Poulet Provençal, which uses white wine, tomatoes, herbs, and sometimes anchovies, and Pastis is found everywhere that alcohol is served.
",5
5603,"The cuisine uses a large amount of vegetables for lighter preparations. Truffles are commonly seen in Provence during the winter. Thirteen desserts in Provence are the traditional Christmas dessert,[17] e.g. quince cheese, biscuits, almonds, nougat, apple, and fougasse.
",5
5604,"Rice is grown in the Camargue, which is the northernmost rice growing area in Europe, with Camargue red rice being a specialty.[10]:387,403,404,410,416 Anibal Camous, a Marseillais who lived to be 104, maintained that it was by eating garlic daily that he kept his ""youth"" and brilliance. When his eighty-year-old son died, the father mourned: ""I always told him he wouldn't live long, poor boy. He ate too little garlic!"" (cited by chef Philippe Gion)
",5
5605,"Salade niçoise
",5
5606,"Vacqueyras wine
",5
5607,"Bouillabaisse
",5
5608,"Pan bagnat
",5
5609,"Ratatouille
",5
5610,"Bourride de fruits de mer
",5
5611,"Salade Mesclun
",5
5612,"Pieds paquets
",5
5613,"Goats and sheep proliferate on the island of Corsica, and lamb are used to prepare dishes such as stufato, ragouts and roasts. Cheeses are also produced, with brocciu being the most popular.
",5
5614,"Chestnuts, growing in the Castagniccia forest, are used to produce flour, which is used in turn to make bread, cakes and polenta. The forest provides acorns used to feed the pigs and boars that provide much of the protein for the island's cuisine. Fresh fish and seafood are common.
",5
5615,"The island's pork is used to make fine hams, sausage and other unique items including coppa (dried rib cut), lonzu (dried pork fillet), figatellu (smoked and dried liverwurst), salumu (a dried sausage), salcietta, Panzetta, bacon, and prisuttu (farmer's ham).
",5
5616,"Clementines (which hold an AOC designation), lemons, nectarines and figs are grown there. Candied citron is used in nougats, while and the aforementioned brocciu and chestnuts are also used in desserts.
",5
5617,"Corsica offers a variety of wines and fruit liqueurs, including Cap Corse, Patrimonio, Cédratine, Bonapartine, liqueur de myrte, vins de fruit, Rappu, and eau-de-vie de châtaigne.[10]:435,441,442
",5
5618,"French Guianan cuisine or Guianan cuisine is a blend of the different cultures that have settled in French Guiana. Creole and Chinese restaurants are common in major cities such as Cayenne, Kourou and Saint-Laurent-du-Maroni. Many indigenous animal species such as caiman and tapir are used in spiced stews.
",5
5619,"French cuisine varies according to the season. In summer, salads and fruit dishes are popular because they are refreshing and produce is inexpensive and abundant. Greengrocers prefer to sell their fruits and vegetables at lower prices if needed, rather than see them rot in the heat. At the end of summer, mushrooms become plentiful and appear in stews throughout France. The hunting season begins in September and runs through February. Game of all kinds is eaten, often in elaborate dishes that celebrate the success of the hunt. Shellfish are at their peak when winter turns to spring, and oysters appear in restaurants in large quantities.
",5
5620,"With the advent of deep-freeze and the air-conditioned hypermarché, these seasonal variations are less marked than hitherto, but they are still observed, in some cases due to legal restrictions. Crayfish, for example, have a short season and it is illegal to catch them out of season.[18] Moreover, they do not freeze well.
",5
5621,"French regional cuisines use locally grown vegetables, such as pomme de terre (potato), blé (wheat), haricots verts (a type of French green bean), carotte (carrot), poireau (leek), navet (turnip), aubergine (eggplant), courgette (zucchini), and échalotte (shallot).
",5
5622,"French regional cuisines use locally grown fungi, such as truffe (truffle), champignon de Paris (button mushroom), chanterelle ou girolle (chanterelle), pleurote (en huître) (oyster mushrooms), and cèpes (porcini).
",5
5623,"Common fruits include oranges, tomatoes, tangerines, peaches, apricots, apples, pears, plums, cherries, strawberries, raspberries, redcurrants, blackberries, grapes, grapefruit, and blackcurrants.
",5
5624,"Varieties of meat consumed include poulet (chicken), pigeon (squab), canard (duck), oie (goose, the source of foie gras), bœuf (beef), veau (veal), porc (pork), agneau (lamb), mouton (mutton), caille (quail), cheval (horse), grenouille (frog), and escargot (snails). Commonly consumed fish and seafood include cod, canned sardines, fresh sardines, canned tuna, fresh tuna, salmon, trout, mussels, herring, oysters, shrimp and calamari.
",5
5625,"Eggs are fine quality and often eaten as: omelettes, hard-boiled with mayonnaise, scrambled plain, scrambled haute cuisine preparation, œuf à la coque.
",5
5626,"Herbs and seasonings vary by region, and include fleur de sel, herbes de Provence, tarragon, rosemary, marjoram, lavender, thyme, fennel, and sage.
",5
5627,"Fresh fruit and vegetables, as well as fish and meat, can be purchased either from supermarkets or specialty shops. Street markets are held on certain days in most localities; some towns have a more permanent covered market enclosing food shops, especially meat and fish retailers. These have better shelter than the periodic street markets.
",5
5628,"Herbes de provence
",5
5629,"Charolais cattle
",5
5630,"Champignon de Paris
",5
5631,"Haricots verts
",5
5632,"Piments d'Espelette
",5
5633,"Fleur de sel de Guérande
",5
5634,"Grappe de raisin
",5
5635,"Poulet de Bresse
",5
5636,"Blé (Wheat)
",5
5637,"Black Périgord truffle
",5
5638,"Le petit déjeuner (breakfast) is traditionally a quick meal consisting of tartines (slices) of French bread with butter and honey or jam (sometimes brioche), along with café au lait (also called café crème), or black coffee, or tea[19] and rarely hot chicory. Children often drink hot chocolate in bowls or cups along with their breakfasts. Croissants, pain aux raisins or pain au chocolat (also named chocolatine in the south-west of France) are mostly included as a weekend treat. Breakfast of some kind is always served in cafés opening early in the day.
",5
5639,"There are also savoury dishes for breakfast. An example is le petit déjeuner gaulois or petit déjeuner fermier with the famous long narrow bread slices topped with soft white cheese or boiled ham, called mouillettes,[20] which is dipped in a soft-boiled egg and some fruit juice and hot drink.
",5
5640,"Another variation called le petit déjeuner chasseur, meant to be very hearty, is served with pâté and other charcuterie products. A more classy version is called le petit déjeuner du voyageur, where delicatessens serve gizzard, bacon, salmon, omelet, or croque-monsieur, with or without soft-boiled egg and always with the traditional coffee/tea/chocolate along fruits or fruit juice. When the egg is cooked sunny-side over the croque-monsieur, it is called a croque-madame.
",5
5641,"In Germinal and other novels, Émile Zola also reported the briquet: two long bread slices stuffed with butter, cheese and or ham. It can be eaten as a standing/walking breakfast, or meant as a ""second"" one before lunch.
",5
5642,"In the movie Bienvenue chez les Ch'tis, Philippe Abrams (Kad Merad) and Antoine Bailleul (Dany Boon) share together countless breakfasts consisting of tartines de Maroilles (a rather strong cheese) along with their hot chicory.
",5
5643,"Le déjeuner (lunch) is a two-hour mid-day meal or a one-hour lunch break. In some smaller towns and in the south of France, the two-hour lunch may still be customary. Sunday lunches are often longer and are taken with the family.[21] Restaurants normally open for lunch at noon and close at 2:30 pm. Some restaurants are closed on Monday during lunch hours.[22]
",5
5644,"In large cities, a majority of working people and students eat their lunch at a corporate or school cafeteria, which normally serves complete meals as described above; it is not usual for students to bring their own lunch to eat. For companies that do not operate a cafeteria, it is mandatory for white-collar workers to be given lunch vouchers as part of their employee benefits. These can be used in most restaurants, supermarkets and traiteurs; however, workers having lunch in this way typically do not eat all three courses of a traditional lunch due to price and time constraints. In smaller cities and towns, some working people leave their workplaces to return home for lunch. Also, an alternative, especially among blue-collar workers, is eating sandwiches followed by a dessert; both dishes can be found ready-made at bakeries and supermarkets at budget prices.
",5
5645,"Le dîner (dinner) often consists of three courses, hors d'œuvre or entrée (appetizers or introductory course, sometimes soup), plat principal (main course), and a cheese course or dessert, sometimes with a salad offered before the cheese or dessert. Yogurt may replace the cheese course, while a simple dessert would be fresh fruit. The meal is often accompanied by bread, wine and mineral water. Most of the time the bread would be a baguette which is very common in France and is made almost every day. Main meat courses are often served with vegetables, along with potatoes, rice or pasta.[21]:82 Restaurants often open at 7:30 pm for dinner, and stop taking orders between the hours of 10:00 pm and 11:00 pm. Some restaurants close for dinner on Sundays.[22]:342
",5
5646,"In French cuisine, beverages that precede a meal are called apéritifs (literally: ""that opens the appetite""), and can be served with amuse-bouches (literally: ""mouth amuser""). Those that end it are called digestifs.
",5
5647,"The apéritif varies from region to region: Pastis is popular in the south of France, Crémant d'Alsace in the eastern region. Champagne can also be served. Kir, also called Blanc-cassis, is a common and popular apéritif-cocktail made with a measure of crème de cassis (blackcurrant liqueur) topped up with white wine. The phrase Kir Royal is used when white wine is replaced with a Champagne wine. A simple glass of red wine, such as Beaujolais nouveau, can also be presented as an apéritif, accompanied by amuse-bouches. Some apéritifs can be fortified wines with added herbs, such as cinchona, gentian and vermouth. Trade names that sell well include Suze (the classic gentiane), Byrrh, Dubonnet, and Noilly Prat.
",5
5648,"Digestifs are traditionally stronger, and include Cognac, Armagnac, Calvados, Eau de vie and fruit alcohols.
",5
5649,"A typical French Christmas dish is turkey with chestnuts. Other common dishes are smoked salmon, oysters, caviar and foie gras. The Yule log is a very French tradition during Christmas. Chocolate and cakes also occupy a prominent place for Christmas in France. This cuisine is normally accompanied by Champagne. Tradition says that thirteen desserts complete the Christmas meal in reference to the twelve apostles and Christ.[23][24][25][26]
",5
5650,"The modern restaurant has its origins in French culture. Prior to the late 18th century, diners who wished to ""dine out"" would visit their local guild member's kitchen and have their meal prepared for them. However, guild members were limited to producing whatever their guild registry delegated to them.[27]:8–10 These guild members offered food in their own homes to steady clientele that appeared day-to-day but at set times. The guest would be offered the meal table d'hôte, which is a meal offered at a set price with very little choice of dishes, sometimes none at all.[27]:30–31
",5
5651,"The first steps toward the modern restaurant were locations that offered restorative bouillons, or restaurants—these words being the origin of the name ""restaurant"". This step took place during the 1760s–1770s. These locations were open at all times of the day, featuring ornate tableware and reasonable prices. These locations were meant more as meal replacements for those who had ""lost their appetites and suffered from jaded palates and weak chests.""[27]:34–35
",5
5652,"In 1782 Antoine Beauvilliers, pastry chef to the future Louis XVIII, opened one of the most popular restaurants of the time—the Grande Taverne de Londres—in the arcades of the Palais-Royal. Other restaurants were opened by chefs of the time who were leaving the failing monarchy of France, in the period leading up to the French Revolution. It was these restaurants that expanded upon the limited menus of decades prior, and led to the full restaurants that were completely legalized with the advent of the French Revolution and abolition of the guilds. This and the substantial discretionary income of the French Directory's nouveau riche helped keep these new restaurants in business.[27]:140–144
",5
5653,"Larger restaurants and hotels in France employ extensive staff and are commonly referred to as either the kitchen brigade for the kitchen staff or dining room brigade system for the dining room staff. This system was created by Georges Auguste Escoffier.  This structured team system delegates responsibilities to different individuals who specialize in certain tasks. The following is a list of positions held both in the kitchen and dining rooms brigades in France:[10]:32
",5
5654,"
",5
5655,"
",5
5656,"Barbecue or barbeque (informally, BBQ; in Australia and UK barbie, in South Africa braai) is a cooking method, a cooking 
device, a style of food, and a name for a meal or gathering at which this style of food is cooked and served.
",5
5657,"A barbecue can refer to the cooking method itself, the meat cooked this way, or to a type of social event featuring this type of cooking. Barbecuing is usually done outdoors by smoking meat over wood or charcoal. Restaurant barbecue may be cooked in large, specially-designed brick or metal ovens. Barbecue is practiced in many countries and there are numerous regional variations.
",5
5658,"Barbecuing techniques include smoking, roasting, and grilling. The technique for which it is named involves cooking using smoke at low temperatures and long cooking times (several hours). Grilling is done over direct, dry heat, usually over a hot fire for a few minutes.
",5
5659,"The English word ""barbecue"" and its cognates in other languages come from the Spanish word barbacoa. Etymologists believe this to be derived from barabicu found in the language of the Arawak people of the Caribbean and the Timucua people of Florida;[1][page needed] 
it has entered some European languages in the form of the aforementioned barbacoa. The Oxford English Dictionary (OED) traces the word to Hispaniola and translates it as a ""framework of sticks set upon posts"".[2] Gonzalo Fernández De Oviedo y Valdés, a Spanish explorer, was the first to use the word ""barbecoa"" in print in Spain in 1526 in the Diccionario de la Lengua Española (2nd Edition) of the Real Academia Española. After Columbus landed in the Americas in 1492, the Spaniards apparently found Taíno roasting meat over a grill consisting of a wooden framework resting on sticks above a fire. The flames and smoke rose and enveloped the meat, giving it a certain flavor.[3]
",5
5660,"Traditional barbacoa involves digging a hole in the ground and placing some meat—usually a whole lamb—above a pot so the juices can be used to make a broth. It is then covered with maguey leaves and coal, and set alight. The cooking process takes a few hours. Olaudah Equiano, an African abolitionist, described this method of roasting alligators among the Mosquito People (Miskito people) on his journeys to Cabo Gracias a Dios in his narrative The Interesting Narrative of the Life of Olaudah Equiano.[4]
",5
5661,"Linguists have suggested the word was loaned successively into Spanish, then Portuguese, French, and English. In the form barbacado the word was used in English in 1648 by the supposed Beauchamp Plantagenet in the tract A description of the province of New Albion: ""the Indians in stead of salt doe barbecado or dry and smoak fish"".[5] According to the OED, the first recorded use in modern form was in 1661, in Edmund Hickeringill's Jamaica Viewed: ""Some are slain, And their flesh forthwith Barbacu'd and eat"";[2] it also appears in 1672 in the writings of John Lederer following his travels in the North American southeast in 1669–70.[6] First known use as a noun was in 1697 by the English buccaneer William Dampier. In his New Voyage Round the World, Dampier wrote, ""  and lay there all night, upon our Borbecu's, or frames of Sticks, raised about 3 foot from the Ground"".[7]
",5
5662,"Samuel Johnson's 1756 dictionary gave the following definitions:[8]
",5
5663,"While the standard modern English spelling of the word is barbecue, variations including barbeque and truncations such as bar-b-q or BBQ may also be found.[9] The spelling barbeque is given in Merriam-Webster and the Oxford Dictionaries as a variant.[10][11] In the southeastern United States, the word barbecue is used predominantly as a noun referring to roast pork, while in the southwestern states cuts of beef are often cooked.[12][page needed]
",5
5664,"Because the word barbecue came from native groups, Europeans gave it ""savage connotations"".[13] This association with barbarians and ""savages"" is strengthened by Edmund Hickeringill's work Jamaica Viewed: with All the Ports, Harbours, and their Several Soundings, Towns, and Settlements through its descriptions of cannibalism. However, according to Andrew Warnes, there is very little proof that Hickeringill's tale of cannibalism in the Caribbean is even remotely true.[14] Another notable false depiction of cannibalistic barbecues appears in Theodor de Bry's Great Voyages, which in Warnes's eyes, ""present smoke cookery as a custom quintessential to an underlying savagery... that everywhere contains within it a potential for cannibalistic violence"".[15] Today, those in the U.S. associate barbecue with ""classic Americana"".[16]
",5
5665,"In American English usage, grilling refers to a fast process over high heat while barbecuing refers to a slow process using indirect heat or hot smoke, similar to some forms of roasting. In a typical U.S. home grill, food is cooked on a grate directly over hot charcoal, while in a U.S. barbecue the coals are dispersed to the sides or at a significant distance from the grate. In British usage, barbecuing refers to a fast cooking process done directly over high heat, while grilling refers to cooking under a source of direct, moderate-to-high heat—known in the United States as broiling. Its South American versions are the southern Brazilian churrasco and the Argentine asado.[17]
",5
5666,"According to estimates, prior to the American Civil War, Southerners ate around five pounds of pork for every pound of beef they consumed.[18] Because of the effort to capture and cook these wild hogs, pig slaughtering became a time for celebration and the neighborhood would be invited to share in the largesse. In Louisiana Creole and Cajun culture, these feasts are called boucheries or ""pig pickin's"". The traditional Southern barbecue grew out of these gatherings.[19]
",5
5667,"Each Southern locale has its own variety of barbecue, particularly sauces. South Carolina is the only state that traditionally includes all four recognized barbecue sauces, including mustard-based, vinegar-based, and light and heavy tomato-based sauces. North Carolina sauces vary by region; eastern North Carolina uses a vinegar-based sauce, the center of the state uses Lexington-style barbecue, with a combination of ketchup and vinegar as their base, and western North Carolina uses a heavier ketchup base. Memphis barbecue is best known for tomato- and vinegar-based sauces. In some Memphis establishments and in Kentucky, meat is rubbed with dry seasoning (dry rubs) and smoked over hickory wood without sauce. The finished barbecue is then served with barbecue sauce on the side.[20]
",5
5668,"The barbecue of Alabama, Georgia, and Tennessee is almost always pork, often served with a sweet tomato-based sauce. Several regional variations exist. Alabama is also known for its distinctive white sauce—a mayonnaise- and vinegar-based sauce originating in northern Alabama, used predominantly on chicken and pork. A popular item in North Carolina and Memphis is the pulled pork sandwich served on a bun and often topped with coleslaw. Pulled pork is prepared by shredding the pork after it has been barbecued.[21]
",5
5669,"Kansas City-style barbecue is characterized by its use of different types of meat, including pulled pork, pork ribs, burnt ends, smoked sausage, beef brisket, beef ribs, smoked/grilled chicken, smoked turkey, and sometimes fish—a variety attributable to Kansas City's history as a center for meat packing. Hickory is the primary wood used for smoking in Kansas City, while the sauces are typically tomato based with sweet, spicy, and tangy flavors.
",5
5670,"Pit beef prevails in Maryland and is often enjoyed at large outdoor ""bull roasts"", which are commonly fundraising events for clubs and associations. Maryland-style pit-beef is not the product of barbecue cookery in the strictest sense; the meat is not smoked but grilled over a high heat. The meat is typically served rare with a strong horseradish sauce as the preferred condiment.[22]
",5
5671,"The state of Kentucky, particularly Western Kentucky, is unusual in its barbecue cooking; the preferred meat is mutton.[23] This kind of mutton barbecue is often used in communal events in Kentucky, such as political rallies, county fairs, and church fund-raising events.[24]
",5
5672,"Barbecue remains one of the most traditional foods in the United States. While many festive foods, such as roasted turkey or ham, are usually served on particular days or holidays, barbecue can be served on any day. Barbecue is often served on the Fourth of July; however, it is not only confined to that day. Barbecues tend to bring people together and serve as a bonding experience at any time of the year. It brings people back to their roots, providing a cooking experience that is often an escape from civilization and closer to nature.[25] Barbecues are traditionally held outside. They could be small informal gatherings with a few people in a backyard or a formal event that could last all day, typically held for larger numbers of people. Barbecue has been a tradition in the United States beginning with Native Americans. As author Andrew Warnes states, ""its mythology of savagery and freedom, of pleasure, masculinity and strength"" is part of what makes barbecues so popular to date.[25] By the 19th century barbecues became one of the main forms of United States public celebration, especially in celebration of 4 July.[26]
",5
5673,"As barbecues continued to be held through the times of U.S. expansion the traditions began to migrate with the people. Today, barbecues held in different regions of the country vary in cuisine but the cuisines all hold the same concept of cooking outside and over a fire.[27] Barbecues today have taken on new meaning yet again with the emergence of competitive barbecue. Competitive barbecue competitions are held throughout the country in which people will compete by cooking barbecue and having it judged by the events judges. The constraints of what one may barbecue and the qualities that are judged vary by competition. Usually competitions are held in big open areas where spectators will be admitted as well and barbecue is served to all.[28][29]
",5
5674,"Barbecuing encompasses multiple types of cooking techniques. The original technique is cooking using smoke at low temperatures—usually around 240–280 °F or 115–145 °C—and significantly longer cooking times (several hours), known as smoking. 
",5
5675,"Grilling is done over direct, dry heat, usually over a hot fire over 500 °F (260 °C) for a few minutes. Grilling may be done over wood, charcoal, gas, or electricity. The time difference between smoking and grilling is because of the temperature difference; at low temperatures used for smoking, meat takes several hours to reach the desired internal temperature.[30][31]
",5
5676,"Smoking is the process of flavoring, cooking, and/or preserving food by exposing it to smoke from burning or smoldering material, most often wood. Meat and fish are the most common smoked foods, though cheeses, vegetables, nuts, and ingredients used to make beverages such as beer or smoked beer are also smoked.[32][33]
",5
5677,"Grilling is a form of cooking that involves a dry heat applied to the food, either from above or below. Grilling is an effective technique in order to cook meat or vegetables quickly since it involves a significant amount of direct, radiant heat. There are many methods of grilling, which involve a type of braising or roasting. This is one of the least common techniques when cooking classic barbecue foods.[34]
",5
5678,"The words ""barbecue"" and ""grilling"" are often used interchangeably, although food experts argue that barbecue is a type of grilling, and that grilling involves the use of a higher level of heat to sear the food, while barbecuing is a slower process over a low heat.[35]
",5
5679,"The term barbecue is also used to designate a flavor added to food items, the most prominent of which are potato chips.[36]
",5
5680,"Wine is an alcoholic drink typically made from fermented grape juice. Yeast consumes the sugar in the grapes and converts it to ethanol, carbon dioxide, and heat. Different varieties of grapes and strains of yeasts produce different styles of wine. These variations result from the complex interactions between the biochemical development of the grape, the reactions involved in fermentation, the grape's growing environment (terroir), and the production process. Many countries enact legal appellations intended to define styles and qualities of wine. These typically restrict the geographical origin and permitted varieties of grapes, as well as other aspects of wine production. Wines not made from grapes involve fermentation of additional crops, including  rice wine and other fruit wines such as plum, cherry, pomegranate, currant and elderberry.
",5
5681,"Wine has been produced for thousands of years. The earliest evidence of wine is from ancient Georgia (6000 BC),[1][2] Persia (5000 BC), and Italy (4000 BC). New World wine has some connection to alcoholic beverages made by the indigenous peoples of the Americas, but is mainly connected to later Viking area of Vinland and Spanish traditions in New Spain.[3][4] Later, as Old World wine further developed viticulture techniques, Europe would encompass three of the largest wine-producing regions. Today, the five countries with the largest wine-producing regions are in Italy, Spain, France, the United States, and China.[5]
",5
5682,"Wine has long played an important role in religion. Red wine was associated with blood by the ancient Egyptians[6] and was used by both the Greek cult of Dionysus and the Romans in their Bacchanalia; Judaism also incorporates it in the Kiddush, and Christianity in the Eucharist. Egyptian, Greek, Roman, and Israeli wine cultures are still connected to these ancient roots. Similarly the largest wine regions in Italy, Spain, and France have heritages in connection to sacramental wine, likewise, viticulture traditions in the Southwestern United States started within New Spain as Catholic friars and monks first produced wines in New Mexico and California.[7][8][9]
",5
5683,"The earliest known traces of wine are from Georgia (c. 6000 BC),[10][11][12][13][14][15] Iran (Persia) (c. 5000 BC),[16][17] and Sicily (c. 4000 BC).[18] Wine reached the Balkans by 4500 BC and was consumed and celebrated in ancient Greece, Thrace and Rome. Throughout history, wine has been consumed for its intoxicating effects.[19][20][21]
",5
5684,"The earliest archaeological and archaeobotanical evidence for grape wine and viniculture, dating to 6000–5800 BC was found on the territory of modern Georgia.[22][23] Both archaeological and genetic evidence suggest that the earliest production of wine elsewhere was relatively later, likely having taken place in the Southern Caucasus (which encompasses Armenia, Georgia and Azerbaijan), or the West Asian region between Eastern Turkey, and northern Iran.[24][25]
",5
5685,"The earliest evidence of a rice and grape mixed based fermented drink was found in ancient China (c. 7000 BC),[26][27][28] earliest evidence of wine in Georgia from 6000 BC,[29][30][31] Iran from 5000 BC,[16] and Sicily from 4000 BC.[18]
",5
5686,"The earliest known wineries from 4100 BC is the Areni-1 winery in Armenia.[32][33] 
",5
5687,"A 2003 report by archaeologists indicates a possibility that grapes were mixed with rice to produce mixed fermented drinks in ancient China in the early years of the seventh millennium BC. Pottery jars from the Neolithic site of Jiahu, Henan, contained traces of tartaric acid and other organic compounds commonly found in wine. However, other fruits indigenous to the region, such as hawthorn, cannot be ruled out.[34][35] If these drinks, which seem to be the precursors of rice wine, included grapes rather than other fruits, they would have been any of the several dozen indigenous wild species in China, rather than Vitis vinifera, which was introduced 6000 years later.[34]
",5
5688,"The spread of wine culture westwards was most probably due to the Phoenicians who spread outward from a base of city-states along the Mediterranean coast of what are today Lebanon, Israel, Syria, and Palestine.[36] The wines of Byblos were exported to Egypt during the Old Kingdom and then throughout the Mediterranean. Evidence includes two Phoenician shipwrecks from 750 BC discovered by Robert Ballard, whose cargo of wine was still intact.[37] As the first great traders in wine (cherem), the Phoenicians seem to have protected it from oxidation with a layer of olive oil, followed by a seal of pinewood and resin, similar to retsina. Although the Nuragic culture in Sardinia already had a custom of consuming wine before the arrival of the Phoenicians.[38][39]
",5
5689,"The earliest remains of Apadana Palace in Persepolis dating back to 515 BC include carvings depicting soldiers from Achaemenid Empire subject nations bringing gifts to the Achaemenid king, among them Armenians bringing their famous wine.
",5
5690,"Literary references to wine are abundant in Homer (8th century BC, but possibly relating earlier compositions), Alkman (7th century BC), and others. In ancient Egypt, six of 36 wine amphoras were found in the tomb of King Tutankhamun bearing the name ""Kha'y"", a royal chief vintner. Five of these amphoras were designated as originating from the king's personal estate, with the sixth from the estate of the royal house of Aten.[40] Traces of wine have also been found in central Asian Xinjiang in modern-day China, dating from the second and first millennia BC.[41]
",5
5691,"The first known mention of grape-based wines in India is from the late 4th-century BC writings of Chanakya, the chief minister of Emperor Chandragupta Maurya. In his writings, Chanakya condemns the use of alcohol while chronicling the emperor and his court's frequent indulgence of a style of wine known as madhu.[42]
",5
5692,"The ancient Romans planted vineyards near garrison towns so wine could be produced locally rather than shipped over long distances. Some of these areas are now world-renowned for wine production.[43] The Romans discovered that burning sulfur candles inside empty wine vessels kept them fresh and free from a vinegar smell.[44] In medieval Europe, the Roman Catholic Church supported wine because the clergy required it for the Mass. Monks in France made wine for years, aging it in caves.[45] An old English recipe that survived in various forms until the 19th century calls for refining white wine from bastard—bad or tainted bastardo wine.[46]
",5
5693,"Later, the descendants of the sacramental wine were refined for a more palatable taste. This gave rise to modern viticulture in French wine, Italian wine, Spanish wine, and these wine grape traditions were brought into New World wine. For example, Mission grapes were brought by Franciscan monks to New Mexico in 1628 beginning the New Mexico wine heritage, these grapes were also brought to California which started the California wine industry. Both of these regions eventually evolved into American wine's oldest and largest wine producers respectively.[47][48][49] Earlier Viking expeditions of Vinland recorded the first  grape vines found in the New World,[50] and prior to the Spanish establishing their American wine grape traditions in California and New Mexico, both France and Britain had unsuccessfully attempted to establish grapevines in Florida and Virginia respectively.[51]
",5
5694,"The English word ""wine"" comes from the Proto-Germanic *winam, an early borrowing from the Latin vinum, Georgian ღვინო, ""wine"" or ""(grape) vine"", itself derived from the Proto-Indo-European stem *win-o- (cf. Armenian: գինի, gini; Ancient Greek: οἶνος oinos; Aeolic Greek: ϝοῖνος woinos; Hittite: wiyana; Lycian: oino).[52][53][54] The earliest attested terms referring to wine are the Mycenaean Greek 𐀕𐀶𐀺𐄀𐀚𐀺 me-tu-wo ne-wo (*μέθυϝος νέϝῳ),[55][56] meaning ""in (the month)"" or ""(festival) of the new wine"", and 𐀺𐀜𐀷𐀴𐀯 wo-no-wa-ti-si,[57] meaning ""wine garden"", written in Linear B inscriptions.[58][59][60][61] Linear B also includes, inter alia, an ideogram for wine, i.e. 𐂖.
",5
5695,"The ultimate Indo-European origin of the word is the subject of some continued debate. Some scholars have noted the similarities between the words for wine in Indo-European languages (e.g. Armenian gini, Latin vinum, Ancient Greek οἶνος, Russian вино [vʲɪˈno]), Kartvelian (e.g. Georgian ღვინო [ɣvinɔ]), and Semitic (*wayn; Hebrew יין [jajin]), pointing to the possibility of a common origin of the word denoting ""wine"" in these language families.[62] The Georgian word goes back to Proto-Kartvelian *ɣwino-,[63] which is either a borrowing from Proto-Indo-European[63][64][65][66][67][68] or the lexeme was specifically borrowed from Proto-Armenian *ɣʷeinyo-, whence Armenian gini.[69][70][71][72][63] An alternate hypothesis by Fähnrich supposes *ɣwino-, a native Kartvelian word derived from the verbal root *ɣun- ('to bend').[73] See *ɣwino- for more. All these theories place the origin of the word in the same geographical location, Trans-Caucasia, that has been established based on archeological and biomolecular studies as the origin of viticulture.
",5
5696,"Wines made in the styles listed below can be vinified in many ways, ranging from dry to sweet:
",5
5697,"The red-wine production process involves extraction of color and flavor components from the grape skin. Red wine is made from dark-colored grape varieties. The actual color of the wine can range from violet, typical of young wines, through red for mature wines, to brown for older red wines. The juice from most purple grapes is actually greenish-white; the red color comes from anthocyan pigments (also called anthocyanins) present in the skin of the grape; exceptions are the relatively uncommon teinturier varieties, which actually have red flesh and produce red juice.
",5
5698,"Fermentation of the non-colored grape pulp produces white wine. The grapes from which white wine is produced are typically green or yellow. Some varieties are well-known, such as the Chardonnay, Sauvignon, and Riesling. Other white wines are blended from multiple varieties; Tokay, Sherry, and Sauternes are examples of these. Dark-skinned grapes may be used to produce white wine if the wine-maker is careful not to let the skin stain the wort during the separation of the pulp-juice. Pinot noir, for example, is commonly used to produce champagne.
",5
5699,"Dry (non-sweet) white wine is the most common, derived from the complete fermentation of the wort. Sweet wines are produced when the fermentation is interrupted before all the grape sugars are converted into alcohol. Sparkling wines, which are mostly white wines, are produced by not allowing carbon dioxide from the fermentation to escape during fermentation, which takes place in the bottle rather than in the barrel.
",5
5700,"A rosé wine incorporates some of the color from the grape skins, but not enough to qualify it as a red wine. It may be the oldest known type of wine, as it is the most straightforward to make with the skin contact method. The pink color can range from a pale orange to a vivid near-purple, depending on the varietals used and wine-making techniques. There are three primary ways to produce rosé wine: skin contact (allowing dark grape skins to stain the wort), saignée (removing juice from the must early in fermentation and continuing fermentation of the juice separately), and blending (uncommon and discouraged in most wine growing regions). Rosé wines can be made still, semi-sparkling, or sparkling, with a wide range of sweetness levels from dry Provençal rosé to sweet White Zinfandels and blushes. Rosé wines are made from a wide variety of grapes all over the world.[74][75]
",5
5701,"Wines from other fruits, such as apples and berries, are usually named after the fruit from which they are produced, and combined with the word ""wine"" (for example, apple wine and elderberry wine) and are generically called fruit wine or country wine (similar to French term vin de pays). Other than the grape varieties traditionally used for wine-making, most fruits naturally lack either sufficient fermentable sugars, proper amount of  acidity, yeast amounts needed to promote or maintain fermentation, or a combination of these three Materials. This is probably one of the main reasons why wine derived from grapes has historically been more prevalent by far than other types, and why specific types of fruit wines have generally been confined to the regions in which the fruits were native or introduced for other reasons.
",5
5702,"Mead, also called honey wine, is created by fermenting honey with water, sometimes with various fruits, spices, grains, or hops. As long as the primary substance fermented is honey, the drink is considered mead.[76] Mead was produced in ancient history throughout Europe, Africa and Asia,[77] and was known in Europe before grape wine.[78]
",5
5703,"Other drinks called ""wine"", such as barley wine and rice wine (e.g. sake, huangjiu and cheongju), are made from starch-based materials and resemble beer  more than traditional  wine, while ginger wine is fortified with brandy. In these latter cases, the term ""wine"" refers to the similarity in alcohol content rather than to the production process.[79] The commercial use of the English word ""wine"" (and its equivalent in other languages) is protected by law in many jurisdictions.[80]
",5
5704,"Some UK supermarkets have been criticized for selling ""wine based"" drinks, which only contain 75% wine, but which are still marketed as wine. The International Organisation of Vine and Wine requires that a ""wine-based drink"" must contain a minimum of 75% wine, but producers do not have to divulge the nature of the remaining 25%.[81]
",5
5705,"Wine is usually made from one or more varieties of the European species Vitis vinifera, such as Pinot noir, Chardonnay, Cabernet Sauvignon, Gamay and Merlot. When one of these varieties is used as the predominant grape (usually defined by law as minimums of 75% to 85%), the result is a ""varietal"" as opposed to a ""blended"" wine. Blended wines are not necessarily inferior to varietal wines, rather they are a different style of wine-making.[82]
",5
5706,"Wine can also be made from other species of grape or from hybrids, created by the genetic crossing of two species. V. labrusca (of which the Concord grape is a cultivar), V. aestivalis, V. rupestris, V. rotundifolia and V. riparia are native North American grapes usually grown to eat fresh or for grape juice, jam, or jelly, and only occasionally made into wine.
",5
5707,"Hybridization is different from grafting. Most of the world's vineyards are planted with European Vitis vinifera vines that have been grafted onto North American species' rootstock, a common practice due to their resistance to phylloxera, a root louse that eventually kills the vine. In the late 19th century, most of Europe's vineyards (excluding some of the driest in the south) were devastated by the infestation, leading to widespread vine deaths and eventual replanting. Grafting is done in every wine-producing region in the world except in Argentina and the Canary Islands — the only places not yet exposed to the insect.[83]
",5
5708,"In the context of wine production, terroir is a concept that encompasses the varieties of grapes used, elevation and shape of the vineyard, type and chemistry of soil, climate and seasonal conditions, and the local yeast cultures.[84] The range of possible combinations of these factors can result in great differences among wines, influencing the fermentation, finishing, and aging processes as well. Many wineries use growing and production methods that preserve or accentuate the aroma and taste influences of their unique terroir.[85] However, flavor differences are less desirable for producers of mass-market table wine or other cheaper wines, where consistency takes precedence. Such producers try to minimize differences in sources of grapes through production techniques such as micro-oxygenation, tannin filtration, cross-flow filtration, thin-film evaporation,
and spinning cones.[86]
",5
5709,"About 700 grapes go into one bottle of wine, approximately 2.6 pounds.[87]
",5
5710,"Regulations govern the classification and sale of wine in many regions of the world. European wines tend to be classified by region (e.g. Bordeaux, Rioja and Chianti), while non-European wines are most often classified by grape (e.g. Pinot noir and Merlot). Market recognition of particular regions has recently been leading to their increased prominence on non-European wine labels. Examples of recognized non-European locales include Napa Valley, Santa Clara Valley, Sonoma Valley, Anderson Valley, and Mendocino County in California; Willamette Valley and Rogue Valley in Oregon; Columbia Valley in Washington; Barossa Valley in South Australia; Hunter Valley in New South Wales; Luján de Cuyo in Argentina; Vale dos Vinhedos in Brazil; Hawke's Bay and Marlborough in New Zealand; Central Valley in Chile; and in Canada, the Okanagan Valley of British Columbia, and the Niagara Peninsula and Essex County regions of Ontario are the three largest producers.
",5
5711,"Some blended wine names are marketing terms whose use is governed by trademark law rather than by specific wine laws. For example, Meritage (sounds like ""heritage"") is generally a Bordeaux-style blend of Cabernet Sauvignon and Merlot, but may also include Cabernet Franc, Petit Verdot, and Malbec. Commercial use of the term Meritage is allowed only via licensing agreements with the Meritage Association.
",5
5712,"France has various appellation systems based on the concept of terroir, with classifications ranging from Vin de Table (""table wine"") at the bottom, through Vin de Pays and Appellation d'Origine Vin Délimité de Qualité Supérieure (AOVDQS), up to Appellation d'Origine Contrôlée (AOC) or similar, depending on the region.[88][89] Portugal has developed a system resembling that of France and, in fact, pioneered this concept in 1756 with a royal charter creating the Demarcated Douro Region and regulating the production and trade of wine.[90] Germany created a similar scheme in 2002, although it has not yet achieved the authority of the other countries' classification systems.[91][92] Spain, Greece and Italy have classifications based on a dual system of region of origin and product quality.[93]
",5
5713,"New World wines—those made outside the traditional wine regions of Europe—are usually classified by grape rather than by terroir or region of origin, although there have been unofficial attempts to classify them by quality.[94][95][needs update]
",5
5714,"According to Canadian Food and Drug Regulations, wine in Canada is an alcoholic drink that is produced by the complete or partial alcoholic fermentation of fresh grapes, grape must, products derived solely from fresh grapes, or any combination of them. There are many materials added during the course of the manufacture, such as yeast, concentrated grape juice, dextrose, fructose, glucose or glucose solids, invert sugar, sugar, or aqueous solutions. Calcium sulphate in such quantity that the content of soluble sulphates in the finished wine shall not exceed 0.2 percent weight by volume calculated as potassium sulphate. Calcium carbonate in such quantity that the content of tartaric acid in the finished wine shall not be less than 0.15 percent weight by volume. Also, sulphurous acid, including salts thereof, in such quantity that its content in the finished wine shall not exceed 70 parts per million in the free state, or 350 parts per million in the combined state, calculated as sulphur dioxide. Caramel, amylase and pectinase at a maximum level of use consistent with good manufacturing practice. Brandy, fruit spirit or alcohol derived from the alcoholic fermentation of a food source distilled to not less than 94 percent alcohol by volume.[clarification needed] Prior to final filtration may be treated with a strongly acid cation exchange resin in the sodium ion form, or a weakly basic anion exchange resin in the hydroxyl ion form.[96]
",5
5715,"In the United States, for a wine to be vintage-dated and labeled with a country of origin or American Viticultural Area (AVA; e.g., Sonoma Valley), 95% of its volume must be from grapes harvested in that year.[97] If a wine is not labeled with a country of origin or AVA the percentage requirement is lowered to 85%.[97]
",5
5716,"Vintage wines are generally bottled in a single batch so that each bottle will have a similar taste. Climate's impact on the character of a wine can be significant enough to cause different vintages from the same vineyard to vary dramatically in flavor and quality.[98] Thus, vintage wines are produced to be individually characteristic of the particular vintage and to serve as the flagship wines of the producer. Superior vintages from reputable producers and regions will often command much higher prices than their average ones. Some vintage wines (e.g. Brunello), are only made in better-than-average years.
",5
5717,"For consistency, non-vintage wines can be blended from more than one vintage, which helps wine-makers sustain a reliable market image and maintain sales even in bad years.[99][100] One recent study suggests that for the average wine drinker, the vintage year may not be as significant for perceived quality as had been thought, although wine connoisseurs continue to place great importance on it.[101]
",5
5718,"Wine tasting is the sensory examination and evaluation of wine. Wines contain many chemical compounds similar or identical to those in fruits, vegetables, and spices. The sweetness of wine is determined by the amount of residual sugar in the wine after fermentation, relative to the acidity present in the wine. Dry wine, for example, has only a small amount of residual sugar. Some wine labels suggest opening the bottle and letting the wine ""breathe"" for a couple of hours before serving, while others recommend drinking it immediately. Decanting (the act of pouring a wine into a special container just for breathing) is a controversial subject among wine enthusiasts. In addition to aeration, decanting with a filter allows the removal of bitter sediments that may have formed in the wine. Sediment is more common in older bottles, but aeration may benefit younger wines.[102]
",5
5719,"During aeration, a younger wine's exposure to air often ""relaxes"" the drink, making it smoother and better integrated in aroma, texture, and flavor. Older wines generally fade (lose their character and flavor intensity) with extended aeration.[103] Despite these general rules, breathing does not necessarily benefit all wines. Wine may be tasted as soon as the bottle is opened to determine how long it should be aerated, if at all.[104][better source needed] When tasting wine, individual flavors may also be detected, due to the complex mix of organic molecules (e.g. esters and terpenes) that grape juice and wine can contain. Experienced tasters can distinguish between flavors characteristic of a specific grape and flavors that result from other factors in wine-making. Typical intentional flavor elements in wine—chocolate, vanilla, or coffee—are those imparted by aging in oak casks rather than the grape itself.[105]
",5
5720,"Vertical and horizontal tasting involves a range of vintages within the same grape and vineyard, or the latter in which there is one vintage from multiple vineyards. ""Banana"" flavors (isoamyl acetate) are the product of yeast metabolism, as are spoilage aromas such as ""medicinal"" or ""Band-Aid"" (4-ethylphenol), ""spicy"" or ""smoky"" (4-ethylguaiacol),[106] and rotten egg (hydrogen sulfide).[107] Some varieties can also exhibit a mineral flavor due to the presence of water-soluble salts as a result of limestone's presence in the vineyard's soil. Wine aroma comes from volatile compounds released into the air.[108] Vaporization of these compounds can be accelerated by twirling the wine glass or serving at room temperature. Many drinkers prefer to chill red wines that are already highly aromatic, like Chinon and Beaujolais.[109]
",5
5721,"The ideal temperature for serving a particular wine is a matter of debate by wine enthusiasts and sommeliers, but some broad guidelines have emerged that will generally enhance the experience of tasting certain common wines. White wine should foster a sense of coolness, achieved by serving at ""cellar temperature"" (13 °C (55 °F)). Light red wines drunk young should also be brought to the table at this temperature, where they will quickly rise a few degrees.  Red wines are generally perceived best when served chambré (""at room temperature""). However, this does not mean the temperature of the dining room—often around 21 °C (70 °F)—but rather the coolest room in the house and, therefore, always slightly cooler than the dining room itself.  Pinot noir should be brought to the table for serving at 16 °C (61 °F) and will reach its full bouquet at 18 °C (64 °F). Cabernet Sauvignon, zinfandel, and Rhone varieties should be served at 18 °C (64 °F) and allowed to warm on the table to 21 °C (70 °F) for best aroma.[110]
",5
5722,"Outstanding vintages from the best vineyards may sell for thousands of dollars per bottle, though the broader term ""fine wine"" covers those typically retailing in excess of US$30–50.[111] ""Investment wines"" are considered by some to be Veblen goods: those for which demand increases rather than decreases as their prices rise.
Particular selections such as ""Verticals"", which span multiple vintages of a specific grape and vineyard, may be highly valued. The most notable was a Château d'Yquem 135-year vertical containing every vintage from 1860 to 2003 sold for $1.5 million.
The most common wines purchased for investment include those from Bordeaux and Burgundy; cult wines from Europe and elsewhere; and vintage port. Characteristics of highly collectible wines include:
",5
5723,"Investment in fine wine has attracted those who take advantage of their victims' relative ignorance of this wine market sector.[112] Such wine fraudsters often profit by charging excessively high prices for off-vintage or lower-status wines from well-known wine regions, while claiming that they are offering a sound investment unaffected by economic cycles. As with any investment, thorough research is essential to making an informed decision.
",5
5724,"* May include official, semi-official or estimated data.
",5
5725,"Wine grapes grow almost exclusively between 30 and 50 degrees latitude north and south of the equator. The world's southernmost vineyards are in the Central Otago region of New Zealand's South Island near the 45th parallel south,[114] and the northernmost are in Flen, Sweden, just north of the 59th parallel north.[115]
",5
5726,"* May include official, semi-official or estimated data.
 
",5
5727,"
",5
5728,"
",5
5729,"The UK was the world's largest importer of wine in 2007.[117]
",5
5730,"Wine-consumption data from a list of countries by alcohol consumption measured in liters of pure ethyl alcohol consumed per capita in a given year, according to the most recent data from the World Health Organization. The methodology includes persons 15 years of age or older.[120] About 40% of individuals above the legal drinking age consider themselves ""wine drinkers"", which is higher than all other alcoholic beverages combined (34%) and those who do not drink at all (26%).[121]
",5
5731,"
",5
5732,"
",5
5733,"Wine is a popular and important drink that accompanies and enhances a wide range of cuisines, from the simple and traditional stews to the most sophisticated and complex haute cuisines. Wine is often served with dinner. Sweet dessert wines may be served with the dessert course. In fine restaurants in Western countries, wine typically accompanies dinner. At a restaurant, patrons are helped to make good food-wine pairings by the restaurant's sommelier or wine waiter. Individuals dining at home may use wine guides to help make food–wine pairings. Wine is also drunk without the accompaniment of a meal in wine bars or with a selection of cheeses (at a wine and cheese party). Wines are also used as a theme for organizing various events such as festivals around the world; the city of Kuopio in North Savonia, Finland is known for its annual Kuopio Wine Festivals (Kuopion viinijuhlat).[122]
",5
5734,"Wine is important in cuisine not just for its value as a drink, but as a flavor agent, primarily in stocks and braising, since its acidity lends balance to rich savory or sweet dishes.[123] Wine sauce is an example of a culinary sauce that uses wine as a primary ingredient.[124] Natural wines may exhibit a broad range of alcohol content, from below 9% to above 16% ABV, with most wines being in the 12.5–14.5% range.[125] Fortified wines (usually with brandy) may contain 20% alcohol or more.
",5
5735,"The use of wine in ancient Near Eastern and Ancient Egyptian religious ceremonies was common. Libations often included wine, and the religious mysteries of Dionysus used wine as a sacramental entheogen to induce a mind-altering state.
",5
5736,"Baruch atah Hashem (Ado-nai) Eloheinu melech ha-olam, boray p'ree hagafen – Praised be the Lord, our God, King of the universe, Creator of the fruit of the vine.",5
5737,"Wine is an integral part of Jewish laws and traditions. The Kiddush is a blessing recited over wine or grape juice to sanctify the Shabbat. On Pesach (Passover) during the Seder, it is a Rabbinic obligation of adults to drink four cups of wine.[126] In the Tabernacle and in the Temple in Jerusalem, the libation of wine was part of the sacrificial service.[127] Note that this does not mean that wine is a symbol of blood, a common misconception that contributes to the Christian beliefs of the blood libel.
""It has been one of history's cruel ironies that the blood libel—accusations against Jews using the blood of murdered gentile children for the making of wine and matzot—became the false pretext for numerous pogroms. And due to the danger, those who live in a place where blood libels occur are halachically exempted from using red wine, lest it be seized as ""evidence"" against them.""[128]
",5
5738,"In Christianity, wine is used in a sacred rite called the Eucharist, which originates in the Gospel account of the Last Supper (Gospel of Luke 22:19) describing Jesus sharing bread and wine with his disciples and commanding them to ""do this in remembrance of me."" Beliefs about the nature of the Eucharist vary among denominations (see Eucharistic theologies contrasted).
",5
5739,"While some Christians consider the use of wine from the grape as essential for the validity of the sacrament, many Protestants also allow (or require) pasteurized grape juice as a substitute. Wine was used in Eucharistic rites by all Protestant groups until an alternative arose in the late 19th century. Methodist dentist and prohibitionist Thomas Bramwell Welch applied new pasteurization techniques to stop the natural fermentation process of grape juice. Some Christians who were part of the growing temperance movement pressed for a switch from wine to grape juice, and the substitution spread quickly over much of the United States, as well as to other countries to a lesser degree.[129] There remains an ongoing debate between some American Protestant denominations as to whether wine can and should be used for the Eucharist or allowed as an ordinary drink, with Catholics and some mainline Protestants allowing wine drinking in moderation, and some conservative Protestant groups opposing consumption of alcohol altogether.[citation needed]
",5
5740,"The earliest viticulture tradition in the Southwestern United States starts with sacramental wine, beginning in the 1600s, with Christian friars and monks producing New Mexico wine.[130]
",5
5741,"Alcoholic drinks, including wine, are forbidden under most interpretations of Islamic law.[131] In many Muslim countries, possession or consumption of alcoholic drinks carry legal penalties. Iran had previously had a thriving wine industry that disappeared after the Islamic Revolution in 1979.[132] In Greater Persia, mey (Persian wine) was a central theme of poetry for more than a thousand years, long before the advent of Islam. Some Alevi sects – one of the two main branches of Islam in Turkey (the other being Sunni Islam) – use wine in their religious services.[citation needed]
",5
5742,"Certain exceptions to the ban on alcohol apply. Alcohol derived from a source other than the grape (or its byproducts) and the date[133] is allowed in ""very small quantities"" (loosely defined as a quantity that does not cause intoxication) under the Sunni Hanafi madhab, for specific purposes (such as medicines), where the goal is not intoxication. However, modern Hanafi scholars regard alcohol consumption as totally forbidden.[134]
",5
5743,"Wine contains ethyl alcohol, the intoxicating chemical in beer and distilled spirits. Different concentrations of alcohol in the human body have different effects on a person. The effects of wine depend on the amount of it consumed, the span of time over which consumption takes place, the amount of alcohol in the wine, and the amount of food eaten, among other factors. Drinking enough to reach a blood alcohol concentration (BAC) of 0.03%-0.12% typically causes an overall improvement in mood, increased self-confidence and sociability, decreased anxiety, flushing of the face, and impairment of judgment and fine motor coordination. A BAC of 0.09% to 0.25% causes lethargy, sedation, balance problems and blurred vision. A BAC from 0.18% to 0.30% causes profound confusion, impaired speech (e.g. slurred speech), staggering, dizziness and vomiting. A BAC from 0.25% to 0.40% causes stupor, unconsciousness, anterograde amnesia, vomiting, and death may occur due to respiratory depression and inhalation of vomit during unconsciousness. A BAC from 0.35% to 0.80% causes coma, life-threatening respiratory depression and possibly fatal alcohol poisoning. The operation of vehicles or machinery while drunk increases the risk of accident, and many countries have laws against drinking and driving.
",5
5744,"Wines can trigger positive emotions in a short period of time, such as feelings of relaxation and comfort. The context and quality of wine can affect the mood and emotions, too.[135]
",5
5745,"The main active ingredient of wine is alcohol, and therefore, the health effects of alcohol apply to wine. A 2016 systematic review and meta-analysis found that moderate ethanol consumption brought no mortality benefit compared with lifetime abstention from ethanol consumption.[136] A systematic analysis of data from the Global Burden of Disease study found that consumption of ethanol increases the risk of cancer and increases the risk of all-cause mortality, and that the level of ethanol consumption that minimizes disease is zero consumption.[137] Some studies have concluded that drinking small quantities of alcohol (less than one drink in women and two in men)[how often?] is associated with a decreased risk of heart disease, stroke, diabetes mellitus, and early death.[138]  Drinking more than this amount actually increases the risk of heart disease, high blood pressure, atrial fibrillation, and stroke. Some of these studies lumped former ethanol drinkers and life-long abstainers into a single group of nondrinkers, hiding the health benefits of life-long abstention from ethanol.[138] Risk is greater in younger people due to binge drinking which may result in violence or accidents.[138] About 3.3 million deaths (5.9% of all deaths) are believed to be due to alcohol each year.[139]
",5
5746,"Alcoholism is a broad term for any drinking of alcohol that results in problems.[140] It was previously divided into two types: alcohol abuse and alcohol dependence.[141][142] In a medical context, alcoholism is said to exist when two or more of the following conditions is present: a person drinks large amounts over a long time period, has difficulty cutting down, acquiring and drinking alcohol takes up a great deal of time, alcohol is strongly desired, usage results in not fulfilling responsibilities, usage results in social problems, usage results in health problems, usage results in risky situations, withdrawal occurs when stopping, and alcohol tolerance has occurred with use.[142] Alcoholism reduces a person's life expectancy by around ten years[143] and alcohol use is the third leading cause of early death in the United States.[138] No professional medical association recommends that people who are nondrinkers should start drinking wine.[138][144]
",5
5747,"Excessive consumption of alcohol can cause liver cirrhosis and alcoholism.[145] The American Heart Association ""cautions people NOT to start drinking ... if they do not already drink alcohol. Consult your doctor on the benefits and risks of consuming alcohol in moderation.""[146]
",5
5748,"Population studies exhibit a J-curve correlation between wine consumption and rates of heart disease: heavy drinkers have an elevated rate, while people who drink small amount (up to 20 g of alcohol per day, approximately 200 ml (7 imp fl oz; 7 US fl oz) of 12.7% ABV wine) have a lower rate than non-drinkers. Studies have also found that moderate consumption of other alcoholic drinks is correlated with decreased mortality from cardiovascular causes,[147] although the association is stronger for wine. Additionally, some studies have found a greater correlation of health benefits with red than white wine, though other studies have found no difference. Red wine contains more polyphenols than white wine, and these could be protective against cardiovascular disease.[148]
",5
5749,"Although red wine contains the chemical resveratrol and there is tentative evidence it may improve heart health, the evidence is unclear for those at high risk as of 2013[update].[149] Grape skins naturally produce resveratrol in response to fungal infection, including exposure to yeast during fermentation. White wine generally contains lower levels of the chemical as it has minimal contact with grape skins during this process.[150]
",5
5750,"Incidents of fraud, such as mislabeling the origin or quality of wines, have resulted in regulations on labeling. ""Wine scandals"" that have received media attention include:
",5
5751,"Most wines are sold in glass bottles and sealed with corks (50% of which come from Portugal).[154] An increasing number of wine producers have been using alternative closures such as screwcaps and synthetic plastic ""corks"". Although alternative closures are less expensive and prevent cork taint, they have been blamed for such problems as excessive reduction.[155]
",5
5752,"Some wines are packaged in thick plastic bags within corrugated fiberboard boxes, and are called ""box wines"", or ""cask wine"". Tucked inside the package is a tap affixed to the bag in box, or bladder, that is later extended by the consumer for serving the contents. Box wine can stay acceptably fresh for up to a month after opening because the bladder collapses as wine is dispensed, limiting contact with air and, thus, slowing the rate of oxidation. In contrast, bottled wine oxidizes more rapidly after opening because of the increasing ratio of air to wine as the contents are dispensed; it can degrade considerably in a few days. Cans are one of the fastest-growing forms of alternative wine packaging on the market.[156]
",5
5753,"Environmental considerations of wine packaging reveal the benefits and drawbacks of both bottled and box wines. The glass used to make bottles is a nontoxic, naturally occurring substance that is completely recyclable, whereas the plastics used for box-wine containers are typically much less environmentally friendly. However, wine-bottle manufacturers have been cited for Clean Air Act violations. A New York Times editorial suggested that box wine, being lighter in package weight, has a reduced carbon footprint from its distribution; however, box-wine plastics, even though possibly recyclable, can be more labor-intensive (and therefore expensive) to process than glass bottles. In addition, while a wine box is recyclable, its plastic bladder most likely is not.[157] Some people are drawn to canned wine due to its portability and recyclable packaging.[156]
",5
5754,"Some wine is sold in stainless steel kegs and is referred to as wine on tap.
",5
5755,"Wine cellars, or wine rooms, if they are above-ground, are places designed specifically for the storage and aging of wine. Fine restaurants and some private homes have wine cellars. In an active wine cellar, temperature and humidity are maintained by a climate-control system. Passive wine cellars are not climate-controlled, and so must be carefully located. Because wine is a natural, perishable food product, all types—including red, white, sparkling, and fortified—can spoil when exposed to heat, light, vibration or fluctuations in temperature and humidity. When properly stored, wines can maintain their quality and in some cases improve in aroma, flavor, and complexity as they age. Some wine experts contend that the optimal temperature for aging wine is 13 °C (55 °F),[158] others 15 °C (59 °F).[159]
",5
5756,"Wine refrigerators offer a smaller alternative to wine cellars and are available in capacities ranging from small, 16-bottle units to furniture-quality pieces that can contain 400 bottles. Wine refrigerators are not ideal for aging, but rather serve to chill wine to the proper temperature for drinking. These refrigerators keep the humidity low (usually under 50%), below the optimal humidity of 50% to 70%. Lower humidity levels can dry out corks over time, allowing oxygen to enter the bottle, which reduces the wine's quality through oxidation.[160] While some types of alcohol are sometimes stored in the freezer, such as vodka, it is not possible to safely freeze wine in the bottle, as there is insufficient room for it to expand as it freezes and the bottle will usually crack. Certain shapes of bottle may allow the cork to be pushed out by the ice, but if the bottle is frozen on its side, the wine in the narrower neck will invariably freeze first, preventing this.
",5
5757,"There are a large number of occupations and professions that are part of the wine industry, ranging from the individuals who grow the grapes, prepare the wine, bottle it, sell it, assess it, market it and finally make recommendations to clients and serve the wine.
",5
5758,"
",5
5759,"A chef is a trained professional cook and tradesman who is proficient in all aspects of food preparation, often focusing on a particular cuisine. The word ""chef"" is derived from the term chef de cuisine (French pronunciation: ​[ʃɛf.də.kɥi.zin]), the director or head of a kitchen. Chefs can receive formal training from an institution, as well as by apprenticing with an experienced chef.
",5
5760,"There are different terms that use the word chef in their titles, and deal with specific areas of food preparation. Examples include the sous-chef, who acts as the second-in-command in a kitchen, and the chef de partie, who handles a specific area of production. The kitchen brigade system is a hierarchy found in restaurants and hotels employing extensive staff, many of which use the word ""chef"" in their titles. Underneath the chefs are the kitchen assistants. A chef's standard uniform includes a hat (called a toque), neckerchief, double-breasted jacket, apron and sturdy shoes (that may include steel or plastic toe-caps).
",5
5761,"The word ""chef"" is derived (and shortened) from the term chef de cuisine (French pronunciation: ​[ʃɛf.də.kɥi.zin]), the director or head of a kitchen. (The French word comes from Latin caput (head) and is cognate with English ""chief""). In English, the title ""chef"" in the culinary profession originated in the haute cuisine of the 19th century. The culinary arts, among other aspects of the French language introduced French loan-words into the English language.[1]
",5
5762,"Various titles, detailed below, are given to those working in a professional kitchen and each can be considered a title for a type of chef. Many of the titles are based on the brigade de cuisine (or brigade system) documented by Auguste Escoffier, while others have a more general meaning depending on the individual kitchen.
",5
5763,"Other names include executive chef, chef manager, head chef, and master chef. This person is in charge of all activities related to the kitchen, which usually includes menu creation, management of kitchen staff, ordering and purchasing of inventory, controlling raw material costs and plating design. Chef de cuisine is the traditional French term from which the English word chef is derived.[2] Head chef is often used to designate someone with the same duties as an executive chef, but there is usually someone in charge of a head chef, possibly making the larger executive decisions such as direction of menu, final authority in staff management decisions, and so on.[3] This is often the case for executive chefs with multiple restaurants. Involved in checking the sensory evaluation of dishes after preparation and they are well aware of each sensory property of those specific dishes.
",5
5764,"In the UK, the title executive chef normally applies to hotels with multi outlets in the same hotel. Other establishments in the UK tend to use the title head chef.
",5
5765,"
",5
5766,"The sous-chef de cuisine (under-chef of the kitchen) is the second-in-command and direct assistant of the chef de cuisine. The sous-chef works under executive chef or head chef. This person may be responsible for scheduling the kitchen staff, or substituting when the head chef is off-duty. Also, he or she will fill in for or assist a chef de partie (line cook) when needed. This person is accountable for the kitchen's inventory, cleanliness, organization, and the continuing training of its entire staff. A sous-chef's duties can also include carrying out the head chef's directives, conducting line checks, and overseeing the timely rotation of all food products. Smaller operations may not have a sous-chef, while larger operations may have more than one.[4]
The sous chef is also responsible when the Executive Chef is absent.
",5
5767,"A chef de partie, also known as a ""station chef"" or ""line cook"",[5] is in charge of a particular area of production. In large kitchens, each chef de partie might have several cooks or assistants. In most kitchens, however, the chef de partie is the only worker in that department.  Line cooks are often divided into a hierarchy of their own, starting with ""first cook"", then ""second cook"", and so on as needed.
",5
5768,"A commis is a basic chef in larger kitchens who works under a chef de partie to learn the station's or range's responsibilities and operation.[6] This may be a chef who has recently completed formal culinary training or is still undergoing training.
",5
5769,"Station-chef titles which are part of the brigade system include:[7]
",5
5770,"
",5
5771,"Kitchen assistants are of two types, kitchen-hands and stewards/ kitchen porters. Kitchen-hands assist with basic food preparation tasks under the chef's direction. They carry out relatively unskilled tasks such as peeling potatoes and washing salad. Stewards/ kitchen porters are involved in the scullery, washing up and general cleaning duties. In a smaller kitchen, these duties may be incorporated.
",5
5772,"A communard is in charge of preparing the meal for the staff during a shift. This meal is often referred to as the staff or family meal.[6]
",5
5773,"The escuelerie (from 15th century French and a cognate of the English ""scullery""), or the more modern plongeur or dishwasher, is the keeper of dishes, having charge of dishes and keeping the kitchen clean. A common humorous title for this role in some modern kitchens is ""chef de plonge"" or ""head dishwasher"".[8]
",5
5774,"Education is available from many culinary institutions offering diploma, associate, and bachelor's degree programs in culinary arts. Depending on the level of education, this can take one to four years. An internship is often part of the curriculum. Regardless of the education received, most professional kitchens follow the apprenticeship system, and most new cooks will start at a lower-level 2nd or 1st cook position and work their way up. 
",5
5775,"Like many skilled trades, chefs usually go through a formal apprenticeship which includes many years of on-the-job training. Culinary schools and restaurants offer these apprenticeships. To become an apprentice, one must be at least 18 years old and have a high school diploma or GED. Apprenticeships usually take 3 to 4 years to complete and combine classroom instruction with on-the-job training. The training period for a chef is generally four years as an apprentice. A newly qualified chef is advanced or more commonly a toquecommis-chef, consisting of first-year commis, second-year commis, and so on. The rate of pay is usually in accordance with the chefs. Like all other chefs except the executive-chef, trainees are placed in sections of the kitchen (e.g., the starter (appetizer) or entrée sections) under the guidance of a demi-chef de partie and are given relatively basic tasks. Ideally, over time, a commis will spend a certain period in each section of the kitchen to learn the basics. Unaided, a commis may work on the vegetable station of a kitchen.[9]
",5
5776,"The usual formal training period for a chef is two to four years in catering college. They often spend the summer in work placements. In some cases this is modified to 'day-release' courses; a chef will work full-time in a kitchen as an apprentice and then would have allocated days off to attend catering college. These courses can last between one and three years. In the UK, most Chefs are trained in the work place, with most doing a formal NVQ level 2 or 3 in the work place.
",5
5777,"The standard uniform for a chef includes a hat called a toque, necktie, double-breasted jacket, apron and shoes with steel or plastic toe-caps. A chef's hat was originally designed as a tall rippled hat called a Dodin Bouffant or more commonly a toque. 
",5
5778,"Neckties were originally worn to allow for the mopping of sweat from the face, but as this is now against health regulations, they are largely decorative. The chef's neck tie was originally worn on the inside of the jacket to stop sweat running from the face and neck down the body.[10] The jacket is usually white to show off the chef's cleanliness and repel heat, and is double-breasted to prevent serious injuries from burns and scalds. The double breast also serves to conceal stains on the jacket as one side can be rebuttoned over the other, which is common practice.
",5
5779,"An apron is worn to just below knee-length, also to assist in the prevention of burns because of spillage. If hot liquid is spilled onto it, the apron can be quickly removed to minimize burns and scalds. Shoes and clogs are hard-wearing and with a steel-top cap to prevent injury from falling objects or knives. According to some hygiene regulations, jewelry is not allowed apart from wedding bands and religious jewelry. If wound dressings are required they should be blue—an unusual colour for foodstuffs—so that they are noticeable if they fall into food. Facial hair and longer hair are often required to be netted, or trimmed, for food safety.[citation needed] Bandages on the hands are usually covered with nylon gloves. Latex is not typically used for food preparation due to latex allergy.
",5
5780,"
",5
5781,"Spaghetti (Italian: [spaˈɡetti]) is a long, thin, solid, cylindrical pasta.[1] It is a staple food of traditional Italian cuisine. Like other pasta, spaghetti is made of milled wheat and water and sometimes enriched with vitamins and minerals. Italian spaghetti is typically made from durum wheat semolina.[2] Usually the pasta is white because refined flour is used, but whole wheat flour may be added. Spaghettoni is a thicker form of spaghetti, while capellini is a very thin spaghetti. 
",5
5782,"Originally, spaghetti was notably long, but shorter lengths gained in popularity during the latter half of the 20th century and now it is most commonly available in 25–30 cm (10–12 in) lengths. A variety of pasta dishes are based on it and it is frequently served with tomato sauce or meat or vegetables.
",5
5783,"Spaghetti is the plural form of the Italian word spaghetto, which is a diminutive of spago, meaning ""thin string"" or ""twine"".[1]
",5
5784,"The first written record of pasta comes from the Talmud in the 5th century AD and refers to dried pasta that could be cooked through boiling,[3] which was conveniently portable.[4] Some historians think that Berbers introduced pasta to Europe during a conquest of Sicily. In the West, it may have first been worked into long, thin forms in Sicily around the 12th century, as the Tabula Rogeriana of Muhammad al-Idrisi attested, reporting some traditions about the Sicilian kingdom.[5]
",5
5785,"The popularity of spaghetti spread throughout Italy after the establishment of spaghetti factories in the 19th century, enabling the mass production of spaghetti for the Italian market.[6]
",5
5786,"In the United States around the end of the 19th century, spaghetti was offered in restaurants as Spaghetti Italienne (which likely consisted of noodles cooked past al dente, and a mild tomato sauce flavored with easily found spices and vegetables such as cloves, bay leaves, and garlic) and it was not until decades later that it came to be commonly prepared with oregano or basil.[7][8][9]
",5
5787,"Spaghetti is made from ground grain (flour) and water.[10] Whole-wheat and multigrain spaghetti are also available.[2]
",5
5788,"At its simplest, imitation spaghetti can be formed using no more than a rolling pin and a knife. A home pasta machine simplifies the rolling and makes the cutting more uniform.[11] But of course cutting sheets produces pasta with a rectangular rather than a cylindrical cross-section and the result is a variant of Fettucine. Some pasta machines have a spaghetti attachment with circular holes that extrude spaghetti or shaped rollers that form cylindrical noodles.
",5
5789,"Spaghetti can be made by hand by manually rolling a ball of dough on a surface to make a long sausage shape. The ends of the sausage are pulled apart to make a long thin sausage. The ends are brought together and the loop pulled to make two long sausages. The process is repeated until the pasta is sufficiently thin. The pasta knobs at each end are cut off leaving many strands which may be hung up to dry.[12]
",5
5790,"Fresh spaghetti would normally be cooked within hours of being formed. Commercial versions of fresh spaghetti are manufactured.
",5
5791,"The bulk of dried spaghetti is produced in factories using auger extruders. While essentially simple, the process requires attention to detail to ensure that the mixing and kneading of the ingredients produces a homogeneous mix, without air bubbles. The forming dies have to be water cooled to prevent spoiling of the pasta by overheating. Drying of the newly formed spaghetti has to be carefully controlled to prevent strands sticking together, and to leave it with sufficient moisture so that it is not too brittle. Packaging for protection and display has developed from paper wrapping to plastic bags and boxes.[13]
",5
5792,"A hydraulic press with automatic spreader built by Consolidated Macaroni Machine Corporation, Brooklyn, New York. This machine was the first ever made to spread long cut alimentary paste products on to a drying stick for the automatic production of spaghetti.
",5
5793,"An industrial dryer for spaghetti or other long goods pasta products. Built by Consolidated Macaroni Machine Corporation
",5
5794,"Dried spaghetti
",5
5795,"Dried spaghetti being measured with a ""spaghetti measure"". 1 portion of dried pasta equals 120 grams (4.1 oz), twice the amount of 1 serving on the package (12 mm circle or 60 g.). The measure can portion out 1, 2, 3, or 4 servings based on the diameter of the circle. This spaghetti is an enriched macaroni product made with 100% semolina.
",5
5796,"Fresh or dry spaghetti is cooked in a large pot of salted, boiling water and then drained in a colander (Italian: scolapasta).
",5
5797,"In Italy, spaghetti is generally cooked al dente (Italian for ""to the tooth""), fully cooked but still firm to the bite. It may also be cooked to a softer consistency.
",5
5798,"Spaghettoni is a thicker spaghetti which takes more time to cook. Spaghettini is a thinner form which takes less time to cook. Capellini is a very thin form of spaghetti (it is also called ""angel hair spaghetti"" or ""angel hair pasta"") which cooks very quickly.
",5
5799,"Utensils used in spaghetti preparation include the spaghetti scoop and spaghetti tongs.
",5
5800,"Spaghetti being placed into a pot of boiling water for cooking
",5
5801,"Draining the water from boiled spaghetti
",5
5802,"A spaghetti scoop
",5
5803,"Spaghetti tongs
",5
5804,"An emblem of Italian cuisine, spaghetti is frequently served with tomato sauce, which may contain various herbs (especially oregano and basil), olive oil, meat, or vegetables. Other spaghetti preparations include amatriciana or carbonara. Grated hard cheeses, such as Pecorino Romano, Parmesan and Grana Padano, are often sprinkled on top.
",5
5805,"In some countries, spaghetti is sold in cans/tins with sauce.
",5
5806,"In the United States, it is sometimes served with chili con carne. Unlike in Italy, in other countries spaghetti is often served with Bolognese sauce.
",5
5807,"In the Philippines, an immensely popular variant is the Filipino spaghetti, which is distinctively sweet with the tomato sauce sweetened with banana ketchup or sugar. It typically uses a large amount of giniling (ground meat), sliced hotdogs, and cheese. The dish dates back to the period between the 1940s to the 1960s. During the American Commonwealth Period, a shortage of tomato supplies in the Second World War forced the development of the banana ketchup.[14][15][16] Spaghetti was introduced by the Americans and was tweaked to suit the local Filipino predilection for sweet dishes.[17]
",5
5808,"Sapaketti phat khi mao (Spaghetti fried drunken noodle style) is a popular dish in Thai cuisine.[18]
",5
5809,"Spaghetti aglio e olio
",5
5810,"Spaghetti alla puttanesca
",5
5811,"Spaghetti cacio e pepe (cheese and pepper) at a restaurant in Rome
",5
5812,"Spaghetti con pollo e funghi
",5
5813,"Spaghetti pomodoro & basilico (tomato sauce and basil)
",5
5814,"Spaghetti alle vongole
",5
5815,"Spaghetti with meatballs
",5
5816,"Pollock roe (Saizeriya)
",5
5817,"Cephalopod  ink (Saizeriya)
",5
5818,"Spaghetti al mare
",5
5819,"With pesto, Italian sauce
",5
5820,"By 1955, annual consumption of spaghetti in Italy doubled from 14 kilograms (30.9 lb) per person before World War II to 28 kilograms (61.7 lb).[20] By that year, Italy produced 1,432,990 tons of spaghetti, of which 74,000 were exported, and had a production capacity of 3 million tons.[20]
",5
5821,"Pasta provides carbohydrates, along with some protein, iron, dietary fiber, potassium and B vitamins.[22] Pasta prepared with whole wheat grain provides more dietary fiber[22] than that prepared with degermed flour.
",5
5822,"The world record for the largest bowl of spaghetti was set in March 2009 and reset in March 2010 when a Buca di Beppo restaurant in Garden Grove, California, filled a swimming pool with more than 13,780 pounds (6,251 kg) of pasta.[23]
",5
5823,"Spaghetti Westerns have little to do with spaghetti other than using the name as a shorthand for Italian.
",5
5824,"The BBC television program Panorama featured a hoax program about the spaghetti harvest in Switzerland on April Fools' Day, 1957.[24]
",5
5825,"
",5
5826,"
",5
5827,"
",5
5828,"Pasta (US: /ˈpɑːstə/, UK: /ˈpæstə/; Italian pronunciation: [ˈpasta]) is a type of food typically made from an unleavened dough of wheat flour mixed with water or eggs, and formed into sheets or other shapes, then cooked by boiling or baking. Rice flour, or legumes such as beans or lentils, are sometimes used in place of wheat flour to yield a different taste and texture, or as a gluten-free alternative. Pasta is a staple food of Italian cuisine.[1][2]
",5
5829,"Pastas are divided into two broad categories: dried (pasta secca) and fresh (pasta fresca). Most dried pasta is produced commercially via an extrusion process, although it can be produced at home. Fresh pasta is traditionally produced by hand, sometimes with the aid of simple machines.[3] Fresh pastas available in grocery stores are produced commercially by large-scale machines.
",5
5830,"Both dried and fresh pastas come in a number of shapes and varieties, with 310 specific forms known by over 1300 documented names.[4] In Italy, the names of specific pasta shapes or types often vary by locale. For example, the pasta form cavatelli is known by 28 different names depending upon the town and region. Common forms of pasta include long and short shapes, tubes, flat shapes or sheets, miniature shapes for soup, those meant to be filled or stuffed, and specialty or decorative shapes.[5]
",5
5831,"As a category in Italian cuisine, both fresh and dried pastas are classically used in one of three kinds of prepared dishes: as pasta asciutta (or pastasciutta), cooked pasta is plated and served with a complementary sauce or condiment; a second classification of pasta dishes is pasta in brodo, in which the pasta is part of a soup-type dish. A third category is pasta al forno, in which the pasta is incorporated into a dish that is subsequently baked in the oven.[6] Pasta dishes are generally simple, but individual dishes vary in preparation. Some pasta dishes are served as a small first course or for light lunches, such as pasta salads. Other dishes may be portioned larger and used for dinner. Pasta sauces similarly may vary in taste, color and texture.[7]
",5
5832,"In terms of nutrition, cooked plain pasta is 31% carbohydrates (mostly starch), 6% protein, and low in fat, with moderate amounts of manganese, but pasta generally has low micronutrient content. Pasta may be enriched or fortified, or made from whole grains.
",5
5833,"First attested in English in 1874, the word ""pasta"" comes from Italian pasta, in turn from Latin pasta, latinisation of the Greek παστά (pasta) ""barley porridge"".
",5
5834,"In the 1st century AD writings of Horace, lagana (singular: laganum) were fine sheets of fried dough[9] and were an everyday foodstuff.[10] Writing in the 2nd century Athenaeus of Naucratis provides a recipe for lagana which he attributes to the 1st century Chrysippus of Tyana: sheets of dough made of wheat flour and the juice of crushed lettuce, then flavoured with spices and deep-fried in oil.[10] An early 5th century cookbook describes a dish called lagana that consisted of layers of dough with meat stuffing, an ancestor of modern-day lasagna.[10] However, the method of cooking these sheets of dough does not correspond to our modern definition of either a fresh or dry pasta product, which only had similar basic ingredients and perhaps the shape.[10] The first concrete information concerning pasta products in Italy dates from the 13th or 14th century.[11]
",5
5835,"Historians have noted several lexical milestones relevant to pasta, none of which changes these basic characteristics. For example, the works of the 2nd century AD Greek physician Galen mention itrion, homogeneous compounds made of flour and water.[12] The Jerusalem Talmud records that itrium, a kind of boiled dough,[12] was common in Palestine from the 3rd to 5th centuries AD.[13] A dictionary compiled by the 9th century Arab physician and lexicographer Isho bar Ali[14] defines itriyya, the Arabic cognate, as string-like shapes made of semolina and dried before cooking. The geographical text of Muhammad al-Idrisi, compiled for the Norman King of Sicily Roger II in 1154 mentions itriyya manufactured and exported from Norman Sicily:
",5
5836,"West of Termini there is a delightful settlement called Trabia.[15] Its ever-flowing streams propel a number of mills. Here there are huge buildings in the countryside where they make vast quantities of itriyya which is exported everywhere: to Calabria, to Muslim and Christian countries. Very many shiploads are sent.[16]",5
5837,"One form of itriyya with a long history is laganum (plural lagana), which in Latin refers to a thin sheet of dough,[10] and gives rise to Italian lasagna.
",5
5838,"In North Africa, a food similar to pasta, known as couscous, has been eaten for centuries. However, it lacks the distinguishing malleable nature of pasta, couscous being more akin to droplets of dough. At first, dry pasta was a luxury item in Italy because of high labor costs; durum wheat semolina had to be kneaded for a long time.
",5
5839,"There is a legend of Marco Polo importing pasta from China[17] which originated with the Macaroni Journal, published by an association of food industries with the goal of promoting pasta in the United States.[18] Rustichello da Pisa writes in his Travels that Marco Polo described a food similar to ""lagana"". Jeffrey Steingarten asserts that Arabs introduced pasta in the Emirate of Sicily in the ninth century, mentioning also that traces of pasta have been found in ancient Greece and that Jane Grigson believed the Marco Polo story to have originated in the 1920s or 30s in an advertisement for a Canadian spaghetti company.[19]
",5
5840,"Food historians estimate that the dish probably took hold in Italy as a result of extensive Mediterranean trading in the Middle Ages. From the 13th century, references to pasta dishes—macaroni, ravioli, gnocchi, vermicelli—crop up with increasing frequency across the Italian peninsula.[20] In the 14th-century writer Boccaccio’s collection of earthy tales, The Decameron, he recounts a mouthwatering fantasy concerning a mountain of Parmesan cheese down which pasta chefs roll macaroni and ravioli to gluttons waiting below.[20]
",5
5841,"In the 14th and 15th centuries, dried pasta became popular for its easy storage. This allowed people to store pasta on ships when exploring the New World.[21] A century later, pasta was present around the globe during the voyages of discovery.[22]
",5
5842,"Although tomatoes were introduced to Italy in the 16th century and incorporated in Italian cuisine in the 17th century, description of the first Italian tomato sauces dates from the late 18th century: the first written record of pasta with tomato sauce can be found in the 1790 cookbook L'Apicio Moderno by Roman chef Francesco Leonardi.[23] Before tomato sauce was introduced, pasta was eaten dry with the fingers; the liquid sauce demanded the use of a fork.[21]
",5
5843,"At the beginning of the 17th century, Naples had rudimentary machines for producing pasta, later establishing the kneading machine and press, making pasta manufacturing cost-effective.[24] In 1740, a license for the first pasta factory was issued in Venice.[24] During the 1800s, water mills and stone grinders were used to separate semolina from the bran, initiating expansion of the pasta market.[24] In 1859, Joseph Topits (1824−1876) founded the first pasta factory of Hungary in the city of Pest, which worked with steam machines; it was one of the first pasta factories of Central Europe.[25] By 1867, Buitoni Company in Sansepolcro, Tuscany became an established pasta manufacturer.[26] During the early 1900s, artificial drying and extrusion processes enabled greater variety of pasta preparation and larger volumes for export, beginning a period called ""The Industry of Pasta"".[24][27] In 1884, the Zátka Brothers's plant in Boršov nad Vltavou was founded and this was the first pasta factory in Bohemia.[28]
",5
5844,"The art of pasta making and the devotion to the food as a whole has evolved since pasta was first conceptualized. It is estimated that Italians eat over 27 kg (60 lb) of pasta per person, per year, easily beating Americans, who eat about 9 kg (20 lb) per person.[29] Pasta is so beloved in Italy that individual consumption exceeds the average production of wheat of the country; thus Italy frequently imports wheat for pasta making. In contemporary society pasta is ubiquitous and individuals can find a variety of types in local supermarkets. With the worldwide demand for this staple food, pasta is now largely mass-produced in factories and only a tiny proportion is crafted by hand.[29]
",5
5845,"Since at least the time of Cato's De Agri Cultura, basic pasta dough has been made mostly of wheat flour or semolina,[4] with durum wheat used predominantly in the South of Italy and soft wheat in the North. Regionally other grains have been used, including those from barley, buckwheat, rye, rice, and maize, as well as chestnut and chickpea flours.
",5
5846,"To address needs of people affected by gluten-related disorders (such as coeliac disease, non-celiac gluten sensitivity and wheat allergy sufferers),[30] some recipes use rice or maize for making pasta. Grain flours may also be supplemented with cooked potatoes.[31][32]
",5
5847,"Other additions to the basic flour-liquid mixture may include vegetable purees such as spinach or tomato, mushrooms, cheeses, herbs, spices and other seasonings. While pastas are, most typically, made from unleavened doughs, the use of yeast-raised doughs are also known for at least nine different pasta forms.[4]
",5
5848,"Additives in dried, commercially sold pasta include vitamins and minerals that are lost from the durum wheat endosperm during milling. They are added back to the semolina flour once it is ground, creating enriched flour. Micronutrients added may include niacin (vitamin B3), riboflavin (vitamin B2), folate, thiamine (vitamin B1), and ferrous iron.[33]
",5
5849,"Long pasta
",5
5850,"Short pasta
",5
5851,"Short pasta
",5
5852,"Minute pasta (pastina, used for soups)
",5
5853,"Pasta all'uovo (egg pasta)
",5
5854,"Fresh pasta
",5
5855,"Pasta for pasta al forno (baked pasta) dishes
",5
5856,"Fresh pasta is usually locally made with fresh ingredients unless it is destined to be shipped, in which case consideration is given to the spoilage rates of the desired ingredients such as eggs or herbs. Furthermore, fresh pasta is usually made with a mixture of eggs and all-purpose flour or “00” low-gluten flour. Since it contains eggs, it is more tender compared to dried pasta and only takes about half the time to cook.[34] Delicate sauces are preferred for fresh pasta in order to let the pasta take front stage.[35]
",5
5857,"Fresh pastas do not expand in size after cooking; therefore, 0.7 kg (1.5 lb) of pasta are needed to serve four people generously.[34] Fresh egg pasta is generally cut into strands of various widths and thicknesses depending on which pasta is to be made (e.g. fettuccine, pappardelle, and lasagne). It is best served with meat, cheese, or vegetables to create ravioli, tortellini, and cannelloni. Fresh egg pasta is well known in the Piedmont region and Emilia Romagna region in North Italy. In this area, dough is only made out of egg yolk and flour resulting in a very refined flavour and texture. This pasta is often served simply with butter sauce and thinly sliced truffles that are native to this region. In other areas, such as Apulia, fresh pasta can be made without eggs. The only ingredients needed to make the pasta dough are semolina flour and water, which is often shaped into orecchiette or cavatelli. Fresh pasta for cavatelli is also popular in other places including Sicily. However, the dough is prepared differently: it is made of flour and ricotta cheese instead.[36]
",5
5858,"Dried pasta can also be defined as factory-made pasta because it is usually produced in large amounts that require large machines with superior processing capabilities to manufacture.[36] Dried pasta is mainly shipped over to farther locations and has a longer shelf life. The ingredients required to make dried pasta include semolina flour and water. Eggs can be added for flavour and richness, but are not needed to make dried pasta. In contrast to fresh pasta, dried pasta needs to be dried at a low temperature for several days to evaporate all the moisture allowing it to be stored for a longer period. Dried pastas are best served in hearty dishes like ragu sauces, soups, and casseroles.[35] Once it is cooked, the dried pasta will usually grow to twice its original size. Therefore, approximately 0.5 kg (1 lb) of dried pasta serves up to four people.[34]
",5
5859,"Pasta is generally served with some type of sauce; the sauce and the type of pasta are usually matched based on consistency and ease of eating. Northern Italian cooking uses less tomato sauce, garlic and herbs, and white sauce is more common.[37] However Italian cuisine is best identified by individual regions. Pasta dishes with lighter use of tomato are found in Trentino-Alto Adige and Emilia Romagna.[38][39] In Bologna, the meat-based Bolognese sauce incorporates a small amount of tomato concentrate and a green sauce called pesto originates from Genoa. In Central Italy, there are sauces such as tomato sauce, amatriciana, arrabbiata and the egg-based carbonara.
Tomato sauces are also present in Southern Italian cuisine, where they originated. In Southern Italy more complex variations include pasta paired with fresh vegetables, olives, capers or seafood. Varieties include puttanesca, pasta alla norma (tomatoes, eggplant and fresh or baked cheese), pasta con le sarde (fresh sardines, pine nuts, fennel and olive oil), spaghetti aglio, olio e peperoncino (literally with garlic, [olive] oil and hot chili peppers), pasta con i peperoni cruschi (crispy peppers and breadcrumbs).[40]
",5
5860,"Ingredients to make pasta dough include semolina flour, egg, salt and water. Flour is first mounded on a flat surface and then a well in the pile of flour is created. Egg is then poured into the well and a fork is used to mix the egg and flour.[41] There are a variety of ways to shape the sheets of pasta depending on the type required. The most popular types include penne, spaghetti, and macaroni.[42]
",5
5861,"Kitchen pasta machines, also called pasta makers, are popular with cooks who make large amounts of fresh pasta. The cook feeds sheets of pasta dough into the machine by hand, and by turning a hand crank, rolls the pasta to thin it incrementally. On the final pass through the pasta machine, the pasta may be directed through a machine 'comb' to shape of the pasta as it emerges.
",5
5862,"Semolina flour consists of a protein matrix with entrapped starch granules. Upon the addition of water, during mixing, intermolecular forces allow the protein to form a more ordered structure in preparation for cooking.[43]
",5
5863,"Durum wheat is ground into semolina flour which is sorted by optical scanners and cleaned.[44] Pipes allow the flour to move to a mixing machine where it is mixed with warm water by rotating blades. When the mixture is of a lumpy consistency, the mixture is pressed into sheets or extruded. Varieties of pasta such as spaghetti and linguine are cut by rotating blades while pasta such as penne and rotini are extruded. The size and shape of the dies in the extruder through which the pasta is pushed determine the shape that results. The pasta is then dried at a high temperature.[45]
",5
5864,"The ingredients to make dried pasta usually include water and semolina flour; egg for colour and richness (in some types of pasta), and possibly vegetable juice (such as spinach, beet, tomato, carrot), herbs or spices for colour and flavour. After mixing semolina flour with warm water the dough is kneaded mechanically until it becomes firm and dry. If pasta is to be flavoured, eggs, vegetable juices, and herbs are added at this stage. The dough is then passed into the laminator to be flattened into sheets, then compressed by a vacuum mixer-machine to clear out air bubbles and excess water from the dough until the moisture content is reduced to 12%. Next, the dough is processed in a steamer to kill any bacteria it may contain.
",5
5865,"The dough is then ready to be shaped into different types of pasta. Depending on the type of pasta to be made, the dough can either be cut or extruded through dies. The pasta is set in a drying tank under specific conditions of heat, moisture, and time depending on the type of pasta. The dried pasta is then packaged: Fresh pasta is sealed in a clear, airtight plastic container with a mixture of carbon dioxide and nitrogen that inhibits microbial growth and prolongs the product's shelf life; dried pastas are sealed in clear plastic or cardboard packages.[46]
",5
5866,"Gluten, the protein found in grains such as wheat, rye, spelt, and barley, contributes to protein aggregation and firm texture of a normally cooked pasta. Gluten-free pasta is produced with wheat flour substitutes, such as vegetable powders, rice, corn, quinoa, amaranth, oats and buckwheat flours.[47] Other possible gluten-free pasta ingredients may include hydrocolloids to improve cooking pasta with high heat resistance, xanthan gum to retain moisture during storage, or hydrothermally-treated polysaccharide mixtures to produce textures similar to those of wheat pasta.[47][48]
",5
5867,"The storage of pasta depends its processing and extent of drying.[43] Uncooked pasta is kept dry and can sit in the cupboard for a year if airtight and stored in a cool, dry area. Cooked pasta is stored in the refrigerator for a maximum of five days in an airtight container. Adding a couple teaspoons of oil helps keep the food from sticking to itself and the container. Cooked pasta may be frozen for up to two or three months. Should the pasta be dried completely, it can be placed back in the cupboard.[49]
",5
5868,"Pasta exhibits a random molecular order rather than a crystalline structure.[50] The moisture content of dried pasta is typically around 12%,[51] indicating that dried pasta will remain a brittle solid until it is cooked and becomes malleable. The cooked product is, as a result, softer, more flexible, and chewy.[50]
",5
5869,"Semolina flour is the ground endosperm of durum wheat,[44] producing granules that absorb water during heating and an increase in viscosity due to semi-reordering of starch molecules.[44][45]
",5
5870,"Another major component of durum wheat is protein which plays a large role in pasta dough rheology.[52] Gluten proteins, which include monomeric gliadins and polymeric glutenin, make up the major protein component of durum wheat (about 75–80%).[52] As more water is added and shear stress is applied, gluten proteins take on an elastic characteristic and begin to form strands and sheets.[52][53] The gluten matrix that results during forming of the dough becomes irreversibly associated during drying as the moisture content is lowered to form the dried pasta product.[54]
",5
5871,"Before the mixing process takes place, semolina particles are irregularly shaped and present in different sizes.[44][55] Semolina particles become hydrated during mixing. The amount of water added to the semolina is determined based on the initial moisture content of the flour and the desired shape of the pasta. The desired moisture content of the dough is around 32% wet basis and will vary depending on the shape of pasta being produced.[55]
",5
5872,"The forming process involves the dough entering an extruder in which the rotation of a single or double screw system pushes the dough toward a die set to a specific shape.[44] As the starch granules swell slightly in the presence of water and a low amount of thermal energy, they become embedded within the protein matrix and align along the direction of the shear caused by the extrusion process.[55]
",5
5873,"Starch gelatinization and protein coagulation are the major changes that take place when pasta is cooked in boiling water.[52] Protein and starch competing for water within the pasta cause a constant change in structure as the pasta cooks.[55]
",5
5874,"In 2015-16, the largest producers of dried pasta were Italy (3.2 million tonnes), the United States (2 million tonnes), Turkey (1.3 million tons), Brazil (1.2 million tonnes), and Russia (1 million tons).[56][57] In 2018, Italy was the world's largest exporter of pasta, with $2.9 billion sold, followed by China with $0.9 billion.[58]
",5
5875,"The largest per capita consumers of pasta in 2015 were Italy (23.5 kg/person), Tunisia (16.0 kg/person), Venezuela (12.0 kg/person) and Greece (11.2 kg/person).[57] In 2017, the United States was the largest consumer of pasta with 2.7 million tons.[59]
",5
5876,"When cooked, plain pasta is composed of 62% water, 31% carbohydrates (26% starch), 6% protein, and 1% fat. A 100-gram (3 1⁄2-ounce) portion of unenriched cooked pasta provides 670 kilojoules (160 kilocalories) of food energy and a moderate level of manganese (15% of the Daily Value), but few other micronutrients.
",5
5877,"Pasta has a lower glycemic index than many other staple foods in Western culture, like bread, potatoes, and rice.[60]
",5
5878,"As pasta was introduced elsewhere in the world, it became incorporated into a number of local cuisines, which often have significantly different ways of preparation from those of Italy. In Hong Kong, the local Chinese have adopted pasta, primarily spaghetti and macaroni, as an ingredient in the Hong Kong-style Western cuisine.
",5
5879,"When pasta was introduced to several nations, every culture adopted different style of preparing it. In the past, ancient Romans cooked pastas by frying or boiling it. It was also sweetened with honey or tossed with garum. Ancient Romans also enjoyed baking it in rich pies, called timballi.[61]
",5
5880,"In cha chaan teng, macaroni is cooked in water and served in broth with ham or frankfurter sausages, peas, black mushrooms, and optionally eggs, reminiscent of noodle soup dishes. This is often a course for breakfast or light lunch fare.[62] These affordable dining shops evolved from American food rations after World War II due to lack of supplies, and they continue to be popular for people with modest means.
Two common spaghetti dishes served in Japan are the Bolognese and the Napolitan. In Nepal, macaroni has been adopted and cooked in a Nepalese way. Boiled macaroni is sautéed along with cumin, turmeric, finely chopped green chillies, onions and cabbage. In Greece hilopittes is considered one of the finest types of dried egg pasta. It is cooked either in tomato sauce or with various kinds of casserole meat. It is usually served with Greek cheese of any type.
",5
5881,"Pasta is also widespread in the Southern Cone, as well most of the rest of Brazil, mostly pervasive in the areas with mild to strong Italian roots, such as Central Argentina, and the eight southernmost Brazilian states (where macaroni are called macarrão, and more general pasta is under the umbrella term massa, literally ""dough"", together with some Japanese noodles, such as bifum rice vermicelli and yakisoba, which also entered general taste). The local names for the pasta are many times varieties of the Italian names, such as ñoquis/nhoque for gnocchi, ravioles/ravióli for ravioli, or tallarines/talharim for tagliatelle, although some of the most popular pasta in Brazil, such as the parafuso (""screw"", ""bolt""), a specialty of the country's pasta salads, are also way different both in name and format from its closest Italian relatives, in this case the fusilli.[63]
",5
5882,"In Sweden, spaghetti is traditionally served with köttfärssås (Bolognese sauce), which is minced meat in a thick tomato soup.
",5
5883,"In the Philippines, spaghetti is often served with a distinct, slightly sweet yet flavourful meat sauce (the base of which would be tomato sauce or paste and ketchup), frequently containing ground beef or pork and diced hot dogs and ham. It is spiced with some soy sauce, heavy quantities of garlic, dried oregano sprigs and sometimes with dried bay leaf, and afterwards topped with grated cheese. Other pasta dishes are also cooked nowadays in the Filipino kitchen, like carbonara, pasta with alfredo sauce, and baked macaroni. These dishes are usually cooked for gatherings and special occasions, like family reunions or Christmas. Macaroni or other tube pasta is also used in sopas, a local chicken broth soup.
",5
5884,"Fettuccine alfredo with cream, cheese and butter, and spaghetti with tomato sauce (with or without meat) are popular Italian-style dishes in the United States.
",5
5885,"In Australia, boscaiola sauce, based on bacon and mushrooms, is popular.
",5
5886,"Although numerous variations of ingredients for different pasta products are known, in Italy the commercial manufacturing and labeling of pasta for sale as a food product within the country is highly regulated.[64][65] Italian regulations recognise three categories of commercially manufactured dried pasta as well as manufactured fresh and stabilized pasta:
",5
5887,"Pasta, or dried pasta with three subcategories – (i.) Durum wheat semolina pasta (pasta di semola di grano duro), (ii.) Low grade durum wheat semolina pasta (pasta di semolato di grano duro) and (iii.) Durum wheat whole meal pasta (pasta di semola integrale di grano duro). Pastas made under this category must be made only with durum wheat semolina or durum wheat whole-meal semolina and water, with an allowance for up to 3% of soft-wheat flour as part of the durum flour. Dried pastas made under this category must be labeled according to the subcategory.
",5
5888,"Special pastas (paste speciali) – As Pasta above, with additional ingredients other than flour and water or eggs. Special pastas must be labeled as durum wheat semolina pasta on the packaging completed by mentioning the added ingredients used (e.g., spinach). The 3% soft flour limitation still applies.
",5
5889,"Egg pasta (pasta all'uovo) – May only be manufactured using durum wheat semolina with at least 4 hens’ eggs (chicken) weighing at least 200 grams (without the shells) per kilogram of semolina, or a liquid egg product produced only with hen's eggs. Pasta made and sold in Italy under this category must be labeled egg pasta.
",5
5890,"Fresh and stabilized pastas (paste alimentari fresche e stabilizzate) – Includes fresh and stabilized pastas, which may be made with soft-wheat flour without restriction on the amount. Prepackaged fresh pasta must have a water content not less than 24%, must be stored refrigerated at a temperature of not more than 4 °C (with a 2 °C tolerance), must have undergone a heat treatment at least equivalent to pasteurisation, and must be sold within 5 days of the date of manufacture. Stabilized pasta has a lower allowed water content of 20%, and is manufactured using a process and heat treatment that allows it to be transported and stored at ambient temperatures.
",5
5891,"The Italian regulations under Presidential Decree N° 187 apply only to the commercial manufacturing of pastas both made and sold within Italy. They are not applicable either to pasta made for export from Italy or to pastas imported into Italy from other countries. They also do not apply to pastas made in restaurants.
",5
5892,"In the US, regulations for commercial pasta products occur both at the federal and state levels. At the Federal level, consistent with Section 341 of the Federal Food, Drug, and Cosmetic Act,[66] the Food and Drug Administration (FDA) has defined standards of identity for what are broadly termed macaroni products. These standards appear in 21 CFR Part 139.[67] Those regulations state the requirements for standardized macaroni products of 15 specific types of dried pastas, including the ingredients and product-specific labeling for conforming products sold in the US, including imports:
",5
5893,"Macaroni products – defined as the class of food prepared by drying formed units of dough made from semolina, durum flour, farina, flour, or any combination of those ingredients with water. Within this category various optional ingredients may also be used within specified ranges, including egg white, frozen egg white or dried egg white alone or in any combination; disodium phosphate; onions, celery, garlic or bay leaf, alone or in any combination; salt; gum gluten; and concentrated glyceryl monostearate. Specific dimensions are given for the shapes named macaroni, spaghetti and vermicelli.
",5
5894,"Noodle products – the class of food that is prepared by drying units of dough made from semolina, durum flour, farina, flour, alone or in any combination with liquid eggs, frozen eggs, dried eggs, egg yolks, frozen yolks, dried yolks, alone or in any combination, with or without water. Optional ingredients that may be added in allowed amounts are onions, celery, garlic, and bay leaf; salt; gum gluten; and concentrated glyceryl monostearate.
",5
5895,"The federal regulations under 21 CFR Part 139 are standards for the products noted, not mandates. Following the FDA's standards, a number of states have, at various times, enacted their own statutes that serve as mandates for various forms of macaroni and noodle products that may be produced or sold within their borders. Many of these specifically require that the products sold within those states be of the enriched form.[68][69][70][71] According to a report released by the Connecticut Office of Legislative Research, when Connecticut's law was adopted in 1972 that mandated certain grain products, including macaroni products, sold within the state to be enriched it joined 38 to 40 other states in adopting the federal standards as mandates.[72]
",5
5896,"Beyond the FDA's standards and state statutes, the United States Department of Agriculture (USDA), which regulates federal school nutrition programs,[73][74] broadly requires grain and bread products served under these programs either be enriched or whole grain (see 7 CFR 210.10 (k) (5)). This includes macaroni and noodle products that are served as part the category grains/breads requirements within those programs. The USDA also allows that enriched macaroni products fortified with protein may be used and counted to meet either a grains/breads or meat/alternative meat requirement, but not as both components within the same meal.[75]
",5
5897,"Cheese corn pasta available in India
",5
5898,"An Asian-style ""Italian"" pasta
",5
5899,"Pasta in Pakistan
",5
5900,"Spaghetti alla carbonara
",5
5901,"Macaroni and cheese
",5
5902,"Lasagna with meat sauce
",5
5903,"Greek flomaria
",5
5904,"Pasta in Japan
",5
5905,"
",5
5906,"Italian cuisine is a Mediterranean cuisine[1] consisting of the ingredients, recipes and cooking techniques developed across the Italian Peninsula since antiquity, and later spread around the world together with waves of Italian diaspora.[2][3][4]
",5
5907,"Significant changes occurred with the colonization of the Americas and the introduction of potatoes, tomatoes, capsicums, maize and sugar beet - the latter introduced in quantity in the 18th century.[5][6] Italian cuisine is known for its regional diversity, especially between the north and the south of the Italian peninsula.[7][8][9] It offers an abundance of taste, and is one of the most popular and copied in the world.[10] It influenced several cuisines around the world, chiefly that of the United States.[11]
",5
5908,"Italian cuisine is generally characterized by its simplicity, with many dishes having only two to four main ingredients.[12] Italian cooks rely chiefly on the quality of the ingredients rather than on elaborate preparation.[13] Ingredients and dishes vary by region. Many dishes that were once regional have proliferated with variations throughout the country.
",5
5909,"Italian cuisine has developed over the centuries. Although the country known as Italy did not unite until the 19th century, the cuisine can claim traceable roots as far back as the 4th century BC. Food and culture were very important at that time as we can see from the cookbook (Apicius) which dates to the first century BC.[14] Through the centuries, neighbouring regions, conquerors, high-profile chefs, political upheaval, and the discovery of the New World have influenced its development. Italian cuisine started to form after the fall of the Roman Empire when different cities began to separate and form their own traditions. Many different types of bread and pasta were made, and there was a variation in cooking techniques and preparation. 
",5
5910,"The country was then split for a long time and influenced by surrounding countries such as Spain, France and Central Europe. This and the trade or the location on the Silk Road with its routes to Asia influenced the local development of special dishes. Due to the climatic conditions and the different proximity to the sea, different basic foods and spices were available from region to region. Regional cuisine is represented by some of the major cities in Italy. For example, Milan (north of Italy) is known for risottos, Trieste (northeast of Italy) is known for multicultural food, Bologna (the central/middle of the country) is known for its tortellini, and Naples (the south) is famous for its pizzas.[15] A good example is the well-known spaghetti where it is believed that they spread across Africa to Sicily and then on to Naples.[16][17]
",5
5911,"The first known Italian food writer was a Greek Sicilian named Archestratus from Syracuse in the 4th century BC. He wrote a poem that spoke of using ""top quality and seasonal"" ingredients. He said that flavours should not be masked by spices, herbs or other seasonings. He placed importance on simple preparation of fish.[18]
",5
5912,"Simplicity was abandoned and replaced by a culture of gastronomy as the Roman Empire developed. By the time De re coquinaria was published in the 1st century AD, it contained 470 recipes calling for heavy use of spices and herbs. The Romans employed Greek bakers to produce breads and imported cheeses from Sicily as the Sicilians had a reputation as the best cheesemakers. The Romans reared goats for butchering, and grew artichokes and leeks.[18]
",5
5913,"With culinary traditions from Rome and Athens, a cuisine developed in Sicily that some consider the first real Italian cuisine.[citation needed] Arabs invaded Sicily in the 9th century, introducing spinach, almonds, and rice.[19] During the 12th century, a Norman king surveyed Sicily and saw people making long strings made from flour and water called atriya, which eventually became trii, a term still used for spaghetti in southern Italy.[20] Normans also introduced the casserole, salt cod (baccalà), and stockfish, all of which remain popular.[21]
",5
5914,"Food preservation was either chemical or physical, as refrigeration did not exist. Meats and fish were smoked, dried, or kept on ice. Brine and salt were used to pickle items such as herring, and to cure pork. Root vegetables were preserved in brine after they had been parboiled. Other means of preservation included oil, vinegar, or immersing meat in congealed, rendered fat. For preserving fruits, liquor, honey, and sugar were used.[22]
",5
5915,"The northern Italian regions show a mix of Germanic and Roman culture while the south reflects Arab[19] influence, as much Mediterranean cuisine was spread by Arab trade.[23] The oldest Italian book on cuisine is the 13th century Liber de coquina written in Naples. Dishes include ""Roman-style"" cabbage (ad usum romanorum), ad usum campanie which were ""small leaves"" prepared in the ""Campanian manner"", a bean dish from the Marca di Trevisio, a torta, compositum londardicum which are similar to dishes prepared today. Two other books from the 14th century include recipes for Roman pastello, Lasagna pie, and call for the use of salt from Sardinia or Chioggia.[24]
",5
5916,"In the 15th century, Maestro Martino was chef to the Patriarch of Aquileia at the Vatican. His Libro de arte coquinaria describes a more refined and elegant cuisine. His book contains a recipe for Maccaroni Siciliani, made by wrapping dough around a thin iron rod to dry in the sun. The macaroni was cooked in capon stock flavored with saffron, displaying Persian influences. Of particular note is Martino's avoidance of excessive spices in favor of fresh herbs.[21] The Roman recipes include coppiette (air-dried salami) and cabbage dishes. His Florentine dishes include eggs with Bolognese torta, Sienese torta and Genoese recipes such as piperata (sweets), macaroni, squash, mushrooms, and spinach pie with onions.[25]
",5
5917,"Martino's text was included in a 1475 book by Bartolomeo Platina printed in Venice entitled De honesta voluptate et valetudine (""On Honest Pleasure and Good Health""). Platina puts Martino's ""Libro"" in regional context, writing about perch from Lake Maggiore, sardines from Lake Garda, grayling from Adda, hens from Padua, olives from Bologna and Piceno, turbot from Ravenna, rudd from Lake Trasimeno, carrots from Viterbo, bass from the Tiber, roviglioni and shad from Lake Albano, snails from Rieti, figs from Tuscolo, grapes from Narni, oil from Cassino, oranges from Naples and eels from Campania. Grains from Lombardy and Campania are mentioned as is honey from Sicily and Taranto. Wine from the Ligurian coast, Greco from Tuscany and San Severino, and Trebbiano from Tuscany and Piceno are also mentioned in the book.[26]
",5
5918,"The courts of Florence, Rome, Venice, and Ferrara were central to the cuisine. Cristoforo di Messisbugo, steward to Ippolito d'Este, published Banchetti Composizioni di Vivande in 1549. Messisbugo gives recipes for pies and tarts (containing 124 recipes with various fillings). The work emphasizes the use of Eastern spices and sugar.[27]
",5
5919,"In 1570, Bartolomeo Scappi, personal chef to Pope Pius V, wrote his Opera in five volumes, giving a comprehensive view of Italian cooking of that period. It contains over 1,000 recipes, with information on banquets including displays and menus as well as illustrations of kitchen and table utensils. This book differs from most books written for the royal courts in its preference for domestic animals and courtyard birds rather than game.
",5
5920,"Recipes include lesser cuts of meats such as tongue, head, and shoulder. The third volume has recipes for fish in Lent. These fish recipes are simple, including poaching, broiling, grilling, and frying after marination.
",5
5921,"Particular attention is given to seasons and places where fish should be caught. The final volume includes pies, tarts, fritters, and a recipe for a sweet Neapolitan pizza (not the current savoury version, as tomatoes had not yet been introduced to Italy). However, such items from the New World as corn (maize) and turkey are included.[28]
",5
5922,"
In the first decade of the 17th century, Giacomo Castelvetro wrote Breve Racconto di Tutte le Radici di Tutte l'Herbe et di Tutti i Frutti (A Brief Account of All Roots, Herbs, and Fruit), translated into English by Gillian Riley. Originally from Modena, Castelvetro moved to England because he was a Protestant. The book lists Italian vegetables and fruits along with their preparation. He featured vegetables as a central part of the meal, not just as accompaniments.[28] Castelvetro favoured simmering vegetables in salted water and serving them warm or cold with olive oil, salt, fresh ground pepper, lemon juice, verjus, or orange juice. He also suggested roasting vegetables wrapped in damp paper over charcoal or embers with a drizzle of olive oil. Castelvetro's book is separated into seasons with hop shoots in the spring and truffles in the winter, detailing the use of pigs in the search for truffles.[28]",5
5923,"In 1662, Bartolomeo Stefani, chef to the Duchy of Mantua, published L'Arte di Ben Cucinare (English: 'The Art of Well Cooking'). He was the first to offer a section on vitto ordinario (""ordinary food""). The book described a banquet given by Duke Charles for Queen Christina of Sweden, with details of the food and table settings for each guest, including a knife, fork, spoon, glass, a plate (instead of the bowls more often used), and a napkin.[29]
",5
5924,"Other books from this time, such as Galatheo by Giovanni della Casa, tell how scalci (""waiters"") should manage themselves while serving their guests. Waiters should not scratch their heads or other parts of themselves, or spit, sniff, cough or sneeze while serving diners. The book also told diners not to use their fingers while eating and not to wipe sweat with their napkin.[29]
",5
5925,"At the beginning of the 18th century, Italian culinary books began to emphasize the regionalism of Italian cuisine rather than French cuisine. Books written then were no longer addressed to professional chefs but to bourgeois housewives.[30] Periodicals in booklet form such as La cuoca cremonese (The Cook of Cremona) in 1794 give a sequence of ingredients according to season along with chapters on meat, fish, and vegetables. As the century progressed these books increased in size, popularity, and frequency.[31]
",5
5926,"In the 18th century, medical texts warned peasants against eating refined foods as it was believed that these were poor for their digestion and their bodies required heavy meals. It was believed by some that peasants ate poorly because they preferred eating poorly. However, many peasants had to eat rotten food and mouldy bread because that was all they could afford.[32]
",5
5927,"In 1779, Antonio Nebbia from Macerata in the Marche region, wrote Il Cuoco Maceratese (The Cook of Macerata). Nebbia addressed the importance of local vegetables and pasta, rice, and gnocchi. For stock, he preferred vegetables and chicken over other meats.
",5
5928,"In 1773, the Neapolitan Vincenzo Corrado's Il Cuoco Galante (The Courteous Cook) gave particular emphasis to vitto pitagorico (vegetarian food). ""Pythagorean food consists of fresh herbs, roots, flowers, fruits, seeds and all that is produced in the earth for our nourishment. It is so called because Pythagoras, as is well known, only used such produce. There is no doubt that this kind of food appears to be more natural to man, and the use of meat is noxious."" This book was the first to give the tomato a central role with thirteen recipes.
",5
5929,"Zuppa alli pomidoro in Corrado's book is a dish similar to today's Tuscan pappa al pomodoro. Corrado's 1798 edition introduced a ""Treatise on the Potato"" after the French Antoine-Augustin Parmentier's successful promotion of the tuber.[34] In 1790, Francesco Leonardi in his book L'Apicio moderno (""Modern Apicius"") sketches a history of the Italian Cuisine from the Roman Age and gives as first a recipe of a tomato-based sauce.[35]
",5
5930,"In the 19th century, Giovanni Vialardi, chef to King Victor Emmanuel, wrote A Treatise of Modern Cookery and Patisserie with recipes ""suitable for a modest household"". Many of his recipes are for regional dishes from Turin including twelve for potatoes such as Genoese Cappon Magro. In 1829, Il Nuovo Cuoco Milanese Economico by Giovanni Felice Luraschi featured Milanese dishes such as kidney with anchovies and lemon and gnocchi alla Romana. Gian Battista and Giovanni Ratto's La Cucina Genovese in 1871 addressed the cuisine of Liguria. This book contained the first recipe for pesto. La Cucina Teorico-Pratica written by Ippolito Cavalcanti described the first recipe for pasta with tomatoes.[36]
",5
5931,"La scienza in cucina e l'arte di mangiare bene (The Science of Cooking and the Art of Eating Well), by Pellegrino Artusi, first published in 1891, is widely regarded as the canon of classic modern Italian cuisine, and it is still in print. Its recipes predominantly originate from Romagna and Tuscany, where he lived.
",5
5932,"Italian cuisine has a great variety of different ingredients which are commonly used, ranging from fruits, vegetables, sauces, meats, etc. In the North of Italy, fish (such as cod, or baccalà), potatoes, rice, corn (maize), sausages, pork, and different types of cheeses are the most common ingredients. Pasta dishes with use of tomato are spread in all of Italy.[37][38] Italians like their ingredients fresh and subtly seasoned and spiced.[39]
",5
5933,"In Northern Italy though there are many kinds of stuffed pasta, polenta and risotto are equally popular if not more so.[40] Ligurian ingredients include several types of fish and seafood dishes. Basil (found in pesto), nuts, and olive oil are very common. In Emilia-Romagna, common ingredients include ham (prosciutto), sausage (cotechino), different sorts of salami, truffles, grana, Parmigiano-Reggiano, and tomatoes (Bolognese sauce or ragù).
",5
5934,"Traditional Central Italian cuisine uses ingredients such as tomatoes, all kinds of meat, fish, and pecorino cheese. In Tuscany, pasta (especially pappardelle) is traditionally served with meat sauce (including game meat). In Southern Italy, tomatoes (fresh or cooked into tomato sauce), peppers, olives and olive oil, garlic, artichokes, oranges, ricotta cheese, eggplants, zucchini, certain types of fish (anchovies, sardines and tuna), and capers are important components to the local cuisine.
",5
5935,"Italian cuisine is also well known (and well regarded) for its use of a diverse variety of pasta. Pasta include noodles in various lengths, widths, and shapes. Most pastas may be distinguished by the shapes for which they are named—penne, maccheroni, spaghetti, linguine, fusilli, lasagne, and many more varieties that are filled with other ingredients like ravioli and tortellini.
",5
5936,"The word pasta is also used to refer to dishes in which pasta products are a primary ingredient. It is usually served with sauce. There are hundreds of different shapes of pasta with at least locally recognized names.
",5
5937,"Examples include spaghetti (thin rods), rigatoni (tubes or cylinders), fusilli (swirls), and lasagne (sheets). Dumplings, like gnocchi (made with potatoes or pumpkin) and noodles like spätzle, are sometimes considered pasta. They are both traditional in parts of Italy.
",5
5938,"Pasta is categorized in two basic styles: dried and fresh. Dried pasta made without eggs can be stored for up to two years under ideal conditions, while fresh pasta will keep for a couple of days in the refrigerator. Pasta is generally cooked by boiling. Under Italian law, dry pasta (pasta secca) can only be made from durum wheat flour or durum wheat semolina, and is more commonly used in Southern Italy compared to their Northern counterparts, who traditionally prefer the fresh egg variety.
",5
5939,"Durum flour and durum semolina have a yellow tinge in color. Italian pasta is traditionally cooked al dente (Italian: firm to the bite, meaning not too soft). Outside Italy, dry pasta is frequently made from other types of flour, but this yields a softer product. There are many types of wheat flour with varying gluten and protein levels depending on the variety of grain used.
",5
5940,"Particular varieties of pasta may also use other grains and milling methods to make the flour, as specified by law. Some pasta varieties, such as pizzoccheri, are made from buckwheat flour. Fresh pasta may include eggs (pasta all'uovo ""egg pasta""). Whole wheat pasta has become increasingly popular because of its supposed health benefits over pasta made from refined flour.
",5
5941,"Each area has its own specialties, primarily at a regional level, but also at the provincial level. The differences can come from a bordering country (such as France or Austria), whether a region is close to the sea or the mountains, and economics.[42] Italian cuisine is also seasonal with priority placed on the use of fresh produce.[43][44]
",5
5942,"Pasta, meat, and vegetables are central to the cuisine of Abruzzo and Molise. Chili peppers (peperoncini) are typical of Abruzzo, where they are called diavoletti (""little devils"") for their spicy heat. Due to the long history of shepherding in Abruzzo and Molise, lamb dishes are common. Lamb is often paired with pasta.[45] Mushrooms (usually wild mushrooms), rosemary, and garlic are also extensively used in Abruzzese cuisine.
",5
5943,"Best-known is the extra virgin olive oil produced in the local farms on the hills of the region, marked by the quality level DOP and considered one of the best in the country.[46] Renowned wines like Montepulciano DOCG and Trebbiano d'Abruzzo DOC are considered amongst the world's finest wines.[47] In 2012 a bottle of Trebbiano d'Abruzzo Colline Teramane ranked #1 in the top 50 Italian wine award.[48] Centerbe (""Hundred Herbs"") is a strong (72% alcohol), spicy herbal liqueur drunk by the locals. Another liqueur is genziana, a soft distillate of gentian roots.
",5
5944,"The best-known dish from Abruzzo is arrosticini, little pieces of castrated lamb on a wooden stick and cooked on coals. The chitarra (literally ""guitar"") is a fine stringed tool that pasta dough is pressed through for cutting. In the province of Teramo, famous local dishes include the virtù soup (made with legumes, vegetables, and pork meat), the timballo (pasta sheets filled with meat, vegetables or rice), and the mazzarelle (lamb intestines filled with garlic, marjoram, lettuce, and various spices). The popularity of saffron, grown in the province of L'Aquila, has waned in recent years.[45] The most famous dish of Molise is cavatelli, a long shaped, handmade maccheroni-type pasta made of flour, semolina, and water, often served with meat sauce, broccoli, or mushrooms. Pizzelle cookies are a common dessert, especially around Christmas.
",5
5945,"Apulia is a massive food producer: major production includes wheat, tomatoes, zucchini, broccoli, bell peppers, potatoes, spinach, eggplants, cauliflower, fennel, endive, chickpeas, lentils, beans, and cheese (like the traditional caciocavallo cheese). Apulia is also the largest producer of olive oil in Italy. The sea offers abundant fish and seafood that are extensively used in the regional cuisine, especially oysters, and mussels.
",5
5946,"Goat and lamb are occasionally used.[49] The region is known for pasta made from durum wheat and traditional pasta dishes featuring orecchiette-type pasta, often served with tomato sauce, potatoes, mussels, or broccoli rabe. Pasta with cherry tomatoes and arugula is also popular.[50]
",5
5947,"Regional desserts include zeppola, doughnuts usually topped with powdered sugar and filled with custard, jelly, cannoli-style pastry cream, or a butter-and-honey mixture. For Christmas, Apulians make a very traditional rose-shaped pastry called cartellate. These are fried and dipped in vin cotto, which is either a wine or fig juice reduction.
",5
5948,"The cuisine of Basilicata is mostly based on inexpensive ingredients and deeply anchored in rural traditions.
",5
5949,"Pork is an integral part of the regional cuisine, often made into sausages or roasted on a spit. Famous dry sausages from the region are lucanica and soppressata. Wild boar, mutton, and lamb are also popular. Pasta sauces are generally based on meats or vegetables. The region produces cheeses like Pecorino di Filiano, Canestrato di Moliterno, Pallone di Gravina, and Paddraccio and olive oils like the Vulture.[51]
",5
5950,"The peperone crusco, (or crusco pepper) is a staple of the local cuisine, much to be defined ""The red gold of Basilicata"".[52] It is consumed as a snack or as a main ingredient for several regional recipes.[53]
",5
5951,"Among the traditional dishes are pasta con i peperoni cruschi, pasta served with dried crunchy pepper, bread crumbs and grated cheese;[54] lagane e ceci, also known as piatto del brigante (brigand's dish), pasta prepared with chick peas and peeled tomatoes;[55] tumacë me tulë, tagliatelle-dish of Arbëreshe culture; rafanata, a type of omelette with horseradish; ciaudedda, a vegetable stew with artichokes, potatoes, broad beans, and pancetta;[56] and the baccalà alla lucana, one of the few recipes made with fish. Desserts include taralli dolci, made with sugar glaze and scented with anise and calzoncelli, fried pastries filled with a cream of chestnuts and chocolate.
",5
5952,"The most famous wine of the region is the Aglianico del Vulture, others include Matera, Terre dell'Alta Val d'Agri and Grottino di Roccanova.[57]
",5
5953,"Basilicata is also known for its mineral waters which are sold widely in Italy. The springs are mostly located in the volcanic basin of the Vulture area.[58]
",5
5954,"In Calabria, a history of French rule under the House of Anjou and Napoleon, along with Spanish influences, affected the language and culinary skills as seen in the naming of things such as cake, gatò, from the French gateau. Seafood includes swordfish, shrimp, lobster, sea urchin, and squid. Macaroni-type pasta is widely used in regional dishes, often served with goat, beef, or pork sauce and salty ricotta.[59]
",5
5955,"Main courses include frìttuli (prepared by boiling pork rind, meat, and trimmings in pork fat), different varieties of spicy sausages (like Nduja and Capicola), goat, and land snails. Melon and watermelon are traditionally served in a chilled fruit salad or wrapped in ham.[60] Calabrian wines include Greco di Bianco, Bivongi, Cirò, Dominici, Lamezia, Melissa, Pollino, Sant'Anna di Isola Capo Rizzuto, San Vito di Luzzi, Savuto, Scavigna, and Verbicaro.
",5
5956,"Calabrese pizza has a Neapolitan-based structure with fresh tomato sauce and a cheese base, but is unique because of its spicy flavor. Some of the ingredients included in a Calabrese pizza are thinly sliced hot soppressata, hot capicola, hot peppers, and fresh mozzarella.
",5
5957,"Campania extensively produces tomatoes, peppers, spring onions, potatoes, artichokes, fennel, lemons, and oranges which all take on the flavor of volcanic soil. The Gulf of Naples offers fish and seafood. Campania is one of the largest producers and consumers of pasta in Italy, especially spaghetti. In the regional cuisine, pasta is prepared in various styles that can feature tomato sauce, cheese, clams, and shellfish.[61]
",5
5958,"Spaghetti alla puttanesca is a popular dish made with olives, tomatoes, anchovies, capers, chili peppers, and garlic. The region is well-known also for its mozzarella production (especially from the milk of water buffalo) that's used in a variety of dishes, including parmigiana (shallow fried eggplant slices layered with cheese and tomato sauce, then baked). Desserts include struffoli (deep fried balls of dough), ricotta-based pastiera and sfogliatelle, and rum-dipped babà.[61]
",5
5959,"Originating in Neapolitan cuisine, pizza has become popular in many different parts of the world.[62] Pizza is an oven-baked, flat, disc-shaped bread typically topped with a tomato sauce, cheese (usually mozzarella), and various toppings depending on the culture. Since the original pizza, several other types of pizzas have evolved.
",5
5960,"Since Naples was the capital of the Kingdom of Two Sicilies, its cuisine took much from the culinary traditions of all the Campania region, reaching a balance between dishes based on rural ingredients (pasta, vegetables, cheese) and seafood dishes (fish, crustaceans, mollusks). A vast variety of recipes is influenced by the local aristocratic cuisine, like timballo and Sartù di riso, pasta or rice dishes with very elaborate preparation, while the dishes coming from the popular traditions contain inexpensive but nutritionally healthy ingredients, like pasta with beans and other pasta dishes with vegetables.
",5
5961,"Famous regional wines are Aglianico (Taurasi), Fiano, Falanghina, and Greco di Tufo.
",5
5962,"Emilia-Romagna is known for its egg and filled pasta made with soft wheat flour. The Romagna subregion is renowned for pasta dishes like cappelletti, garganelli, strozzapreti, sfoglia lorda, and tortelli alla lastra  [ it] as well as cheeses such as squacquerone  [ it], Piadina snacks are also a specialty of the subregion.
",5
5963,"In the Emilia subregion, except Piacenza which is heavily influenced by the cuisines of Lombardy, rice is eaten to a lesser extent. Polenta, a maize-based dish, is common in both Emilia and Romagna.
",5
5964,"Bologna and Modena are notable for pasta dishes like tortellini, lasagne, gramigna, and tagliatelle which are found also in many other parts of the region in different declinations. The celebrated balsamic vinegar is made only in the Emilian cities of Modena and Reggio Emilia, following legally binding traditional procedures.[63] Parmigiano Reggiano cheese is produced in Reggio Emilia, Parma, Modena, and Bologna and is often used in cooking. Grana Padano cheese is produced in Piacenza.
",5
5965,"Although the Adriatic coast is a major fishing area (well known for its eels and clams), the region is more famous for its meat products, especially pork-based, that include Parma's prosciutto, culatello, and Salame Felino  [ it]; Piacenza's pancetta, coppa, and salami; Bologna's mortadella and salame rosa; Zampone Modena  [ it], cotechino, and cappello del prete [ it]; and Ferrara's salama da sugo  [ it]. Piacenza is also known for some dishes prepared with horse and donkey meat. Regional desserts include zuppa inglese (custard-based dessert made with sponge cake and Alchermes liqueur) and panpepato (Christmas cake made with pepper, chocolate, spices, and almonds).
",5
5966,"Friuli-Venezia Giulia conserved, in its cuisine, the historical links with Austria-Hungary. Udine and Pordenone, in the western part of Friuli, are known for their traditional San Daniele del Friuli ham, Montasio cheese, and Frico cheese dish. Other typical dishes are pitina (meatballs made of smoked meats), game, and various types of gnocchi and polenta.
",5
5967,"The majority of the eastern regional dishes are heavily influenced by Austrian, Hungarian, Slovene and Croatian cuisines: typical dishes include Istrian stew (soup of beans, sauerkraut, potatoes, bacon, and spare ribs), Vienna sausages, goulash, ćevapi, apple strudel, gugelhupf. Pork can be spicy and is often prepared over an open hearth called a fogolar. Collio Goriziano, Friuli Isonzo, Colli Orientali del Friuli, and Ramandolo are well-known denominazione di origine controllata regional wines.
",5
5968,"But the seafood from the Adriatic is also used in this area. While the tuna fishing has declined, the anchovies from the Gulf of Trieste off Barcola (in the local dialect: ""Sardoni barcolani"") are a special and sought-after delicacy.[64][65][66]
",5
5969,"Liguria is known for herbs and vegetables (as well as seafood) in its cuisine. Savory pies are popular, mixing greens and artichokes along with cheeses, milk curds, and eggs. Onions and olive oil are used. Because of a lack of land suitable for wheat, the Ligurians use chickpeas in farinata and polenta-like panissa. The former is served plain or topped with onions, artichokes, sausage, cheese or young anchovies.[67] Farinata is typically cooked in a wood-fired oven, similar to southern pizzas. Furthermore, fresh fish features heavily in Ligurian cuisine. Baccala, or salted cod, features prominently as a source of protein in coastal regions. It is traditionally prepared in a soup. 
",5
5970,"Hilly districts use chestnuts as a source of carbohydrates. Ligurian pastas include corzetti, typically stamped with traditional designs, from the Polcevera valley; pansoti  [ it], a triangular shaped ravioli filled with vegetables; piccagge, pasta ribbons made with a small amount of egg and served with artichoke sauce or pesto sauce; trenette, made from whole wheat flour cut into long strips and served with pesto; boiled beans and potatoes; and trofie, a Ligurian gnocchi made from whole grain flour and boiled potatoes, made into a spiral shape and often tossed in pesto.[67] Many Ligurians emigrated to Argentina in the late 19th and early 20th centuries, influencing the cuisine of the country (which was otherwise dominated by meat and dairy products that the narrow Ligurian hinterland would have not allowed). Pesto, sauce made from basil and other herbs, is uniquely Ligurian, and features prominently among Ligurian pastas.
",5
5971,"Pasta dishes based on the use of guanciale (unsmoked bacon prepared with pig's jowl or cheeks) are often found in Lazio, such as pasta alla carbonara and pasta all'amatriciana. Another pasta dish of the region is arrabbiata, with spicy tomato sauce. The regional cuisine widely use offal, resulting in dishes like the entrail-based rigatoni with pajata sauce and coda alla vaccinara.[68]
",5
5972,"Iconic of Lazio is cheese made from ewes' milk (Pecorino Romano), porchetta (savory, fatty, and moist boneless pork roast) and Frascati white wine. The influence of the ancient Jewish community can be noticed in the Roman cuisine's traditional carciofi alla giudia.[68]
",5
5973,"The regional cuisine of Lombardy is heavily based upon ingredients like maize, rice, beef, pork, butter, and lard. Rice dishes are very popular in this region, often found in soups as well as risotto. The best-known version is risotto alla milanese  [ it], flavoured with saffron. Due to its characteristic yellow color, it is often called risotto giallo. The dish is sometimes served with ossobuco (cross-cut veal shanks braised with vegetables, white wine and broth).[69]
",5
5974,"Other regional specialities include cotoletta alla milanese (a fried breaded cutlet of veal similar to Wiener schnitzel, but cooked ""bone-in""), cassoeula (a typically winter dish prepared with cabbage and pork), Mostarda (rich condiment made with candied fruit and a mustard flavoured syrup), Valtellina's bresaola (air-dried salted beef), pizzoccheri (a flat ribbon pasta made with 80% buckwheat flour and 20% wheat flour cooked along with greens, cubed potatoes, and layered with pieces of Valtellina Casera cheese), casoncelli (a kind of stuffed pasta, usually garnished with melted butter and sage, typical of Brescia) and tortelli di zucca  [ it] (a type of ravioli with pumpkin filling, usually garnished with melted butter and sage or tomato).[70]
",5
5975,"Regional cheeses include Grana Padano, Gorgonzola, Crescenza, Robiola, and Taleggio (the plains of central and southern Lombardy allow intensive cattle farming). Polenta is common across the region. Regional desserts include the famous panettone (soft sweet bread with raisins and candied citron and orange chunks).
",5
5976,"On the coast of Marche, fish and seafood are produced. Inland, wild and domestic pigs are used for sausages and hams. These hams are not thinly sliced, but cut into bite-sized chunks. Suckling pig, chicken, and fish are often stuffed with rosemary or fennel fronds and garlic before being roasted or placed on the spit.[71]
",5
5977,"Ascoli, Marche's southernmost province, is well known for olive ascolane  [ it], (stoned olives stuffed with several minced meats, egg, and Parmesan, then fried).[72] Another well-known Marche product are the Maccheroncini di Campofilone [ it], from little town of Campofilone, a kind of hand-made pasta made only of hard grain flour and eggs, cut so thin that melts in one's mouth.
",5
5978,"Between the Alps and the Po valley, featuring a large number of different ecosystems, the Piedmont region offers the most refined and varied cuisine of the Italian peninsula. As a point of union between traditional Italian and French cuisine, Piedmont is the Italian region with the largest number of cheeses with protected geographical status and wines under DOC. It is also the region where both the Slow Food association and the most prestigious school of Italian cooking, the University of Gastronomic Sciences, were founded.[73]
",5
5979,"Piedmont is a region where gathering nuts, mushrooms, and cardoons, as well as hunting and fishing, are commonplace. Truffles, garlic, seasonal vegetables, cheese, and rice feature in the cuisine. Wines from the Nebbiolo grape such as Barolo and Barbaresco are produced as well as wines from the Barbera grape, fine sparkling wines, and the sweet, lightly sparkling, Moscato d'Asti. The region is also famous for its Vermouth and Ratafia production.[73]
",5
5980,"Castelmagno is a prized cheese of the region. Piedmont is also famous for the quality of its Carrù beef (particularly bue grasso, ""fat ox""), hence the tradition of eating raw meat seasoned with garlic oil, lemon, and salt; carpaccio; Brasato al vino, wine stew made from marinated beef; and boiled beef served with various sauces.[73]
",5
5981,"The food most typical of the Piedmont tradition are the traditional agnolotti (pasta folded over with roast beef and vegetable stuffing), paniscia (a typical dish of Novara, a kind of risotto with Arborio rice or Maratelli rice, the typical kind of Saluggia beans, onion, Barbera wine, lard, salami, season vegetables, salt and pepper), taglierini (thinner version of tagliatelle), bagna cauda (sauce of garlic, anchovies, olive oil, and butter), and bicerin (hot drink made of coffee, chocolate, and whole milk). Piedmont is one of the Italian capitals of pastry and chocolate in particular, with products like Nutella, gianduiotto, and marron glacé that are famous worldwide.[73]
",5
5982,"Suckling pig and wild boar are roasted on the spit or boiled in stews of beans and vegetables, thickened with bread. Herbs such as mint and myrtle are widely used in the regional cuisine. Sardinia also has many special types of bread, made dry, which keeps longer than high-moisture breads.[74]
",5
5983,"Also baked are carasau bread civraxu  [ it], coccoi a pitzus [ it], a highly decorative bread, and pistocu  [ it] made with flour and water only, originally meant for herders, but often served at home with tomatoes, basil, oregano, garlic, and a strong cheese. Rock lobster, scampi, squid, tuna, and sardines are the predominant seafoods.[74]
",5
5984,"Casu marzu is a very strong cheese produced in Sardinia, but is of questionable legality due to hygiene concerns.[75]
",5
5985,"Sicily shows traces of all the cultures which established themselves on the island over the last two millennia. Although its cuisine undoubtedly has a predominantly Italian base, Sicilian food also has Spanish, Greek and Arab influences. Dionysus is said to have introduced wine to the region: a trace of historical influence from Ancient Greece.[76]
",5
5986,"The ancient Romans introduced lavish dishes based on goose. The Byzantines favored sweet and sour flavors and the Arabs brought sugar, citrus, rice, spinach, and saffron. The Normans and Hohenstaufens had a fondness for meat dishes. The Spanish introduced items from the New World including chocolate, maize, turkey, and tomatoes.[76]
",5
5987,"Much of the island's cuisine encourages the use of fresh vegetables such as eggplant, peppers, and tomatoes, as well as fish such as tuna, sea bream, sea bass, cuttlefish, and swordfish. In Trapani, in the extreme western corner of the island, North African influences are clear in the use of various couscous based dishes, usually combined with fish.[77] Mint is used extensively in cooking unlike the rest of Italy.
",5
5988,"Traditional specialties from Sicily include arancini (a form of deep-fried rice croquettes), pasta alla Norma, caponata, pani ca meusa, and a host of desserts and sweets such as cannoli, granita, and cassata.[78]
",5
5989,"Typical of Sicily is Marsala, a red, fortified wine similar to Port and largely exported.[79][80]
",5
5990,"Before the Council of Trent in the middle of the 16th century, the region was known for the simplicity of its peasant cuisine. When the prelates of the Catholic Church established there, they brought the art of fine cooking with them. Later, also influences from Venice and the Austrian Habsburg Empire came in.[81]
",5
5991,"The Trentino subregion produces various types of sausages, polenta, yogurt, cheese, potato cake, funnel cake, and freshwater fish. In the Südtirol (Alto Adige) subregion, due to the German-speaking majority population, strong Austrian and Slavic influences prevail. The most renowned local product is traditional speck juniper-flavored ham which, as Speck Alto Adige, is regulated by the European Union under the protected geographical indication (PGI) status. Goulash, knödel, apple strudel, kaiserschmarrn, krapfen, rösti, spätzle, and rye bread are regular dishes, along with potatoes, dumpling, homemade sauerkraut, and lard.[81] The territory of Bolzano is also reputed for its Müller-Thurgau white wines.
",5
5992,"Simplicity is central to the Tuscan cuisine. Legumes, bread, cheese, vegetables, mushrooms, and fresh fruit are used. A good example of typical Tuscan food is ribollita, a notable soup whose name literally means ""reboiled"". Like most Tuscan cuisine, the soup has peasant origins. Ribollita was originally made by reheating (i.e. reboiling) the leftover minestrone or vegetable soup from the previous day. There are many variations but the main ingredients always include leftover bread, cannellini beans, and inexpensive vegetables such as carrot, cabbage, beans, silverbeet, cavolo nero (Tuscan kale), onion, and olive oil.
",5
5993,"A regional Tuscan pasta known as pici resembles thick, grainy-surfaced spaghetti, and is often rolled by hand. White truffles from San Miniato appear in October and November. High-quality beef, used for the traditional Florentine steak, come from the Chianina cattle breed of the Chiana Valley and the Maremmana from Maremma.
",5
5994,"Pork is also produced.[82] The region is well-known also for its rich game, especially wild boar, hare, fallow deer, roe deer, and pheasant that often are used to prepare pappardelle dishes. Regional desserts include panforte (prepared with honey, fruits, and nuts), ricciarelli (biscuits made using an almond base with sugar, honey, and egg white), necci (galettes made with chestnut flour) and cavallucci (cookies made with almonds, candied fruits, coriander, flour, and honey). Well-known regional wines include Brunello di Montalcino, Carmignano, Chianti, Morellino di Scansano, Parrina, Sassicaia, and Vernaccia di San Gimignano.
",5
5995,"Many Umbrian dishes are prepared by boiling or roasting with local olive oil and herbs. Vegetable dishes are popular in the spring and summer,[83] while fall and winter sees meat from hunting and black truffles from Norcia. Meat dishes include the traditional wild boar sausages, pheasants, geese, pigeons, frogs, and snails. Castelluccio is known for its lentils. Spoleto and Monteleone are known for spelt. Freshwater fish include lasca, trout, freshwater perch, grayling, eel, barbel, whitefish, and tench.[84] Orvieto and Sagrantino di Montefalco are important regional wines.
",5
5996,"In the Aosta Valley, bread-thickened soups are customary as well as cheese fondue, chestnuts, potatoes, rice. Polenta is a staple along with rye bread, smoked bacon, motsetta  [ it] (cured chamois meat), and game from the mountains and forests. Butter and cream are important in stewed, roasted, and braised dishes.[85] Typical regional products include Fontina cheese, Vallée d'Aoste Lard d'Arnad, red wines and Génépi Artemisia-based liqueur.[86]
",5
5997,"Venice and many surrounding parts of Veneto are known for risotto, a dish whose ingredients can highly vary upon different areas. Fish and seafood are added in regions closer to the coast while pumpkin, asparagus, radicchio, and frog legs appear farther away from the Adriatic Sea.
",5
5998,"Made from finely ground maize meal, polenta is a traditional, rural food typical of Veneto and most of Northern Italy. It may be included in stirred dishes and baked dishes. Polenta can be served with various cheese, stockfish, or meat dishes. Some polenta dishes include porcini, rapini, or other vegetables or meats, such as small song-birds in the case of the Venetian and Lombard dish polenta e osei, or sausages. In some areas of Veneto it can be also made of a particular variety of cornmeal, named biancoperla, so that the color of polenta is white and not yellow (the so-called polenta bianca).
",5
5999,"Beans, peas, and other legumes are seen in these areas with pasta e fagioli (beans and pasta) and risi e bisi  [ it] (rice and peas). Venice features heavy dishes using exotic spices and sauces. Ingredients such as stockfish or simple marinated anchovies are found here as well.
",5
6000,"Less fish and more meat is eaten away from the coast. Other typical products are sausages such as Soppressa Vicentina, garlic salami, Piave cheese, and Asiago cheese. High quality vegetables are prized, such as red radicchio from Treviso and white asparagus from Bassano del Grappa. Perhaps the most popular dish of Venice is fegato alla veneziana, thinly-sliced veal liver sauteed with onions.
",5
6001,"Squid and cuttlefish are common ingredients, as is squid ink, called nero di seppia.[87][88] Regional desserts include tiramisu (made of biscuits dipped in coffee, layered with a whipped mixture of egg yolks and mascarpone, and flavored with liquor and cocoa[89]), baicoli (biscuits made with butter and vanilla), and nougat.
",5
6002,"The most celebrated Venetian wines include Bardolino, Prosecco, Soave, Amarone, and Valpolicella DOC wines.
",5
6003,"Traditional meals in Italy typically contained four or five courses.[90] Especially on weekends, meals are often seen as a time to spend with family and friends rather than simply for sustenance; thus, meals tend to be longer than in other cultures. During holidays such as Christmas and New Year's Eve, feasts can last for hours.[91]
",5
6004,"Today, full-course meals are mainly reserved for special events such as weddings, while everyday meals include only a first or second course (sometimes both), a side dish, and coffee. The primo (first course) is usually a filling dish such as risotto or pasta, with sauces made from meat, vegetables, or seafood. Whole pieces of meat such as sausages, meatballs, and poultry are eaten in the secondo. Italian cuisine has some single-course meals (piatto unico) combining starches and proteins. Contorni of vegetables and starches are served on a separate plate and not on the plate with the meat as is done in northern European Style serving.
",5
6005,"Each type of establishment has a defined role and traditionally sticks to it.[92]
",5
6006,"The garden at an osteria in Castello Roganzuolo, Veneto, Italy
",5
6007,"A pizzeria in Naples, Italy circa 1910
",5
6008,"Interior of a trattoria in Tolmezzo, Friuli, Italy
",5
6009,"Italian style coffee (caffè), also known as espresso, is made from a blend of coffee beans. Espresso beans are roasted medium to medium dark in the north, and darker as one moves south.
",5
6010,"A common misconception is that espresso has more caffeine than other coffee; in fact the opposite is true. The longer roasting period extracts more caffeine. The modern espresso machine, invented in 1937 by Achille Gaggia, uses a pump and pressure system with water heated to 90 to 95 °C (194 to 203 °F) and forced at high pressure through a few grams of finely ground coffee in 25–30 seconds, resulting in about 25 milliliters (0.85 fl oz, two tablespoons) of liquid.[100]
",5
6011,"Home coffee makers are simpler but work under the same principle. La Napoletana is a four-part stove-top unit with grounds loosely placed inside a filter; the kettle portion is filled with water and once boiling, the unit is inverted to drip through the grounds. The Moka per il caffè is a three-part stove-top unit that is placed on the stovetop with loosely packed grounds in a strainer; the water rises from steam pressure and is forced through the grounds into the top portion. In both cases, the water passes through the grounds just once.[101]
",5
6012,"Espresso is usually served in a demitasse cup. Caffè macchiato is topped with a bit of steamed milk or foam; ristretto is made with less water, and is stronger; cappuccino is mixed or topped with steamed, mostly frothy, milk. It is generally considered a morning beverage, and usually is not taken after a meal; caffelatte is equal parts espresso and steamed milk, similar to café au lait, and is typically served in a large cup. Latte macchiato (spotted milk) is a glass of warm milk with a bit of coffee and caffè corretto is ""corrected"" with a few drops of an alcoholic beverage such as grappa or brandy.
",5
6013,"The bicerin is also an Italian coffee, from Turin. It is a mixture of cappuccino and traditional hot chocolate, as it consists of a mix of coffee and drinking chocolate, and with a small addition of milk. It is quite thick, and often whipped cream/foam with chocolate powder and sugar is added on top.
",5
6014,"Italy produces the largest amount of wine in the world and is both the largest exporter and consumer of wine. Only about a quarter of this wine is put into bottles for individual sale. Two-thirds is bulk wine used for blending in France and Germany. The wine distilled into spirits in Italy exceeds the production of wine in the entirety of the New World.[102] There are twenty separate wine regions.[103]
",5
6015,"The Italian government passed the Denominazione di origine controllata (DOC) law in 1963 to regulate place of origin, quality, production method, and type of grape. The designation Indicazione Geografica Tipica (IGT) is a less restrictive designation to help a wine maker graduate to the DOC level. In 1980, the government created the Denominazione di origine controllata e garantita (DOCG), reserved for only the best wines.[104]
",5
6016,"In Italy wine is commonly consumed (alongside water) in meals, which are rarely served without it, though it is extremely uncommon for meals to be served with any other drink, alcoholic, or otherwise.
",5
6017,"Italy hosts a wide variety of different beers, which are usually pale lager. Beer is not as popular and widespread as wine (even though this is changing as beer becomes increasingly popular), and average beer consumption in Italy is less than in some other European nations, such as the United Kingdom, Germany, and Austria. Among many popular brands, the most notable Italian breweries are Peroni and Moretti. Beer in Italy is often drunk in pizzerias, and South Tyrol (German-speaking region) is the area where beer is made and consumed the most.
",5
6018,"There are also several other popular alcoholic drinks in Italy. Limoncello, a traditional lemon liqueur from Campania (Sorrento, Amalfi and the Gulf of Naples) is the second most popular liqueur in Italy after Campari.[105] Made from lemon, it is an extremely strong drink which is usually consumed in very small proportions, served chilled in small glasses or cups.[105]
",5
6019,"Amaro Sicilianos are common Sicilian digestifs, made with herbs, which are usually drunk after heavy meals. Mirto, an herbal distillate made from the berries (red mirto) and leaves (white mirto) of the myrtle bush, is popular in Sardinia and other regions. Another well-known digestif is Amaro Lucano from Basilicata.[106]
",5
6020,"Grappa is the typical alcoholic drink of northern Italy, generally associated with the culture of the Alps and of the Po Valley. The most famous grappas are distilled in Friuli-Venezia Giulia, Veneto, Piedmont, and Trentino. The three most notable and recognizable Italian aperitifs are Martini, Vermouth, and Campari. A sparkling drink which is becoming internationally popular as a less expensive substitute for French champagne is prosecco, from the Veneto region.[107][108]
",5
6021,"From the Italian perspective, cookies and candy belong to the same category of sweets.[109] Traditional candies include candied fruits, torrone, and nut brittles, all of which are still popular in the modern era. In medieval times, northern Italy became so famous for the quality of its stiff fruit pastes (similar to marmalade or conserves, except stiff enough to mold into shapes) that ""Paste of Genoa"" became a generic name for high-quality fruit conserves.[110]
",5
6022,"Silver-coated almond dragées, which are called confetti, are thrown at weddings. The idea of including a romantic note with candy may have begun with Italian dragées, no later than the early 19th century, and is carried on with the multilingual love notes included in boxes of Italy's most famous chocolate, Baci by Perugina in Milan.[111] The most significant chocolate style is a combination of hazelnuts and milk chocolate, which is featured in gianduja pastes like Nutella, which is made by Ferrero SpA in Alba, Piedmont, as well as Perugnia's Baci and many other chocolate confections.[109]
",5
6023,"Panettone is a traditional Christmas cake
",5
6024,"Gelato is Italian ice cream
",5
6025,"Panna Cotta with garnish
",5
6026,"Tiramisu with cocoa powder garnish
",5
6027,"Cannoli with pistachio, candied fruit, and chocolate chips
",5
6028,"Every region has its own holiday recipes. During La Festa di San Giuseppe (St. Joseph's Day) on 19 March, Sicilians give thanks to St. Joseph for preventing a famine during the Middle Ages.[112][113] The fava bean saved the population from starvation, and is a traditional part of St. Joseph's Day altars and traditions.[114] Other customs celebrating this festival include wearing red clothing, eating Sicilian pastries known as zeppole and giving food to the poor.
",5
6029,"On Easter Sunday, lamb is served throughout Italy. A typical Easter Sunday breakfast in Umbria and Tuscany includes salami, boiled eggs, wine, Easter Cakes, and pizza. The common cake for Easter Day is the Colomba Pasquale (literally, Easter dove), which is often simply known as ""Italian Easter cake"" abroad. It is supposed to represent the dove, and is topped with almonds and pearl sugar.
",5
6030,"On Christmas Eve a symbolic fast is observed with the cena di magro (""light dinner""), a meatless meal. Typical cakes of the Christmas season are panettone and pandoro.
",5
6031,"Due to several Italian colonies established in Africa, mainly in Ethiopia, Eritrea, Libya, and Somalia (except the northern part, which was under British rule), there is a considerable Italian influence on the cuisines of these nations.
",5
6032,"Italy's legacy from the days when Libya was invaded by Italy can be seen in the popularity of pasta on its menus, particularly sharba, a highly spiced Libyan soup. Bazin, a local specialty, is a hard paste made from barley, salt and water, and one of the most popular meals in the Libyan cuisine is batata mubatana (filled potato),  consisting of fried potato pieces filled with spiced minced meat and covered with egg and breadcrumbs.
",5
6033,"All major cities and towns in South Africa have substantial populations of Italians. There are ""Italian clubs"" in all main cities and they have had a significant influence on the cuisine of this country. Italian foods, like ham and cheeses, are imported and some also made locally, and every city has a popular Italian restaurant or two, as well as pizzerias. Pastas are popular and eaten more and more by South Africans. The production of good quality olive oil is on the rise in South Africa, especially in the drier south-western parts where there is a more Mediterranean-type of rainfall pattern. Some oils have even won top international awards.
",5
6034,"In France, the cuisine of Corsica has much in common with the Italian cuisine, since the island was from the Early Middle Ages until 1768 first of a Pisan and then a Genoese possession. This is above all relevant in the first courses and the charcuterie.
",5
6035,"Pizza and pasta dishes such as spaghetti bolognese and lasagne with bolognese ragù and Béchamel sauce are the most popular forms of Italian food in British, notably, English, cuisine.
",5
6036,"Italian cuisine has had a strong influence on Slovenian cuisine. For centuries, north-eastern Italy and western Slovenia have formed part of the same cultural-historical and geographical space. Between 1918 and 1945, some of western Slovenia (the Slovenian Littoral and part of Inner Carniola) were part of Italy. In addition, an autochthonous Italian minority live in Slovenian Istria.
",5
6037,"Dishes that are shared between Slovenian cuisine and the cuisine Italian Friuli Venezia Giulia include the gubana nut roll of Friuli (known as guban'ca or potica in Slovenia) and the jota stew.
",5
6038,"Dishes that come directly from Italian cuisine include gnocchi and some types of pasta; minestrone (mineštra in Slovene); frittata (frtalja); Prosciutto (pršut); and polenta.
",5
6039,"Much of Italian-American cuisine is based on that found in Campania and Sicily, heavily Americanized to reflect ingredients and conditions found in the United States. Most pizza eaten around the world derives ultimately from the Neapolitan style, if somewhat thicker and usually with more toppings in terms of quantity.
",5
6040,"Throughout the country the ""torta de milanesa"" is a common item offered at food carts and stalls. It is a sandwich made from locally baked bread and contains a breaded, pan-fried cutlet of pork or beef. ""Pescado Veracruzano"" is a dish that originates from the port city of Veracruz and features a fillet of fresh fish (usually Gulf Red Snapper) covered in a distinctly Mediterranean influenced sauce containing stewed tomatoes, garlic, green olives, and capers. Also, ""espagueti"" (spaghetti) and other pastas are popular in a variety of soups.
",5
6041,"Due to large Italian immigration to Argentina, Italian food and drink is heavily featured in Argentine cuisine. An example could be milanesas (The name comes from the original cotoletta alla milanese from Milan, Italy) or breaded cutlets. Pizza (locally pronounced pisa or pitsa), for example, has been wholly subsumed and in its Argentine form more closely resembles Italian calzones than it does its Italian ancestor. There are several other Italian-Argentine dishes, such as sorrentinos  [ es] and Argentine gnocchi.
",5
6042,"Italian cuisine is popular in Brazil, due to great immigration there in the late 1800s and early 1900s. Due to the huge Italian community, São Paulo is the place where this cuisine is most appreciated. Several types of pasta and meat, including milanesa steaks, have made their way into both daily home and street kitchens and fancy restaurants. The city has also developed its particular variety of pizza, different from both Neapolitan and American varieties, and it is largely popular on weekend dinners. In Rio de Janeiro Italian cuisine is also popular, and pizza has developed as a typical botequim counter snack.
",5
6043,"There is considerable Italian influence in Venezuelan cuisine. Pan chabata, or Venezuelan ciabatta, pan siciliano, Sicilian bread, cannoli siciliani, Sicilian cannoli, and the drink  Chinotto are examples of the Italian influence in Venezuelan food and beverages.
",5
6044,"
",5
6045,"Hummus (/ˈhʊməs/, /ˈhʌməs/;[1][2] Arabic: حُمُّص‎, 'chickpeas'; full Arabic name: ḥummuṣ bi-ṭ-ṭaḥīna Arabic: حمص بالطحينة‎, 'chickpeas with tahini') is a Middle Eastern dip, spread, or savory dish made from cooked, mashed chickpeas blended with tahini, lemon juice, and garlic.[3] The standard garnish in the Middle East includes olive oil, a few whole chickpeas, parsley, and paprika.[4][5]
",5
6046,"In Middle Eastern cuisine, it is usually eaten as a dip, with pita bread. In the West, it is now produced industrially, and is often served as a snack or appetizer with crackers.
",5
6047,"The word hummus comes from Arabic: حُمُّص‎‎, romanized: ḥummuṣ 'chickpeas'.[6][2][7] The full name of the prepared spread in Arabic is ḥummuṣ bi ṭaḥīna 'chickpeas with tahini'.[8] The colloquial Arabic word ḥummuṣ is a variant of the Arabic ḥimmaṣ or ḥimmiṣ which may be derived from the Aramaic language (ḥemṣīn, ḥemṣāy[9]), corresponding to the Syriac word for chickpeas: ḥem(m)ṣē.[10] The word entered the English language around the mid-20th century from the Arabic ḥummuṣ or via its borrowing for the name of the dish in Turkish: humus.[11][12]
",5
6048,"Spelling of the word in English can be inconsistent, though most major dictionaries from American and British publishers give hummus as the primary spelling. Some American dictionaries give hommos as an alternative, while British dictionaries give houmous or hoummos.[13][2][10]
Other spellings include homous, houmos, houmus, and similar variants. While humus (as it is spelled in Turkish) is sometimes found, it is avoided as a heteronym of humus, organic matter in soil.[13]
",5
6049,"Although multiple different theories and claims of origins exist in various parts of the Middle East, evidence is insufficient to determine the precise location or time of the invention of hummus.[14] Its basic ingredients—chickpeas, sesame, lemon, and garlic—have been combined and eaten in Egypt and the Levant over centuries.[15][16] Though regional populations widely ate chickpeas, and often cooked them in stews and other hot dishes,[17] puréed chickpeas eaten cold with tahini do not appear before the Abbasid period in Egypt and the Levant.[18]
",5
6050,"The earliest known written recipes for a dish resembling hummus bi tahina are recorded in cookbooks written in Cairo in the 13th century.[14][19] A cold purée of chickpeas with vinegar and pickled lemons with herbs, spices, and oil, but no tahini or garlic, appears in the Kanz al-Fawa'id fi Tanwi' al-Mawa'id;[18] and a purée of chickpeas and tahini called hummus kasa appears in the Kitab Wasf al-Atima al-Mutada: it is based on puréed chickpeas and tahini, and acidulated with vinegar (though not lemon), but it also contains many spices, herbs, and nuts, and no garlic. It is also served by rolling it out and letting it sit overnight,[20] which presumably gives it a very different texture from hummus bi tahina.
",5
6051,"As an appetizer and dip, diners scoop hummus with flatbread, such as pita.[21] It is also served as part of a meze or as an accompaniment to falafel, grilled chicken, fish, or eggplant.[21] Garnishes include chopped tomato, cucumber, coriander, parsley, caramelized onions, sautéed mushrooms, whole chickpeas, olive oil, hard-boiled eggs, paprika, sumac, ful, olives, pickles, and pine nuts. Outside the Middle East, it is sometimes served with tortilla chips or crackers.
",5
6052,"Hummus ful (pronounced [fuːl]) is topped with a paste made from fava beans boiled until soft and then crushed. Hummus msabbaha/mashawsha is a mixture of hummus paste, warm chickpeas, and tahini.
",5
6053,"Hummus is a popular dip in Egypt where it is eaten with pita,[22] and frequently flavored with cumin or other spices.[21][22][23]
",5
6054,"For Palestinians and Jordanians, hummus has long been a staple food, often served as a warm dish, with bread for breakfast, lunch or dinner. All of the ingredients in hummus are easily found in Palestinian gardens, farms and markets, thus adding to the availability and popularity of the dish. In Palestine, hummus is usually garnished, with olive oil, ""nana"" mint leaves, paprika, and parsley.[24] A related dish popular in Palestine and Jordan is laban ma' hummus (""yogurt and chickpeas""), which uses yogurt in the place of tahini and butter in the place of olive oil and is topped with pieces of toasted bread.
",5
6055,"Hummus is a common part of everyday meals in Israel. It is made from ingredients that, following Kashrut (Jewish dietary laws), can be combined with both meat and dairy meals. Jewish immigrants arriving from Europe in the late 19th and early 20th century adopted much of the local Palestinian cuisine, including hummus, though it traditionally has been part of the cuisine of the Mizrahi Jews who lived in Arabic-speaking lands. The many Mizrahi Jewish immigrants from these countries brought their own unique variations, such as hummus with fried eggplant and boiled eggs prepared by Iraqi Jews, and Hasa Al Hummus, a chickpea soup preferred by Moroccans. The Yemenite quarter of Tel Aviv is known for its hummus with traditional skhug hot sauce. More recently, African immigrants have brought specialties such as Sudanese Hummus Darfur, with eggs, tomatoes, and grated cheese. Arab Israelis and Jews alike seek out authentic hummus in Arab hummusia, restaurants specializing in hummus dishes, making famous such Arab villages as Abu Gosh and Kafr Yasif. Enthusiasts travel to the more remote Arab and Druze villages in the northern Galilee region in search of the perfect hummus experience.[21][25][26]
",5
6056,"Although sometimes criticized as Jewish appropriation of Palestinian and Arab culture,[27] hummus has been adopted as an unofficial ""national dish"" of Israel, reflecting its huge popularity and significance among the entire Israeli population.[21] Many restaurants run by Mizrahi Jews and Arab citizens of Israel are dedicated to warm hummus,[21] which may be served as chick peas softened with baking soda along with garlic, olive oil, cumin and tahini. One of the hummus versions available is msabbaha, made with lemon-spiked tahini garnished with whole chick peas, a sprinkling of paprika and a drizzle of olive oil.[28]
",5
6057,"One author calls hummus, ""One of the most popular and best-known of all Syrian dishes"" and a ""must on any mezzeh table.""[29] Syrian and Lebanese in Canada's Arab diaspora prepare and consume hummus along with other dishes like falafel, kibbeh and tabbouleh, even among the third- and fourth-generation offspring of the original immigrants.[30]
",5
6058,"In Cyprus, hummus is part of the local cuisine in both Turkish Cypriot and Greek Cypriot communities where it is called ""humoi"" (Greek: χούμοι).[31][32] In the United Kingdom, hummus was popularized by Greek Cypriot caterers, sometimes leading to a perception of it being a Greek food,[33] though it is not well known in Greece.[citation needed]
",5
6059,"In Turkey, hummus is considered a meze[34] and usually oven-dried with pastırma, which differs from the traditional serving.
",5
6060,"In the United States and Europe, hummus is commercially available in numerous traditional and non-traditional varieties, such as beet or chocolate.[35]
",5
6061,"Chickpeas, the main ingredient of conventional hummus, have appreciable amounts of dietary fiber, protein, vitamin B6, manganese and other nutrients.[36]
",5
6062,"As hummus recipes vary, so does nutritional content, depending primarily on the relative proportions of chickpeas, tahini, and water. Hummus provides roughly 170 calories for 100 grams, and is a good to excellent (more than 10% of the Daily Value) source of dietary fiber, vitamin B6, and several dietary minerals.[37][38]
",5
6063,"Fat content, mostly from tahini and olive oil, is about 14% of the total; other major components are 65% water, 17% total carbohydrates, including a small amount of sugar, and about 10% protein.[37][38]
",5
6064,"In 2006, hummus was present in 12 percent of American households, rising to 17 percent by early 2009.[39] One commentator attributed the growth of hummus to America's embrace of ethnic and exotic foods.[39]
",5
6065,"While in 2006–08 when some 15 million Americans consumed hummus, and annual national sales were about $5 million, sales growth in 2016 was reflected by an estimated 25% of US households consuming hummus.[40] By 2016, the leading American hummus manufacturer, Sabra Dipping Company, held a 62% market share for hummus sales in the United States, and was forecast to exceed $1 billion in sales in 2017.[40][41][42] To meet the rising consumer demand for hummus, American farmers increased their production of chickpeas four-fold since 2009, harvesting more than 100,000,000 pounds (45,000,000 kg) in 2015, an increase from 25,000,000 pounds (11,000,000 kg) in 2009.[40] Hummus consumption has been so popular, many tobacco farmers have switched to growing chickpeas to meet demand.[43]
",5
6066,"Hummus has served as a symbol of national identity for both Lebanon and Israel and is at the center of a rhetorical battle between the two countries.[44]
",5
6067,"In October 2008, the Association of Lebanese Industrialists petitioned to the Lebanese Ministry of Economy and Trade to request protected status from the European Commission for hummus as a uniquely Lebanese food, similar to the Protected Geographical Status rights held over regional food items by various European Union countries.[45][46][47] As of late 2009, the Lebanese Industrialists Association was still ""collecting documents and proof"" to support its claim.[48]
",5
6068,"The 2005 short film West Bank Story features a rivalry between two fictional restaurants, the Israeli ""Kosher King"" and the Palestinian ""Hummus Hut"". A parody of West Side Story, which is itself an adaptation of Romeo and Juliet, the film won the 2006 Academy Award for Best Live Action Short Film.[49] In 2012, Australian filmmaker Trevor Graham released a documentary, Make Hummus Not War, on the political and gastronomic aspects of hummus.[50]
",5
6069,"Lebanon and Israel have been engaged in a competition over the largest dish of hummus, as validated by the Guinness World Record, as a form of contestation of ""ownership"".[44] The ""title"" has gone back and forth between Israel (2008), Lebanon (2009), Israel (January 2010),[51] and, as of 2021[update], Lebanon (May 2010).[44][52][53] The winning dish, cooked by 300 cooks in the village of al-Fanar, near Beirut, weighed approximately 10,450 kilograms (23,040 lb), more than double the weight of the previous record.[54][55][56] According to local media, the recipe included eight tons of boiled chick peas, two tonnes of tahini, two tonnes of lemon juice, and 70 kilograms (150 lb) of olive oil.[52]
",5
6070,"
",5
6071,"Yogurt (UK: /ˈjɒɡərt/; US: /ˈjoʊɡərt/,[1] from Turkish: yoğurt, Armenian: յոգուրտ)  also spelled yoghurt, yogourt or yoghourt, is a food produced by bacterial fermentation of milk.[2] The bacteria used to make yogurt are known as yogurt cultures. Fermentation of sugars in the milk by these bacteria produces lactic acid, which acts on milk protein to give yogurt its texture and characteristic tart flavor.[2] Cow's milk is commonly available worldwide and, as such, is the milk most commonly used to make yogurt. Milk from water buffalo, goats, ewes, mares, camels, yaks and plant milks are also used to produce yogurt. The milk used may be homogenized or not. It may be pasteurized or raw. Each type of milk produces substantially different results.
",5
6072,"Yogurt is produced using a culture of Lactobacillus delbrueckii subsp. bulgaricus and Streptococcus thermophilus bacteria. In addition, other lactobacilli and bifidobacteria are sometimes added during or after culturing yogurt. Some countries require yogurt to contain a specific amount of colony-forming units (CFU) of bacteria; in China, for example, the requirement for the number of lactobacillus bacteria is at least 1 million CFU per milliliter.[3]
",5
6073,"To produce yogurt, milk is first heated, usually to about 85 °C (185 °F), to denature the milk proteins so that they do not form curds. After heating, the milk is allowed to cool to about 45 °C (113 °F).[4] The bacterial culture is mixed in, and that temperature of 45 °C is maintained for 4 to 12 hours to allow fermentation to occur.[5]
",5
6074,"The word is derived from Turkish: yoğurt,[6] and is usually related to the verb yoğurmak, ""to knead"", or ""to be curdled or coagulated; to thicken"".[6] It may be related to yoğun, meaning thick or dense. The sound ğ was traditionally rendered as ""gh"" in transliterations of Turkish from around 1615–1625.[6] In modern Turkish the letter ğ marks a diaeresis between two vowels, without being pronounced itself, which is reflected in some languages' versions of the word (e.g. Greek γιαούρτι giaoúrti, French yaourt, Romanian iaurt).
",5
6075,"In English, the several variations of the spelling of the word include yogurt, yoghurt, and to a lesser extent yoghourt or yogourt.[6]
",5
6076,"Analysis of the L. delbrueckii subsp. bulgaricus genome indicates that the bacterium may have originated on the surface of a plant.[7] Milk may have become spontaneously and unintentionally exposed to it through contact with plants, or bacteria may have been transferred from the udder of domestic milk-producing animals.[8] The origins of yogurt are unknown, but it is thought to have been invented in Mesopotamia around 5000 BC.[9] In ancient Indian records, the combination of yogurt and honey is called ""the food of the gods"".[10] Persian traditions hold that ""Abraham owed his fecundity and longevity to the regular ingestion of yogurt"".[11]
",5
6077,"The cuisine of ancient Greece included a dairy product known as oxygala (οξύγαλα) which was similar to yogurt.[12][13][14][15] Galen (AD 129 – c. 200/c. 216) mentioned that oxygala was consumed with honey, similar to the way thickened Greek yogurt is eaten today.[15][14] The oldest writings mentioning yogurt are attributed to Pliny the Elder, who remarked that certain ""barbarous nations"" knew how ""to thicken the milk into a substance with an agreeable acidity"".[16] The use of yogurt by medieval Turks is recorded in the books Dīwān Lughāt al-Turk by Mahmud Kashgari and Kutadgu Bilig by Yusuf Has Hajib written in the 11th century.[17][18] Both texts mention the word ""yogurt"" in different sections and describe its use by nomadic Turks.[17][18] The earliest yogurts were probably spontaneously fermented by wild bacteria in goat skin bags.[19]
",5
6078,"Some accounts suggest that Mughal Indian emperor Akbar's cooks would flavor yogurt with mustard seeds and cinnamon.[20] Another early account of a European encounter with yogurt occurs in French clinical history: Francis I suffered from a severe diarrhea which no French doctor could cure. His ally Suleiman the Magnificent sent a doctor, who allegedly cured the patient with yogurt.[20][21] Being grateful, the French king spread around the information about the food that had cured him.
",5
6079,"Until the 1900s, yogurt was a staple in diets of people in the Russian Empire (and especially Central Asia and the Caucasus), Western Asia, South Eastern Europe/Balkans, Central Europe, and the Indian subcontinent. Stamen Grigorov (1878–1945), a Bulgarian student of medicine in Geneva, first examined the microflora of the Bulgarian yogurt. In 1905, he described it as consisting of a spherical and a rod-like lactic acid-producing bacteria. In 1907, the rod-like bacterium was called Bacillus bulgaricus (now Lactobacillus delbrueckii subsp. bulgaricus). The Russian biologist and Nobel laureate Ilya Mechnikov, from the Institut Pasteur in Paris, was influenced by Grigorov's work and hypothesized that regular consumption of yogurt was responsible for the unusually long lifespans of Bulgarian peasants.[22] Believing Lactobacillus to be essential for good health, Mechnikov worked to popularize yogurt as a foodstuff throughout Europe.
",5
6080,"Isaac Carasso industrialized the production of yogurt. In 1919, Carasso, who was from Ottoman Salonika, started a small yogurt business in Barcelona, Spain, and named the business Danone (""little Daniel"") after his son. The brand later expanded to the United States under an Americanized version of the name: Dannon. Yogurt with added fruit jam was patented in 1933 by the Radlická Mlékárna dairy in Prague.[23]
",5
6081,"Yogurt was introduced to the United States in the first decade of the twentieth century, influenced by Élie Metchnikoff's The Prolongation of Life; Optimistic Studies (1908); it was available in tablet form for those with digestive intolerance and for home culturing.[24] It was popularized by John Harvey Kellogg at the Battle Creek Sanitarium, where it was used both orally and in enemas,[25] and later by Armenian immigrants Sarkis and Rose Colombosian, who started ""Colombo and Sons Creamery"" in Andover, Massachusetts in 1929.[26][27]
",5
6082,"Colombo Yogurt was originally delivered around New England in a horse-drawn wagon inscribed with the Armenian word ""madzoon"" which was later changed to ""yogurt"", the Turkish language name of the product, as Turkish was the lingua franca between immigrants of the various Near Eastern ethnicities who were the main consumers at that time. Yogurt's popularity in the United States was enhanced in the 1950s and 1960s, when it was presented as a health food by scientists like Hungarian-born bacteriologist Stephen A. Gaymont.[28] Plain yogurt still proved too sour for the American palate and in 1966 Colombo Yogurt sweetened the yogurt and added fruit preserves, creating ""fruit on the bottom"" style yogurt. This was successful and company sales soon exceeded $1 million per year.[29] By the late 20th century, yogurt had become a common American food item and Colombo Yogurt was sold in 1993 to General Mills, which discontinued the brand in 2010.[30]
",5
6083,"In 2017, the average American ate 13.7 pounds of yogurt. The average consumption of yogurt has been declining since 2014.
",5
6084,"Sale of yogurt was down 3.4 percent over the 12 months ending in February 2019.  The decline of Greek-style yogurt has allowed Icelandic style yogurt to gain a foothold in the United States with sales of the Icelandic style yogurt increasing 24 percent in 2018 to $173 million.[31]
",5
6085,"Yogurt (plain yogurt from whole milk) is 81% water, 9% protein, 5% fat, and 4% carbohydrates, including 4% sugars (table). A 100-gram amount provides 406 kilojoules (97 kcal) of dietary energy. As a proportion of the Daily Value (DV), a serving of yogurt is a rich source of vitamin B12 (31% DV) and riboflavin (23% DV), with moderate content of protein, phosphorus, and selenium (14 to 19% DV; table).
",5
6086,"Tilde (~) represents missing or incomplete data. 
The above shows little difference exists between whole milk and yogurt made from whole milk with respect to the listed nutritional constituents.
",5
6087,"Because it may contain live cultures, yogurt is often associated with probiotics, which have been postulated as having positive effects on immune, cardiovascular or metabolic health.[34][35][36] However, to date high-quality clinical evidence has been insufficient to conclude that consuming yogurt lowers the risk of diseases or otherwise improves health.[37][needs update]
",5
6088,"Dahi is a yogurt from the Indian subcontinent, known for its characteristic taste and consistency. The word dahi seems to be derived from the Sanskrit word dadhi (""sour milk""), one of the five elixirs, or panchamrita, often used in Hindu ritual. Sweetened dahi (mishti doi or meethi dahi) is common in eastern parts of India, made by fermenting sweetened milk. While cow's milk is currently the primary ingredient for yogurt, goat and buffalo milk were widely used in the past, and valued for the fat content (see buffalo curd).
",5
6089,"Dadiah or dadih is a traditional West Sumatran yogurt made from water buffalo milk, fermented in bamboo tubes.[38] Yogurt is common in Nepal, where it is served as both an appetizer and dessert. Locally called dahi, it is a part of the Nepali culture, used in local festivals, marriage ceremonies, parties, religious occasions, family gatherings, and so on. One Nepalese yogurt is called juju dhau, originating from the city of Bhaktapur. In Tibet, yak milk (technically dri milk, as the word yak refers to the male animal) is made into yogurt (and butter and cheese) and consumed.
",5
6090,"In Northern Iran, Mâst Chekide is a variety of kefir yogurt with a distinct sour taste. It is usually mixed with a pesto-like water and fresh herb purée called delal. Common appetizers are spinach or eggplant borani, Mâst-o-Khiâr with cucumber, spring onions and herbs, and Mâst-Musir with wild shallots. In the summertime, yogurt and ice cubes are mixed together with cucumbers, raisins, salt, pepper and onions and topped with some croutons made of Persian traditional bread and served as a cold soup. Ashe-Mâst is a warm yogurt soup with fresh herbs, spinach and lentils. Even the leftover water extracted when straining yogurt is cooked to make a sour cream sauce called kashk, which is usually used as a topping on soups and stews.
",5
6091,"Matsoni is a Georgian yogurt in the Caucasus and Russia. Tarator and Cacık are cold soups made from yogurt during summertime in eastern Europe. They are made with ayran, cucumbers, dill, salt, olive oil, and optionally garlic and ground walnuts. Tzatziki in Greece and milk salad in Bulgaria are thick yogurt-based salads similar to tarator.
",5
6092,"Khyar w Laban (cucumber and yogurt salad) is a dish in Lebanon and Syria. Also, a wide variety of local Lebanese and Syrian dishes are cooked with yogurt like ""Kibbi bi Laban"" Rahmjoghurt, a creamy yogurt with much higher fat content (10%) than many yogurts offered in English-speaking countries. Dovga, a yogurt soup cooked with a variety of herbs and rice, is served warm in winter or refreshingly cold in summer. Jameed, yogurt salted and dried to preserve it, is consumed in Jordan. Zabadi is the type of yogurt made in Egypt, usually from the milk of the Egyptian water buffalo. It is particularly associated with Ramadan fasting, as it is thought to prevent thirst during all-day fasting.[39]
",5
6093,"To offset its natural sourness, yogurt is also sold sweetened, sweetened and flavored or in containers with fruit or fruit jam on the bottom.[40] The two styles of yogurt commonly found in the grocery store are set-style yogurt and Swiss-style yogurt. Set-style yogurt is poured into individual containers to set, while Swiss-style yogurt is stirred prior to packaging. Either may have fruit added to increase sweetness.[40]
",5
6094,"Lassi is a common Indian beverage made from stirred liquified yogurt that is either salted or sweetened with sugar commonly, less commonly honey and combined with fruit pulp to create flavored lassi.[41] Consistency can vary widely, with urban and commercial lassis having uniform texture through being processed, whereas rural and rustic lassi has discernible curds or fruit pulp.[41]
",5
6095,"Large amounts of sugar – or other sweeteners for low-energy yogurts – are often used in commercial yogurt.[40][42] Some yogurts contain added modified starch,[43] pectin (found naturally in fruit) or gelatin to create thickness and creaminess. This type of yogurt may be marketed under the name Swiss-style, although it is unrelated to conventional Swiss yogurt. Some yogurts, often called ""cream line"", are made with whole milk which has not been homogenized so the cream rises to the top. In many countries, sweetened, flavored yogurt is common, typically sold in single-serving plastic cups.[40] Common flavors may include vanilla, honey, and toffee, and various fruits.[40][42] In the early 21st century, yogurt flavors inspired by desserts, such as chocolate or cheesecake, became common.[42] There is concern about the health effects of sweetened yogurt due to its high sugar content,[40] although research indicates that use of sugar in yogurt manufacturing has decreased since 2016 in response to WHO and government initiatives to combat obesity.[40][44]
",5
6096,"Strained yogurt has been strained through a filter, traditionally made of muslin and more recently of paper or non-muslin cloth. This removes the whey, giving a much thicker consistency.  Strained yogurt is made at home, especially if using skimmed milk which results in a thinner consistency.[45] Yogurt that has been strained to filter or remove the whey is known as Labneh in Middle Eastern countries. It has a consistency between that of yogurt and cheese. It may be used for sandwiches in Middle Eastern countries. Olive oil, cucumber slices, olives, and various green herbs may be added. It can be thickened further and rolled into balls, preserved in olive oil, and fermented for a few more weeks. It is sometimes used with onions, meat, and nuts as a stuffing for a variety of pies or kibbeh balls.
",5
6097,"Some types of strained yogurts are boiled in open vats first, so that the liquid content is reduced. The East Indian dessert, a variation of traditional dahi called mishti dahi, offers a thicker, more custard-like consistency, and is usually sweeter than western yogurts.[46] In western Indian (Marathi and Gujarati) cuisine, strained yogurt is macerated with sugar and spices such as saffron, cardamom and nutmeg to make the dessert ""shrikhand"". Strained yogurt is also enjoyed in Greece and is the main component of tzatziki (from Turkish ""cacık""), a well-known accompaniment to gyros and souvlaki pita sandwiches: it is a yogurt sauce or dip made with the addition of grated cucumber, olive oil, salt and, optionally, mashed garlic. Srikhand, a dessert in India, is made from strained yogurt, saffron, cardamom, nutmeg and sugar and sometimes fruits such as mango or pineapple.
",5
6098,"In North America, strained yogurt is commonly called ""Greek yogurt"". Powdered milk is sometimes added in lieu of straining to achieve thickness. In Britain as ""Greek-style yogurt"". In Britain the name ""Greek"" may only be applied to yogurt made in Greece.[47]
",5
6099,"Ayran, doogh (""dawghe"" in Neo-Aramaic) or dhallë is a yogurt-based, salty drink. It is made by mixing yogurt with water and (sometimes) salt.
",5
6100,"Borhani (or burhani) is a spicy yogurt drink from Bangladesh. It is usually served with kacchi biryani at weddings and special feasts. Key ingredients are yogurt blended with mint leaves (mentha), mustard seeds and black rock salt (Kala Namak). Ground roasted cumin, ground white pepper, green chili pepper paste and sugar are often added.
",5
6101,"Lassi is a yogurt-based beverage that is usually slightly salty or sweet, and may be commercially flavored with rosewater, mango or other fruit juice. Salty lassi is usually flavored with ground, roasted cumin and red chilies, may be made with buttermilk.
",5
6102,"An unsweetened and unsalted yogurt drink usually called simply jogurt is consumed with burek and other baked goods in the Balkans. Sweetened yogurt drinks are the usual form in Europe (including the UK) and the US, containing fruit and added sweeteners. These are typically called ""drinkable yogurt"". Also available are ""yogurt smoothies"", which contain a higher proportion of fruit and are more like smoothies.
",5
6103,"A variety of plant milk yogurts appeared in the 2000s, using soy milk, rice milk, and nut milks such as almond milk and coconut milk fermented with cultures. These yogurts may be suitable for people with lactose intolerance or those who prefer plant-based foods such as vegetarians or vegans.[48] Plant-based milks have different structures and components than dairy milk. Though they can be used to make many products similar to those made from dairy, there are differences in taste and texture. For example, ""soy, almond, [and] coconut yogurts do not have the same delicate and smooth structure that conventional yogurts have.""[49] Since plant-based milks do not contain lactose (the food of Streptococcus thermophilus and Lactobacillus bulgaricus), plant-based yogurts usually contain different bacterial strains than a dairy yogurt, such as Lactobacillus casei, Lactobacillus rhamnosus, and Bifidobacterium bifidum.[50] Plant-based yogurts also vary considerably in their nutrition and ingredients, and may contain gums, stabilizers, high-intensity sweeteners, and artificial colors.[50]
",5
6104,"Yogurt is made by heating milk to a temperature that denaturates its proteins (scalding), essential for making yogurt,[51] cooling it to a temperature that will not kill the live microorganisms that turn the milk into yogurt, inoculating certain bacteria (starter culture), usually Streptococcus thermophilus and Lactobacillus bulgaricus, into the milk, and finally keeping it warm for several hours. The milk may be held at 85 °C (185 °F) for a few minutes, or boiled (giving a somewhat different result). It must be cooled to 50 °C (122 °F) or somewhat less, typically 40–46 °C (104–115 °F). Starter culture must then be mixed in well, and the mixture must be kept undisturbed and warm for some time, anywhere between 5 and 12 hours. Longer fermentation times produces a more acidic yogurt. The starter culture may be a small amount of live (not sterilized) existing yogurt or commercially available dried starter culture.
",5
6105,"Milk with a higher concentration of solids than normal milk may be used; the higher solids content produces a firmer yogurt. Solids can be increased by adding dried milk.[52] The yogurt-making process provides two significant barriers to pathogen growth, heat and acidity (low pH). Both are necessary to ensure a safe product. Acidity alone has been questioned by recent outbreaks of food poisoning by E. coli O157:H7 that is acid-tolerant. E. coli O157:H7 is easily destroyed by pasteurization (heating); the initial heating of the milk kills pathogens as well as denaturing proteins.[53] The microorganisms that turn milk into yogurt can tolerate higher temperatures than most pathogens, so that a suitable temperature not only encourages the formation of yogurt, but inhibits pathogenic microorganisms. Once the yogurt has formed it can, if desired, be strained to reduce the whey content and thicken it.
",5
6106,"Two types of yogurt are supported by the Codex Alimentarius for import and export.[54]
",5
6107,"Under US Food and Drug Administration regulations, milk must be pasteurized before it is cultured, and may optionally be heat treated after culturing to increase shelf life.[56] Most commercial yogurts in the United States are not heat treated after culturing, and contain live cultures.
",5
6108,"Yogurt with live cultures[57][58][59] is more beneficial than pasteurized yogurt for people with lactose malabsorption.[60]
",5
6109,"Lactose intolerance is a condition in which people have symptoms due to the decreased ability to digest lactose, a sugar found in dairy products. In 2010, the European Food Safety Authority (EFSA) determined that lactose intolerance can be alleviated by ingesting live yogurt cultures (lactobacilli) that are able to digest the lactose in other dairy products.[60] The scientific review by EFSA enabled yogurt manufacturers to use a health claim on product labels, provided that the ""yogurt should contain at least 108 CFU live starter microorganisms (Lactobacillus  delbrueckii subsp. bulgaricus and Streptococcus thermophilus) per gram. The target population is individuals with lactose maldigestion.""[60]
",5
6110,"Doogh is a savory yogurt-based beverage, traditionally served cold and is sometimes carbonated and seasoned with mint and salt.
",5
6111,"Skyr is an Icelandic cultured dairy product, similar to strained yogurt traditionally served cold with milk and a topping of sugar
",5
6112,"Raita is a condiment made with yogurt in the Indian subcontinent
",5
6113,"Dadiah in a market
",5
6114,"Plant milk yogurt
",5
6115,"Home yogurt maker
",5
6116,"A drinkable yogurt made from water buffalo milk
",5
6117,"
",5
6118,"
",5
6119,"A hamburger (also burger for short) is a sandwich consisting of one or more cooked patties of ground meat, usually beef, placed inside a sliced bread roll or bun. The patty may be pan fried, grilled, smoked or flame broiled. Hamburgers are often served with cheese, lettuce, tomato, onion, pickles, bacon, or chiles; condiments such as ketchup, mustard, mayonnaise, relish, or a ""special sauce"", often a variation of Thousand Island dressing; and are frequently placed on sesame seed buns. A hamburger topped with cheese is called a cheeseburger.[1]
",5
6120,"The term ""burger"" can also be applied to the meat patty on its own, especially in the United Kingdom, where the term ""patty"" is rarely used, or the term can even refer simply to ground beef. Since the term hamburger usually implies beef, for clarity ""burger"" may be prefixed with the type of meat or meat substitute used, as in beef burger, turkey burger, bison burger, or veggie burger.
",5
6121,"Hamburgers are sold at fast-food restaurants, diners, and specialty and high-end restaurants. There are many international and regional variations of the hamburger.
",5
6122,"The term hamburger originally derives from Hamburg,[2] Germany's second-largest city. Hamburger in German is the demonym of Hamburg, similar to frankfurter and wiener, names for other meat-based foods and demonyms of the cities of Frankfurt and Vienna (in German Wien) respectively.
",5
6123,"By back-formation, the term ""burger"" eventually became a self-standing word that is associated with many different types of sandwiches, similar to a (ground meat) hamburger, but made of different meats such as buffalo in the buffalo burger, venison, kangaroo, chicken, turkey, elk, lamb or fish like salmon in the salmon burger, but even with meatless sandwiches as is the case of the veggie burger.[3]
",5
6124,"As versions of the meal have been served for over a century, its origin remains ambiguous.[4] The popular book The Art of Cookery Made Plain and Easy by Hannah Glasse included a recipe in 1758 as ""Hamburgh sausage"", which suggested to serve it ""roasted with toasted bread under it"". A similar snack was also popular in Hamburg by the name ""Rundstück warm"" (""bread roll warm"") in 1869 or earlier,[5] and supposedly eaten by many emigrants on their way to America, but may have contained roasted beefsteak rather than Frikadeller. Hamburg steak is reported to have been served between two pieces of bread on the Hamburg America Line, which began operations in 1847. Each of these may mark the invention of the Hamburger, and explain the name.
",5
6125,"There is a reference to a ""Hamburg steak"" as early as 1884 in the Boston Journal.[OED, under ""steak""] On July 5, 1896, the Chicago Daily Tribune made a highly specific claim regarding a ""hamburger sandwich"" in an article about a ""Sandwich Car"": ""A distinguished favorite, only five cents, is Hamburger steak sandwich, the meat for which is kept ready in small patties and 'cooked while you wait' on the gasoline range.""[6]
",5
6126,"According to Connecticut Congresswoman Rosa DeLauro, the hamburger, a ground meat patty between two slices of bread, was first created in America in 1900 by Louis Lassen, a Danish immigrant, owner of Louis' Lunch in New Haven.[7] There have been rival claims by Charlie Nagreen, Frank and Charles Menches, Oscar Weber Bilby, and Fletcher Davis.[8][9] White Castle traces the origin of the hamburger to Hamburg, Germany with its invention by Otto Kuase.[10] However, it gained national recognition at the 1904 St. Louis World's Fair when the New York Tribune referred to the hamburger as ""the innovation of a food vendor on the pike"".[9] No conclusive argument has ever ended the dispute over invention. An article from ABC News sums up: ""One problem is that there is little written history. Another issue is that the spread of the burger happened largely at the World's Fair, from tiny vendors that came and went in an instant. And it is entirely possible that more than one person came up with the idea at the same time in different parts of the country.""[11]
",5
6127,"Louis Lassen of Louis' Lunch, a small lunch wagon in New Haven, Connecticut, is said to have sold the first hamburger and steak sandwich in the U.S. in 1900.[12][13][14] New York Magazine states that ""The dish actually had no name until some rowdy sailors from Hamburg named the meat on a bun after themselves years later"", noting also that this claim is subject to dispute.[15] A customer ordered a quick hot meal and Louis was out of steaks. Taking ground beef trimmings, Louis made a patty and grilled it, putting it between two slices of toast.[9] Some critics like Josh Ozersky, a food editor for New York Magazine, claim that this sandwich was not a hamburger because the bread was toasted.[16]
",5
6128,"One of the earliest claims comes from Charlie Nagreen, who in 1885 sold a meatball between two slices of bread at the Seymour Fair[17] now sometimes called the Outagamie County Fair.[16] The Seymour Community Historical Society of Seymour, Wisconsin, credits Nagreen, now known as ""Hamburger Charlie"", with the invention. Nagreen was fifteen when he was reportedly selling pork sandwiches at the 1885 Seymour Fair, made so customers could eat while walking. The Historical Society explains that Nagreen named the hamburger after the Hamburg steak with which local German immigrants were familiar.[18][19]
",5
6129,"According to White Castle, Otto Kuase was the inventor of the hamburger. In 1891, he created a beef patty cooked in butter and topped with a fried egg. German sailors would later omit the fried egg.[9]
",5
6130,"The family of Oscar Weber Bilby claim the first-known hamburger on a bun was served on July 4, 1891 on Grandpa Oscar's farm. The bun was a yeast bun.[20][21][22] In 1995, Governor Frank Keating proclaimed that the first true hamburger on a bun was created and consumed in Tulsa, Oklahoma in 1891, calling Tulsa, ""The Real Birthplace of the Hamburger.""[23]
",5
6131,"Frank and Charles Menches claim to have sold a ground beef sandwich at the Erie County Fair in 1885 in Hamburg, New York.[16] During the fair, they ran out of pork sausage for their sandwiches and substituted beef.[17] Kunzog[who?], who spoke to Frank Menches, says they exhausted their supply of sausage, so purchased chopped up beef from a butcher, Andrew Klein. Historian Joseph Streamer wrote that the meat was from Stein's market not Klein's, despite Stein's having sold the market in 1874.[17] The story notes that the name of the hamburger comes from Hamburg, New York not Hamburg, Germany.[17] Frank Menches's obituary in The New York Times states that these events took place at the 1892 Summit County Fair in Akron, Ohio.[24]
",5
6132,"Fletcher Davis of Athens, Texas claimed to have invented the hamburger. According to oral histories, in the 1880s he opened a lunch counter in Athens and served a 'burger' of fried ground beef patties with mustard and Bermuda onion between two slices of bread, with a pickle on the side.[9] The story is that in 1904, Davis and his wife Ciddy ran a sandwich stand at the St. Louis World's Fair.[9] Historian Frank X. Tolbert, noted that Athens resident Clint Murchison said his grandfather dated the hamburger to the 1880s with 'Old Dave' a.k.a. Fletcher Davis.[17] A photo of ""Old Dave's Hamburger Stand"" from 1904 was sent to Tolbert as evidence of the claim.[17]
",5
6133,"Various non-specific claims of invention relate to the term ""hamburger steak"" without mention of its being a sandwich. The first printed American menu which listed hamburger is said to be an 1834 menu from Delmonico's in New York.[25] However, the printer of the original menu was not in business in 1834.[22] In 1889, a menu from Walla Walla Union in Washington offered hamburger steak as a menu item.[9]
",5
6134,"Between 1871 and 1884, ""Hamburg Beefsteak"" was on the ""Breakfast and Supper Menu"" of the Clipper Restaurant at 311/313 Pacific Street in San Fernando, California. It cost 10 cents—the same price as mutton chops, pig's feet in batter, and stewed veal. It was not, however, on the dinner menu. Only ""Pig's Head,"" ""Calf Tongue,"" and ""Stewed Kidneys"" were listed.[26] Another claim ties the hamburger to Summit County, New York or Ohio. Summit County, Ohio exists, but Summit County, New York does not.[17]
",5
6135,"Hamburgers are usually a feature of fast food restaurants. The hamburgers served in major fast food establishments are usually mass-produced in factories and frozen for delivery to the site.[30] These hamburgers are thin and of uniform thickness, differing from the traditional American hamburger prepared in homes and conventional restaurants, which is thicker and prepared by hand from ground beef. Most American hamburgers are round, but some fast-food chains, such as Wendy's, sell square-cut hamburgers. Hamburgers in fast food restaurants are usually grilled on a flat-top, but some firms, such as Burger King, use a gas flame grilling process. At conventional American restaurants, hamburgers may be ordered ""rare"", but normally are served medium-well or well-done for food safety reasons. Fast food restaurants do not usually offer this option.
",5
6136,"The McDonald's fast-food chain sells the Big Mac, one of the world's top selling hamburgers, with an estimated 550 million sold annually in the United States.[31] Other major fast-food chains, including Burger King (also known as Hungry Jack's in Australia), A&W, Culver's, Whataburger, Carl's Jr./Hardee's chain, Wendy's (known for their square patties), Jack in the Box, Cook Out, Harvey's, Shake Shack, In-N-Out Burger, Five Guys, Fatburger, Vera's, Burgerville, Back Yard Burgers, Lick's Homeburger, Roy Rogers, Smashburger, and Sonic also rely heavily on hamburger sales. Fuddruckers and Red Robin are hamburger chains that specialize in the mid-tier ""restaurant-style"" variety of hamburgers.
",5
6137,"Some restaurants offer elaborate hamburgers using expensive cuts of meat and various cheeses, toppings, and sauces. One example is the Bobby's Burger Palace chain founded by well-known chef and Food Network star Bobby Flay.
",5
6138,"Hamburgers are often served as a fast dinner, picnic or party food and are often cooked outdoors on barbecue grills.
",5
6139,"A high-quality hamburger patty is made entirely of ground (minced) beef and seasonings; these may be described as ""all-beef hamburger"" or ""all-beef patties"" to distinguish them from inexpensive hamburgers made with cost-savers like added flour, textured vegetable protein, ammonia treated defatted beef trimmings (which the company Beef Products Inc, calls ""lean finely textured beef""),[32][33] advanced meat recovery, or other fillers. In the 1930s ground liver was sometimes added. Some cooks prepare their patties with binders like eggs or breadcrumbs. Seasonings may include salt and pepper and others like as parsley, onions, soy sauce, Thousand Island dressing, onion soup mix, or Worcestershire sauce. Many name brand seasoned salt products are also used.
",5
6140,"Raw hamburger may contain harmful bacteria that can produce food-borne illness such as Escherichia coli O157:H7, due to the occasional initial improper preparation of the meat, so caution is needed during handling and cooking. Because of the potential for food-borne illness, the USDA recommends hamburgers be cooked to an internal temperature of 160 °F (71 °C).[34] If cooked to this temperature, they are considered well-done.[35]
",5
6141,"Burgers can also be made with patties made from ingredients other than beef.[36] For example, a turkey burger uses ground turkey meat, a chicken burger uses ground chicken meat. A buffalo burger uses ground meat from a bison, and an ostrich burger is made from ground seasoned ostrich meat. A deer burger uses ground venison from deer.[37]
",5
6142,"Vegetarian and vegan burgers can be formed from a meat analogue, a meat substitute such as tofu, TVP, seitan (wheat gluten), quorn, beans, grains or an assortment of vegetables, ground up and mashed into patties.
",5
6143,"Vegetable patties have existed in various Eurasian cuisines for millennia, and are a commonplace item in Indian cuisine.
",5
6144,"A steak burger is a marketing term for a hamburger claimed to be of superior quality,[38][39][40] except in Australia, where it is a sandwich containing a steak.
",5
6145,"Steak burgers are first mentioned in the 1920s. Like other hamburgers, they may be prepared with various accompaniments and toppings.
",5
6146,"Use of the term ""steakburger"" dates to the 1920s in the United States.[41] In the U.S. in 1934, A.H. ""Gus"" Belt, the founder of Steak 'n Shake, devised a higher-quality hamburger and offered it as a ""steakburger"" to customers at the company's first location in Normal, Illinois.[42] This burger used a combination of ground meat from the strip portion of T-bone steak and sirloin steak in its preparation.[42] Steak burgers are a primary menu item at Steak 'n Shake restaurants,[42] and the company's registered trademarks included ""original steakburger"" and ""famous for steakburgers"".[43] Steak 'n Shake's ""Prime Steakburgers"" are now made of choice grade brisket and chuck.[44]
",5
6147,"Beef is typical, although other meats such as lamb and pork may also be used.[45] The meat is ground[46] or chopped.[47]
",5
6148,"In Australia, a steak burger is a steak sandwich which contains a whole steak, not ground meat.[48]
",5
6149,"Steak burgers may be cooked to various degrees of doneness.[49]
",5
6150,"Steak burgers may be served with standard hamburger toppings such as lettuce, onion, and tomato.[49] Some may have additional various toppings such as cheese,[49] bacon, fried egg, mushrooms,[50] additional meats,[51] and others.
",5
6151,"Various fast food outlets and restaurants ‍—‌ such as Burger King, Carl's Jr., Hardee's, IHOP, Steak 'n Shake, Mr. Steak, and Freddy's ‍—‌ market steak burgers.[41][43][52][53][54] Some restaurants offer high-end burgers prepared from aged beef.[55] Additionally, many restaurants have used the term ""steak burger"" at various times.[53]
",5
6152,"Some baseball parks concessions in the United States call their hamburgers steak burgers, such as Johnny Rosenblatt Stadium in Omaha, Nebraska.[56]
",5
6153,"Burger King introduced the Sirloin Steak sandwich in 1979 as part of a menu expansion that in turn was part of a corporate restructuring effort for the company.[41] It was a single oblong patty made of chopped steak served on a sub-style, sesame seed roll.[57][58] Additional steak burgers that Burger King has offered are the Angus Bacon Cheddar Ranch Steak Burger, the Angus Bacon & Cheese Steak Burger, and a limited edition Stuffed Steakhouse Burger.[41]
",5
6154,"In 2004, Steak 'n Shake sued Burger King over the latter's use of term Steak Burger in conjunction with one of its menu items, claiming that such use infringed on trademark rights.[59][60]
(According to the St. Louis Post-Dispatch, Burger King's attorneys ""grilled"" Steak 'n Shake's CEO in court about the precise content of Steak 'n Shake's steakburger offering.)[59] The case was settled out of court.[61]
",5
6155,"The hamburger is considered a national dish of the United States.[62] In the United States and Canada, burgers may be classified as two main types: fast food hamburgers and individually prepared burgers made in homes and restaurants. The latter are often prepared with a variety of toppings, including lettuce, tomato, onion, and often sliced pickles (or pickle relish). French fries often accompany the burger. Cheese (usually processed cheese slices but often Cheddar, Swiss, pepper jack, or blue), either melted directly on the meat patty or crumbled on top, is generally an option.
",5
6156,"Condiments might be added to a hamburger or may be offered separately on the side including ketchup, mustard, mayonnaise, relish, salad dressings and barbecue sauce.
",5
6157,"Other toppings can include bacon, avocado or guacamole, sliced sautéed mushrooms, cheese sauce, chili (usually without beans), fried egg, scrambled egg, feta cheese, blue cheese, salsa, pineapple, jalapeños and other kinds of chili peppers, anchovies, slices of ham or bologna, pastrami or teriyaki-seasoned beef, tartar sauce, french fries, onion rings or potato chips.
",5
6158,"In 2012, according to a study by the NDP cabinet, the French consume 14 hamburgers in restaurants per year per person, placing them fourth in the world and second in Europe, just behind the British.[72]
",5
6159,"According to a study by Gira Conseil on the consumption of hamburger in France in 2013, 75% of traditional French restaurants offer at least one hamburger on their menu and for a third of these restaurants, it has become the leader in the range of dishes, ahead of rib steaks, grills or fish.[73]
",5
6160,"In Mexico, burgers (called hamburguesas) are served with ham[74] and slices of American cheese fried on top of the meat patty. The toppings include avocado, jalapeño slices, shredded lettuce, onion and tomato. The bun has mayonnaise, ketchup and mustard. In certain parts are served with bacon, which can be fried or grilled along with the meat patty. A slice of pineapple is also a usual option, and the variation is known as a ""Hawaiian hamburger"".
",5
6161,"Some restaurants' burgers also have barbecue sauce, and others also replace the ground patty with sirloin, Al pastor meat, barbacoa or a fried chicken breast. Many burger chains from the United States can be found all over Mexico, including Carl's Jr., Sonic, as well as global chains such as McDonald's and Burger King.
",5
6162,"Hamburgers in the UK and Ireland are very similar to those in the US, and the High Street is dominated by the same big two chains as in the U.S. — McDonald's and Burger King. The menus offered to both countries are virtually identical, although portion sizes tend to be smaller in the UK. In Ireland the food outlet Supermacs is widespread throughout the country serving burgers as part of its menu. In Ireland, Abrakebabra (started out selling kebabs) and Eddie Rocket's are also major chains.
",5
6163,"An original and indigenous rival to the big two U.S. giants was the quintessentially British fast-food chain Wimpy, originally known as Wimpy Bar (opened 1954 at the Lyon's Corner House in Coventry Street London), which served its hamburgers on a plate with British-style chips, accompanied by cutlery and delivered to the customer's table. In the late 1970s, to compete with McDonald's,[75] Wimpy began to open American-style counter-service restaurants and the brand disappeared from many UK high streets when those restaurants were re-branded as Burger Kings between 1989 and 1990 by the then-owner of both brands, Grand Metropolitan. A management buyout in 1990 split the brands again and now Wimpy table-service restaurants can still be found in many town centres whilst new counter-service Wimpys are now often found at motorway service stations.
",5
6164,"Hamburgers are also available from mobile kiosks, commonly known as “burger vans"", particularly at outdoor events such as football matches. Burgers from this type of outlet are usually served without any form of salad — only fried onions and a choice of tomato ketchup, mustard or brown sauce.
",5
6165,"Chip shops, particularly in the West Midlands and North-East of England, Scotland and Ireland, serve battered hamburgers called batter burgers. This is where the burger patty, by itself, is deep-fat-fried in batter and is usually served with chips.
",5
6166,"Hamburgers and veggie burgers served with chips and salad, are standard pub grub menu items. Many pubs specialize in ""gourmet"" burgers. These are usually high quality minced steak patties, topped with items such as blue cheese, brie, avocado, anchovy mayonnaise, et cetera. Some British pubs serve burger patties made from more exotic meats including venison burgers (sometimes nicknamed Bambi Burgers), bison burgers, ostrich burgers and in some Australian themed pubs even kangaroo burgers can be purchased. These burgers are served in a similar way to the traditional hamburger but are sometimes served with a different sauce including redcurrant sauce, mint sauce and plum sauce.
",5
6167,"In the early 21st century ""premium"" hamburger chain and independent restaurants have arisen, selling burgers produced from meat stated to be of high quality and often organic, usually served to eat on the premises rather than to take away.[76] Chains include Gourmet Burger Kitchen, Ultimate Burger, Hamburger Union and Byron Hamburgers in London. Independent restaurants such as Meatmarket and Dirty Burger developed a style of rich, juicy burger in 2012 which is known as a dirty burger or third-wave burger.[77]
",5
6168,"In recent years Rustlers has sold pre-cooked hamburgers reheatable in a microwave oven in the United Kingdom.[78]
",5
6169,"In the UK, as in North America and Japan, the term ""burger"" can refer simply to the patty, be it beef, some other kind of meat, or vegetarian.
",5
6170,"Fast food franchises sell American-style fast food hamburgers in Australia and New Zealand. The traditional Australasian hamburgers are usually bought from fish and chip shops or milk bars, rather than from chain restaurants. These traditional hamburgers are becoming less common as older-style fast food outlets decrease in number. The hamburger meat is almost always ground beef, or ""mince"" as it is more commonly referred to in Australia and New Zealand. They commonly include tomato, lettuce, grilled onion and meat as minimum—in this form, known in Australia as a ""plain hamburger"", which often also includes a slice of beetroot—and, optionally, can  include cheese, beetroot, pineapple, a fried egg and bacon. If all these optional ingredients are included, it is known in Australia as ""burger with the lot"".[79][80]  The term 'burger' is also applied to any hot sandwich using a bun for the bread, even when the filling does not contain beef, such as a chicken burger (generally with chicken breast rather than chicken mince), salmon burger, pulled pork burger, veggie burger, etc. The term 'sandwich' is usually only applied when the bread used is sliced bread.
",5
6171,"The only variance between the two countries' hamburgers is that New Zealand's equivalent to ""The Lot"" often contains a steak (beef) as well. The condiments regularly used are barbecue sauce and tomato sauce. The traditional Australasian hamburger never includes mayonnaise. The McDonald's ""McOz"" Burger is partway between American and Australian style burgers, having beetroot and tomato in an otherwise typical American burger; however, it is no longer a part of the menu. Likewise, McDonald's in New Zealand created a Kiwiburger, similar to a Quarter Pounder, but features salad, beetroot and a fried egg. The Hungry Jack's (Burger King) ""Aussie Burger"" has tomato, lettuce, onion, cheese, bacon, beetroot, egg, ketchup and a meat patty, while adding pineapple is an upcharge. It is essentially a ""Burger with the lot"", but uses the standard HJ circular breakfast Egg, rather than the fully fried egg used by local fish shops.[81]
",5
6172,"In China, due to the branding of their sandwiches by McDonald's and KFC restaurants in China, the word ""burger"" (汉堡) refers to all sandwiches that are consist of two pieces of bun and a meat patty in between. This has led to confusions when Chinese nationals try to order sandwiches with meat fillings other than beef in fast-food restaurants in North America.[82]
",5
6173,"A popular Chinese street food, known as roujiamo (肉夹馍), consists of meat (most commonly pork) sandwiched between two buns. Roujiamo has been called the ""Chinese hamburger"".[83] Since the sandwich dates back to the Qin dynasty (221 BC–206 BC) and fits the aforementioned Chinese word for burger, Chinese media have claimed that the hamburger was invented in China.[84][85][82]
",5
6174,"In Japan, hamburgers can be served in a bun, called hanbāgā (ハンバーガー), or just the patties served without a bun, known as hanbāgu (ハンバーグ) or ""hamburg"", short for ""hamburg steak"".
",5
6175,"Hamburg steaks (served without buns) are similar to what are known as Salisbury steaks in the U.S. They are made from minced beef, pork or a blend of the two mixed with minced onions, egg, breadcrumbs and spices. They are served with brown sauce (or demi-glace in restaurants) with vegetable or salad sides, or occasionally in Japanese curries. Hamburgers may be served in casual, western style suburban restaurant chains known in Japan as ""family restaurants"".
",5
6176,"Hamburgers in buns, on the other hand, are predominantly the domain of fast food chains. Japan has homegrown hamburger chain restaurants such as MOS Burger, First Kitchen and Freshness Burger. Local varieties of burgers served in Japan include teriyaki burgers, katsu burgers (containing tonkatsu) and burgers containing shrimp korokke. Some of the more unusual examples include the rice burger, where the bun is made of rice, and the luxury 1000-yen (US$10) ""Takumi Burger"" (meaning ""artisan taste""), featuring avocados, freshly grated wasabi, and other rare seasonal ingredients. In terms of the actual patty, there are burgers made with Kobe beef, butchered from cows that are fed with beer and massaged daily. McDonald's Japan also recently launched a McPork burger, made with U.S. pork. McDonald's has been gradually losing market share in Japan to these local hamburger chains, due in part to the preference of Japanese diners for fresh ingredients and more refined, ""upscale"" hamburger offerings.[86] Burger King once retreated from Japan, but re-entered the market in Summer 2007 in cooperation with the Korean owned Japanese fast-food chain Lotteria.
",5
6177,"In Denmark, the hamburger was introduced in 1949, though it was called the bøfsandwich. There are many variations. While the original bøfsandwich was simply a generic meet patty containing a mix of beef and horse meat, though with slightly different garnish(sennep, ketchup and soft onions), it has continued to evolve. Today, a bøfsandwich usually contains a beef patty, pickled cucumber, raw, pickled, fried and/or soft onions, pickled red beets, mustard, ketchup, remoulade, and perhaps most strikingly, is often often overflowing with brown gravy, which is sometimes even poured on top of the assembled bøfsandwich. The original bøfsandwich is still on the menu at the same restaurant from which it originated in 1949, now run by the grandson of the original owner.[87]
",5
6178,"Following the popularity of the bøfsandwich, many variations sprung up, using different types of meat instead of the beef patty. One variation, the flæskestegssandwich, grew especially popular. This variation replaces the minced beef patty with slices of pork loin or belly, and typically uses sweet-and-sour pickled red cabbage, mayonnaise, mustard, and pork rinds as garnish.[88]
",5
6179,"Today, the bøfsandwich, flæskestegssandwich, and their many variations co-exist with the more typical hamburger, with the opening of the first Burger King restaurant in 1977 popularizing the original dish in Denmark. Many local, high-end burger restaurants dot the major cities, including Popl, an offshoot of Noma. 
",5
6180,"Rice burgers, mentioned above, are also available in several East Asian countries such as Taiwan and South Korea. Lotteria is a big hamburger franchise in Japan owned by the South Korean Lotte group, with outlets also in China, South Korea, Vietnam, and Taiwan. In addition to selling beef hamburgers, they also have hamburgers made from squid, pork, tofu, and shrimp. Variations available in South Korea include Bulgogi burgers and Kimchi burgers.
",5
6181,"In the Philippines, a wide range of major U.S. fast-food franchises are well represented, together with local imitators, often amended to the local palate. The chain McDonald's (locally nicknamed ""McDo"") have a range of burger and chicken dishes often accompanied by plain steamed rice or French fries. The Philippines boasts its own burger-chain called Jollibee, which offers burger meals and chicken, including a signature burger called ""Champ"". Jollibee now has a number of outlets in the United States, the Middle East and East Asia.
",5
6182,"In India, burgers are usually made from chicken or vegetable patties due to cultural beliefs against eating beef (which stem from Hindu religious practice) and pork (which stems from Islamic religious practice). Because of this, the majority of fast food chains and restaurants in India do not serve beef. McDonald's in India, for instance, does not serve beef, offering the ""Maharaja Mac"" instead of the Big Mac, substituting the beef patties with chicken. Another version of the Indian vegetarian burger is the Wada Pav consisting deep-fried potato patty dipped in gramflour batter. It is usually served with mint chutney and fried green chili. Another alternative is the ""Buff Burger"" made with buffalo meat.[89]
",5
6183,"In Pakistan, apart from American fast food chains, burgers can be found in stalls near shopping areas, the best known being the ""shami burger"". This is made from ""shami kebab"", made by mixing lentil and minced lamb.[90] Onions, scrambled egg and ketchup are the most popular toppings.
",5
6184,"In Malaysia there are 300 McDonald's restaurants. The menu in Malaysia also includes eggs and fried chicken on top of the regular burgers. Burgers are also easily found at nearby mobile kiosks, especially Ramly Burger.
",5
6185,"In Mongolia, a recent fast food craze due to the sudden influx of foreign influence has led to the prominence of the hamburger. Specialized fast food restaurants serving to Mongolian tastes have sprung up and seen great success.
",5
6186,"In Turkey, in addition to the internationally familiar offerings, numerous localized variants of the hamburger may be found, such as the Islak Burger (lit. ""Wet-Burger""), which a beef slider doused in seasoned tomato sauce and steamed inside a special glass chamber, and has its origins in the Turkish fast food retailer Kizilkayalar. Other variations include lamb-burgers and offal-burgers, which are offered by local fast food businesses and global chains alike, such as McDonald's and Burger King. Most burger shops have also adopted a pizzeria-like approach when it comes to home delivery, and almost all major fast food chains deliver.
",5
6187,"In the former Yugoslavia, and originally in Serbia, there is a local version of the hamburger known as the pljeskavica. It is often served as a patty, but may have a bun as well.
",5
6188,"Throughout Belgium and in some eateries in the Netherlands, a Bicky Burger is sold that combines pork, chicken, and horse meat.[91][92] The hamburger, usually fried, is served between a bun, sprinkled with sesame seeds. It often comes with a specific Bickysaus (Bicky dressing) made with mayonnaise, mustard, cabbage, and onion.[91]
",5
6189,"
",5
6190,"
",5
6191,"Beer is one of the oldest[1][2][3] and most widely consumed[4] alcoholic drinks in the world, and the third most popular drink overall after water and tea.[5] Beer is brewed from cereal grains—most commonly from malted barley, though wheat, maize (corn), and rice are also used. During the brewing process, fermentation of the starch sugars in the wort produces ethanol and carbonation in the resulting beer.[6] Most modern beer is brewed with hops, which add bitterness and other flavours and act as a natural preservative and stabilizing agent. Other flavouring agents such as gruit, herbs, or fruits may be included or used instead of hops. In commercial brewing, the natural carbonation effect is often removed during processing and replaced with forced carbonation.[7]
",5
6192,"Some of humanity's earliest known writings refer to the production and distribution of beer: the Code of Hammurabi included laws regulating beer and beer parlours,[8] and ""The Hymn to Ninkasi"", a prayer to the Mesopotamian goddess of beer, served as both a prayer and as a method of remembering the recipe for beer in a culture with few literate people.[9][10]
",5
6193,"Beer is distributed in bottles and cans and is also commonly available on draught, particularly in pubs and bars. The brewing industry is a global business, consisting of several dominant multinational companies and many thousands of smaller producers ranging from brewpubs to regional breweries. The strength of modern beer is usually around 4% to 6% alcohol by volume (ABV), although it may vary between 0.5% and 20%, with some breweries creating examples of 40% ABV and above.[11]
",5
6194,"Beer forms part of the culture of many nations and is associated with social traditions such as beer festivals, as well as a rich pub culture involving activities like pub crawling and pub games.
",5
6195,"When beer is distilled, the resulting liquor is a form of whisky.[12]
",5
6196,"In early forms of English, and in the Scandinavian languages, the usual word for beer was the word whose Modern English form is ale.[13]
",5
6197,"The word beer comes into present-day English from Old English bēor, itself from Common Germanic; although the word is not attested in the East Germanic branch of the language-family, it is found throughout the West Germanic and North Germanic dialects (modern Dutch and German bier, Old Norse bjórr). The earlier etymology of the word is debated: the three main theories are that the word originates in Proto-Germanic *beuzą (putatively from Proto-Indo-European *bʰeusóm), meaning ""brewer's yeast, beer dregs""; that it is related to the word barley; or that it was somehow borrowed from Latin bibere, ""to drink"".[14][15][13]
",5
6198,"In Old English and Old Norse, the beer-word did not denote a malted alcoholic drink like ale, but a sweet, potent drink made from honey and the juice of one or more fruits other than grapes, much less ubiquitous than ale, perhaps served in the kind of tiny drinking cups sometimes found in early medieval grave-goods: a drink more like mead or cider. In German, however, the meaning of the beer-word expanded to cover the meaning of the ale-word already before our earliest surviving written evidence. As German hopped ale became fashionable in England in the late Middle Ages, the English word beer took on the German meaning, and thus in English too beer came during the early modern period to denote hopped, malt-based alcoholic drinks.[13]
",5
6199,"Beer is one of the world's oldest prepared alcoholic drinks. The earliest archaeological evidence of fermentation consists of 13,000-year-old residues of a beer with the consistency of gruel, used by the semi-nomadic Natufians for ritual feasting, at the Raqefet Cave in the Carmel Mountains near Haifa in Israel.[16][17] There is evidence that beer was produced at Göbekli Tepe during the Pre-Pottery Neolithic (around 8500 BC to 5500 BC).[18] The earliest clear chemical evidence of beer produced from barley dates to about 3500–3100 BC, from the site of Godin Tepe in the Zagros Mountains of western Iran.[19][20] It is possible, but not proven, that it dates back even further—to about 10,000 BC, when cereal was first farmed.[21] Beer is recorded in the written history of ancient Iraq and ancient Egypt,[22][23] and archaeologists speculate that beer was instrumental in the formation of civilizations.[24] Approximately 5000 years ago, workers in the city of Uruk (modern day Iraq) were paid by their employers with volumes of beer.[25] During the building of the Great Pyramids in Giza, Egypt, each worker got a daily ration of four to five litres of beer, which served as both nutrition and refreshment that was crucial to the pyramids' construction.[26]
",5
6200,"Some of the earliest Sumerian writings contain references to beer; examples include a prayer to the goddess Ninkasi, known as ""The Hymn to Ninkasi"",[27] which served as both a prayer and a method of remembering the recipe for beer in a culture with few literate people, and the ancient advice (""Fill your belly. Day and night make merry"") to Gilgamesh, recorded in the Epic of Gilgamesh, by the ale-wife Siduri may, at least in part, have referred to the consumption of beer.[28] The Ebla tablets, discovered in 1974 in Ebla, Syria, show that beer was produced in the city in 2500 BC.[29] A fermented drink using rice and fruit was made in China around 7000 BC. Unlike sake, mold was not used to saccharify the rice (amylolytic fermentation); the rice was probably prepared for fermentation by chewing or malting.[30][31] During the Vedic period in Ancient India, there are records of consumption of the beer-like sura.[32][33] Xenophon noted that during his travels, beer was being produced in Armenia.[34]
",5
6201,"Almost any substance containing sugar can naturally undergo alcoholic fermentation, and can thus be utilized in the brewing of beer. It is likely that many cultures, on observing that a sweet liquid could be obtained from a source of starch, independently invented beer. Bread and beer increased prosperity to a level that allowed time for development of other technologies and contributed to the building of civilizations.[35][36][37][38]
",5
6202,"Beer was spread through Europe by Germanic and Celtic tribes as far back as 3000 BC,[39] and it was mainly brewed on a domestic scale.[40] The product that the early Europeans drank might not be recognised as beer by most people today. Alongside the basic starch source, the early European beers may have contain fruits, honey, numerous types of plants, spices and other substances such as narcotic herbs.[41] What they did not contain was hops, as that was a later addition, first mentioned in Europe around 822 by a Carolingian Abbot[42] and again in 1067 by abbess Hildegard of Bingen.[43]
",5
6203,"In 1516, William IV, Duke of Bavaria, adopted the Reinheitsgebot (purity law), perhaps the oldest food-quality regulation still in use in the 21st century, according to which the only allowed ingredients of beer are water, hops and barley-malt.[44] Beer produced before the Industrial Revolution continued to be made and sold on a domestic scale, although by the 7th century AD, beer was also being produced and sold by European monasteries. During the Industrial Revolution, the production of beer moved from artisanal manufacture to industrial manufacture, and domestic manufacture ceased to be significant by the end of the 19th century.[45] The development of hydrometers and thermometers changed brewing by allowing the brewer more control of the process and greater knowledge of the results.
",5
6204,"In 1912, the use of brown bottles began to be used by Joseph Schlitz Brewing Company of Milwaukee, Wisconsin in the United States. This innovation has since been accepted worldwide and prevents harmful rays from destroying the quality and stability of beer.[46]
",5
6205,"As of 2007, the brewing industry is a global business, consisting of several dominant multinational companies and many thousands of smaller producers ranging from brewpubs to regional breweries.[47] As of 2006, more than 133 billion litres (35 billion US gallons), the equivalent of a cube 510 metres on a side, of beer are sold per year, producing total global revenues of US$294.5 billion. In 2010, China's beer consumption hit 450 million hectolitres (45 billion litres), or nearly twice that of the United States, but only 5 per cent sold were premium draught beers, compared with 50 per cent in France and Germany.[48]
",5
6206,"A recent and widely publicized study suggests that sudden decreases in barley production due to extreme drought and heat could in the future cause substantial volatility in the availability and price of beer.[49]
",5
6207,"The process of making beer is known as brewing. A dedicated building for the making of beer is called a brewery, though beer can be made in the home and has been for much of its history. A company that makes beer is called either a brewery or a brewing company. Beer made on a domestic scale for non-commercial reasons is classified as homebrewing regardless of where it is made, though most homebrewed beer is made in the home. Brewing beer is subject to legislation and taxation in developed countries, which from the late 19th century largely restricted brewing to a commercial operation only. However, the UK government relaxed legislation in 1963, followed by Australia in 1972 and the US in 1978,[50] though individual states were allowed to pass their own laws limiting production,[51] allowing homebrewing to become a popular hobby.
",5
6208,"The purpose of brewing is to convert the starch source into a sugary liquid called wort and to convert the wort into the alcoholic drink known as beer in a fermentation process effected by yeast.
",5
6209,"The first step, where the wort is prepared by mixing the starch source (normally malted barley) with hot water, is known as ""mashing"". Hot water (known as ""liquor"" in brewing terms) is mixed with crushed malt or malts (known as ""grist"") in a mash tun.[52] The mashing process takes around 1 to 2 hours,[53] during which the starches are converted to sugars, and then the sweet wort is drained off the grains. The grains are now washed in a process known as ""sparging"". This washing allows the brewer to gather as much of the fermentable liquid from the grains as possible. The process of filtering the spent grain from the wort and sparge water is called wort separation. The traditional process for wort separation is lautering, in which the grain bed itself serves as the filter medium. Some modern breweries prefer the use of filter frames which allow a more finely ground grist.[54]
",5
6210,"Most modern breweries use a continuous sparge, collecting the original wort and the sparge water together. However, it is possible to collect a second or even third wash with the not quite spent grains as separate batches. Each run would produce a weaker wort and thus a weaker beer. This process is known as second (and third) runnings. Brewing with several runnings is called parti gyle brewing.[55]
",5
6211,"The sweet wort collected from sparging is put into a kettle, or ""copper"" (so-called because these vessels were traditionally made from copper),[56] and boiled, usually for about one hour. During boiling, water in the wort evaporates, but the sugars and other components of the wort remain; this allows more efficient use of the starch sources in the beer. Boiling also destroys any remaining enzymes left over from the mashing stage. Hops are added during boiling as a source of bitterness, flavour and aroma. Hops may be added at more than one point during the boil. The longer the hops are boiled, the more bitterness they contribute, but the less hop flavour and aroma remains in the beer.[57]
",5
6212,"After boiling, the hopped wort is now cooled, ready for the yeast. In some breweries, the hopped wort may pass through a hopback, which is a small vat filled with hops, to add aromatic hop flavouring and to act as a filter; but usually the hopped wort is simply cooled for the fermenter, where the yeast is added. During fermentation, the wort becomes beer in a process that requires a week to months depending on the type of yeast and strength of the beer. In addition to producing ethanol, fine particulate matter suspended in the wort settles during fermentation. Once fermentation is complete, the yeast also settles, leaving the beer clear.[58]
",5
6213,"During fermentation most of the carbon dioxide is allowed to escape through a trap and the beer is left with carbonation of only about one atmosphere of pressure. The carbonation is often increased either by transferring the beer to a pressure vessel such as a keg and introducing pressurized carbon dioxide, or by transferring it before the fermentation is finished so that carbon dioxide pressure builds up inside the container as the fermentation finishes. Sometimes the beer is put unfiltered (so it still contains yeast) into bottles with some added sugar, which then produces the desired amount of carbon dioxide inside the bottle.[7]
",5
6214,"Fermentation is sometimes carried out in two stages, primary and secondary. Once most of the alcohol has been produced during primary fermentation, the beer is transferred to a new vessel and allowed a period of secondary fermentation. Secondary fermentation is used when the beer requires long storage before packaging or greater clarity.[59] When the beer has fermented, it is packaged either into casks for cask ale or kegs, aluminium cans, or bottles for other sorts of beer.[60]
",5
6215,"The basic ingredients of beer are water; a starch source, such as malted barley, able to be saccharified (converted to sugars) then fermented (converted into ethanol and carbon dioxide); a brewer's yeast to produce the fermentation; and a flavouring such as hops.[61] A mixture of starch sources may be used, with a secondary carbohydrate source, such as maize (corn), rice, wheat, or sugar, often being termed an adjunct, especially when used alongside malted barley.[62] Less widely used starch sources include millet, sorghum and cassava root in Africa, and potato in Brazil, and agave in Mexico, among others.[63] The amount of each starch source in a beer recipe is collectively called the grain bill.
",5
6216,"Water is the main ingredient of beer, accounting for 93% of its weight.[64] Though water itself is, ideally, flavorless, its level of dissolved minerals, specifically, bicarbonate ion, does influence beer's finished taste.[65] Due to the mineral properties of each region's water, specific areas were originally the sole producers of certain types of beer, each identifiable by regional characteristics.[66] Regional geology accords that Dublin's hard water is well-suited to making stout, such as Guinness, while the Plzeň Region's soft water is ideal for brewing Pilsner (pale lager), such as Pilsner Urquell.[66] The waters of Burton in England contain gypsum, which benefits making pale ale to such a degree that brewers of pale ales will add gypsum to the local water in a process known as Burtonisation.[67]
",5
6217,"The starch source, termed as the ""mash ingredients"", in a beer provides the fermentable material and is a key determinant of the strength and flavour of the beer. The most common starch source used in beer is malted grain. Grain is malted by soaking it in water, allowing it to begin germination, and then drying the partially germinated grain in a kiln. Malting grain produces enzymes that convert starches in the grain into fermentable sugars.[68] Different roasting times and temperatures are used to produce different colours of malt from the same grain. Darker malts will produce darker beers.[69] Nearly all beer includes barley malt as the majority of the starch. This is because its fibrous hull remains attached to the grain during threshing. After malting, barley is milled, which finally removes the hull, breaking it into large pieces. These pieces remain with the grain during the mash, and act as a filter bed during lautering, when sweet wort is separated from insoluble grain material. Other malted and unmalted grains (including wheat, rice, oats, and rye, and less frequently, corn and sorghum) may be used. Some brewers have produced gluten-free beer, made with sorghum with no barley malt, for those who cannot consume gluten-containing grains like wheat, barley, and rye.[70]
",5
6218,"Flavouring beer is the sole major commercial use of hops.[71] The flower of the hop vine is used as a flavouring and preservative agent in nearly all beer made today. The flowers themselves are often called ""hops"". The first historical mention of the use of hops in beer was from 822 AD in monastery rules written by Adalhard the Elder, also known as Adalard of Corbie,[45][72] though the date normally given for widespread cultivation of hops for use in beer is the thirteenth century.[45][72] Before the thirteenth century, and until the sixteenth century, during which hops took over as the dominant flavouring, beer was flavoured with other plants; for instance, grains of paradise or alehoof. Combinations of various aromatic herbs, berries, and even ingredients like wormwood would be combined into a mixture known as gruit and used as hops are now used.[73] Some beers today, such as Fraoch' by the Scottish Heather Ales company[74] and Cervoise Lancelot by the French Brasserie-Lancelot company,[75] use plants other than hops for flavouring.
",5
6219,"Hops contain several characteristics that brewers desire in beer. Hops contribute a bitterness that balances the sweetness of the malt; the bitterness of beers is measured on the International Bitterness Units scale. Hops contribute floral, citrus, and herbal aromas and flavours to beer. Hops have an antibiotic effect that favours the activity of brewer's yeast over less desirable microorganisms and aids in ""head retention"",[76][77] the length of time that a foamy head created by carbonation will last. The acidity of hops is a preservative.[78][79]
",5
6220,"Yeast is the microorganism that is responsible for fermentation in beer. Yeast metabolises the sugars extracted from grains, which produces alcohol and carbon dioxide, and thereby turns wort into beer. In addition to fermenting the beer, yeast influences the character and flavour.[80] The dominant types of yeast used to make beer are the top-fermenting Saccharomyces cerevisiae and bottom-fermenting Saccharomyces pastorianus.[81] Brettanomyces ferments lambics,[82] and Torulaspora delbrueckii ferments Bavarian weissbier.[83] Before the role of yeast in fermentation was understood, fermentation involved wild or airborne yeasts. A few styles such as lambics rely on this method today, but most modern fermentation adds pure yeast cultures.[84]
",5
6221,"Some brewers add one or more clarifying agents or finings to beer, which typically precipitate (collect as a solid) out of the beer along with protein solids and are found only in trace amounts in the finished product. This process makes the beer appear bright and clean, rather than the cloudy appearance of ethnic and older styles of beer such as wheat beers.[85] Examples of clarifying agents include isinglass, obtained from swimbladders of fish; Irish moss, a seaweed; kappa carrageenan, from the seaweed Kappaphycus cottonii; Polyclar (artificial); and gelatin.[86] If a beer is marked ""suitable for vegans"", it was clarified either with seaweed or with artificial agents.[87]
",5
6222,"The history of breweries in the 21st century has included larger breweries absorbing smaller breweries in order to ensure economy of scale.[clarification needed] In 2002, South African Breweries bought the North American Miller Brewing Company to found SABMiller, becoming the second largest brewery, after North American Anheuser-Busch. In 2004, the Belgian Interbrew was the third largest brewery by volume and the Brazilian AmBev was the fifth largest. They merged into InBev, becoming the largest brewery. In 2007, SABMiller surpassed InBev and Anheuser-Bush when it acquired Royal Grolsch, brewer of Dutch premium beer brand Grolsch in 2007.[89] In 2008, when InBev (the second-largest) bought Anheuser-Busch (the third largest), the new Anheuser-Busch InBev company became again the largest brewer in the world.[90]
",5
6223,"As of 2020[update], according to the market research firm Technavio, AB InBev remains the largest brewing company in the world, with Heineken second, CR Snow third, Carlsberg fourth, and Molson Coors fifth.[91]
",5
6224,"A microbrewery, or craft brewery, produces a limited amount of beer. The maximum amount of beer a brewery can produce and still be classed as a microbrewery varies by region and by authority; in the US it is 15,000 US beer barrels (1.8 megalitres; 390 thousand imperial gallons; 460 thousand US gallons) a year.[92] A brewpub is a type of microbrewery that incorporates a pub or other drinking establishment. The highest density of breweries in the world, most of them microbreweries, exists in the German Region of Franconia, especially in the district of Upper Franconia, which has about 200 breweries.[93][94] The Benedictine Weihenstephan brewery in Bavaria, Germany, can trace its roots to the year 768, as a document from that year refers to a hop garden in the area paying a tithe to the monastery. The brewery was licensed by the City of Freising in 1040, and therefore is the oldest working brewery in the world.[95]
",5
6225,"While there are many types of beer brewed, the basics of brewing beer are shared across national and cultural boundaries.[96] The traditional European brewing regions—Germany, Belgium, England and the Czech Republic—have local varieties of beer.[97]
",5
6226,"English writer Michael Jackson, in his 1977 book The World Guide To Beer, categorised beers from around the world in local style groups suggested by local customs and names.[98] Fred Eckhardt furthered Jackson's work in The Essentials of Beer Style in 1989.
",5
6227,"Top-fermented beers are most commonly produced with Saccharomyces cerevisiae, a top-fermenting yeast which clumps and rises to the surface,[99] typically between 15 and 25 °C (59 and 77 °F). At these temperatures, yeast produces significant amounts of esters and other secondary flavour and aroma products, and the result is often a beer with slightly ""fruity"" compounds resembling apple, pear, pineapple, banana, plum, or prune, among others.[100]
",5
6228,"After the introduction of hops into England from Flanders in the 15th century, ""ale"" referred to an unhopped fermented drink, ""beer"" being used to describe a brew with an infusion of hops.[101]
",5
6229,"Real ale is the term coined by the Campaign for Real Ale (CAMRA) in 1973[102] for ""beer brewed from traditional ingredients, matured by secondary fermentation in the container from which it is dispensed, and served without the use of extraneous carbon dioxide"". It is applied to bottle conditioned and cask conditioned beers.
",5
6230,"Pale ale is a beer which uses a top-fermenting yeast[103] and predominantly pale malt. It is one of the world's major beer styles.
",5
6231,"Stout and porter are dark beers made using roasted malts or roast barley, and typically brewed with slow fermenting yeast. There are a number of variations including Baltic porter, dry stout, and Imperial stout. The name ""porter"" was first used in 1721 to describe a dark brown beer popular with the street and river porters of London.[104] This same beer later also became known as stout, though the word stout had been used as early as 1677.[105] The history and development of stout and porter are intertwined.[106]
",5
6232,"Mild ale has a predominantly malty palate. It is usually dark coloured with an abv of 3% to 3.6%, although there are lighter hued milds as well as stronger examples reaching 6% abv and higher.
",5
6233,"Wheat beer is brewed with a large proportion of wheat although it often also contains a significant proportion of malted barley. Wheat beers are usually top-fermented.[107] The flavour of wheat beers varies considerably, depending upon the specific style.
",5
6234,"Lambic, a beer of Belgium, is naturally fermented using wild yeasts, rather than cultivated. Many of these are not strains of brewer's yeast (Saccharomyces cerevisiae) and may have significant differences in aroma and sourness. Yeast varieties such as Brettanomyces bruxellensis and Brettanomyces lambicus are common in lambics. In addition, other organisms such as Lactobacillus bacteria produce acids which contribute to the sourness.[108]
",5
6235,"Lager is cool fermented beer. Pale lagers are the most commonly consumed beers in the world. Many are of the “pilsner” type. The name ""lager"" comes from the German ""lagern"" for ""to store"", as brewers around Bavaria stored beer in cool cellars and caves during the warm summer months. These brewers noticed that the beers continued to ferment, and to also clear of sediment, when stored in cool conditions.[109]
",5
6236,"Lager yeast is a cool bottom-fermenting yeast (Saccharomyces pastorianus) and typically undergoes primary fermentation at 7–12 °C (45–54 °F) (the fermentation phase), and then is given a long secondary fermentation at 0–4 °C (32–39 °F) (the lagering phase). During the secondary stage, the lager clears and mellows. The cooler conditions also inhibit the natural production of esters and other byproducts, resulting in a ""cleaner""-tasting beer.[110]
",5
6237,"With improved modern yeast strains, most lager breweries use only short periods of cold storage, typically 1–3 weeks.
",5
6238,"Beer is measured and assessed by bitterness, by strength and by colour. The perceived bitterness is measured by the International Bitterness Units scale (IBU), defined in co-operation between the American Society of Brewing Chemists and the European Brewery Convention.[111] The international scale was a development of the European Bitterness Units scale, often abbreviated as EBU, and the bitterness values should be identical.[112]
",5
6239,"Beer colour is determined by the malt.[113] The most common colour is a pale amber produced from using pale malts. Pale lager and pale ale are terms used for beers made from malt dried with the fuel coke. Coke was first used for roasting malt in 1642, but it was not until around 1703 that the term pale ale was used.[114][115]
",5
6240,"In terms of sales volume, most of today's beer is based on the pale lager brewed in 1842 in the town of Pilsen in the present-day Czech Republic.[116] The modern pale lager is light in colour with a noticeable carbonation (fizzy bubbles) and a typical alcohol by volume content of around 5%.[117] The Pilsner Urquell, Bitburger, and Heineken brands of beer are typical examples of pale lager, as are the American brands Budweiser, Coors, and Miller.
",5
6241,"Dark beers are usually brewed from a pale malt or lager malt base with a small proportion of darker malt added to achieve the desired shade. Other colourants—such as caramel—are also widely used to darken beers. Very dark beers, such as stout, use dark or patent malts that have been roasted longer. Some have roasted unmalted barley.[118][119]
",5
6242,"Beer ranges from less than 3% alcohol by volume (abv) to around 14% abv, though this strength can be increased to around 20% by re-pitching with champagne yeast,[120] and to 55% abv by the freeze-distilling process.[121] The alcohol content of beer varies by local practice or beer style.[122] The pale lagers that most consumers are familiar with fall in the range of 4–6%, with a typical abv of 5%.[123] The customary strength of British ales is quite low, with many session beers being around 4% abv.[124] In Belgium, some beers, such as table beer are of such low alcohol content (1%–4%) that they are served instead of soft drinks in some schools.[125]
",5
6243,"The alcohol in beer comes primarily from the metabolism of sugars that are produced during fermentation. The quantity of fermentable sugars in the wort and the variety of yeast used to ferment the wort are the primary factors that determine the amount of alcohol in the final beer. Additional fermentable sugars are sometimes added to increase alcohol content, and enzymes are often added to the wort for certain styles of beer (primarily ""light"" beers) to convert more complex carbohydrates (starches) to fermentable sugars. Alcohol is a by-product of yeast metabolism and is toxic to the yeast in higher concentrations; typical brewing yeast cannot survive at alcohol concentrations above 12% by volume. Low temperatures and too little fermentation time decreases the effectiveness of yeasts and consequently decreases the alcohol content.
",5
6244,"The weakest beers are dealcoholized beers, which typically have less than 0.05% alcohol (also called ""near beer"") and light beers, which usually have 4% alcohol.
",5
6245,"
The strength of beers has climbed during the later years of the 20th century. Vetter 33, a 10.5% abv (33 degrees Plato, hence Vetter ""33"") doppelbock, was listed in the 1994 Guinness Book of World Records as the strongest beer at that time,[126][127] though Samichlaus, by the Swiss brewer Hürlimann, had also been listed by the Guinness Book of World Records as the strongest at 14% abv.[128][129][130] Since then, some brewers have used champagne yeasts to increase the alcohol content of their beers. Samuel Adams reached 20% abv with Millennium,[120] and then surpassed that amount to 25.6% abv with Utopias. The strongest beer brewed in Britain was Baz's Super Brew by Parish Brewery, a 23% abv beer.[131][132] In September 2011, the Scottish brewery BrewDog produced Ghost Deer, which, at 28%, they claim to be the world's strongest beer produced by fermentation alone.[133]
",5
6246,"The product claimed to be the strongest beer made is Schorschbräu's 2011 Schorschbock 57 with 57,5%.[134][135] It was preceded by The End of History, a 55% Belgian ale,[121] made by BrewDog in 2010. The same company had previously made Sink The Bismarck!, a 41% abv IPA,[136] and Tactical Nuclear Penguin, a 32% abv Imperial stout. Each of these beers are made using the eisbock method of fractional freezing, in which a strong ale is partially frozen and the ice is repeatedly removed, until the desired strength is reached,[137][138] a process that may class the product as spirits rather than beer.[139] The German brewery Schorschbräu's Schorschbock, a 31% abv eisbock,[140][141][142] and Hair of the Dog's Dave, a 29% abv barley wine made in 1994, used the same fractional freezing method.[143] A 60% abv blend of beer with whiskey was jokingly claimed as the strongest beer by a Dutch brewery in July 2010.[144][145]
",5
6247,"Draught (also spelled ""draft"") beer from a pressurised keg using a lever-style dispenser and a spout is the most common method of dispensing in bars around the world. A metal keg is pressurised with carbon dioxide (CO2) gas which drives the beer to the dispensing tap or faucet. Some beers may be served with a nitrogen/carbon dioxide mixture. Nitrogen produces fine bubbles, resulting in a dense head and a creamy mouthfeel. Some types of beer can also be found in smaller, disposable kegs called beer balls. In traditional pubs, the pull levers for major beer brands may include the beer's logo and trademark.
",5
6248,"In the 1980s, Guinness introduced the beer widget, a nitrogen-pressurised ball inside a can which creates a dense, tight head, similar to beer served from a nitrogen system.[146] The words draft and draught can be used as marketing terms to describe canned or bottled beers containing a beer widget, or which are cold-filtered rather than pasteurised.
",5
6249,"Cask-conditioned ales (or cask ales) are unfiltered and unpasteurised beers. These beers are termed ""real ale"" by the CAMRA organisation. Typically, when a cask arrives in a pub, it is placed horizontally on a frame called a ""stillage"" which is designed to hold it steady and at the right angle, and then allowed to cool to cellar temperature (typically between 11–13 °C or 52–55 °F),[147] before being tapped and vented—a tap is driven through a (usually rubber) bung at the bottom of one end, and a hard spile or other implement is used to open a hole in the side of the cask, which is now uppermost. The act of stillaging and then venting a beer in this manner typically disturbs all the sediment, so it must be left for a suitable period to ""drop"" (clear) again, as well as to fully condition—this period can take anywhere from several hours to several days. At this point the beer is ready to sell, either being pulled through a beer line with a hand pump, or simply being ""gravity-fed"" directly into the glass.
",5
6250,"Draught beer's environmental impact can be 68% lower than bottled beer due to packaging differences.[148][149] A life cycle study of one beer brand, including grain production, brewing, bottling, distribution and waste management, shows that the CO2 emissions from a 6-pack of micro-brew beer is about 3 kilograms (6.6 pounds).[150] The loss of natural habitat potential from the 6-pack of micro-brew beer is estimated to be 2.5 square metres (26 square feet).[151] Downstream emissions from distribution, retail, storage and disposal of waste can be over 45% of a bottled micro-brew beer's CO2 emissions.[150] Where legal, the use of a refillable jug, reusable bottle or other reusable containers to transport draught beer from a store or a bar, rather than buying pre-bottled beer, can reduce the environmental impact of beer consumption.[152]
",5
6251,"Most beers are cleared of yeast by filtering when packaged in bottles and cans.[153] However, bottle conditioned beers retain some yeast—either by being unfiltered, or by being filtered and then reseeded with fresh yeast.[154] It is usually recommended that the beer be poured slowly, leaving any yeast sediment at the bottom of the bottle. However, some drinkers prefer to pour in the yeast; this practice is customary with wheat beers. Typically, when serving a hefeweizen wheat beer, 90% of the contents are poured, and the remainder is swirled to suspend the sediment before pouring it into the glass. Alternatively, the bottle may be inverted prior to opening. Glass bottles are always used for bottle conditioned beers.
",5
6252,"Many beers are sold in cans, though there is considerable variation in the proportion between different countries. In Sweden in 2001, 63.9% of beer was sold in cans.[155] People either drink from the can or pour the beer into a glass. A technology developed by Crown Holdings for the 2010 FIFA World Cup is the 'full aperture' can, so named because the entire lid is removed during the opening process, turning the can into a drinking cup.[156] Cans protect the beer from light (thereby preventing ""skunked"" beer) and have a seal less prone to leaking over time than bottles. Cans were initially viewed as a technological breakthrough for maintaining the quality of a beer, then became commonly associated with less expensive, mass-produced beers, even though the quality of storage in cans is much like bottles.[157] Plastic (PET) bottles are used by some breweries.[158]
",5
6253,"The temperature of a beer has an influence on a drinker's experience; warmer temperatures reveal the range of flavours in a beer but cooler temperatures are more refreshing. Most drinkers prefer pale lager to be served chilled, a low- or medium-strength pale ale to be served cool, while a strong barley wine or imperial stout to be served at room temperature.[159]
",5
6254,"Beer writer Michael Jackson proposed a five-level scale for serving temperatures: well chilled (7 °C or 45 °F) for ""light"" beers (pale lagers); chilled (8 °C or 46 °F) for Berliner Weisse and other wheat beers; lightly chilled (9 °C or 48 °F) for all dark lagers, altbier and German wheat beers; cellar temperature (13 °C or 55 °F) for regular British ale, stout and most Belgian specialities; and room temperature (15.5 °C or 60 °F) for strong dark ales (especially trappist beer) and barley wine.[160]
",5
6255,"Drinking chilled beer began with the development of artificial refrigeration and by the 1870s, was spread in those countries that concentrated on brewing pale lager.[161] Chilling beer makes it more refreshing,[162] though below 15.5 °C (60 °F) the chilling starts to reduce taste awareness[163] and reduces it significantly below 10 °C (50 °F).[164] Beer served unchilled—either cool or at room temperature—reveal more of their flavours. Cask Marque, a non-profit UK beer organisation, has set a temperature standard range of 12°–14 °C (53°–57 °F) for cask ales to be served.[165]
",5
6256,"Beer is consumed out of a variety of vessels, such as a glass, a beer stein, a mug, a pewter tankard, a beer bottle or a can; or at music festivals and some bars and nightclubs, from a plastic cup. The shape of the glass from which beer is consumed can influence the perception of the beer and can define and accent the character of the style.[166] Breweries offer branded glassware intended only for their own beers as a marketing promotion, as this increases sales of their product.[167]
",5
6257,"The pouring process has an influence on a beer's presentation. The rate of flow from the tap or other serving vessel, tilt of the glass, and position of the pour (in the centre or down the side) into the glass all influence the end result, such as the size and longevity of the head, lacing (the pattern left by the head as it moves down the glass as the beer is drunk), and the release of carbonation.[168]
A beer tower is a beer dispensing device, usually found in bars and pubs, that consists of a cylinder attached to a beer cooling device at the bottom. Beer is dispensed from the beer tower into a drinking vessel.
",5
6258,"Beer contains ethanol, an alcohol, which has short and long-term effects on the user when consumed. Different concentrations of alcohol in the human body have different effects on a person. The effects of alcohol depend on the amount an individual has drunk, the percentage of alcohol in the beer and the timespan over which the consumption has taken place, the amount of food eaten and whether an individual has taken other prescription, over-the-counter or street drugs, among other factors. Drinking enough to cause a blood alcohol concentration (BAC) of 0.03%–0.12% typically causes an overall improvement in mood and possible euphoria, increased self-confidence and sociability, decreased anxiety, a flushed, red appearance in the face, impaired judgement and fine muscle coordination. A BAC of 0.09% to 0.25% causes lethargy, sedation, balance problems and blurred vision. A BAC from 0.18% to 0.30% causes profound confusion, impaired speech (e.g., slurred speech), staggering, dizziness and vomiting. A BAC from 0.25% to 0.40% causes stupor, unconsciousness, anterograde amnesia, vomiting (death may occur due to inhalation of vomit (pulmonary aspiration) while unconscious) and respiratory depression (potentially life-threatening). A BAC from 0.35% to 0.80% causes a coma (unconsciousness), life-threatening respiratory depression and possibly fatal alcohol poisoning. As with all alcoholic drinks, drinking while driving, operating an aircraft or heavy machinery increases the risk of an accident; many countries have severe criminal penalties against drunk driving.
",5
6259,"A 2016 systematic review and meta-analysis found that moderate ethanol consumption brought no mortality benefit compared with lifetime abstention from ethanol consumption.[169] Some studies have concluded that drinking small quantities of alcohol (less than one drink in women and two in men) is associated with a decreased risk of heart disease, stroke, diabetes mellitus, and early death.[170] Some of these studies combined former ethanol drinkers and lifelong abstainers into a single group of nondrinkers, which hides the health benefits of lifelong abstention from ethanol. The long-term health effects of continuous, moderate or heavy alcohol consumption include the risk of developing alcoholism and alcoholic liver disease. Alcoholism, also known as ""alcohol use disorder"", is a broad term for any drinking of alcohol that results in problems.[171] It was previously divided into two types: alcohol abuse and alcohol dependence.[172][173] In a medical context, alcoholism is said to exist when two or more of the following conditions is present: a person drinks large amounts over a long time period, has difficulty cutting down, acquiring and drinking alcohol takes up a great deal of time, alcohol is strongly desired, usage results in not fulfilling responsibilities, usage results in social problems, usage results in health problems, usage results in risky situations, withdrawal occurs when stopping, and alcohol tolerance has occurred with use.[173] Alcoholism reduces a person's life expectancy by around ten years[174] and alcohol use is the third leading cause of early death in the United States.[170] No professional medical association recommends that people who are nondrinkers should start drinking wine.[170][175] A total of 3.3 million deaths (5.9% of all deaths) are believed to be due to alcohol.[176]
",5
6260,"It is considered that overeating and lack of muscle tone is the main cause of a beer belly, rather than beer consumption. A 2004 study, however, found a link between binge drinking and a beer belly. But with most overconsumption, it is more a problem of improper exercise and overconsumption of carbohydrates than the product itself.[177] Several diet books quote beer as having an undesirably high glycemic index of 110, the same as maltose; however, the maltose in beer undergoes metabolism by yeast during fermentation so that beer consists mostly of water, hop oils and only trace amounts of sugars, including maltose.[178]
",5
6261,"Beers vary in their nutritional content.[179] The ingredients used to make beer, including the yeast, provide a rich source of nutrients; therefore beer may contain nutrients including magnesium, selenium, potassium, phosphorus, biotin, chromium and B vitamins. Beer is sometimes referred to as ""liquid bread"",[180] though beer is not a meal in itself.[181]
",5
6262,"In many societies, beer is the most popular alcoholic drink. Various social traditions and activities are associated with beer drinking, such as playing cards, darts, or other pub games; attending beer festivals; engaging in zythology (the study of beer);[182][183] visiting a series of pubs in one evening; visiting breweries; beer-oriented tourism; or rating beer.[184] Drinking games, such as beer pong, are also popular.[185] A relatively new profession is that of the beer sommelier, who informs restaurant patrons about beers and food pairings.
",5
6263,"Beer is considered to be a social lubricant in many societies[186][187] and is consumed in countries all over the world. There are breweries in Middle Eastern countries such as Syria, and in some African countries. Sales of beer are four times those of wine, which is the second most popular alcoholic drink.[188]
",5
6264,"A study published in the Neuropsychopharmacology journal in 2013 revealed the finding that the flavour of beer alone could provoke dopamine activity in the brain of the male participants, who wanted to drink more as a result. The 49 men in the study were subject to positron emission tomography scans, while a computer-controlled device sprayed minute amounts of beer, water and a sports drink onto their tongues. Compared with the taste of the sports drink, the taste of beer significantly increased the participants desire to drink. Test results indicated that the flavour of the beer triggered a dopamine release, even though alcohol content in the spray was insufficient for the purpose of becoming intoxicated.[189]
",5
6265,"Some breweries have developed beers to pair with food.[190][191][192] Wine writer Malcolm Gluck disputed the need to pair beer with food, while beer writers Roger Protz and Melissa Cole contested that claim.[193][194][195]
",5
6266,"Around the world, there are many traditional and ancient starch-based drinks classed as beer. In Africa, there are various ethnic beers made from sorghum or millet, such as Oshikundu[196] in Namibia and Tella in Ethiopia.[197] Kyrgyzstan also has a beer made from millet; it is a low alcohol, somewhat porridge-like drink called ""Bozo"".[198] Bhutan, Nepal, Tibet and Sikkim also use millet in Chhaang, a popular semi-fermented rice/millet drink in the eastern Himalayas.[199] Further east in China are found Huangjiu and Choujiu—traditional rice-based drinks related to beer.
",5
6267,"The Andes in South America has Chicha, made from germinated maize (corn); while the indigenous peoples in Brazil have Cauim, a traditional drink made since pre-Columbian times by chewing manioc so that an enzyme (amylase) present in human saliva can break down the starch into fermentable sugars;[200] this is similar to Masato in Peru.[201]
",5
6268,"Some beers which are made from bread, which is linked to the earliest forms of beer, are Sahti in Finland, Kvass in Russia and Ukraine, and Bouza in Sudan. 4000 years ago fermented bread was used in Mesopotamia. Food waste activists got inspired by this ancient recipes and use leftover bread to replace a third of the malted barley that would otherwise be used for brewing their craft ale.[202]
",5
6269,"Beer contains the phenolic acids 4-hydroxyphenylacetic acid, vanillic acid, caffeic acid, syringic acid, p-coumaric acid, ferulic acid, and sinapic acid. Alkaline hydrolysis experiments show that most of the phenolic acids are present as bound forms and only a small portion can be detected as free compounds.[203] Hops, and beer made with it, contain 8-prenylnaringenin which is a potent phytoestrogen.[204] Hop also contains myrcene, humulene, xanthohumol, isoxanthohumol, myrcenol, linalool, tannins, and resin. The alcohol 2M2B is a component of hops brewing.[205]
",5
6270,"Barley, in the form of malt, brings the condensed tannins prodelphinidins B3, B9 and C2 into beer. Tryptophol, tyrosol, and phenylethanol are aromatic higher alcohols found in beer[206] as secondary products of alcoholic fermentation[207] (products also known as congeners) by Saccharomyces cerevisiae.
",5
6271,"
",5
6272,"A taco (US: /ˈtɑːkoʊ/, UK: /ˈtækoʊ/, Spanish: [ˈtako]) is a traditional Mexican dish consisting of a small hand-sized corn or wheat tortilla topped with a filling. The tortilla is then folded around the filling and eaten by hand. A taco can be made with a variety of fillings, including beef, pork, chicken, seafood, beans, vegetables, and cheese, allowing for great versatility and variety. They are often garnished with various condiments, such as salsa, guacamole, or sour cream, and vegetables, such as lettuce, onion, tomatoes, and chiles. Tacos are a common form of antojitos, or Mexican street food, which have spread around the world.
",5
6273,"Tacos can be contrasted with similar foods such as burritos, which are often much larger and rolled rather than folded; taquitos, which are rolled and fried; or chalupas/tostadas, in which the tortilla is fried before filling.
",5
6274,"The origins of the taco are not precisely known, and etymologies for the culinary usage of the word are generally theoretical.[1] According to the Real Academia Española, publisher of Diccionario de la Lengua Española, the word taco describes a typical Mexican dish of a maize tortilla folded around food.[2] This meaning of the Spanish word ""taco"" is a Mexican innovation, but in other dialects ""taco"" is used to mean ""wedge; wad, plug; billiard cue; blowpipe; ramrod; short, stocky person; [or] short, thick piece of wood."" In this non-culinary usage, the word ""taco"" has cognates in other European languages, including the French word ""tache"" and the English word ""tack (nail).""[citation needed]
",5
6275,"According to one etymological theory, the culinary meaning of ""taco"" derives from its ""plug"" meaning as employed among Mexican silver miners, who used explosive charges in plug form consisting of a paper wrapper and gunpowder filling.[1]
",5
6276,"Indigenous origins for the culinary word ""taco"" are also proposed. One possibility is that the word derives from the Nahuatl word ""tlahco"", meaning ""half"" or ""in the middle,""[3] in the sense that food would be placed in the middle of a tortilla.[4] Furthermore, dishes analogous to the taco were known to have existed in Pre-Columbian society—for example, the Nahuatl word ""tlaxcalli"" (a type of corn tortilla).[3]
",5
6277,"The taco predates the arrival of the Spanish in Mexico. There is anthropological evidence that the indigenous people living in the lake region of the Valley of Mexico traditionally ate tacos filled with small fish. Writing at the time of the Spanish conquistadors, Bernal Díaz del Castillo documented the first taco feast enjoyed by Europeans, a meal which Hernán Cortés arranged for his captains in Coyoacán.[5][6]
",5
6278,"There are many traditional varieties of tacos:
",5
6279,"As an accompaniment to tacos, many taco stands will serve whole or sliced red radishes, lime slices, salt, pickled or grilled chilis (hot peppers), and occasionally cucumber slices, or grilled cambray onions.
",5
6280,"Tacos made with a carnitas filling
",5
6281,"Grilled shrimp taco
",5
6282,"Tacos de suadero (grey) and chorizo (red) being prepared at a taco stand
",5
6283,"Barbacoa tacos
",5
6284,"Taco al pastor with guacamole
",5
6285,"The hard-shell or crispy taco is a tradition that developed in the United States. The most common type of taco in the US is the hard-shell, U-shaped version, first described in a cookbook in 1949.[14] This type of taco is typically served as a crisp-fried corn tortilla filled with seasoned ground beef, cheese, lettuce, and sometimes tomato, onion, salsa, sour cream, and avocado or guacamole.[15] Such tacos are sold by restaurants and by fast food chains, while kits are readily available in most supermarkets. Hard shell tacos are sometimes known as tacos dorados (""golden tacos"") in Spanish,[16] a name that they share with taquitos.
",5
6286,"Various sources credit different individuals with the invention of the hard-shell taco, but some form of the dish likely predates all of them.[16] Beginning from the early part of the twentieth century, various types of tacos became popular in the country, especially in Texas and California but also elsewhere.[17] By the late 1930s,  companies like Ashley Mexican Food and Absolute Mexican Foods were selling appliances and ingredients for cooking hard shell tacos, and the first patents for hard-shell taco cooking appliances were filed in the 1940s.[16]
",5
6287,"In the mid-1950s, Glen Bell opened Taco Tia, and began selling a simplified version of the tacos being sold by Mexican restaurants in San Bernardino, particularly the tacos dorados being sold at the Mitla Cafe, owned by Lucia and Salvador Rodriguez across the street from another of Bell's restaurants.[16] Over the next few years, Bell owned and operated a number of restaurants in southern California including four called El Taco.[18] At this time, Los Angeles was racially-segregated, and the tacos sold at Bell's restaurants were many white Americans' first introduction to Mexican food.[16] Bell sold the El Tacos to his partner and built the first Taco Bell in Downey in 1962. Kermit Becky, a former Los Angeles police officer, bought the first Taco Bell franchise from Glen Bell in 1964,[18] and located it in Torrance. The company grew rapidly, and by 1967, the 100th restaurant opened at 400 South Brookhurst in Anaheim. In 1968, its first franchise location east of the Mississippi River opened in Springfield, Ohio.[19]
",5
6288,"A hard-shell taco, made with a prefabricated shell
",5
6289,"Common ingredients for North American hard shell tacos
",5
6290,"A crispy taco from a Sacramento, California taqueria
",5
6291,"
Traditionally, soft-shelled tacos referred to corn tortillas that were cooked to a softer state than a hard taco - usually by grilling or steaming. More recently, the term has come to include flour-tortilla-based tacos mostly from large manufacturers and restaurant chains. In this context, soft tacos are tacos made with wheat flour tortillas and filled with the same ingredients as a hard taco.[20]",5
6292,"The breakfast taco, found in Tex-Mex cuisine, is a soft corn or flour tortilla filled with meat, eggs, or cheese, and can also contain  other ingredients.[21] Some have claimed that Austin, Texas is the home of the breakfast taco.[22] However, food writer and OC Weekly editor Gustavo Arellano responded that such a statement reflects a common trend of ""whitewashed"" foodways reporting, noting that predominantly Hispanic San Antonio, Texas ""never had to brag about its breakfast taco love—folks there just call it 'breakfast'"".[23]
",5
6293,"Indian tacos, or Navajo tacos, are made using frybread instead of tortillas. They are commonly eaten at pow-wows, festivals, and other gatherings by and for indigenous people in the United States and Canada.[24][25]
",5
6294,"This kind of taco is not known to have been present before the arrival of Europeans in what is now the Southwestern United States. Navajo tradition indicates that frybread came into use in the 1860s when the government forced the tribe to relocate from their homeland in Arizona in a journey known as the Long Walk of the Navajo. It was made from ingredients given to them by the government to supplement their diet since the region couldn’t support growing the agricultural commodities that had been previously used.[26]
",5
6295,"A puffy taco
",5
6296,"A frybread taco
",5
6297,"A fish taco on frybread
",5
6298,"Since at least 1978, a variation called the ""puffy taco"" has been popular. Henry's Puffy Tacos, opened by Henry Lopez in San Antonio, Texas, claims to have invented the variation, in which uncooked corn tortillas (flattened balls of masa dough[27]) are quickly fried in hot oil until they expand and become ""puffy"".[28][29] Fillings are similar to hard-shell versions. Restaurants offering this style of taco have since appeared in other Texas cities, as well as in California, where Henry's brother, Arturo Lopez, opened Arturo's Puffy Taco in Whittier, not long after Henry's opened.[30][31] Henry's continues to thrive, managed by the family's second generation.[28]
",5
6299,"Kits are available at grocery and convenience stores and usually consist of taco shells (corn tortillas already fried in a U-shape), seasoning mix and taco sauce. Commercial vendors for the home market also market soft taco kits with tortillas instead of taco shells.[32][33]
",5
6300,"The tacodilla contains melted cheese in between the two folded tortillas, thus resembling a quesadilla.[34]
",5
6301,"In the United States, National Taco Day is celebrated annually on October 4.[35][36]
",5
6302,"







",5
6303,"
",5
6304,"
",5
6305,"Rice is the seed of the grass species Oryza sativa (Asian rice) or less commonly Oryza glaberrima (African rice). As a cereal grain, it is the most widely consumed staple food for a large part of the world's human population, especially in Asia and Africa. It is the agricultural commodity with the third-highest worldwide production (rice, 741.5 million tonnes in 2014), after sugarcane (1.9 billion tonnes) and maize (1.0 billion tonnes).[1]
",5
6306,"Since sizable portions of sugarcane and maize crops are used for purposes other than human consumption, rice is the most important food crop with regard to human nutrition and caloric intake, providing more than one-fifth of the calories consumed worldwide by humans.[2] There are many varieties of rice and culinary preferences tend to vary regionally.
",5
6307,"Rice, a monocot, is normally grown as an annual plant, although in tropical areas it can survive as a perennial and can produce a ratoon crop for up to 30 years.[3] Rice cultivation is well-suited to countries and regions with low labor costs and high rainfall, as it is labor-intensive to cultivate and requires ample water. However, rice can be grown practically anywhere, even on a steep hill or mountain area with the use of water-controlling terrace systems. Although its parent species are native to Asia and certain parts of Africa, centuries of trade and exportation have made it commonplace in many cultures worldwide.
",5
6308,"The traditional method for cultivating rice is flooding the fields while, or after, setting the young seedlings. This simple method requires sound irrigation planning but reduces the growth of less robust weed and pest plants that have no submerged growth state, and deters vermin. While flooding is not mandatory for the cultivation of rice, all other methods of irrigation require higher effort in weed and pest control during growth periods and a different approach for fertilizing the soil.
",5
6309,"The name wild rice is usually used for species of the genera Zizania and Porteresia, both wild and domesticated, although the term may also be used for primitive or uncultivated varieties of Oryza.
",5
6310,"The rice plant can grow to 1–1.8 m (3 ft 3 in–5 ft 11 in) tall, occasionally more depending on the variety and soil fertility. It has long, slender leaves 50–100 cm (20–40 in) long and 2–2.5 cm (3⁄4–1 in) broad. The small wind-pollinated flowers are produced in a branched arching to pendulous inflorescence 30–50 cm (12–20 in) long. The edible seed is a grain (caryopsis) 5–12 mm (3⁄16–15⁄32 in) long and 2–3 mm (3⁄32–1⁄8 in) thick.
",5
6311,"The varieties of rice are typically classified as long-, medium-, and short-grained.[4] The grains of long-grain rice (high in amylose) tend to remain intact after cooking; medium-grain rice (high in amylopectin) becomes more sticky. Medium-grain rice is used for sweet dishes, for risotto in Italy, and many rice dishes, such as arròs negre, in Spain. Some varieties of long-grain rice that are high in amylopectin, known as Thai Sticky rice, are usually steamed.[5] A stickier short-grain rice is used for sushi;[6] the stickiness allows rice to hold its shape when cooked.[7] Short-grain rice is used extensively in Japan,[8] including to accompany savoury dishes.[9] Short-grain rice is often used for rice pudding.
",5
6312,"Instant rice differs from parboiled rice in that it is fully cooked and then dried, though there is a significant degradation in taste and texture. Rice flour and starch often are used in batters and breadings to increase crispiness.
",5
6313,"Rinsing rice before cooking removes much of the starch, thereby reducing the extent to which individual grains will stick together. This yields a fluffier rice, whereas not rinsing yields a stickier and creamier result.[10] Rice produced in the US is usually fortified with vitamins and minerals, and rinsing will result in a loss of nutrients. 
",5
6314,"Rice may be soaked to decrease cooking time, conserve fuel, minimize exposure to high temperature, and reduce stickiness. For some varieties, soaking improves the texture of the cooked rice by increasing expansion of the grains. Rice may be soaked for 30 minutes up to several hours.
",5
6315,"Brown rice may be soaked in warm water for 20 hours to stimulate germination. This process, called germinated brown rice (GBR),[11] activates enzymes and enhances amino acids including gamma-aminobutyric acid to improve the nutritional value of brown rice. This method is a result of research carried out for the United Nations International Year of Rice.
",5
6316,"Rice is cooked by boiling or steaming, and absorbs water during cooking. With the absorption method, rice may be cooked in a volume of water equal to the volume of dry rice plus any evaporation losses.[12] With the rapid-boil method, rice may be cooked in a large quantity of water which is drained before serving. Rapid-boil preparation is not desirable with enriched rice, as much of the enrichment additives are lost when the water is discarded. Electric rice cookers, popular in Asia and Latin America, simplify the process of cooking rice. Rice (or any other grain) is sometimes quickly fried in oil or fat before boiling (for example saffron rice or risotto); this makes the cooked rice less sticky, and is a cooking style commonly called pilaf in Iran and Afghanistan or biryani in India and Pakistan.
",5
6317,"In Arab cuisine, rice is an ingredient of many soups and dishes with fish, poultry, and other types of meat. It is used to stuff vegetables or is wrapped in grape leaves (dolma). When combined with milk, sugar, and honey, it is used to make desserts. In some regions, such as Tabaristan, bread is made using rice flour. Rice may be made into congee (also called rice porridge or rice gruel) by adding more water than usual, so that the cooked rice is saturated with water, usually to the point that it disintegrates. Rice porridge is commonly eaten as a breakfast food, and is a traditional food for the sick.
",5
6318,"Rice is the staple food of over half the world's population. It is the predominant dietary energy source for 17 countries in Asia and the Pacific, 9 countries in North and South America and 8 countries in Africa. Rice provides 20% of the world's dietary energy supply, while wheat supplies 19% and maize (corn) 5%.[13]
",5
6319,"Cooked unenriched long-grain white rice is composed of 68% water, 28% carbohydrates, 3% protein, and negligible fat (table). A 100-gram (3 1⁄2-ounce) reference serving of it provides 540 kilojoules (130 kilocalories) of food energy and contains no micronutrients in significant amounts, with all less than 10% of the Daily Value (DV) (table). Cooked short-grain white rice provides the same food energy and contains moderate amounts of B vitamins, iron, and manganese (10–17% DV) per 100-gram serving (table).
",5
6320,"A detailed analysis of nutrient content of rice suggests that the nutrition value of rice varies based on a number of factors. It depends on the strain of rice, such as white, brown, red, and black (or purple) varieties having different prevalence across world regions.[14] It also depends on nutrient quality of the soil rice is grown in, whether and how the rice is polished or processed, the manner it is enriched, and how it is prepared before consumption.[15]
",5
6321,"A 2018 World Health Organization (WHO) guideline showed that fortification of rice to reduce malnutrition may involve different micronutrient strategies, including iron only, iron with zinc, vitamin A, and folic acid, or iron with other B-complex vitamins, such as thiamin, niacin, vitamin B6, and pantothenic acid.[14] A systematic review of clinical research on the efficacy of rice fortification showed the strategy had the main effect of reducing the risk of iron deficiency by 35% and increasing blood levels of hemoglobin.[14] The guideline established a major recommendation: ""Fortification of rice with iron is recommended as a public health strategy to improve the iron status of populations, in settings where rice is a staple food.""[14]
",5
6322,"Rice grown experimentally under elevated carbon dioxide levels, similar to those predicted for the year 2100 as a result of human activity, had less iron, zinc, and protein, as well as lower levels of thiamin, riboflavin, folic acid, and pantothenic acid.[16]
",5
6323,"A  raw yellow dent corn
B  raw unenriched long-grain white rice
C  raw hard red winter wheat
D  raw potato with flesh and skin
E  raw cassava
F  raw green soybeans
G  raw sweet potato
H  raw sorghum
Y  raw yam
Z  raw plantains
/*  unofficial
",5
6324,"As arsenic is a natural element in soil, water, and air, the United States Food and Drug Administration (FDA) monitors the levels of arsenic in foods, particularly in rice products used commonly for infant food.[18] While growing, rice plants tend to absorb arsenic more readily than other food crops, requiring expanded testing by the FDA for possible arsenic-related risks associated with rice consumption in the United States.[18] In April 2016, the FDA proposed a limit of 100 parts per billion (ppb) for inorganic arsenic in infant rice cereal and other foods to minimize exposure of infants to arsenic.[18] For water contamination by arsenic, the United States Environmental Protection Agency has set a lower standard of 10 ppb.[19]
",5
6325,"Arsenic is a Group 1 carcinogen.[18][20] The amount of arsenic in rice varies widely with the greatest concentration in brown rice and rice grown on land formerly used to grow cotton, such as in Arkansas, Louisiana, Missouri, and Texas.[21] White rice grown in Arkansas, Louisiana, Missouri, and Texas, which account collectively for 76 percent of American-produced rice, had higher levels of arsenic than other regions of the world studied, possibly because of past use of arsenic-based pesticides to control cotton weevils.[22] Jasmine rice from Thailand and Basmati rice from Pakistan and India contain the least arsenic among rice varieties in one study.[23] China has set a limit of 150 ppb for arsenic in rice.[24]
",5
6326,"Cooked rice can contain Bacillus cereus spores, which produce an emetic toxin when left at 4–60 °C (39–140 °F). When storing cooked rice for use the next day, rapid cooling is advised to reduce the risk of toxin production.[25] One of the enterotoxins produced by Bacillus cereus is heat-resistant; reheating contaminated rice kills the bacteria, but does not destroy the toxin already present.
",5
6327,"Medieval Islamic texts spoke of medical uses for the plant.[26]
",5
6328,"Rice growth and production are affected by: the environment, soil properties, biotic conditions, and cultural practices. Environmental factors include rainfall and water, temperature, photoperiod, solar radiation and, in some instances, tropical storms. Soil factors refer to soil type and their position in uplands or lowlands. Biotic factors deal with weeds, insects, diseases, and crop varieties. [27]
",5
6329,"Rice can be grown in different environments, depending upon water availability.[28] Generally, rice does not thrive in a waterlogged area, yet it can survive and grow herein[29] and it can survive flooding.[30]
",5
6330,"First used in English in the middle of the 13th century, the word ""rice"" derives from the Old French ris, which comes from the Italian riso, in turn from the Latin orȳza, which derives from the Greek ὄρυζα (oruza). The Greek word is the source of all European words (compare Welsh reis, German Reis, Lithuanian ryžiai, Serbo-Croatian riža, Polish ryż, Dutch rijst, Hungarian rizs, Romanian orez, Spanish arroz).[32][33][34]
",5
6331,"The origin of the Greek word is unclear. It is sometimes held to be from the Tamil word அரிசி (arisi), or rather Old Tamil 𑀅𑀭𑀺𑀘𑀺 (arici).[35][36] However, Krishnamurti[37] disagrees with the notion that Old Tamil arici is the source of the Greek term, and proposes that it was borrowed from descendants of Proto-Dravidian *wariñci instead. Mayrhofer[38] suggests that the immediate source of the Greek word is to be sought in Old Iranian words of the types *vrīz- or *vrinj-, source of the modern Persian word برنج (berenj), but these are ultimately traced back to Indo-Aryan (as in Sanskrit व्रीहि, vrīhí-).
",5
6332,"The current scientific consensus, based on archaeological and linguistic evidence, is that rice was first domesticated in the Yangtze River basin in China.[40][41][42][43] Because the functional allele for nonshattering, the critical indicator of domestication in grains, as well as five other single-nucleotide polymorphisms, is identical in both indica and japonica, Vaughan et al. (2008) determined a single domestication event for O. sativa.[41] This was supported by a genetic study in 2011 that showed that all forms of Asian rice, both indica and japonica, sprang from a single domestication event that occurred 13,500 to 8,200 years ago in China from the wild rice Oryza rufipogon.[44] A more recent population genomic study indicates that japonica was domesticated first, and that indica rice arose when japonica arrived in India about ~4,500 years ago and hybridized with an undomesticated proto-indica or wild O. nivara.[45]
",5
6333,"There are two most likely centers of domestication for rice as well as the development of the wetland agriculture technology. The first, and most likely, is in the lower Yangtze River, believed to be the homelands of the pre-Austronesians and possibly also the Kra-Dai, and associated with the Kauhuqiao, Hemudu, Majiabang, Songze, Liangzhu, and Maqiao cultures. It is characterized by pre-Austronesian features, including stilt houses, jade carving, and boat technologies. Their diet were also supplemented by acorns, water chestnuts, foxnuts, and pig domestication.[43][39][46][47][48]
",5
6334,"The second is in the middle Yangtze River, believed to be the homelands of the early Hmong-Mien-speakers and associated with the Pengtoushan, Nanmuyuan, Liulinxi, Daxi, Qujialing, and Shijiahe cultures. Both of these regions were heavily populated and had regular trade contacts with each other, as well as with early Austroasiatic speakers to the west, and early Kra-Dai speakers to the south, facilitating the spread of rice cultivation throughout southern China.[39][46][48]
",5
6335,"Rice was gradually introduced north into early Sino-Tibetan Yangshao and Dawenkou culture millet farmers, either via contact with the Daxi culture or the Majiabang-Hemudu culture. By around 4000 to 3800 BC, they were a regular secondary crop among southernmost Sino-Tibetan cultures. It did not replace millet, largely because of different environment conditions in northern China, but it was cultivated alongside millet in the southern boundaries of the millet-farming regions. Conversely, millet was also introduced into rice-farming regions.[39][49]
",5
6336,"By the late Neolithic (3500 to 2500 BC), population in the rice cultivating centers had increased rapidly, centered around the Qujialing-Shijiahe culture and the Liangzhu culture. There was also evidence of intensive rice cultivation in paddy fields as well as increasingly sophisticated material cultures in these two regions. The number of settlements among the Yangtze cultures and their sizes increased, leading some archeologists to characterize them as true states, with clearly advanced socio-political structures. However, it is unknown if they had centralized control.[50][51]
",5
6337,"Liangzhu and Shijiahe declined abruptly in the terminal Neolithic (2500 to 2000 BC). With Shijiahe shrinking in size, and Liangzhu disappearing altogether. This is largely believed to be the result of the southward expansion of the early Sino-Tibetan Longshan culture. Fortifications like walls (as well as extensive moats in Liangzhu cities) are common features in settlements during this period, indicating widespread conflict. This period also coincides with the southward movement of rice-farming cultures to the Lingnan and Fujian regions, as well as the southward migrations of the Austronesian, Kra-Dai, and Austroasiatic-speaking peoples to Mainland Southeast Asia and Island Southeast Asia.[50][52][53] A genomic study also indicates that at around this time, a global cooling event (the 4.2 k event) led to tropical japonica rice being pushed southwards, as well as the evolution of temperate japonica rice that could grow in more northern latitudes.[54]
",5
6338,"Genomic studies suggests that indica rice arrives in China from India between 2,000 and 1,400 years ago.[54]
",5
6339,"The spread of japonica rice cultivation to Southeast Asia started with the migrations of the Austronesian Dapenkeng culture into Taiwan between 3500 and 2000 BC (5,500 BP to 4,000 BP). The Nanguanli site in Taiwan, dated to ca. 2800 BC, has yielded numerous carbonized remains of both rice and millet in waterlogged conditions, indicating intensive wetland rice cultivation and dryland millet cultivation.[46] A multidisciplinary study using rice genome sequences indicate that tropical japonica rice was pushed southwards from China after a global cooling event (the 4.2k event) that occurred approximately 4,200 years ago.[54]
",5
6340,"From about 2000 to 1500 BC, the Austronesian expansion began, with settlers from Taiwan moving south to colonize Luzon in the Philippines, bringing rice cultivation technologies with them. From Luzon, Austronesians rapidly colonized the rest of Island Southeast Asia, moving westwards to Borneo, the Malay Peninsula and Sumatra; and southwards to Sulawesi and Java. By 500 BC, there is evidence of intensive wetland rice agriculture already established in Java and Bali, especially near very fertile volcanic islands.[46]
",5
6341,"However, rice (as well as dogs and pigs) did not survive the first Austronesian voyages into Micronesia due to the sheer distance of ocean they were crossing. These voyagers became the ancestors of the Lapita culture. By the time they migrated southwards to the Bismarck Archipelago, they had already lost the technology of rice farming, as well as pigs and dogs. However, knowledge of rice cultivation is still evident in the way they adapted the wetland agriculture techniques to taro cultivation. The Lapita culture in Bismarck reestablished trade connections with other Austronesian branches in Island Southeast Asia. They also came into contact with the non-Austronesian (Papuan) early agriculturists of New Guinea and introduced wetland farming techniques to them. In turn, they assimilated their range of indigenous cultivated fruits and tubers, as well as reacquiring domesticated dogs and pigs, before spreading further eastward to Island Melanesia and Polynesia.[46]
",5
6342,"Rice, along with other Southeast Asian food plants, were also later introduced to Madagascar, the Comoros, and the coast of East Africa by around the 1st millennium AD by Austronesian settlers from the Greater Sunda Islands.[55]
",5
6343,"Much later Austronesian voyages from Island Southeast Asia succeeded in bringing rice to Guam during the Latte Period (AD 900 to AD 1700). Guam is the only island in Oceania where rice was grown in pre-colonial times.[56][57]
",5
6344,"Within Mainland Southeast Asia, rice was presumably spread through river trade between the early Hmong-Mien-speakers of the Middle Yangtze basin and the early Kra-Dai-speakers of the Pearl River and Red River basins, as well as the early Austroasiatic-speakers of the Mekong River basin. Evidence for rice cultivation in these regions, dates to slightly later than the Dapenkeng settlement of Taiwan, at around 3000 BC. Southward migrations of the Austroasiatic and Kra-Dai-speakers introduced it into Mainland Southeast Asia. The earliest evidence of rice cultivation in Mainland Southeast Asia come from the Ban Chiang site in northern Thailand (ca. 2000 to 1500 BC); and the An Sơn site in southern Vietnam (ca. 2000 to 1200 BC).[46][58] A genomic study indicates that rice diversified into Maritime Southeast Asia between 2,500 and 1,500 years ago.[54]
",5
6345,"Mainstream archaeological evidence derived from palaeoethnobotanical investigations indicate dry-land rice was introduced to Korea and Japan sometime between 3500 and 1200 BC. The cultivation of rice then occurred on a small scale, fields were impermanent plots, and evidence shows that in some cases domesticated and wild grains were planted together. The technological, subsistence, and social impact of rice and grain cultivation is not evident in archaeological data until after 1500 BC. For example, intensive wet-paddy rice agriculture was introduced into Korea shortly before or during the Middle Mumun pottery period (circa 850–550 BC) and reached Japan by the final Jōmon or initial Yayoi periods circa 300 BC.[59][60] A genomic study indicates that temperate japonica, which predominates in Korea and Japan, evolved after a global cooling event (the 4.2k event) that occurred 4,200 years ago.[54]
",5
6346,"Rice was cultivated in the Indian subcontinent from as early as 5,000 BC.[61] ""Several wild cereals, including rice, grew in the Vindhyan Hills, and rice cultivation, at sites such as Chopani-Mando and Mahagara, may have been underway as early as 7,000 BP. Rice appeared in the Belan and Ganges valley regions of northern India as early as 4530 BC and 5440 BC, respectively.[62] The early domestication process of rice in ancient India was based around the wild species Oryza nivara. This led to the local development of a mix of 'wetland' and 'dryland' agriculture of local Oryza sativa var. indica rice agriculture, before the truly 'wetland' rice Oryza sativa var. japonica, arrived around 2000 BC.[63]
",5
6347,"Rice was cultivated in the Indus Valley civilization (3rd millennium BC).[64] Agricultural activity during the second millennium BC included rice cultivation in the Kashmir and Harrappan regions.[62] Mixed farming was the basis of Indus valley economy.[64]
",5
6348,"O. sativa was recovered from a grave at Susa in Iran (dated to the first century AD) at one end of the ancient world, while at the same time rice was grown in the Po valley in Italy. In northern Iran, in Gilan province, many indica rice cultivars including 'Gerdeh', 'Hashemi', 'Hasani', and 'Gharib' have been bred by farmers.[65]
",5
6349,"Although Oryza sativa was domesticated in Asia, the now less popular Oryza glaberrima rice was independently domesticated in Africa 3,000 to 3,500 years ago.[66] Between 1500 and 800 BC, Oryza glaberrima propagated from its original centre, the Niger River delta, and extended to Senegal. However, it never developed far from its original region. Its cultivation even declined in favour of the Asian species, which was introduced to East Africa early in the common era and spread westward.[67]
",5
6350,"Rice was known to the Classical world, being imported from Egypt, and perhaps west Asia. It was known to Greece (where it is still cultivated in Macedonia and Thrace) by returning soldiers from Alexander the Great's military expedition to Asia. Large deposits of rice from the first century AD have been found in Roman camps in Germany.[68]
",5
6351,"The Moors brought Asiatic rice to the Iberian Peninsula in the 10th century. Records indicate it was grown in Valencia and Majorca. In Majorca, rice cultivation seems to have stopped after the Christian conquest, although historians are not certain.[69]
",5
6352,"Muslims also brought rice to Sicily with cultivation starting in the 9th century,[70] where it was an important crop[69] long before it is noted in the plain of Pisa (1468) or in the Lombard plain (1475), where its cultivation was promoted by Ludovico Sforza, Duke of Milan, and demonstrated in his model farms.[71]
",5
6353,"After the 15th century, rice spread throughout Italy and then France, later propagating to all the continents during the age of European exploration.
",5
6354,"In Russia, a short-grain, starchy rice similar to the Italian varieties, has been grown in the Krasnodar Krai, and known in Russia as ""Kuban Rice"" or ""Krasnodar Rice"". In the Russian Far East several japonica cultivars are grown in Primorye around the Khanka lake. Increasing scale of rice production in the region has recently brought criticism towards growers' alleged bad practices in regards to the environment.
",5
6355,"The origin of Oryza sativa rice domestication has been a subject of much debate among those who study crop history and anthropology - whether rice originated in India or China.[72][73] Asian rice, Oryza sativa, is one of oldest crop species. It has tens of thousands of varieties and two major subspecies, japonica and indica. Archeologists focusing on East and Southeast Asia argue that rice farming began in south-central China along the Yangtze River and spread to Korea and Japan from there south and northeast.[74][73] Archaeologists working in India argue that rice cultivation started in the valley of the Ganges River[75] and Indus valley,[76] by peoples unconnected to those of the Yangzte.[77][78][73]
",5
6356,"A 2012 study, through a map of genome variation in modern wild rice populations, indicated that the domestication of rice probably occurred around the central Pearl River valley region of southern China, in contradiction to archaeological evidence.[79] However, the study is based on modern distribution maps of wild rice populations which are potentially misleading due to drastic climatic changes that happened during the end of the last glacial period, ca. 12,000 years ago. Human activity over thousands of years has also removed populations of wild rice from their previous ranges. Based on Chinese texts, there were populations of wild rice along the Yangtze basin in c. AD 1,000 that have recently become extinct.[49]
",5
6357,"An older theory, based on one chloroplast and two nuclear gene regions, Londo et al. (2006) had proposed that O. sativa rice was domesticated at least twice—indica in eastern India, Myanmar, and Thailand; and japonica in southern China and Vietnam—though they concede that archaeological and genetic evidence exist for a single domestication of rice in the lowlands of southern China.[80]
",5
6358,"In 2003, Korean archaeologists alleged they discovered burnt grains of domesticated rice in Soro-ri, Korea, which dated to 13,000 BC. These antedate the oldest grains in China, which were dated to 10,000 BC, and potentially challenge the mainstream explanation that domesticated rice originated in China.[81] The findings were received by academia with strong skepticism at first,[82][83] but later accepted in secondary sources such as the archaeology text book Archaeology: Theories, Methods and Practice.[84]
",5
6359,"Today, the majority of all rice produced comes from China, India, Indonesia, Bangladesh, Vietnam, Thailand, Myanmar, Pakistan, Philippines, Korea and Japan. Asian farmers still account for 87% of the world's total rice production. Because so much rice is produced in Bangladesh, it is also the staple food of the country.
",5
6360,"Rice is a staple food for all classes in contemporary Indonesia,[85][86] and it holds the central place in Indonesian culture and Indonesian cuisine: it shapes the landscape; is sold at markets; and is served in most meals. Rice accounts for more than half of the calories in the average diet, and the source of livelihood for about 20 million households. The importance of rice in Indonesian culture is demonstrated through the reverence of Dewi Sri, the rice goddess of ancient Java and Bali.
",5
6361,"Evidence of wild rice on the island of Sulawesi dates from 3000 BC. Historic written evidence for the earliest cultivation, however, comes from eighth century stone inscriptions from the central island of Java, which show kings levied taxes in rice. The images of rice cultivation, rice barn, and mouse pest investing a rice field is evident in Karmawibhangga bas-reliefs of Borobudur. Divisions of labour between men, women, and animals that are still in place in Indonesian rice cultivation, were carved into relief friezes on the ninth century Prambanan temples in Central Java: a water buffalo attached to a plough; women planting seedlings and pounding grain; and a man carrying sheaves of rice on each end of a pole across his shoulders (pikulan). In the sixteenth century, Europeans visiting the Indonesian islands saw rice as a new prestige food served to the aristocracy during ceremonies and feasts.[86]
",5
6362,"Rice is the major food amongst all the ethnic groups in Nepal. In the Terai, most rice varieties are cultivated during the rainy season. The principal rice growing season, known as ""Berna-Bue Charne"", is from June to July when water is sufficient for only a part of the fields; the subsidiary season, known as ""Ropai, is from April to September, when there is usually enough water to sustain the cultivation of all rice fields. Farmers use irrigation channels throughout the cultivation seasons.[citation needed]
",5
6363,"The Banaue Rice Terraces (Filipino: Hagdan-hagdang Palayan ng Banawe) are 2,000-year-old terraces that were carved into the mountains of Ifugao in the Philippines by the ancestors of the Igorot people. The Rice Terraces are commonly referred to as the ""Eighth Wonder of the World"".[87][88][89] It is commonly thought that the terraces were built with minimal equipment, largely by hand. The terraces are located approximately 1,500 meters (5,000 ft) above sea level. They are fed by an ancient irrigation system from the rainforests above the terraces. It is said that if the steps were put end to end, it would encircle half the globe.[90] The terraces are found in the province of Ifugao and the Ifugao people have been its caretakers. Ifugao culture revolves[91] around rice and the culture displays an elaborate array of celebrations linked with agricultural rites from rice cultivation to rice consumption. The harvest season generally calls for thanksgiving feasts, while the concluding harvest rites called tango or tungul (a day of rest) entails a strict taboo on any agricultural work. Partaking of the bayah (rice beer), rice cakes, and betel nut constitutes an indelible practise during the festivities.
",5
6364,"The Ifugao people practice traditional farming spending most of their labor at their terraces and forest lands while occasionally tending to root crop cultivation. The Ifugaos have also[90] been known to culture edible shells, fruit trees, and other vegetables which have been exhibited among Ifugaos for generations. The building of the rice terraces consists of blanketing walls with stones and earth which are designed to draw water from a main irrigation canal above the terrace clusters. Indigenous rice terracing technologies have been identified with the Ifugao's rice terraces such as their knowledge of water irrigation, stonework, earthwork and terrace maintenance. As their source of life and art, the rice terraces have sustained and shaped the lives of the community members.
",5
6365,"Rice is the staple food amongst all the ethnic groups in Sri Lanka. Agriculture in Sri Lanka mainly depends on the rice cultivation. Rice production is acutely dependent on rainfall and government supply necessity of water through irrigation channels throughout the cultivation seasons. The principal cultivation season, known as ""Maha"", is from October to March and the subsidiary cultivation season, known as ""Yala"", is from April to September. During Maha season, there is usually enough water to sustain the cultivation of all rice fields, nevertheless in Yala season there is only enough water for cultivation of half of the land extent. Traditional rice varieties are now making a comeback with the recent interest in green foods.
",5
6366,"Rice is the main export of Thailand, especially white jasmine rice 105 (Dok Mali 105).[92] Thailand has a large number of rice varieties, 3,500 kinds with different characters, and five kinds of wild rice cultivates.[93] In each region of the country there are different rice seed types. Their use depends on weather, atmosphere, and topography.[94]
",5
6367,"The northern region has both low lands and high lands. The farmers' usual crop is non-glutinous rice[94] such as Niew Sun Pah Tong rice. This rice is naturally protected from leaf disease, and its paddy (unmilled rice) (Thai: ข้าวเปลือก) has a brown color.[95] The northeastern region is a large area where farmers can cultivate about 36 million square meters of rice. Although most of it is plains and dry areas,[96] white jasmine rice 105—the most famous Thai rice—can be grown there. White jasmine rice was developed in Chonburi Province first and after that grown in many areas in the country, but the rice from this region has a high quality, because it is softer, whiter, and more fragrant.[97] This rice can resist drought, acidic soil, and alkaline soil.[98]
",5
6368,"The central region is mostly composed of plains. Most farmers grow Jao rice.[96] For example, Pathum Thani 1 rice which has qualities similar to white jasmine 105 rice. Its paddy has the color of thatch and the cooked rice also has fragrant grains.[99]
",5
6369,"In the southern region, most farmers transplant around boundaries to the flood plains or on the plains between mountains. Farming in the region is slower than other regions because the rainy season comes later.[96] The popular rice varieties in this area are the Leb Nok Pattani seeds, a type of Jao rice. Its paddy has the color of thatch and it can be processed to make noodles.[100]
",5
6370,"One of the earliest known examples of companion planting is the growing of rice with Azolla, the mosquito fern, which covers the top of a fresh rice paddy's water, blocking out any competing plants, as well as fixing nitrogen from the atmosphere for the rice to use. The rice is planted when it is tall enough to poke out above the azolla. This method has been used for at least a thousand years.
",5
6371,"Rice was grown in some areas of Mesopotamia (southern Iraq). With the rise of Islam it moved north to Nisibin, the southern shores of the Caspian Sea (in Gilan and Mazanderan provinces of Iran)[65] and then beyond the Muslim world into the valley of the Volga. In Egypt, rice is mainly grown in the Nile Delta. In Palestine, rice came to be grown in the Jordan Valley. Rice is also grown in Saudi Arabia at Al-Ahsa Oasis and in Yemen.[69]
",5
6372,"Most of the rice used today in the cuisine of the Americas is not native, but was introduced to Latin America and the Caribbean by European colonizers at an early date. However, there are at least two native (endemic) species of rice present in the Amazon region of South America, and one or both were used by the indigenous inhabitants of the region to create the domesticated form Oryza sp., some 4000 years ago.[101]
",5
6373,"Spanish colonizers introduced Asian rice to Mexico in the 1520s at Veracruz, and the Portuguese and their African slaves introduced it at about the same time to colonial Brazil.[102] Recent scholarship suggests that enslaved Africans played an active role in the establishment of rice in the New World and that African rice was an important crop from an early period.[103] Varieties of rice and bean dishes that were a staple dish along the peoples of West Africa remained a staple among their descendants subjected to slavery in the Spanish New World colonies, Brazil and elsewhere in the Americas.[104]
",5
6374,"In 1694, rice arrived in South Carolina, probably originating from Madagascar.[102] Tradition (possibly apocryphal) has it that pirate John Thurber was returning from a slave-trading voyage to Madagascar when he was blown off course and put into Charleston for repairs. While there he gave a bag of seed rice to explorer Dr. Henry Woodward, who planted the rice and experimented with it until finding that it grew exceptionally well in the wet Carolina soil.[105][106]
",5
6375,"The mastery of rice farming was a challenge for the English and other European settlers who were unfamiliar with the crop. Native Americans, who mostly gathered wild rice, were also inexperienced with rice cultivation. However, within the first fifty years of settlement rice became the dominant crop in South Carolina.[107]
",5
6376,"In the United States, colonial South Carolina and Georgia grew and amassed great wealth from the slave labor obtained from the Senegambia area of West Africa and from coastal Sierra Leone. At the port of Charleston, through which 40% of all American slave imports passed, slaves from this region of Africa brought the highest prices due to their prior knowledge of rice culture, which was put to use on the many rice plantations around Georgetown, Charleston, and Savannah.
",5
6377,"From the enslaved Africans, plantation owners learned how to dyke the marshes and periodically flood the fields. At first the rice was laboriously milled by hand using large mortars and pestles made of wood, then winnowed in sweetgrass baskets (the making of which was another skill brought by slaves from Africa). The invention of the rice mill increased profitability of the crop, and the addition of water power for the mills in 1787 by millwright Jonathan Lucas was another step forward.
",5
6378,"Rice culture in the southeastern U.S. became less profitable with the loss of slave labor after the American Civil War, and it finally died out just after the turn of the 20th century. Today, people can visit the only remaining rice plantation in South Carolina that still has the original winnowing barn and rice mill from the mid-19th century at the historic Mansfield Plantation in Georgetown, South Carolina. The predominant strain of rice in the Carolinas was from Africa and was known as 'Carolina Gold'. The cultivar has been preserved and there are current attempts to reintroduce it as a commercially grown crop.[108]
",5
6379,"In the southern United States, rice has been grown in southern Arkansas, Louisiana, and east Texas since the mid-19th century. Many Cajun farmers grew rice in wet marshes and low-lying prairies where they could also farm crayfish when the fields were flooded.[109] In recent years rice production has risen in North America, especially in the Mississippi embayment in the states of Arkansas and Mississippi (see also Arkansas Delta and Mississippi Delta).
",5
6380,"Rice cultivation began in California during the California Gold Rush, when an estimated 40,000 Chinese laborers immigrated to the state and grew small amounts of the grain for their own consumption. However, commercial production began only in 1912 in the town of Richvale in Butte County.[110] By 2006, California produced the second-largest rice crop in the United States,[111] after Arkansas, with production concentrated in six counties north of Sacramento.[112] Unlike the Arkansas–Mississippi Delta region, California's production is dominated by short- and medium-grain japonica varieties, including cultivars developed for the local climate such as Calrose, which makes up as much as 85% of the state's crop.[113]
",5
6381,"References to ""wild rice"" native to North America are to the unrelated Zizania palustris.[114]
",5
6382,"More than 100 varieties of rice are commercially produced primarily in six states (Arkansas, Texas, Louisiana, Mississippi, Missouri, and California) in the U.S.[115] According to estimates for the 2006 crop year, rice production in the U.S. is valued at $1.88 billion, approximately half of which is expected to be exported. The U.S. provides about 12% of world rice trade.[115] The majority of domestic utilization of U.S. rice is direct food use (58%), while 16% is used in each of processed foods and beer. 10% is found in pet food.[115]
",5
6383,"Rice was one of the earliest crops planted in Australia by British settlers, who had experience with rice plantations in the Americas and India.
",5
6384,"Although attempts to grow rice in the well-watered north of Australia have been made for many years, they have consistently failed because of inherent iron and manganese toxicities in the soils and destruction by pests.
",5
6385,"In the 1920s, it was seen as a possible irrigation crop on soils within the Murray–Darling basin that were too heavy for the cultivation of fruit and too infertile for wheat.[116]
",5
6386,"Because irrigation water, despite the extremely low runoff of temperate Australia,[117] was (and remains) very cheap, the growing of rice was taken up by agricultural groups over the following decades. Californian varieties of rice were found suitable for the climate in the Riverina,[116] and the first mill opened at Leeton in 1951.
",5
6387,"Even before this Australia's rice production greatly exceeded local needs,[116] and rice exports to Japan have become a major source of foreign currency. Above-average rainfall from the 1950s to the middle 1990s[118] encouraged the expansion of the Riverina rice industry, but its prodigious water use in a practically waterless region began to attract the attention of environmental scientists. These became severely concerned with declining flow in the Snowy River and the lower Murray River.
",5
6388,"Although rice growing in Australia is highly profitable due to the cheapness of land, several recent years of severe drought have led many to call for its elimination because of its effects on extremely fragile aquatic ecosystems. The Australian rice industry is somewhat opportunistic, with the area planted varying significantly from season to season depending on water allocations in the Murray and Murrumbidgee irrigation regions.
",5
6389,"Australian Aboriginal people have harvested native rice varieties for thousands of years, and there are ongoing efforts to grow commercial quantities of these species.[119][120]
",5
6390,"In 2017, world production of paddy rice was 769.7 million tonnes,[121] led by China and India with a combined 49% of this total.[1] Other major producers were Indonesia, Bangladesh and Vietnam. The five major producers accounted for 72% of total production, while the top fifteen producers accounted for 91% of total world production in 2017 (see table on right). Developing countries account for 95% of the total production.[122]
",5
6391,"Rice is a major food staple and a mainstay for the rural population and their food security. It is mainly cultivated by small farmers in holdings of less than one hectare. Rice is also a wage commodity for workers in the cash crop or non-agricultural sectors. Rice is vital for the nutrition of much of the population in Asia, as well as in Latin America and the Caribbean and in Africa; it is central to the food security of over half the world population.
",5
6392,"Many rice grain producing countries have significant losses post-harvest at the farm and because of poor roads, inadequate storage technologies, inefficient supply chains and farmer's inability to bring the produce into retail markets dominated by small shopkeepers. A World Bank – FAO study claims 8% to 26% of rice is lost in developing nations, on average, every year, because of post-harvest problems and poor infrastructure. Some sources claim the post-harvest losses exceed 40%.[122][123] Not only do these losses reduce food security in the world, the study claims that farmers in developing countries such as China, India and others lose approximately US$89 billion of income in preventable post-harvest farm losses, poor transport, the lack of proper storage and retail. One study claims that if these post-harvest grain losses could be eliminated with better infrastructure and retail network, in India alone enough food would be saved every year to feed 70 to 100 million people.[124]
",5
6393,"The seeds of the rice plant are first milled using a rice huller to remove the chaff (the outer husks of the grain) (see: rice hulls). At this point in the process, the product is called brown rice. The milling may be continued, removing the bran, i.e., the rest of the husk and the germ, thereby creating white rice. White rice, which keeps longer, lacks some important nutrients; moreover, in a limited diet which does not supplement the rice, brown rice helps to prevent the disease beriberi.
",5
6394,"Either by hand or in a rice polisher, white rice may be buffed with glucose or talc powder (often called polished rice, though this term may also refer to white rice in general), parboiled, or processed into flour. White rice may also be enriched by adding nutrients, especially those lost during the milling process. While the cheapest method of enriching involves adding a powdered blend of nutrients that will easily wash off (in the United States, rice which has been so treated requires a label warning against rinsing), more sophisticated methods apply nutrients directly to the grain, coating the grain with a water-insoluble substance which is resistant to washing.
",5
6395,"In some countries, a popular form, parboiled rice (also known as converted rice and easy-cook rice[125]) is subjected to a steaming or parboiling process while still a brown rice grain. The parboil process causes a gelatinisation of the starch in the grains. The grains become less brittle, and the color of the milled grain changes from white to yellow. The rice is then dried, and can then be milled as usual or used as brown rice. Milled parboiled rice is nutritionally superior to standard milled rice, because the process causes nutrients from the outer husk (especially thiamine) to move into the endosperm, so that less is subsequently lost when the husk is polished off during milling. Parboiled rice has an additional benefit in that it does not stick to the pan during cooking, as happens when cooking regular white rice. This type of rice is eaten in parts of India and countries of West Africa are also accustomed to consuming parboiled rice.
",5
6396,"Rice bran, called nuka in Japan, is a valuable commodity in Asia and is used for many daily needs. It is a moist, oily inner layer which is heated to produce oil. It is also used as a pickling bed in making rice bran pickles and takuan.
",5
6397,"Raw rice may be ground into flour for many uses, including making many kinds of beverages, such as amazake, horchata, rice milk, and rice wine. Rice does not contain gluten, so is suitable for people on a gluten-free diet.[126] Rice can be made into various types of noodles. Raw, wild, or brown rice may also be consumed by raw-foodist or fruitarians if soaked and sprouted (usually a week to 30 days – gaba rice).
",5
6398,"Processed rice seeds must be boiled or steamed before eating. Boiled rice may be further fried in cooking oil or butter (known as fried rice), or beaten in a tub to make mochi.
",5
6399,"Rice is a good source of protein and a staple food in many parts of the world, but it is not a complete protein: it does not contain all of the essential amino acids in sufficient amounts for good health, and should be combined with other sources of protein, such as nuts, seeds, beans, fish, or meat.[127]
",5
6400,"Rice, like other cereal grains, can be puffed (or popped). This process takes advantage of the grains' water content and typically involves heating grains in a special chamber. Further puffing is sometimes accomplished by processing puffed pellets in a low-pressure chamber. The ideal gas law means either lowering the local pressure or raising the water temperature results in an increase in volume prior to water evaporation, resulting in a puffy texture. Bulk raw rice density is about 0.9 g/cm³. It decreases to less than one-tenth that when puffed.
",5
6401,"Unmilled rice, known as ""paddy"" (Indonesia and Malaysia: padi; Philippines, palay), is usually harvested when the grains have a moisture content of around 25%. In most Asian countries, where rice is almost entirely the product of smallholder agriculture, harvesting is carried out manually, although there is a growing interest in mechanical harvesting. Harvesting can be carried out by the farmers themselves, but is also frequently done by seasonal labor groups. Harvesting is followed by threshing, either immediately or within a day or two. Again, much threshing is still carried out by hand but there is an increasing use of mechanical threshers. Subsequently, paddy needs to be dried to bring down the moisture content to no more than 20% for milling.
",5
6402,"A familiar sight in several Asian countries is paddy laid out to dry along roads. However, in most countries the bulk of drying of marketed paddy takes place in mills, with village-level drying being used for paddy to be consumed by farm families. Mills either sun dry or use mechanical driers or both. Drying has to be carried out quickly to avoid the formation of molds. Mills range from simple hullers, with a throughput of a couple of tonnes a day, that simply remove the outer husk, to enormous operations that can process 4,000 tonnes a day and produce highly polished rice. A good mill can achieve a paddy-to-rice conversion rate of up to 72% but smaller, inefficient mills often struggle to achieve 60%. These smaller mills often do not buy paddy and sell rice but only service farmers who want to mill their paddy for their own consumption.
",5
6403,"Because of the importance of rice to human nutrition and food security in Asia, the domestic rice markets tend to be subject to considerable state involvement. While the private sector plays a leading role in most countries, agencies such as BULOG in Indonesia, the NFA in the Philippines, VINAFOOD in Vietnam and the Food Corporation of India are all heavily involved in purchasing of paddy from farmers or rice from mills and in distributing rice to poorer people. BULOG and NFA monopolise rice imports into their countries while VINAFOOD controls all exports from Vietnam.[128]
",5
6404,"World trade figures are very different from those for production, as less than 8% of rice produced is traded internationally.[129] In economic terms, the global rice trade was a small fraction of 1% of world mercantile trade. Many countries consider rice as a strategic food staple, and various governments subject its trade to a wide range of controls and interventions.
",5
6405,"Developing countries are the main players in the world rice trade, accounting for 83% of exports and 85% of imports. While there are numerous importers of rice, the exporters of rice are limited. Just five countries—Thailand, Vietnam, China, the United States and India—in decreasing order of exported quantities, accounted for about three-quarters of world rice exports in 2002.[122] However, this ranking has been rapidly changing in recent years. In 2010, the three largest exporters of rice, in decreasing order of quantity exported were Thailand, Vietnam and India. By 2012, India became the largest exporter of rice with a 100% increase in its exports on year-to-year basis, and Thailand slipped to third position.[130][131] Together, Thailand, Vietnam and India accounted for nearly 70% of the world rice exports.
",5
6406,"The primary variety exported by Thailand and Vietnam were Jasmine rice, while exports from India included aromatic Basmati variety. China, an exporter of rice in early 2000s, was a net importer of rice in 2010 and will become the largest net importer, surpassing Nigeria, in 2013.[129][132] According to a USDA report, the world's largest exporters of rice in 2012 were India (9.75 million tonnes), Vietnam (7 million tonnes), Thailand (6.5 million tonnes), Pakistan (3.75 million tonnes) and the United States (3.5 million tonnes).[133]
",5
6407,"Major importers usually include Nigeria, Indonesia, Bangladesh, Saudi Arabia, Iran, Iraq, Malaysia, the Philippines, Brazil and some African and Persian Gulf countries. In common with other West African countries, Nigeria is actively promoting domestic production. However, its very heavy import duties (110%) open it to smuggling from neighboring countries.[134] Parboiled rice is particularly popular in Nigeria. Although China and India are the two largest producers of rice in the world, both countries consume the majority of the rice produced domestically, leaving little to be traded internationally.
",5
6408,"The average world yield for rice was 4.3 tonnes per hectare, in 2010.
",5
6409,"Australian rice farms were the most productive in 2010, with a nationwide average of 10.8 tonnes per hectare.[135]
",5
6410,"Yuan Longping of China National Hybrid Rice Research and Development Center, China, set a world record for rice yield in 2010 at 19 tonnes per hectare on a demonstration plot. In 2011, this record was surpassed by an Indian farmer, Sumant Kumar, with 22.4 tonnes per hectare in Bihar. Both these farmers claim to have employed newly developed rice breeds and System of Rice Intensification (SRI), a recent innovation in rice farming. SRI is claimed to have set new national records in rice yields, within the last 10 years, in many countries. The claimed Chinese and Indian yields have yet to be demonstrated on seven-hectare lots and to be reproducible over two consecutive years on the same farm.[136][137][138][139]
",5
6411,"In late 2007 to May 2008, the price of grains rose greatly due to droughts in major producing countries (particularly Australia), increased use of grains for animal feed and US subsidies for bio-fuel production. Although there was no shortage of rice on world markets this general upward trend in grain prices led to panic buying by consumers, government rice export bans (in particular, by Vietnam and India) and inflated import orders by the Philippines marketing board, the National Food Authority. This caused significant rises in rice prices. In late April 2008, prices hit 24 US cents a pound, twice the price of seven months earlier.[140] Over the period of 2007 to 2013, the Chinese government has substantially increased the price it pays domestic farmers for their rice, rising to US$500 per metric ton by 2013.[129] The 2013 price of rice originating from other southeast Asian countries was a comparably low US$350 per metric ton.[129]
",5
6412,"On April 30, 2008, Thailand announced plans for the creation of the Organisation of Rice Exporting Countries (OREC) with the intention that this should develop into a price-fixing cartel for rice.[141][142] However, as of mid-2011[update] little progress had been made to achieve this.
",5
6413,"As of 2013[update], world food consumption of rice was 565.6 million metric tons of paddy equivalent (377,283 of milled equivalent), while the largest consumers were China consuming 162.4 million metric tons of paddy equivalent (28.7% of world consumption) and India consuming 130.4 million metric tons of paddy equivalent (23.1% of world consumption).[143]
",5
6414,"Between 1961 and 2002, per capita consumption of rice increased by 40%.
",5
6415,"Rice is the most important crop in Asia. In Cambodia, for example, 90% of the total agricultural area is used for rice production.[144]
",5
6416,"U.S. rice consumption has risen sharply over the past 25 years, fueled in part by commercial applications such as beer production.[145] Almost one in five adult Americans now report eating at least half a serving of white or brown rice per day.[146]
",5
6417,"Rice cultivation on wetland rice fields is thought to be responsible for 11% of the anthropogenic methane emissions.[147] Rice requires slightly more water to produce than other grains.[148] Rice production uses almost a third of Earth's fresh water.[149]
",5
6418,"Long-term flooding of rice fields cuts the soil off from atmospheric oxygen and causes anaerobic fermentation of organic matter in the soil.[150] Methane production from rice cultivation contributes ~1.5% of anthropogenic greenhouse gases.[151] Methane is twenty times more potent a greenhouse gas than carbon dioxide.[152]
",5
6419,"A 2010 study found that, as a result of rising temperatures and decreasing solar radiation during the later years of the 20th century, the rice yield growth rate has decreased in many parts of Asia, compared to what would have been observed had the temperature and solar radiation trends not occurred.[153][154] The yield growth rate had fallen 10–20% at some locations. The study was based on records from 227 farms in Thailand, Vietnam, Nepal, India, China, Bangladesh, and Pakistan. The mechanism of this falling yield was not clear, but might involve increased respiration during warm nights, which expends energy without being able to photosynthesize.
",5
6420,"Rice requires high temperature above 20 °C (68 °F) but not more than 35 to 40 °C (95 to 104 °F); the optimal temperature is between 20 and 30 °C (68 and 86 °F).[155]
",5
6421,"The amount of solar radiation received during the 45 days leading up to harvest determines final crop output.[155]
",5
6422,"High water vapor content (in humid tropics) subjects unusual stress which favors the spread of fungal and bacterial diseases.[155]
",5
6423,"Light wind transports CO2 to the leaf canopy but strong wind causes severe damage and may lead to sterility (due to pollen dehydration, spikelet sterility, and abortive endosperms).[155]
",5
6424,"Rice pests are any organisms or microbes with the potential to reduce the yield or value of the rice crop (or of rice seeds).[156] Rice pests include weeds, pathogens, insects, nematode, rodents, and birds. A variety of factors can contribute to pest outbreaks, including climatic factors, improper irrigation, the overuse of insecticides and high rates of nitrogen fertilizer application.[157] Weather conditions also contribute to pest outbreaks. For example, rice gall midge and army worm outbreaks tend to follow periods of high rainfall early in the wet season, while thrips outbreaks are associated with drought.[158]
",5
6425,"Major rice insect pests include: the brown planthopper (BPH),[159] several species of stemborers—including those in the genera Scirpophaga and Chilo,[160] the rice gall midge,[161] several species of rice bugs,[162] notably in the genus Leptocorisa,[163] defoliators such as the rice: leafroller, hispa and grasshoppers.[164] The fall army worm, a species of Lepidoptera, also targets and causes damage to rice crops.[165] Rice weevils attack stored produce.
",5
6426,"Rice blast, caused by the fungus Magnaporthe grisea,[166] is the most significant disease affecting rice cultivation. Other major rice diseases include: sheath blight (caused by Rhizoctonia solani), rice ragged stunt (vector: BPH), and tungro (vector: Nephotettix spp).[167] There is also an ascomycete fungus, Cochliobolus miyabeanus, that causes brown spot disease in rice.[168][169]
",5
6427,"Several nematode species infect rice crops, causing diseases such as Ufra (Ditylenchus dipsaci), White tip disease (Aphelenchoide bessei), and root knot disease (Meloidogyne graminicola). Some nematode species such as Pratylenchus spp. are most dangerous in upland rice of all parts of the world. Rice root nematode (Hirschmanniella oryzae) is a migratory endoparasite which on higher inoculum levels will lead to complete destruction of a rice crop. Beyond being obligate parasites, they also decrease the vigor of plants and increase the plants' susceptibility to other pests and diseases.
",5
6428,"These include the apple snail Pomacea canaliculata, panicle rice mite, rats,[170] and the weed Echinochloa crusgali.[171]
",5
6429,"Crop protection scientists are trying to develop rice pest management techniques which are sustainable. In other words, to manage crop pests in such a manner that future crop production is not threatened.[172] Sustainable pest management is based on four principles: biodiversity, host plant resistance (HPR),[173] landscape ecology, and hierarchies in a landscape—from biological to social.[174] At present, rice pest management includes cultural techniques, pest-resistant rice varieties,[173] and pesticides (which include insecticide). Increasingly, there is evidence that farmers' pesticide applications are often unnecessary, and even facilitate pest outbreaks.[175][176][177][178] By reducing the populations of natural enemies of rice pests,[179] misuse of insecticides can actually lead to pest outbreaks.[180] The International Rice Research Institute (IRRI) demonstrated in 1993 that an 87.5% reduction in pesticide use can lead to an overall drop in pest numbers.[181] IRRI also conducted two campaigns in 1994 and 2003, respectively, which discouraged insecticide misuse and smarter pest management in Vietnam.[182][183]
",5
6430,"Rice plants produce their own chemical defenses to protect themselves from pest attacks. Some synthetic chemicals, such as the herbicide 2,4-D, cause the plant to increase the production of certain defensive chemicals and thereby increase the plant's resistance to some types of pests.[184] Conversely, other chemicals, such as the insecticide imidacloprid, can induce changes in the gene expression of the rice that cause the plant to become more susceptible to attacks by certain types of pests.[185] 5-Alkylresorcinols are chemicals that can also be found in rice.[186]
",5
6431,"Botanicals, so-called ""natural pesticides"", are used by some farmers in an attempt to control rice pests. Botanicals include extracts of leaves, or a mulch of the leaves themselves. Some upland rice farmers in Cambodia spread chopped leaves of the bitter bush (Chromolaena odorata) over the surface of fields after planting. This practice probably helps the soil retain moisture and thereby facilitates seed germination. Farmers also claim the leaves are a natural fertilizer and helps suppress weed and insect infestations.[187]
",5
6432,"Among rice cultivars, there are differences in the responses to, and recovery from, pest damage.[162][188][173] Many rice varieties have been selected for resistance to insect pests.[189][190][173] Therefore, particular cultivars are recommended for areas prone to certain pest problems.[173] The genetically based ability of a rice variety to withstand pest attacks is called resistance. Three main types of plant resistance to pests are recognized as nonpreference, antibiosis, and tolerance.[191] Nonpreference (or antixenosis) describes host plants which insects prefer to avoid; antibiosis is where insect survival is reduced after the ingestion of host tissue; and tolerance is the capacity of a plant to produce high yield or retain high quality despite insect infestation.[192]
",5
6433,"Over time, the use of pest-resistant rice varieties selects for pests that are able to overcome these mechanisms of resistance. When a rice variety is no longer able to resist pest infestations, resistance is said to have broken down. Rice varieties that can be widely grown for many years in the presence of pests and retain their ability to withstand the pests are said to have durable resistance. Mutants of popular rice varieties are regularly screened by plant breeders to discover new sources of durable resistance.[191][193]
",5
6434,"Rice is parasitized by the weed eudicot Striga hermonthica,[194] which is of local importance for this crop.
",5
6435,"While most rice is bred for crop quality and productivity, there are varieties selected for characteristics such as texture, smell, and firmness. There are four major categories of rice worldwide: indica, japonica, aromatic and glutinous. The different varieties of rice are not considered interchangeable, either in food preparation or agriculture, so as a result, each major variety is a completely separate market from other varieties. It is common for one variety of rice to rise in price while another one drops in price.[195]
",5
6436,"Rice cultivars also fall into groups according to environmental conditions, season of planting, and season of harvest, called ecotypes. Some major groups are the Japan-type (grown in Japan), ""buly"" and ""tjereh"" types (Indonesia); sali (or aman—main winter crop), ahu (also aush or ghariya, summer), and boro (spring) (Bengal and Assam).[196][197] Cultivars exist that are adapted to deep flooding, and these are generally called ""floating rice"".[198]
",5
6437,"The largest collection of rice cultivars is at the International Rice Research Institute[199] in the Philippines, with over 100,000 rice accessions[200] held in the International Rice Genebank.[201] Rice cultivars are often classified by their grain shapes and texture. For example, Thai Jasmine rice is long-grain and relatively less sticky, as some long-grain rice contains less amylopectin than short-grain cultivars. Chinese restaurants often serve long-grain as plain unseasoned steamed rice though short-grain rice is common as well. Japanese mochi rice and Chinese sticky rice are short-grain. Chinese people use sticky rice which is properly known as ""glutinous rice"" (note: glutinous refer to the glue-like characteristic of rice; does not refer to ""gluten"") to make zongzi. The Japanese table rice is a sticky, short-grain rice. Japanese sake rice is another kind as well.
",5
6438,"Indian rice cultivars include long-grained and aromatic Basmati (ਬਾਸਮਤੀ) (grown in the North), long and medium-grained Patna rice, and in South India (Andhra Pradesh and Karnataka) short-grained Sona Masuri (also called as Bangaru theegalu). In the state of Tamil Nadu, the most prized cultivar is ponni which is primarily grown in the delta regions of the Kaveri River. Kaveri is also referred to as ponni in the South and the name reflects the geographic region where it is grown. In the Western Indian state of Maharashtra, a short grain variety called Ambemohar is very popular. This rice has a characteristic fragrance of Mango blossom.
",5
6439,"Aromatic rices have definite aromas and flavors; the most noted cultivars are Thai fragrant rice, Basmati, Patna rice, Vietnamese fragrant rice, and a hybrid cultivar from America, sold under the trade name Texmati. Both Basmati and Texmati have a mild popcorn-like aroma and flavor. In Indonesia, there are also red and black cultivars.
",5
6440,"High-yield cultivars of rice suitable for cultivation in Africa and other dry ecosystems, called the new rice for Africa (NERICA) cultivars, have been developed. It is hoped that their cultivation will improve food security in West Africa.
",5
6441,"Draft genomes for the two most common rice cultivars, indica and japonica, were published in April 2002. Rice was chosen as a model organism for the biology of grasses because of its relatively small genome (~430 megabase pairs). Rice was the first crop with a complete genome sequence.[202]
",5
6442,"On December 16, 2002, the UN General Assembly declared the year 2004 the International Year of Rice. The declaration was sponsored by more than 40 countries.
",5
6443,"The high-yielding varieties are a group of crops created intentionally during the Green Revolution to increase global food production. This project enabled labor markets in Asia to shift away from agriculture, and into industrial sectors. The first ""Rice Car"", IR8 was produced in 1966 at the International Rice Research Institute which is based in the Philippines at the University of the Philippines' Los Baños site. IR8 was created through a cross between an Indonesian variety named ""Peta"" and a Chinese variety named ""Dee Geo Woo Gen.""[203]
",5
6444,"Scientists have identified and cloned many genes involved in the gibberellin signaling pathway, including GAI1 (Gibberellin Insensitive) and SLR1 (Slender Rice).[204] Disruption of gibberellin signaling can lead to significantly reduced stem growth leading to a dwarf phenotype. Photosynthetic investment in the stem is reduced dramatically as the shorter plants are inherently more stable mechanically. Assimilates become redirected to grain production, amplifying in particular the effect of chemical fertilizers on commercial yield. In the presence of nitrogen fertilizers, and intensive crop management, these varieties increase their yield two to three times.
",5
6445,"As the UN Millennium Development project seeks to spread global economic development to Africa, the ""Green Revolution"" is cited as the model for economic development. With the intent of replicating the successful Asian boom in agronomic productivity, groups like the Earth Institute are doing research on African agricultural systems, hoping to increase productivity. An important way this can happen is the production of ""New Rices for Africa"" (NERICA). These rices, selected to tolerate the low input and harsh growing conditions of African agriculture, are produced by the African Rice Center, and billed as technology ""from Africa, for Africa"". The NERICA have appeared in The New York Times (October 10, 2007) and International Herald Tribune (October 9, 2007), trumpeted as miracle crops that will dramatically increase rice yield in Africa and enable an economic resurgence. Ongoing research in China to develop perennial rice could result in enhanced sustainability and food security.
",5
6446,"Rice kernels do not contain vitamin A, so people who obtain most of their calories from rice are at risk of vitamin A deficiency. German and Swiss researchers have genetically engineered rice to produce beta-carotene, the precursor to vitamin A, in the rice kernel. The beta-carotene turns the processed (white) rice a ""gold"" color, hence the name ""golden rice."" The beta-carotene is converted to vitamin A in humans who consume the rice.[205] Although some rice strains produce beta-carotene in the hull, no non-genetically engineered strains have been found that produce beta-carotene in the kernel, despite the testing of thousands of strains. Additional efforts are being made to improve the quantity and quality of other nutrients in golden rice.[206]
",5
6447,"The International Rice Research Institute is currently further developing and evaluating Golden Rice as a potential new way to help address vitamin A deficiency.[207]
",5
6448,"Ventria Bioscience has genetically modified rice to express lactoferrin, lysozyme which are proteins usually found in breast milk, and human serum albumin, These proteins have antiviral, antibacterial, and antifungal effects.[208]
",5
6449,"Rice containing these added proteins can be used as a component in oral rehydration solutions which are used to treat diarrheal diseases, thereby shortening their duration and reducing recurrence. Such supplements may also help reverse anemia.[209]
",5
6450,"Due to the varying levels that water can reach in regions of cultivation, flood tolerant varieties have long been developed and used. Flooding is an issue that many rice growers face, especially in South and South East Asia where flooding annually affects 20 million hectares.[210] Standard rice varieties cannot withstand stagnant flooding of more than about a week,[211] mainly as it disallows the plant access to necessary requirements such as sunlight and essential gas exchanges, inevitably leading to plants being unable to recover.[210]
In the past, this has led to massive losses in yields, such as in the Philippines, where in 2006, rice crops worth $65 million were lost to flooding.[212] Recently developed cultivars seek to improve flood tolerance.
",5
6451,"Drought represents a significant environmental stress for rice production, with 19–23 million hectares of rainfed rice production in South and South East Asia often at risk.[213][214] Under drought conditions, without sufficient water to afford them the ability to obtain the required levels of nutrients from the soil, conventional commercial rice varieties can be severely affected—for example, yield losses as high as 40% have affected some parts of India, with resulting losses of around US$800 million annually.[215]
",5
6452,"The International Rice Research Institute conducts research into developing drought-tolerant rice varieties, including the varieties 5411 and Sookha dhan, currently being employed by farmers in the Philippines and Nepal respectively.[214] In addition, in 2013 the Japanese National Institute for Agrobiological Sciences led a team which successfully inserted the DEEPER ROOTING 1 (DRO1) gene, from the Philippine upland rice variety Kinandang Patong, into the popular commercial rice variety IR64, giving rise to a far deeper root system in the resulting plants.[215] This facilitates an improved ability for the rice plant to derive its required nutrients in times of drought via accessing deeper layers of soil, a feature demonstrated by trials which saw the IR64 + DRO1 rice yields drop by 10% under moderate drought conditions, compared to 60% for the unmodified IR64 variety.[215][216]
",5
6453,"Soil salinity poses a major threat to rice crop productivity, particularly along low-lying coastal areas during the dry season.[213] For example, roughly 1 million hectares of the coastal areas of Bangladesh are affected by saline soils.[217] These high concentrations of salt can severely affect rice plants' normal physiology, especially during early stages of growth, and as such farmers are often forced to abandon these otherwise potentially usable areas.[218][219]
",5
6454,"Progress has been made, however, in developing rice varieties capable of tolerating such conditions; the hybrid created from the cross between the commercial rice variety IR56 and the wild rice species Oryza coarctata is one example.[220] O. coarctata is capable of successful growth in soils with double the limit of salinity of normal varieties, but lacks the ability to produce edible rice.[220] Developed by the International Rice Research Institute, the hybrid variety can utilise specialised leaf glands that allow for the removal of salt into the atmosphere. It was initially produced from one successful embryo out of 34,000 crosses between the two species; this was then backcrossed to IR56 with the aim of preserving the genes responsible for salt tolerance that were inherited from O. coarctata.[218] Extensive trials are planned prior to the new variety being available to farmers by approximately 2017–18.[218]
",5
6455,"When the problem of soil salinity arises it will be opportune to select salt tolerant varieties (IRRI[222] or to resort to soil salinity control.
",5
6456,"Soil salinity is often measured as the electric conductivity (EC) of the extract of a saturated soil paste (ECe). The EC units are usually expressed in decisiemens per metre or dS/m. The critical ECe value of 5.5 dS/m in the figure, obtained from measurements in farmers' fields, indicates that the rice crop is slightly salt sensitive.
",5
6457,"Producing rice in paddies is harmful for the environment due to the release of methane by methanogenic bacteria. These bacteria live in the anaerobic waterlogged soil, and live off nutrients released by rice roots. Researchers have recently reported in Nature that putting the barley gene SUSIBA2 into rice creates a shift in biomass production from root to shoot (above ground tissue becomes larger, while below ground tissue is reduced), decreasing the methanogen population, and resulting in a reduction of methane emissions of up to 97%. Apart from this environmental benefit, the modification also increases the amount of rice grains by 43%, which makes it a useful tool in feeding a growing world population.[223][224]
",5
6458,"Rice is used as a model organism for investigating the molecular mechanisms of meiosis and DNA repair in higher plants. Meiosis is a key stage of the sexual cycle in which diploid cells in the ovule (female structure) and the anther (male structure) produce haploid cells that develop further into gametophytes and gametes. So far, 28 meiotic genes of rice have been characterized.[225] Studies of rice gene OsRAD51C showed that this gene is necessary for homologous recombinational repair of DNA, particularly the accurate repair of DNA double-strand breaks during meiosis.[226] Rice gene OsDMC1 was found to be essential for pairing of homologous chromosomes during meiosis,[227] and rice gene OsMRE11 was found to be required for both synapsis of homologous chromosomes and repair of double-strand breaks during meiosis.[228]
",5
6459,"Rice plays an important role in certain religions and popular beliefs. In many cultures relatives will scatter rice during or towards the end of a wedding ceremony in front of the bride and groom.[229]
",5
6460,"The pounded rice ritual is conducted during weddings in Nepal. The bride gives a leafplate full of pounded rice to the groom after he requests it politely from her.[230]
",5
6461,"In the Philippines rice wine, popularly known as tapuy, is used for important occasions such as weddings, rice harvesting ceremonies and other celebrations.[231]
",5
6462,"Dewi Sri is the traditional rice goddess of the Javanese, Sundanese, and Balinese people in Indonesia. Most rituals involving Dewi Sri are associated with the mythical origin attributed to the rice plant, the staple food of the region.[232][233] In Thailand, a similar rice deity is known as Phosop; she is a deity more related to ancient local folklore than a goddess of a structured, mainstream religion.[234] The same female rice deity is known as Po Ino Nogar in Cambodia and as Nang Khosop in Laos. Ritual offerings are made during the different stages of rice production to propitiate the Rice Goddess in the corresponding cultures.
",5
6463,"A 2014 study of Han Chinese communities found that a history of farming rice makes cultures more psychologically interdependent, whereas a history of farming wheat makes cultures more independent.[235]
",5
6464,"A Royal Ploughing Ceremony is held in certain Asian countries to mark the beginning of the rice planting season. It is still honored in the kingdoms of Cambodia and Thailand.
",5
6465,"* Calpe, Concepción. ""International trade in rice: recent developments and prospects."" Rice is Life: scientific perspectives for the 21st century (2005). online
",5
6466,"
",5
